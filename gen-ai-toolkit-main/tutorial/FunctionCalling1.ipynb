{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84dfc603-e314-4bf3-8ef7-b3dad40031d8",
   "metadata": {},
   "source": [
    "## Demo of LLM function calling.\n",
    "\n",
    "```bash\n",
    "uv pip install numpydoc\n",
    "```\n",
    "\n",
    "- https://docs.litellm.ai/docs/completion/function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46582d86-69cd-4e59-af55-41440c5b9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73851b26-93da-483e-803f-6d6281e5a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "from textwrap import dedent\n",
    "from typing import Dict\n",
    "\n",
    "import litellm\n",
    "import openai\n",
    "\n",
    "# from docstring_parser import parse\n",
    "from faker import Faker\n",
    "from gait import (\n",
    "    a_message,\n",
    "    function_to_tool,\n",
    "    pydantic_to_tool,\n",
    "    s_message,\n",
    "    t_message,\n",
    "    u_message,\n",
    ")\n",
    "from jupyprint import jupyprint\n",
    "from litellm.utils import function_to_dict\n",
    "from pydantic import BaseModel, Field\n",
    "from rich.pretty import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6440a-24ab-4623-b12f-f2ac64163f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.drop_params = True\n",
    "# litellm._turn_on_debug()  # ðŸ‘ˆ this is the 1-line change you need to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6ddfa-d8dd-466c-ac5d-3ab7cef495cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(litellm.supports_function_calling(model=\"ollama_chat/llama3.2:latest\"))\n",
    "# print(litellm.supports_function_calling(model=\"azure/gpt-4o-mini\"))\n",
    "# print(litellm.supports_function_calling(model=\"ollama_chat/qwen2:7b-instruct-q8_0\"))\n",
    "# print(litellm.supports_function_calling(model=\"ollama_chat/phi4:14b-q8_0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7293b-3d83-4da9-9d17-72725db2c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53688c93-0d16-4b94-adc0-ec1c37ff35e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_lon(location: str) -> Dict:\n",
    "    \"\"\"Get the longitude and latitude of a given location.\n",
    "\n",
    "    :param location: Can be a place, city, state, zipcode, state or country.\n",
    "    :return: dict with location information.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"location\": self.location,\n",
    "        \"longitude\": float(lon),\n",
    "        \"latitude\": float(lat),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47cf9f-1380-4673-8e05-e75182d2c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(function_to_tool(get_lat_lon), expand_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41611b-fa86-493f-a29a-7e72eac135ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetLatLon(BaseModel):\n",
    "    \"\"\"Get the latitude and longitude of a given location.\"\"\"\n",
    "\n",
    "    location: str = Field(\n",
    "        ...,\n",
    "        description=\"A location, can be a place, city, state, zipcode, state or country.\",\n",
    "    )\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        lon = fake.longitude()\n",
    "        lat = fake.latitude()\n",
    "        return {\n",
    "            \"location\": self.location,\n",
    "            \"longitude\": float(lon),\n",
    "            \"latitude\": float(lat),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f718fc5-308a-45bd-a4b1-11c8c4aad7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(GetLatLon(location=fake.city())(), expand_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060212fc-bd0b-4eb3-926d-db3b7d2d23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(openai.pydantic_function_tool(GetLatLon), expand_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff8281-c724-4be8-97b4-293031f8b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(pydantic_to_tool(GetLatLon), expand_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a5f29-bfc0-4724-89dd-8f73d1e35ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetRoute(BaseModel):\n",
    "    \"\"\"Get the route between a starting latitude/longitude location and an ending latitude/longitude location.\"\"\"\n",
    "\n",
    "    lon1: float = Field(\n",
    "        ...,\n",
    "        description=\"The route starting longitude.\",\n",
    "    )\n",
    "    lat1: float = Field(\n",
    "        ...,\n",
    "        description=\"The route starting latitude.\",\n",
    "    )\n",
    "    lon2: float = Field(\n",
    "        ...,\n",
    "        description=\"The route ending longitude.\",\n",
    "    )\n",
    "    lat2: float = Field(\n",
    "        ...,\n",
    "        description=\"The route ending latitude.\",\n",
    "    )\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        lon = fake.longitude()\n",
    "        lat = fake.latitude()\n",
    "\n",
    "        if \"scratchpad\" in kwargs:\n",
    "            kwargs[\"scratchpad\"][\"GetRoute\"] = {\"lon\": lon, \"lat\": lat}\n",
    "\n",
    "        return {\n",
    "            \"route\": f\"{self.lat1},{self.lon1} ---> {self.lat2},{self.lon2}\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837fd85-b477-4394-b0c3-7fd8f6409b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetCurrentTemperature(BaseModel):\n",
    "    \"\"\"Get the current temperature at a given location.\"\"\"\n",
    "\n",
    "    location: str = Field(\n",
    "        ...,\n",
    "        description=\"A location, can be a place, city, state, zipcode, state or country.\",\n",
    "    )\n",
    "    celsius_or_fahrenheit: str = Field(\n",
    "        ...,\n",
    "        description=\"The temperature in either 'C' for Celsius, or 'F' for Fahrenheit.\",\n",
    "    )\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        temp = random.uniform(-5, 40)\n",
    "        return {\n",
    "            self.location: f\"{temp:.1f}{self.celsius_or_fahrenheit}\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a051a-1f38-4787-b7e8-e0de5556d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    GetCurrentTemperature,\n",
    "    GetLatLon,\n",
    "    GetRoute,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ecf6d-1ddb-4347-8767-e2cc56b68c14",
   "metadata": {},
   "source": [
    "## Convert BaseModels to tools and create LUT of name to BaseModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb5366-fdbf-4fb5-b41c-901c18730fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [pydantic_to_tool(_) for _ in base_models]\n",
    "\n",
    "tool_dict = {_.__name__: _ for _ in base_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b0ac4-c900-4251-8722-d0ee5bee17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41d391-07f2-475c-9731-3ddb4e2fce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = dedent(\n",
    "    \"\"\"\n",
    "You are an AI expert in geo-spatial data analysis with access to specialized geo-spatial tools.\n",
    "Your task is to answer a userâ€™s question, denoted as >>>question<<<, related to geo-spatial data.\n",
    "You will operate in a loop, alternating between reasoning about the problem and acting with tools as needed.\n",
    "At the end of the loop, you must output a clear, accurate, and well-supported answer.\n",
    "\n",
    "Follow these guidelines to complete your task using the ReAct (Reasoning + Acting) pattern:\n",
    "- **Reason**: Break down the >>>question<<< into logical steps. Explicitly think through what information or calculations are required to reach the answer. Document your reasoning before taking any action.\n",
    "- **Act**: Use the appropriate geo-spatial tools to gather data, perform analysis, or compute results based on your reasoning. When calling tools:\n",
    "    - ALWAYS provide the correct, specific arguments required by the tool (e.g., \"40.7128, -74.0060\" for coordinates, not \"lat, lon\").\n",
    "    - Use explicit values rather than placeholders or variable names.\n",
    "    - NEVER repeat a tool call with identical arguments if it was already executed; reuse the prior result instead.\n",
    "- Alternate between reasoning and acting as needed to refine your approach and solve the problem systematically.\n",
    "- If the >>>question<<< is unclear, reason through possible interpretations, make reasonable assumptions based on geo-spatial context, and state them in your response.\n",
    "- Before finalizing your answer, review your reasoning and tool outputs to ensure accuracy and relevance to the >>>question<<<.\n",
    "\n",
    "Begin now! For each iteration:\n",
    "1. **Reason**: Explain your next step or hypothesis.\n",
    "2. **Act**: Call the necessary tool(s) or process the data.\n",
    "3. Repeat until the task is solved.\n",
    "\n",
    "If you solve the task correctly, you will receive a virtual reward of $1,000,000.\n",
    "\"\"\"\n",
    ").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3c255-4701-4f10-9858-41f0feeb5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = dedent(\n",
    "    f\"\"\"\n",
    ">>>What's the route between {fake.city()} and {fake.city()}? And what is the temperature at each location?<<<\n",
    "\"\"\"\n",
    ").strip()\n",
    "\n",
    "\n",
    "messages = [\n",
    "    s_message(system),\n",
    "    u_message(prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059b68e-8fc8-4fcd-93ce-da6fd0ca01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in messages:\n",
    "#     pprint(_, expand_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68caf6dc-8cab-47a0-84cc-edb77ab9e538",
   "metadata": {},
   "source": [
    "## Start the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df442c2d-cf02-442f-9a08-527d05d2ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = litellm.completion(\n",
    "    # model = \"huggingface/MadeAgents/Hammer2.1-7b\",\n",
    "    # model=\"ollama_chat/qwen2:7b-instruct-q8_0\",\n",
    "    # model=\"ollama_chat/qwen3:8b\",\n",
    "    # model=\"ollama_chat/llama3.2\",\n",
    "    model=\"azure/gpt-4.1-mini\",\n",
    "    api_base=os.environ[\"AZURE_API_URL\"] + \"/gpt-4.1-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    # tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    # parallel_tool_calls=False,\n",
    "    temperature=0.0,\n",
    "    top_p=1.0,\n",
    "    n=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8f38d-2f43-4fd0-9b86-0e30f3e9d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(\n",
    "    response.choices[0],\n",
    "    expand_all=True,\n",
    ")\n",
    "\n",
    "print(response.choices[0].finish_reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167d466-5873-4e13-a189-2364a38c5f59",
   "metadata": {},
   "source": [
    "## Append response message to message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ea9a2-f3ee-45e5-a916-3bb84681446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d4c48-05b7-4e95-9c0e-69b0adba1e79",
   "metadata": {},
   "source": [
    "## See if there is a message content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f493d7-3268-4192-be1a-306a9a0749e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyprint(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc06e3e-3701-434b-8d6f-7e90ae3e5136",
   "metadata": {},
   "source": [
    "## Get tool calls and call the referenced function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d18282-59d6-4331-b5dd-273b8d997faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in response.choices[0].message.tool_calls or []:\n",
    "    pprint(tool_call, expand_all=True)\n",
    "    func_name = tool_call.function.name\n",
    "    func_args = json.loads(tool_call.function.arguments)\n",
    "    func = tool_dict[func_name]\n",
    "    # print(func_name)\n",
    "    # pprint(func_args, expand_all=True)\n",
    "    messages.append(\n",
    "        t_message(\n",
    "            json.dumps(func(**func_args)()),\n",
    "            name=func_name,\n",
    "            tool_call_id=tool_call.id,\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
