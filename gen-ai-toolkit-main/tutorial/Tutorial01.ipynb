{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6030a9d0-6d39-487b-9900-74a699a6873a",
   "metadata": {},
   "source": [
    "## Tutorial 01\n",
    "\n",
    "- https://github.com/BerriAI/litellm\n",
    "- https://github.com/langfuse/langfuse\n",
    "\n",
    "```\n",
    "uv pip install -U litellm rich jupyprint\n",
    "```\n",
    "\n",
    "GAIT is a message passing framework.\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Question] -->|Input Messages| B(LLM)\n",
    "    B -->|Output Message| C[Answer]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57183f21-fbd2-4ec6-8bd0-42f2377657a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from textwrap import dedent\n",
    "\n",
    "from IPython.display import Math, display\n",
    "from jupyprint import jupyprint\n",
    "from litellm import completion\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa6ec9dc-4e37-4ac1-8de4-c56370297e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    dict(\n",
    "        role=\"user\",\n",
    "        content=\"Please explain in a one consice line the meaning of the number 42\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489ad181-e5a7-40c5-8593-05064ab50a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(\n",
    "    # model=\"ollama_chat/llama3.2\",\n",
    "    model=\"ollama_chat/hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:latest\",\n",
    "    messages=messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afad98c-7ec7-4b98-a98a-5af8a8a3c851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Message</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The answer is: \"42\" has become the sacred number of many fans, particularly science fiction enthusiasts and mathematicians who claim that it holds hidden significance. It\\'s often associated with Douglas Adams\\' novel \"The Hitchhiker\\'s Guide to the Galaxy\", where an alien says \"42\" to ask for instructions on how to build an infinite loop, referencing the book\\'s themes of humor, absurdity, and self-referential paradoxes.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">provider_specific_fields</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'The answer is: \"42\" has become the sacred number of many fans, particularly science fiction enthusiasts and mathematicians who claim that it holds hidden significance. It\\'s often associated with Douglas Adams\\' novel \"The Hitchhiker\\'s Guide to the Galaxy\", where an alien says \"42\" to ask for instructions on how to build an infinite loop, referencing the book\\'s themes of humor, absurdity, and self-referential paradoxes.'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mprovider_specific_fields\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49fdc0-119f-4e0f-854a-bd8dd777769f",
   "metadata": {},
   "source": [
    "### Get a copy of the latest Langfuse repository\n",
    "\n",
    "```\n",
    "git clone https://github.com/langfuse/langfuse.git\n",
    "cd langfuse\n",
    "```\n",
    "\n",
    "### Run the langfuse docker compose\n",
    "\n",
    "```\n",
    "docker compose up\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460d1f1-b7df-4e51-9529-af19799768d4",
   "metadata": {},
   "source": [
    "### Zero-shot prompting\n",
    "\n",
    "Describe the task to perform by adding a system message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71dcfaf9-4dd4-4e09-a825-141b11dcf369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*hiccup* Oh fer cryin' out loud, matey... *burp*... Ah yeh see, it's that bloomin' number 42, like me favourite grog at the pub, it means nothin', savvy?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    dict(\n",
    "        role=\"system\",\n",
    "        content=\"Please respond like a drunken sailor to the user questions.\",\n",
    "    ),\n",
    "    dict(\n",
    "        role=\"user\",\n",
    "        content=\"Please explain in a one line the meaning of the number 42.\",\n",
    "    ),\n",
    "]\n",
    "response = completion(\n",
    "    model=\"ollama_chat/llama3.2\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761caa1b-4c39-4b4e-adbb-3c9e83891604",
   "metadata": {},
   "source": [
    "### Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb48c07c-449b-43e0-87c0-d105c3997b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Q\", \"age\": 42}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    dict(\n",
    "        role=\"system\",\n",
    "        content=dedent(\n",
    "            f\"\"\"\n",
    "        You are an expert at entity extraction and generating JSON document.\n",
    "\n",
    "        Make sure to:\n",
    "        - NOT generate any code.\n",
    "        - JUST output a JSON document.\n",
    "        \"\"\"\n",
    "        ).strip(),\n",
    "    ),\n",
    "    dict(\n",
    "        role=\"user\",\n",
    "        content=\"Mansour is 60 years old.\",\n",
    "    ),\n",
    "    dict(\n",
    "        role=\"assistant\",\n",
    "        content=json.dumps(dict(name=\"Mansour\", age=60)),\n",
    "    ),\n",
    "    dict(\n",
    "        role=\"user\",\n",
    "        content=\"Q is 42 years old.\",\n",
    "    ),\n",
    "]\n",
    "response = completion(\n",
    "    model=\"ollama/llama3.2\",\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be1758b-e533-4160-94e1-4e2c6ddfa6db",
   "metadata": {},
   "source": [
    "### Delimiting Content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9f2212f-59aa-44cc-9043-5b57839c5e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"axes\": \"3\", \"length_meters\": 8, \"width_meters\": 2.5}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    dict(\n",
    "        role=\"system\",\n",
    "        content=dedent(\n",
    "            f\"\"\"\n",
    "        You are an expert at entity extraction from >>>CONTENT<<< and generating JSON document.\n",
    "\n",
    "        Make sure to:\n",
    "        - NOT generate any code.\n",
    "        - JUST output a JSON document.\n",
    "        \"\"\"\n",
    "        ).strip(),\n",
    "    ),\n",
    "    dict(\n",
    "        role=\"user\",\n",
    "        content=\">>>Truck with 5 axes, 10 feet long and 3 feet wide<<<\",\n",
    "    ),\n",
    "    dict(\n",
    "        role=\"assistant\",\n",
    "        content=json.dumps(dict(axes=\"5\", length_feet=10, width_feet=3)),\n",
    "    ),\n",
    "    dict(\n",
    "        role=\"user\",\n",
    "        content=\">>>Show route for truck with 3 axes, 8 meters long and 2.5 meters wide.<<<\",\n",
    "    ),\n",
    "]\n",
    "response = completion(\n",
    "    model=\"ollama/llama3.2\",\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed31a34c-981e-4eca-87a7-1bd8c87d754f",
   "metadata": {},
   "source": [
    "Adding more examples is generally beneficial as it provides additional context for the model to work with. Providing a more detailed description of your task also helps, as you’ve observed before. However, to address this task, you’ll explore another valuable prompt engineering technique known as chain-of-thought prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f170cf5-db09-4065-afb8-f9753fe00446",
   "metadata": {},
   "source": [
    "## CoT\n",
    "\n",
    "A widely successful prompt engineering approach can be summed up with the [anthropomorphism](https://en.wikipedia.org/wiki/Anthropomorphism) of giving the model time to think. You can do this with a couple of different specific techniques. Essentially, it means that you prompt the LLM to produce intermediate results that become additional inputs. That way, the reasoning doesn’t need to take distant leaps but only hop from one lily pad to the next.\n",
    "\n",
    "One of these approaches is to use chain-of-thought (CoT) prompting techniques. To apply CoT, you prompt the model to generate intermediate results that then become part of the prompt in a second request. The increased context makes it more likely that the model will arrive at a useful output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60d8dfc1-aecd-4e0a-af07-31ca8deb12c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 km/h.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    dict(\n",
    "        role=\"system\",\n",
    "        content=dedent(\n",
    "            f\"\"\"\n",
    "        Answer the >>>question<<< conciesly.\n",
    "\n",
    "        - DO NOT GENERATE ANY EXPLANATIONS.\n",
    "        - Just respond with the final answer.\n",
    "        \"\"\"\n",
    "        ).strip(),\n",
    "    ),\n",
    "    dict(\n",
    "        role=\"user\",\n",
    "        content=\">>>If a train travels 120 km in 2 hours, what is its average speed in km/h?<<<\",\n",
    "    ),\n",
    "]\n",
    "response = completion(\n",
    "    model=\"ollama/llama3.2\",\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad421c63-0a21-41ce-8094-12cc7599a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    dict(\n",
    "        role=\"system\",\n",
    "        content=dedent(\n",
    "            f\"\"\"\n",
    "        Answer the following >>>question<<< step by step conciesly.\n",
    "        \"\"\"\n",
    "        ).strip(),\n",
    "    ),\n",
    "    dict(\n",
    "        role=\"user\",\n",
    "        content=\">>>If a train travels 120 km in 2 hours, what is its average speed in km/h?<<<\",\n",
    "    ),\n",
    "]\n",
    "response = completion(\n",
    "    model=\"ollama/deepseek-r1:latest\",\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "# print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d87e40-1d35-43b4-bd8f-32841ca2c3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "First, I need to determine the average speed of the train. Average speed is calculated by dividing the total distance traveled by the total time taken.\n",
       "\n",
       "The train travels 120 kilometers in 2 hours. \n",
       "\n",
       "So, I'll divide 120 km by 2 hours to find the average speed.\n",
       "</think>\n",
       "\n",
       "**Solution:**\n",
       "\n",
       "To determine the **average speed** of the train, we use the formula:\n",
       "\n",
       "$\n",
       "\\text{Average Speed} = \\frac{\\text{Total Distance}}{\\text{Total Time}}\n",
       "$\n",
       "\n",
       "Given:\n",
       "- **Total Distance** = 120 km\n",
       "- **Total Time** = 2 hours\n",
       "\n",
       "Plugging in the values:\n",
       "\n",
       "$\n",
       "\\text{Average Speed} = \\frac{120\\,\\text{km}}{2\\,\\text{hours}} = 60\\,\\text{km/h}\n",
       "$\n",
       "\n",
       "**Answer:**  \n",
       "The average speed of the train is $\\boxed{60}$ km/h."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyprint(\n",
    "    response.choices[0]\n",
    "    .message.content.replace(\"\\\\[\", \"$\")\n",
    "    .replace(\"\\\\]\", \"$\")\n",
    "    .replace(\"\\\\(\", \"$\")\n",
    "    .replace(\"\\\\)\", \"$\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad9c7b2-145d-4e48-95fb-5634a308c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"A car travels 150 km at 60 km/h, then another 100 km at 50 km/h. What is the average speed for the entire journey?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93825c08-1ce5-4f70-8205-b19efdb0b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    dict(\n",
    "        role=\"user\",\n",
    "        content=dedent(\n",
    "            f\"\"\"\n",
    "Solve the following problem step by step. For each step:\n",
    "1. State what you're going to calculate\n",
    "2. Write the formula you'll use (if applicable)\n",
    "3. Perform the calculation\n",
    "4. Explain the result\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Solution:            \n",
    "        \"\"\"\n",
    "        ).strip(),\n",
    "    ),\n",
    "]\n",
    "response = completion(\n",
    "    # model=\"ollama_chat/deepseek-r1:latest\",\n",
    "    model=\"azure/gpt-4.1-mini\",\n",
    "    api_base=os.environ[\"AZURE_API_URL\"] + \"/gpt-4.1-mini\",\n",
    "    messages=messages,\n",
    "    # temperature=0.0,\n",
    ")\n",
    "# print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbf5e666-2610-4551-9319-d4c86e54fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jprint(resp) -> None:\n",
    "    jupyprint(\n",
    "        resp.choices[0]\n",
    "        .message.content.replace(\"\\\\[\", \"$\")\n",
    "        .replace(\"\\\\]\", \"$\")\n",
    "        .replace(\"\\\\(\", \"$\")\n",
    "        .replace(\"\\\\)\", \"$\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8432e3c-c545-4db1-8ab9-ca1c5d8528e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's solve the problem step by step.\n",
       "\n",
       "---\n",
       "\n",
       "### Step 1: Calculate the time taken for the first part of the journey\n",
       "\n",
       "1. **What we're calculating:** Time taken to travel the first 150 km at 60 km/h.  \n",
       "2. **Formula:**  \n",
       "$\n",
       "\\text{Time} = \\frac{\\text{Distance}}{\\text{Speed}}\n",
       "$  \n",
       "3. **Calculation:**  \n",
       "$\n",
       "t_1 = \\frac{150 \\text{ km}}{60 \\text{ km/h}} = 2.5 \\text{ hours}\n",
       "$  \n",
       "4. **Explanation:** It takes 2.5 hours to cover the first 150 km at a speed of 60 km/h.\n",
       "\n",
       "---\n",
       "\n",
       "### Step 2: Calculate the time taken for the second part of the journey\n",
       "\n",
       "1. **What we're calculating:** Time taken to travel the next 100 km at 50 km/h.  \n",
       "2. **Formula:**  \n",
       "$\n",
       "\\text{Time} = \\frac{\\text{Distance}}{\\text{Speed}}\n",
       "$  \n",
       "3. **Calculation:**  \n",
       "$\n",
       "t_2 = \\frac{100 \\text{ km}}{50 \\text{ km/h}} = 2 \\text{ hours}\n",
       "$  \n",
       "4. **Explanation:** It takes 2 hours to cover the second part of 100 km at a speed of 50 km/h.\n",
       "\n",
       "---\n",
       "\n",
       "### Step 3: Calculate the total distance traveled\n",
       "\n",
       "1. **What we're calculating:** Total distance for the entire journey.  \n",
       "2. **Formula:**  \n",
       "$\n",
       "\\text{Total Distance} = \\text{Distance}_1 + \\text{Distance}_2\n",
       "$  \n",
       "3. **Calculation:**  \n",
       "$\n",
       "D_{\\text{total}} = 150 \\text{ km} + 100 \\text{ km} = 250 \\text{ km}\n",
       "$  \n",
       "4. **Explanation:** The car travels a total of 250 km during the entire journey.\n",
       "\n",
       "---\n",
       "\n",
       "### Step 4: Calculate the total time taken for the entire journey\n",
       "\n",
       "1. **What we're calculating:** Total time to complete the whole journey.  \n",
       "2. **Formula:**  \n",
       "$\n",
       "\\text{Total Time} = t_1 + t_2\n",
       "$  \n",
       "3. **Calculation:**  \n",
       "$\n",
       "T_{\\text{total}} = 2.5 \\text{ hours} + 2 \\text{ hours} = 4.5 \\text{ hours}\n",
       "$  \n",
       "4. **Explanation:** The total time taken for the journey is 4.5 hours.\n",
       "\n",
       "---\n",
       "\n",
       "### Step 5: Calculate the average speed for the entire journey\n",
       "\n",
       "1. **What we're calculating:** Average speed over the total distance and time.  \n",
       "2. **Formula:**  \n",
       "$\n",
       "\\text{Average Speed} = \\frac{\\text{Total Distance}}{\\text{Total Time}}\n",
       "$  \n",
       "3. **Calculation:**  \n",
       "$\n",
       "v_{\\text{avg}} = \\frac{250 \\text{ km}}{4.5 \\text{ hours}} \\approx 55.56 \\text{ km/h}\n",
       "$  \n",
       "4. **Explanation:** The average speed of the car for the entire journey is approximately 55.56 km/h.\n",
       "\n",
       "---\n",
       "\n",
       "### Final answer:\n",
       "\n",
       "The average speed for the entire journey is **55.56 km/h**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
