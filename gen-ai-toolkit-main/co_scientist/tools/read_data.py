import json
import tiktoken
from nano_graphrag import GraphRAG, QueryParam
import subprocess
import os
import shutil
from gait import Agent


def empty_folder(folder_path):

    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        if os.path.isfile(file_path) or os.path.islink(file_path):
            os.unlink(file_path)
            shutil.rmtree(file_path)
def generate_llm_context_from_layer_json(layer_path, output_path=None, max_values=1):
    """
    This function generates a context string from a layer JSON file for use in LLMs.
    The layer json file is generated by the PrepareExistingLocations.py script.
    Then it uses the GraphRAG to insert the context into the RAG database.
    """
    # if os.path.exists("./data_rag"):
    #     empty_folder("./data_rag")
    # else:
    #     os.makedirs("./data_rag")
    # script_path = r"C:\Users\64963\OneDrive - The University of Texas at Austin\PhD\6-Job\ESRI\Spatial_Co_Scientist\gen-ai-toolkit-main\zp_toolboxes\PrepareExistingLocations.py"
    # conda_path = r"D:\MyTool\anaconda\Scripts\conda.exe"
    # cmd = f'"{conda_path}" run -n arcgispro python "{script_path}" --project_path "{layer_path}"'
    # result = subprocess.run(cmd, shell=True, capture_output=True, text=True, encoding="utf-8")
    # print("STDOUT:\n", result.stdout)
    # # print("STDERR:\n", result.stderr)
    # json_path = "../co_scientist/temp_folder/data_context.json"
    # with open(json_path, "r", encoding="utf-8") as f: data = json.load(f)
    # all_contexts = []
    # for layer in data.get("layers", []):
    #     name = layer.get("name", "Unknown Layer")
    #     stype = layer.get("stype", "Unknown Type")
    #     uri = layer.get("uri", "Unknown URI")
    #     context = f'Layer: "{name}"; Type: {stype}; File Path: "{uri}"; This layer represents {name.lower()} with the following attributes: '
    #     col_descriptions = []
    #     for col in layer.get("columns", []):
    #         cname = col.get("name", "Unknown")
    #         alias = col.get("alias", "")
    #         dtype = col.get("dtype", "Unknown")
    #         values = col.get("values", [])[:max_values]
    #         vstr = ", ".join(f'"{v}"' for v in values)
    #         desc = f'{cname} ({dtype})'
    #         if alias and alias.lower() != cname.lower(): desc += f' aka "{alias}"'
    #         if values: desc += f': Examples: {vstr}'
    #         col_descriptions.append(desc)
    #     context += " | ".join(col_descriptions)
    #     all_contexts.append(context)
    # final_context = " || ".join(all_contexts)

    graph_func = GraphRAG(working_dir=r"./data_rag",using_azure_openai=True)
    # graph_func.insert(final_context)

    """auto rag information
    Below is the information that is hard to get:
    (1) dataset path
    (2) CRS information
    ... meta information
    The rag can not get accurate attribute name and its relevant data, we need to multiple time ragging and post-processing.
    """

    rag_questions = [
        "List all attribute fields (raw name) in each data, including their full field names, aliases, data types, and a short description if available. Remember, when you return the attribute, always tell me the attribute is of which data",
        "Does each dataset include a geometry field? If so, what is the spatial type (e.g., point, polygon, polyline)? How is geometry represented?",
        "Which attributes are suitable as join keys for linking each dataset with other geographic or demographic datasets? For each, specify its format and uniqueness.",
        "Based on field types and value examples, which fields are likely suitable as target variables for spatial clustering or predictive modeling? Explain your reasoning briefly for each. Remember, when you return the attribute, always tell me the attribute is of which data",
        "Separate all attributes into categorical and numerical variables, listing at least three of each type.  Remember, when you return the attribute, always tell me the attribute is of which data",
        "Does the dataset include any time or date fields? If so, specify their names, types, and typical format.  Remember, when you return the attribute, always tell me the attribute is of which data",
        "Are there any calculated, flag, or indicator fields that require special interpretation in analysis? Briefly describe them.  Remember, when you return the attribute, always tell me the attribute is of which data",
    ]

    obs_dict = {}
    for q in rag_questions:
        obs = graph_func.query(q, param=QueryParam(mode="local"))
        obs_dict.update({q:obs})
    return graph_func, obs_dict
    # if output_path:
    #     with open(output_path, "w", encoding="utf-8") as f: f.write(final_context)

    # print(len(tokens))

if __name__ == "__main__":
    ctx = generate_llm_context_from_layer_json(r"C:\Users\64963\OneDrive - The University of Texas at Austin\PhD\6-Job\ESRI\Spatial_Co_Scientist\gen-ai-toolkit-main\co_scientist\temp_folder\data_context.json")

    print(ctx)
