{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T19:37:45.025972Z",
     "start_time": "2025-06-17T19:37:43.874953Z"
    }
   },
   "source": "import dspy\n",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:45:09.551560Z",
     "start_time": "2025-06-17T19:45:09.546796Z"
    }
   },
   "cell_type": "code",
   "source": "lm = dspy.LM('azure/gpt-4.1', api_key='3c744295edda4f13bf0ef198ddb4d24c', api_base='https://ist-apim-aoai.azure-api.net/load-balancing/gpt-4.1')\n",
   "id": "e6b1df89dbbec876",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:45:24.258385Z",
     "start_time": "2025-06-17T19:45:24.256082Z"
    }
   },
   "cell_type": "code",
   "source": "dspy.configure(lm=lm)",
   "id": "dcae132ab463196f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:45:32.891777Z",
     "start_time": "2025-06-17T19:45:31.231905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "math = dspy.ChainOfThought(\"question -> answer: float\")\n",
    "math(question=\"Two dice are tossed. What is the probability that the sum equals two?\")"
   ],
   "id": "4b267128af56852d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='When two dice are tossed, each die has 6 faces, so there are 6 × 6 = 36 possible outcomes. The sum equals two only if both dice show a 1, i.e., (1,1). This is only 1 outcome out of 36 possible outcomes.\\n\\nProbability = Number of favorable outcomes / Total number of outcomes = 1 / 36 = 0.027777...',\n",
       "    answer=0.027777777777777776\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T19:53:53.119657Z",
     "start_time": "2025-06-17T19:53:53.114241Z"
    }
   },
   "cell_type": "code",
   "source": "lm.history",
   "id": "a1b1b93d8c06be5c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': None,\n",
       "  'messages': [{'role': 'system',\n",
       "    'content': 'Your input fields are:\\n1. `question` (str):\\nYour output fields are:\\n1. `reasoning` (str): \\n2. `answer` (float):\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n[[ ## question ## ]]\\n{question}\\n\\n[[ ## reasoning ## ]]\\n{reasoning}\\n\\n[[ ## answer ## ]]\\n{answer}        # note: the value you produce must be a single float value\\n\\n[[ ## completed ## ]]\\nIn adhering to this structure, your objective is: \\n        Given the fields `question`, produce the fields `answer`.'},\n",
       "   {'role': 'user',\n",
       "    'content': '[[ ## question ## ]]\\nTwo dice are tossed. What is the probability that the sum equals two?\\n\\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]` (must be formatted as a valid Python float), and then ending with the marker for `[[ ## completed ## ]]`.'}],\n",
       "  'kwargs': {},\n",
       "  'response': ModelResponse(id='chatcmpl-BjWXL3zaDNJ7Zc8FYTFA4YjqipyWj', created=1750189531, model='gpt-4.1-2025-04-14', object='chat.completion', system_fingerprint='fp_07e970ab25', choices=[Choices(finish_reason='stop', index=0, message=Message(content='[[ ## reasoning ## ]]\\nWhen two dice are tossed, each die has 6 faces, so there are 6 × 6 = 36 possible outcomes. The sum equals two only if both dice show a 1, i.e., (1,1). This is only 1 outcome out of 36 possible outcomes.\\n\\nProbability = Number of favorable outcomes / Total number of outcomes = 1 / 36 = 0.027777...\\n\\n[[ ## answer ## ]]\\n0.027777777777777776\\n\\n[[ ## completed ## ]]', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]))], usage=Usage(completion_tokens=110, prompt_tokens=203, total_tokens=313, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier=None, prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], cache_hit=None),\n",
       "  'outputs': ['[[ ## reasoning ## ]]\\nWhen two dice are tossed, each die has 6 faces, so there are 6 × 6 = 36 possible outcomes. The sum equals two only if both dice show a 1, i.e., (1,1). This is only 1 outcome out of 36 possible outcomes.\\n\\nProbability = Number of favorable outcomes / Total number of outcomes = 1 / 36 = 0.027777...\\n\\n[[ ## answer ## ]]\\n0.027777777777777776\\n\\n[[ ## completed ## ]]'],\n",
       "  'usage': {'completion_tokens': 110,\n",
       "   'prompt_tokens': 203,\n",
       "   'total_tokens': 313,\n",
       "   'completion_tokens_details': CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None),\n",
       "   'prompt_tokens_details': PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)},\n",
       "  'cost': 0.0012859999999999998,\n",
       "  'timestamp': '2025-06-17T14:45:32.885778',\n",
       "  'uuid': '778adc57-45b8-4128-9012-74523bf1c6a1',\n",
       "  'model': 'azure/gpt-4.1',\n",
       "  'response_model': 'gpt-4.1-2025-04-14',\n",
       "  'model_type': 'chat'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T20:13:25.442633Z",
     "start_time": "2025-06-17T20:13:24.432107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Emotion(dspy.Signature):\n",
    "    \"\"\"Classify emotion.\"\"\"\n",
    "    sentence: str = dspy.InputField()\n",
    "    sentiment: Literal['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'] = dspy.OutputField()\n",
    "\n",
    "sentence = \"i started feeling a little vulnerable when the giant spotlight started blinding me\"\n",
    "classify = dspy.Predict(Emotion)\n",
    "classify(sentence=sentence)"
   ],
   "id": "39c73f18665e2d37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    sentiment='fear'\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:05:46.191180Z",
     "start_time": "2025-06-18T15:05:45.906624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dspy\n",
    "\n",
    "# 1. 连接 ColBERTv2 检索服务（Wikipedia DEMO）\n",
    "search = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "\n",
    "# 2. 检索问题\n",
    "query = \"Who designed the Eiffel Tower?\"\n",
    "results = search(query, k=3)\n",
    "\n",
    "# 3. 打印检索结果\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"[{i+1}] {r['text']}\")"
   ],
   "id": "278901c96fa177a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Stephen Sauvestre | Charles Léon Stephen Sauvestre (26 December 1847 - 18 June 1919) was a French architect. He is notable for being one of the architects contributing to the design of the world-famous Eiffel Tower, built for the 1889 Universal Exposition in Paris, France.\n",
      "[2] Émile Nouguier | Émile Nouguier (17 February 1840 – 23 November 1897) was a French civil engineer and architect. He is famous for co-designing the Eiffel Tower, built 1887–1889 for the 1889 Universal Exposition in Paris, France, the Garabit viaduct, the highest in the world at the time, near Ruynes-en-Margeride, Cantal, France, and the Faidherbe Bridge over the Sénégal River in Senegal.\n",
      "[3] Eiffel Tower | The Eiffel Tower ( ; French: \"tour Eiffel\" , ] ) is a wrought iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T19:51:55.948017Z",
     "start_time": "2025-06-19T19:51:55.067723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from mem0 import Memory\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"3c744295edda4f13bf0ef198ddb4d24c\"  # embedding用\n",
    "\n",
    "# 1. 设置环境变量（可选，或直接写在config中）\n",
    "os.environ[\"LLM_AZURE_OPENAI_API_KEY\"] = \"3c744295edda4f13bf0ef198ddb4d24c\"\n",
    "os.environ[\"LLM_AZURE_DEPLOYMENT\"] = \"gpt-4.1\"  # 你的部署名称\n",
    "os.environ[\"LLM_AZURE_ENDPOINT\"] = \"https://ist-apim-aoai.azure-api.net/load-balancing/gpt-4.1\"  # 你的endpoint路径\n",
    "os.environ[\"LLM_AZURE_API_VERSION\"] = \"2024-10-21\"  # 你的API版本\n",
    "\n",
    "# 2. Mem0配置\n",
    "config = {\n",
    "    \"llm\": {\n",
    "        \"provider\": \"azure_openai\",\n",
    "        \"config\": {\n",
    "            \"model\": os.getenv(\"LLM_AZURE_DEPLOYMENT\"),  # \"gpt-4.1\"\n",
    "            # reasoning模型可能不支持temperature、max_tokens，如报错请删除\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 2000,\n",
    "            \"azure_kwargs\": {\n",
    "                \"azure_deployment\": os.getenv(\"LLM_AZURE_DEPLOYMENT\"),\n",
    "                \"api_version\": os.getenv(\"LLM_AZURE_API_VERSION\"),\n",
    "                \"azure_endpoint\": os.getenv(\"LLM_AZURE_ENDPOINT\"),\n",
    "                \"api_key\": os.getenv(\"LLM_AZURE_OPENAI_API_KEY\"),\n",
    "                \"default_headers\": {\n",
    "                    # 若无自定义header可为空或删掉\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. 实例化并使用Memory\n",
    "m = Memory.from_config(config)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"I'm planning to watch a movie tonight. Any recommendations?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"How about thriller movies? They can be quite engaging.\"},\n",
    "    {\"role\": \"user\", \"content\": \"I’m not a big fan of thriller movies but I love sci-fi movies.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Got it! I'll avoid thriller recommendations and suggest sci-fi movies in the future.\"}\n",
    "]\n",
    "\n",
    "m.add(messages, user_id=\"alice\", metadata={\"category\": \"movies\"})\n"
   ],
   "id": "391903db358f714",
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: 3c744295********************d24c. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAuthenticationError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 43\u001B[0m\n\u001B[1;32m     34\u001B[0m m \u001B[38;5;241m=\u001B[39m Memory\u001B[38;5;241m.\u001B[39mfrom_config(config)\n\u001B[1;32m     36\u001B[0m messages \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     37\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mm planning to watch a movie tonight. Any recommendations?\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m     38\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massistant\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHow about thriller movies? They can be quite engaging.\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m     39\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI’m not a big fan of thriller movies but I love sci-fi movies.\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m     40\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massistant\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot it! I\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mll avoid thriller recommendations and suggest sci-fi movies in the future.\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m     41\u001B[0m ]\n\u001B[0;32m---> 43\u001B[0m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43malice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcategory\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmovies\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ai_agent/lib/python3.10/site-packages/mem0/memory/main.py:261\u001B[0m, in \u001B[0;36mMemory.add\u001B[0;34m(self, messages, user_id, agent_id, run_id, metadata, infer, memory_type, prompt)\u001B[0m\n\u001B[1;32m    257\u001B[0m     future2 \u001B[38;5;241m=\u001B[39m executor\u001B[38;5;241m.\u001B[39msubmit(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_to_graph, messages, effective_filters)\n\u001B[1;32m    259\u001B[0m     concurrent\u001B[38;5;241m.\u001B[39mfutures\u001B[38;5;241m.\u001B[39mwait([future1, future2])\n\u001B[0;32m--> 261\u001B[0m     vector_store_result \u001B[38;5;241m=\u001B[39m \u001B[43mfuture1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    262\u001B[0m     graph_result \u001B[38;5;241m=\u001B[39m future2\u001B[38;5;241m.\u001B[39mresult()\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_version \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv1.0\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ai_agent/lib/python3.10/concurrent/futures/_base.py:451\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    449\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ai_agent/lib/python3.10/concurrent/futures/_base.py:403\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 403\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    405\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    406\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ai_agent/lib/python3.10/concurrent/futures/thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ai_agent/lib/python3.10/site-packages/mem0/memory/main.py:348\u001B[0m, in \u001B[0;36mMemory._add_to_vector_store\u001B[0;34m(self, messages, metadata, filters, infer)\u001B[0m\n\u001B[1;32m    346\u001B[0m new_message_embeddings \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m new_mem \u001B[38;5;129;01min\u001B[39;00m new_retrieved_facts:\n\u001B[0;32m--> 348\u001B[0m     messages_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_mem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43madd\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    349\u001B[0m     new_message_embeddings[new_mem] \u001B[38;5;241m=\u001B[39m messages_embeddings\n\u001B[1;32m    350\u001B[0m     existing_memories \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvector_store\u001B[38;5;241m.\u001B[39msearch(\n\u001B[1;32m    351\u001B[0m         query\u001B[38;5;241m=\u001B[39mnew_mem,\n\u001B[1;32m    352\u001B[0m         vectors\u001B[38;5;241m=\u001B[39mmessages_embeddings,\n\u001B[1;32m    353\u001B[0m         limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,\n\u001B[1;32m    354\u001B[0m         filters\u001B[38;5;241m=\u001B[39mfilters,\n\u001B[1;32m    355\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ai_agent/lib/python3.10/site-packages/mem0/embeddings/openai.py:46\u001B[0m, in \u001B[0;36mOpenAIEmbedding.embed\u001B[0;34m(self, text, memory_action)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;124;03mGet the embedding for the given text using OpenAI.\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;124;03m    list: The embedding vector.\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     44\u001B[0m text \u001B[38;5;241m=\u001B[39m text\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdimensions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding_dims\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;241m.\u001B[39mdata[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;241m.\u001B[39membedding\n\u001B[1;32m     49\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ai_agent/lib/python3.10/site-packages/openai/resources/embeddings.py:129\u001B[0m, in \u001B[0;36mEmbeddings.create\u001B[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    123\u001B[0m             embedding\u001B[38;5;241m.\u001B[39membedding \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfrombuffer(  \u001B[38;5;66;03m# type: ignore[no-untyped-call]\u001B[39;00m\n\u001B[1;32m    124\u001B[0m                 base64\u001B[38;5;241m.\u001B[39mb64decode(data), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    125\u001B[0m             )\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[0;32m--> 129\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/embeddings\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEmbeddingCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpost_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    139\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCreateEmbeddingResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ai_agent/lib/python3.10/site-packages/openai/_base_client.py:1242\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1228\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1229\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1230\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1237\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1238\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1239\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1240\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1241\u001B[0m     )\n\u001B[0;32m-> 1242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ai_agent/lib/python3.10/site-packages/openai/_base_client.py:1037\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1034\u001B[0m             err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1036\u001B[0m         log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1037\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1039\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcould not resolve response (should never happen)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mAuthenticationError\u001B[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 3c744295********************d24c. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3c74b7da9145c8f3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
