{
  "chunk-bfd5a95d2a94bd0e225ec3d367a8cc2a": {
    "tokens": 1200,
    "content": "Spatial Clustering in the Presence of  Obstacles * \n\nAnthony K. H. Tung \n\nJean  Hou \n\nJiawei  Han \n\nSchool of  Computing Science \nSimon Fraser University \nBritish  Columbia \nCanada V5A  1S6 \nEmail:  {khtung, jhou, han}@cs.sfu.ca} \n\nAbstract \n\nClustering i n  spatial  data  mining is to group  similar \nobjects  based  on  their  distance,  connectivity,  or  their \nrelative  density  in space.  In  the  real  world,  there  exist \nmany physical  obstacles  such  as  rivers, lakes  and high- \nways,  and  their presence  may  affect  the  result  of  clus- \ntering substantially.  In this paper,  we study the problem \nof  clustering  in the presence  of  obstacles  and  define  it \nas  a  COD (Clustering  with  Obstructed  Distance) prob- \nlem.  A s  a  solution  t o  this problem,  we  propose  a  scal- \nable  clustering  algorithm, called COD-CLARANS .  W e  \ndiscuss  various forms of  pre-processed information that \ncould  enhance the eficiency of  COD-CLARANS . In the \nstrictest  sense,  the  CODproblem  can  be  treated  as  a \nchange  an  distance function and  thus  could  be  handled \nby  current  clustering  algorithms  by  changing  the  dis- \ntance function.  However,  we  show  that  by pushing  the \ntask  of  handling obstacles  into COD-CLARANS instead \nof  abstracting it at the distance function level, more op- \ntimization  can  be  done  in  the form  of  a  pruning func- \ntion  E’.  W e  conduct  various  performance  studies  to \nshow  that  COD-CLARANS is  both  eficient  and  effec- \ntive. \n\n1 \n\nIntroduction \n\nCluster  analysis,  which  groups  data  for  finding \noverall  distribution  patterns  and  interesting  correla- \ntions  among  data  sets,  has  numerous  applications \nin  pattern  recognition,  spatial  data  analysis,  image \nprocessing,  market  research,  etc.  Cluster  analysis \nhas  been  an  active  area  of  research \nin  computa- \ntional statistics and  data mining, with  many  effective \nand  scalable  clustering  methods  developed  recently. \nThese  methods  can  be  categorized  into  partitioning \nmethods [KR90, NH94, BFR981 , hierarchical  methods \n[KR90, ZRL96, GRS98, KHK991, density-based  meth- \nods  [EKSX96,  ABKS99,  HK981,  grid-based  methods \n\n~~~~ \n\n*The work  was supported in part by the Natural Sciences and \nEngineering Research  Council  of  Canada  (NSERC-A3723)  and \nthe  Networks  of  Centres of  Excellence of  Canada  (NCE/IRIS-3 \nand NCE/GEOID) \n\n[WYM97,  SCZ98,  AGGR981 , and  model-based  meth- \nods [SD90, Koh821. \n\nTypically,  a  clustering task  consists  of  separating  a \nset  of  objects into different  groups  according  to some \nmeasures  of goodness  that  differ according  to applica- \ntion.  A common measure of  goodness  will be the sum \nof square of the direct Euclidean  distance between  the \ncustomers and the center  of  the cluster  they belong to. \nHowever,  in  many  real  applications, the  use  of  direct \nEuclidean  distance  has  its  weakness  as illustrated  by \nthe following example. \n\nExample  1.1  A  bank  planner  wishes  to  locate  4 \nATMs  in  the  area  shown  in  Figure  l ( a )  to serve  the \ncustomers who  are represented  by  points in the figure. \nIn  such  a situation, however,  natural obstacles exist  in \nthe  area  and  they  should  not  be  ignored.  This is  be- \ncause ignoring these obstacles  will result  in clusters  like \nthose in Figure 1 (b) which are obviously inappropriate. \nFor  example, Cluster  C11  is,  as  a  result  of  clustering, \nsplit by  a river, and some customers on one side of  the \nriver will have to travel a long way to the ATM  located \nat the other side. \n0 \n\nExample 1.1 shows a simple but a serious fact which \nhas  not  been  addressed  so  far:  most  clustering  algo- \nrithms  assume  direct  Euclidean  distance  among  the \nobjects  to  be  clustered  without  obstacles  in  the  way, \nhowever,  most  applications do have  obstacles  in  pres- \nence,  and  the  omission  of  such  obstacles  may  lead  to \ndistorted  and often useless  clustering  results.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-4dbc5972148c5e76eeda194bcd97902a": {
    "tokens": 1200,
    "content": "addressed  so  far:  most  clustering  algo- \nrithms  assume  direct  Euclidean  distance  among  the \nobjects  to  be  clustered  without  obstacles  in  the  way, \nhowever,  most  applications do have  obstacles  in  pres- \nence,  and  the  omission  of  such  obstacles  may  lead  to \ndistorted  and often useless  clustering  results. \n\nIn  this study, we  examine the problem  of  clustering \nspatial objects with the presence  of  obstacles.  The def- \ninition of  the problem  that we  are solving is as follows. \n\nDefinition 1.1  The  Clustering with  Obstructed \nDistance (COD )  Problem \nGiven  (1) a  set  P  of  n  points  {pl,p2, ..., p n } ,  and  (2) \na  set  0 of  m non-intersecting  obstacles  (01,  ..., om} \nin  a  two-dimensional  region,  R,  with  each  obstacle \n0, represented  by  a  simple  polygon,  the  direct  Eu- \nclidean  distance  between  two points  p j   and  pk,  de- \nnoted  as  d(pj,pk), is  the  Euclidean  distance  between \n\n1063-6382/01 $10.00 0 2001 IEEE \n\n359 \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE Xplore.  Restrictions apply. \n\n\fthe  two points  by  ignoring  the  obstacles;  whereas  the \nobstructed distance, between the two points,  denoted \n( I S  d'(pj, p k ) ,   is defined as the length of  the shortest Eu- \nclidean path from pj to pk  without  cutting  through  any \nobstacles. \n\nThe  problem  of  clustering  with  obstacle  dis- \nis  to  partition  P  into  k  clusters,  C11, \ntance  (COD) \n. . . .  elk, such  that  the following square-error function, \nE ,  is  minimized. \n\nwhere  ci  is  the  center  of  cluster  Cli  that  is  deter- \n0 \n\nmined  by  the  clustering. \n\n0 \n\n0 \n0 \n\n0 .\n\n0 \n\n0\n\n0\n\n====== \n0 0 .\n\n7; \n\n0  0 . / , J o 0 ~ ~  \n\n  0 . .  \n\n0 .\n\n0 .\n\nriver \n\n0 \n\n0 \n\n0\n\n.\n\n0 \n\n(a) Customers' locations and obsta- \ncles. \n\n..*. \n\n0 0  \n\n...... \n\n.... ::,.o..... \n\n. . . . . . .  \n1 \n'.+ \n\".... \n\n: .  '., \n........  .xc!2.I 0  . .i \n\n.;. ., \n\n0\". \n\nj \n\n0  0 \n\n0  0  .;.: \n\n0  0 \n\n...... \n\n..... .._e ............ \n\n(b)  Clusters  formed  when  ignoring \nobstacles. \n\nFigure 1. Planning the locations of ATMs \n\nSince  our  given  problem  is  to  ensure  a  minimized \noverall travel distances of  all the customers in  the city, \nthe partitioning-based  algorithms will be a good choice \nas  a  solution.  This is  because  most  of  the other  cate- \ngories of  clustering  algorithm  focus on  finding natural \nclusters  which  do  not  guarantee  minimization  of  the \ndistances to the cluster centers. \n\nOf  the two typical  types  of  partitioning-based  algo- \nrithms, k-means and k-medoids, the k-medoids method \n\n0  Z o  \n\nmean \n\n0 \n0  0 0  \n\nmedoid \n\nFigure 2. Mean vs Medoid. \n\nis  selected  due  to  the  fact  that  the  mean  of  a  set  of \npoints  is  not  well  defined  when  obstacles  are  involved. \nFor example, in  Figure 2, the mean  of  the points is  in- \nside  an  obstacle  and  thus by  definition  is  unreachable \nby  all the points in the cluster.  On the other hand, the \nk-medoids method chooses an object  within the cluster \nas a center  and  thus ensures  that such  a problem  does \nnot  exist.  In  view  of  this,  we  derived  an  efficient  k- \nmedoids  algorithm  called  COD algorithm for  solving \nthis problem. \n\nThe COD-CLARANS  algorithm is developed in the \nspirit  of  CLARANS  [NH94]  and  is  designed  for  han- \ndling  obstacles.  While  CLARANS  algorithm can  be \nmade to handle obstacles by changing its distance func- \ntion, COD-CLARANS  further  optimized  this function \nby  \"pushing\"  the  task  of  handling  obstacles  into the \nalgorithm. \n\nFigure  3  shows  the  overall  structure  of  COD- \nCLAR",
    "chunk_order_index": 1,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-ee8e65cefe55b72390539059c0aa813c": {
    "tokens": 1200,
    "content": "94]  and  is  designed  for  han- \ndling  obstacles.  While  CLARANS  algorithm can  be \nmade to handle obstacles by changing its distance func- \ntion, COD-CLARANS  further  optimized  this function \nby  \"pushing\"  the  task  of  handling  obstacles  into the \nalgorithm. \n\nFigure  3  shows  the  overall  structure  of  COD- \nCLARANS.  To  facilitate \nthe  running  of  COD- \nCLARANS, we  pre-process  the d a t a  and store certain \ninformation which will  be needed  by  COD-CLARANS \nduring its run.  Pre-processing  will 'be  discussed  in Sec- \ntion  2.  The  COD-CLARANS  algorithm  consists  of \nthree  main  parts,  the  main  algorithm] the  computa- \ntion of the squared-error  E  and a pruning function  E'. \nThe  pruning  function  E'  has  two  purposes.  First,  it \ncan  help  to prune  off  search  and  avoid  the  computa- \ntion  of  E .  Second, in  the event  when  the computation \nof  E  cannot  be  avoided, the pruning function can pro- \nvide focusing information to make the computation \nof  E  more  efficient.  Section  3  will  describe  them  in \nmore  detail.  In  Section  4,  we  will  do  a  performance \nstudy on the COD-CLARANS  algorithm.  We  will dis- \ncuss some possible future work  in Slection 5.  Our study \nis concluded in  Section 6. \n\n2  Pre-processing \n\nDuring the course of clustering,the COD-CLARANS \noften  needs  to  compute  the  obstructed  distance  be- \ntween  a  point  and  a  temporary  cluster  center.  Our \naim  of  pre-processing  here  is  t o   materialize  informa- \ntion  which  will facilitate such  a computation. \n\n360 \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE Xplore.  Restrictions apply. \n\n \n \n \n \n \n\f( Preprocessed Information) \nII \n\nMain Function \n\nV \n\nComputation of E \n\nFigure 3. Overview of COD-CLARANS. \n. . . .  . .  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . \n\nr \n\nI \n\nVG’ \n\nFigure 4. A visibility graph. \n\n2.1  The BSP-tree \n\nThe Binary-Space-Partition  (BSP) tree  [SG97] is  a \ndata structure which can efficiently determine whether \ntwo points p  and q  are visible to each other within the \nregion R. We define p to be visible from q in the region \nR if  the straight line joining p  and q  does not  intersect \nany obstacles.  In  our  algorithm, the BSP-tree  is used \nto determine the set of all visible obstacle vertices from \na point  p.  Henceforth,  we  will use  the notation  v i s ( p )  \nto  denote  such  a  set  of  vertices.  More  details of  the \nBSP-tree  can  be found  in  [SG97]. \n\n2.2  The Visibility Graph \n\nDefinition 2.1  Visibility  Graph \nGiven a set of  m obstacles,  0 = (01,  ..., om}, the visibil- \nity graph  is a graph  V G  = (V, E )  such that each vertex \nof  the  obstacles  has  a  corresponding  node  in  V ,  and \ntwo  nodes  v1 and  212  in  V  are joined  by  an  edge  in E \nif  and  only i f  the  corresponding  vertices they represent \nare  visible  to each  other. \n0 \n\nTo generate  V G ,  we  make use of the BSP-tree  com- \nputed  previously  and  search  all  other  visible  vertices \nfrom each  vertex  of  the obstacles.  The visibility  graph \nis pre-computed  because  it is useful for finding the ob- \nstructed distance between  any two points in the region. \nThe following lemma is proven  in  [O’R98]. \n\nLemma 2.1  Let  p  and  q  be  two points  in  the  region \nR  and  V G  = (V, E )  be  the  visibility  graph  of  R.  Let \nVG’ = (VI, E’) be  a visibility graph created from V G  by \n\nadding two additional nodes p’  and q’  i n  V’  representing \np  and  q .   Similar  t o  earlier definition,  E’  contains  an",
    "chunk_order_index": 2,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-511a75b70556542599e72cb80b486f19": {
    "tokens": 1200,
    "content": "two points  in  the  region \nR  and  V G  = (V, E )  be  the  visibility  graph  of  R.  Let \nVG’ = (VI, E’) be  a visibility graph created from V G  by \n\nadding two additional nodes p’  and q’  i n  V’  representing \np  and  q .   Similar  t o  earlier definition,  E’  contains  an \nedge joining two nodes i n  V’  if the points represented  by \nthe  two nodes  are  mutually  visible.  T h e  shortest path \nbetween  the  two points  p  and  q  will  be  a  sub-path  of \nVG’. \n\n0 \n\nIn  Figure 4  , we  show how  the visibility graph  VG’ \ncan be derived  from the visibility graph V G  of a region \nwith two obstacles  01  and 02. From Lemma 2.1, we can \nsee  that the shortest  path  from p  to q  will begin  with \nan edge from p  to either 211, v2  or  213, go through some \npath  in  V G  and then end  with  an edge from either  214 \nor  v5 to q. \n\n2.3  Micro-clustering \n\nIn  order for  COD-CLARANS to handle a  large num- \nber  of data points, we  use the concept  of pre-clustering \nwhich  is  similar  to  those  used  in  BIRCH  [ZRL96], \nScaleKM  [BFR98]  and  CHAMELEON  [KHK99].  A \nmicro-cluster  is  a  compressed  representation  of  a \ngroup  of  points  which  are so close together  that  they \nare  likely  t o   belong  to  the  same  cluster.  As  such, \ninstead  of  representating  each  point  in  the  micro- \ncluster  individually,  we  represent  them  using  their \ncenter  and  a  count  of  the  number  of  points  in  the \nmicro-clusters.  Using this summarized information, the \nCOD-CLARANS algorithm can approximate the square- \nerror  function  E by  assuming that all the points in the \nmicro-clusters  are  located  a t  the  center  of  the  micro- \ncluster. \n\nTo ensure  that  not  too much  accuracy  is sacrificed \nby  using  micro-cluster,  we  limit  the  radius  of  each \nmicro-cluster  to  be  below  a  user-specified  threshold, \nmax-radius.  With  the  presence  of  obstacles,  one key \ncomplication  is  to  avoid  having  a  micro-cluster  that \nis  split  by  an  obstacle.  To do so, we  first  triangulate \nthe region  R into triangles  [O’R98] and group the data \npoints according to the triangle that they are in. Figure \n5 illustrates a triangulation of the region  and the form- \ning of  micro-clusters within  each triangle.  Since all the \npoints within a  triangle are always mutually visible, it \nis  guaranteered  that  no  micro-cluster  will  be  split  by \nan obstacle. \n\n2.4  Spatial Join Index \n\nWhile  the information described  earlier  is sufficient \nfor  computing the  obstructed  distance  efficiently, im- \nprovements  can be  achieved by  the  additional compu- \ntation  of  a  spatial join index  [Va187, Rot91, LH921. \nIn  such  an index, each entry  is  a  3-tuple  ( p ,  q ,  d’(p, q ) )  \nwhere p and q are two points in the region R and d’(p, q )  \nis the obstructed  distance between  p  and q .   There  are \nthree spatial join indexes  which can be materialized: \n\n361 \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE Xplore.  Restrictions apply. \n\n\f3  The COD-CLARANS  Algorithm \n\nIn  this section,  we  look  at  the  COD-CLARANS  al- \n\ngorithm in detail. \n\n3.1  The Main Function \n\nWe show the main function  of  the COD-CLARANS \nalgorithm  in  Algorithm  3.1.  The  algorithm  first  ran- \ndomly selects k points as the centers of the clusters and \nthen  tries to find  better  solutions by  iterating through \nStep  5 to Step 26.  At  each  iteration, the  cluster  cen- \nters  are randomly ordered,  and  attempts will be made \nto  replace  them  with  a  better  ceni,er  in  that  order. \nWhen  a  center  cj  is  selected  to  be  replaced,  the  ob- \nstructed  distances  of  the  objects  to  the  other  k  - 1 \ncenters  in  r e m a i n   will",
    "chunk_order_index": 3,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-262243d4a5d82d189743fe5bbb3cb721": {
    "tokens": 1200,
    "content": "- \nters  are randomly ordered,  and  attempts will be made \nto  replace  them  with  a  better  ceni,er  in  that  order. \nWhen  a  center  cj  is  selected  to  be  replaced,  the  ob- \nstructed  distances  of  the  objects  to  the  other  k  - 1 \ncenters  in  r e m a i n   will  first  be  computed  in  Step  10. \nThis information is computed  because  they  can be re- \npeatedly  used  in  the  loop from Step  11 to Step 22  for \nthe  computation of  E’  and  E .   In  Step  12, a  random \nobject  C T a n d o m   is selected  to replace  c J .  Using  C r a n d o m ,  \na lower bound for the squared-error  E’  is computed.  If \nE’  is higher than the previous best  solution, the actual \nsquared-error E  need not  be computed since C r a n d o m   is \nobviously  a  bad  choice.  Otherwise,  E  is  computed to \ndetermine whether  a better solution has been  found.  If \nthis is so, the best solution will be updated and crandom \nwill  replace  the  position  of  cj  in  current.  For  each \ncluster  center,  an  attempt  to  replace  it  will  be  done \nm a z - t r y  times, if no better  solution  is found for all the \ncenters, the  algorithm terminates. \n\n3.2  Computing  Obstructed  Distance  to  Nearest \n\nCenters in r e m a i n  \n\nIn this section, the execution of Step 10 is discussed. \n\nWe  separate  this step into two phases: \n\nAlgorithm 3.2  Computang Dastances between  Objects \nand  Cluster Centres \nPhase  I:  For  all  vertzces  of  the  obstacles,  find  the \nshortest  obstructed  dastance  t o  the  nearest  cluster cen- \nter zn  r e m a i n .   G w e n  a  vertex U ,   we  denote zts  nearest \ncluster center  as  N ( u )  . \nPhase  11:  For  each  mzcro-clusterp,  let  us  denote  the \nset  of  all  vaszble obstacle  vertzces from p  as  uis(p). W e  \nchoose  U  from  u i s ( p )  such  that  ( d ’ ( u ,  N ( u ) )  + d ( p ,  U ) )  \n2s  manamum.  The shortest  dzstance  between p  and  ats \nnearest  cluster center wzll be  computed as (d’(v, N ( u ) ) +  \nd ( p ,  U ) )   and  p  ’s  nearest  cluster  center an  r e m a i n   wzll \nbe  N ( u ) .  \n\nThe  execution  of  Phase  I  can  differ  depending  on \nwhether  the spatial join indexes VV  and MV have been \nmaterialized.  We separate  them  into three  cases. \n\n362 \n\nFigure 5. Forming micro-clusters. \n\n1.  VV Index:  Compute an index entry for any \n\npair of  obstacles  vertices \nThe  materialization  of  this  index  is equivalent  to \nfinding  the  all-pairs  shortest  paths  in  the  visibil- \nity  graph  V G .  We  make use  of  the Johnson’s  al- \ngorithm [CLRSO] for  this  purpose.  From  Lemma \n2.1, we  can  see  that  the  computation of  shortest \npath  between  two  points  in  R  will  often  require \nthe calculation of obstructed  distance between  the \nvertices.  As  such  materializing the VV  index will \nhelp avoid the redundant  computation of these dis- \ntances. \n\n2.  MV Index: Compute an index entry for any \npair of micro-cluster and obstacles vertex \nIn such  an index, the obstructed  distance between \nany  pair  of  micro-cluster  and  vertex  will  be  com- \nputed.  An  efficient  way  to  materialize  the  MV \nindex  is  to first  materialize the BSP-tree  and  the \nVV index.  For each micro-cluster p ,  the set of  visi- \nble obstacle vertices,  u i s ( p )  can then  be computed \nby  using  the  BSP-tree  and  the  distance  to  other \nnon-visible  be computed  by  using the VV  Index. \n\n3.  MM Index:  Compute an index entry for any \n\npair of  micro-clusters \nBy  computing  this  index,  the  obstructed  dis- \ntance  between  any  two micro-clusters  will  be  ma- \nterialized.  Having  the  MM  index  means  that \nCOD-CLARANS  algorithm will  performed  like",
    "chunk_order_index": 4,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-640294e0af80c29be32bb00a2fc506f0": {
    "tokens": 1200,
    "content": "be computed  by  using the VV  Index. \n\n3.  MM Index:  Compute an index entry for any \n\npair of  micro-clusters \nBy  computing  this  index,  the  obstructed  dis- \ntance  between  any  two micro-clusters  will  be  ma- \nterialized.  Having  the  MM  index  means  that \nCOD-CLARANS  algorithm will  performed  like  the \nCLARANS algorithm since  a lookup on the index \nis sufficient t o  find the obstructed distance between \nany two micro-clusters.  However, the size of  such \nan index will  be huge.  Thus, we  feel that such  an \nalternative  will not  be feasible. \n\nWe will compare the relative performance of the first \n\nand second  alternatives in Section 4. \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE Xplore.  Restrictions apply. \n\n\fA l g o r i t h m  3.1  Algorithm COD-CLARANS . \nInput: A set of n objects, k  and clustering parameters, m a i t r y .  \nOutput:  A partition of the n objects into k  clusters with cluster \ncenters, c1, ..., ck. \nM e t h o d :  \n\n- \n\ncompute square-error function E; \nlet  currentE = E; \n\n1. Function COD-CLARANSO \n2. {  randomly select  k  objects to be current; \n3. \n4. \n5.  do \n6. \n7. \n8. \n9. \n\nrandomly reorder current  into { c l ,  ..., ck}; \nfor (j=1  ; jsk  ; j++) \n{  let  remain = current - c3  ; \n/* remain contain the remaining center */ \n\n{  foundnew  = FALSE; \n\n10. \n\n11. \n12. \n13. \n14. \n15. \n16. \n17. \n18. \n19. \n\ncompute obstructed distance of objects to nearest \ncenter in remain; \nfor (try=@ try < maz-try; try++) \n{  replace c3 with a randomly selected object  Crandom  ; \n\ncompute estimated square-error function E’; \nif  (E’ > currentE) \n\ncontinue; /* Not  a good solution */ \n\ncompute square-error function E; \nif  ( E  < currentE) /* Is the new solution better ?  */ \n{  foundnew  = TRUE; /* Found a better solution */ \n\ncurrent = { c l ,  ..., crandom, ... ck} \n/* replace c,  with  Crandom  */ \ncurrentE = E; \n\n1 \n\n} \nif  (foundnew) \n\n20. \n21. \n22. \n23. \n24. \n25. \n26.  } while (foundnew) \n28.  output current  ; \n27) \n\n} \n\nbreak; /* Reorder cluster centers again */ \n\n1. \n\nVV is materialized \nIf  VV  is  computed,  then  all  we  have  to  do  is \nto find  the  visible  vertices  from  each  cluster  cen- \nter  ci  and  then  compute the  obstructed  distance \nof  each  vertex  vj as  d’(ci,vj) = m i n ( d ( c i , v k )  + \nd’( vj , vk)), v k  E vis( c i ) .   The nearest  center of each \nvertex  can then  be  identified. \n\n2. \n\nMV is materialized \nIf MV is available, the obstructed distance between \nany  cluster  center  and  any  obstacles  vertex  will \nbe  materialized.  As  such, a  search  in  MV  will be \nsufficient t o  find the obstructed distance of a node \nv  to the IC  - 1 centers.  The nearest  center  of  the \nvertex  can then  be  determined. \n\nc and a vertex  v  if  v  is visible from c .  In addition, \na  virtual  node  s  is  also  inserted  and  linked  by \nan edge of  weight zero t o  each of  the k - 1 cluster \ncenters.  The Dijkstra’s algorithm is then ran  with \nthe virtual node  s as the source point.  To identify \nthe closest  cluster  center  for  a vertex  w ,  the short- \nest  path  from  s  to  v  is traced  during  the  run  of \nDijkstra’s algorithm to monitor which cluster  cen- \nter  is in  the  path.  This cluster  center  will  be  the \ncluster center  that  is closest  to U. \n\nOnce Phase I is completed, the execution of Phase I1 \nis trivial except  for forming of  vis(p) with  respect  to a \npoint p .  We make use of the BSP-tree for this purpose. \n\n3.3  Computing the Lower Bound E’ \n\nAfter  Crandom  is  generated  at  line  13  of  Algo- \nrithm 3.1, we  first  underestimate  the distance between \nC,andom  and  the  micro-clusters  by  using  direct  Eu- \nclidean distance.",
    "chunk_order_index": 5,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-5985572200df3c53053a5da9aebea077": {
    "tokens": 1200,
    "content": "vis(p) with  respect  to a \npoint p .  We make use of the BSP-tree for this purpose. \n\n3.3  Computing the Lower Bound E’ \n\nAfter  Crandom  is  generated  at  line  13  of  Algo- \nrithm 3.1, we  first  underestimate  the distance between \nC,andom  and  the  micro-clusters  by  using  direct  Eu- \nclidean distance.  Note that in Step 10, we  have already \ncomputed  the nearest  cluster centers  from remain for \neach  object  p .   Let  us  denote this  center  as  N ( p ) .  If \nthe  direct  Euclidean  distance between  a  micro-cluster \np  and Crandom  is shorter than d’(p, N ( p ) )  (which is also \ncomputed  with  the  k  - 1 unchanged  cluster  centers), \nthen p  is  assigned  to Crandom  and the direct  Euclidean \ndistance  between  them  will  be  used  when  computing \nthe  estimated  square-error  function  E‘.  We  have  the \nfollowing lemma. \n\nLemma  3.1  E‘  is a  lower bound f o r  the actual  square- \nerror function  E .  \n\nThe proof  of  the  Lemma 3.1 is  omitted  for  lack  of \napace.  Since  E’  is  a lower  bound  of  E ,  we  can choose \nto  abandon  Crandom  if  E’  is  already  higher  than  the \nsquare-error  function  of the best  solution found  so far. \nHowever,  if  E’  is  lower  than  the  best  solution,  then \nE  must be computed. Since the obstructed distance of \neach micro-cluster p  to N ( p )  is already calculated, what \nwe  need  to find  is the obstructed  distance between  the \nnew center  Crandom  and  the micro-clusters  that will be \nassigned to Crandom.  For this purpose, we  can use of the \nfocusing information provided  by  the  computation \nof  E’  to limit the set  of  micro-clusters  which  will have \nCrandom as the nearest  center.  This is done by observing \nthe following lemma. \n\n3. \n\nNo spatial join index is materialized \nIf  no spatial join index is  available, then  the  pre- \ncomputed visibility graph V G  = (V, E )  will be uti- \nlized.  We  make  use  of  the  Dijkstra’s  algorithm \n[CLRSO] for  this  purpose.  We  insert  k  - 1 addi- \ntional nodes  representing  the k  - 1 cluster  centers \ninto V .  An edge is created between  a cluster center \n\nLemma  3.2  I f   a  micro-cluster  p  is  not  assigned  to \nCrandom  when  computing  E’,  then  it  can  never  be  as- \nsigned  to Crandom  when  computing  E .  \n\nUsing  Lemma 3.2, we  can  limit our computation of \nobstructed  distance  t o   CTandom  to  a  subset  of  micro- \nclusters  instead of  all micro-clusters. \n\n363 \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE Xplore.  Restrictions apply. \n\n\f3.4  Computing the Squared-error E \n\nAs  mentioned  earlier, since  the obstructed  distance \nof  each  micro-cluster  to its nearest  center  in remain is \nalready computed in Step 10, what we  only need to find \nwhen  computing E  is the obstructed  distance between \nthe new  center  crQndom and the micro-clusters  that will \nbe  assigned  to crandom.  This process  is similar to Step \n10 except that we  can use the focusing information pro- \nvided  by  E’  to limit the computation. \n\n4  Performance  Study \n\nIn  this  section,  we  will  have  a  look  a t  the  perfor- \nmance of  the  COD-CLARANS algorithm by  perform- \ning experiments on  a PC with a Pentium 6OOMhz pro- \ncessor  and a IBM  7200rpm hard disk.  For these  exper- \niments, we  use  two  synthetic datasets,  DS1  and  DS2, \nwhich  are  shown  in  Figure  6.  DS1  consists  of  63350 \npoints randomly distributed in the region.  We simulate \nmajor  “obstacles” like rivers,  highways] and industrial \nparks  in  the  region  by  adding in  20  obstacles.  These \npolygons  have  a  total  of  194 edges.  DS2  dataset  con- \nsists  of  five  clusters  that  are  cut  through  by  “stick” \nobstacles.  There  are  altogether  60000  points  and  10 \nobstacles",
    "chunk_order_index": 6,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-56fe189bf559750f0e0500ecf6dd5b62": {
    "tokens": 1200,
    "content": "like rivers,  highways] and industrial \nparks  in  the  region  by  adding in  20  obstacles.  These \npolygons  have  a  total  of  194 edges.  DS2  dataset  con- \nsists  of  five  clusters  that  are  cut  through  by  “stick” \nobstacles.  There  are  altogether  60000  points  and  10 \nobstacles  in  DS2.  Each  obstacle has 4 edges. \n\nIn  our  experiments, we  set  the  parameter  max-try \nto be  40.  Micro-clusters  are formed  by  applying  the \nBIRCH algorithm described  in  [ZRL96]. \n\nThe experiments  proceed  as follows.  First,  we  as- \nsess the  efficiency  and effectiveness  of  the  various  fla- \nvor of  COD-CLARANS  by  running our algorithms on \nDS1.  COD-CLARANS can be separated into three cat- \negories in  term of  materialized index:  1) non  material- \nized, 2)  VV  materialized and 3)  MV  materialized.  We \ndenote them as COD-CLARANS-N, COD-CLARANS- \nVV,  and  COD-CLARANS-MV,  respectively.  In  addi- \ntion, a symbol “%”  will be appended to the end of these \nalgorithms  to denote  a  version  in  which  the  pruning \nfunction  is  not  used.  We  assess  these  algorithms by \nadjusting the  parameter  maz-radius  that control  the \nnumber of  micro-clusters  being  formed.  Next, we  look \nat the clustering result  of COD-CLARANS on DS2 and \ncompare it  to those  of  CLARANS which  ignore obsta- \ncles in  its clustering. \n\n4.1  Varying max-radius \n\nIn  this  experiment,  we  vary  the  number  of  micro- \nclusters  that  are  generated  from  DS1  by  tuning  the \nparameter  max-radius  that  bound  the  radius  of  the \nmicro-clusters being formed. There are two purposes in \ndoing this.  First, since more accuracy  will be lost when \n\n(a) DS1. \n\n(b) DS2. \n\nFigure 6. Two datasets. \n\nmax-radius is increased, we  like tal investigate how the \nquality  of  the clusters is  affected  by  the  use  of  micro- \nclustering.  Second, since  the number of  micro-clusters \nvaries according to max-radius, we can investigate how \nthe various algorithms scale up as the number of micro- \nclusters increases.  Performing  this as a scalability test \nis  preferable  over  arbitrarily adding points which  may \naffect the distribution of the data and subsequently the \nexecution  time of  the algorithms. \n\nThe various values of max-radius and the number of \nmicro-clusters  which are formed for DS1 shown in Table \n1 together  with  the average  squared-error  of  the clus- \nters.  As can be seen,  the increase  in the quality of  the \n\n364 \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE Xplore.  Restrictions apply. \n\n\fTable 1. Effect of Varvina max-radius. \n\n,\n\n,\n\n,\n\n,\n\n,\n\n I\n\n,\n\n2wo \n\n1sw \n\n;*, \n\n,\n\nC O E C U ~ S - N  +- \nW E - C W N S W  ---*-- \nWECLARANS-MV  ...a... \nCOECURANS-NX  -e-- \nCOECLARANSW%  - t - \nWE-CLARANSYV%  - -0 - \n\n0.02 \n0.03 \n0.04 \n0.05 \n\nI \n\nI \n\n63350 \n\n3133 \n1546 \n\n965 \n520 \n\n1.51 \n1.55 \n\n~ \n\n1.56 \n1.59 \n\nI \n\nI \nI \n\nclusters  due to micro-clustering  is not  significant  com- \nparing t o  the decrease  in  the number of  micro-clusters \nfor  DS1.  The  drop  in  cluster  quality  by  performing \nmicro-clustering  is at most  8%. \n\nLet  us  now  look  at  the  pre-processing  time that  is \nrequired  for  DS1 in  Figure  7.  The pre-processing  time \nfor  COD-CLARANS-N  and  COD-CLARANS-VV  are \nonly  minorly  affected  by  max-radius.  This is because \nthe only pre-processing  operation that max-radius has \nan  effect  on  is  the forming  of  micro-clusters.  We  can \nalso  see  that  COD-CLARANS-VV  has  a  higher  pre- \nprocessing  time due  to the  materialization of  the  VV \nindex  which  is  equivalent  to  an  all-pair shortest  path \nsearch  on  the visibility  graph.  COD-CLARANS-MV, \non  the  other",
    "chunk_order_index": 7,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-3daaa67e5962ecc9c0782c6442381587": {
    "tokens": 1200,
    "content": "on  is  the forming  of  micro-clusters.  We  can \nalso  see  that  COD-CLARANS-VV  has  a  higher  pre- \nprocessing  time due  to the  materialization of  the  VV \nindex  which  is  equivalent  to  an  all-pair shortest  path \nsearch  on  the visibility  graph.  COD-CLARANS-MV, \non  the  other  hand,  will  decrease  with  as  max-radius \nincreases.  This is  because  increasing  max-radius  will \nresult  in  less  micro-clusters  and  corresponding  the \namount of computation that much be done to calculate \nthe  obstructed  distance  between  each  micro-clusters \nand  the obstacles  vertices. \n\nNext,  let  us look  at the  actual  running  time of  our \nalgorithm for  DS1  in  Figure  8.  From  the  graph,  we \nhave  the following observations. \n\nB m -  \n\n, \n\n, \n\n, \n\n, \n\n, \n\n, \n\n, \n\n, \nCOEcLAkANsN  -+- \nCOE-CLARANSW  .--X--- \nWECURANS-MV  -..*-.. \n\nsm \n\n-  '!. \n\n400- \n\n'., \n\n- - \n- \nE  300 \n= \n\n- \n\n200 \n\n....... \nI \n\n............ \n\n100:; \n\n.................*.................* \n\n.*-. \n\n.................. x .................... =.=.  ....... =.... .. \" \n\n*.- .................. \n\n................. \n\n. \n\nFigure 7. Pre-processing Time of DS1. \n\nFirst,  algorithms  which  does  not  use  the  pruning \nfunction  will  have  a  longer  execution  time than  those \nwith pruning function. This is especially true for COD- \nCLARANS-N%  when  the  number  of  micro-clusters  is \nhigh.  The execution  time of  COD-CLARANS-N%  on \nDS1  reach  as  high  as  66392  seconds  and  3119  sec- \n\n1Bm \n\nis, \nI  *. . .  \n\n.%*. \n\n12M \n\n- \n\n1WO \n\n803 \n\nE m  \n\n400 \n\n2w \n\n0 \n0 \n\n0.005 \n\n0.01 \n\n0.015 \n\n0.02 \n\n0.025 \n\n0.W \n\n0.W5  0.01  0.M  0 . S  \n\nI  d \n\nFigure 8. Algorithms Running Time of  DS1. \n\nonds when  max-radius  is set  to 0.00 and  0.01 respec- \ntively.  When spatial join indexes  are available, the dif- \nferences between  the pruning and non-pruning  versions \nare narrower.  This is because  the computation of  ob- \nstructed distance is more efficient with the use of spatial \njoin indexes  and thus the reduction  of  processing  time \nthrough the pruning function  becomes less significant. \nSecond,  the  spatial  join  indexes  are  useful  in  re- \nducing  the  execution  time of  the  algorithms.  This  is \ntrue even when  the pre-processing  times are taken into \nconsideration.  For  the pruning  versions  of  the COD- \nCLARANS  algorithm, having  spatial indexes  will  im- \nprove the execution  times of  the algorithms marginally. \nHaving spatial join indexes in the non-pruning  versions \nof  the  algorithm  however,  has  significant  advantages \nover  one  that  does  not  have  spatial join  indexes.  Be- \ntween the two spatial join indexes, VV  and MV, having \nthe MV  index generally gives better  performance  than \nhaving  the  VV  index.  The only  exception  is observed \nfor  DS1 when  the number of  micro-clusters  is high.  In \nsuch  a  case,  the size  of  MV  is  much  higher  than  the \nsize of  VV  and the time taken to access MV  will offset \nthe advantage that it has by  storing more information. \nAs  a  whole,  we  found  that the COD-CLARANS  al- \ngorithm scales well for large number of  points.  We rec- \nommend the use of spatial join index MV if the number \nof edges is small. However, the use of spatial join index \nVV will be more space efficient since the obstructed dis- \ntance between  any two obstacle  vertices  is sufficient to \navoid  running  the  Dijkstra  algorithm on  the  visibility \ngraph. \n\n4.2  Clustering Results \n\nTo  ascertain  that  clustering  with  consideration  of \nobstacles  is  in  fact  useful,  we  will  compare the  clus- \nter  quality of  COD-CLARANS  with  the  clusters  that \nis  discovered  by  the  CLARANS  algorithm.  For  the \n\n365 \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE Xplore.  Restrictions apply. \n\n \n\fCLARANS  algorithm, we  first  cluster  the  data points \nby",
    "chunk_order_index": 8,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-eb58b1784471dc4779392e06c39fe293": {
    "tokens": 1200,
    "content": "ter  quality of  COD-CLARANS  with  the  clusters  that \nis  discovered  by  the  CLARANS  algorithm.  For  the \n\n365 \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE Xplore.  Restrictions apply. \n\n \n\fCLARANS  algorithm, we  first  cluster  the  data points \nby  ignoring the obstacles.  At the end of the algorithm, \nthe cluster  centers are fixed.  Data points are then  allo- \ncated to the nearest  centers by obstructed distance \nand  the squared-error  will  be  computed.  Note that  in \nthis case, points which  are earlier  assigned  to a cluster \ncenter  may  be  reassigned  to a  different  one  when  ob- \nstacles are taken  into consideration.  The results  of  the \ntwo algorithms for  DS2  are shown in  Figure  9. \n\nWhen  k  = 5,  the  average  squared-error  found  by \nthe  COD-CLARANS  algorithm  on  DS2  is  1.24 while \nCLARANS  gives  an  average  squared-error  of  1.68. \nThe  clustering  result  of  DS2  illustrates  why  COD- \nCLARANS  performs  better  than  CLARANS  in  both \ncases.  Let  us  refer  to  the  space  between  any  two  ob- \nstacles as a corridor.  As  we  can  see, the cluster  centers \nthat are discovered by  the COD-CLARANS algorithm \nare mostly placed  at the  “entrance”  of  the corridor  so \nthat they  are accessible by  points from other corridors. \nOn the other hand, CLARANS which has no knowledge \nof the obstacles will place the centers into the corridors, \nwhich  means  that  points  from other  corridors  will  be \nvery  far from the nearest  center. \n\nWhile the performance of  COD-CLARANS is better \nthan  CLARANS  for  low  value  of  k ,   this  performance \ngap is found to decrease  as we  increase  k.  The reason \nbehind  this is that  as k  increases,  most points  will  be \ndirectly  visible to the  nearest  center.  As  such, the  ef- \nfect  of  the  obstacles  will  diminish.  We  thus  conclude \nthat COD-CLARANS will be  effective for value of  k  in \nwhich most  point  will not  be  directly  visible from any \nof  the k centers. \n\n5  Future  Work \n\nWhile the work presented  here is sufficient for many \napplications  of  clustering  with  obstructed  distance, \nthere are still a lot of  future work  to be  considered. \n\nAlthough the model  of  discussion in  this paper  is in \na two-dimensional  region with obstacles represented  as \nsimple  polygons,  it  can  be  generalized  to other  mod- \nels  as  well.  For  example, consider  clustering  objects \naround  a  network  structure.  We  can  still  perform \nmicro-clustering  although  there  is  no  requirement  for \nother  pre-processing  information.  To  speed  up  the \nprocess,  a  spatial join  index  can  still  be  materialized. \nA  pruning function  E’  can  also be  used  to  prune  the \nsearch  space. \n\nIn  our  work,  one  implicit  assumption  is  that  the \nnumber of obstacles is smaller than the number of  data \npoints.  This  is  true  for  many  applications like  ATM \nlocations  planning  where  we  only  need  to  take  major \nobstacles  into consideration.  However, in  cases  where \nthere are a lot of obstacles between any two data points, \n\n(a) Result of  COD-CLARANS. \n\n(b) Result of  CLARANS. \n\nFigure 9. Clustering Result for DS2. \n\ntechniques  like micro-clustering  will not  be  applicable \nsince  a  triangulation of  the  region  will result  in few  or \nno  points  in  each  triangular  region.  Further  study  is \nrequired  to handle such  cases. \n\nBesides this, a look at how obstacles will affect other \nclustering paradigms will be interesting  as well.  For ex- \nample, it  will be  challenging to see  how  density-based \nalgorithms like  DBSCAN  [EKSX96]  can  be  enhanced \nto cluster  under  obstructed  distance.  Since  DBSCAN \nmakes uses of the k-nearest-neighbors  operation  to per- \nform  clustering,  an  immediate  subproblem  is  to  find \nthe  k  nearest  neighbors  with  consideration  of  obsta- \ncles.  This subproblem  is  a  challenge  by  itself  as most \n\n366 \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE X",
    "chunk_order_index": 9,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-373c6ca4376cebee0c228eac7632e9c0": {
    "tokens": 1200,
    "content": "arest-neighbors  operation  to per- \nform  clustering,  an  immediate  subproblem  is  to  find \nthe  k  nearest  neighbors  with  consideration  of  obsta- \ncles.  This subproblem  is  a  challenge  by  itself  as most \n\n366 \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE Xplore.  Restrictions apply. \n\n\fk-nearest-neighbors  implementation are relying on spa- \ntial index structures like the R-tree  to speed up the op- \neration  and  no consideration of  obstacles  are taken  in \nsuch  a spatial data structure  [BBKK97]. \n\n[EKSX96] \n\n6  Conclusion \n\nIn  this  paper,  we  have  studied  on  the  problem  of \nClustering  with  Obstructed  Distance  (COD)  which \nwe  believe  is  a  very  has  many  practical  applica- \ntions.  We  formalize  the  definition  of  this  prob- \nlem  and  derive  an  algorithm  COD-CLARANS for  solv- \ning  it.  We  discuss  various  types  of  pre-processed \ninformation  that  could  enhance  the  efficiency  of \nCOD-CLARANS .  By  pushing  the  handling  of  obsta- \ncles  into the  COD-CLARANS algorithm  instead  of  ab- \nstracting it  at the distance function level,  we  are able \nto provide  a  pruning function  E’  that greatly enhance \nthe efficiency of  COD-CLARANS  . We  perform  various \nexperiments on  COD-CLARANS to ascertain its useful- \nness  and scalability.  Finally, we  discuss some potential \nenhancements  to  the  COD-CLARANS algorithm.  We \nbelieve  that  there  is still a  lot of  room  for  research  in \nthe problem  of COD and hope that our work could mo- \ntivate more people to look into this area. \n\nAcknowledgment:  The first  author  wishes to thank \nBinay  Bhattacharya  for  introducing the field  of  Com- \nputation Geometry to him.  Discussions with  Raymond \nT. Ng and Laks V. S. Lakshmanan have been  very use- \nful  towards  this  work.  The  code  for  BIRCH  is  kindly \nprovided  by  Raghu Ramakrishnan. \n\nReferences \n\n[ABKS99]  M.  Ankerst,  M.  Breunig,  H.-P.  Kriegel,  a n d  \nJ.  Sander.  OPTICS:  Ordering  points  t o   identify \nIn  Proc.  1999  ACM- \nthe  clustering  structure. \nSIGMOD  Int.  Conf.  Management  of  Data  (SIG- \nMOD’99), pages 49-60,  Philadelphia, PA, June 1999. \n[AGGR98]  R. Agrawal, J. Gehrke, D. Gunopulos, a n d  P. Ragha- \nvan.  Automatic  subspace  clustering  of  high  di- \nIn \nmensional  d a t a   for  d a t a   mining  applications. \nProc.  1998  AGM-SIGMOD  Int.  Conf. Management \nof  Data  (SIGMOD’98), pages 94-105,  Seattle, WA, \nJune 1998. \n\n[BFRSS] \n\n[BBKK97]  S.  Berchtold,  C.  Bohm,  D.  A.  Keim,  and  H.  P. \nKriegel.  A cost model for nearest neighbor search in \nhigh  dimensional d a t a  space.  In  Proc.  of  16th A CM \nSymp.  on  Principles  of  Database  Systems  (PODS), \n1997. \nP.  Bradley,  U.  Fayyad, and  C. Reina.  Scaling clus- \ntering algorithms t o  large databases.  In  Proc.  1998 \nInt.  Conf.  Knowledge  Discovery  and  Data  Mining \n(KDD’98), pages 9-15,  New  York, NY, Aug.  1998. \nT.  Cormen,  C.  Leiserson, and  R.  Rivest.  Introduc- \ntion to Algorithms. T h e  MIT Press, Cambridge, MA, \n1990. \n\n[CLRSO] \n\n[GRS98] \n\n[HK98] \n\n[KHK99] \n\n[Koh82] \n\n[KR90] \n\n[LH92] \n\n[NH94] \n\n[O’R98] \n\n[Rot911 \n\n[SCZ98] \n\n[SD90] \n\n[SG97] \n\n[Val871 \n\n[WYM97] \n\n[ZRL96] \n\n367 \n\nM.  Ester,  H.-P.  Kriegel,  J.  Sander, a n d   X.  Xu.  A \ndensity-based algorithm  for  discovering  clusters  in \nlarge  spatial  databases.  In",
    "chunk_order_index": 10,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-9e18d37e51b9a471c9bb5a258841cc4d": {
    "tokens": 1200,
    "content": "[O’R98] \n\n[Rot911 \n\n[SCZ98] \n\n[SD90] \n\n[SG97] \n\n[Val871 \n\n[WYM97] \n\n[ZRL96] \n\n367 \n\nM.  Ester,  H.-P.  Kriegel,  J.  Sander, a n d   X.  Xu.  A \ndensity-based algorithm  for  discovering  clusters  in \nlarge  spatial  databases.  In  Proc.  1996  Int.  Conf. \nKnowledge  Discovery  and  Data  Mining  (KDD’96), \npages  226-231,  Portland, Oregon, Aug.  1996. \n\nS.  Guha,  R.  Rastogi,  a n d   K.  Shim.  Cure:  An  ef- \nficient  clustering algorithm for  large  databases.  In \nProc.  1998 AGM-SIGMOD  Int.  Conf. Management \nof  Data  (SIGMOD’98), pages  73-84,  Seattle,  WA, \nJune 1998. \n\nA.  Hinneburg  and  D.  A.  Keim.  An  efficient  a p  \nproach  t o  clustering in  large  multimedia  databases \nwith noise.  In Proc.  1998 Int.  Conf. Knowledge  Dis- \ncovery  and  Data  Mining  (Ii‘DD’98),  pages  58-65, \nNew  York, NY,  Aug.  1998. \nG.  Karypis,  E.  -  H.  Han,  and  V.  Kumar. \nCHAMELEON:  A  hierarchical  clustering algorithm \nusing  dynamic  modeling.  COMPUTER, 32:68-75, \n1999. \n\nT.  Kohonen.  Self-organized  formation  of  topologi- \ncally  correct feature  maps.  Biological  Cybernetics, \n43:59-69,  1982. \n\nL.  Kaufman  and  P.  J.  Rousseeuw.  Finding  Groups \ni n  Data:  an  Introduction  to  Cluster  Analysis.  John \nWiley &  Sons, 1990. \n\nW.  Lu  a n d   J.  Han.  Distance-associated  join  in- \ndices  for  spatial  range  search.  In  Proc.  2992  Int. \nConf.  Data  Engineering  (ICDE’92), pages  284-292, \nPhoenix, AZ, Feb.  1992. \n\nR.  Ng  a n d   J.  Han.  Efficient  and  effective cluster- \ning method  for  spatial d a t a  mining.  In  Proc.  1994 \nInt.  Conf. Very Large  Data Bases  ( V L D B  ’94), pages \n144-155,  Santiago, Chile, Sept.  1994. \n\nJ.  O’Rourke.  Computational  Geometry  in  C  (2nd \nEd.).  Cambridge University  Press,  1998. \n\nD. Rotem.  Spatial join  indices.  In  Proc.  1992  Int. \nConf.  Data  Engineering  (ICDE’gl), pages  500-509, \nKobe, J a p a n ,  Apr.  1991. \n\nG .   Sheikholeslami,  S.  Chatterjee,  a n d   A.  Zhang. \nWavecluster:  A multi-resolution clustering approach \nfor  very  large spatial databases.  In  Proc.  1998  Int. \nConf.  Very  Large  Data  Bases  (VLDB’98),  pages \n428-439,  New  York, NY, Aug.  1998. \n\nJ.W.  Shavlik and T.G.  Dietterich.  Readings  in Ma- \nchine  Learning.  Morgan  Kaufmann, 1990. \n\nSilicon  Graphics. Inc.  BSP Tree:  Frequently asked \nquestions. \nhttp://reality.sgi.com/bspfaq/index.shtml,  1997. \n\nP.  Valduriez.  Join  indices.  AGM  Trans.  Database \nSystems, 12:218-246,  1987. \nW .  Wang, J. Yang, and R. Muntz.  STING:  A statis- \ntical information grid approach t o  spatial d a t a  min- \ning. In Proc.  1997 Int.  Conf.  Very Large  Data  Bases \n(VLDB’97),  pages  186-195,  Athens,  Greece,  Aug. \n1997. \n\nT. Zhang, R. Ramakrishnan, and M. Livny. BIRCH: \na n   efficient  d a t a   clustering  method  for  very  large \ndatabases. In Proc.  1996  AGM-SIGMOD Int.  Conf, \nManagement  of  Data  (SIGMOD’96), pages 103-114, \nMontreal, Canada, J u n e  1996. \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from",
    "chunk_order_index": 11,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-7ed4b934374539664a845430e389fd36": {
    "tokens": 108,
    "content": "d a t a   clustering  method  for  very  large \ndatabases. In Proc.  1996  AGM-SIGMOD Int.  Conf, \nManagement  of  Data  (SIGMOD’96), pages 103-114, \nMontreal, Canada, J u n e  1996. \n\nAuthorized licensed use limited to: University of Texas at Austin. Downloaded on June 12,2025 at 01:47:06 UTC from IEEE Xplore.  Restrictions apply.",
    "chunk_order_index": 12,
    "full_doc_id": "doc-7f956df614d7c7497f9cf8c796395448"
  },
  "chunk-b4d020eea8d8c5f472a5022133bac26a": {
    "tokens": 1200,
    "content": "SPATIAL\nCLUSTER\nMODELLING\n\n\f \n\fSPATIAL\nCLUSTER\nMODELLING\n\nEdited by\nAndrew B. Lawson\nDepartment of Mathematical Sciences\nUniversity of Aberdeen\nAberdeen, UK\n\nDavid G.T. Denison\nDepartment of Mathematics\nImperial College of Science, Technology and Medicine\nLondon, UK\n\nCHAPMAN & HALL/CRC\n\nA CRC Press Company\nBoca Raton   London   New York   Washington, D.C.\n\n\fC2662 disclaimer  Page 1  Monday, March 18, 2002  1:53 PM\n\nLibrary of Congress Cataloging-in-Publication Data\n\nLawson, Andrew (Andrew B.)\n\nSpatial cluster modeling / edited by Andrew B. Lawson, David G.T. Denison.\n\np. cm.\n\nIncludes bibliographical references and index.\nISBN 1-58488-266-2 (alk. paper)\n1. Cluster analysis. 2. Spatial analysis. I. Denison, David G. T. II. Title.\n\nQA278 .L39 2002\n519.5\n\n3—dc21\n\n′\n\n2002019297\n\nThis book contains information obtained from authentic and highly regarded sources. Reprinted material\nis quoted with permission, and sources are indicated. A wide variety of references are listed. Reasonable\nefforts have been made to publish reliable data and information, but the authors and the publisher cannot\nassume responsibility for the validity of all materials or for the consequences of their use.\n\nNeither this book nor any part may be reproduced or transmitted in any form or by any means, electronic\nor mechanical, including photocopying, microﬁlming, and recording, or by any information storage or\nretrieval system, without prior permission in writing from the publisher.\n\nAll  rights  reserved. Authorization  to  photocopy  items  for  internal  or  personal  use,  or  the  personal  or\ninternal  use  of  speciﬁc  clients,  may  be  granted  by  CRC  Press  LLC,  provided  that  $1.50  per  page\nphotocopied is paid directly to Copyright Clearance Center, 222 Rosewood Drive, Danvers, MA 01923\nUSA.  The  fee  code  for  users  of  the  Transactional  Reporting  Service  is  ISBN  1-58488-266-\n2/02/$0.00+$1.50. The fee is subject to change without notice. For organizations that have been granted\na photocopy license by the CCC, a separate system of payment has been arranged.\n\nThe consent of CRC Press LLC does not extend to copying for general distribution, for promotion, for\ncreating new works, or for resale. Speciﬁc permission must be obtained in writing from CRC Press LLC\nfor such copying.\n\nDirect all inquiries to CRC Press LLC, 2000 N.W. Corporate Blvd., Boca Raton, Florida 33431. \n\nTrademark Notice: \nused only for identiﬁcation and explanation, without intent to infringe.\n\nProduct or corporate names may be trademarks or registered trademarks, and are\n\nVisit the CRC Press Web site at www.crcpress.com\n\n© 2002 by Chapman & Hall/CRC  \n\nNo claim to original U.S. Government works\nInternational Standard Book Number 1-58488-266-2\nLibrary of Congress Card Number 2002019297\nPrinted in the United States of America  1  2  3  4  5  6  7  8  9  0\nPrinted on acid-free paper\n\n \n \n \n \n \n \n \n \n \n \n \n \n\fContents\n\nList of Contributors\n\nPreface\n\n1 Spatial Cluster Modelling: An Overview\n\n1.1 Introduction\n1.2 Historical Development\n\n1.2.1 Conventional Clustering\n1.2.2 Spatial Clustering\n\n1.3 Notation and Model Development\n1.3.1 Nonparametric Approaches\n1.3.2 Point or Object Process Modelling\n1.3.3 Random Eﬀect Modelling\n1.3.4 Partition Modelling\n1.3.5 Spatio-Temporal Process Modelling\n\nI Point process cluster modelling\n\n2 Signiﬁcance in Scale-Space for Clustering\n\n2.1 Introduction\n2.2 Overview\n2.3 New Method\n2.4 Future Directions\n\n3 Statistical Inference for Cox Processes\n\n3.1 Introduction\n3.2 Poisson Processes\n3.3 Cox Processes\n3.4 Summary Statistics\n3.5 Parametric Models of Cox Processes\n\n3.5.1 Neyman-Scott Processes as Cox Processes\n3.5.2 Log Gaussian Cox Processes\n3.5.3 Shot Noise G Cox Processes\n\n3.6 Estimation for Parametric Models of Cox Processes\n\nxi\n\nxiii\n\n1\n1\n3\n6\n8\n12\n13\n15\n16\n18\n18\n\n21\n\n23\n23\n24\n29\n35\n\n37\n37\n39\n41\n43\n45\n45\n48\n49\n51\n\n\fvi\n\n3.7 Prediction\n\nCONTENTS\n\n3.7.1 Conditional Simulation for Neyman-Scott Processes\n3.7.2 Conditional Simulation for LGCPs\n3.7.3 Conditional Simulation for Shot-noise G Cox Pro-\n\ncesses\n\n3.8 Discussion\n\n4 Extrapolating and Interpolating Spatial Patterns\n\n4.1 Introduction\n4.2 Formulation and Notation\n4.2.1 Germ–grain Models\n4.2.2 Problem Statement\n4.2.3 Edge Eﬀects and Sampling Bias\n4.2.4 Extrap",
    "chunk_order_index": 0,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-8d615ec5c2c224b5167b1a6b1f304a30": {
    "tokens": 1200,
    "content": "3.7.2 Conditional Simulation for LGCPs\n3.7.3 Conditional Simulation for Shot-noise G Cox Pro-\n\ncesses\n\n3.8 Discussion\n\n4 Extrapolating and Interpolating Spatial Patterns\n\n4.1 Introduction\n4.2 Formulation and Notation\n4.2.1 Germ–grain Models\n4.2.2 Problem Statement\n4.2.3 Edge Eﬀects and Sampling Bias\n4.2.4 Extrapolation\n4.3 Spatial Cluster Processes\n\n4.3.1 Independent Cluster Processes\n4.3.2 Cox Cluster Processes\n4.3.3 Cluster Formation Densities\n\n4.4 Bayesian Cluster Analysis\n\n4.4.1 Markov Point Processes\n4.4.2 Sampling Bias for Independent Cluster Processes\n4.4.3 Spatial Birth-and-Death Processes\nExample: Redwood Seedlings\n\n4.4.4 Parameter Estimation\n\nExample: Cox–Mat´ern Cluster Process\n\n4.4.5 Adaptive Coupling from the Past\n4.4.6 Example: Cox–Mat´ern Cluster Process\n\n4.5 Summary and Conclusion\n\n5 Perfect Sampling for Point Process Cluster Modelling\n\n5.1 Introduction\n5.2 Bayesian Cluster Model\n5.2.1 Preliminaries\n5.2.2 Model Speciﬁcation\n\n5.3 Sampling from the Posterior\n5.4 Specialized Examples\n\n5.4.1 Neyman–Scott Model\n5.4.2 Pure Silhouette Models\n\n5.5 Leukemia Incidence in Upstate New York\n5.6 Redwood Seedlings Data\n\n6 Bayesian Estimation and Segmentation of Spatial Point\n\nProcesses Using Voronoi Tilings\n6.1 Introduction\n\n54\n55\n55\n\n56\n58\n\n61\n61\n62\n63\n63\n64\n65\n66\n67\n68\n69\n72\n72\n74\n75\n76\n78\n80\n80\n84\n86\n\n87\n87\n89\n89\n90\n93\n95\n95\n98\n100\n106\n\n109\n109\n\n\fCONTENTS\n\n6.2 Proposed Solution Framework\n\n6.2.1 Formulation\n6.2.2 Voronoi Tilings\n6.2.3 Markov Chain Monte Carlo Using Dynamic Voronoi\n\nTilings\n\n6.3 Intensity Estimation\n\n6.3.1 Formulation\n6.3.2 MCMC Implementation\n\nFixed Number of Tiles\nVariable Number of Tiles\n\n6.4 Intensity Segmentation\n6.4.1 Formulation\n\nFixed Number of Tiles\nVariable Number of Tiles\n\n6.5 Examples\n\n6.5.1 Simulated Examples\nA Sine Wave\nA Linear Feature\n\n6.5.2 New Madrid Seismic Region\n\n6.6 Discussion\n\nII Spatial process cluster modelling\n\n7 Partition Modelling\n7.1 Introduction\n7.2 Partition Models\n\n7.2.1 Partitioning for Spatial Data\n7.2.2 Bayesian Inference\n7.2.3 Predictive Inference\n7.2.4 Markov Chain Monte Carlo Simulation\n7.2.5 Partition Model Prior\n\n7.3 Piazza Road Dataset\n7.4 Spatial Count Data\n\n7.4.1 The Poisson-Gamma Model for Disease Mapping\n7.4.2 Disease Mapping with Covariates\n7.4.3 East German Lip Cancer Dataset\n\n7.5 Discussion\n7.6 Further Reading\n\n8 Cluster Modelling for Disease Rate Mapping\n\n8.1 Introduction\n8.2 Statistical Model\n8.3 Posterior Calculation\n8.4 Example: U.S. Cancer Mortality Atlas\n\nvii\n\n110\n110\n111\n\n111\n112\n112\n112\n113\n114\n115\n115\n115\n117\n117\n117\n117\n118\n118\n119\n\n123\n\n125\n125\n126\n127\n128\n131\n132\n133\n135\n135\n137\n138\n141\n144\n144\n\n147\n147\n148\n150\n153\n\n\fviii\n\nCONTENTS\n\n8.4.1 Breast Cancer\n8.4.2 Cervical Cancer\n8.4.3 Colorectal Cancer\n8.4.4 Lung Cancer\n8.4.5 Stomach Cancer\n\n8.5 Conclusions\n\n9 Analyzing Spatial Data Using Skew-Gaussian Processes\n\n9.1 Introduction\n9.2 Skew-Gaussian Processes\n9.2.1 The Model\n9.2.2 Bayesian Analysis\n9.2.3 Computational Strategy\n\n9.3 Real Data Illustration: Spatial Potential Data Prediction\n9.4 Discussion\n\n10 Accounting for Absorption Lines in Images Obtained with\n\nthe Chandra X-ray Observatory\n10.1 Statistical Challenges of the Chandra X-ray Observatory\n10.2 Modeling the Image\n\n10.2.1 Model-Based Spatial Analysis\n10.2.2 Model-Based Spectral Analysis\n\n10.3 Absorption Lines\n\n10.3.1 Scientiﬁc Background\n10.3.2 Statistical Models\n10.3.3 Model Fitting\n10.3.4 A Simulation-Based Example\n10.4 Spectral Models with Absorption Lines\n\n10.4.1 Combining Models and Algorithms\n10.4.2 An Example\n\n10.5 Discussion\n\n11 Spatial Modelling of Count Data: A Case Study in Mod-\nelling Breeding Bird Survey Data on Large Spatial Do-\nmains\n11.1 Introduction\n11.2 The Poisson Random Eﬀects Model\n\n11.2.1 Spectral Formulation\n11.2.2 Model Implementation and Prediction\nSelected Full-Conditional Distributions\nPrediction\nImplementation\n\n11.3 Results\n11.4 Conclusion\n\n154",
    "chunk_order_index": 1,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-a1056b4862c03eee0af49ed73cf774e8": {
    "tokens": 1200,
    "content": ".4.2 An Example\n\n10.5 Discussion\n\n11 Spatial Modelling of Count Data: A Case Study in Mod-\nelling Breeding Bird Survey Data on Large Spatial Do-\nmains\n11.1 Introduction\n11.2 The Poisson Random Eﬀects Model\n\n11.2.1 Spectral Formulation\n11.2.2 Model Implementation and Prediction\nSelected Full-Conditional Distributions\nPrediction\nImplementation\n\n11.3 Results\n11.4 Conclusion\n\n154\n155\n155\n159\n159\n159\n\n163\n163\n164\n165\n166\n167\n168\n171\n\n175\n175\n179\n179\n183\n184\n184\n185\n188\n190\n192\n192\n195\n196\n\n199\n199\n200\n202\n204\n205\n206\n206\n206\n207\n\n\fCONTENTS\n\nIII Spatio-temporal cluster modelling\n\n12 Modelling Strategies for Spatial-Temporal Data\n\n12.1 Introduction\n12.2 Modelling Strategy\n12.3 D-D (Drift-Drift) Models\n12.4 D-C (Drift-Correlation) Models\n12.5 C-C (Correlation-Correlation) Models\n12.6 A Uniﬁed Analysis on the Circle\n12.7 Discussion\n\n13 Spatio-Temporal Partition Modelling: An Example from\n\nNeurophysiology\n13.1 Introduction\n13.2 The Neurophysiological Experiment\n13.3 The Linear Inverse Solution\n13.4 The Mixture Model\n\n13.4.1 Initial Preparation of the Data\n13.4.2 Formulation of the Mixture Model\n\n13.5 Classiﬁcation of the Inverse Solution\n13.6 Discussion\n\n14 Spatio-Temporal Cluster Modelling of Small Area Health\n\nData\n14.1 Introduction\n14.2 Basic Cluster Modelling approaches\n14.2.1 Case Event Data Models\n\nInter-Event versus Hidden Process Modelling\n\n14.2.2 Small Area Count Data Models\n14.2.3 Spatio-Temporal Extensions to Cluster Models\n\n14.3 A Spatio-Temporal Hidden Process Model\n14.4 Model Development\n\n14.4.1 Estimation of g(s,t)\n\nThe Prior Distribution for Cluster Centres\nChoice of Cluster Distribution Function\nOther Prior Distributions and the Posterior Distri-\n\nbution\n\n14.4.2 Region Counts\n\nIntegrated Intensity\n\n14.5 The Posterior Sampling Algorithm\n\n14.5.1 Goodness-of-Fit Measures for the Model\n\n14.6 Data Example: Scottish Birth Abnormalities\n\n14.6.1 Introduction\n14.6.2 Exploratory Analysis\n\nix\n\n211\n\n213\n213\n214\n215\n220\n222\n224\n225\n\n227\n227\n227\n228\n229\n229\n230\n232\n234\n\n235\n235\n235\n236\n236\n239\n239\n240\n240\n243\n244\n245\n\n245\n246\n247\n248\n249\n249\n249\n250\n\n\fx\n\nCONTENTS\n\n14.6.3 Model Fitting Results\n\n14.7 Discussion\n\nReferences\n\nIndex\n\nAuthor Index\n\n252\n256\n\n259\n\n277\n\n281\n\n\fList of Contributors\n\nAdrian Baddeley\n\nUniversity of Western Australia\n\nDankmar B¨ohning\n\nFree University of Berlin\n\nSimon D. Byers\n\nAT&T Labs, New Jersey\n\nAllan B. Clark\n\nUniversity of Aberdeen\n\nMurray K. Clayton\n\nUniversity of Wisconsin, Madison\n\nDavid G.T. Denison\n\nImperial College, London\n\nJos´e Tom´e A.S. Ferreira\n\nImperial College, London\n\nJ¨urgen Gallinat\n\nFree University of Berlin\n\nRonald B. Gangnon\n\nUniversity of Wisconsin, Madison\n\nFred Godtliebsen\n\nUniversity of Tromsø\n\nChristopher M. Hans\n\nDuke University\n\nChristopher C. Holmes\n\nImperial College, London\n\nJohn T. Kent\n\nUniversity of Leeds\n\nHyoung Moon Kim\n\nTexas A&M University\n\nAndrew B. Lawson\n\nUniversity of Aberdeen\n\nMarc Loizeaux\n\nFlorida State University, Tallahassee\n\nIan W. McKeague\n\nFlorida State University, Tallahassee\n\n\fxii\n\nLIST OF CONTRIBUTORS\n\nBani K. Mallick\n\nTexas A&M University\n\nKanti V. Mardia\n\nUniversity of Leeds\n\nJ. Steve Marron\n\nUniversity of North Carolina, Chapel Hill\n\nJesper Møller\n\nAalborg University\n\nStephen M. Pizer\n\nUniversity of North Carolina, Chapel Hill\n\nAdrian E. Raftery\n\nUniversity of Washington, Seattle\n\nPeter Schlattmann\n\nFree University of Berlin\n\nDavid A. van Dyk\n\nHarvard University\n\nMarie-Colette van Lieshout\n\nCWI, Amsterdam\n\nRasmus P. Waagepetersen\n\nAalborg University\n\nChristopher K. Wikle\n\nUniversity of Missouri–Columbia\n\n\fPreface\n\nThe development of statistical methodology for the analysis of spatial data\nhas seen considerable advances since the publication of the seminal work\nof Cressie (1993). In particular, the development of fast computational\nalgorithms for sampling of complex Bayesian models (most notably Markov\nchain Monte Carlo algorithms) has allowed a wide range of problems to\nbe addressed which hitherto could not be directly analysed. Many spatial\nproblems can be considered within the paradigm of hierarchical Bayesian\nmodelling and so the emphasis within this volume will lie within that area.\nThe aim of this volume is not to present a general review of spatial statis-\ntical modelling but rather to focus on the area of spatial cluster modelling.\nHence the theme of this work is the highlighting of the diverse approaches\nto the deﬁnition of clusters and clustering in space (and its adjunct space-\ntime), and",
    "chunk_order_index": 2,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-9327867a94aab237a41308f659bef36e": {
    "tokens": 1200,
    "content": "directly analysed. Many spatial\nproblems can be considered within the paradigm of hierarchical Bayesian\nmodelling and so the emphasis within this volume will lie within that area.\nThe aim of this volume is not to present a general review of spatial statis-\ntical modelling but rather to focus on the area of spatial cluster modelling.\nHence the theme of this work is the highlighting of the diverse approaches\nto the deﬁnition of clusters and clustering in space (and its adjunct space-\ntime), and to present state-of-the-art coverage of the diverse modelling\napproaches which are currently available. In Chapter 1 we provide a brief\nhistorical introduction to the subject area and, in particular, compare con-\nventional and spatial clustering. In addition this chapter introduces the\nnotation and diﬀerent areas of study explored. After this initial chapter\nthe volume is split into 3 parts, each relating to a speciﬁc area of cluster\nmodelling. Part I deals with point and object process modelling, Part II\ninvolves spatial process modelling, while Part III contains papers relating\nto spatio-temporal models.\n\nOne of the features of modelling spatial data is the need to use fast\ncomputational algorithms to be able to evaluate the complex posterior dis-\ntributions or likelihood surfaces which arise in spatial applications. The\n1980s saw the development of Markov chain Monte Carlo algorithms based\non the Gibbs and Metropolis-Hastings samplers, and witnessed rapid de-\nvelopment of models for complex spatial problems. Not only could existing\nmodels be sampled from but newer more sophisticated models could also\nbe developed and applied. Often these models are of a hierarchical form\nso this naturally leads to the Bayesian paradigm being of importance in a\ngreat deal of the work.\n\nAs the potential ﬁelds of application for spatial methods are so wide\nwe cannot hope to cover all of them. Nevertheless the chapters here do\nmake reference to data in astrophysics (Chapter 10), spatial epidemiology\n(Chapters 5,7,8,14), ecology (Chapters 4,11), imaging (Chapter 13), ge-\n\n\fxiv\n\nPREFACE\n\nology and the geosciences (Chapters 6,4,7,9,12). In addition, the volume\nprovides a useful insight into the current issues and methodology used for\nspatial cluster modelling. We have speciﬁcally included the burgeoning area\nof spatio-temporal modelling as an important extension to standard spatial\ndata analysis and Chapters 12,13,14 speciﬁcally deal with this topic.\n\nFinally we would like to thank all the contributors for their timely and\nthoughtful articles. In addition, we acknowledge the help of the staﬀ at\nCRC Press, in particular Kirsty Stroud, Jasmin Naim and Helena Redshaw\nfor their continued support and encouragement in the production of this\nvolume.\n\n\fCHAPTER 1\n\nSpatial Cluster Modelling: An\nOverview\n\nA.B. Lawson D.G.T. Denison\n\n1.1 Introduction\n\nWhen analysing spatial data one is often interested in detecting deviations\nfrom the expected. For instance, we may be interested in the answers to\nquestions like, “Is there an unusual aggregation of leukemia cases around a\nnuclear power station ?” or, “Where is it likely that the air pollution level\nis above the legally allowed limit ?”. In both cases the focus is on ﬁnding\nregions in (usually two-dimensional) space in which higher than expected\ncounts, or readings, are observed. We shall call such areas clusters and\ndetermining their nature forms the focus of this work.\n\nThis volume brings together a collection of papers on the topic of spatial\ncluster modelling and gives descriptions of various approaches which begin\nto solve the problem of detecting clusters. The papers are statistical in\nnature but draw on results in other ﬁelds as diverse as astrophysics, medical\nimaging, ecology and environmental engineering.\n\nTwo examples of the sort of spatial processes that we shall consider here\nare displayed in Figs. 1.1-1.2. Fig. 1.1 is an example of a point process,\nwhere each dot is an “event” (in this case the occurrence of a cancer).\nHere it is of interest to determine whether the cases are more aggregated,\nor clustered, than expected and whether the clustering relates to the loca-\ntions of any possible pollution sources. To assess this a background control\ndisease map (which is not shown) is often used to represent the expected\nvariation in the distribution of cases; this is often a function of the relative\npopulation density.\n\nFig. 1.2 is an example of a dataset that consists of observations of an\nunderlying spatial process at a number of locations. The usual aim of an\nanalysis of this type of data is to determine the value of the spatial process\nat all the locations in the domain of interest, assuming that each mea-\nsurement is only observed in the presence of a random error component.\nHowever, we may also be interested in determining areas where the pro-\ncess is above some predeﬁned limit or even, in some sense, above average.\n\n\f2\n\n4\nx 10\n\n4.3\n\n4.28\n\n4.26\n\n4.24\n\n4.22\n\n4.2\n\n4.18\n\n4.16\n\n4.14\n\nSPATIAL CLUSTER MODELLING: AN OVERVIEW\n\nlarynx cancer case locations\n\n0\n0\n2\n\n0\n5\n1\n\nd\nr\no\no\nc\n-\ny\n\n0\n0\n1\n\n0\n5\n\n0\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n•\n• •\n•\n••\n•\n• •\n••\n• •\n••\n• •",
    "chunk_order_index": 3,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-501ac27febe74b9ce625334004fe2be0": {
    "tokens": 1200,
    "content": "4.18\n\n4.16\n\n4.14\n\nSPATIAL CLUSTER MODELLING: AN OVERVIEW\n\nlarynx cancer case locations\n\n0\n0\n2\n\n0\n5\n1\n\nd\nr\no\no\nc\n-\ny\n\n0\n0\n1\n\n0\n5\n\n0\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n•\n• •\n•\n••\n•\n• •\n••\n• •\n••\n• •\n•\n••\n•\n• •\n••\n•\n•\n• •\n••\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n••\n• •\n\n•\n\n•\n\n•\n\n•\n\n• •\n•\n•\n••\n• •\n•\n•\n••\n•\n••\n••\n••\n• •\n••\n• •\n••\n• •\n•\n•\n••\n•\n•\n••\n••\n•\n••\n••\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n••\n• •\n•\n••\n\n•\n••\n•\n• •\n••\n• •\n•\n•\n••\n•\n•\n• •\n••\n• •\n•\n•\n••\n•\n• •\n••\n••\n••\n••\n••\n• •\n•\n••\n• •\n••\n• •\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n••\n•\n•\n\n••\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n• •\n••\n• •\n••\n• •\n••\n•\n• •\n••\n• •\n••\n••\n•\n••\n•\n•\n••\n•\n••\n••\n••\n••\n••\n••\n•\n•\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n••\n•\n• •\n••\n•\n• •\n••\n• •\n••\n•\n••\n••\n••\n••\n•\n•\n• •\n•\n••\n•\n••\n•\n••\n•\n•\n••\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n• •\n••\n• •\n••\n• •\n••\n• •\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n• •\n•\n••\n• •\n••\n•\n••\n••\n•\n• •\n••\n•\n• •\n••\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n• •\n•\n••\n\n•\n•\n\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n\n••\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n80\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n100\n\n3.62\n4\nx 10\n\n0\n\n20\n\n40\n\n60\n\nx-coord\n\n4.12\n\n3.48\n\n3.5\n\n3.52\n\n3.54\n\n3.56\n\n3.58\n\n3.6\n\nFigure 1.1 An example of a point pro-\ncess: The Larynx cancer case event\nmap (Diggle 1990) relating to cases in\nLancashire, UK from 1974 to 1983.\n\nFigure 1.2 An example of observations\nof a spatial process: The Piazza Road\ndata (Higdon et al. 1999). Each dot\nrepresents a location where a measure-\nment of the dioxin concentration in an\narea around the Piazza Road is taken.\nThe size of the dots gives an indication\nof\nthe observed measurements, with\nlarger dots representing higher concen-\ntrations.\n\nSpatio-temporal data will also be looked at in this volume. In these ex-\namples either measurements or point processes are observed over time and\nsimilar questions arise but now clusters can occur in space, in time, or even\nin space and time jointly.\n\nThe analysis of spatial clustering has had a varied history with develop-\nments often resulting from particular applications, and so these develop-\nments have related to varying interest over time in diﬀerent applications.\nFor example, much work in the 1960s and 1970s on clustering developed\nfrom ecology applications (e.g. Diggle 1983, Ripley 1981), whereas an in-\ncreased interest in image analysis in the 1980s led to associated advances\nin image segmentation and object recognition (e.g. Besag et al. 1991). In-\ncreased public and scientiﬁc interest in environmental hazards and health\nin the late 1980s and 1990s, has led to increased emphasis on cluster de-\ntection in small area health studies (Lawson et al. 1999, Elliott et al. 1999,\nLawson 2001). The context of this historical development in relation to\nmethodological progress is discussed more fully in the next section.\n\n\fHISTORICAL DEVELOPMENT\n\n1.2 Historical Development\n\n3\n\nThe analysis of clustering has a long history in statistical science. In one\ndimension the analysis of aggregation of data around a preferred",
    "chunk_order_index": 4,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-6dde638b5bad90c0fb7d38dc0bf8b990": {
    "tokens": 1200,
    "content": "led to increased emphasis on cluster de-\ntection in small area health studies (Lawson et al. 1999, Elliott et al. 1999,\nLawson 2001). The context of this historical development in relation to\nmethodological progress is discussed more fully in the next section.\n\n\fHISTORICAL DEVELOPMENT\n\n1.2 Historical Development\n\n3\n\nThe analysis of clustering has a long history in statistical science. In one\ndimension the analysis of aggregation of data around a preferred location\nis at the heart of much statistical work, whether the focus is on the mean\ntendency of the aggregation of data or on its spread or variance. In addition\nin cluster studies the location of the maximum aggregation may also be of\ninterest (modal property). In two dimensions, the natural extension of these\nideas is to a two-dimensional aggregation, perhaps around a single point.\nIn this case the centre of the aggregation may be deﬁned either by mean\nor modal properties while the variance or spread of the aggregation can be\ndeﬁned around the putative centre which is now a two-dimensional location.\nIn the case of spatial data these quantities have obvious interpretations as\ncluster centre location and cluster spread.\n\nIn the spatial domain, it is possible to view a clustered pattern in diﬀerent\nways depending on the focus of the analysis. First, it may be possible\nto conceive of the pattern as the realisation of a random process which\nproduces aggregations as a result of the global structure of the process,\nwhereby a small number of parameters control the scale and frequency of\naggregations but the deﬁned process does not parameterise the locations of\nthe aggregations. This is akin to the geostatistical view of random processes,\nwhere the intensity or local density of events is deﬁned by, for example, a\nspatial Gaussian process. The peaks of this process would correspond with\nlocal aggregations, but no parameterisation of the locations is made. Recent\nexamples of this approach can be found in Cressie (1993) and Diggle et al.\n(1998). Essentially, this approach regards the aggregations as produced\nby random eﬀects which are governed by global model parameters, i.e. the\ndegree of aggregation and spread of the aggregations would be controlled by\na small number of global parameters. This form of random eﬀect modelling\nis at the heart of much hierarchical Bayesian modelling in this context,\nand in the literature of spatial applications the term clustering or cluster\nmodelling is used to refer to such random eﬀect modelling. An example\nfrom small area health studies is Clayton and Bernardinelli (1992).\n\nThe second approach to the modelling of clusters is to include within the\nmodelled process speciﬁc elements which relate to cluster location and how\nthese locations relate to the surrounding data. Much of the early work in\nstochastic geometry relating to point processes examined clustering of point\nprocesses and models such as the Neyman-Scott and Cox cluster processes.\nThe fundamental feature of these processes was the deﬁnition of a set of\ncluster centres around which the oﬀspring (data) lie. The term oﬀspring\ncomes from the idea that the clustering could arise from a multigenerational\nprocess. The variation in the local aggregation of data is thought to be\nsummarised by the local density of events around the cluster centre set. In\nthe case of a Neyman-Scott or Poisson cluster process the local density is\n\n\f4\n\nSPATIAL CLUSTER MODELLING: AN OVERVIEW\n\na function of distance from the cluster centre set within an inﬁnite plane.\nThe appearance of such clustered event sets is controlled by the location\nof centres and the spread of the distribution around these centres.\n\nThe dichotomy between these two approaches leads from the diﬀerent\nfocus and objectives of the analyses. While both approaches use global\nparameters to describe the local variation in space, they are distinguished\nby their speciﬁcity with regard to cluster location. Within this volume a\nrange of approaches to clustering is described including examples from both\ntypes of analysis and some where the distinctions are more blurred.\n\nMost of the earliest work in clustering related to the development of\ntheoretical models for clusters and cluster processes, with limited applica-\ntion of the models to real data. In addition, the earliest theoretical work\nconcerned one-dimensional processes. Early reference sources for such mod-\nels and their properties are Snyder (1975) and Cox and Isham (1980). In\nthe 1970s, increased attention was paid to the application of cluster mod-\nels to ecological and biological examples. In these developments, summary\nstatistics were developed which would allow the assessment of ﬁrst second\norder properties of realisations of point processes. The Ripley-K function,\nnearest neighbour and inter-event statistics are all examples of these devel-\nopments (see Diggle 1983). Such methods have been further developed in\napplications to processes of objects other than points (e.g. Baddeley 1999).\nDuring the 1980s, developments in the analysis of pixellated images led\nto the application of Markov random ﬁeld (MRF) models. These models\nwere intended for segmentation or noise reduction in images. These models\nwere often characterised by the inclusion of a neighbourhood eﬀect, often\nincluded within a prior distribution for the image. Bayesian hierarchical\nmodelling of images was a natural development as prior beliefs about the\nspatial structure of the image could be incorporated within a spatial prior\ndistribution, while measurement error could be included within the likeli-\nhood.\n\nAssociated with these developments, were the increased use of stochastic\nalgorithms for maximising or sampling posterior distributions of image fea",
    "chunk_order_index": 5,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-7bead3edf8c1d66d6a0166f2a05a423e": {
    "tokens": 1200,
    "content": ". These models\nwere often characterised by the inclusion of a neighbourhood eﬀect, often\nincluded within a prior distribution for the image. Bayesian hierarchical\nmodelling of images was a natural development as prior beliefs about the\nspatial structure of the image could be incorporated within a spatial prior\ndistribution, while measurement error could be included within the likeli-\nhood.\n\nAssociated with these developments, were the increased use of stochastic\nalgorithms for maximising or sampling posterior distributions of image fea-\ntures – in particular, the development of Gibbs and Metropolis-Hastings\nsamplers (e.g. Gilks et al. 1996) and simulated annealing for maximisa-\ntion (Ripley 1988). These developments regard aggregation as described by\nnon-speciﬁc neighbourhood structures with associated global parameters.\nAs such they have similarities to geostatistical models where continuous\nvariation is modelled by predeﬁned covariance structures. Essentially these\nare random eﬀect models.\n\nAt the other end of the spectrum during the 1980s and 1990s, another\nform of image modelling developed which emphasised the speciﬁc locational\nfeatures of the image. This approach can be described as object recognition\nor object modelling. In this collection of approaches the locational charac-\nteristics of the image features are speciﬁcally modelled (e.g. the landmark\n\n\fHISTORICAL DEVELOPMENT\n\n5\n\nmethods of Dryden and Mardia 1997). Object process modelling is one area\nwhich has seen considerable development. Here a noisy image is assumed\nto have an underlying distribution of objects. The aim is to reconstruct\nthe noise-free object set. Often for simplicity the objects are assumed to\nbe simple geometric shapes and have associated with them a speciﬁc point\nwhich ﬁxes their location. Simple processes could consist of lines, circles or\neven tessellations and triangulations.\n\nThe recovery of such processes from images has seen the development\nand application of sophisticated Markov Chain Monte Carlo (MCMC)\n(Baddeley and van Lieshout 1993, Cressie and Lawson 2000) culminat-\ning in the use of special birth-death MCMC algorithms (Geyer and Møller\n1994, Stephens 2000).\n\nThe above two approaches to image analysis have many variants which\nconsist of either components of random eﬀect and object recognition tasks.\nFor example some models attempt to group or classify areas of images, and\nthese partition models can be thought of as cluster models with locational\ncomponents. A review of these diﬀerent approaches is found in Hurn et al.\n(2001).\n\nWhile image analysis has seen the greatest development of novel method-\nologies, other application areas have also seen considerable progress in re-\ncent years, particularly in the application of Bayesian hierarchical models.\nSuch areas as climatology, geosciences, environmetrics, genetics and spatial\nepidemiology have seen considerable advances in the modelling of clustered\ndata. Within climatology and geo-/environmental sciences the development\nof geostatistical methods related to kriging and Bayesian hierarchical mod-\nels for random eﬀects has been marked (e.g. Wikle et al. 1998, Mardia et\nal. 1998).\n\nIn the last decade a considerable body of work has developed with a\nfocus on small area health data, mainly in the area of spatial epidemiology.\nThe study of disease clustering has a considerable history and many ap-\nproaches have been advanced ranging from hypothesis testing for clusters\nto more recently non-speciﬁc (random eﬀect) and speciﬁc cluster modelling\n(for a review see Chapter 6 of Lawson 2001). Model-based approaches to\nclustering of diseases has developed both in terms of random eﬀect mod-\nelling of clustering (Clayton and Bernardinelli 1992, Breslow and Clayton\n1993, Bernardinelli et al. 1995, Waller et al. 1997a, Zia et al. 1997, Knorr-\nHeld and Besag 1998, Langford et al. 1999, Diggle et al. 1998, Ghosh et\nal. 1998, Best et al. 1998, Byers and Besag 2000, Knorr-Held 2000, Sun et\nal. 2000, Best and Wakeﬁeld 1999, Lawson and Clark 2001) and, to a lesser\nextent, in speciﬁc modelling of clusters and their locations (Lawson and\nClark 1999a, Lawson and Clark 1999b, Gangnon and Clayton 2000). Vari-\nants of these two extremes of random eﬀect and random object modelling\nhave been proposed. For example, partition models which group small ar-\neas into constant risk classes have been suggested as a form of cluster\n\n\f6\n\nSPATIAL CLUSTER MODELLING: AN OVERVIEW\n\nmodelling (Schlattmann and B¨ohning 1993, Knorr-Held and Rasser 2000).\nOn the other hand, in disease mapping it may be beneﬁcial to assume little\nprior information about parametric forms of cluster, and so nonparametric\napproaches may also be useful (e.g. Kelsall and Diggle 1995a, Kelsall and\nDiggle 1998).\n\nIn what follows we reﬂect this spectrum of approaches between random\neﬀect and random object modelling approaches by presenting a review of\nthe range of approaches currently advocated for cluster modelling. We also\ninclude nonparametric approaches which provide a weakly model-based\nalternative to the parameterised approaches discussed",
    "chunk_order_index": 6,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-e475576ca3608f0e74d69c47f7132f96": {
    "tokens": 1200,
    "content": "so nonparametric\napproaches may also be useful (e.g. Kelsall and Diggle 1995a, Kelsall and\nDiggle 1998).\n\nIn what follows we reﬂect this spectrum of approaches between random\neﬀect and random object modelling approaches by presenting a review of\nthe range of approaches currently advocated for cluster modelling. We also\ninclude nonparametric approaches which provide a weakly model-based\nalternative to the parameterised approaches discussed above.\n\n1.2.1 Conventional Clustering\n\nCluster analysis in conventional non-spatial statistical applications has de-\nveloped in parallel with its spatial counterpart but has a longer pedigree. In\nthe following, we seek to draw parallels with conventional cluster analysis\nand to show how spatial approaches closely relate to a subset of non-spatial\nclustering methods. A recent review of the ﬁeld of non-spatial cluster anal-\nysis is given in Everitt et al. (2001). The basis of cluster analysis is the\nnotion of classiﬁcation of objects into categories based on a measure of\nsimilarity. Often classiﬁcation is a task which allows the diﬀerentiation of\nsub-populations at an early stage of a subject’s development, and indeed\ncluster analysis is often applied to yield information about groupings or\naggregations in the data at an exploratory stage in an analysis.\n\nBefore considering the basic parametric forms of clustering it should be\nnoted that exploratory clustering analysis of multi-dimensional data is often\nperformed by using nonparametric density estimation or related techniques\n(see the relevant chapters of Everitt et al. 2001, Duda et al. 2001). These\nmethods are also applicable where the domain is spatial or spatio-temporal.\nAn application of these methods is discussed here in Chapter 2, and exam-\nples of their use in epidemiological applications are given in Bithell (1990),\nKelsall and Diggle (1995b).\n\nBayesian decision theory can be applied to simple classiﬁcation problems\nwhere measurements on a range of variables are used to classify data into\nparticular groups. For example, in medical diagnoses a range of physical and\nbiomedical measurements is made on patients and these are used to classify\nthe patient (in the simple binary-state model) into “having a disease”, or\nnot. Often in this case a simple belief network and naive Bayesian classiﬁer\ncan be applied (Lucas 2001). More complex Bayesian approaches can be\nused for multi-state models and Bayesian discrimination can approximate\nthe behaviour of neural network classiﬁcation algorithms. Many of these\nalgorithms use information about the labelling (or classiﬁcation) of data\nitems, using some training data, i.e. in the medical diagnosis problem the\n\n\fHISTORICAL DEVELOPMENT\n\n7\n\ndistributions of measurements/symptoms for a particular disease are known\nfrom historical data and these can be used to train the classiﬁer.\n\nIn clustering studies the aim is usually to examine data which do not\ncontain labels and it is the focus of the analysis to ﬁnd groupings, or clus-\nters, in the data. This is a form of unsupervised learning, where no training\ndata are used (see Chapter 10 of Duda et al. 2001). In the case of cluster-\ning, the focus is to assign labels to the data, which represent the clusters\nin the data. Often the number of clusters will be unknown as well as the\nlabelling. In addition, it may be important to estimate some characteris-\ntic feature of the cluster. For example, it may be hypothesised that each\ncluster has a centre around which the data aggregate. Hence the emphasis\nin classiﬁcation is to recover the labels of data, whereas the object of clus-\ntering is often to assess the number and location and/or scale of cluster\nfeatures. An example would be the estimation of the number and location\nof galaxies in an astrophysical example. The labelling of stars with galaxy\nnumber could be a secondary task. However, in many forms of analysis the\nlabelling and estimation of cluster features are related and can be included\nwithin iterative algorithms for cluster feature extraction. For example the\nconditional distribution of galaxy number and location could be speciﬁed\nin relation to a given labelling of stars, and in turn the labelling of stars\ncould be conditionally related to the number and location of galaxies.\n\nUsually clustering algorithms are based on a metric which describes how\nclosely related respective data items are to each other, or to unobserved\ncluster features. These metrics can be distance-based or take other forms\n(see Chapter 3 of Everitt et al. 2001). In addition to this, such algorithms\nuse a clustering criterion to establish the appropriate grouping or labelling\nof the data.\n\nA fundamental form of model which can be used for cluster problems\nis that of the mixture distribution. The classical cluster mixture assumes\nthat the data come from a number of clusters, m, where the prior proba-\nbility of each cluster is known along with the forms of cluster-conditional\nprobability densities. However, the values of the cluster feature vector and\nthe total number of clusters m are unknown. We deﬁne a data vector by\nx, the feature vector by θ = (θ1, . . . , θm), the prior cluster probability as\np(ωj) (j = 1, . . . , m) and the jth cluster-conditional probability densities\nas p(x|ωj, θj). Then the probability density function of the data vector is\n\np(x|θ) =\n\nm(cid:1)\n\nj=1\n\np(x",
    "chunk_order_index": 7,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-0c0042e0b91e94267c2f638de84d1565": {
    "tokens": 1200,
    "content": "We deﬁne a data vector by\nx, the feature vector by θ = (θ1, . . . , θm), the prior cluster probability as\np(ωj) (j = 1, . . . , m) and the jth cluster-conditional probability densities\nas p(x|ωj, θj). Then the probability density function of the data vector is\n\np(x|θ) =\n\nm(cid:1)\n\nj=1\n\np(x|ωj, θj)p(ωj).\n\n(1.1)\n\nUsually the focus is on estimation of the feature vector θ. For example, these\ncould be means and variances of Gaussian densities, or could be other rel-\nevant feature parameters. If classiﬁcation is the goal, then once θ is known\nthe mixture can be decomposed into its components and a maximum a\n\n\f8\n\nSPATIAL CLUSTER MODELLING: AN OVERVIEW\n\nposteriori classiﬁer could be used. If the component densities are Gaus-\nsian then it is possible for mixture components to overlap and hence the\nclustering criterion does not restrict the cluster form to be disjoint. Other\nmixture forms produce disjoint non-overlapping partitions of the space.\n\nThe above brief discussion focuses on what is, in computer science ter-\nminology, a ‘ﬂat’ classiﬁcation: that is, the clusters exist within one level\nof organisation only. Flat classiﬁcations could be disjoint (such as discrim-\ninant functions) or overlapping (such as mixture densities). However it is\nalso possible that multiple levels of clustering exist within the data, and to\ndeal with this situation hierarchical clustering algorithms have also been\ndeveloped. These algorithms have many natural applications in the sciences\nas hierarchical classes or groupings are commonly found. Their basis lies\nin the the use of threshold values for clustering of data based on some\nform of distance metric. By changing the distance threshold the cluster\nmembership at the new level in the hierarchy is deﬁned.\n\nIn the above discussion the issue of unknown numbers of clusters has not\nbeen addressed. In this situation, both the cluster features and the number\nof clusters are unknown. With little information to inform the problem it\nis diﬃcult to proceed without recourse to prior assumptions concerning the\nnature of the components or clusters. One approach is to apply algorithms\nfor a range of c values and examine a comparison criterion (a type of proﬁle\ninference). Alternatively, the whole space of the joint distribution of number\nand cluster feature must be examined.\n\nIn the next section we compare and contrast the forms of spatial cluster-\ning which have been developed and attempt to relate these to conventional\nnon-spatial approaches.\n\n1.2.2 Spatial Clustering\n\nBasic random eﬀect modelling in spatial applications considers groupings\nas random disturbances described by model factors. These factors are often\ntreated as random eﬀects and modelled via prior distributions. More specif-\nically, let us deﬁne an arbitrary spatial location as x and a spatial process\nat that location as z(x). The observed process at x, y say, consists of z(x)\nand some form of uncorrelated measurement error ε(x). For example, an\nadditive form is sometimes assumed so that\n\ny = z(x) + ε(x).\nThe spatial process z(x) can include long range eﬀects (e.g. spatial trend)\nand short range covariance eﬀects. This model is that underlying geo-\nstatistical modelling of spatial processes, and kriging is a method which\nyields point estimates of values of z(x) at various locations (e.g. Chapter\n3, Cressie 1993). Often a zero-mean Gaussian process is assumed to un-\nderlie the z(x) process. In space-time this model could be simply extended\n\n\fHISTORICAL DEVELOPMENT\n\n9\n\nto\n\ny = z(x, t) + ε(x, t)\n\nwhere t denotes a time point.\n\nIn these models concentrations of values of the random process are rep-\nresented by peaks in the resulting ﬁtted surface. These peaks could be\nregarded as containing location information about elevated values in the\ndata. Of course these are peaks of a process and not concentrations of\ndata locations (as in conventional clustering). However, there is a close\ncorrespondence between these ideas. For example if the density or inten-\nsity of points or objects on a map were to be modelled then peaks in the\ndensity/intensity surface would hold information concerning clustering and\ncluster locations. In fact the treatment of the intensity of an object process\nas a random ﬁeld is one fruitful approach to modelling clustering of objects\nin the spatial or spatio-temporal domain. For example, in spatial epidemi-\nology problems, it is possible to model peaks in relative disease risk surfaces\nand these peaks correspond to local aggregations of cases of disease.\n\nRandom eﬀect models in imaging have a structure similar to geosta-\ntistical models except they usually use simpliﬁed covariance structures to\ndescribe spatial correlation (i.e. neighbourhood eﬀects).\n\nAlthough it is possible to attempt to adapt random eﬀect models to pro-\nvide information about cluster related features, basic random eﬀect models\nare mainly designed to provide smooth reconstructions of surfaces. As ag-\ngregations or peaks in density are by nature not smooth, these models may\nnot be successful in describing clustering. However, the residual from a\nsmoothed surface estimate could contain cluster information.\n\nIn the spatial domain the closest correspondence with conventional clus-\nter analysis can be found in the analysis of point or object processes and\nderived processes such as counting measures in disjoint",
    "chunk_order_index": 8,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-028c7296c93820c6e153748125327afd": {
    "tokens": 1200,
    "content": "related features, basic random eﬀect models\nare mainly designed to provide smooth reconstructions of surfaces. As ag-\ngregations or peaks in density are by nature not smooth, these models may\nnot be successful in describing clustering. However, the residual from a\nsmoothed surface estimate could contain cluster information.\n\nIn the spatial domain the closest correspondence with conventional clus-\nter analysis can be found in the analysis of point or object processes and\nderived processes such as counting measures in disjoint regions. Deﬁne a\nspatial study window as T and within this window a realisation of a spatial\npoint process is observed. Denote the n points of this realisation as {xi}\ni = 1, ..., n. It is believed that the spatial point process is clustered. At this\npoint, conventional clustering methods could be used in the reconstruction\nof the clusters within the pattern, e.g. simple Bayesian classiﬁers could be\nused to make a ﬂat classiﬁcation or more sophisticated mixture models\ncould be applied.\n\nAt this point a diﬀerence arises in the approaches depending on whether\nthe nature of the underlying spatial point process is to be taken into con-\nsideration. Probability models for clustering can be speciﬁed in the form\nof mixtures which do not directly use point process properties. For ex-\nample, we can assume that the c components of a mixture have densities\nfj(xi|θj) and, in a likelihood formulation, two forms can be examined: a)\n\n\f10\n\nSPATIAL CLUSTER MODELLING: AN OVERVIEW\n\na classiﬁcation likelihood\n\nLclass =\n\nn(cid:2)\n\nfγi(xi|θγi)\n\ni=1\nwhere the γi are discrete label values: γi = j if xi belongs to the jth\ncomponent (cluster), and b) a mixture likelihood\n\nLm =\n\nn(cid:2)\n\nm(cid:1)\n\ni=1\n\nj=1\n\npjfγi(xi|θj)\n\nwhere pj is the probability that an observation belongs to the jth com-\nponent. Fraley and Raftery (1998) (see also Banﬁeld and Raftery 1993)\nuse this approach as a basis for a variety of clustering algorithms. Usually\nthe form of the component densities is multivariate normal. The covariance\nstructure of the components determines the form of the clusters likely to\nbe found in these models. A variety of algorithms have been proposed for\nthe estimation of the parameters in these models. The EM algorithm can\nbe used, and is often used when incomplete data are available. In clus-\ntering, the complete data would consist of both the {xi} set and a set of\nlabels associating the data to clusters. Often these labels are unknown and\nhence the {xi} themselves constitute the incomplete data. A complete data\nlikelihood is then formed and the EM algorithm iterates between estima-\ntion of the labels and maximisation of the complete data likelihood. A full\nBayesian approach to mixture models can be adopted. Binder (1978) out-\nlined many of the issues in this approach – see also Richardson and Green\n(1997). While these mixture modelling approaches can be and are applied\nto spatial problems, the basic form of the mixture is quite general and these\nmodels are closest to those of conventional cluster analysis. They do not\ndirectly employ spatial stochastic process models for the distribution of the\nevents in the clustered pattern.\n\nModels for spatial clustering can also be based on the stochastic process\nassumed to underlie the spatial distribution of the data. For example, if\nthe {xi} are a realisation of a spatial point process, then it is possible\nto include features of the process in the model formulation. In the case\nof clustered point processes a simple model might be the Poisson cluster\nprocess, where the points are thought to cluster around unobserved cluster\ncentres. In this approach the cluster features are the centre locations and\na variance parameter determining the cluster spread. This approach is also\nbased on a mixture of cluster components where the centres form a hidden\npoint process. In this approach the approximate ﬁrst order intensity of the\nprocess is deﬁned (conditional on the centre process) to be:\n\nλ(x|cj) = ρ f\n\nh(x − cj; θ)\n\n\n\n\n\n\nm(cid:1)\n\n\n\nj=1\n\n\n\n\n\fHISTORICAL DEVELOPMENT\n\n11\n\nwhere ρ is the overall rate of the point process, f is a link function, h is\na cluster distribution function and cj are now the centre locations. The h\nfunction can take a wide variety of forms depending on the assumed form\nof the clusters of interest and is not required to be a density. The θ vector\nnow contains only non-locational parameters.\n\nA likelihood can be formed and a full Bayesian analysis can proceed by\nintroducing prior distributions for the number of centres, their locations\nand other parameters. Special MCMC algorithms have been introduced to\nsample the posterior distribution of number and location of centres (Birth-\nDeath-MCMC) (Geyer and Møller 1994, Geyer 1999, Stephens 2000). This\napproach can be generalised or modiﬁed in a number of ways.\n\nFirst, the hidden cluster object process can take diﬀerent forms: for ex-\nample linear features could form the centres and so a hidden line process\nmay be assumed. Second, the rigid formulation of parameterisation can\nbe relaxed by allowing the cluster distribution function to be estimated\nnonparametrically, so that the parameter vector θ includes smoothing con",
    "chunk_order_index": 9,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-3ef17d8daebb274a3172024a45bf89c1": {
    "tokens": 1200,
    "content": "1999, Stephens 2000). This\napproach can be generalised or modiﬁed in a number of ways.\n\nFirst, the hidden cluster object process can take diﬀerent forms: for ex-\nample linear features could form the centres and so a hidden line process\nmay be assumed. Second, the rigid formulation of parameterisation can\nbe relaxed by allowing the cluster distribution function to be estimated\nnonparametrically, so that the parameter vector θ includes smoothing con-\nstants. These types of models can be extended to model applications where\nenvironmental heterogeneity is present, as with modulating functions in\nspatial epidemiology (Lawson 2000) or to distinguish multi-type processes\nin geosciences (Cressie and Lawson 2000). Clustering of non-point objects\ncan also be considered in a similar way.\n\nDiﬃculties arise in all the above approaches when clustering cannot be\nsimply parameterised by a simple set of components or hidden process. For\nexample, clusters of events could form around linear features or have a spa-\ntially varying form which cannot be simply modelled by such components.\nThis tends to suggest that a more fully nonparametric approach to clus-\ntering should be pursued. The idea of using nonparametric smoothing to\nisolate residual areas of excess intensity in a spatial window has been pur-\nsued by a number of workers (e.g. Kelsall and Diggle 1998, Godtliebsen et\nal. 2001a). Another approach is to assume a diﬀerent form of point process\nmodel where the intensity of the process is governed by a spatial process\nwhich does not necessarily parameterise the clustering tendency but rather\nmodels the random variation. Log Gaussian Cox process models fall into\nthis class as described in Chapter 3 (see also Møller et al. 1998). Some\nmore recent developments in clustering focus on models which consist of\npartitions of the intensity space. These models provide a ﬂexible locally\nvarying alternative to global models for the process intensity (Denison and\nHolmes 2001, Denison et al. 2002a).\n\nHierarchical clustering can be achieved in the spatial domain using stan-\ndard methods or the model-based mixture methods described above. In\nthe spatial domain, it is natural to consider the equivalence of hierarchical\nclustering with changes in the spatial scale of clustering. Hence methods\nwhich allow there to be varying scales in the clustered pattern are equiv-\nalent in this sense. The hidden point process methods do allow multiscale\n\n\f12\n\nSPATIAL CLUSTER MODELLING: AN OVERVIEW\n\nphenomena to be examined as they sample the range of cluster number\n(m) and cluster spread or variance. For a given realisation of points, these\nare correlated and so large scale clustering is likely to be sampled when\nsmall values of m are visited. In general one of the advantages of the use of\nMCMC algorithms for sampling the joint distribution of the number and\ncluster feature vector, within a Bayesian setting, is the ability to examine\nnon-ﬂat classiﬁcations.\n\nThe modelling of clustering in counting processes is closely related to\nthat of point processes in the spatial domain. Where counts of point data\nare observed in disjoint subregions of a window it is possible to apply many\nof the above algorithms. Often the conditional expectation of the subregion\ncount is modelled as an integral of the underlying event intensity. Hidden\nprocesses can still be estimated in this way, although the spatial information\nis now at an aggregated level and hence less diﬀerentiated (Lawson 1997).\nCount data arises frequently in spatial epidemiology as well as in spatial\necology. In the former case, there have been a few recent attempts to apply\npartition models to counts (Knorr-Held and Rasser 2000) as well as using\nspecial image priors for count clustering (Gangnon and Clayton 2000).\n\nFinally it can be noted that the ﬁeld of spatial and spatio-temporal\ncluster modelling is currently expanding considerably and is likely to be a\nﬁeld for much fruitful research during the new millennium.\n\n1.3 Notation and Model Development\n\nIn this section we introduce some of the relevant concepts which underpin\nthe topics covered in depth within this volume. Our intention is to provide\na brief account of the basic issues and the notation used in later chapters.\nTo this end, we will consider the topics as divided into spatial and spatio-\ntemporal models and applications, and within these sections we will con-\nsider a broad division between models designed for random variation (of-\nten via random eﬀects) and those models designed speciﬁcally to detect\nor recover random objects (such as cluster locations). In addition, we will\nintroduce the concepts associated with other localised models for random\nvariation (such as partition modelling).\n\nIn the spatial domain it is useful to consider both parametric and non-\nparametric approaches to cluster analysis. Before considering parametric\napproaches, we introduce the basic ideas associated with nonparametric\nanalysis. It should be borne in mind that many nonparametric approaches\nin the spatial domain can be easily extended to the spatio-temporal domain\nor to other higher dimensions. In Chapter 2, an approach to nonparametric\nidentiﬁcation of clusters in the spatial domain is described, and in addition,\nthe extension to higher dimensions is also explicitly described in that work.\nIn the next section we introduce ideas underpinning the approaches there\ndescribed.\n\n\fNOTATION AND MODEL DEVELOPMENT\n\n13\n\n1.3.1 Nonparametric Approaches\n\nIt is often the case that only a vague de",
    "chunk_order_index": 10,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-47bb72b6cdb3b8229b9dab12b6d44da7": {
    "tokens": 1200,
    "content": "the spatio-temporal domain\nor to other higher dimensions. In Chapter 2, an approach to nonparametric\nidentiﬁcation of clusters in the spatial domain is described, and in addition,\nthe extension to higher dimensions is also explicitly described in that work.\nIn the next section we introduce ideas underpinning the approaches there\ndescribed.\n\n\fNOTATION AND MODEL DEVELOPMENT\n\n13\n\n1.3.1 Nonparametric Approaches\n\nIt is often the case that only a vague deﬁnition of clustering, or what con-\nstitutes a cluster, is available. This may be the case at an exploratory stage\nof analysis, or it may be that the clusters examined can take a wide, or\nperhaps ill-deﬁned, variety of forms. Often, in this case, areas of a study\nregion which display unusual aggregations of items/events are of interest.\nThe deﬁnition of unusual being made with reference to some null distri-\nbution of aggregation. In spatial epidemiology, the null distribution would\nbe the distribution expected from the population at risk of the disease of\ninterest. In other applications, the null distribution could be complete spa-\ntial randomness (CSR) and departures from such a distribution are to be\ndetected and possibly interpreted as clusters.\n\nOften in this broad deﬁnition, clusters are regarded as areas of elevated\naggregation where the degree of aggregation surpasses some threshold. Of-\nten this threshold is deﬁned by a critical p-value, and any areas on the\nresulting map which exceed this critical value can be regarded as valid clus-\nters. Usually only areas of elevated aggregation are of interest, although it\nis possible that areas of particularly low aggregation may also be of interest.\nThe group of methods known as bump-hunting describe this area of\nnonparametric clustering (for example, see Section 9.2 Scott 1992). These\nmethods rely on the use of nonparametric density estimation methods,\nsuch as kernel density estimation, to estimate the local density surface of\nevents on the map. Subsequently, the peaks of this surface (bumps) are\ndetected and a threshold value is applied to allow a signiﬁcance decision.\nBump-hunting, in the spatial domain, consists of a set of methods which are\ndesigned to detect peaks in a nonparametric density estimate surface. In\nsome special applications, such as point processes, the ﬁrst order intensity\nof the process is to be estimated and special edge-corrected estimators are\navailable (Diggle 1983, Diggle 1985a). In other cases, ratios of intensities\nmust be estimated such as in spatial epidemiology (Bithell 1990, Lawson\nand Williams 1993, Kelsall and Diggle 1995b). Here we discuss density\nestimation and bump-hunting.\n\nDensity/Intensity Estimation For our purposes, the complete set of loca-\ntions of events/items within a study window is deﬁned to be a realisation\nof an event process. The density of events within the study window will be\nestimated via nonparametric density estimation. Deﬁne the realisation of\nevents as {x}i=1,...,n. A bivariate (product) kernel estimator of the density,\nf (x), at arbitrary location {s, u}, (cid:9)f (s, u) say, can be speciﬁed as:\n(cid:10)\n\n(cid:12)(cid:13)\n\n(cid:11)\n\n(cid:11)\n\n(cid:12)\n\n(cid:9)f (s, u) =\n\n1\nnh1h2\n\nn(cid:1)\n\nK\n\ni=1\n\ns − x1i\nh1\n\n× K\n\nu − x2i\nh2\n\n.\n\n(1.2)\n\nHere the spatial (x,y) coordinates of the event locations are speciﬁed as\n\n\f14\nSPATIAL CLUSTER MODELLING: AN OVERVIEW\n{x1i, x2i}, and the kernel function K(.) is deﬁned as a univariate density\nfunction centred on zero. A commonly used form of kernel is the Gaussian\nwhich places symmetric normal form on the contribution of the ith data\npoint to the local density. In this approach the local density of events is\ncontrolled by smoothing constants h1 and h2., one for each direction. If no\nseparate directional smoothing is desired, then a common smoothing pa-\nrameter can be applied in each direction. The smoothness of the resulting\ndensity surface depends crucially on the value of the smoothing constant(s)\n(bandwidths). A variety of methods have been developed to provide objec-\ntive criteria for bandwidth selection, such as cross-validation (Section 6.5\nScott 1992).\n\nIn applications in spatial clustering, any smoothing of the spatial varia-\ntion in aggregation could potentially reduce the evidence for clustering. If\nthe ﬁrst order intensity of a point or event process is locally elevated, then\nthis may provide evidence for a local cluster of events. Over-smoothing\nof the density/intensity might reduce the elevation of the density or ﬁrst\norder intensity locally, and so reduce evidence for clustering. Hence over-\nsmoothing by improper bandwidth choice could be a concern here. Of\ncourse, examining the evidence for clustering at diﬀerent bandwidths may\nshed light on the persistence of clusters (and perhaps their signiﬁcance)\nand the pattern of clustering at diﬀerent spatial scales. In Chapter 2, this\nidea is exploited via graphical tools to ﬁnd features which arise at diﬀerent\nscales.\n\nBump-Hunting The basic focus of bump-hunting in the spatial domain is\nthe task of ﬁ",
    "chunk_order_index": 11,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-a48ee5c735e891d08651a03f3ded1e7a": {
    "tokens": 1200,
    "content": "Of\ncourse, examining the evidence for clustering at diﬀerent bandwidths may\nshed light on the persistence of clusters (and perhaps their signiﬁcance)\nand the pattern of clustering at diﬀerent spatial scales. In Chapter 2, this\nidea is exploited via graphical tools to ﬁnd features which arise at diﬀerent\nscales.\n\nBump-Hunting The basic focus of bump-hunting in the spatial domain is\nthe task of ﬁnding modes or peaks of a spatial distribution of events/features.\nThere are two distinct approaches to this task. The ﬁrst approach regards\nareas of elevated aggregation as evidence of a localised peak. With more\nextreme aggregation the peaks become more elevated and so this approach\nseeks to determine the areas of the local density/intensity which have ‘sig-\nniﬁcantly’ elevated levels. In this approach there is an implicit assumption\nof a background, or null, variation in risk under a suitable null hypothe-\nsis. This approach has been advocated for the isolation of areas of excess\nrelative risk in spatial epidemiology, and is a potentially useful tool for\nexploratory analysis of excess variation in applications where background\n(null) spatial variation or heterogeneity is to be included. In the example\nof spatial epidemiology, an intensity ratio is formed from the intensity esti-\nmates of disease case events on a disease map, and the intensity estimate of\ncontrol disease events on the same map. The control disease events are used\nto represent the null or background variation. Let (cid:9)f (x) be the intensity of\ncases at arbitrary location x, and (cid:9)g(x) the intensity of control events. Then\nthe ratio\n\n(cid:9)R(x) =\n\n(cid:9)f (x)\n(cid:9)g(x)\n\n(1.3)\n\n\fNOTATION AND MODEL DEVELOPMENT\n\n15\n\nwill display excess risk over the study area. Further, it is possible to con-\nstruct a Monte Carlo p-value surface by simulating case event realisations\nfrom the null intensity (cid:9)g(x). The rank of the pointwise (cid:9)R(x) compared to\nthe ratios computed from the (cid:9)f (x) for the simulated realisations, gives a\npointwise signiﬁcance surface. Details of this procedure are given in Kelsall\nand Diggle (1995b) and Chapter 6 of Lawson (2001).\n\nWhile the excess variation procedure is a useful exploratory tool it does\nnot use all the information available from the surface concerning the local\npeaks of variation. Much of the literature in bump-hunting for density esti-\nmation has focussed on the estimation of derivatives of density estimates.\nThe derivative shows gradient information and can point to areas of el-\nevated variation. The kernel estimate of the derivative for the univariate\ncase is a sum of the derivative of the kernel function. In the spatial case\ndirectional derivatives must be speciﬁed, and similar results arise. By ex-\namining the nature of a map of ﬁrst and second directional derivatives it\nis possible to assess the degree of peaking on the map. The SiZer and S3\nprocedures described in Chapter 2 address these gradient issues for one and\ntwo dimensions.\n\nThe ﬁnal issue related to bump hunting is the use of scale information\nin the construction of thresholds for accepting areas as clusters. The scale\nof clusters relates closely to the number of clusters and so these also relate\nto the degree of smoothing and hence the bandwidth used. The notion of\na critical bandwidth beyond which clusters appear/disappear has appeal,\nand a test was developed in the univariate case by Silverman (Section\n9.2 Scott 1992). This idea is further examined for the spatial (and higher\ndimensional) case in Chapter 2 where the idea of ‘signiﬁcance in scale-space’\nis introduced.\n\n1.3.2 Point or Object Process Modelling\n\nThe parametric modelling of the locations of point or object events can\nbe approached in a variety of ways. Unlike the nonparametric approaches\ndescribed in 1.3.1, models for the location and nature of clusters must be\nintroduced and the appropriate inferential machinery developed. Usually\nthe available data are a realisation of events (points or objects) within a\nstudy window, and the spatial distribution of the events is assumed to be\ngoverned by a parametric model. Models from within stochastic geometry\nare often used to describe the spatial distribution. In the case of clustering,\nthe Neyman-Scott process is often assumed where a notional set of unob-\nserved cluster centres is thought to explain the clustering of the observed\ndata. The development of such models and their estimation are discussed\nin detail in chapters 3 and 4 in this volume. Another approach is to assume\nthat the local aggregation of events (ﬁrst order intensity) has diﬀerent lev-\nels or partitions (see Chapter 6). The use of Markov chain Monte Carlo\n\n\f16\n\nSPATIAL CLUSTER MODELLING: AN OVERVIEW\n\nand perfect sampling are also featured in Chapters 4, 5, 6 and 14. Models\nwhere the distribution of events is related to a hidden process of centres\nconstitute one form of Cox Process, whereas log Gaussian Cox processes, as\ndescribed in Chapter 3, have a governing intensity which is the realisation\nof a Gaussian spatial process. In the ﬁrst case, the locations of centres are\nexplicitly modelled, whereas in the second case areas of elevated intensity\n(peaks in the Gaussian process) correspond to local aggregations.\n\nWhile the focus of modelling of the spatial distribution",
    "chunk_order_index": 12,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-f77cc0d30404cd787558e68379217712": {
    "tokens": 1200,
    "content": "distribution of events is related to a hidden process of centres\nconstitute one form of Cox Process, whereas log Gaussian Cox processes, as\ndescribed in Chapter 3, have a governing intensity which is the realisation\nof a Gaussian spatial process. In the ﬁrst case, the locations of centres are\nexplicitly modelled, whereas in the second case areas of elevated intensity\n(peaks in the Gaussian process) correspond to local aggregations.\n\nWhile the focus of modelling of the spatial distribution of events is a\nprimary concern in clustering, it is also the case that events may have\nassociated measurements which also require to be modelled. For exam-\nple, the location of trees in a forest may be of interest but the height or\nwidth of the trees may have also been measured and may possibly relate\nto the locational preferences of the trees. Another example, from spatial\nepidemiology, would be the diagnostic history of cases of disease located\nat residential addresses. In each case, the location of an event is marked\nwith an associated measurement. This implies that models for locations\nand for marks must be considered. It may be that the marks themselves\nare clustered spatially and/or the locations are clustered. One approach\nto this problem is to model the marks conditionally on the locations (as\nif they were a ﬁxed sampling network). Of course this does not explicitly\nallow for interaction between the two processes, but it does demonstrate\nthe close linkage between models for random processes (marks) and models\nfor locations (events).\n\n1.3.3 Random Eﬀect Modelling\n\nParametric modelling of spatial data is often formulated in terms of tra-\nditional ﬁxed and random eﬀect components. Usually a random variable\nis observed at spatial locations, and this is regarded as the observation of\na spatial random process at these locations. The observed values of the\nspatial process are {yi}n\ni=1 for n locations. The true process at arbitrary\nlocation x is deﬁned to be z(x). The model relating these components is\ndeﬁned to be :\n\ny|z ∼ g{z(x); θ},\n(1.4)\nwhere g{.} is deﬁned as a probability distribution describing the variation\naround the true model, and θ represents a set of parameters.\n\nThe true process, z(x), can be composed of a variety of eﬀects. If a\n\nGaussian measurement error model is assumed, then\n\ny|z ∼ N {z(x), σ2}.\n\nThe error term ((cid:30)) is usually assumed to have zero mean and be spatially\nuncorrelated, and so y = z(x) + (cid:30). In the simple case where variation\nin {yi} is thought to be related to a set of explanatory ﬁxed covariates,\npossibly measured at the n sites, then we can deﬁne a generalised linear\n\n\fNOTATION AND MODEL DEVELOPMENT\n\n17\n\nor additive regression model. Here we introduce a design matrix F which\nconsists of p covariates and is of dimension n × p and α, a p × 1 vector of\nparameters. Note that the covariates can be spatially dependent or not as\nthe context dictates. For example, if there is no spatial correlation inherent\nin the process, then a simple generalised linear model might be appropriate\nfor which\n\ny|z ∼ g{f (F α), θ}\nwhere f (.) is a suitable link function. In the simple normal model case then\nthis is just:\n\ny|z ∼ N {f (F α), σ2}\nIn the case of additive models (GAMs) then f (F α) will be partitioned into\ndiﬀerent smoothed components.\n\nIn the general case (1.4), z(x) could be extended to include random\neﬀects as well as ﬁxed eﬀects. For example, z(x) = µ + z1(x) + z2(x), where\nthe ﬁxed eﬀect µ = F α could be speciﬁed. Here, the extra components\n(z1(x), z2(x)) can represent eﬀects which are not observed but may yield\nextra variation in the observed value of y. In spatial epidemiology, these\neﬀects could represent unobserved covariates such as deprivation, lifestyle,\nage, gender or ethnic origin or even unknown eﬀects as yet not measured,\nor even unmeasurable. In image analysis this extra variation may simply\nbe attributable to unknown unobserved eﬀects. Generalised linear mixed\nmodels (GLMMs) are special cases of these models (Breslow and Clayton\n1993).\n\nThe two extra components (z1(x), z2(x)) are often speciﬁed to model\nspatially correlated or uncorrelated heterogeneity. In this way any extra\npeakedness in the true or observed process will be included in the model.\nIn many situations, these heterogeneity eﬀects are also termed clustering\neﬀects. However, while these eﬀects tend to mimic the eﬀect of peaks in, say,\na clustered event process, the peakedness does not relate to the aggregation\nof an underlying event process, but simply to extra variation in the observed\nprocess or underlying true process. Of course, if the intensity of an event\nprocess was a Gaussian or log Gaussian spatial process then peaks in the\nGaussian process would relate to areas of elevated aggregation in the events\n(for more details see the discussion of Cox processes in Chapters 3, 4, 5 in\nthis volume).\n\nOften the modelling of z1(x), z2",
    "chunk_order_index": 13,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-9f54bd64f6033bfd8108d2214d77690c": {
    "tokens": 1200,
    "content": "ness does not relate to the aggregation\nof an underlying event process, but simply to extra variation in the observed\nprocess or underlying true process. Of course, if the intensity of an event\nprocess was a Gaussian or log Gaussian spatial process then peaks in the\nGaussian process would relate to areas of elevated aggregation in the events\n(for more details see the discussion of Cox processes in Chapters 3, 4, 5 in\nthis volume).\n\nOften the modelling of z1(x), z2(x) is easily carried out via Bayesian\nhierarchical modelling, although a wide range of alternative approaches\ncould also be adopted. In the Bayesian approach the processes z1(x), and\nz2(x) are given prior distributions which deﬁne the spatially structured\n(correlated) term z1(x) say, and the overdispersion term z2(x) say. One\nversion of this speciﬁes that the z1(x) has a spatial Gaussian process prior\nwith speciﬁed covariance model. This approach can be described as gener-\nalised linear geostatistics (Diggle et al. 1998). In Chapter 11 in this volume\n\n\f18\n\nSPATIAL CLUSTER MODELLING: AN OVERVIEW\n\nan extension of this approach is described where a discrete data Poisson\nmodel is assumed. Another approach, popular in applications such as spa-\ntial epidemiology, is to assume a intrinsic Gaussian prior distribution for\nthe spatially structured component (Besag et al. 1991), where dependence\nneighbourhoods are speciﬁed instead of a parametric covariance model.\nThe uncorrelated component is often assumed to have a zero-mean Gaus-\nsian prior distribution. In chapter 9 a new class of skew-Gaussian models for\ngeostatiscial prediction are discussed within a Bayesian hierarchical frame-\nwork.\n\nMore traditional non-Bayesian approaches include universal kriging where\nthe value of y is thought to be modelled by a linear predictor and the second\norder properties of the true underlying process are described by a covari-\nance model. In general, we should note that random eﬀect modelling does\nnot have as its primary focus the estimation of the location of clusters or\nareas of unusually elevated variation.\n\n1.3.4 Partition Modelling\n\nAn alternative approach to modelling of spatially localised variation is to\nassume that the spatial process considered is underlain by a mixture (sum)\nof components and these components are to be estimated. A review of such\nmodels is given in Chapter 7. The basis of these models is similar to the\nrandom eﬀect models of Section 1.3.3 in that the observed data at the ith\nsample location is modelled by\n\nyi = µ + z(xi) + (cid:30)i,\n\nbut here the spatial process is thought to consist of a sum of spatial com-\nponents\n\nJ(cid:1)\n\nz(x) =\n\nwjzj(x|cj)\n\n(1.5)\n\nj=1\n\nwhere the {wj} are weights and {cj} are the centres of a tiling of the study\narea. The extension to this for non-Gaussian non-centred data would be of\nthe form\n\ny|z ∼ g{z(x); θ},\nwhere z(x) is deﬁned as in equation (1.5). In Chapter 8 a diﬀerent for-\nmulation seeks to model discrete count data clusters as partitions where\nclustering is controlled by a prior distribution which penalises certain forms\nof conﬁguration.\n\n1.3.5 Spatio-Temporal Process Modelling\n\nExtensions to the spatial modelling described in Section 1.3.3 can be made\nto the spatio-temporal case. In this extension the data observed at a speciﬁc\n\n\fNOTATION AND MODEL DEVELOPMENT\n\n19\n\nlocation in space-time is to be modelled. The type of data arising depends\non the measurement units adopted and can vary considerably depending\non the application context. For example, in disease mapping applications it\nmay be possible to obtain the residential address and the date of diagnosis\nof a case. In this case a complete realisation of a spatio-temporal point\nprocess may be observed. However in other cases, only counts of events\nwithin ﬁxed spatial or temporal periods are available, or measurements at\nspatial monitoring sites are made at ﬁxed time intervals. For ﬁxed spatial\nsites indexed as i = 1, ..., n and temporal periods tj (j = 1, . . . , m) then a\nmodel for the observation yij could be speciﬁed in general as:\n\nyij|z(xi, tj) ∼ g {z(xi, tj); θ} ,\n\nwhere the components of the model will depend on context. In Chapter\n12 a decomposition of z(xi, tj) into spatial and temporal basis functions\n(principal kriging functions) is examined as well as other possible models.\nThe models including correlation are based on parameterised covariance\nfunctions. Other forms can be speciﬁed for the structure of z(xi, tj). In\nepidemiology, a number of models have been proposed for space-time counts\nof disease (Knorr-Held and Besag 1998, Cressie and Mugglin 2000, Waller et\nal. 1997b, Bernardinelli et al. 1995, Sun et al. 2000, Zia et al. 1997, Knorr-\nHeld 2000). These often include separate forms of spatial and temporal\nvariation including spatial and temporal correlation and spatio-temporal\ninteraction terms. These models seek to describe the variation in disease\nrisk across a study region but do",
    "chunk_order_index": 14,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-350f4f1c28c6520b2f1600ffe5f479f2": {
    "tokens": 1200,
    "content": ", Cressie and Mugglin 2000, Waller et\nal. 1997b, Bernardinelli et al. 1995, Sun et al. 2000, Zia et al. 1997, Knorr-\nHeld 2000). These often include separate forms of spatial and temporal\nvariation including spatial and temporal correlation and spatio-temporal\ninteraction terms. These models seek to describe the variation in disease\nrisk across a study region but do not focus on cluster location per se.\n\nExtensions to partition models in space-time can also be made. In Chap-\nter 13 an application of spatio-temporal partitioning to an imaging prob-\nlem is described. In their model, brain responses are assigned via a mixture\nmodel to a ﬁnite number of levels.\n\nThe spatio-temporal extension for event or point process clustering can\nalso be speciﬁed in a straightforward manner. The point process is gov-\nerned by an intensity of form λ(x, t) = f {z(x, t), θ} which is speciﬁed to\ndepend on the realisation of a spatio-temporal process. This process could\ndepend on the (unobserved) locations of cluster centres (a hidden cluster\ncentre process) or could be designed to be dependent on the proximity of\nobserved events up to a particular time. Alternative formulations where\nlog{λ(x, t)} depends on a spatio-temporal Gaussian process (a log Gaus-\nsian Cox process) could also be speciﬁed. However they do not directly\nmodel the locations of clusters in space-time. The division between data-\ndependent and hidden process dependent models for clusters is discussed\nin more detail in Chapter 14. In that chapter the connection between point\nprocesses and binned counts is examined and a hidden process model is\napplied to a binned realisation of events.\n\n\f\fPART I\n\nPoint process cluster modelling\n\n\f\fCHAPTER 2\n\nSigniﬁcance in Scale-Space for\nClustering\n\nF. Godtliebsen\n\nJ.S. Marron\n\nS.M. Pizer\n\n2.1 Introduction\n\nAn intuitive, visual approach to ﬁnding clusters in low dimensions is through\nthe study of smoothed histograms, e.g. kernel density estimates. Scale-\nspace provides a useful framework for understanding data smoothing. See\nLindeberg (1994) and ter Haar Romeny (2001) for an excellent overview of\nthe extensive scale-space literature.\n\nThe scale-space approach has allowed practical resolution of several long-\nstanding problems in the statistical smoothing literature. See Chaudhuri\nand Marron (1999, 2000) for detailed discussion. For example, the classical\nproblem of choice of the level of smoothing (bandwidth) can be viewed in an\nentirely new way using scale-space ideas. In particular, instead of choosing\none level of smoothing, one should consider the full range of smooths (the\nwhole scale-space). This corresponds to viewing the data at a number of\ndiﬀerent levels of resolution, each of which may contain useful information.\nFor clustering purposes, this simultaneous viewing of several diﬀerent\nIn particular,\nlevels of smoothing incurs an added cost of interpretation.\nit becomes more challenging to decide which of the many clusters that\nare found at diﬀerent levels represent important underlying structure, and\nwhich are insigniﬁcant sampling artifacts. An overview of some solutions\nto this problem is given in Section 2.2. These solutions involve scale-\nspace views of the data (i.e. a family of smooths), which are enhanced\nby visual devices that reﬂect the statistical signiﬁcance of the clusters that\nare present.\n\nIn keeping with the visual nature of these new methods, only one and two\ndimensional cases are presented. Certainly higher dimensional clustering is\nof keen interest, but visual implementation in higher dimensions represents\na very signiﬁcant hurdle. For now, dimension reduction methods need to\nbe applied ﬁrst, before these approaches can be used in higher dimensions.\nIn Section 2.3 we propose a new enhancement of the two dimensional\n\nversion, based on the natural idea of contour lines.\n\n\f24\n\nSIGNIFICANCE IN SCALE-SPACE FOR CLUSTERING\n\nFinally there is some discussion of interesting future research directions\n\nin Section 2.4.\n\n2.2 Overview\n\nThere are a number of diﬀerent approaches to the nonparametric assess-\nment of the statistical signiﬁcance of clusters in one and two dimensions.\nThis problem was called “bump hunting” by Good and Gaskins (1980).\nA wide range of approaches to this topic may be found in the papers Sil-\nverman (1981), Hartigan and Hartigan (1985), Donoho (1988), Izenman\nand Sommer (1988), M¨uller and Sawitzki (1991), Hartigan and Mohanty\n(1992), Minnotte and Scott (1993), Fisher et al. (1994), Cheng and Hall\n(1997), Minnotte (1997) and Fisher and Marron (2001). Many of these\napproaches are only concerned with the number of signiﬁcant clusters.\n\nIn this chapter we discuss more visual approaches to signiﬁcant clusters,\nthat make more explicit use of scale-space ideas. An advantage of the vi-\nsual approach is that one also learns where clusters are located. Viewing\nthrough scale-space reveals the levels of resolution at which each cluster\nappears.\n\nNonparametric statistical inference for clustering in one dimension was\ndeveloped by Chaudhuri and Marron (1999). Their method is called SiZer,",
    "chunk_order_index": 15,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-513514acfe8269e242c2f137950c231f": {
    "tokens": 1200,
    "content": "iﬁcant clusters.\n\nIn this chapter we discuss more visual approaches to signiﬁcant clusters,\nthat make more explicit use of scale-space ideas. An advantage of the vi-\nsual approach is that one also learns where clusters are located. Viewing\nthrough scale-space reveals the levels of resolution at which each cluster\nappears.\n\nNonparametric statistical inference for clustering in one dimension was\ndeveloped by Chaudhuri and Marron (1999). Their method is called SiZer,\nfor “SIgniﬁcance of ZERo crossings”. SiZer ﬁnds clusters through the study\nof the slope of the smooth histogram. A cluster is signiﬁcant when the slope\nof the curve is signiﬁcantly positive on the left, and signiﬁcantly negative\nIn particular, when there is a statistically signiﬁcant zero\non the right.\ncrossing of the derivative. An example is given in Figure 2.1.\n\nFlow cytometry studies the presence as well as the percentage of ﬂuo-\nrescence marked antibodies on cells. The ﬂuorescence of individual cells is\nmeasured, and the results are binned, into bins called “channels”. The top\nof Figure 2.1 shows a bar graph of square root bincounts, from a single ex-\nperiment. The bar graph suggests that there are two clusters in the data.\nAre the clusters statistically signiﬁcant? Or could they be mere artifacts of\nthe sampling process? The issue is not 100% clear, because the peaks con-\ntain some bars that dip below the taller bars located in the valley between.\nSiZer aims to address this issue.\n\nThe heights of the bars in the top panel of Figure 2.1 are shown as dots in\nthe middle panel, which also shows the scale-space as the family of curves.\nIf the raw ﬂuorescence levels were available, the scale-space curves would\nbe kernel density estimates. However SiZer also works in terms of counts,\nusing local linear smoothing to obtain the scale-space, which is done here.\nThe inference done by SiZer is shown in the map in the bottom panel of\nFigure 2.1. The horizontal (x) axis of this map is the same as the x-axis of\nboth of the panels above, i.e. “location”. The vertical (y) axis of the map is\n“scale”, i.e. bandwidth of the smooth, on the log scale. Thus each row of the\n\n\fOVERVIEW\n\n25\n\nFlow Cytometry Histogram\n\n)\ns\nt\nn\nu\no\nc\n(\nt\nr\nq\ns\n\n)\ns\nt\nn\nu\no\nc\n(\nt\nr\nq\ns\n\n8\n\n6\n\n4\n\n2\n\n0\n\n8\n\n6\n\n4\n\n2\n\n0\n\n2.5\n\n2\n\n50\n\n100\n\n150\n\n200\n\n250\n\nScaleSpace Overlay\n\n50\n\n100\n\n150\nSiZer Map\n\n200\n\n250\n\n)\nh\n(\n\n1.5\n\n0\n1\n\ng\no\n\nl\n\n1\n\n0.5\n\n0\n\n50\n\n100\n\n150\n\n200\n\n250\n\nchannel\n\nFigure 2.1 SiZer analysis of the ﬂow cytometry data. Original square root bin\ncounts in the top panel. Family of smooths in the middle panel. SiZer analysis,\nshowing two signiﬁcant clusters in the bottom panel.\n\n\f26\n\nSIGNIFICANCE IN SCALE-SPACE FOR CLUSTERING\n\nFigure 2.2 The raw earthquake data (shown as a scatterplot). An S3 analysis\nappears in Figure 2.3 (which has been separated, since color pictures have been\ncombined).\n\nFigure 2.3 S3 analysis of the earthquake data (shown as a scatterplot in Fig-\nure 2.2), using gradient streamlines (left panel) and curvature dots (right panel).\nThe right cluster is clearly statistically signiﬁcant, the middle cluster is not quite\nconclusive, the left cluster is less well deﬁned.\n\n\fOVERVIEW\n\n27\n\nSiZer map corresponds to one of the curves in the middle panel. The SiZer\nstatistical inference is based on a conﬁdence interval, for slope (derivative)\nof the smooth at each location, and at each scale. When the conﬁdence\ninterval is completely above 0, the smooth is signiﬁcantly increasing, and\nthe color blue (shown here as a dark shade of gray to minimize the need for\ncolor printing) is used. When the conﬁdence interval is entirely below 0,\nthe smooth signiﬁcantly decreases, and this location in the map is colored\nred (shown here as a light shade of gray).\nIn the indeterminate case,\nwhen the conﬁdence interval contains 0, the intermediate color of purple\n(shown here as a the lighter intermediate shade of gray) is used. The\nfourth SiZer color is gray (the darker intermediate shade here), which is\nused at locations and scales where there is not enough data in each kernel\nwindow for reliable statistical inference. This SiZer map shows that both\nclusters are statistically signiﬁcant.\nIn particular the left hand cluster\naround channel 110 is seen to be ”really there” because of the large blue\n(dark) patch to the left, and the smaller red (light) patch on the right\n(ﬂagging signiﬁcant increase, followed by decrease). The same holds for\nthe larger cluster around channel 160.\n\nThe SiZer visualization is very useful in one dimension, but does not\nextend easily to the two dimensional case",
    "chunk_order_index": 16,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-06a0be4b3549dcf60fbc0ab59829327a": {
    "tokens": 1200,
    "content": "iﬁcant.\nIn particular the left hand cluster\naround channel 110 is seen to be ”really there” because of the large blue\n(dark) patch to the left, and the smaller red (light) patch on the right\n(ﬂagging signiﬁcant increase, followed by decrease). The same holds for\nthe larger cluster around channel 160.\n\nThe SiZer visualization is very useful in one dimension, but does not\nextend easily to the two dimensional case. One reason is that an overlay\nview of the family of curves (the scale-space) is no longer possible. A\nmore serious reason is that the SiZer foundation of “signiﬁcantly sloping\nup or down” no longer makes sense in two dimensions. Proposals for some\ncompletely new visualizations of statistically signiﬁcant features, called S3\nfor “signiﬁcance in scale-space”, were made in the case of two dimensional\nimages by Godtliebsen et al. (2001a). Some closely related proposals for two\ndimensional smooth histograms, and thus for ﬁnding signiﬁcant clusters,\nwere made by Godtliebsen et al. (2001b). The problem of lack of availability\nof overlays in two dimensions is addressed by the construction of movies\nwhere time is the scale (i.e. level of smoothing). The problem of statistical\ninference is addressed by adding visual enhancements to the movie. Some\nof these are illustrated in Figures 2.2-2.3.\n\nFigures 2.2-2.3 provide a visual clustering of the earthquake data from\nSection 4.2 in Wand and Jones (1995), shown as a scatterplot in the top\npanel. These data record the locations of epicenters, in longitude (the x\ncoordinate, with 122 subtracted for numerical convenience) and latitude\n(the y coordinate, with 46 subtracted) of earthquakes in the Mount St.\nHelens area of the United States.\n\nThe left hand panel of Figure 2.3 demonstrates the streamline version\nof S3. The green “streamlines” are the visual cues indicating statistically\nsigniﬁcant structure. These are based on the gradient of the gray level\nsurface, which is the direction of maximal change. These green curves\nessentially show the direction that a drop of water would follow as it moves\ndown the surface. However, lines are only drawn in regions where the\n\n\f28\n\nSIGNIFICANCE IN SCALE-SPACE FOR CLUSTERING\n\ngradient is statistically signiﬁcantly diﬀerent from 0, i.e. where there is a\nsigniﬁcant slope.\n\nThe gray level plot, together with the streamlines, suggest three clusters,\nas does the scatterplot on the top. The streamlines show that there is strong\nevidence only for the right cluster being statistically signiﬁcant, as indicated\nby the ring of streamlines pointing towards the peak, that are completely\naround this cluster. The middle cluster has streamlines pointing towards\nthe peak most of the way around, which is a suggestion of a cluster, but\nnot conclusive statistical evidence. The left cluster is much less convincing\n(in the sense of statistical signiﬁcance), because there are few streamlines\npointing towards its peak. Of course it must be kept in mind that statistical\nsigniﬁcance is necessarily one sided. Streamlines give strong evidence of\npresence of a feature, but lack of streamlines only indicates the evidence is\nnot strong enough to be sure, and does not prove absence of a cluster.\n\nTo save space, only one scale, i.e. bandwidth, is shown in Figure 2.3.\nThis is h = 4, which was chosen for presentation purposes, after viewing\nthe full scale-space. For data analytic purposes, this viewing of the full\nscale-space is essential, and we suggest doing this as a movie. We recom-\nmend viewing the movie version of the left side of Figure 2.3, in the ﬁle\nSSScntr1Fig2a.avi in the web directory\nhttp://www.unc.edu/depts/statistics/postscript/papers/marron/SSS cntr/.\nThe movie format is AVI, which is easily viewable on most computers with-\nout the need of downloading an extra viewer.\n\nThe right panel of Figure 2.3 shows an alternate version of S3. This time\nthe statistical inference is based on curvature. Curvature is conveniently\ndescribed in two dimensions using the eigenvalues of the Hessian matrix.\nAt a grid of image locations, statistical signiﬁcance of these eigenvalues\nis assessed. Colored dots, overlaid on top of the gray level image, provide\nquick visual access to this information. The following table indicates colors\nthat are used for the various curvature cases, depending on the largest\neigenvalue (cid:1)λ+, the smallest eigenvalue (cid:1)λ−, and the appropriate quantile\n(cid:1)q (cid:1)T . See Godtliebsen et al. (2001a) for details of the derivation, including\nthe choice of (cid:1)q (cid:1)T . The latter requires substantial eﬀort, even when the\ndata are exactly Gaussian, because the joint distribution of the eigenvalues\n(cid:1)λ+ and (cid:1)λ− is non-standard. Appropriate rescaling and tabulation of this\ndistribution using simulation methods is done in Godtliebsen et al. (2001a).\n\ncolor\nyellow\n\norange\n\nfeature\nhole\n\nlong valley\n\nred\n\nsaddle point\n\npurple\n\nlong ridge",
    "chunk_order_index": 17,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-6efa508e6e0b633b4cc24edc89a735b0": {
    "tokens": 1200,
    "content": "T . The latter requires substantial eﬀort, even when the\ndata are exactly Gaussian, because the joint distribution of the eigenvalues\n(cid:1)λ+ and (cid:1)λ− is non-standard. Appropriate rescaling and tabulation of this\ndistribution using simulation methods is done in Godtliebsen et al. (2001a).\n\ncolor\nyellow\n\norange\n\nfeature\nhole\n\nlong valley\n\nred\n\nsaddle point\n\npurple\n\nlong ridge\n\ndark blue\n\npeak\n\ncharacterization\n(cid:1)λ+, (cid:1)λ− > (cid:1)q (cid:1)T\n(cid:2)\n(cid:2)\n(cid:2)\n(cid:2)\n(cid:2)(cid:1)λ−\n(cid:1)λ+ > (cid:1)q (cid:1)T ,\n(cid:2) < (cid:1)q (cid:1)T\n(cid:1)λ+ > (cid:1)q (cid:1)T , (cid:1)λ− < −(cid:1)q (cid:1)T\n(cid:2)\n(cid:2)\n(cid:2)\n(cid:2)\n(cid:2)(cid:1)λ+\n(cid:2) < (cid:1)q (cid:1)T , (cid:1)λ− < −(cid:1)q (cid:1)T\n(cid:1)λ+, (cid:1)λ− < −(cid:1)q (cid:1)T\n\n.\n\n\fNEW METHOD\n\n29\n\nMost of these colors appear in the right side of Figure 2.3. Again only a\nsingle scale has been selected, h = 5.19, after viewing the full scale-space.\nThis scale is larger than that chosen for the streamline analysis in the left\npanel, because curvature estimates feel noise more strongly than slope esti-\nmates, so more smoothing is needed for similar inference. Viewing the full\nscale-space is again recommended, using the movie ﬁle SSScntr1Fig2b.avi\nin the above web directory. As in the above analysis, the right cluster in\nthe data comes through very strongly.\nIn particular there are a number\nof dark blue dots. The center cluster is less clear, showing all purple dots,\nwhich only show existence of a ridge, not a cluster. Some suggestion that\nthe middle cluster is separate is provided by the red saddle point dots be-\ntween the clusters, but this is not conclusive, because these also appear on\na ridge that then slopes upwards. The potential third cluster on the side\nshows up less strongly here than in the streamline analysis, because at this\ncoarser scale (needed for adequate noise reduction) it is nearly smoothed\naway. The orange dots highlight locations where “clusters emerge from\nregions of no data”.\n\nA disappointing aspect of the analysis of Figure 2.3 is that only the right\nhand cluster is statistically signiﬁcant in this sense. A possible approach to\ninvestigating the signiﬁcance of the other clusters is to adjust the statistical\ninference, via the level of signiﬁcance, α.\nIn Figure 2.3, and all other\nexamples in this chapter, the standard α = 0.05 is used. Results for the less\nstringent case of α = 0.2 are viewable in the movie ﬁles SSScntr1Fig2c.avi\nand SSScntr1Fig2d.avi. These are not shown here to save space. The\nmost interesting result was that at the scale h = 6.17, at least one dark\nblue dot appeared at the top of each of the three clusters, providing evidence\nthat all 3 clusters were signiﬁcant (at this lower level).\n\nAll smoothing methods used in the chapter are kernel based methods.\nFor more background information on these, see for example Scott (1992),\nWand and Jones (1995) and Fan and Gijbels (1996). The Gaussian kernel\nfunction is used everywhere in this chapter, as this has the most appealing\nscale-space properties, see Lindeberg (1994).\n\nAn important technical component of these methods is correct simulta-\nIn particular, many inferences are performed\nneous statistical inference.\nhere at one time. In such situations, naive implementations of hypothesis\ntests will result in a number of false positives. Care has been taken to\navoid this problem in the construction of SiZer and S3. See Chaudhuri\nand Marron (1999) and Godtliebsen et al. (2001a, 2001b) for details.\n\n2.3 New Method\nThe streamline approach to S3, shown in the left panel of Figure 2.3, high-\nlights “statistically signiﬁcant gradient directions” in two dimensions quite\nwell. However, gradients alone are not a particularly intuitive vehicle for\n\n\f30\n\nSIGNIFICANCE IN SCALE-SPACE FOR CLUSTERING\n\nFigure 2.4 S3 analysis of the asymmetric volcano simulated example. Streamline\nonly (left panel) and streamline and contour (right panel) versions. This shows\nthat the addition of contours enhances the interpretability.\n\nunderstanding “surface shape”. This is shown in the left hand panel of\nFigure 2.4, which is based on a simulated data set, composed of a surface\nwith additive i.i.d. Gaussian noise. The underlying surface is an “asym-\nmetric volcano”, that is formed from the volume of revolution of a Gaussian\nprobability density, with mean between the center and edge, with an oﬀ-",
    "chunk_order_index": 18,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-e7f72e10201d6adc22d9ae7b88596c7c": {
    "tokens": 1200,
    "content": "This shows\nthat the addition of contours enhances the interpretability.\n\nunderstanding “surface shape”. This is shown in the left hand panel of\nFigure 2.4, which is based on a simulated data set, composed of a surface\nwith additive i.i.d. Gaussian noise. The underlying surface is an “asym-\nmetric volcano”, that is formed from the volume of revolution of a Gaussian\nprobability density, with mean between the center and edge, with an oﬀ-\ncenter (towards the right) cylinder lowered to height 0 near the middle.\nOne frame of the scale-space is shown, and it is recommended that others\nbe viewed in the movie SSScntr1Fig3a.avi from the above web directory.\nAfter careful contemplation, using visual clues from the underlying gray-\nlevel image, it becomes clear that the central streamlines start in the low\nblack region near the center and climb the inner cone in a radial fashion.\nWhen they reach the circular crest, they then follow the gradient of the\ncrest towards the left. Finally at the top of the crest (on the left side)\nthe gradient is no longer signiﬁcant, and the streamlines stop. Streamlines\ncoming from the outer edge climb the outer cone in a radial way, and join\nthe inner streamlines at the crest.\n\nWhile the streamlines describe the statistically signiﬁcant aspects of the\nshape of the surface, substantial thought is required for complete under-\nstanding. The goal of this section is to provide additional visual clues,\nwhich assist this process, in particular by the addition of contour lines to\nthe S3 graphics. The result of this is shown in the right hand panel of\nFigure 2.4. Note that the contour lines, shown in purple, are orthogonal\nto the green gradient lines. Statistical signiﬁcance of the feature being\nillustrated (e.g. a cluster), is shown by only drawing contours in regions\n\n\fNEW METHOD\n\n31\n\nwhere the gradient is statistically signiﬁcant. This notion of statistical\nsigniﬁcance is particularly well suited to ﬁnding clusters.\nIn particular a\nsigniﬁcant cluster will be a hill of high density (i.e. light gray), that is high-\nlighted by a purple circle surrounding it. The interpretation of the circle\nis that everywhere around, the slope is signiﬁcant, which is a useful notion\nof “cluster”.\n\nThe contour lines in the right part of Figure 2.4 provide quicker intuitive\nunderstanding of the shape of the surface. The central circular contours\nclearly show the inner cone of the volcano. The banana shaped higher level\ncontours immediately reveal the shape of the light colored curved ridge on\nthe left side.\n\nThese new signiﬁcant contours are constructed using the same statistical\ninference methods as for the streamline version of S3. In particular, each\npixel location is ﬂagged as having either a signiﬁcant, or an insigniﬁcant\ngradient. Streamlines are drawn by using a step-wise procedure, following\ngradient directions, with some random starting values. This methodology\ncould be used for the contours, by simply stepping orthogonally to the\ngradient. However, contours are not easy to draw in this way, because they\ngenerally form closed curves, which are not simple to construct using step-\nwise procedures involving accumulating numerical errors. But contours\nhave the advantage that many ready made functions to draw them are\navailable. We use the generic contour subroutine in Matlab, with deletion\nof parts of the contours in regions where the gradient is not signiﬁcant.\n\n30\n\n20\n\n10\n\n30\n\n20\n\n10\n\n10\n\n20\n\n30\n\n10\n\n20\n\n30\n\nFigure 2.5 Shows streamline and contour analysis is more eﬀective than stream-\nlines only, for the Melbourne temperature data.\n\nFigure 2.5 shows some S3 analyses of the Melbourne temperature data.\nThe raw data here is a lag one scatterplot of daily maximal temperatures in\n\n\f32\n\nSIGNIFICANCE IN SCALE-SPACE FOR CLUSTERING\n\nMelbourne, Australia, over a 10 year span. The x axis shows yesterday’s\nmaximum, and the y axis shows today’s maximum. A simple weather\nprediction idea is to use yesterday’s maximum to predict today’s maximum.\nIf that were exactly correct, all the data points would lie on the diagonal\n45◦ line. Using a conditional density estimation analysis, Hyndman et al.\n(1996) showed visually that there is a “horizontal ridge of high density”, i.e.\na ridge where today’s maximum is 20 degrees (Celsius). Veriﬁcation of the\nstatistical signiﬁcance of this ridge (and evidence for a related vertical ridge)\nwere provided by Godtliebsen et al. (2001b), using an analysis similar to\nthat shown in the left panel of Figure 2.5. Both the horizontal and vertical\nridges have a physical explanation, discussed in Godtliebsen et al. (2001b).\nThe left hand panel shows the streamline only analysis at the scale h =\n4.36. Again all scales should be viewed, and are available in the movie ﬁle\nSSScntr1Fig4a.avi at that above web address. The horizontal ridge is\nvisible as a coalescence of streamlines. The diagonal ridge does not show\nup well because near 30 degrees the gradient along the ridge is no longer\nsigniﬁcant. The vertical ridge does not appear at this scale, but does show\nup for smaller scales.\n\nThe right panel of Figure 2.5 shows that adding contours again enhances\nthe analysis, for the same scale (see also the full scale-space movie",
    "chunk_order_index": 19,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-6c66895640cd568b7227e3b29e598a39": {
    "tokens": 1200,
    "content": "avi at that above web address. The horizontal ridge is\nvisible as a coalescence of streamlines. The diagonal ridge does not show\nup well because near 30 degrees the gradient along the ridge is no longer\nsigniﬁcant. The vertical ridge does not appear at this scale, but does show\nup for smaller scales.\n\nThe right panel of Figure 2.5 shows that adding contours again enhances\nthe analysis, for the same scale (see also the full scale-space movie in\nSSScntr1Fig4b.avi), h = 4.36. Curves in the contours provide a stronger\nvisual impression of “ridges” than is available from the streamlines. Even\na hint at the vertical ridge is available in this way. The contour plot\nprovides much more immediate visual insight about the diagonal and hor-\nizontal ridges.\n\nFigure 2.6 Simulated example showing the diﬀerence between equal height and\nmodiﬁed quantile contour spacing.\n\n\fNEW METHOD\n\n33\n\nAn issue in the construction of contours is their spacing. Most of the ex-\namples in this chapter use equal height spacing. However, this is sometimes\ninappropriate. This is demonstrated in a simulated example in Figure 2.6.\nHere the underlying surface is two elongated peaks, as can be seen from\nthe gray level plot. The left panel of Figure 2.6 shows equal height spacing\nof the contours. Here the scale is h = 4, but other scales revealed similar\neﬀects (see the movie version in the ﬁle SSScntr1Fig5a.avi in the same\nweb directory). Note that in the large ﬂat areas on the upper left and\nthe lower right, the contours are somewhat deﬁcient, in the sense that no\ncontour appears for long stretches of the signiﬁcant green streamlines.\n\nGray Level Histogram\n\n200\n\n150\n\n100\n\ns\nt\n\nn\nu\no\nC\n\n50\n\n0\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\n60\n\nGray Level\n\nFigure 2.7 Gray level histogram for image shown in Figure 2.6. This contrasts\nequal height contour spacing (represented as gray bars in the top half ), with mod-\niﬁed quantile spacing (represented as gray bars in the bottom half ).\n\nA simple solution to this problem is to add more contours. However, this\nis not satisfactory, because the contours then become too dense in other\nregions. A better solution is to use diﬀerent types of contour spacing. An\nalternate approach to contour spacings is explained using the gray level\nhistogram shown in Figure 2.7. The gray bars in Figure 2.7 appearing in\nthe top half of the plot show how equally spaced height contours relate to\nthe population of gray levels in the image. Note that a quite large number\nof pixels near the left edge of the population (nearly black) are represented\n\n\f34\n\nSIGNIFICANCE IN SCALE-SPACE FOR CLUSTERING\n\nby only a few contour lines. This explains the poor contour performance\nin the dark areas of the left panel of Figure 2.6.\n\nFigure 2.7 suggests that this problem can be solved by taking the con-\ntour heights according to quantiles of the gray level population, as indicated\nby the gray bars in the lower half. An initial experiment (see the movie\nSSScntr1Fig5c.avi in the same web directory) with equally spaced quan-\ntiles suggested it was worth including more contours at each end. Some\nexperimentation led us to suggest including 0.1 and 0.4 times the quantile\nspacing at the lower end, and making a symmetrical inclusion at the up-\nper end. This is done for the gray bars on the bottom of Figure 2.7, and\nfor the contours in the right panel of Figure 2.6, see the movie version in\nSSScntr1Fig5b.avi in the same web directory. The equally spaced quan-\ntile version is quite similar to the right panel of Figure 2.6, except that\nthe two contours nearest the peak are missing. An advantage of quantile\nspacing is an additional interpretation. When 9 equally spaced quantiles\nare used, the region between two consecutive contours encloses ten percent\nof the pixels.\n\nThe Melbourne temperature data, shown in Figure 2.5 is a case where\nequal spacing does not work, so the modiﬁed quantile spacing was used\nthere. In general, we suggest choosing between height spacing and modiﬁed\nquantile spacing, by starting with height spacing, and switching when that\nis unsatisfactory (which is visually apparent).\n\nFigure 2.8 Contour and streamline analysis of the earthquake data.\n\nIn Figure 2.8, the earthquake data from Figure 2.2 are analyzed by adding\ncontours to the streamline analysis from the left side of Figure 2.3 (at\n\n\fFUTURE DIRECTIONS\n\n35\n\nthe same scale h = 4). The full scale-space movie is available in the ﬁle\nSSScntr1Fig7a.avi in the same web directory.\n\nThe main lessons about statistical signiﬁcance of clusters is the same as\nabove, but again the contours make the information more easily accessible.\n\n2.4 Future Directions\n\n30\n\n20\n\n10\n\n10\n\n20\n\n30\n\nFigure 2.9 Curvature dots analysis of the Melbourne temperature data.\n\nWhile the contour version of S3 provides an improvement to earlier ver-\nsions, there are many other possible improvements, and interesting direc-\ntions for further research.\n\nOne such area is to combine the information present in",
    "chunk_order_index": 20,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-b4be883b42d7eb601822209bc912a9f7": {
    "tokens": 1200,
    "content": "cance of clusters is the same as\nabove, but again the contours make the information more easily accessible.\n\n2.4 Future Directions\n\n30\n\n20\n\n10\n\n10\n\n20\n\n30\n\nFigure 2.9 Curvature dots analysis of the Melbourne temperature data.\n\nWhile the contour version of S3 provides an improvement to earlier ver-\nsions, there are many other possible improvements, and interesting direc-\ntions for further research.\n\nOne such area is to combine the information present in the dot version\nof S3 with signiﬁcant contours. A straightforward approach is to color the\ncontours using the same dot colors. This could provide more immediate\ninterpretation of some of the contours, as well as incorporating additional\nuseful information. Figure 2.9 shows the curvature information available\nfor the Melbourne temperature data. Note that this provides a diﬀerent\ncompelling evidence for the statistical signiﬁcance of the ridges. The full\nscale-space movie version is available in SSScntr1Fig8.avi in the same\nweb directory.\n\nA more complicated, but perhaps more useful extension is to visually\nrepresent the statistical signiﬁcance of the curvature of the contour lines\nthemselves. For example with the contour analysis of the Melbourne tem-\n\n\f36\n\nSIGNIFICANCE IN SCALE-SPACE FOR CLUSTERING\n\nperature data shown in Figure 2.5, it appears that a number of the contours\nare not convex. Is this concavity statistically signiﬁcant?\n\nPerhaps the most challenging extension of S3 is from two dimensions to\nthree. As with the extension from SiZer (dimension 1) to S3 (dimension\n2), the main challenge is the visualization. For example, the scale-space\nis easily presented as an overlay in one dimension, and a movie in two\ndimensions, but it is less clear how to present a three dimensional scale-\nspace. After this problem is solved, then careful attention needs to be\ngiven to which quantities (e.g. gradient and curvature) should have their\nstatistical signiﬁcance displayed, and how they should be visualized.\n\n\fCHAPTER 3\n\nStatistical Inference for Cox Processes\n\nJ. Møller\n\nR.P. Waagepetersen\n\n3.1 Introduction\n\nThis chapter is concerned with statistical inference for a large class of point\nprocess models, which were studied in a seminal paper by Cox (1955) un-\nder the name doubly stochastic Poisson processes, but are today usually\ncalled Cox processes. Much of the literature on Cox processes is concerned\nwith point processes deﬁned on the real line R, but we pay attention to the\ngeneral d-dimensional Euclidean case of Rd, and in particular to the planar\ncase d = 2 (which covers most cases of spatial applications). However, the\ntheory does not make much use of the special properties of Rd, and exten-\nsions to other state spaces are rather obvious. We discuss in some detail\nhow various Cox process models can be constructed and simulated, study\nnonparametric as well as parametric analysis (with a particular emphasis\non minimum contrast estimation), and relate the methods to simulated and\nreal datasets of aggregated spatial point patterns. Further material on Cox\nprocesses can be found in the references mentioned in the sequel and in\nGrandell (1976), Diggle (1983), Daley and Vere-Jones (1988), Stoyan et al.\n(1995), and the references therein.\n\nTo explain brieﬂy what is meant by a Cox process, consider the spatial\npoint patterns in Figure 3.1. As demonstrated in Section 3.3, each point\npattern in Figure 3.1 is more aggregated than can be expected under a\nhomogeneous Poisson process (the reference model in statistics for spatial\npoint patterns). The aggregation is in fact caused by a realization z =\n{z(x) : x ∈ R2} of an underlying nonnegative spatial process Z, which is\nshown in gray scale in Figure 3.1. If the conditional distribution of a point\nprocess X given Z = z is an inhomogeneous Poisson process with intensity\nfunction z, we call X a Cox process with random intensity surface Z (for\ndetails, see Section 3.3). Note that points of X are most likely to occur in\nareas where Z is large, cf. Figure 3.1. In many applications we can think\nof Z as an underlying “environmental” process. Aggregation in a spatial\npoint process X may indeed be due to other sources, including (i) clustering\nof the points in X around the points of another point process C, and (ii)\ninteraction between the points in X. For certain models, (i) is equivalent to\n\n\f38\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\n•\n•\n\nX\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\nX\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\nX\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n•\nX\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n••\nX\n\n• •\n\n•\n\n•\n\n•\n\n•\n\nX\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\nX\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•",
    "chunk_order_index": 21,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-d41d4fe4c74333ba80e303f70e9a48ca": {
    "tokens": 1200,
    "content": "•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\nX\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\nFigure 3.1 From left to right, top to bottom: realizations of Thomas, LGCP,\nSNGCP, and “logistic” processes, and associated random intensity surfaces (in\ngray scale). The crosses in the upper left plot show the cluster centres for the\nThomas process. For more details, see Example 4 (Thomas), Example 5 (LGCP),\nExample 6 (SNGCP), and Example 2 and Example 5 (“logistic”).\n\na Cox process model (see Section 3.5.1). This is in fact the case for the upper\nleft point pattern in Figure 3.1, where the cluster centres C = {c1, . . . , cm}\nare also shown. The case (ii) is not considered in this contribution, but we\nrefer the interested reader to the literature on Markov point processes, see,\nfor example, Møller (1999) and van Lieshout (2000).\n\nGeneral deﬁnitions and descriptions of Poisson and Cox processes are\ngiven in Sections 3.2–3.3, while Section 3.4 provides some background on\nnonparametric analysis. Section 3.5 concerns certain parametric models for\nCox processes. Speciﬁcally, Section 3.5.1 considers the case where Neyman-\nScott processes (Neyman and Scott 1958) are Cox processes, Section 3.5.2\n\n\fPOISSON PROCESSES\n\n39\n\ndeals with log Gaussian Cox processes (Coles and Jones 1991, Møller et\nal. 1998), and Section 3.5.3 with shot noise G Cox processes (Brix 1999).\nThe latter class of models includes the Poisson/gamma processes (Wolpert\nand Ickstadt 1998). As explained in more detail later, the point patterns\nin Figure 3.1 are realizations of a certain Neyman-Scott process, a log\nGaussian Cox process (LGCP), a shot-noise G Cox process (SNGCP), and\na certain “logistic process”, respectively.\n\nIn most applications with an aggregated point pattern modeled by a\nCox process X, the underlying environmental process Z is unobserved.\nFurther, only X ∩ W is observed, where W is a bounded region contained\nin the area where the points in X occur. In Section 3.6 we discuss various\napproaches to estimation in parametric models for Cox processes and focus\nin particular on minimum contrast estimation. In Section 3.7 we discuss how\nZ and X \\ W can be predicted under the various models from Section 3.5.\nSection 3.8 contains some concluding remarks.\n\nThe discussion in Sections 3.5–3.7 will be related to the dataset in Fig-\nure 3.2, which shows the positions of 378 weed plants (Veronica spp./ speed-\nwell). This point pattern is a subset of a much larger dataset analyzed in\nBrix and Møller (2001) and Brix and Chadoeuf (2000) where several weed\nspecies at diﬀerent sampling dates were considered. Note that we have ro-\ntated the design 90◦ in Figure 3.2. The 45 frames are of size 30 × 20 cm2,\nand they are organized in 9 groups each containing 5 frames, where the\nvertical and horizontal distances between two neighbouring groups are 1 m\nand 1.5 m, respectively. The size of the experimental area is 7.5 × 5 m2.\nThe observation window W is given by the union of the 45 frames.\n\n3.2 Poisson Processes\n\nThis section surveys some fundamental concepts of point processes and\nPoisson processes, without going too much into measure theoretical details;\nfor further details, we refer to Daley and Vere-Jones (1988) and Kingman\n(1993).\n\nBy a point process X in Rd we understand a random subset X ⊂ Rd\nwhich is locally ﬁnite, i.e. X ∩ A is ﬁnite for any bounded region A ⊂ Rd.\nBy a region we mean a Borel subset of Rd, and measurability of X is\nequivalent to that\n\nN (A) ≡ card(X ∩ A)\n\nis a random variable for each bounded region A.\n\nHenceforth X denotes a point process in Rd. Its distribution is deter-\nmined by the joint distribution of N (A1), . . . , N (An) for",
    "chunk_order_index": 22,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-33b302b1a659fdecb171450c3ed3757a": {
    "tokens": 1200,
    "content": "X ∩ A is ﬁnite for any bounded region A ⊂ Rd.\nBy a region we mean a Borel subset of Rd, and measurability of X is\nequivalent to that\n\nN (A) ≡ card(X ∩ A)\n\nis a random variable for each bounded region A.\n\nHenceforth X denotes a point process in Rd. Its distribution is deter-\nmined by the joint distribution of N (A1), . . . , N (An) for any disjoint re-\ngions A1, . . . , An and any integer n ≥ 1.\n\nNow, let µ denote an arbitrary locally ﬁnite and diﬀuse measure deﬁned\non the regions in Rd, i.e. µ(A) < ∞ for bounded regions A, and µ({x}) = 0\n\n\f40\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n• •\n\n•\n\n•\n\n••\n\n•\n\n•\n\n•\n\n480\n\n460\n\n440\n\n420\n\n400\n\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n480\n\n460\n\n440\n\n420\n\n400\n\n•\n\n•\n\n•\n\n•\n\n•\n\n0\n5\n7\n\n0\n0\n7\n\n0\n5\n6\n\n0\n0\n6\n\n0\n5\n4\n\n0\n0\n4\n\n0\n5\n3\n\n0\n0\n3\n\n0\n5\n1\n\n0\n0\n1\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n0\n\n5\n\n0\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n280\n\n260\n\n240\n\n220\n\n200\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n0\n5\n7\n\n0\n0\n7\n\n0\n5\n6\n\n0\n0\n6\n\n0\n5\n4\n\n0\n0\n4\n\n0\n5\n3\n\n0\n0\n3\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•••\n\n•••\n\n•\n\n•••\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n100\n\n80\n\n60\n\n•\n•\n\n•\n\n•\n\n•\n\n40\n\n20\n\n0\n\n••\n\n•\n\n•\n•\n\n• •\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•• •\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n••\n\n•\n\n•\n\n280\n\n260\n\n240\n\n220\n\n200\n\n100\n\n80\n\n60\n\n40\n\n20\n\n0\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n0\n5\n1\n\n0\n0\n1\n\n0\n\n5\n\n0\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n• •\n\n•\n\n•\n\n•\n\n•\n\n0\n5\n7\n\n0\n0\n7\n\n0\n5\n6\n\n0\n0\n6\n\n0\n5\n4\n\n0\n0\n4\n\n0\n5\n3\n\n0\n0\n3\n\n0\n5\n1\n\n0\n0\n1\n\n0\n\n5\n\n0\n\n480\n\n460\n\n440\n\n420\n\n400\n\n280\n\n260\n\n240\n\n220\n\n200\n\n100\n\n80\n\n60\n\n40\n\n20\n\n0\n\nFigure 3.2 Positions of weed plants when the design is rotated 90◦.\n\nfor all singleton sets {x} ⊂ Rd. We say that X is a Poisson process with\nintensity measure µ if the following two properties are satisﬁed:\n\n\fCOX PROCESSES\n\n41\n\n(a) independent scattering: N (A1), . . . , N (An) are independent for disjoint\n\nbounded regions A1, . . . , An and integers n ≥ 2;\n\n(b) N (A) is Poisson distributed with mean µ(A) for bounded regions A.\nThe properties (a)–(b) are easily seen to be equivalent to (b)–(c), where\n(c) for any bounded region A with µ(A) > 0 and any integer n ≥ 1, condi-\ntionally on N (A) = n, the n points x1, . . . , xn in X ∩ A are independent\nand each point has distribution µ(A ∩ ·)/µ(A).\n\nThe conditional distribution in (c) is called a binomial process. Using (a)–\n(c) it is not hard to verify that the Poisson process exists.\n\nA point process is said to be stationary if its distribution is invariant\nunder translations in Rd, and isotropic if its distribution is invariant under\nrotations around the origin in Rd. A Poisson process which is stationary is\nalso isotropic, so it is called a homogeneous Poisson point process; otherwise\nit is said to be an inhomogeneous Poisson process.\n\nOften µ has a density ρ : Rd → [0, ∞)",
    "chunk_order_index": 23,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-d706aa53e96d5a48d915b6f4d93c1662": {
    "tokens": 1200,
    "content": "verify that the Poisson process exists.\n\nA point process is said to be stationary if its distribution is invariant\nunder translations in Rd, and isotropic if its distribution is invariant under\nrotations around the origin in Rd. A Poisson process which is stationary is\nalso isotropic, so it is called a homogeneous Poisson point process; otherwise\nit is said to be an inhomogeneous Poisson process.\n\nOften µ has a density ρ : Rd → [0, ∞) so that µ(A) =\n\nA ρ(x)dx for all\nregions A. Then ρ is called the intensity function. A homogeneous Poisson\nprocess has a constant intensity function, and this constant is simply called\nthe intensity.\n\n(cid:1)\n\nBy (b)–(c) it is very easy to simulate a homogeneous Poisson process\nX on, for example, a rectangular or spherical region B. Denote ρhom the\nintensity of X, and imagine we have simulated X on B. Suppose we want\nto simulate another Poisson process Xthin on a bounded region A ⊆ B,\nwhere Xthin has an intensity function ρthin which is bounded on A by\nρhom. Then we obtain a simulation of Xthin ∩ A by including/excluding the\npoints from X ∩ A in Xthin ∩ A independently of each other, so that a point\nx ∈ X ∩ A is included in Xthin ∩ A with probability π(x) = ρthin(x)/ρhom.\nThis procedure is called independent thinning; it is extended in Example 2,\nSections 3.3–3.4.\n\nFinally, all moments of the counts N (·) for a Poisson process are easily\n\nobtained from (a)–(b). For instance,\n\nEN (A) = µ(A)\n\nand\n\ncov(N (A), N (B)) = µ(A ∩ B)\n\n(3.1)\n\nfor bounded regions A and B.\n\n3.3 Cox Processes\n\nA natural extension of a Poisson process is to let µ be a realization of a\nrandom measure M so that the conditional distribution of X given M = µ\nfollows a Poisson process with intensity measure µ. Then X is said to\nbe a Cox process driven by M . This deﬁnition can be extended to both\nmultivariate point processes and to space-time processes, see Diggle (1983),\nMøller et al. (1998), Brix and Møller (2001), and Brix and Diggle (2001).\n\n\f42\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\n(cid:1)\n\nExample 1 A simple example of a Cox process is a mixed Poisson process\nA Zdx where Z is a positive random variable, i.e. X|Z\nwith M (A) =\nfollows a homogeneous Poisson process with intensity Z. For example, if\nZ is gamma distributed, N (A) follows a negative binomial distribution for\nbounded regions A. Note that N (A) and N (B) are correlated for disjoint\nbounded regions A and B (except in the trivial case where Z is almost surely\nconstant, i.e. when we have a homogeneous Poisson process).\n\nExample 2 Suppose that X is a Cox process driven by M , and Π = {Π(x) :\nx ∈ Rd} ⊆ [0, 1] is a random process which is independent of (X, M ). Let\nXthin denote the point process obtained by random independent thinning of\nthe points in X with retention probabilities Π. More precisely, conditionally\non Π = π, Xthin is obtained by independent thinning of X where a point in\nX is retained with probability π(x). Then Xthin is a Cox process driven by\nA Π(x)M (dx). A simple example is shown in the lower right\nMthin(A) =\nplot in Figure 3.1, where X is a homogeneous Poisson process (i.e. M is\nproportional to Lebesgue measure), and Π follows a “logistic” process, i.e.\nlog(Π/(1 − Π)) is a Gaussian process (see Example 5 in Section 3.5.2).\n\n(cid:1)\n\nCox processes are like inhomogeneous Poisson processes models for aggre-\ngated point patterns. Usually in applications M is unobserved, and so we\ncannot distinguish a Cox process X from its corresponding Poisson process\nX|M when only one realization of X ∩W is available (where W denotes the\nobservation window). Which of the two models might be most appropriate,\ni.e. whether M should be random or “systematic”/deterministic, depends\non\n• prior knowledge and the scientiﬁc questions to be investigated: if, for\nexample, one wants to investigate the dependence of certain covariates\nassociated to M , these may be treated as systematic terms, while un-\nobserved eﬀects may be treated as random terms (for an example, see\nBenes et al. 2001);\n\n• the particular application: if it seems diﬃcult to model an aggregated\npoint pattern with a parametric class of inhomogeneous Poisson pro-\ncesses (e.g. a class of polynomial intensity functions), Cox process mod-\nels such as those in Section 3.5 may allow more ﬂexibility and/or a more\nparsimonious parametrization;\n\n• another application is nonparametric Bayesian modelling: nonparamet-\nric Bayesian smoothing for the intensity surface of an inhomogeneous\nPoisson process is treated in Heikkinen and Arjas (1998) (whose ap-\nproach is very",
    "chunk_order_index": 24,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-c067f260beb3bccaa9d42950c8e920d8": {
    "tokens": 1200,
    "content": "Poisson pro-\ncesses (e.g. a class of polynomial intensity functions), Cox process mod-\nels such as those in Section 3.5 may allow more ﬂexibility and/or a more\nparsimonious parametrization;\n\n• another application is nonparametric Bayesian modelling: nonparamet-\nric Bayesian smoothing for the intensity surface of an inhomogeneous\nPoisson process is treated in Heikkinen and Arjas (1998) (whose ap-\nproach is very similar to the one in Chapter 6); see also Remark 4 in\nSection 3.8.\n\nDistributional properties of a Cox process X driven by M follow imme-\ndiately by conditioning on M and exploiting the properties of the Poisson\n\n\fSUMMARY STATISTICS\n\nprocess X|M . For instance, by (3.1),\n\nEN (A) = EM (A)\n\n43\n\nand\n\ncov(N (A), N (B)) = cov(M (A), M (B)) + EM (A ∩ B)\nfor bounded regions A and B. Hence, var(N (A)) = var(M (A)) + EM (A) ≥\nEN (A) with equality only when M (A) is almost surely constant as in the\nPoisson case. In other words, a Cox process exhibits over dispersion when\ncompared to a Poisson process.\n\nIn many speciﬁc models for Cox processes, including those considered in\nExamples 1–2 and in Section 3.5, M is speciﬁed by a nonnegative spatial\nprocess Z = {Z(x) : x ∈ Rd} so that\n(cid:2)\n\nM (A) =\n\nZ(x)dx.\n\n(3.2)\n\nA\nThen we say that X is driven by the random intensity surface Z. In the\nsequel we restrict attention to Cox processes driven by a random intensity\nsurface.\n\nSimulation of X is easy in principle: if we have a simulation zA = {z(x) :\nx ∈ A} of Z restricted to a bounded region A, where zA is bounded by a\nconstant, then the simulation method at the end of Section 3.2 can be used\nto obtain a realization of X ∩ A|ZA = zA. Note that by the independent\nscattering property (a) in Section 3.2, the conditional distribution X ∩ A|Z\ndepends only on ZA.\n\n3.4 Summary Statistics\nThe ﬁrst and second order moments of the counts N (·) for a Cox process\ncan be expressed in terms of two functions:\n\nρ(x) = E[Z(x)]\n\nand\n\ng(x1, x2) = E[Z(x1)Z(x2)]/[ρ(x1)ρ(x2)]\n\nwhich are called the intensity function and the pair correlation function,\nrespectively (“pair correlation function” is standard terminology, though it\nis somewhat misleading). The intensity and pair correlation functions can\nbe deﬁned for general point process models and not just Cox processes,\nsee, for example, Stoyan et al. (1995). Intuitively, E[Z(x1)Z(x2)]dx1dx2\nis the probability for having a point from X in each of the inﬁnitesimally\nsmall volumes dx1 and dx2. It is, however, more informative to work with\nthe pair correlation function which is normalized with the “marginal prob-\nabilities” ρ(x1)dx1 and ρ(x2)dx2 for observing a point in dx1 and dx2,\nrespectively. Another good reason is that g is invariant under random in-\ndependent thinning of a point process; this is exempliﬁed in Example 3\nbelow for the particular case of a Cox process. Finally, g = 1 in the Poisson\ncase.\n\n\f44\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\nExample 3 Consider again Example 2 with M given by (3.2), and let ρ and\ng denote the intensity and pair correlation functions of X. Then Xthin is a\nCox process with random intensity surface Zthin(x) = Π(x)Z(x), intensity\nfunction ρthin(x) = EΠ(x)ρ(x), and pair correlation function gthin = g.\n\nThe intensity and pair correlation functions can be estimated by non-\nparametric methods under rather general conditions, see Diggle (1985b),\nStoyan & Stoyan (1994, 2000), Baddeley et al. (2000), Ohser and M¨ucklich\n(2000), and Møller and Waagepetersen (2001). When the pair correlation\nfunction exists (as it does for the Cox processes we consider), all we need to\nassume is that g is invariant under translations, i.e. g(x1, x2) = g0(x1−x2).\nThen also a so-called K-function can be deﬁned by\n\n(cid:2)\n\nK(r) =\n\n(cid:2)x(cid:2)≤r\n\ng0(x)dx,\n\nr ≥ 0,\n\n(3.3)\n\nand it is easier to estimate K than g by nonparametric methods (Baddeley\net al. 2000). For a stationary point process X, Ripley’s K-function (Ripley\n1976) agrees with K in (3.3), and ρK(r) can be interpreted as the expected\nnumber of further points within distance r from a typical point in X. Note\nthat K and g0 are in one-to-one correspondence if g0(x) depends only on\nthe distance (cid:17)x(cid:17). Moreover, one often makes the transformation",
    "chunk_order_index": 25,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-1c59526fa3978e239a19d956a4017032": {
    "tokens": 1200,
    "content": "2000). For a stationary point process X, Ripley’s K-function (Ripley\n1976) agrees with K in (3.3), and ρK(r) can be interpreted as the expected\nnumber of further points within distance r from a typical point in X. Note\nthat K and g0 are in one-to-one correspondence if g0(x) depends only on\nthe distance (cid:17)x(cid:17). Moreover, one often makes the transformation\n\nL(r) = [K(r)/(πd/2/Γ(1 + d/2))]1/d\n\nas L(r) = r is the identity in the Poisson case.\n\nNonparametric estimators of ρ, g, K, and L are summary statistics of\nthe ﬁrst and second order properties of a spatial point process. These may\nbe supplied with other summary statistics, including nonparametric esti-\nmators of the so-called F , G, and J functions which are based on interpoint\ndistances for a stationary point process X. Brieﬂy, for any r > 0, 1 − F (r)\nis the probability that X has no points within distance r from an arbi-\ntrary ﬁxed point in Rd, 1 − G(r) is the conditional probability that X\nhas no further points within distance r from a typical point in X, and\nJ(r) = (1 − G(r))/(1 − F (r)) (deﬁned for F (r) < 1; see van Lieshout &\nBaddeley 1996). For a stationary Cox process,\n\n1 − F (r) = E exp\n\n−\n\nZ(x)dx\n\n,\n\n(cid:3)(cid:4)\n\n(cid:2)\n\n(cid:2)x(cid:2)≤r\n\n(cid:5)(cid:6)\n\nand\n\n(cid:7)\n\n(cid:4)\n\n(cid:2)\n\n(cid:5)\n\n(cid:8)(cid:9)\n\n1 − G(r) = E\n\nexp\n\n−\n\nZ(x)dx\n\nZ(0)\n\nρ.\n\n(cid:2)x(cid:2)≤r\n\nIn the special case of a homogeneous Poisson process,\n\n1 − F (r) = 1 − G(r) = exp\n\n(cid:10)\n\n(cid:11)\n− ρrdπd/2/Γ(1 + d/2)\n\n.\n\nFurther results are given in Section 3.5.1.\n\n\fPARAMETRIC MODELS OF COX PROCESSES\n\n45\n\nA plot of a summary statistic is often supplied with envelopes obtained\nby simulation of a point process under some speciﬁed model: Consider,\nfor example, the L-function. Let ˆL0 be a nonparametric estimator of L\nobtained from X observed within some window W , and let ˆL1, . . . , ˆLn\nbe estimators obtained in the same way as ˆL0 but from i.i.d. simulations\nX1, . . . , Xn under the speciﬁed model for X. Then, for each distance r, we\nhave that\n\nmin\n1≤i≤n\n\nˆLi(r) ≤ ˆL0 ≤ max\n1≤i≤n\n\nˆLi(r)\n\n(3.4)\n\nwith probability (n − 1)/(n + 1) if X follows the speciﬁed model. We refer\nto the bounds in (3.4) as lower and upper envelopes. In our examples we\nchoose n = 39 so that (3.4) speciﬁes a 2.5% lower envelope and a 97.5%\nupper envelope.\n\nThe estimated L, g, and F functions for the weed data in Figure 3.2 are\nshown in Figures 3.3 and 3.4. The ﬁgures also show the averages of these\nsummary statistics and envelopes obtained from 39 simulations under a\nhomogeneous Poisson process with expected number of points in W equal\nto the observed number of points. The plots for L and g clearly indicate\naggregation, so the homogeneous Poisson process provides a poor ﬁt. We\ndo not consider G due to problems with handling of edge eﬀects in the\nspecial experimental design for the weed plants (see the discussion in Brix\n& Møller, 2001). The averages are close to the theoretical curves except for\ng where ˆg(r) is biased upwards for small r < 2.5 cm (see the discussion\np. 286 in Stoyan & Stoyan, 1994). The envelopes for g are rather wide for\n25 cm < r < 55 cm where few interpoint distances are observed. Similarly,\nthe envelopes for L are wide for r > 25 cm.\n\n3.5 Parametric Models of Cox Processes\n\n3.5.1 Neyman-Scott Processes as Cox Processes\n\nA Neyman-Scott process (Neyman and Scott 1958) is a particular case of a\nPoisson cluster process. In this section we consider the case when Neyman-\nScott processes become Cox processes.\n\nLet C be a homogeneous Poisson process of cluster centres with inten-\nsity κ > 0. Assume that conditionally on C = {c1, c2, . . .}, the clusters\nX1, X2, . . . are independent Poisson processes, where the intensity measure\nof Xi, i ≥ 1, is given by\n\n(cid:2)\n\nµi(A) =\n\nαf (x − ci)dx\n\nA\n\n(3.5)\n\nwhere α > 0 is a parameter and f is a density function for a continuous\nrandom variable in Rd. Then X = ∪i",
    "chunk_order_index": 26,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-f5e9884e6e387587c624417d5426eece": {
    "tokens": 1200,
    "content": "c1, c2, . . .}, the clusters\nX1, X2, . . . are independent Poisson processes, where the intensity measure\nof Xi, i ≥ 1, is given by\n\n(cid:2)\n\nµi(A) =\n\nαf (x − ci)dx\n\nA\n\n(3.5)\n\nwhere α > 0 is a parameter and f is a density function for a continuous\nrandom variable in Rd. Then X = ∪iXi is a Neyman-Scott process. It is\n\n\f46\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\nr\n-\n)\nr\n(\nL\n\n4\n\n2\n\n0\n\n2\n-\n\n4\n-\n\n6\n-\n\n0\n\n10\n\n20\n\n30\nr\n\n40\n\n50\n\n60\n\nFigure 3.3 Estimated L(r) − r for positions of weed plants (solid line), envelopes,\nand average calculated from 39 simulations under the ﬁtted homogeneous Poisson\nprocess (short-dashed line), and theoretical value of L(r) − r (long-dashed line).\n\nalso a Cox process with random intensity surface\n\nZ(x) =\n\nαf (x − c).\n\n(3.6)\n\n(cid:12)\n\nc∈C\n\nThe process (3.6) is stationary. It is also isotropic if f (x) only depends\n\non (cid:17)x(cid:17). The intensity and the pair correlation function are given by\n\nρ = ακ,\n\ng0(x) = 1 + h(x)/κ,\n\n(3.7)\n\nwhere\n\n(cid:2)\n\nh(x) =\n\nf (x0)f (x + x0)dx0\n\nis the density for the diﬀerence between two independent points which each\nhave density f . Furthermore,\n\n(cid:2)\n\n(cid:4)\n\n(cid:2)\n\n(cid:5)\n\nJ(r) =\n\nf (x1) exp\n\n− α\n\nf (x1 + x2)dx2\n\ndx1,\n\n(cid:2)x2(cid:2)≤r\n\nsee Bartlett (1975) and van Lieshout & Baddeley (1996). Hence, F ≤ G\nand J is nonincreasing with range [exp(−α), 1].\n\n\fPARAMETRIC MODELS OF COX PROCESSES\n\n47\n\n5\n.\n2\n\n0\n.\n2\n\n)\nr\n(\ng\n\n5\n.\n1\n\n0\n.\n1\n\n5\n.\n0\n\n0\n.\n1\n\n8\n.\n0\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n0\n.\n0\n\n)\nr\n(\nF\n\n0\n\n10\n\n20\n\n30\nr\n\n40\n\n50\n\n60\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\nr\n\nFigure 3.4 Left and right: as Figure 3.3 but for g and F , respectively.\n\nExample 4 Closed form expressions for g0 are known for a few Neyman-\nScott models. A Thomas process (Thomas 1949) has\n\n(cid:10)\n\n(cid:11)−d/2\n\n(cid:10)\n\n(cid:10)\n− (cid:17)x(cid:17)2/\n\n2ω2\n\n(cid:11)(cid:11)\n\nf (x) =\n\n2πω2\n\n(3.8)\nexp\nthe density for Nd(0, ω2Id), i.e. for d independent normally distributed vari-\nables with mean 0 and variance ω2 > 0. This process is isotropic with\n(cid:11)−d/2\n\n(cid:11)(cid:11)\n\n(cid:10)\n\n(cid:10)\n\n,\n\n(cid:10)\n− (cid:17)x(cid:17)2/\n\n4ω2\n\nexp\n\n/κ.\n\ng0(x) = 1 +\n\n4πω2\n\n(3.9)\n\nThe K-function can be expressed in terms of the cumulative distribution\nfunction for a χ2-distribution with d degrees of freedom, and for d = 2 we\nsimply obtain\n\nK(r) = πr2 + [1 − exp(−r2/(4ω2))]/κ.\n\n(3.10)\n\nThe upper left plot in Figure 3.1 shows a simulation of a Thomas process\nwith κ = 10, α = 10, and ω2 = 0.1.\n\nAnother mathematically tractable model is a Mat´ern cluster process (Mat´ern\n\n1960, Mat´ern 1986), where f is the uniform density on a d-dimensional ball\nwith centre at the origin; see Santal´o (1976) and Stoyan et al. (1995).\n\nWe can obviously modify the deﬁnition of a Neyman-Scott process and\nthe results above in many ways, for example, by replacing α and f (x − ci)\nin (3.5) by α(ci) and fci(x) (using an obvious notation), or by replacing\nC in (3.6) by an arbitrary Poisson process — we consider such extensions\nin Section 3.5.3. In either case we obtain a Cox process.\n\nSimulation of a Neyman-Scott process follows in principle straightfor-\nwardly from either (3.6) and its deﬁnition as a Cox process or from its\nconstruction as a Poisson cluster process. However, boundary eﬀects play a\nrole: if we wish to simulate X within a bounded region W , we ﬁrst simulate\nC within an extended region Bext ⊃ W so that points in X associated to\ncluster centres in C \\ Bext fall in W with a negligible probability.\n\n\f48\n\nSTATISTICAL INFERENCE FOR CO",
    "chunk_order_index": 27,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-1bc69bfd8a724d13912324e3c4102c65": {
    "tokens": 1200,
    "content": "(3.6) and its deﬁnition as a Cox process or from its\nconstruction as a Poisson cluster process. However, boundary eﬀects play a\nrole: if we wish to simulate X within a bounded region W , we ﬁrst simulate\nC within an extended region Bext ⊃ W so that points in X associated to\ncluster centres in C \\ Bext fall in W with a negligible probability.\n\n\f48\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\n3.5.2 Log Gaussian Cox Processes\n\nIf Y = log Z is a Gaussian process, i.e. if any ﬁnite linear combination\n(cid:13)\naiY (xi) follows a normal distribution, then X is said to be a log Gaussian\nCox process (LGCP). Such models have independently been introduced in\nastronomy by Coles and Jones (1991) and in statistics by Møller et al.\n(1998). The deﬁnition of an LGCP can easily be extended in a natural\nway to multivariate LGCPs (Møller et al. 1998) and to multivariate spatio-\ntemporal LGCPs (Brix and Møller 2001, Brix and Diggle 2001).\n\nIt is necessary to impose weak conditions on the mean and covariance\n\nfunctions\n\nm(x) = E[Y (x)]\n\nand\n\nc(x1, x2) = cov(Y (x1), Y (x2))\n(cid:1)\n\nB Z(x)dx for bounded\nin order to get a well-deﬁned and ﬁnite integral\nregions B. For example, we may require that x → Y (x) is almost surely\ncontinuous. Weak conditions ensuring this, and which are satisﬁed for the\nmodels of m and c used in practice, are given in Theorem 3.4.1 in Adler\n(1981) (or see Møller et al. 1998).\n\n(cid:10)\n\n(cid:11)\n\nExample 5 The covariance function belongs to the power exponential family\nif\n\n,\n\n0 ≤ δ ≤ 2,\n\nc(x1, x2) = σ2 exp\n\n− (cid:17)(x1 − x2)/α(cid:17)δ\n(3.11)\nwhere α > 0 is a scale parameter for the correlation and σ2 > 0 is the\nvariance. The special case δ = 1 is an exponential covariance function,\nand δ = 2 a Gaussian covariance function. If m is continuous, then x →\nY (x) is almost surely continuous. For the LGCP in the upper right plot\nin Figure 3.1, (δ, α) = (1, 0.14). The lower right plot in Figure 3.1 is for\nthe logistic process in Example 2 with (δ, α) = (2, 0.10). In both plots the\nGaussian process has mean zero and variance one.\n\nDue to the richness of possible mean and covariance functions, LGCPs\nare ﬂexible models for aggregation as demonstrated in Møller et al. (1998),\nwhere examples of covariance functions together with simulated realiza-\ntions of LGCPs and their underlying Gaussian processes are shown. In the\nspeciﬁc examples of applications considered in this chapter, we let m be\nconstant and c an exponential covariance function. Brix and Møller (2001)\nand Møller and Waagepetersen (2001) consider situations where m is a lin-\near or polynomial function, and Benes et al. (2001) consider a case where\nm depends on covariates.\n\nThe intensity and pair correlation functions of an LGCP are given by\n\nρ(x) = exp(m(x) + c(x, x)/2)\n\nand\n\ng(x1, x2) = exp(c(x1, x2)).\n\n(3.12)\nHence there is a one-to-one correspondence between (m, c) and (ρ, g), and\n\n\fPARAMETRIC MODELS OF COX PROCESSES\n\n49\n\nthe distribution of an LGCP is determined by (ρ, g). This makes para-\nmetric models easy to interpret. Moreover, stationarity respective isotropy\nof an LGCP is equivalent to stationarity respective isotropy of (m, c) or\nequivalently of (ρ, g).\n\nThe simple relationship (3.12) indicates that LGCPs are more tractable\nfor mathematical analysis than Neyman-Scott processes; further results are\ngiven in Møller et al. (1998).\n\nWe now turn to simulation of an LGCP. In contrast to the case of\nNeyman-Scott processes, we do not have problems with boundary eﬀects\nsince the distribution of an LGCP restricted to a bounded region B de-\npends only on the distribution of YB = {Y (x) : x ∈ B}. As YB does not in\ngeneral have a ﬁnite representation in a computer, we approximate YB by\na random step function with constant value Y (ci) within disjoint cells Ci.\nHere B = ∪i∈I Ci is a subdivision with ﬁnite index set I, and ci ∈ Ci is a\n“centre” point of Ci. So we actually consider how to simulate the Gaussian\nvector ˜Y = ( ˜Yi)i∈I where ˜Yi = Y (ci).\n\nAs discussed in Møller et al. (1998), there is an eﬃcient way of simulating\n˜Y when c(ξ, η) = c(ξ − η) is invariant under translations, d = 2, and B is",
    "chunk_order_index": 28,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-cc2eafec117f4e1a5028474907a7269b": {
    "tokens": 1200,
    "content": "∈ Ci is a\n“centre” point of Ci. So we actually consider how to simulate the Gaussian\nvector ˜Y = ( ˜Yi)i∈I where ˜Yi = Y (ci).\n\nAs discussed in Møller et al. (1998), there is an eﬃcient way of simulating\n˜Y when c(ξ, η) = c(ξ − η) is invariant under translations, d = 2, and B is\nrectangular: Let I ⊂ B denote a rectangular grid which is embedded in a\nrectangular grid Iext, which is wrapped on a torus. Then a block circulant\nmatrix K = {Kij}i,j∈Iext can be constructed so that {Kij}(i,j)∈I is the\ncovariance matrix of ˜Y . Since K is block circulant, it can easily be diag-\nonalized by means of the two-dimensional discrete Fourier transform with\nassociated matrix F2 (see Wood & Chan 1994 and Section 6.1 in Møller\net al. 1998). Suppose that K has non-negative eigenvalues. Then we can\nextend ˜Y = ( ˜Y(i,j))(i,j)∈I to a larger Gaussian ﬁeld ˜Yext = ( ˜Y(i,j))(i,j)∈Iext\nwith covariance matrix K: set\n\n˜Yext = ΓQ + µext\n(3.13)\nwhere Γ follows a standard multivariate normal distribution, Q = ¯F2Λ1/2F2,\nΛ is the diagonal matrix of eigenvalues for K, and the restriction of µext\nto I agrees with the mean of ˜Y . Using the two-dimensional fast Fourier\ntransform a fast simulation algorithm for ˜Yext and hence ˜Y is obtained. We\nuse this method for the simulations in Figure 3.1 and in connection with\nthe MCMC algorithm considered in Section 3.7.2.\n\nAnother possibility is to use the Choleski decomposition of the covari-\nance matrix of ˜Y , provided this covariance matrix is positive deﬁnite. This\nmay be advantageous if the covariance function is not translation invariant\nor B is far from being rectangular. On the other hand, the Choleski decom-\nposition is only practically applicable if the dimension of ˜Y is moderate.\n\n3.5.3 Shot Noise G Cox Processes\n\nBrix (1999) introduces shot noise G Cox processes (SNGCP) by smooth-\n\n\f50\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\ning a so-called G measure which is driving a so-called G Cox process, see\nRemark 2 in Section 3.8. We instead deﬁne directly a SNGCP as a Cox\nprocess X with\n\n(cid:12)\n\nZ(x) =\n\nγjk(x, cj)\n\n(3.14)\n\nj\nwhere the notation means the following. For each c ∈ Rp, k(·, c) is a density\nfunction for a continuous random variable. Further, {(cj, γj)} is a Poisson\nprocess deﬁned on Rp × [0, ∞) by the intensity measure\n\n(cid:2)\n\nν(A×B) = (κ(A)/Γ(1−α))×\n\nγ−α−1 exp(−τ γ)dγ, A ⊆ Rp, B ⊆ [0, ∞).\n\n(3.15)\nHere α < 1 and τ ≥ 0 are parameters with τ > 0 if α ≤ 0, and κ is a locally\nﬁnite measure.\n\nB\n\nThis deﬁnition can obviously be modiﬁed in many ways. For instance, if\n\nα = 0 and we redeﬁne ν by\n\n(cid:2)\n\n(cid:2)\n\nν(A × B) = (1/Γ(1 − α))\n\nγ−α−1 exp(−τ (c)γ)κ(dc)dγ,\n\nA\n\nB\n\nwhere τ is now a positive measurable function, we obtain a Poisson/gamma\nprocess as studied in Wolpert and Ickstadt (1998). Extensions to multi-\nvariate SNGCPs are also obvious (Brix 1999). In the sequel X denotes an\nSNGCP with Z and ν given by (3.14) and (3.15).\n\nAssume that κ(·) = κ0|·| is proportional to Lebesgue measure. Then {cj}\nis stationary. Assume also that the kernels k(x, c) = k0(x − c), x, c ∈ Rp,\nare given by a common kernel k0. Then X is stationary, and the intensity\nand pair correlation functions exist for τ (cid:21)= 0 and are given by\n\nρ = κ0τ α−1,\n\ng0(x) = 1 +\n\n1 − α\nκ0τ α\n\n(cid:2)\n\nk0(x0)k0(x + x0)dx0.\n\n(3.16)\n\nThese are of the same form as for a Neyman-Scott process, cf. (3.7), so\nwe cannot distinguish between the two types of models by considering a\nnonparametric estimate of (ρ, g0) only. If furthermore k0(x) depends only\non the distance (cid:17)x(cid:17), then X is isotropic.\n\nExample 6 If k0 is given by the normal density f in (3.8) with variance\nω2, X is isotropic, and g and K are of the same form as for a Thomas\nprocess (replacing κ in (3.9) and (3.",
    "chunk_order_index": 29,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-2b10e853d35bcedd1f6f1c2f31eafa0e": {
    "tokens": 1200,
    "content": "nonparametric estimate of (ρ, g0) only. If furthermore k0(x) depends only\non the distance (cid:17)x(cid:17), then X is isotropic.\n\nExample 6 If k0 is given by the normal density f in (3.8) with variance\nω2, X is isotropic, and g and K are of the same form as for a Thomas\nprocess (replacing κ in (3.9) and (3.10) by τ ακ0/(1 − α)). In the lower left\nplot in Figure 3.1, α = 0, κ0 = 50, τ = 0.5 and ω2 = 0.001.\n\nThe marginal distributions of the independent processes {cj} and {γj}\n\ndepend much on α as described below.\n\nThe case α < 0: Then {cj} is a Poisson process with intensity mea-\nsure (τ α/|α|)κ, and the γj are mutually independent and follow a common\n\n\fESTIMATION FOR PARAMETRIC MODELS OF COX PROCESSES\n\n51\n\nGamma distribution Γ(|α|, τ ). Hence, X is a kind of modiﬁed Neyman-\nScott process. Particularly, X can be simulated within a bounded region in\nmuch the same way as we would simulate a Neyman-Scott process, cf. Sec-\ntion 3.5.1.\n\nThe case 0 ≤ α < 1: The situation is now less simple as {cj} is not\nlocally ﬁnite. For α = 0, we have a Poisson/gamma model (Daley and\nVere-Jones 1988, Wolpert and Ickstadt 1998). For simplicity, suppose that\nκ is concentrated on a region D with 0 < κ(D) < ∞, and write {(cj, γj)} =\n{(c1, γ1), (c2, γ2), . . .} so that γ1 > γ2 > . . . > 0. Deﬁne q(t) = ν(D×[t, ∞))\nfor t > 0. Then q is a strictly decreasing function which maps (0, ∞) onto\n(0, ∞), and q(γ1) < q(γ2) < . . . are the points of a homogeneous Poisson\nprocess of intensity 1 and restricted to (0, ∞). Furthermore, c1, c2, . . . are\nindependent, and each cj follows the probability measure κ(·)/κ(D). For\nsimulation and inference, one approximates Z by\n\nZ(x) ≈ Z J (x) =\n\nJ(cid:12)\n\nj=1\n\nγjk(x, cj)\n\n(3.17)\n\nwhere J < ∞ is a “cut oﬀ”. Brix (1999) and Wolpert and Ickstadt (1998)\ndiscuss how q−1 and the tail sum\n\nj>J γj can be evaluated.\n\n(cid:13)\n\n3.6 Estimation for Parametric Models of Cox Processes\n\nFor speciﬁcity we discuss ﬁrst estimation in the context of a Thomas process\nX with unknown parameters κ > 0, α > 0, and σ > 0. We next turn to\nLGCPs and SNGCPs in Examples 8 and 9.\n\nIn most applications the process of cluster centres C is treated as missing\ndata, and we have only observed X ∩ W = {x1, . . . , xn}, where W is a\nbounded observation window. Let Bext ⊃ W be speciﬁed as in the end of\nSection 3.5.1, and redeﬁne the random intensity surface (3.6) so that the\nsum over cluster centres C is replaced by a sum over C ∩ Bext.\n\nThe likelihood function for θ = (κ, α, ω) is\n\n(cid:7)\n\n(cid:4)\n\n(cid:2)\n\nL(θ) = Eκ\n\nexp\n\n−\n\nZ(x; C ∩ Bext, α, ω)dx\n\n(cid:5) n(cid:14)\n\n(cid:8)\nZ(xj; C ∩ Bext, α, ω)\n\nW\n\nj=1\n\nwhere the mean is with respect to the Poisson process C ∩ Bext, and\n\nZ(x; C ∩ Bext, α, ω) = (α/ω2)\n\nϕ((x − c)/ω)\n\n(cid:12)\n\nc∈C∩Bext\n\n(3.18)\n\nwhere ϕ denotes the density for the d-dimensional standard normal dis-\ntribution. If W is rectangular (or a disjoint union of rectangular sets as\nin Figure 3.2), the integral in (3.18) can be expressed in terms of the cu-\nmulative distribution function for N (0, 1). The likelihood (3.18) can fur-\n\n\f52\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\nmk\n\n1, . . . , ck\n\nther be estimated by Markov chain Monte Carlo (MCMC) methods: For a\ngiven value θ0 = (κ0, α0, ω0) of θ, suppose C 1 = {c1\n}, . . . , C k =\n} is a Markov chain sample from the conditional distribution\n{ck\nC ∩ Bext|X ∩ W = {x1, . . . , xn} (Section 3.7.1 describes how such a sample\ncan be generated). The Monte Carlo approximation of L(θ)/L(θ0) is\n−\nW (",
    "chunk_order_index": 30,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-c501335f76546094f6d43d22fff84861": {
    "tokens": 1200,
    "content": "α0, ω0) of θ, suppose C 1 = {c1\n}, . . . , C k =\n} is a Markov chain sample from the conditional distribution\n{ck\nC ∩ Bext|X ∩ W = {x1, . . . , xn} (Section 3.7.1 describes how such a sample\ncan be generated). The Monte Carlo approximation of L(θ)/L(θ0) is\n−\nW (κ + Z(x; C i, α, ω))dx\n(cid:1)\nW (κ0 + Z(x; C i, α0, ω0))dx\n\nj=1 Z(xj; C i, α, ω)\nj=1 Z(xj; C i, α0, ω0)\n\nκmi exp\n(cid:10)\n−\n\n1, . . . , c1\nm1\n\n(cid:11) (cid:15)\nn\n(cid:11) (cid:15)\n\nκmi\n0 exp\n\nk(cid:12)\n\n1\nk\n\n(cid:1)\n\n(cid:10)\n\nn\n\n.\n\ni=1\n\nNote that the approximation is based on importance sampling, so it only\nworks for θ suﬃciently close to θ0. The generation and storing of C 1, . . . , Ck\nis further computationally rather demanding; see also Remark 1 in Sec-\ntion 3.8 and Chapter 4.\n\nA computationally easier alternative for parameter estimation is mini-\nmum contrast estimation (Diggle 1983, Møller et al. 1998): The closed form\nexpressions (3.9) and (3.10) may be compared with the nonparametric sum-\nmary statistics ˆg and ˆK obtained assuming only stationarity and isotropy\nof X (Section 3.4). If for example d = 2 and the K-function is used, a\nminimum contrast estimate (ˆκ, ˆω) is chosen to minimize\n\na2\n\n(cid:16)(cid:10)\n\nˆK(r) − πr2\n\n(cid:10)(cid:17)\n\n(cid:11)\n\n−\n\n1 − exp(−r2/(4ω2))]/κ\n\n(cid:11)(cid:18)2\n\ndr\n\n(3.19)\n\n(cid:2)\n\na1\n\nwhere 0 ≤ a1 < a2 are user speciﬁed parameters (see Example 7 below).\nSetting\n\n(cid:11)\n\n(cid:10)\nA\n\nω2\n\n(cid:2)\n\na2\n\n=\n\na1\n\n(cid:17)\n1 − exp(−r2/(4ω2))]2dr\n\nand\n\n(cid:11)\n\n(cid:10)\nω2\n\nB\n\n=\n\n(cid:2)\n\na2\n\na1\n\n(cid:17)\n(cid:19)\n( ˆK(r) − πr2)(1 − exp(−r2/(4ω2)))\n\ndr,\n\nthen\n\nˆω2 = arg max\n\nω2\nInserting this into the equation ρ = ακ and using the natural estimate\nˆρ = n/|W | where |W | denotes the area of W , we obtain ﬁnally the estimate\n\nˆκ =\n\nˆω2\n\nˆω2\n\n/B\n\nB\n\n(cid:17)\n\n(cid:11)2\n\n(cid:10)\nω2\n\n(cid:10)\n/A\n\n(cid:11)(cid:19)\n,\n\n(cid:10)\n(cid:17)\nA\n\n(cid:11)\n\n(cid:10)\n\n(cid:11)(cid:19)\n.\n\nˆα = ˆρ/ˆκ.\n\nDiggle (1983) suggests the alternative contrast\n\n(cid:2)\n\na2\n\n(cid:16)(cid:10)\n\n(cid:11)\nˆK(r)\n\nb −\n\n(cid:10)\n\nπr2 +\n\n(cid:17)\n1 − exp(−r2/(4ω2))]/κ\n\n(cid:11)\n\nb\n\n(cid:18)2\n\ndr\n\na1\n\nwhere b > 0 is a third user-speciﬁed parameter recommended to be between\n0.25 and 0.5. This approach requires numerical minimization with respect\nto κ and ω jointly. Brix (1999) reports that minimum contrast estimation\nfor SNGCPs is numerically more stable if g is used instead of K. Minimum\ncontrast estimation for LGCPs and space-time LGCPs is considered in\n\n\fESTIMATION FOR PARAMETRIC MODELS OF COX PROCESSES\n\n53\n\nMøller et al. (1998), Brix and Møller (2001), and Brix and Diggle (2001);\nsee also Example 8 below.\n\nExample 7 (Thomas) For the weed data and certain choices of a1 and a2,\nthe contrast (3.19) did not have a well-deﬁned minimum. Numerically more\nstable results were obtained by using the g-function given by (3.9), i.e.\n(cid:17)\nby considering the contrast obtained by replacing ˆK(r) − πr2 and\n1 −\nexp(−r2/(4ω2))]/κ in (3.19) by ˆg(r) − 1 and exp(−r2/(4ω2)/(4πω2κ), re-\nspectively. The middle plot in Figure 3.4 suggests to use a1 = 2.5 cm and\na2 = 25 cm due to the bias of ˆg(r) for r < 2.5 cm and the large variabil-\nity of ˆg(r) for r > 25 cm. With these values of a1 and a2 the estimates",
    "chunk_order_index": 31,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-f4f6354ad4067673a601643a5c43b848": {
    "tokens": 1200,
    "content": "1 and exp(−r2/(4ω2)/(4πω2κ), re-\nspectively. The middle plot in Figure 3.4 suggests to use a1 = 2.5 cm and\na2 = 25 cm due to the bias of ˆg(r) for r < 2.5 cm and the large variabil-\nity of ˆg(r) for r > 25 cm. With these values of a1 and a2 the estimates\nˆκ=0.005, ˆω2 = 51.0, and ˆα = 3.05 are obtained.\n\nExample 8 (LGCP) Turning next to a stationary LGCP, the mean func-\ntion m is equal to a real constant ξ, say. Let c = cα,σ be the exponential\ncovariance function with positive parameters (α, σ) as in (3.11) with δ = 1.\nFor similar reasons as for the Thomas process, likelihood estimation of\nθ = (ξ, α, σ2) is computationally demanding, and minimum contrast esti-\nmation is a simpler method. Because of the simple relationship (3.12), the\nminimum contrast estimate (ˆα, ˆσ2) is chosen to minimize\n\n(cid:2)\n\na2\n\n(cid:16)\n\nˆg(r)b −\n\n(cid:10)\n\n(cid:11)\nσ2 exp(−r/α)\n\n(cid:18)2\n\nb\n\ndr\n\na1\n\nwhere b > 0. As for the Thomas process we can easily ﬁnd (ˆα, ˆσ2) and\ncombine this with (3.12) and the estimate for the intensity to obtain the\nequation n/|W | = exp( ˆξ + ˆσ2/2) for the estimate of ξ. Using the same\nvalues of a1 and a2 as in Example 5 and letting b = 1, we obtain the\nminimum contrast estimates ˆξ = −4.5, ˆσ2 = 0.45, and ˆα = 9.5.\n\nExample 9 (SNGCP) Consider the SNGCP from Example 6. Using mini-\nmum contrast estimation as for the Thomas process we obtain ˆκ0=0.005,\nˆω2 = 51.0, and ˆτ = 0.33.\n\nA comparison of the nonparametric estimates ˆg and ˆF with the envelopes\ncalculated under the various ﬁtted models in Examples 7–9 (see Figure 3.5)\ndoes not reveal obvious inconsistencies between the data and any of the\nﬁtted models, except perhaps for the SNGCP where ˆF (r) coincides with\nthe upper envelope for a range of distances r. The bias of ˆg near zero makes\nit diﬃcult to make inference about the behaviour of the pair correlation\nnear zero. For an LGCP it is for example diﬃcult to infer whether an\nexponential or a “Gaussian” covariance function should be used for the\nGaussian ﬁeld Y . See also Remark 1, Section 3.8.\n\n\f54\n\n5\n.\n2\n\n0\n.\n2\n\n)\nr\n(\ng\n\n5\n.\n1\n\n)\nr\n(\ng\n\n0\n.\n1\n\n5\n.\n0\n\n0\n.\n3\n\n5\n.\n2\n\n0\n.\n2\n\n5\n\n.\n\n1\n\n0\n1\n\n.\n\n5\n\n.\n\n0\n\n5\n\n.\n\n2\n\n0\n\n.\n\n2\n\n)\nr\n(\ng\n\n5\n\n.\n\n1\n\n0\n1\n\n.\n\n5\n0\n\n.\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\n0\n\n10\n\n20\n\n30\nr\n\n40\n\n50\n\n60\n\n0\n\n10\n\n20\n\n30\nr\n\n40\n\n50\n\n60\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\nr\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\nr\n\n0\n.\n1\n\n8\n.\n0\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n0\n.\n0\n\n0\n.\n1\n\n8\n.\n0\n\n6\n.\n0\n\n4\n\n.\n\n0\n\n2\n\n.\n\n0\n\n0\n\n.\n\n0\n\n0\n\n.\n\n1\n\n8\n0\n\n.\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n0\n0\n\n.\n\n)\nr\n(\nF\n\n)\nr\n(\nF\n\n)\nr\n(\nF\n\n0\n\n10\n\n20\n\n30\nr\n\n40\n\n50\n\n60\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\nr\n\nFigure 3.5 Upper left: ˆg(r) for the weed data (solid line), envelopes and aver-\nage calculated from 39 simulations under the ﬁtted Thomas process (short-dashed\nline), and theoretical value of g(r) for ﬁtted Thomas process (long-dashed line).\nUpper right: estimated F (r) (solid line), and envelopes and average calculated\nfrom 39 simulations under the ﬁtted Thomas process (short-dashed line). Middle\nplots: as upper plots but for LGCP (Example 8). Lower plots: as upper plots but\nfor SNGCP (Example 9).\n\n3.7 Prediction\nAs in Section 3.6 suppose that a realization x = {x1, . . . , xn} of X∩W is ob-\nserved, where W is a bounded observation window. Given a bounded region\n\n\fPREDICTION\n55\nB, one may be interested in predicting ZB = {Z(x)}x∈B or X ∩ (B \\ W )\nor, more generally, in",
    "chunk_order_index": 32,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-8f53e3cec73a46b19d292aa1aa8b5eaf": {
    "tokens": 1200,
    "content": "NGCP (Example 9).\n\n3.7 Prediction\nAs in Section 3.6 suppose that a realization x = {x1, . . . , xn} of X∩W is ob-\nserved, where W is a bounded observation window. Given a bounded region\n\n\fPREDICTION\n55\nB, one may be interested in predicting ZB = {Z(x)}x∈B or X ∩ (B \\ W )\nor, more generally, in computing the conditional distributions of ZB and\nX ∩ (B \\ W ) given X ∩ W = x. In the sequel we mainly focus on the\nconditional distribution of ZB, since X ∩ (B \\ W ) is conditionally indepen-\ndent of X ∩ B given ZB, and X ∩ (B \\ W ) is simply an inhomogeneous\nPoisson process given ZB. The conditional distribution of ZB is in general\nnot analytically tractable, so MCMC methods become useful for computing\ncharacteristics of the conditional distribution. In the following we discuss\nMCMC algorithms for the model classes considered in Section 3.5. For back-\nground knowledge on MCMC algorithms (particularly Metropolis-Hastings\nalgorithms), see, for example, Gilks et al. (1996) and Robert and Casella\n(1999).\n\n3.7.1 Conditional Simulation for Neyman-Scott Processes\n\nFor a Neyman-Scott process (Section 3.5.1), ZB is determined by the pro-\ncess of cluster centres. We approximate this by the process of cluster centres\nfalling in a suﬃciently large region Bext which contains B, and ignore clus-\nter centres outside Bext. The conditional distribution of the cluster centres\non Bext then has a density with respect to the homogeneous Poisson process\nof intensity 1 and restricted to Bext. The density is given by\n\n(cid:4)\n\n(cid:2)\n\np(c|x) ∝ κcard(c) exp\n\n−\n\nZ(x)dx\n\nW\n\n(cid:5) (cid:14)\n\nc∈c\n\nZ(c)\n\nfor ﬁnite point conﬁgurations c ⊂ Bext, where Z(x) is given by (3.6) but\nwith C replaced by c. The conditional distribution can be simulated using\nthe MCMC algorithm studied in Geyer and Møller (1994). Prediction and\nBayesian inference for Neyman-Scott processes viewed as cluster processes\nhas been considered by, for example, Lawson (1993a), Baddeley and van\nLieshout (1993), and van Lieshout & Baddeley (1995); see also Chapters 4\nand 5.\n\n3.7.2 Conditional Simulation for LGCPs\n\nConsider now an LGCP with YB = log ZB where we use a notation as in\nSection 3.5.2. Approximate simulations of YB|XW = x can be obtained\nfrom simulations of ˜Y |XW = x, which in turn can be obtained from simu-\nlations of Γ|XW = x using the transformation (3.13). Omitting an additive\nconstant depending on x only, the log conditional density of Γ given x is\n\n(cid:12)\n\n−(cid:17)γ(cid:17)2/2 +\n\n(˜yini − Ai exp(˜yi))\n\n(3.20)\n\nwhere, in accordance with (3.13), (˜yi)i∈Iext = γQ + µext, ni = card(x ∩ Ci),\nand Ai = |Ci| if Ci ⊂ W and Ai = 0 otherwise. The gradient of (3.20)\n\ni∈I\n\n\f56\n\nbecomes\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\n∇(γ) = −γ +\n\n(cid:10)\n\n(cid:11)\nni − Ai exp(˜yi)\n\nQT,\n\ni∈Iext\n\nand diﬀerentiating once more, the conditional density of Γ given x is seen\nto be strictly log-concave.\n\nFor simulation from Γ|XW = x, Møller et al. (1998) use a Langevin-\nHastings algorithm or Metropolis-adjusted Langevin algorithm as introduced\nin the statistical community by Besag (1994) (see also Roberts & Tweedie\n1996) and earlier in the physics literature by Rossky et al. (1978). This is\na Metropolis-Hastings algorithm with the proposal distribution given by a\nNd(γ + (h/2)∇(γ), hId) where h > 0 is a user-speciﬁed proposal variance.\nThe use of the gradient in the proposal distribution may lead to much\nbetter convergence properties when compared to the standard alternative\nof a random walk Metropolis algorithm (see Christensen et al. (2000) and\nChristensen and Waagepetersen (2001)).\n\nA truncated version of the Langevin-Hastings algorithm is obtained by\n\nreplacing the gradient ∇(γ) in the proposal distribution by\nQT\n\n(cid:11)\nni − min{H, Ai exp(˜yi)}\n\n∇trun(γ) = −γ +\n\n(cid:10)\n\ni∈Iext\n\n(3.21)\n\nwhere H > 0 is a user-speciﬁed parameter which can, for example, be taken\nto be twice the maximal ni, i ∈ I. As shown in Møller et al. (1998) the\ntruncated Langevin-Hastings algorithm is geometrically ergodic.\n\nBenes et al. (200",
    "chunk_order_index": 33,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-97c498820d9ad4e2390f5560b5641b10": {
    "tokens": 1200,
    "content": "˜yi)}\n\n∇trun(γ) = −γ +\n\n(cid:10)\n\ni∈Iext\n\n(3.21)\n\nwhere H > 0 is a user-speciﬁed parameter which can, for example, be taken\nto be twice the maximal ni, i ∈ I. As shown in Møller et al. (1998) the\ntruncated Langevin-Hastings algorithm is geometrically ergodic.\n\nBenes et al. (2001) consider a fully Bayesian approach for an LGCP\nwhere the truncated Langevin-Hastings algorithm is extended with updates\nof the model parameters. Benes et al. (2001) also discuss convergence of\nthe posterior for the discretized LGCP when the cell sizes tend to zero.\n\nExample 10 Let W be the union of the ﬁve frames in the lower right corner\nin Figure 3.2, let B be the smallest rectangle containing these ﬁve frames,\nand deﬁne the discretized Gaussian ﬁeld ˜Y on a 60 × 40 rectangular grid I\non B. The left plot in Figure 3.6 shows a prediction of ˜Z = exp( ˜Y ) given\nby the conditional mean E( ˜Z|x) of ˜Z using the parameter estimates from\nExample 8. The minimum and maximum values of E( ˜Z|x) are 0.01 and\n0.03, respectively.\n\n3.7.3 Conditional Simulation for Shot-noise G Cox Processes\n\nConditional simulation for an SNGCP with α < 0 follows much the same\nway as in Section 3.7.1, so we let 0 ≤ α < 1 in the sequel. In applications\ninvolving MCMC we consider the approximation (3.17) where D is typically\nequal to an extended region Bext ⊃ B as in Section 3.7.1. Let ψj = q(γj),\nj = 1, . . . , J. By (3.17), conditional simulation of Z J is given by conditional\nsimulation of the vector (c1, ψ1, . . . , cJ , ψJ ). Assuming that the measure κ\nhas a density kκ with respect to Lebesgue measure, (c1, ψ1, . . . , cJ , ψJ ) has\n\n\fPREDICTION\n\n57\n\n0\n0\n1\n\n0\n8\n\n0\n6\n\n0\n4\n\n0\n2\n\n0\n\n0\n0\n1\n\n0\n8\n\n0\n6\n\n0\n4\n\n0\n2\n\n0\n\n0\n\n5 0\n\n100\n\n150\n\n0\n\n5 0\n\n100\n\n150\n\nFigure 3.6 Left: conditional mean of ˜Z under an LGCP model. Right: conditional\nmean of Z J\nB under an SNGCP model. The same gray scales are used in the two\nplots. The ﬁve observation frames are those found in the lower left plot in Fig-\nure 3.2 but here rotated back 90◦.\n\ndensity proportional to exp(−ψJ )\n0 < ψ1 < . . . < ψJ . Note that the conditional density\n\ni=1 kκ(ci) for (c1, . . . , cJ ) ∈ DJ and\n\np(x|c1, ψ1, . . . , cJ , ψJ ) ∝ exp\n\n−\n\nZ J (x)dx\n\nW\n\n(cid:5) n(cid:14)\n\nj=1\n\nZ J (xj)\n\n(cid:15)\n\nJ\n\n(cid:4)\n\n(cid:2)\n\ndoes not depend on the order of (cj, ψj), j = 1, . . . , J. So we can forget\nthe constraint 0 < ψ1 < . . . < ψJ , and simply consider the posterior\ni=1 kκ(ci)\nobtained with the prior density proportional to exp(−ψmax)\nwhere ψmax = max{ψ1, . . . , ψJ }. The density of (c1, ψ1, . . . , cJ , ψJ ) given\nx is then proportional to\n(cid:4)\n\n(cid:8)(cid:7)\n\n(cid:15)\n\n(cid:7)\n\nJ\n\n(cid:2)\n\n(cid:5) n(cid:14)\n\nexp\n\n−\n\nZ J (x)dx\n\nZ J (xj)\n\nexp(−ψmax)\n\nJ(cid:14)\n\n(cid:8)\nkκ(ci)\n\n.\n\nW\n\nj=1\n\ni=1\n\nFor the special case of shot-noise Poisson-gamma models, Wolpert and\nIckstadt (1998) use a certain data augmentation scheme and a Gibbs sam-\npler, but we consider a more simple approach where we just apply a stan-\ndard random scan single-site Metropolis algorithm. A proposal for our\nMetropolis algorithm is obtained by picking a j in {1, . . . , J} uniformly\nat random, and then replacing (cj, ψj) by (c(cid:7)\nj) generated from the uni-\nform distribution on Bext×]cj − sc, cj + sc[ , where sc > 0 is a user-speciﬁed\nparameter. In the implementation of the algorithm it is helpful to introduce\nan auxiliary variable U which takes the value j if ψmax = ψj, j = 1, . . . , J,\nand thus keeps track of the maximal ψj. The variable U can further be used\nto monitor convergence for the Markov chain, since U follows the uniform\ndistribution on {1, . . . , J} when the chain is in",
    "chunk_order_index": 34,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-0e487993fb23e5094b3752af16687a6f": {
    "tokens": 1200,
    "content": "0 is a user-speciﬁed\nparameter. In the implementation of the algorithm it is helpful to introduce\nan auxiliary variable U which takes the value j if ψmax = ψj, j = 1, . . . , J,\nand thus keeps track of the maximal ψj. The variable U can further be used\nto monitor convergence for the Markov chain, since U follows the uniform\ndistribution on {1, . . . , J} when the chain is in equilibrium.\n\nj, ψ(cid:7)\n\nThe algorithm can straightforwardly be extended to accommodate a fully\nBayesian analysis with priors also on the model parameters. Fully Bayesian\n\n\f58\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\nanalysis of Poisson-gamma shot-noise processes is considered in Wolpert\nand Ickstadt (1998) and Best et al. (2000), for example.\n\nExample 11 Let W and B = [0, 150] × [0, 100] be as in Example 10, let\nBext = [−40, 190] × [−40, 140], and consider the ﬁtted SNGCP from Exam-\nple 9. The right plot in Figure 3.6 shows the posterior mean of (Z J (x))x∈B\nobtained with J = 2000, using a sample obtained by subsampling each 104\nstate of a Markov chain of length 107 generated by the Metropolis algorithm.\nThe minimal and maximal values of E(Z J (x)|x), x ∈ B, are the same as\nin Example 10, but the predicted intensity surface is more smooth under\nthe SNGCP.\n\n3.8 Discussion\n\nRemark 1 (Likelihood-based inference) Concerning parameter estimation\nwe have focused on minimum contrast estimation which is advantageous for\ncomputational reasons. This is somewhat out of line with modern spatial\nstatistics where likelihood-based methods (either in a Bayesian or frequen-\ntist framework) attracts increasing attention. In general one must expect\nminimum contrast estimation to be less eﬃcient than likelihood-based esti-\nmation. The minimum contrast estimates can also be very sensitive to the\nchoice of user-speciﬁed parameters.\n\nIf we consider LGCPs and SNGCPs with 0 ≤ α < 1, then two problems\nappear in connection with likelihood-based inference. First, in order to\napply MCMC methods, we need to approximate the processes either by\ndiscretizing the Gaussian ﬁeld for an LGCP or by using the truncated sum\n(3.17). Second, in order to get a good approximation, we need to use either\na ﬁne grid I or a large truncation value J. Conditional simulation for the\napproximate processes thereby becomes computationally very demanding.\nAlso the storage of samples for Monte Carlo estimation of the likelihood\nmay be problematic. For Neyman-Scott processes and SNGCPs with α < 0\nand a moderate value of κ, the conditional distribution will in contrast\ntypically be of moderate dimension, and there is no need to introduce an\napproximation (apart from possible edge eﬀects when the kernel density f\ndoes not have bounded support).\n\nRemark 2 (Deﬁnition of an SNGCP) In Section 3.5.3 we gave a direct def-\ninition of an SNGCP. Below we brieﬂy discuss how such processes have been\nintroduced in Brix (1999).\n\nBrix (1999) deﬁnes ﬁrst a G measure M . This is a random measure\nso that M (A1), . . . , M (An) are independent for disjoint bounded regions\nA1, . . . , An, and each M (Ai) follows a so-called G distribution which is\nparameterized in a certain way by (α, κ(Ai), τ ). It turns out that a G\nj γj1{cj ∈ A}\nmeasure is a locally ﬁnite measure of the form M (A) =\n\n(cid:13)\n\n\fDISCUSSION\n59\nwhere {(cj, γj)} is deﬁned as in Section 3.5.3. Secondly, since M is purely\natomic, Brix views a G Cox process as a random measure Φ: conditionally\non M , we have that Φ is a random measure so that Φ(A1), . . . , Φ(An)\nare independent for disjoint regions A1, . . . , An, and each Φ(Ai) is Poisson\ndistributed with mean M (Ai). Finally, in order to obtain some smoothing,\nBrix deﬁnes an SNGCP by extending the deﬁnition of M to M (A) =\n(cid:13)\nj γjK(A, cj) where each K(·, cj) is an arbitrary probability measure.\nWhen K(·, cj) is given by a density function k(·, cj) as in Section 3.5.3, we\nobtain that Φ is now a nonatomic measure, which can be identiﬁed with\nour SNGCP X given by (3.14).\n\nG Cox processes have nice properties under aggregation due to the sim-\nple form of the distribution of aggregated counts Φ(A1), . . . , Φ(An). For\nexample under a Poisson-gamma model (Wolpert and Ickstadt 1998), the\ncounts are negative binomial distributed. However, one should note that\nthese simple properties are not valid for SNGCPs, due to the smoothing by\nthe kernel k(·, ·). See also the discussion in Richardson (2001) and Møller\n(2001a).\n\nRemark",
    "chunk_order_index": 35,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-3f6b10059027b3b78c65b4fbbfbd8305": {
    "tokens": 1200,
    "content": "aggregated counts Φ(A1), . . . , Φ(An). For\nexample under a Poisson-gamma model (Wolpert and Ickstadt 1998), the\ncounts are negative binomial distributed. However, one should note that\nthese simple properties are not valid for SNGCPs, due to the smoothing by\nthe kernel k(·, ·). See also the discussion in Richardson (2001) and Møller\n(2001a).\n\nRemark 3 (Extension of SNGCPs) One may note that both SNGCPs and\nNeyman-Scott processes are special cases of Cox processes driven by a\nrandom intensity surface of the form\n(cid:12)\n\nZ(x) =\n\nλjk(x, cj)\n\n(3.22)\n\nj\nwhere {(cj, λj)} is a Poisson process with an intensity measure of the form\nν(d(c, λ)) = κ(dc)ζ(dλ) (i.e. a product measure). Here ν is assumed to be\nlocally ﬁnite, but the marginal process {cj} may not be locally ﬁnite, since\nit is possible that ζ([0, ∞)) = ∞, cf. the case of an SNGCP with 0 ≤ α ≤ 1.\nMany properties for Neyman-Scott processes and SNGCPs follow from\ngeneral results for the extended model. For example, if k(x, c) = k0(x − c)\nand κ(·) = κ0|·| where κ0 > 0 is a parameter, the process is stationary with\n(cid:1)\nλ2ζ(dλ) < ∞, the pair correlation\nintensity ρ = κ0\nexists and is given by\n\nλζ(dλ). Assuming\n\n(cid:1)\n\n(cid:2)\n\n(cid:2)\n\ng0(x) = 1 + (κ0/ρ)2\n\nλ2ζ(dλ)\n\nk0(x0)k0(x + x0)dx0.\n\nEquations (3.7) and (3.16) are special cases of this result.\n\nAs in Møller (2001a) we suggest that more attention should be drawn\nto “modiﬁed” Neyman-Scott models of the type (3.22) with {cj} a locally\nﬁnite Poisson process. One can thereby utilize the additional ﬂexibility\noﬀered by the random coeﬃcients λj and still work with a locally ﬁnite\nconditional distribution in connection with Bayesian inference or maximum\nlikelihood estimation.\n\n\f60\n\nSTATISTICAL INFERENCE FOR COX PROCESSES\n\nRemark 4 (Comparison of models) The focus in this chapter has been on\ninferential and computational aspects of various parametric models for Cox\nprocesses. The advantages and disadvantages of LGCPs, SNGCPs, and the\nHeikkinen and Arjas (1998) model for inhomogeneous Poisson processes\nare also discussed in Richardson (2001) and Møller (2001a). Which model\nis most appropriate depends of course on prior knowledge and the purpose\nof the statistical analysis. LGCPs provide easily interpretable Cox process\nmodels with some ﬂexibility in modelling aggregated point patterns when\nthe aggregation is due to an environmental heterogeneity. Even more ﬂex-\nibility may be obtained by using SNGCPs and their extensions (Remark\n3), and such models seem natural when the aggregation is due to clus-\ntering around a process of cluster centres. They seem also appropriate for\nnonparametric Bayesian modelling (Wolpert and Ickstadt 1998, Richardson\n2001, Møller 2001a).\n\n\fCHAPTER 4\n\nExtrapolating and Interpolating\nSpatial Patterns\n\nM.N.M. van Lieshout\n\nA.J. Baddeley\n\n4.1 Introduction\n\nObservations of a spatial pattern are typically conﬁned to a bounded re-\ngion of space, while the original pattern of interest can often be imagined\nto extend outside. Much attention has been paid to statistical inference for\nmodels of the pattern given only the partial observations in the sampling\nwindow. Less attention has been given to prediction or extrapolation of the\nprocess (i.e. of the same realisation of the process) beyond the window of\nobservation, conditional on the partially observed realisation. A motivat-\ning example is the charting of geological faults encountered during coal\nmining (Baddeley et al. 1993, Chil`es 1989). It is of interest to predict the\nlikely presence of geological faults outside the region mined so far, and\nthereby to choose between various mining strategies. Other examples may\nbe found in image processing, for instance the problem of replicating a\ntexture beyond the region where it has been observed as in the editing of\na video image so that a foreground object is removed and replaced seam-\nlessly by the background texture (De Bonet 1997). Partial observation of\na spatial pattern may also include eﬀects such as aggregation by admin-\nistrative regions, deletion of part of the pattern, and the unobservability\nof a related pattern. Recovery of full information in this context might be\ncalled interpolation; it resembles a missing data problem. In the mining\nproblem discussed above, mapped charts represent only those parts of ge-\nological faults which were physically encountered. Gaps may arise because\nthe mined region is not convex both at its outer boundary and within this\nboundary, because pillars of unmined material remain. Hence it is of in-\nterest to join observed line segments together and to interpret them as\npart of the same continuous fault zone, a",
    "chunk_order_index": 36,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-94e4f1411a720a369ef239d32108d972": {
    "tokens": 1200,
    "content": "this context might be\ncalled interpolation; it resembles a missing data problem. In the mining\nproblem discussed above, mapped charts represent only those parts of ge-\nological faults which were physically encountered. Gaps may arise because\nthe mined region is not convex both at its outer boundary and within this\nboundary, because pillars of unmined material remain. Hence it is of in-\nterest to join observed line segments together and to interpret them as\npart of the same continuous fault zone, a process that is known as ‘in-\nterpretation’ by geologists. As another example, geostatistics deals with\npredicting values of a spatial random process (e.g. precipitation or pol-\nlution measurements) from observations at known locations (e.g. Journel\nand Huijbregts 1978, Cressie 1993, Stein 1999) and interpolation techniques\n\n\f62\n\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\n\nhave been developed under the name of conditional simulation for Gaus-\nsian and other second-order random ﬁelds, as well as for discrete Markov\nrandom ﬁeld models. Relatively few conditional simulation techniques have\nbeen developed for spatial processes of geometric features such as points,\nline segments and ﬁlled shapes. Those that exist are based largely on Pois-\nson processes and the associated Boolean models (Lantu´ejoul 1997, Kendall\nand Th¨onnes 1999, van Lieshout and van Zwet 2001). A major obstacle is\nthe scarcity of spatial models that are both realistic and tractable for simu-\nlation. Some exceptions are the following. There has been much interest in\nthe conditional simulation of oil-bearing reservoirs given data obtained from\none or more exploration wells (Haldorsen 1983, Chessa 1995). The wells are\nessentially linear transects of the spatial pattern of reservoir sand bodies.\nTypically the sand bodies are idealised as rectangles with horizontal and\nvertical sides of independent random lengths, placed at random locations\nfollowing a Poisson point process. For line segment processes, Chil`es (1989)\npresents some stochastic models with particular application to modelling\ngeological faults (based largely on Poisson processes), geostatistical infer-\nence, and possibilities for conditional simulation; Hjort and Omre (1994)\ndescribe a pairwise interaction point process model for swarms of small\nfaults in a fault zone, and Stoica et al. (2000,2001) study a line segment\nprocess for extracting linear networks from remote sensing images. Some\nof these authors have correctly noted the sampling bias eﬀect attendant on\nobserving a spatial pattern of geometric features within a bounded window\n(analogous to the ‘bus paradox’). Techniques from stochastic geometry need\nto be enlisted to check the validity of simulation algorithms. Extrapolation\nor interpolation of a spatial pattern entails ﬁtting a stochastic model to the\nobserved data, and computing properties of the conditional distribution of\nthis model given the observed data. We will discuss a variety of stochastic\nmodels for patterns of geometric objects, and treat typical issues such as\nedge eﬀects, occlusion and prediction in some generality. Subsequently, we\nshall focus on the problem of identifying clusters in a spatial point pattern,\nwhich can be regarded as interpolation of a two-type point pattern from\nobservations of points of one type only, the points of the other type being\nthe cluster centres (Baddeley and van Lieshout 1993, Lawson 1993b, van\nLieshout 1995, van Lieshout and Baddeley 1995). Applications may be\nfound in epidemiology, forestry, archaeology, coal mining, animal territory\nresearch, and the removal of land mines.\n\n4.2 Formulation and Notation\n\nIn this section we describe the general framework considered throughout.\nThe spatial pattern is a random closed set (Matheron 1975, Stoyan et\nal. 1995) U in Rd, typically d = 2 or 3. The distribution of U is governed\nby a parameter θ in some space Θ.\n\n\fFORMULATION AND NOTATION\n\n4.2.1 Germ–grain Models\n\n63\n\n(cid:1)\n\nAll models considered in this chapter are germ–grain models (Stoyan et\nal. 1995) constructed as follows. There is an underlying process X =\n{Xi, i = 1, 2, . . .} of germs in Rd, each associated with a random com-\npact set Zi (the ‘grain’) in Rd speciﬁed by a parameter in some space Z.\nThe ‘complete data’ process W = {(Xi, Zi)} consists of pairs of germs with\ntheir associated grains and hence can be seen as a marked point process.\ni(Xi + Zi), forms the germ-\nThe union of the translated grains, U =\ngrain model. We shall be concerned mostly with spatial cluster processes,\nwhich can be formulated as germ-grain models where the Xi are the clus-\nter centres, Zi is the cluster of points or objects associated with centre Xi\ntranslated back to the origin (i.e. Zi is a random ﬁnite set of geometric\nobjects), and U is the union pattern. We will sometimes refer to the Xi as\nthe parents and to Xi + Zi as the daughters or oﬀspring of Xi. If both the\ncluster centres and their oﬀspring are points, Z is the space N consisting\nof all ﬁnite point patterns in Rd. The complete data W then consists of the\npatterns X and U together with information mapping each member of U\nto its cluster centre in X. Note that if X = {Xi, i = 1, 2",
    "chunk_order_index": 37,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-689048bfbcd21326e92d65a1a610f8ee": {
    "tokens": 1200,
    "content": "sometimes refer to the Xi as\nthe parents and to Xi + Zi as the daughters or oﬀspring of Xi. If both the\ncluster centres and their oﬀspring are points, Z is the space N consisting\nof all ﬁnite point patterns in Rd. The complete data W then consists of the\npatterns X and U together with information mapping each member of U\nto its cluster centre in X. Note that if X = {Xi, i = 1, 2, . . .} is a homoge-\nneous Poisson point process, and the Zi are i.i.d. the random closed set U\nis a Boolean model (see pp. 484–502 Serra 1982). The common distribution\nof Zi is called the distribution of the typical grain; the germs Xi play only\nan indirect role. In practice, one observes the intersection Y = U ∩ A of\nU with a compact window A ⊆ Rd. Mostly the window A is ﬁxed and\nknown. More generally, one may assume that A is an observable random\nset and condition on it, eﬀectively implying A should be ancillary for θ\nand independent of U . The requirement that A be observable excludes,\nfor example, random thinning models (Cressie 1993, Stoyan et al. 1995).\nThese are unidentiﬁable in the sense that one cannot distinguish between a\npoint process of low intensity and a heavily thinned point process of higher\nintensity, without imposing further assumptions.\n\n4.2.2 Problem Statement\n\ni such that X ∗\n\nThe goal is, given data y = U ∩ A, to obtain estimates of the conditional\nexpectations of random variables associated with U or W . Note that in the\nlatter case, W will contain grains Z ∗\ni hits the boundary\nof A. Hence, any extrapolation technique will have to extend Z ∗\ni as well\nas locate germ-grain pairs not hitting A. It is important to realise that\nthe individual objects Xi + Zi in the germ-grain model are not assumed\nto be observable separately. They are merely an intermediate stage in the\nconstruction of the model for the random set U . For example, any object\nXi + Zi which is completely occluded, i.e. contained in the union of other\nobjects, is not observable and may as well be absent. Consequently our\n\ni + Z ∗\n\n\f64\n\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\n\nanalysis must depend only on the union set U and not on the representation\nof U as a union of objects Xi + Zi. In other words, if the data image y can\nbe represented in two diﬀerent ways\n\ny =\n\nn(cid:2)\n\ni=1\n\n(Xi + Zi) ∩ A =\n\nm(cid:2)\n\n(X (cid:2)\n\nj + Z (cid:2)\n\nj) ∩ A\n\nj=1\n\nthen inference based on either representation must yield identical results.\nThis rules out mark-correlation techniques (Penttinen and Stoyan 1989).\nSpecialising to spatial cluster analysis, inference focuses on the conditional\nexpected number of clusters, the conditional mean number of points per\ncluster and the posterior distribution of centre locations as well as the\nstrength of evidence for clustering. As for occlusion eﬀects, the whole\nessence of the problem is that we do not know which data points be-\nlong to the same cluster. Below, we adopt a Bayesian strategy and base\ninference on the posterior distribution of W given y. The parameter vec-\ntor θ will be estimated by Monte Carlo maximum likelihood (Gelfand and\nCarlin 1993, Geyer 1999).\n\n4.2.3 Edge Eﬀects and Sampling Bias\n\nEdge eﬀects and sampling bias are bound to arise when a spatial pattern\nof unbounded extent is observed in a bounded frame (Baddeley 1999).\nIn this section, we illustrate these problems for partial realisations of a\nPoisson process of geometric objects. Although the Poisson assumption\nallows for explicit computations, the essential complexities of the general\nproblem are already present. Thus, assume that the germ process X =\n{Xi} is a homogeneous Poisson point process in Rd with intensity λ > 0,\nthat the grains Zi are i.i.d. random compact sets, and that A ⊆ Rd is a\nﬁxed, compact window. We wish to generate a realisation of U ∩ A. The\napproach taken will be to sample those objects which wholly or partly\nintersect A, and to clip the resulting pattern to the window A. First, note\nthat a translated grain Xi + Zi intersects A if and only if Xi ∈ A ⊕ ˇZi,\nwhere A ⊕ B = {a + b : a ∈ A, b ∈ B} is the Minkowski sum of two sets\nA, B ⊆ Rd and ˇA = { −a : a ∈ A} is the reﬂection of A about the origin\n(Matheron 1975, Serra 1982, Stoyan et al. 1995). Hence, the germ–grain\npairs (Xi, Zi) for which Xi + Zi hits A form an inhomogeneous Poisson\nprocess whose intensity measure has density λ 1{x ∈ A ⊕ ˇZ} with respect\nto the product of Lebesgue measure and the probability distribution of the\ngrains. Write | · | for d-dimensional volume. Then the number of objects\nintersecting A is Poisson distributed with mean\n\nλE(|A �",
    "chunk_order_index": 38,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-9d2203646066d73219b8fec3e75db918": {
    "tokens": 1200,
    "content": ", the germ–grain\npairs (Xi, Zi) for which Xi + Zi hits A form an inhomogeneous Poisson\nprocess whose intensity measure has density λ 1{x ∈ A ⊕ ˇZ} with respect\nto the product of Lebesgue measure and the probability distribution of the\ngrains. Write | · | for d-dimensional volume. Then the number of objects\nintersecting A is Poisson distributed with mean\n\nλE(|A ⊕ ˇZ|)\n\n(4.1)\n\nwhere the expectation is with respect to the distribution of the typical\ngrain Z, provided (4.1) is ﬁnite. Given n objects are present, they are i.i.d.\n\n\fFORMULATION AND NOTATION\n65\nwith density 1{x ∈ A ⊕ ˇZ}/E(|A ⊕ ˇZ|). Turning to the marginal grain\ndistribution, it should be noted that the grains Zi corresponding to objects\nwhich intersect A are not a random sample from the distribution of the\ntypical grain Z. Instead, their distribution is weighted in the sense that Zi\nare i.i.d. with distribution\n\nPA(Z ∈ ·) =\n\nE\n\n(cid:3)\n\n(cid:4)\n1{Z ∈ ·} |A ⊕ ˇZ|\nE(|A ⊕ ˇZ|)\n\n(4.2)\n\nwhere E denotes the expectation with respect to the distribution of the\ntypical grain Z. Thus the sampling bias favours larger grains: a larger object\nis more likely than a smaller object to intersect A. The sampling bias also\ndepends on the geometry and relative orientations of A and Z. For further\ninformation, see Serra (1982) or Stoyan et al. (1995). To simulate U ∩A, the\nproperties just described can be used if the function f (Z) = |A ⊕ ˇZ| and\nthe distribution (4.2) can be evaluated analytically. In two dimensions, if A\nis a disc of radius r and Z is almost surely convex with nonempty interior,\nthen by Steiner’s formula (page 200 Santal´o 1976)\n\n|A ⊕ ˇZ| = |Z| + r length(∂Z) + πr2\n\n(4.3)\n\nalmost surely, where length(∂Z) denotes the length of the boundary of Z.\nHence (4.2) is a mixture of the area-weighted, the length-weighted and the\nunweighted typical grain distribution. Of course, if Z is a cluster of points,\nit is not convex. However, if the diameter of Z is almost surely bounded\nby D (say), we can generate centres Xi ∈ A ⊕ BD where BD is the disc of\ndiameter D, form the associated Zi and clip Xi +Zi to A. Similarly, one can\nreduce to the case where A is convex, or even a disc, by simply enclosing\nA in a larger, convex region A+ such as the convex hull or circumcircle of\nA, generating a simulated realisation of U in A+, and clipping it to A.\n\n4.2.4 Extrapolation\n\nWhen extending a germ-grain model beyond the observation window, two\ncases may be distinguished, namely\n(i) extending grains Z ∗\n\ni hits the boundary of A based\n\ni such that X ∗\n\ni + Z ∗\n\non U ∩ A;\n\n(ii) extending the pattern U beyond the window A based on U ∩ A.\nBelow we discuss several geometric aspects in some generality. Speciﬁc\naspects related to spatial cluster processes will be treated in subsequent\nsections. For Poisson germ-grain models, the conditional distribution of\n{X ∗\ni ) ∩ A : i = 1, 2, . . .} is such that\nthe X ∗\ni + Z ∗\ni are conditionally independent, and the conditional distri-\ni + Z ∗\nbution of X ∗\ni ) ∩ A (Daley and Vere-\nJones 1988, Last 1990, Kingman 1993, Reiss 1993). Note that this con-\nditional distribution as well as the law of (X ∗\ni ) ∩ A may have atoms,\n\ni depends only on (X ∗\n\n: i = 1, 2, . . . } given {(X ∗\n\ni + Z ∗\n\ni + Z ∗\n\ni + Z ∗\n\ni + Z ∗\n\ni\n\n\fi + Z ∗\n\n66\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\nas for example if there is a non-zero probability that a single object X ∗\ni +Z ∗\ni\ncovers A completely, or, in the conditional case, if a grain is speciﬁed fully\nby its restriction to A. Atoms need to be treated separately using integral-\ngeometric factorisation techniques (Santal´o 1976). If the distribution gov-\nerning X is not that of a Poisson point process, as for spatial clustering\nproblems, the grains can no longer be extended independently of each other.\nOther obstacles arise from the unobservability of the individual objects in\nthe pattern (cf. section 4.2.2), and we need to extend grains based on the\nunion set U ∩ A. Sometimes, U ∩ A suﬃces to determine the individual sets\n(X ∗\ni ) ∩ A; more often it will not be possible to determine the compo-\nnents uniquely from U especially",
    "chunk_order_index": 39,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-d2a345fad1758091777bc4407efb56f2": {
    "tokens": 1200,
    "content": "grains can no longer be extended independently of each other.\nOther obstacles arise from the unobservability of the individual objects in\nthe pattern (cf. section 4.2.2), and we need to extend grains based on the\nunion set U ∩ A. Sometimes, U ∩ A suﬃces to determine the individual sets\n(X ∗\ni ) ∩ A; more often it will not be possible to determine the compo-\nnents uniquely from U especially if the window A is not convex or if objects\nmay occlude one another. Indeed, the identiﬁcation of the oﬀspring parti-\ntioning is the whole point of spatial clustering. To conclude this section,\nnote that alternative classes of models include the various Poisson-based\nconstructions described in Chil`es (1989), chapter XIII in Serra (1982), and\nArak-Surgailis-Cliﬀord mosaics and random graphs in Arak et al. (1993).\nWe use germ–grain models mainly because they are quite ﬂexible while\nremaining relatively simple from a computational point of view: Markov\nchain Monte Carlo simulation methods are available by combining existing\nmethods for point processes and for Poisson processes of geometric objects,\nand parametric and nonparametric inferential methods can be carried over\nfrom existing methods for spatial point processes. Moreover, in the alter-\nnative models listed above, the geometric features may be connected (e.g.\nseveral line segments may have a common endpoint) in a fashion which is\ninappropriate to most of the applications considered here, although posi-\ntively desirable for other applications such as random tessellations.\n\n4.3 Spatial Cluster Processes\n\nThe identiﬁcation of centres of clustering is of interest in many areas of ap-\nplications, including archeology (Hodder and Orton 1976), mining (Chil`es\n1989, Baddeley et al. 1993) and animal territory research (Blackwell 1998).\nIn disease mapping the identiﬁcation of cluster centres is of interest (Mar-\nshall 1991; see also Chapter 14 of this volume) and mine ﬁeld detection relies\non separating clusters of land mines from clutter of other kinds (Dasgupta\nand Raftery 1998, Cressie and Lawson 2000). Most traditional clustering\napproaches build a tree based on some similarity measure, for example,\nMardia et al. (1979), Chatﬁeld and Collins (1980), Kaufman and Rousseeuw\n(1990) or other textbooks on multivariate statistics (see also Chapter 1).\nFrom this tree, the number of clusters and the corresponding partition\nare decided in an ad hoc (and mostly subjective) manner. More recently,\nmodel based clustering techniques (Dasgupta and Raftery 1998, Deibolt\nand Robert 1994) consider ﬁnite mixture models. The number of groups is\ndetermined by a Bayes factors or AIC criterion, and given the number of\n\n\fSPATIAL CLUSTER PROCESSES\n\n67\n\nmixture components, model parameters are estimated by maximum like-\nlihood, often using a variant of the EM algorithm. Most applications also\nallow a ‘do not know’ class for outliers or noise. The cluster centres only\nplay an implicit role – approximated by the centre of gravity, principal\naxis or other ‘mean’ of the detected clusters – if they appear at all. No-\ntable exceptions are Lund et al. (1999) and Lund and Th¨onnes (2000) who\nmodel uncertainty in point locations by means of a cluster process consist-\ning of at most a single point, and van Lieshout et al. (2001) who employ\nvariational analysis in the space of intensity measures of the parent point\nprocess. In contrast, following up on earlier work (Baddeley et al. 1993, van\nLieshout 1995, van Lieshout and Baddeley 1995), this chapter advocates the\nuse of point process and germ–grain models (see Section 4.2.1). A virtue of\nthis approach is that the number of clusters, the locations of their centres,\nand the grouping or labelling of observed points into clusters, are intrinsic\naspects of the underlying process (rather than additional parameters) and\nare all treated simultaneously. The most general model we consider is the\nindependent cluster process introduced in Section 4.3.1, but most attention\nwill be focussed on the computationally convenient Cox cluster processes\n(Section 4.3.2). The cluster formation densities are derived in Section 4.3.3\nbelow.\n\n4.3.1 Independent Cluster Processes\nLet X be a point process on Rd and associate with each Xi a ﬁnite clus-\nter Zi of points ‘centred’ at the origin of Rd. Throughout we will assume\nthat the grains Zi are conditionally independent. The union of oﬀspring\nU = ∪i(Xi + Zi) is an independent cluster process (pp. 236–238 in Daley\nand Vere–Jones 1988, pp. 75–81 and 148 ﬀ. in Cox and Isham 1980). Tech-\nnical conditions of ﬁniteness and measurability must be satisﬁed for such\na process to exist, see p. 236 in Daley and Vere-Jones (1988). The data\nconsist of a realisation of Y = U ∩ A in a compact window A ⊆ Rd of\npositive volume. Thus,\n\ny = { y1, . . . , ym} ,\n\nm > 0, y",
    "chunk_order_index": 40,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-81b8deac97549cc9f8a5f47b05386641": {
    "tokens": 1200,
    "content": "Isham 1980). Tech-\nnical conditions of ﬁniteness and measurability must be satisﬁed for such\na process to exist, see p. 236 in Daley and Vere-Jones (1988). The data\nconsist of a realisation of Y = U ∩ A in a compact window A ⊆ Rd of\npositive volume. Thus,\n\ny = { y1, . . . , ym} ,\n\nm > 0, y ⊆ A\n\nis a conﬁguration of daughters in A. The above formulation is quite ﬂexible,\nin that it retains the possibility of locating putative cluster parents outside\nthe window A to counteract sampling bias eﬀects (see the discussion in\nSection 4.2.3) and of grain characteristics such as the daughter intensity\nor the spread of the cluster to be randomly and spatially varying. In order\nto be able to base inference on penalised likelihoods, we shall restrict the\ngerm process to lie inside some compact set X ⊆ Rd of positive volume,\nand assume that its distribution is absolutely continuous with respect to\na unit rate Poisson point process on X . For each ξ ∈ X we are given\nthe distribution Qξ of a ﬁnite point process Zξ on a compact subset ˜X\n\n\f68\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\nof Rd; Zξ represents the oﬀspring of a parent ξ translated back to the\norigin to ﬁt in the general germ-grain model of Section 4.2.1. We assume\nthat Qξ is absolutely continuous with a density g(·|ξ) with respect to the\ndistribution of a unit rate Poisson process on ˜X . Thus Z = N = N ˜X , the\nfamily of ﬁnite point conﬁgurations in ˜X . To ensure existence of U , we shall\nassume that the family of densities is jointly measurable seen as a function\ng : X × N → R+. More generally, we could have set ˜X = Rd equipped\nwith some ﬁnite diﬀuse intensity measure ν(·), with the assumption that\nQξ is absolutely continuous with respect to the distribution of a Poisson\nprocess with intensity measure ν(·). It is of interest to note that when X\nis a Poisson process and we extend the process onto the whole of Rd, then\nQ may be almost surely reconstructed from a single joint observation of\nparents and daughters (Milne 1970, Bendrath 1974). Table 4.1 summarises\nstandard nomenclature for special cases of the independent cluster model\n(Stoyan et al. 1995, Daley and Vere-Jones 1988).\n\nParents X\n\nClusters Z\n\nName of process U\n\ngeneral\nPoisson\ngeneral\nPoisson\nPoisson (homogeneous)\nPoisson (homogeneous)\n\nIndependent cluster process\ngeneral\nPoisson cluster process\ngeneral\nCox cluster process\nPoisson\nPoisson\nNeyman-Scott process\nPoisson (uniform in disc) Mat´ern cluster process\nPoisson (Gaussian)\n\nModiﬁed Thomas process\n\nTable 4.1 Standard nomenclature for independent cluster processes.\n\n4.3.2 Cox Cluster Processes\n\nFor simplicity, most attention will be focussed on the Cox cluster process\nmodel, where each grain Zξ, ξ ∈ X , is a realisation of an inhomogeneous\nPoisson point process on ˜X with intensity function h(· + ξ|ξ) : ˜X → [0, ∞).\nIn other words, a parent point ξ is replaced by a Poisson number of oﬀ-\n(cid:5)\n˜X h(t + ξ|ξ) dt ∈ (0, ∞), and given the number\nspring with mean H(ξ) =\nof oﬀspring their locations are independently and identically distributed\nwith probability density f (·) = h(·|ξ)/H(ξ) on ξ + ˜X (with respect to\nLebesgue measure). We shall assume the intensity function h(·|·) to be\njointly measurable in its arguments, as well as integrable so that H(ξ) < ∞\nfor all ξ ∈ X . As in Dasgupta and Raftery (1998), van Lieshout (1995) and\nvan Lieshout and Baddeley (1995), scatter noise and outliers – also known\nas orphans – are modelled by a Poisson point process of constant inten-\nsity % > 0 independently of all Zξ. This ﬁts into the germ–grain frame-\nwork of Section 4.2.1 by introducing an extra dummy or ‘ghost’ parent\nx0. We shall write h(·|x0) ≡ %, and denote its integral over X ⊕ ˜X by\n\n\fSPATIAL CLUSTER PROCESSES\n\n69\n\nH(x0). By the superposition property of Poisson processes, conditional on\nX = x = { x1, . . . , xn}, the combined oﬀspring form a Poisson point pro-\ncess on X ⊕ ˜X with intensity function\n\nλ(· | x) = % +\n\nn(cid:6)\n\ni=1\n\nh(·|xi)\n\n(4.4)\n\nwith the convention that h(t|xi) = 0 if t (cid:18)∈ xi + ˜X , i = 1, . . . , n. The\nmarginal distribution of U is that of a Cox point process Stoyan et al.",
    "chunk_order_index": 41,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-610f7bcaaf9a1b34514b87e2b80d4a4f": {
    "tokens": 1200,
    "content": "on X ⊕ ˜X with intensity function\n\nλ(· | x) = % +\n\nn(cid:6)\n\ni=1\n\nh(·|xi)\n\n(4.4)\n\nwith the convention that h(t|xi) = 0 if t (cid:18)∈ xi + ˜X , i = 1, . . . , n. The\nmarginal distribution of U is that of a Cox point process Stoyan et al.\n(1995). Often, the intensity function h(t|ξ) will depend only on the distance\nd(ξ, t) between ξ and t. An example is\n\n(cid:7)\n\nh(t|ξ) =\n\nµ\n0\n\nif d(ξ, t) ≤ Rh\notherwise\n\n(4.5)\n\nwhich, if X is also a Poisson process, is known as the Mat´ern cluster process\n(Mat´ern 1986). Another interesting special case is (for d = 2, say)\n\nh(t|ξ) =\n\nµ\n\n2πσ2 e−d(ξ,t)2/2σ2\n\n.\n\n(4.6)\n\nAccording to (4.6), the daughters follow an isotropic Gaussian distribution\nwith centre ξ. Again if X is a Poisson process, the distribution of U is called\nthe modiﬁed Thomas process. More generally, the spread σ may depend on\nξ. For further details, consult Diggle (1983), Daley and Vere-Jones (1988),\nor Stoyan et al. (1995). For a Cox cluster process, conditional on X =\nx = { x1, . . . , xn} and the number m of oﬀspring, the points are drawn\nindependently from a ﬁnite mixture distribution (Hand 1981, Titterington\net al. 1985) with n + 1 component distributions determined by the xi and\nweights\n\npi =\n\nH(xi)\n(cid:8)\nn\ni=0 H(xi)\n\n,\n\ni = 0, . . . , n.\n\nIf the intensity function h is translation invariant in the sense that h(t +\nξ|ξ) = h(t|0) for all ξ ∈ X – a common assumption in our spatial context\n– the weights are identical for all parents except the ghost, a rather unnat-\nural restriction in the ﬁnite mixture context. Furthermore, the connection\nwith mixture distributions is lost when the clusters are not Poisson pro-\ncesses. To conclude this section, note that some parents may be childless.\nIn particular, if the clusters Zξ are Poisson processes, they have a positive\nprobability of being empty. If in a particular application there is no interest\nin such parents, one could condition each Zξ on { Zξ (cid:18)= ∅}, or consider only\nthose parents having at least one daughter.\n\n4.3.3 Cluster Formation Densities\n\nIn order to be able to draw inference about parents and cluster membership,\nwe need the (posterior) distribution of W = { (x0, Z0), . . . , (Xn, Zn)}, i.e.\n\n\f70\n\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\n\nof parents Xi marked by their associated grain Zi, i = 0, . . . , n. We will\ntake a Bayesian approach based on\n\npW |U ({(xi, zi)}\n\ni≤n\n\n| u) ∝ P (z0, . . . , zn | x0, . . . , xn, u) pX|U (x | u)\n(4.7)\n\n= c(u) P (z0, . . . , zn | x0, . . . , xn, u) pU |X (u | x) pX (x),\nthe posterior density of W with respect to a unit rate Poisson process\non X marked at ξ ∈ X by a label in P(u − ξ) according to the uniform\ndistribution on the power set of u translated back to the origin. The term\npX (x) is the prior density for X with respect to the distribution of a unit\nrate Poisson process on X , and c(u) a normalising constant depending on\nthe ‘data’ u. If only the cluster centres are of interest, the posterior density\nof X (with respect to the distribution of a unit rate Poisson process on X )\nmay be used instead:\n\npX|U (x | u) = c(cid:2)(u) pU |X (u | x) pX (x).\nWe will discuss the choice of prior later on and here describe only the\n‘forward terms’ of cluster formation. Firstly, recall from Section 4.3.1 that\nconditional on X = x = {x1, . . . , xn}, the grains Z1, . . . , Zn associated\nwith x1, . . . , xn respectively are independent with distributions that are\nabsolutely continuous with respect to a unit rate Poisson process on ˜X .\nThus, the conditional joint density of (Z1, . . . , Zn) equals\n\n(4.8)\n\nn(cid:9)\n\ni=1\n\ng(zi|xi)\n\nwith respect to the n-fold product measure of unit rate Poisson processes on\n˜X . The orphans Z0 are modelled as a Poisson process of rate % > 0. Again\nconditioning on X = x, the superposition U is absolutely continuous with\nrespect to the distribution of a unit rate Poisson process on X ⊕ ˜X . Its\ndensity at u = {u1, . .",
    "chunk_order_index": 42,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-6fcf43af02963df135b33bd51eb3f916": {
    "tokens": 1200,
    "content": "9)\n\ni=1\n\ng(zi|xi)\n\nwith respect to the n-fold product measure of unit rate Poisson processes on\n˜X . The orphans Z0 are modelled as a Poisson process of rate % > 0. Again\nconditioning on X = x, the superposition U is absolutely continuous with\nrespect to the distribution of a unit rate Poisson process on X ⊕ ˜X . Its\ndensity at u = {u1, . . . , um} can be found by summing over all partitions\nin sibling clusters\n\npU |X (u | x) = e(1−(cid:17))|X ⊕ ˜X |−n| ˜X |×\n\n(4.9)\n\n(cid:6)\n\nϕ\n\n%n(uϕ−1({0}))\n\nn(cid:9)\n\ni=1\n\ng(uϕ−1({i}) − xi|xi)1{uϕ−1({i}) − xi ⊆ ˜X }\n\nwhere the sum ranges over all possible oﬀspring-to-parent assignment func-\ntions ϕ : { 1, . . . , m} → {0, . . . , n}, uϕ−1({i}) = {uj : ϕ(j) = i} consists of\nthose uj ascribed to parent xi by ϕ, and n(·) denotes cardinality. Equation\n(4.9) is most readily derived using Janossy densities (page 122 Daley and\nVere-Jones 1988). The details can be found in lemma 23 of van Lieshout\n(1995). Note that (4.9) can be expressed as\nn(cid:9)\n\n(cid:6)\n\ne(1−n−(cid:17))|X ⊕ ˜X |\n\n%n(uϕ−1({0}))\n\ng(cid:2)(uϕ−1({i}) − xi|xi)\n\nϕ\n\ni=1\n\n\fSPATIAL CLUSTER PROCESSES\n71\nwhere g(cid:2)(· − xi|xi) = e|X ⊕ ˜X |−| ˜X |g(· − xi|xi)1{· − xi ⊆ ˜X } is a density of the\ntranslated typical grain with respect to a unit rate Poisson process on X ⊕\n˜X . Next, consider the conditional distribution of the complete model given\nthe cluster centres x1, . . . , xn. Since we already derived the conditional joint\ndensity of (Z1, . . . , Zn), an identiﬁcation\n\n(Z n, πn\n\nZ , A) ↔ (NX ×Z , ξx, B)\n\nof grain vectors (z1, . . . , zn) ∈ Z n with the marked point conﬁguration\n{ (x1, z1), . . . , (xn, zn)} ∈ NX ×Z is needed. Here Z = N ˜X is the grain\nspace (cf. Section 4.2.1) consisting of all ﬁnite point conﬁgurations, πn\nZ\nis the n-fold product measure of unit rate Poisson processes on ˜X , A is\nthe usual Borel product σ-algebra of the weak topology (Daley and Vere-\nJones 1988), and B the Borel σ-algebra of the weak topology on marked\npoint patterns. To do so, deﬁne a measurable bijection ix (in the sense that\nthe complement of the range of ix has measure zero under ξx) depending\non the parent pattern x = { x1, . . . , xn} by\n\nix : (z1, . . . , zn) (cid:26)→ { (x1, z1), ...(xn, zn)} .\n\nUsing the identiﬁcation thus deﬁned, the measure ξx is given by ξx(B) =\nZ (i−1\nx (B)) for all B ∈ B. Finally, the conditional distribution of W or\nπn\nequivalently the marks Zi given (X, U ) is discrete, with probabilities\n\nP (z0, . . . zn | x0, . . . , xn, u) =\nϕ %n(uϕ−1({0})) (cid:10)\n\n(cid:8)\n\nn\n\n%n(z0)\n\n(cid:10)\n\nn\n\ni=1 g(zi|xi)\n\n(4.10)\n\ni=1 g(uϕ−1({i}) − xi|xi)1{uϕ−1({i}) − xi ⊆ ˜X }\n\nprovided the union ∪i(xi + zi) equals u. If g(· − ξ|ξ) is hereditary (cf.\nSection 4.4.1) for each ξ ∈ X , the sum in the denominator of (4.10) over\nall functions ϕ ascribing parents to each oﬀspring, is non-zero. Otherwise,\nwe have to impose the condition that the grain partition and (X, U ) are\ncompatible, in the sense that there exists at least one ϕ for which the\nterm %n(uϕ−1({0})) (cid:10)\ni=1 g(uϕ−1({i}) − xi|xi)1{uϕ−1({i}) − xi ⊆ ˜X } is strictly\npositive (Van Lieshout 1995, theorem 29). For Cox cluster processes, the\nformulae (4.7)–(4.10",
    "chunk_order_index": 43,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-8b60ad872397fc4df544c2882845a6e3": {
    "tokens": 1200,
    "content": "that there exists at least one ϕ for which the\nterm %n(uϕ−1({0})) (cid:10)\ni=1 g(uϕ−1({i}) − xi|xi)1{uϕ−1({i}) − xi ⊆ ˜X } is strictly\npositive (Van Lieshout 1995, theorem 29). For Cox cluster processes, the\nformulae (4.7)–(4.10) can be greatly simpliﬁed. Since Zξ has density\n\nn\n\n(cid:11)(cid:12)\n\n(cid:11)(cid:12)\n\ng(z|ξ) = exp\n\n(1 − h(t + ξ|ξ)) dt\n\n˜X\n\nh(z + ξ|ξ)\n\nwith respect to a unit rate Poisson process on ˜X , (4.9) reduces to\n\npU |X (u | x) = exp\n\n= exp\n\n(1 − λ(t | x)) dt\n\n(1 − λ(t | x)) dt\n\nX ⊕ ˜X\n\n(cid:11)(cid:12)\n\nX ⊕ ˜X\n\nn(cid:9)\n\n(cid:9)\n\ni=0\n\nt∈uϕ−1({i})\n\nh(t|xi)\n\nλ(uj | x)\n\n(4.11)\n\n(cid:13) (cid:9)\n\nz∈z\n\n(cid:13) (cid:6)\n\nϕ\n\n(cid:13) m(cid:9)\n\nj=1\n\n\f72\n\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\n\ncoding h(·|x0) ≡ % for the dummy parent x0. Thus, (4.11) is in accordance\nwith the fact that the independent superposition of Poisson processes is\nagain a Poisson process, here with intensity λ(· | x) (cf. (4.4) and the\ndiscussion in Section 4.3.2). As for the oﬀspring labelling, (4.10) for a Cox\ncluster process equals\n\nP (z0, . . . , zn | x0, . . . , xn, u) =\n\n(cid:10)\n\n(cid:10)\n\nn\ni=0\n\n(cid:10)\n\nt∈zi h(t + xi|xi)\nj=1 λ(uj | x)\n\nm\n\n(4.12)\n\nwhenever ∪i(xi + zi) = u, see van Lieshout and Baddeley (1995) or corol-\nlary 30 in van Lieshout (1995). In terms of the label allocation function\nϕ : {1, . . . , m} (cid:26)→ {0, 1, . . . , n} allocating each daughter point to its parent,\nequation (4.12) implies that the daughters are ascribed to a cluster centre\nxI independently of one another, with probabilities\n\nP (ϕ(j) = I) =\n\nh(uj|xI )\nλ(uj | x)\n\n.\n\nThe analogue of this result for ﬁnite mixtures with m and n ﬁxed was\ncalled the Random Imputation Principle by Deibolt and Robert (1994).\nIt was taken as an assumption by Binder (1978) (see page 32). Note the\nstatement holds only for Cox cluster processes, i.e. when the clusters are\nPoisson.\n\n4.4 Bayesian Cluster Analysis\n\nFrom Section 4.2.2, recall that the prime object of spatial cluster analysis\nis to evaluate conditional expectations of quantities such as the number of\nclusters and the mean number of points per cluster based on the posterior\ndistribution (4.7) of the complete data W given y. In the previous section,\nwe derived the densities associated with cluster formation. In Section 4.4.1\nbelow, we discuss the prior, and investigate properties of the posterior dis-\ntribution in Section 4.4.2. Then we turn to the problems of generating real-\nisations of (4.7) by Markov chain Monte Carlo methods, and of estimating\nthe model parameters (Sections 4.4.3–4.4.4). In Section 4.4.5, we propose\nan adaptive coupling from the past algorithm that yields exact samples\nfrom (4.7). Throughout, the redwood data set (Strauss 1975, Ripley 1977)\nis used as an illustration.\n\n4.4.1 Markov Point Processes\n\nIn this section we focus on the prior term pX (x) in (4.7), which we shall\nassume to be the density of a Markov point process (Ruelle 1969, Preston\n1976, Ripley 1977, Ripley 1988, Baddeley and Møller 1989, van Lieshout\n2000). Following is a brief summary of the facts we need. Let X be a point\nprocess on a compact subset X ⊆ Rd of positive volume, whose distribution\n\n\fBAYESIAN CLUSTER ANALYSIS\n\n73\n\nis absolutely continuous with respect to a unit rate Poisson process on X ,\nsay with density pX (·). Then X is Markov at range R in the sense of Ripley\n(1977) if the ratio\n\nλX (ξ; x) =\n\npX (x ∪ {ξ})\npX (x)\n\n(4.13)\n\nis well-deﬁned for all ξ ∈ X (i.e. pX (x ∪ {ξ}) = 0 implies pX (x) = 0; in this\ncase we will also say that pX",
    "chunk_order_index": 44,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-75bb3377215c5103496c8d9d91da64dd": {
    "tokens": 1200,
    "content": "). Then X is Markov at range R in the sense of Ripley\n(1977) if the ratio\n\nλX (ξ; x) =\n\npX (x ∪ {ξ})\npX (x)\n\n(4.13)\n\nis well-deﬁned for all ξ ∈ X (i.e. pX (x ∪ {ξ}) = 0 implies pX (x) = 0; in this\ncase we will also say that pX (·) is hereditary) and depends only on those\nxi ∈ x for which d(xi, ξ) ≤ R. More generally, the ﬁxed range dependence\nmay be replaced by an arbitrary symmetric neighbourhood relation ∼ (so\nthat (4.13) depends on xi ∼ ξ only). Even more general Markov point\nprocesses are considered by Baddeley and Møller (1989), and the Marko-\nvianity of spatial cluster processes is studied in Baddeley et al. (1996). A\n(Markov) point process deﬁned by its density with respect to a unit rate\nPoisson process is said to be locally stable if its conditional intensity (4.13)\nis well-deﬁned and uniformly bounded in both its arguments. To model\npatterns in which the points tend to avoid coming too close together, it is\nconvenient to consider pairwise-interaction processes with densities of the\nform\n\n(cid:9)\n\n(cid:9)\n\npX (x) = α\n\nβ(x)\n\nx∈x\n\nx∼x(cid:4)∈x\n\nγ(x, x(cid:2))\n\n(4.14)\n\nwhere β : X → [0, ∞) (the ‘intrinsic activity’) and γ : X × X → [0, ∞) (the\n‘pairwise interaction’) are measurable functions, γ is symmetric, and α > 0\nis the normalising constant. This model is well-deﬁned (i.e. the density is\nintegrable) at least whenever β(·) is uniformly bounded and γ(·, ·) ≤ 1.\nA standard example of (4.14) is the Strauss process (Strauss 1975) with\nβ(·) ≡ β > 0 and\n\n(cid:7)\n\nγ\n1\nwhere 0 ≤ γ ≤ 1, which has density\n\nγ(x, x(cid:2)) =\n\nif d(x, x(cid:2)) ≤ R\notherwise\n\n(4.15)\n\npX (x) = αβn(x)γs(x)\nwhere n(x) is the number of points in x and s(x) is the number of pairs\nx, x(cid:2) with d(x, x(cid:2)) ≤ R. The model favours realisations x that tend to have\nmore points at distances larger than R than under the Poisson model, that\nis there is repulsion between the points. The special case γ = 0 in which no\nR-close point pairs are permitted is known as the hard core process; γ = 1\ncorresponds to a Poisson process with intensity β. More formally, a point\nprocess density pX (·) is called anti-monotone (or repulsive) if\n\nλX (ξ; x(cid:2)) ≤ λX (ξ; x)\nfor all ξ whenever x ⊆ x(cid:2) and monotone (or attractive) if its conditional\nintensity satisﬁes\n\nλX (ξ; x(cid:2)) ≥ λX (ξ; x).\n\n\f74\n\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\n\nThe reader may verify that the Strauss process is repulsive for all γ ≤ 1.\n\n4.4.2 Sampling Bias for Independent Cluster Processes\n\nNote that the restriction Y of an independent cluster process U to some\ncompact observation window A is itself an independent cluster process.\nIndeed,\n\n(cid:2)\n\n(cid:2)\n\nY = U ∩ A =\n\n(x + Zx) ∩ A =\n\n(x + (Zx ∩ (A − x))).\n\nx∈X\n\nx∈X\n\nThe distribution Qξ,A of the grain Zξ ∩ (A − ξ) associated with ξ in the\nA-clipped process has density\n\ngA(z|ξ) =\n\n∞(cid:6)\n\nk=0\n\n1\nk!\n\n(cid:12)\n\n(cid:12)\n\n· · ·\n\n( ˜X \\(A−ξ))k\n\ng(z ∪ { v1, . . . , vk} |ξ) dv1 . . . dvk (4.16)\n\nwith respect to a unit rate Poisson process on ˜X . It follows that the pos-\nterior distribution of X given Y is analogous to (4.8), except for the fact\nthat gA(·|·) features instead of g(·|·). As before, a ghost parent is added to\naccount for scatter noise. For Cox cluster processes, (4.16) simpliﬁes to\n\n(cid:11)(cid:12)\n\ngA(z|ξ) = exp\n\n˜X\n\n(1 − h(t + ξ|ξ) 1{t ∈ A − ξ}) dt\n\nh(z + ξ|ξ)\n\n(cid:13) (cid:9)\n\nz∈z\n\nfor z ⊆ A − ξ, the density of a Poisson point process with intensity function\nh(· + ξ|ξ) 1{· ∈ A − ξ}. Hence, conditionally on X = x = {x1, . . . , xn}, Y\nis an inhom",
    "chunk_order_index": 45,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-a18be86cbd7e413424c227be956d4e6d": {
    "tokens": 1200,
    "content": "|ξ) 1{t ∈ A − ξ}) dt\n\nh(z + ξ|ξ)\n\n(cid:13) (cid:9)\n\nz∈z\n\nfor z ⊆ A − ξ, the density of a Poisson point process with intensity function\nh(· + ξ|ξ) 1{· ∈ A − ξ}. Hence, conditionally on X = x = {x1, . . . , xn}, Y\nis an inhomogeneous Poisson process on A with intensity function\n\nλ(a | x) = % +\n\nn(cid:6)\n\ni=1\n\nh(a|xi),\n\na ∈ A,\n\nwhere % > 0 is the background clutter term (cf. Section 4.3.2). As for the\nprior, one could simply assume the parents to be distributed as a Poisson\npoint process, but it seems more natural to incorporate repulsion at short\nrange to avoid ‘over ﬁtting’ in the sense of many close parents. Thus, one\nmight take as prior for example a hard core process (cf. Section 4.4.1) with\ndensity\n\npX (x) =\n\nif d(xi, xj) > R for all pairs\notherwise\nwith respect to a unit rate Poisson process on X . Upon observing Y = y =\n{y1, . . . , ym}, the analogue of (4.8) for the A-clipped process is\n\n(4.17)\n\nαβn(x)\n0\n\npX|Y (x | y) = c(y) pX (x) exp\n\n(cid:11)(cid:12)\n\nA\n\n(cid:13) m(cid:9)\n\n(1 − λ(a | x)) da\n\nj=1\n\nλ(yj | x)\n\n(4.18)\n\n(cid:7)\n\n\fBAYESIAN CLUSTER ANALYSIS\n\n75\n\nwhich has posterior conditional intensity\n\nλX|Y (ξ; x | y) = λX (ξ; x) exp\n\n−\n\n(cid:11)\n\n(cid:12)\n\n(cid:13) m(cid:9)\n\nh(a|ξ) da\n\nA\n\nj=1\n\n(cid:11)\n\n1 +\n\n(cid:13)\n\n.\n\nh(yj|ξ)\nλ(yj | x)\n\n(4.19)\nIf the prior density pX (·) is that of a repulsive Markov point process, the\nposterior distribution speciﬁed by (4.18) is hereditary and repulsive too.\nThe posterior range of interaction depends on the support of the family\nh(·|ξ), ξ ∈ X , of intensity functions. If furthermore the prior density pX (·)\nis locally stable with bound λ for its conditional intensity and h(·|·) is\nuniformly bounded in both its arguments by H, then λX|Y (ξ; x | y) ≤\nλ(1 + H/%)m implying local stability of (4.18).\n\n4.4.3 Spatial Birth-and-Death Processes\n\nIn this section, we address the problem of sampling from the posterior dis-\ntribution of the complete data W given partial observations Y = U ∩ A =\n{y1, . . . , ym} of a Cox cluster process U within some compact observa-\ntion window A. Note that since the oﬀspring allocation labels are discrete\nand distributed according to (4.12), and by the Poisson assumption any\ndaughters in Ac are conditionally independent of those in A, the problem\nreduces to sampling from the conditional distribution (4.18) of X given\nY . Since direct sampling does not seem feasible, we apply Markov chain\nMonte Carlo techniques. Perhaps the oldest such technique is based on\nspatial birth-and-death processes (Preston 1977), continuous time Markov\nprocesses whose transitions are either births or deaths. The traditional\nchoice (Ripley 1977, Baddeley and Møller 1989, Møller 1989) is to take a\nbirth rate proportional to the posterior conditional intensity and a constant\ndeath rate. Under mild non-explosion conditions, this procedure converges\nto the target distribution and hence yields approximate samples if run for\nlong enough (Preston 1977, Møller 1989). A disadvantage is that the total\nbirth rate is diﬃcult to compute, and the product over data points in (4.19)\nmay be very large. For these reasons, we prefer to work with the alternative\nbirth rate\n\n\n\n\n\nb(x, ξ) = λX (ξ; x)\n\n1 +\n\nm(cid:6)\n\nj=1\n\nh(yj|ξ)\n%\n\n\n\n(4.20)\n\nwhich is less peaked than the posterior conditional intensity, while retaining\nthe desirable property of placing most new-born points in the vicinity of\npoints of y. In order to satisfy the detailed balance equations\n\npX|Y (x | y) b(x, ξ) = pX|Y (x ∪ {ξ} | y) d(x ∪ {ξ} , ξ),\n\n\f76\n\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\n\n\n\nd(x ∪ {ξ} , ξ) =\n\nthe death rate for deleting ξ from conﬁguration x ∪ {ξ} is\n(cid:18)(cid:5)\n(cid:19)\nA h(a|ξ) da\n(cid:21)\n(cid:20)\n1 + h(yj |ξ)\nλ(yj |x)\nNote that for any locally stable prior distribution for which λX (ξ; x) ≤ λ\nuniformly in",
    "chunk_order_index": 46,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-7a67e6cf79cdedf5cefaf2b1a56a2a75": {
    "tokens": 1200,
    "content": "\n\nd(x ∪ {ξ} , ξ) =\n\nthe death rate for deleting ξ from conﬁguration x ∪ {ξ} is\n(cid:18)(cid:5)\n(cid:19)\nA h(a|ξ) da\n(cid:21)\n(cid:20)\n1 + h(yj |ξ)\nλ(yj |x)\nNote that for any locally stable prior distribution for which λX (ξ; x) ≤ λ\nuniformly in x and ξ, and any h(·|·) that is uniformly bounded in both its\narguments by H, the total birth rate\n\nh(yj | ξ)\n%\n\nexp\n(cid:10)\n\n1 +\n\n(4.21)\n\nm\nj=1\n\n .\n\nm(cid:6)\n\nj=1\n\n\n\n\n\n\n\nB(x) =\n\n(cid:12)\n\nX\n\nb(x, ξ) dξ ≤ λ\n\n|X | +\n\nh(yj|ξ) dξ\n\n := B\n\n(cid:12)\n\nm(cid:6)\n\nj=1\n\nX\n\n1\n%\n\nis bounded from above by a constant B ≤ λ|X |(1 + mH/%) that is easy to\nevaluate for typical choices of h(·|·) such as (4.5) or (4.6). The total death\nrate from parent conﬁguration x satisﬁes\n\n(cid:6)\n\nD(x) =\n\ni\n\nd(x, xi) ≥ n(x)(1 + H/%)−m.\n\nHence, by the Preston theorem (Preston 1977) (see e.g. Baddeley and\nMøller 1989, Møller 1989), there exists a unique spatial birth-and-death\nprocess with transition rates given by (4.20) and (4.21). It has unique equi-\nlibrium distribution pX|Y (· | y), to which it converges in distribution from\nany initial state. From an algorithmic point of view, if the current state is\nx, after an exponentially distributed sojourn time of rate B + D(x), with\nprobability D(x)/(B + D(x)) a point of x is deleted according to the dis-\ntribution d(x, xi)/D(x); a birth is proposed with the complementary prob-\nability B/(B + D(x)) by sampling a candidate ξ from the mixture density\nλ\n, which is then accepted with probability λX (ξ; x)/λ.\nB\n\nh(yj |ξ)\n(cid:17)\n\nm\nj=1\n\n1 +\n\n(cid:8)\n\n(cid:20)\n\n(cid:21)\n\nExample: Redwood Seedlings\n\nFigure 4.1 shows the locations of 62 redwood seedlings in a square of side ap-\nproximately 23 m. The data were extracted by (Ripley 1977) from a larger\ndata set in Strauss (1975). The K-function (Ripley 1979, Ripley 1981) for\nthese data is given in Ripley (1977) and suggests aggregation. As noted\nby Strauss this is caused by the presence of stumps known to exist in the\nplot, but whose position has not been recorded. Previous analyses of this\ndata set include that of Strauss (1975), who ﬁtted a model later criticised\nby Kelly and Ripley (1976). Ripley (1977) concluded we should reject the\nPoisson hypothesis and remarked that there appears to be both cluster-\ning and inhibition between clusters. Diggle (1983) ﬁtted a Poisson cluster\nprocess of Thomas type and reported least squares estimates (25.6, 0.042)\nfor the parent intensity and the standard deviation of daughter–parent dis-\ntances. A goodness of ﬁt test showed adequate ﬁt, but, from a biological\n\n\fBAYESIAN CLUSTER ANALYSIS\n\n77\n\n• •\n\n•\n\n• •\n\n•\n•\n\n•\n\n•\n\n•\n• •\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n• •\n\n•\n\n• • •\n\n•\n\n• •\n\n•\n•\n\n•\n\n••\n\n•\n\n•\n\n• •\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n•\n\n••\n•\n\n•\n\n••\n\nFigure 4.1 Positions of 62 redwood\nseedlings in a unit square\n\nFigure 4.2 Empirical log posterior par-\nent intensity surface based on a Cox–\nMat´ern cluster process with Rh = 0.061\nand on average 2.14 points per cluster,\nnoise intensity (cid:3) = 10.0 and a hard core\nprior with R = 0.03 and β = 1.0 by\nspatial birth-and-death over 2.0 × 104\ntime units. Black corresponds to high\nvalues, white to small ones\n\npoint of view, a mean number of 26 stumps seems implausible. In Diggle\n(1978), a Poisson cluster process of Mat´ern type was ﬁtted with similar\nresults (radius 0.061 and 29 clusters). None of the above have looked at\ncluster centre location. This was ﬁrst studied in Baddeley and van Lieshout\n(1993) and by Lawson (1993a) who ﬁtted a Poisson–Thomas cluster pro-\ncess and reported 16 parents. An approach based on variational methods\ncan be found in Van Lieshout et al. (2001). In earlier work (Baddeley and\nvan Lieshout 1993, van Lieshout 1995, van Lieshout and Baddeley 1995),\nwe analysed the redwood data using a modiﬁed Thomas displacement\nfunction",
    "chunk_order_index": 47,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-bb698f2c4eb6fb9960e605d1e25ad725": {
    "tokens": 1200,
    "content": "1993) and by Lawson (1993a) who ﬁtted a Poisson–Thomas cluster pro-\ncess and reported 16 parents. An approach based on variational methods\ncan be found in Van Lieshout et al. (2001). In earlier work (Baddeley and\nvan Lieshout 1993, van Lieshout 1995, van Lieshout and Baddeley 1995),\nwe analysed the redwood data using a modiﬁed Thomas displacement\nfunction (4.6) and a Strauss prior (4.15) with interaction distance 0.084\n(Diggle 1983) and log β = log γ = −10. Simulation was based on a con-\nstant death rate spatial birth-and-death process. Initialising with parame-\nter values µ = 7, σ = 0.042 and an empty list of cluster centres, we ran the\nbirth-and-death process for 2 time units and found maximum likelihood\nestimates µ = 6.5 and σ = 0.05. Here, we use the spatial birth-and-death\nprocess with rates (4.20)–(4.21) to sample from the posterior distribution of\ncluster centres for a Cox model with a Mat´ern style intensity function given\nby (4.5) with Rh = 0.061 and µ = 2.14/(πR2\nh) as in Diggle (1978), orphan\nintensity % = 10.0, and a hard core prior with R = 0.03 and β = 1.0. The\nposterior intensity surface of parents in X = [−Rh, 1.0+Rh]2 over 2.0×104\ntime units after a burn-in period of 200.0 units with empty initial state is\n\n \n \n\f78\n\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\n\nplotted in Figure 4.2; for the posterior histogram of the number of clusters,\nsee Figure 4.3 (right). To indicate the eﬀect of the choice of parameters,\nthe posterior histogram for β = 0.052 and an average cluster size of 4.3 is\nshown in Figure 4.3 (left). It can be seen that the latter choice shifts the\nposterior histogram towards fewer cluster centres.\n\n4\n.\n0\n\n3\n.\n0\n\n2\n.\n0\n\n1\n.\n\n0\n\n0\n0\n\n.\n\n5\n2\n.\n0\n\n0\n2\n.\n0\n\n5\n1\n.\n0\n\n0\n1\n.\n0\n\n5\n0\n\n.\n\n0\n\n0\n0\n\n.\n\n0\n\n5\n\n10\n\n15\n\n0\n\n5\n\n10\n\n15\n\n20\n\nFigure 4.3 (Left) Posterior histogram for the number of parents given the data\nof Figure 4.1 based on a Cox–Mat´ern cluster process with Rh = 0.061 and on\naverage 4.3 points per cluster, noise intensity (cid:3) = 10.0 and a hard core prior with\nR = 0.03 and β = exp(4.3 + 2.0 log((cid:3)/((cid:3) + µ)) by spatial birth-and-death over\n2.0 × 105 time units and (right) for on average 2.14 points and β = 1.0 over\n2.0 × 104 time units as in Figure 4.2.\n\n4.4.4 Parameter Estimation\n\nIn general, the independent cluster model g(·|·) will contain parameters θ\nthat must be estimated. For the Cox cluster model, the parameters are\nthe clutter intensity % as well as parameters of the displacement function\nh(·|·) specifying the shape, the spread and the number of daughters in\neach cluster. Moreover, the prior model pX (·) also contains parameters,\nbut since these are merely used as regularisation to avoid over ﬁtting, we\nwill treat these as ﬁxed. We shall use the Monte Carlo maximum likelihood\nmethod for missing data models (Gelfand and Carlin 1993, Geyer 1999).\nIn the context of detecting the centres in an independent cluster process,\nthe observed data consists of a point pattern y, the combined oﬀspring in\nthe window A. The missing data are both the parents and their associated\n\n\fBAYESIAN CLUSTER ANALYSIS\n\n79\n\ngrains. In terms of the cluster formation density derived in Section 4.3.3,\nthe log likelihood ratio with respect to a ﬁxed reference parameter θ0 can\nbe written as\n\nl(θ) = log Eθ0\n\n\n\nY = y\n\n\n\n(4.22)\n\n\n\nn(X)(cid:9)\n\ni=0\n\ngθ(Zi|Xi)\ngθ0(Zi|Xi)\n\n(cid:22)\n(cid:22)\n(cid:22)\n(cid:22)\n(cid:22)\n(cid:22)\n\n\n\nby importance sampling theory. The Monte Carlo analogue lk(θ) of (4.22)\nis obtained by replacing the expectation by the average in a sample W1, . . . ,\nWk from the complete model under the conditional distribution with pa-\nrameter θ0. Diﬀerentiating with respect to θ, the parameter of interest, we\nobtain\n\n∇lk(θ) =\n\n1\nk\n\nk(cid:6)\n\nj=1\n\nwj,θ0,θ\n\n∇\n\n(cid:20)(cid:10)\n\n(cid:21)\n(Xi,Zi)∈Wj gθ(Zi",
    "chunk_order_index": 48,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-21abceff4562a2e6e5724029746c75bf": {
    "tokens": 1200,
    "content": ", . . . ,\nWk from the complete model under the conditional distribution with pa-\nrameter θ0. Diﬀerentiating with respect to θ, the parameter of interest, we\nobtain\n\n∇lk(θ) =\n\n1\nk\n\nk(cid:6)\n\nj=1\n\nwj,θ0,θ\n\n∇\n\n(cid:20)(cid:10)\n\n(cid:21)\n(Xi,Zi)∈Wj gθ(Zi|Xi)\n(Xi,Zi)∈Wj gθ(Zi|Xi)\n\n(cid:10)\n\n(4.23)\n\nwhere\n\nwj,θ0,θ =\n\n\n\n\n\n(cid:9)\n\n(Xi,Zi)∈Wj\n\ngθ(Zi|Xi)\ngθ0(Zi|Xi)\n\n\n\n /\n\n\n 1\nk\n\nk(cid:6)\n\n(cid:9)\n\nj=1\n\n(Xi,Zi)∈Wj\n\n\n\n\n\ngθ(Zi|Xi)\ngθ0(Zi|Xi)\n\nare the importance weights. The well-known EM algorithm (Dempster et\nal. 1977b) is an iterative procedure based on (4.23) that consists of two\nsteps: the E-step computes the conditional log likelihood given the data\nand current estimates of the parameters, the M-step maximises the result\nwith respect to the parameter. Thus, the importance weights reduce to 1,\nbut resampling is needed at each step. For a critical evaluation of these\nand other parameter estimation methods, the reader is referred to Geyer\n(1999); see also Diggle et al. (1994), Geyer and Møller (1994) and Huang\nand Ogata (2001). For Cox cluster processes, (4.22) simpliﬁes to\n(cid:22)\n(cid:22)\n(cid:22)\n(cid:22)\n(cid:22)\n(cid:22)\n\nhθ(t|Xi)\nhθ0(t|Xi)\n\nl(θ) = log Eθ0\n\n(Xi)−Hθ(Xi))\n\ni=0 (Hθ0\n\nY = y\n\n(cid:8) n(X)\n\nn(X)(cid:9)\n\n e\n\n(cid:9)\n\n\n\n\n\n\n\ni=0\n\nt∈Xi+Zi\n\nhence the Monte Carlo score vector (4.23) is\n\n∇lk(θ) =\n\n\n\nwj,θ0,θ\n\n1\nk\n\nk(cid:6)\n\nj=1\n\n(cid:6)\n\n[−∇Hθ(Xi) +\n\n(cid:6)\n\n(Xi,Zi)∈Wj\n\nt∈Xi+Zi\n\n\n\n\n∇ log hθ(t|Xi)]\n\n\n\nwhere as before {Wj} is a sample of size k from the conditional distribution\nof the complete data given y under the reference parameter θ0, and wj,θ0,θ\nare the importance weights.\n\n\f80\n\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\n\nExample: Cox–Mat´ern Cluster Process\nConsider the Cox–Mat´ern cluster process on R2 with oﬀspring governed\nby (4.5) and independent Poisson background clutter. Treating the range\nRh as ﬁxed, the parameter vector is θ = (%, µ). The grain is a ﬁnite point\nprocess on ˜X = B(0, Rh), and H(ξ) = µπR2\nh for each genuine parent\nξ ∈ X . For the dummy parent, H(x0) = %|X ⊕ B(0, Rh)|. If X is a convex\nset, the Steiner formula may be used to ﬁnd an explicit expression of this\narea, see Section 4.2.3. By diﬀerentiation with respect to the parameter\nvector, it follows that the components of ∇lk(θ) are the weighted averages\nn(Wj )\n0)/% and −n(Wj) π R2\nof −|X ⊕ B(0, Rh)| + n(Z j\ni=1 n(Z j\ni )/µ where\nn(Wj) denotes the number of genuine parents in Wj, and Z j\n0 its orphan\ncluster. The EM-updates are easily derived:\n\nh +\n\n(cid:8)\n\n%(n+1) =\n\nµ(n+1) =\n\n;\n\n(cid:20)(cid:8)\n\nEθ(n) [n(Z0) | Y = y]\n|X ⊕ B(0, Rh)|\nn(X)\ni=1 n(Zi) | Y = y\nhn(X) | Y = y]\n\nEθ(n) [πR2\n\nEθ(n)\n\n(cid:21)\n\n.\n\nFor the example on redwood seedlings (Section 4.4.3) with a unit rate\nhard core prior at range 0.03 and reference parameter vector (10.0, 183.06)\nas in Figure 4.2, the Monte Carlo log likelihood ratio for % ∈ (5, 30) and\nµπR2\n∈ (1.14, 7.14) is given in Figure 4.4; the solution of the Monte Carlo\nh\nscore equations is (ˆ%100, ˆµ100) = (19.65, 354.15). For comparison, the Monte\nCarlo EM-up",
    "chunk_order_index": 49,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-87f8887881784dfdec46ac9127ceee02": {
    "tokens": 1200,
    "content": "183.06)\nas in Figure 4.2, the Monte Carlo log likelihood ratio for % ∈ (5, 30) and\nµπR2\n∈ (1.14, 7.14) is given in Figure 4.4; the solution of the Monte Carlo\nh\nscore equations is (ˆ%100, ˆµ100) = (19.65, 354.15). For comparison, the Monte\nCarlo EM-updates would be % = 15.12 and µ = 311.61 corresponding to\n3.64 daughters on average in a cluster.\n\n4.4.5 Adaptive Coupling from the Past\n\nRemarkably, the spatial birth–and–death approach described in Section\n4.4.3 can be adapted to yield an exact sample from the desired posterior\ndistribution using coupling from the past (Propp and Wilson 1996, Kendall\nand Møller 2000). Such algorithms are particularly eﬃcient when there is\nsome monotonicity in the state space, and the sampler respects this order.\nIn the context of this chapter, the prior distribution of X is a repulsive\nMarkov point process. Whether the same is true for the posterior distri-\nbution depends on the grain distributions Qξ. However, for Cox cluster\nprocesses, we showed in Section 4.4.2 that the posterior distribution is re-\npulsive and hereditary too. Moreover, (4.20)–(4.21) reverse the inclusion\nordering in the sense that if x ⊆ x(cid:2) then b(x, ξ) ≥ b(x(cid:2), ξ) for all ξ ∈ X ,\nwhile d(x, xi) ≤ d(x(cid:2), xi) for xi ∈ x. Our proof can be found in Section 4.9.3\nof van Lieshout (2000). If the displacement functions h(·|·) are uniformly\nbounded by H, the posterior inherits local stability from the prior. Such\nproperties are particularly pleasing for Bayesian analysis, as they imply\n\n\fBAYESIAN CLUSTER ANALYSIS\n\n81\n\n7\n\n6\n\n5\n\n4\n\n30\n\n25\n\n20\n\n15\n\n3\n\n2\n\n10\n\n5\n\nFigure 4.4 Monte Carlo log likelihood ratio surface as a function of the noise\nintensity (cid:3) ∈ (5, 30) and the mean cluster size µπR2\nh ∈ (1.14, 7.14) for the redwood\nseedlings data (Figure 4.1) based on a Cox–Mat´ern cluster process with Rh =\n0.061 and reference parameter values such that the average number of points per\ncluster is 2.14, the noise intensity (cid:3) = 10.0. We used a hard core prior with\nR = 0.03 and β = 1.0. One hundred realisations were subsampled from a run of\na spatial birth-and-death process over 2.0 × 104 time units after burn-in.\n\nthat the choice of prior is not crucial in these respects. Hence the coupling\nfrom the past algorithm of Kendall and Møller (2000) for locally stable\npoint processes in principle applies. Those authors presented their method\nfor the constant death rate dynamics, with a dominating process that is\nPoisson with an upper bound to the conditional intensity of the distribu-\ntion to be sampled as intensity. In our context, such a method would be\nimpractical, as in most cases the upper bound will be orders of magnitude\ntoo large. For this reason, we present an adaptive coupling from the past\nalgorithm based on (4.20)–(4.21). Suppose a spatial birth-and-death pro-\ncess with transition rates b(·, ·) and d(·, ·) is available to sample from the\nposterior density of cluster centres pX|Y (· | y), and we have upper and\n\n\f82\n\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\n\nlower bounds\n\nb(x, ξ) ≤ ¯b(ξ)\n(4.24)\nd(x ∪ {ξ} , ξ) ≥ d(x ∪ {ξ} , ξ)\n(4.25)\nholding for all conﬁgurations x and all ξ ∈ X . Suppose furthermore a\nunique probability density π(·) solving the detailed balance equations\n\nπ(x) ¯b(ξ) = π(x ∪ {ξ}) d(x ∪ {ξ} , ξ)\nexists. For the classical constant death rate process, d(x ∪ {ξ} , ξ) ≡ 1, ¯b(ξ)\nis an upper bound to the posterior conditional intensity at ξ that does\nnot depend on the conﬁguration to which ξ is added, and π(·) deﬁnes an\ninhomogeneous Poisson process with intensity function ¯b(·). The generic\nadaptive choice in our context is\n(cid:11)\n\n(cid:11)\n\n(cid:11)\n\n(cid:13)\n\n(cid:13)\n\n(cid:12)\n\n(cid:13) m(cid:9)\n\n¯b(ξ) = λ exp\n\n−\n\nh(a|ξ)da\n\nA\n\nj=1\n\n1 +\n\nh(yj|ξ)\n%\n\n≤ λ\n\nm(cid:9)\n\n1 +\n\nj=1\n\nh(yj|ξ)\n%\n\nwhere λ is the prior local stability bound. If a uniform bound is required\n(Chapter 5), the right hand side above may be replaced by\n\n(cid:11)\n\nλ sup\nξ∈X\n\nm(cid:9)\n\nj=1\n\n1",
    "chunk_order_index": 50,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-c6f002571f5925a904d98d22d233e3d0": {
    "tokens": 1200,
    "content": "exp\n\n−\n\nh(a|ξ)da\n\nA\n\nj=1\n\n1 +\n\nh(yj|ξ)\n%\n\n≤ λ\n\nm(cid:9)\n\n1 +\n\nj=1\n\nh(yj|ξ)\n%\n\nwhere λ is the prior local stability bound. If a uniform bound is required\n(Chapter 5), the right hand side above may be replaced by\n\n(cid:11)\n\nλ sup\nξ∈X\n\nm(cid:9)\n\nj=1\n\n1 +\n\nh(yj|ξ)\n%\n\n(cid:13)\n\n.\n\nSimilarly, for the transition rates given by (4.20)–(4.21), generic bounds\nare\n\n\n\n\n\n¯b(ξ) = λ\n\n1 +\n\nm(cid:6)\n\nj=1\n\nh(yj|ξ)\n%\n\n\n\nand\n\nd(x ∪ {ξ}, ξ) = exp\n\n(cid:13)\nh(a|ξ) da\n\n\n\n1 +\n\n(cid:11)(cid:12)\n\nA\n\nm(cid:6)\n\nj=1\n\nh(yj|ξ)\n%\n\n\n\n /\n\n(cid:11)\n\nm(cid:9)\n\nj=1\n\n1 +\n\nh(yj|ξ)\n%\n\n(cid:13)\n\n.\n\n(cid:5)\n\n(cid:10)\n\nA h(a|ξ) da\n\nThe corresponding equilibrium distribution is that of a Poisson process with\nintensity function λe−\nm\n. However, one may of-\nj=1\nten do better by exploiting speciﬁc model characteristics, as we shall il-\nlustrate in Section 4.4.6 below. If we couple the spatial birth-and-death\nprocess deﬁned by ¯b(·) and d(·, ·) to processes deﬁned by b(·, ·) and d(·, ·)\nas in Kendall and Møller (2000), we obtain the following algorithm.\n\n(cid:20)\n1 + h(yj |ξ)\n\n(cid:21)\n\n(cid:17)\n\nAlgorithm 1 Let Vt,ξ, t ≤ 0, ξ ∈ X , be a family of independent, uniformly\ndistributed random variables on (0, 1). Initialise T = 1, and let D(0) be a\nsample from π(·). Repeat\n• extend D(·) backwards until time −T by means of a spatial birth-and-\n\ndeath process with birth rate ¯b(·) and death rate d(·, ·);\n\n\fBAYESIAN CLUSTER ANALYSIS\n83\n• generate a lower process L−T (·) and an upper process U−T (·) on [−T, 0]\n\nas follows:\n\n– initialise L−T (−T ) = ∅, U−T (−T ) = D(−T );\n– to each forward transition time t ∈ (−T, 0] of D(·) correspond updates\n\nof the upper and lower processes;\n\n– in case of a death (i.e. a backwards birth), say D(t) = D(t−) \\ {d}\nwhere D(t−) denotes the state just prior to time t, the point d is\ndeleted from L−T (t−) and U−T (t−) as well;\n\n– in case of a birth, say D(t) = D(t−) ∪ {ξ}, the point ξ is added to\n\nU−T (t−) only if\n(cid:7)\n\nVt,ξ ≤ max\n\nb(x, ξ) d(x ∪ {ξ} , ξ)\n¯b(ξ) d(x ∪ {ξ} , ξ)\n\n: L−T (t−) ⊆ x ⊆ U−T (t−)\n\n.\n\n!\n\nsimilarly, ξ is added to L−T (t−) only if Vt,ξ does not exceed the above\nexpression with a minimum instead of a maximum;\n\n• if U−T (0) = L−T (0), return the common value U−T (0); otherwise set\n\nT := 2T ;\n\nuntil the upper and lower processes have coalesced.\n\nThe next theorem gives conditions for algorithm 1 to output unbiased\n\nsamples from the posterior distribution of cluster centres.\n\nTheorem 1 Let pX (·) be an anti-monotone, locally stable Markov point\nprocess density with respect to a unit rate Poisson process on a compact\nset X ⊆ Rd, and h(·|·) a uniformly bounded displacement function of a\nCox cluster process U observed in a bounded window A. Suppose the birth\nrates b(·, ·) and death rates d(·, ·) deﬁne a unique spatial birth-and-death\nprocess converging in distribution to the posterior density of cluster cen-\ntres pX|Y (· | y), and there exist upper and lower bounds (4.24)–(4.25)\nalso deﬁning a unique spatial birth-and-death process that converges in\ndistribution to a probability density π(·) for which π(∅) > 0 and detailed\nbalance between births and deaths holds. Then the coupling from the past\nalgorithm 1 almost surely terminates and outputs an unbiased sample from\npX|Y (· | y).\n\nThe proof is an adaptation to the inhomogeneous case of the proof in\n\nKendall and Møller (2000).\nProof. First, note that by assumption the dominating process D(·) is in\nequilibrium, its distribution being deﬁned by π(·). Clearly, for all T > 0,\n∅ = L−",
    "chunk_order_index": 51,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-d3a3e4d0fd8f4c100019f1f4cc4d742a": {
    "tokens": 1200,
    "content": "from the past\nalgorithm 1 almost surely terminates and outputs an unbiased sample from\npX|Y (· | y).\n\nThe proof is an adaptation to the inhomogeneous case of the proof in\n\nKendall and Møller (2000).\nProof. First, note that by assumption the dominating process D(·) is in\nequilibrium, its distribution being deﬁned by π(·). Clearly, for all T > 0,\n∅ = L−T (−T ) ⊆ U−T (−T ) = D(−T )\n\n\f84\nEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\nand by construction the updates respect the inclusion order. Hence L−T (t) ⊆\nU−T (t) for all t ∈ [−T, 0]. Moreover, the processes funnel, i.e.\n\nL−T (t) ⊆ L−S(t) ⊆ U−S(t) ⊆ U−T (t)\n\n(4.26)\n\nwhenever −S ≤ −T ≤ t ≤ 0. The ﬁrst inclusion can be veriﬁed by noting\nthat L−T (−T ) = ∅ ⊆ L−S(−T ) and recalling that the transitions respect\nthe inclusion order. Since U−T (−T ) = D(−T ) ⊇ U−S(−T ), the last in-\nclusion in (4.26) follows by the same argument. If L−T (t0) = U−T (t0) for\nsome t0 ∈ [−T, 0], as the processes are coupled, L−T (t) = U−T (t) for all\nt ∈ [t0, 0]. Next, set X−T (−T ) = ∅ and deﬁne a process X−T (·) on [−T, 0]\nin analogy to the upper and lower processes, except that if X−T (t−) = x\nthe birth at time t of a point ξ is accepted if Vt,ξ ≤ b(x,ξ) d(x∪{ξ},ξ)\n¯b(ξ) d(x∪{ξ},ξ) . In other\nwords, X−T (·) exhibits the dynamics of a spatial birth-and-death process\nwith birth rate ˜b(x, ξ) = b(x, ξ) d(x∪{ξ},ξ)\nd(x∪{ξ},ξ) and death rate ˜d(x ∪ {ξ} , ξ) =\nd(x ∪ {ξ} , ξ). Thus, its detailed balance equations coincide with those for\nb(·, ·) and d(·, ·). Furthermore, ˜b(·, ·) ≤ b(·, ·), hence explosion is prevented\nso that the process converges in distribution to its equilibrium distribu-\ntion deﬁned by pX|Y (· | y). The inclusion properties derived above imply\nL−T (0) ⊆ X−T (0) ⊆ U−T (0), so that – provided the sampler terminates al-\nmost surely – with probability 1 the limit limT →∞ X−T (0) is well-deﬁned.\nSince D(·) is in equilibrium, X−T (0) has the same distribution as if the\nX-process were run forward from time 0 (coupled to the dominating pro-\ncess as before) over a time period of length T , the limit distribution of\nwhich is pX|Y (· | y). We conclude that the algorithm outputs an unbiased\nsample from the posterior distribution of parents. It remains to show that\ncoalescence occurs almost surely. Recall that by assumption π(∅) > 0. Set,\nfor n ∈ N0, En = 1{D(−n) (cid:18)= ∅}. Now (En)n is an irreducible aperiodic\nMarkov chain on {0, 1} for which the equilibrium probability π(∅) of state 0\nis strictly positive. Hence state 0 will be reached with probability 1, which\nimplies that the dominating process D(t)t≤0 will almost surely be empty\nfor some t. But then (4.26) and the coupling imply that the algorithm\nterminates almost surely, and the proof is complete.\n\n4.4.6 Example: Cox–Mat´ern Cluster Process\n\nTo describe a tailor-made coupling from the past algorithm, consider a\nCox cluster process with intensity function given by (4.4)–(4.5) and prior\ndensity (4.17). For this model, the birth rate (4.20) satisﬁes\n\n\n\n\nb(x, ξ) ≤ β\n\n1 +\n\nm(cid:6)\n\nj=1\n\nh(yj|ξ)\n%\n\n = ¯b(ξ).\n\n(4.27)\n\n\fBAYESIAN CLUSTER ANALYSIS\n\n85\n\nIn order to derive a lower bound for the death rate (4.21), note that\n\n1 +\n\nh(yj|ξ)\nλ(yj | x)\n\n≤ 1 +\n\nµ\n% + µ\n\n≤ 2\n\nif yj ∈ B(ξ, Rh) ∩ Ux, where Ux = ∪xi∈xB(xi, Rh) denotes the union of\nballs centred at the points of x. It follows that the death rate d(x ∪ {ξ} , ξ)\nis bounded below by\n\nd",
    "chunk_order_index": 52,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-370585af9b95b99a195862c88c718850": {
    "tokens": 1200,
    "content": "21), note that\n\n1 +\n\nh(yj|ξ)\nλ(yj | x)\n\n≤ 1 +\n\nµ\n% + µ\n\n≤ 2\n\nif yj ∈ B(ξ, Rh) ∩ Ux, where Ux = ∪xi∈xB(xi, Rh) denotes the union of\nballs centred at the points of x. It follows that the death rate d(x ∪ {ξ} , ξ)\nis bounded below by\n\nd(x ∪ {ξ} , ξ) = d(x ∪ {ξ} , ξ)\n\n(cid:9)\n\nj:yj ∈B(ξ,Rh)∩Ux\n\n\"\n\n#\n\n1\n2\n\n+\n\nµ\n2 λ(yj | x)\n\n.\n\n(4.28)\n\nBy the Preston theorem, the transition rates ¯b(ξ) and d(x ∪ {ξ} , ξ) deﬁne\n\n•\n\n•\n\n•\n\n•\n\n•\n\n• •\nP\n\n• • •\n\n•\n•\n\n• •\nP\n• •\n•\n\n•\n•••\n\nP\n\n•\n\n•\n•\n\n•\n\n••\nP\n\n••\n\n•\n\n•\n\n•••\nP\n•\n•\n\n•\n\n•••\nP\n•\n\n•\nP\n•\n\n• •\n\n•\n••\n•\nP\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n••\n\n•\n\n••\n•\n\n••\n•\nP\n••\n•\n\n•\n\nFigure 4.5 Realisation of extrapolated redwood seedling pattern on X ⊕ B(0, Rh)\nfrom observations in unit square (box) and interpolated parent pattern (‘P’) based\non a Cox–Mat´ern cluster process with Rh = 0.061 and (ˆ(cid:3)100, ˆµ100) obtained by\ncoupling from the past. We used a hard core prior with R = 0.03 and β = 1.0.\n\na unique spatial birth-and-death process, whose limit distribution is given\nby\n\nπ(x) ∝ γ−n(y∩Ux)\n\nn(x)(cid:9)\n\ni=1\n\nβ(xi),\n\n(4.29)\n\na generalised area-interaction process (Widom and Rowlinson 1970, Bad-\ndeley and van Lieshout 1995, Kendall 1998, H¨aggstr¨om et al. 1999) with\nintensity function\n\n(cid:11)\n\n(cid:12)\n\n(cid:13)\nh(a|ξ) da\n\n2n(y∩B(ξ,Rh))\n\nβ(ξ) = β exp\n\n−\n\nA\n\n\fEXTRAPOLATING AND INTERPOLATING SPATIAL PATTERNS\n2(cid:17) )−1. Regarding the implementation\n\"\n#\n\n2 + µ\n\n86\nand interaction parameter γ = ( 1\nof algorithm 1, note that\nb(x, ξ) d(x ∪ {ξ} , ξ)\n¯b(ξ) d(x ∪ {ξ} , ξ)\n\n1\n2\n\n+\n\nµ\n2λ(yj | x)\n\n= 1{d(ξ, x) > R}\n\n(cid:9)\n\nj:yj ∈B(ξ,Rh)∩Ux\n\nis decreasing in x, so the sampler is anti-monotone, and the births in the\nupper and lower processes may be implemented by simply considering the\ncurrent state of the other process at each transition; see Kendall (1998). We\napplied the above algorithm to the redwood seedlings data of Figure 4.1\nfor the Mat´ern parameter vector (%, µ) equal to its Monte Carlo maximum\nlikelihood estimate (cf. Section 4.4.4) and a hard core prior with β = 1.0 and\nR = 0.03 as before. A typical realisation from the posterior distribution of\nparents can be seen in Figure 4.5 as well as an extrapolation of the redwood\npattern to the set X ⊕ B(0, Rh).\n\n4.5 Summary and Conclusion\n\nWe discussed issues arising when a spatial pattern is observed within some\nbounded region of space, and one wishes to predict the process outside of\nthis region (extrapolation) as well as to perform inference on features of\nthe pattern that cannot be observed (interpolation). We focused on spatial\ncluster analysis. Here the interpolation arises from the fact that the centres\nof clustering are not observed. We took a Bayesian approach with a repul-\nsive Markov prior, derived the posterior distribution of the complete data,\ni.e. cluster centres with associated oﬀspring marks, and proposed an adap-\ntive coupling from the past algorithm to sample from this posterior. The\napproach was illustrated by means of the redwood data set (Ripley 1977).\n\nAcknowledgements\n\nWe gratefully acknowledge the expert programming support of Adri Steen-\nbeek, very helpful comments from Yih Chong Chin, Nick Fisher, Richard\nGill, Ilya Molchanov and Elke Th¨onnes, and the inﬂuence of previous un-\npublished collaboration with Andrew Lawson and Henry Y.W. Cheng.\nThe research for this chapter was carried out under CWI project PNA4.3\n‘Stochastic Geometry’, ARC large grant A69941083 ‘Extrapolating and In-\nterpolating Spatial Patterns’, and NWO grant CIMS 613.003.100.\n\n\fCHAPTER 5\n\nPerfect Sampling for Point Process\nCluster Modelling\n\nI.W. McKeague M. Loizeaux\n\n5.1 Introduction\n\nWhen disease incidence locations are observed in a region, there is often\ninterest in studying whether there is clustering about landmarks repre-\nsenting possible centralized sources of the disease. In this article we study\na Bayesian approach to the detection and estimation of such landmarks.",
    "chunk_order_index": 53,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-aaa63782840bd702b69e3c46682e27c7": {
    "tokens": 1200,
    "content": "Patterns’, and NWO grant CIMS 613.003.100.\n\n\fCHAPTER 5\n\nPerfect Sampling for Point Process\nCluster Modelling\n\nI.W. McKeague M. Loizeaux\n\n5.1 Introduction\n\nWhen disease incidence locations are observed in a region, there is often\ninterest in studying whether there is clustering about landmarks repre-\nsenting possible centralized sources of the disease. In this article we study\na Bayesian approach to the detection and estimation of such landmarks.\nSpatial point processes are used to specify both the observation process\nand the prior distribution of the landmarks. We develop a perfect sampling\nalgorithm for the posterior distribution of landmarks under various condi-\ntions on the prior and likelihood. Bayesian cluster models of the type we\nconsider were introduced by Baddeley and van Lieshout (1993), primarily\nfor applications in computer vision. The dissertation of van Lieshout (1995)\n(see also Chapter 4) focused on the special case of the Neyman–Scott cluster\nprocess, in which the observations arise from a superposition of inhomo-\ngeneous Poisson processes associated with each landmark (Neyman and\nScott 1958) and she applied it to the well-known redwood seedling data\nused by Strauss (1975). Hurn (1998) applied the Baddeley–van Lieshout\napproach to the study of changes in the size and shape of living cells. Law-\nson and Clark (1999b) survey the statistical literature on disease clustering\nmodels. Markov chain Monte Carlo (MCMC) techniques are indispensable\nfor the application of point process models in statistics, see, for example,\nthe survey of Møller (1999). The typical MCMC sampler obtains draws\nthat are at best only approximately from the target distribution, and are\noften plagued by convergence problems, even when a long “burn-in” pe-\nriod is used. Moreover, if independent draws are required, then every draw\nmust be produced by a separate chain. However, using an algorithm devel-\noped by Kendall and Møller (2000), it is possible to sample perfectly from\nthe posterior distribution in the Bayesian cluster model. Perfect samplers\noriginate in the seminal work of Propp and Wilson (1996), whose coupling\nfrom the past (CFTP) algorithm delivers an exact draw from the target\ndistribution. The most important practical advantage of perfect samplers\n\n\f88\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\nover traditional MCMC schemes is that the need to assess convergence of\nthe sampler is eliminated. There are many examples of perfect samplers\nin the literature. Mira et al. (2001) apply perfect simulation to slice sam-\nplers for bounded target distributions; Casella et al. (1999) create perfect\nslice samplers for mixtures of exponential distributions and mixtures of\nnormal distributions. For an example of perfect sampling of a conditioned\nBoolean model, see Cai and Kendall (1999). H¨aggstr¨om et al. (1999) ob-\ntain perfect samples from the area–interaction point process (attractive\ncase) using auxiliary variables. Another version of perfect sampling called\nread-once CFTP, which runs the Markov chain forward in time and never\nrestarts it at previous past times (thus avoiding the need to store random\nnumbers for reuse), is given by Wilson (2000). For recent applications of\nperfect simulation in statistics, see Green and Murdoch (1999) and Møller\nand Nicholls (1999). The Kendall–Møller version of perfect simulation was\ndeveloped for spatial point processes that are locally stable. We show that\nthe posterior distribution in the Bayesian cluster model is locally stable on\nits support, provided the prior is locally stable and the likelihood satisﬁes\nsome mild conditions. In particular, this shows that the posterior density\nis proper (has unit total mass). The Kendall–Møller algorithm is compu-\ntationally feasible, however, only when the locally stable point process is\neither attractive (favoring clustered patterns) or repulsive (discouraging\nclustered patterns), or a product of attractive and repulsive components.\nWe examine the feasibility of the sampler in two special cases: the Neyman–\nScott process and the pure silhouette model (in which only the support of\nthe observations is determined by the landmarks). Our approach is applied\nto data on leukemia counts in an eight county area of upstate New York\nduring the years 1978–82. There is an extensive literature on the analysis\nof these data, the main goal being the detection of disease clusters; see,\nfor example, Ghosh et al. (1999), Ahrens et al. (1999) and Denison and\nHolmes (2001). The study area includes 11 inactive hazardous waste sites,\nand it is natural in any study to attempt to determine if any of these sites\ncan be seen as a contributor to the incidence of leukemia in the area. We\nﬁnd evidence for an elevated leukemia incidence in the neighborhood of\none of the sites. The paper is organized as follows. Section 5.2 gives back-\nground material and describes the general model. In this section we also\nstate the main result of the paper showing that the posterior is locally\nstable on its support. Section 5.4 examines several examples of the basic\nmodel, and addresses the question of whether perfect sampling is feasible\nin each case. Section 5.5 contains the disease clustering application, and a\nfurther application to the classic redwood seedlings data is given in Section\n5.6.\n\n\fBAYESIAN CLUSTER MODEL\n\n5.2 Bayesian Cluster Model\n\n5.2.1 Preliminaries",
    "chunk_order_index": 54,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-7c3264f1ce1b7ded2ee1c209b745f4e2": {
    "tokens": 1200,
    "content": "paper showing that the posterior is locally\nstable on its support. Section 5.4 examines several examples of the basic\nmodel, and addresses the question of whether perfect sampling is feasible\nin each case. Section 5.5 contains the disease clustering application, and a\nfurther application to the classic redwood seedlings data is given in Section\n5.6.\n\n\fBAYESIAN CLUSTER MODEL\n\n5.2 Bayesian Cluster Model\n\n5.2.1 Preliminaries\n\n89\n\nThe point process notation used throughout the paper is standard, cf.\nH¨aggstr¨om et al. (1999), Baddeley and Møller (1989), or Møller (1999,\n2001b). For in-depth accounts of the theory of point processes, see Daley\nand Vere-Jones (1988) and van Lieshout (2000). Let W be a compact sub-\nset of the plane representing the study region, and let | · | denote Lebesgue\nmeasure on W . A realization of a point process in W is a ﬁnite set of\npoints x = {x1, x2, . . . , xn(x)} ⊂ W , where n(x) is the number of points\nin x. If n(x) = 0, write x = ∅ for the empty conﬁguration. Let Ω denote\nthe exponential space (Carter and Prenter 1972) of all such ﬁnite point\nconﬁgurations in W , and furnish it with the σ-ﬁeld F generated by sets\nof the form {x : n(x ∩ B) = k}, where B ∈ B, the Borel σ-ﬁeld on W ,\nand k = 0, 1, 2, . . .. Let (W, B, λ) be a measure space with λ(W ) < ∞. The\nPoisson process Z on W with intensity measure λ is an Ω-valued random\nvariable such that the number of points n(Z) follows the Poisson distri-\nbution with mean λ(W ), and conditional on n(Z) = m, the m points are\nindependent and identically distributed with distribution λ(·)/λ(W ). If λ is\nLebesgue measure | · |, then we say Z is the unit rate Poisson process on W .\nAll point processes considered here will have distributions that are abso-\nlutely continuous with respect to the distribution π of the unit rate Poisson\nprocess, and thus speciﬁed by a density with respect to π. Two important\npoint processes are the Strauss (1975) process and the area-interaction\nprocess of Baddeley and van Lieshout (1995). The Strauss process has un-\nnormalized density f (x) = βn(x)γt(x), where β > 0, 0 < γ ≤ 1 and t(x) is\nthe number of unordered pairs of points in x which are within a speciﬁed\ndistance r of each other. The Strauss process only models pairwise inter-\naction which is repulsive, i.e., the points in the process tend to separate\nfrom one another. For the area-interaction process, the unnormalized den-\nsity is given by f (x) = βn(x)γ−ν(U (x)), where β > 0, γ > 0, ν is a totally\nﬁnite, regular Borel measure on W , and U (x) is the intersection of W with\nthe union of balls of ﬁxed radius r centered at points in x. We can also\nwrite U (x) = (x ⊕ G) ∩ W , where ⊕ denotes Minkowski addition, and the\ngrain G is the ball of radius r centered at the origin (more generally, G\ncan be any compact subset of R2\n). Area-interaction processes can be used\nto model both clustered (attractive) and ordered (repulsive) patterns, and\nallow interactions of inﬁnite order. The parameter γ controls the type of\ninteraction; γ > 1 produces clustered patterns, 0 < γ < 1 produces ordered\npatterns. An unnormalized density f (or corresponding process X) is said\nto be locally stable if there is a constant K > 0 such that\n\nf (x ∪ {ξ}) ≤ Kf (x)\n\n\f90\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\nfor all x ∈ Ω, ξ ∈ W \\x. As noted by Kendall and Møller (2000), local\nstability is equivalent to an upper bound on the Papangelou conditional\nintensity\n\nq(x, ξ) ≡ f (x ∪ {ξ})\n\nf (x)\n\n, x ∈ Ω, ξ ∈ W \\x,\n\n(with c/0 = 0 for c ≥ 0) and the hereditary property, which states that if\nx ⊂ x(cid:2) then f (x(cid:2)) > 0 implies f (x) > 0. In addition, local stability implies\nf (∅) > 0, since repeated use of the condition gives f (x) ≤ K n(x)f (∅).\nMost point processes that have been suggested for modeling spatial point\npatterns are locally stable, including the Strauss and the area-interaction\nprocesses.\n\n5.2.2 Model Speciﬁcation\nThe observed point conﬁguration which arises from the landmarks x will be\ndenoted y = {y1, y2, . . . , yn(y)} ⊂ W , and assumed to be non-empty. The\nprior and observation models are speci",
    "chunk_order_index": 55,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-2d98bb5a5e45e7e422f00711eef7bcf5": {
    "tokens": 1200,
    "content": ")f (∅).\nMost point processes that have been suggested for modeling spatial point\npatterns are locally stable, including the Strauss and the area-interaction\nprocesses.\n\n5.2.2 Model Speciﬁcation\nThe observed point conﬁguration which arises from the landmarks x will be\ndenoted y = {y1, y2, . . . , yn(y)} ⊂ W , and assumed to be non-empty. The\nprior and observation models are speciﬁed by point processes on W . The\nprior distribution of landmarks corresponds to a point process X having\ndensity pX (x) with respect to π. The landmarks produce daughters y, a\ncertain proportion of which will be required to fall in a silhouette region\nS(x) ⊂ W given by the union of discs\n\nS(x) = ∪ξ∈xD(ξ, rsil) = (x ⊕ Gsil) ∩ W,\nwhere D(ξ, rsil) = {x ∈ W : ||x − ξ|| ≤ rsil}, || · || is Euclidean distance, and\nGsil is the disk of radius rsil centered at the origin. The random closed set\nS(X) is known as a Boolean model, see, for example, Chapter 3 of Stoyan et\nal. (1995). With appropriate measurability conditions, our approach allows\nmore general types of silhouettes S(x), but we have restricted attention\nto Boolean silhouettes for simplicity. We have used diﬀerent notation for\nS(x) and U (x), even though they are silhouettes of the same type, to\navoid confusion later on. The observation process is deﬁned in terms of\nan unnormalized density f (·|x) conditioned on the event {y : s(y|x) ≥ c},\nwhere 0 ≤ c ≤ 1 and s(y|x) = n(y ∩ S(x))/n(y) is the proportion of points\nin y within the silhouette region (with 0/0 = 0). Thus, for a given set of\nlandmarks x, the density of the observed point process Y with respect to\nπ is\n\nwhere\n\npY |X=x(y) = αY (x)f (y|x)1{s(y|x) ≥ c},\n(cid:3)−1\n\n(cid:1)(cid:2)\n\nαY (x) =\n\n{v:s(v|x)≥c}\n\nf (v|x) π(dv)\n\nis the normalizing constant. We assume that f (y|x) is jointly measurable\nin x and y. The silhouette portion of the observation process could be\nabsorbed into f (y|x), as in the formulation of Baddeley and van Lieshout\n\n\fBAYESIAN CLUSTER MODEL\n\n91\n\n(1993), but we ﬁnd it useful to isolate 1{s(y|x) ≥ c} in this fashion in\norder to provide conditions under which perfect sampling is feasible. Our\nformulation of the model also provides a ﬂexible class of Boolean models\nwhich are of independent interest. When f (y|x) = f (y) and c = 1 we say\nthe likelihood follows a pure silhouette model ; this is similar to the blur-\nfree model of Baddeley and van Lieshout (1993). From Bayes formula, the\nposterior density of X with respect to π is\n\npX|Y =y(x) ∝ fX|Y =y(x)1{s(y|x) ≥ c},\n\nwhere the unnormalized density\n\nfX|Y =y(x) = αY (x)f (y|x)pX (x)\n\n(5.1)\n\n(5.2)\n\nis called the unrestricted posterior. Theorem 5.2.1 which follows provides\nsuﬃcient conditions for the unrestricted posterior to be locally stable. We\nnote in passing that the posterior itself is not hereditary (thus not locally\nstable) if c > 0, because S(∅) = ∅ and y (cid:20)= ∅. We assume local stability of\nthe prior pX (·) and of the likelihood f (y|·) (for each ﬁxed y). In addition,\nwe assume that the family of functions {f (y|·) : y ∈ Ω} satisﬁes the\nfollowing local growth condition: there exists a constant L > 0 such that\nf (y|x ∪ {ξ}) ≥ Lf (y|x)\n(5.3)\nfor all x ∈ Ω, ξ ∈ W \\x. We call this a ‘local growth’ condition because\nit implies that the Papangelou conditional intensity for f (y|·) is bounded\naway from zero. As it turns out, L = 1 in the examples to follow. Prior to\nstating our main theorem, for easy reference we state the following lemma\ngiving the density of an inhomogeneous Poisson process with respect to the\nunit rate Poisson process. The proof can be found, for example, on page\n499 of Daley and Vere-Jones (1988).\n\nLemma 5.2.1 Let π be the distribution of the unit rate Poisson process on\nthe compact set W ⊂ R2, and let πβ be the distribution of the inhomo-\ngeneous Poisson process on W with intensity function β(t). Then πβ (cid:21) π\nand\n\ndπβ\ndπ\n\n(cid:4)(cid:2)\n\n(cid:5) n(x)(cid:6)\n\n(x) = exp\n\n(1 − β",
    "chunk_order_index": 56,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-864c0768489ae89c2d7bb00cc3c6ebef": {
    "tokens": 1200,
    "content": ".2.1 Let π be the distribution of the unit rate Poisson process on\nthe compact set W ⊂ R2, and let πβ be the distribution of the inhomo-\ngeneous Poisson process on W with intensity function β(t). Then πβ (cid:21) π\nand\n\ndπβ\ndπ\n\n(cid:4)(cid:2)\n\n(cid:5) n(x)(cid:6)\n\n(x) = exp\n\n(1 − β(t)) dt\n\nW\n\nβ(xj).\n\nj=1\n\nTheorem 5.2.1 Suppose pX (·) and f (y|·) (for each y) are locally stable,\nand {f (y|·): y ∈ Ω} satisﬁes the local growth condition (5.3). Then the\nunrestricted posterior (5.2) is locally stable.\n\nProof: We ﬁrst show that density (5.1) is measurable. Since pX (·) and\nf (y|·) are measurable, we need only establish the measurability of αY (·)\n\n\f92\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\nand {x : s(y|x) ≥ c}. First consider {x : s(y|x) ≥ c} in the case c = 1.\nWith y = {y1, y2, . . . , ym},\n\n{x : s(y|x) ≥ 1} = {x : y ⊂ S(x)} =\n\nm(cid:7)\n\n{x : n(x ∩ D(yj, r)) ≥ 1}\n\nj=1\nm(cid:7)\n\n∞(cid:8)\n\n=\n\n{x : n(x ∩ D(yj, r)) = k},\n\nj=1\n\nk=1\n\nwhich belongs to F. The general case reduces to the special case of c = 1\nbecause {x : s(y|x) ≥ c} is the ﬁnite union of sets of the form {x : z ⊂\nS(x)} with z ⊂ y and n(z) ≥ cn(y). To show that αY (·) is measurable,\nthe π-λ theorem allows us to reduce to the case f (v|x) = 1C(v)1D(x),\nwhere C and D are generating sets in F. Thus we only need show the\nmeasurability of\n\nx (cid:22)−→ π{v : n(v ∩ B) = k and n(v ∩ S(x)) ≥ cn(v)},\n\nwhere B ∈ B and k ≥ 0. Since π is Poisson, the above function only depends\non x through a continuous function of the areas of the disjoint regions\nB∗ ∩ S(x)∗, where A∗ = A or Ac. These areas are measurable functions\nof x by Lemma 2.1 of Baddeley and van Lieshout (1995). To establish\nlocal stability of the unrestricted posterior it is enough to show that αY (·)\nis locally stable; pX (·) and f (y|·) were assumed to be locally stable, and\nﬁnite products of locally stable densities are locally stable. Given ξ ∈ W \\x,\n\n(cid:2)\n\nαY (x ∪ {ξ})−1 =\n\n{v:s(v|x∪{ξ})≥c}\n(cid:2)\n\nf (v|x ∪ {ξ}) π(dv)\n\n≥ L\n\n≥ L\n\n{v:s(v|x∪{ξ})≥c}\n\n(cid:2)\n\nf (v|x) π(dv)\n\n{v:s(v|x)≥c}\n\nf (v|x) π(dv)\n\n= LαY (x)−1,\n\nwhere we have used the local growth condition (5.3) and the fact that\ns(v|x) ≤ s(v|x ∪ {ξ}). Thus αY (·) is locally stable. ✷\n\nIt is convenient to introduce some notation for the bounds implied by the\nlocal stability and local growth conditions. Let Kprior be an upper bound\non the Papangelou conditional intensity for pX (x), and let Klik(y) be an\nupper bound on the Papangelou conditional intensity for f (y|·). Under the\nassumptions given in Theorem 5.2.1, since ﬁnite products of locally stable\ndensities are locally stable, we ﬁnd that\n\nKpost =\n\n1\nL\n\nKlik(y)Kprior\n\n(5.4)\n\n\fSAMPLING FROM THE POSTERIOR\n\n93\n\nis an upper bound on the Papangelou conditional intensity for the unre-\nstricted posterior density (5.2).\n\n5.3 Sampling from the Posterior\n\nClearly, once we develop a sampler for the unrestricted posterior (5.2),\nsimple rejection sampling can be used to obtain samples from the pos-\nterior (5.1) itself. This is an eﬃcient approach provided draws from the\nunrestricted posterior are not rejected too frequently. As previously stated,\nMCMC methods are needed to sample from (5.2), and from point pro-\ncesses in general. The Hastings–Metropolis–Green sampler of Geyer and\nMøller (1994) is applicable and easy to implement. Under the conditions of\nTheorem 5.2.1, the unrestricted posterior is locally stable, so the Geyer–\nMøller algorithm is geometrically ergodic; see Geyer (1999). As explained\nin the Introduction, however, it would be preferable to utilize the algo-\nrithm of Kendall and Mø",
    "chunk_order_index": 57,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-38c8101b42ce66c4f0e147fa9bb76ff8": {
    "tokens": 1200,
    "content": "in general. The Hastings–Metropolis–Green sampler of Geyer and\nMøller (1994) is applicable and easy to implement. Under the conditions of\nTheorem 5.2.1, the unrestricted posterior is locally stable, so the Geyer–\nMøller algorithm is geometrically ergodic; see Geyer (1999). As explained\nin the Introduction, however, it would be preferable to utilize the algo-\nrithm of Kendall and Møller (2000) if possible. This algorithm is not fea-\nsible in every situation, but when feasible has the advantage of producing\nperfect samples. Kendall (1998) introduced the algorithm initially for area-\ninteraction processes. Kendall and Th¨onnes (1999) give a review of the\nmethod from the perspective of image processing. An alternative perfect\nsampler for area-interaction processes has been suggested by H¨aggstr¨om et\nal. (1999). The Kendall–Møller algorithm uses the method of dominated\ncoupling from the past (CFTP) to produce perfect samples from a locally\nstable point process. The sampler is driven by a spatial birth-and-death\nprocess ˜X(t) having equilibrium distribution which agrees with the distri-\nbution of the target point process. Dominated CFTP is sometimes referred\nto as “horizontal CFTP”, as opposed to the “vertical CFTP” originally\nintroduced by Propp and Wilson (1996). Vertical CFTP requires minimal\nand maximal elements with respect to some partial ordering of the state\nspace; it is not applicable to point processes because a maximal element\ndoes not exist in Ω under set inclusion. Horizontal CFTP, however, only\nrequires a minimal element ∅ which functions as an ergodic atom for a dom-\ninating process D(t). Once the dominating process D(t) hits the minimal\nelement, subsequent evolution of ˜X(t) does not depend on the initial state,\nso ˜X(0) represents the endpoint of a path from the inﬁnite past (coales-\ncence), and thus a perfect sample from the target distribution. A further\naspect of horizontal CFTP is the use of lower and upper processes that\nbound ˜X(t) more eﬃciently than ∅ and D(t), and thus provide coalescence\nmore rapidly. These various processes are deﬁned below. The spatial birth-\nand-death process ˜X = { ˜X(t) : t ∈ R} has birth rate b(x, ξ) = q(x, ξ) given\nby the Papangelou conditional intensity corresponding to fX|Y =y(x), and\ndeath rate d(x, ξ) = 1. It is clear that the target density fX|Y =y(x) and ˜X\n\n\f94\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\nare in detailed balance, i.e.\n\nfX|Y =y(x)b(x, ξ) = fX|Y =y(x ∪ ξ)d(x, ξ) > 0,\n\nso ˜X(t) converges in distribution to X as t → ∞, where X has density (5.2);\nsee Kendall and Møller (2000). The dominating process D(t) has birth rate\nKpost and death rate 1, so its equilibrium distribution is homogeneous\nPoisson with intensity Kpost. Suppose that ˜X(t−) = x ⊂ y = D(t−) are\nthe states of ˜X and D just before time t. If at time t a point ξ is added to\nD, then this same point is added to ˜X with probability q(x, ξ)/Kpost, that\nis, if M (t) ≤ q(x, ξ)/Kpost where M (t) is an iid uniform(0,1) mark process.\nIf at time t a point is deleted from D, then this same point is deleted from\n˜X. For every n > 0, the upper process U−n is initialized at time −n with\nˆx = D(−n). The initial state for L−n is the empty conﬁguration. Using\nthe mark M (t), a new point ξ is added to U−n at time −t, t < n, with\nprobability\n\n(cid:9)\n\n(cid:9)\n\nmax\n\nq(x, ξ)\nKpost\n\n: L−t−\n\n−n (∅) ⊆ x ⊆ U −t−\n\n−n (ˆx)\n\nand the same point ξ is added to L−n with probability\n\nmin\n\nq(x, ξ)\nKpost\n\n: L−t−\n\n−n (∅) ⊆ x ⊆ U −t−\n\n−n (ˆx)\n\n(cid:10)\n\n(cid:10)\n\n,\n\n,\n\nwhere L−t−\nbefore time −t. The construction described then gives\n\n−n (∅) and U −t−\n\n−n (ˆx) are the states of L−n(∅) and U−n(ˆx) just\n\n−n(∅) ⊆ ˜X(−t) ⊆ U −t\nL−t\n\n−n(ˆx) ⊆ D(−t),\n\nand the funnelling property\n≤ L−t\n−m\n\nL−t\n−n\n\n≤ U −t\n−m\n\n≤ U −t\n\n−n, m ≥ n ≥ t.\n\n−n(∅) = U 0\n\n−n(ˆx), in which case L0\n\nSince X is locally stable by Theorem",
    "chunk_order_index": 58,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-c1cdc6e433cbb9b2414132e0ef0da5bd": {
    "tokens": 1200,
    "content": "�� U −t\nL−t\n\n−n(ˆx) ⊆ D(−t),\n\nand the funnelling property\n≤ L−t\n−m\n\nL−t\n−n\n\n≤ U −t\n−m\n\n≤ U −t\n\n−n, m ≥ n ≥ t.\n\n−n(∅) = U 0\n\n−n(ˆx), in which case L0\n\nSince X is locally stable by Theorem 5.2.1, the empty conﬁguration is an\nergodic atom for D(t). Thus it is simply a matter of ﬁnding n large enough\nso that L0\n−n(∅) is a perfect draw from\nthe posterior distribution. Note the inherent diﬃculty in calculating the\nprobability of adding a point to U at time −t (and similarly to L): in\nthe general case it is necessary to evaluate q(x, ξ)/Kpost for every x such\nthat L−t−\n−n (ˆx). These probabilities are easy to calculate,\nhowever, if the locally stable point process X is either attractive:\n\n−n (∅) ⊆ x ⊆ U −t−\n\nq(x, ξ) ≤ q(x(cid:2), ξ) whenever ξ /∈ x(cid:2) and x ⊂ x(cid:2),\n\nor repulsive:\n\nq(x, ξ) ≥ q(x(cid:2), ξ) whenever ξ /∈ x(cid:2) and x ⊂ x(cid:2).\n\n\fSPECIALIZED EXAMPLES\n\n5.4 Specialized Examples\n\n95\n\nIn this section we examine various choices of the prior and likelihood which\nsatisfy Theorem 5.2.1. In addition, we describe conditions under which the\nposterior is either attractive or repulsive, so that perfect simulation is fea-\nsible. A small dataset is used to illustrate the viability of perfect simulation\nin each case. In Section 5.4.1 the Neyman–Scott model is described in de-\ntail (see also Chapter 3). Section 5.4.2 provides several cases of the pure\nsilhouette model.\n\n5.4.1 Neyman–Scott Model\n\nIn this section we consider the Neyman–Scott model in which the obser-\nvation process Y is the superposition of n(x) independent inhomogeneous\nPoisson processes Zxi and a background Poisson noise process of intensity\n* > 0. The intensity h(·|xi) of Zxi is speciﬁed parametrically, and the prior\npX (x) is assumed to be locally stable. This ﬁts into our general framework\nby taking c = 0 and f (y|x) =\n\nn(y)\nj=1 µ(yj|x), where\n\n(cid:11)\n\nµ(t|x) = * +\n\nn(x)(cid:12)\n\ni=1\n\nh(t|xi)\n\nis the conditional intensity at t of Y given x. We now check the relevant\nconditions of Theorem 5.2.1, assuming that h(t|·) is bounded for each t ∈\nW . To show that f (y|·) is locally stable, note that for ξ ∈ W \\x\n\n\n\n\nf (y|x ∪ {ξ}) =\n\n* +\n\nh(yj|xi) + h(yj|ξ)\n\n\n\nn(y)(cid:6)\n\nn(x)(cid:12)\n\n(cid:4)\n\n\n\n*\n\nj=1\n\nn(y)(cid:6)\n\nj=1\n\n≤\n\ni=1\n\n1 +\n\nh(yj|ξ)\n*\n\n(cid:5)\n\nn(x)(cid:12)\n\n+\n\ni=1\n\n\n\nh(yj|xi)\n\n\n\n≤ Klik(y)f (y|x),\n\nwhere\n\nKlik(y) = supξ∈W\n\n(cid:4)\n\nn(y)(cid:6)\n\nj=1\n\n1 +\n\nh(yj|ξ)\n*\n\n(cid:5)\n\n< ∞.\n\nTo check the local growth condition, note that for ξ ∈ W \\x\n\nf (y|x ∪ {ξ}) =\n\nn(y)(cid:6)\n\nj=1\n\n(µ(yj|x) + h(yj|ξ)) ≥ f (y|x),\n\nuniformly in y, and we can use L = 1. Thus the conditions of Theorem\n5.2.1 are satisﬁed, so the posterior is locally stable. As previously noted, the\n\n\f96\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\nKendall–Møller algorithm is feasible if the posterior is either attractive or\nrepulsive, or factors into attractive/repulsive components. The Papangelou\nconditional intensity corresponding to f (y|·) is\n\nf (y|x ∪ {ξ})\nf (y|x)\n\n=\n\n(cid:1)\n\nn(y)(cid:6)\n\n1 +\n\n* +\n\nj=1\n\n(cid:17)\n\nh(yj|ξ)\nn(x)\ni=1 h(yj|xi)\n\n(cid:3)\n\n,\n\nfor ξ ∈ W \\x, which is clearly decreasing in x, thus repulsive. By Lemma\n5.2.1 (with intensity β(t) = µ(t|x)), we have\n\n(cid:9)(cid:2)\n\n(cid:10)\n\nαY (x) = exp\n\n(1 − µ(t|x)) dt\n\n.\n\nW\nTherefore, the Papangelou conditional intensity corresponding to αY (·) is",
    "chunk_order_index": 59,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-2ce8aa2f672987b0778ee21fea7394f5": {
    "tokens": 1200,
    "content": "|xi)\n\n(cid:3)\n\n,\n\nfor ξ ∈ W \\x, which is clearly decreasing in x, thus repulsive. By Lemma\n5.2.1 (with intensity β(t) = µ(t|x)), we have\n\n(cid:9)(cid:2)\n\n(cid:10)\n\nαY (x) = exp\n\n(1 − µ(t|x)) dt\n\n.\n\nW\nTherefore, the Papangelou conditional intensity corresponding to αY (·) is\n\nαY (x ∪ {ξ})\nαY (x)\n\n(cid:9)\n\n(cid:2)\n\n(cid:10)\n\n= exp\n\n−\n\nh(t|ξ) dt\n\n,\n\nW\n\nfor ξ ∈ W \\x, which does not depend on x. We conclude that the posterior\nis repulsive whenever the prior is repulsive, and sampling from the poste-\nrior is possible if the prior is either repulsive or attractive. Figure 5.1 shows\nan artiﬁcial dataset in the unit square consisting of two clusters of three\nobservations each and one isolated observation. Figure 5.2 gives an illustra-\ntion of perfect sampling for the Neyman–Scott model based on these data.\nWe used a Strauss prior that produces empty conﬁgurations of landmarks\napproximately 50% of the time. For the likelihood we used the Thomas\n\nFigure 5.1 Artiﬁcial dataset used to illustrate the examples in Section 1.4.\n\nintensity model (radially symmetric Gaussian)\n\nh(t|x) =\n\nκ\n\n2πσ2 e−||t−x||2/2σ2\n\n,\n\n(5.5)\n\nwhere κ, σ > 0. Note that the contribution of a particular landmark x to the\nintensity rate at x is exactly κ∗ = κ/(2πσ2), the maximum value of h(t|x).\nWe will refer to κ∗ as the (Thomas) landmark weight, and ﬁnd it convenient\nto express κ∗ as a multiple of the background intensity rate *. Large values\n\n\fSPECIALIZED EXAMPLES\n\n97\n\n9000\n\n8000\n\n7000\n\n6000\n\n5000\n\n4000\n\n3000\n\n2000\n\n1000\n\n0\n1\n\n9000\n\n8000\n\n7000\n\n6000\n\n5000\n\n4000\n\n3000\n\n2000\n\n1000\n\n0\n1\n\n9000\n\n8000\n\n7000\n\n6000\n\n5000\n\n4000\n\n3000\n\n2000\n\n1000\n\n0\n1\n\n9000\n\n8000\n\n7000\n\n6000\n\n5000\n\n4000\n\n3000\n\n2000\n\n1000\n\n0\n1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\nFigure 5.2 Features of the prior and posterior distributions using the Neyman–\nScott model with a Thomas intensity, (cid:1) = 0.1 and σ = 0.07, and a Strauss prior,\nβX = 0.1, r = 0.1, and γX = 0.1. The dataset consists of seven points in the unit\nsquare. Left: histogram of the number of landmarks. Right: contour plot of the\nintensity. Top: the Strauss prior. (cid:1) = 0.1 and σ = 0.07. Row 2: the posterior with\nκ∗ = (cid:1). Row 3: the posterior with κ∗ = 2(cid:1). Row 4: the posterior with κ∗ = 5(cid:1). In\neach case, 10, 000 exact samples were drawn using the Kendall–Møller algorithm.\n\nof κ∗ increase the inﬂuence of the landmarks, while small values increase\nthe inﬂuence of the background noise. The Kendall–Møller algorithm was\nused to sample from the posterior; Kprior = βX . The algorithm provided\n10,000 samples on a Silicon Graphics workstation in less than 1 minute for\nthe prior and about 3 minutes for the largest value of κ∗.\n\n\f98\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\n5.4.2 Pure Silhouette Models\n\nIn this section we look at some special cases of the pure silhouette model:\nf (y|x) = f (y) and c = 1. In this case, {s(y|x) ≥ c} = {y ⊂ S(x)},\nand the landmarks are now unidentiﬁable in a frequentist sense because\nthe likelihood only depends on the landmarks through their silhouette: for\nξ ∈ W \\x such that S({ξ}) ⊂ S(x) (that is, S(x ∪ {ξ}) = S(x)), we have\npY |X=x(·) = pY |X=x∪{ξ}(·). The conditions of Theorem 5.2.1 are satisﬁed\nprovided the prior is locally stable, and then Kpost = Kprior. The posterior\nnow only depends on the data through the restriction y ⊂ S(x) because\nf (y) is absorbed into the normalizing constant:\n\npX|Y =y(x) ∝ αY (x)pX (x)1{y ⊂ S(x)}.\n\nThus it is possible to generate draws from the unrestricted posterior before\nseeing the data. The computationally expensive MCMC simulations can\nbe carried out ahead of time; once the data become available, we just",
    "chunk_order_index": 60,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-acfb5c6c586aa092e05455b23c4cad4c": {
    "tokens": 1200,
    "content": "now only depends on the data through the restriction y ⊂ S(x) because\nf (y) is absorbed into the normalizing constant:\n\npX|Y =y(x) ∝ αY (x)pX (x)1{y ⊂ S(x)}.\n\nThus it is possible to generate draws from the unrestricted posterior before\nseeing the data. The computationally expensive MCMC simulations can\nbe carried out ahead of time; once the data become available, we just\nselect those draws with silhouettes covering the data. Suppose now that\nthe observation process is inhomogeneous Poisson with intensity βY (t) on\nn(y)\nthe silhouette, so f (y) =\nj=1 βY (yj). If the prior is homogeneous Poisson\nthen the unrestricted posterior turns out to be an area-interaction process,\nas stated in the following theorem.\n\n(cid:11)\n\nTheorem 5.4.1 In the pure silhouette model, if the prior is homogeneous\nPoisson with parameter βX , and the observation process is Poisson with in-\ntensity βY (·), then the unrestricted posterior is an area-interaction process\nwith ν(·) =\n\n· βY (t) dt and parameters β = βX , γ = e:\n\n(cid:18)\n\npX|Y =y(x) ∝ βn(x)\n\nX e−ν(S(x))1{y ⊂ S(x)}.\n\nProof: Note that\n\nαY (x) =\n\n\n\n(cid:2)\n\n\n\nn(v)(cid:6)\n\n{v:v⊂S(x)}\n\nj=1\n\n\n\n−1\n\nβY (vj) π(dv)\n\n\n\n\n\n(cid:2)\n\n\n\n=\n\nn(v)(cid:6)\n\nW\n\nj=1\n\n\n\n−1\n\nβY (vj)1{vj ∈ S(x)} π(dv)\n\n\n\n.\n\nThen, applying Lemma 5.2.1 to the intensity β(t) = βY (t)1{t ∈ S(x)},\n\n(cid:23)\n\n(cid:2)\n\n(cid:24)\n\nαY (x) = exp\n\n|W | −\n\nβY (t) dt\n\n.\n\nS(x)\n\n\fSPECIALIZED EXAMPLES\n99\nSince γX = 1 and e|W | can be absorbed into the normalizing constant, the\nresult follows by substitution in (5.1). ✷\n\n300\n\n200\n\n100\n\n0\n\n0\n\n300\n\n200\n\n100\n\n0\n\n0\n\n300\n\n200\n\n100\n\n0\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\nFigure 5.3 Features of the posterior using the pure silhouette model, rsil = 0.15,\nand a Poisson prior. The observation model is homogeneous Poisson, with βY =\n3. Top row: βX = 0.693, so that the prior probability of the empty conﬁguration\nis 0.5. Middle row: βX = 2. Bottom row: βX = 3. In each case 500 exact samples\nwere drawn using the Kendall–Møller algorithm.\n\npX|Y =y(x) ∝ βn(x)\n\nThus the unrestricted posterior is attractive (γ > 1) in this case. For a\nhomogeneous Poisson likelihood with intensity βY , the above result reduces\nto\n\nX (eβY )−|S(x)|1{y ⊂ S(x)}.\n\n(5.6)\nTo implement perfect sampling for (5.6), use Kpost = Kprior = βX . Figure\n5.3 illustrates this example with the same data as Figure 5.2. For this ﬁgure\nwe varied the prior intensity βX , while keeping all other hyperparameters\nconstant. In the top row the prior probability of the empty conﬁguration\nis 0.5 (βX = 0.693). The Kendall–Møller algorithm along with rejection\nsampling provided 500 exact samples in about 72 hours on a Silicon Graph-\nics workstation. The sampling in this case took much longer than for the\nNeyman–Scott model (even for a reduced number of samples) due to an\nacceptance rate in the rejection sampling step of approximately 1/44, 000;\nthis was caused by the diﬃculty of covering the data by the silhouette of\n\n\f100\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\nthe landmarks. The results are markedly diﬀerent from the Neyman–Scott\nmodel (Figure 5.2): three distinct circular clusters are readily apparent.\nNow suppose that the prior is an arbitrary locally stable point process\n(and the observation process is still inhomogeneous Poisson with intensity\nβY (t)). From the expression for αY (·) in the proof of Theorem 5.4.1, we\nsee that the Papangelou conditional intensity corresponding to αY (·) is\nattractive:\n\n(cid:1)\n\n(cid:2)\n\n(cid:3)\n\nαY (x ∪ {ξ})\nαY (x)\n\n= exp\n\n−\n\nS({ξ})\\S(x)\n\nβY (t) dt\n\nfor ξ ∈ W \\x, which is increasing in x. We conclude that the unrestricted\nposterior is attractive if the prior is attractive. Perfect sampling is feasible\nfor either an attractive or a repulsive prior. One interesting choice of prior\nis the area-inter",
    "chunk_order_index": 61,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-4e289fadf993b621f4efb9e4aff04618": {
    "tokens": 1200,
    "content": ":1)\n\n(cid:2)\n\n(cid:3)\n\nαY (x ∪ {ξ})\nαY (x)\n\n= exp\n\n−\n\nS({ξ})\\S(x)\n\nβY (t) dt\n\nfor ξ ∈ W \\x, which is increasing in x. We conclude that the unrestricted\nposterior is attractive if the prior is attractive. Perfect sampling is feasible\nfor either an attractive or a repulsive prior. One interesting choice of prior\nis the area-interaction process with parameters βX , γX , ν = Lebesgue mea-\nsure, and interaction radius r taken to coincide with the silhouette radius.\nThen the unrestricted posterior density (cf. (5.6)) is an area-interaction\nprocess with parameters β = βX and γ = γX eβY :\n\nfX|Y =y(x) = βn(x)\n\nX (γX eβY )−|U (x)|.\n\n(5.7)\nThe unrestricted posterior is then repulsive if βY ≤ −log(γX ) and attrac-\ntive if βY ≥ −log(γX ). Beyond the examples we have considered, it may\nbe diﬃcult to check the attractive or repulsive properties; in that case,\na computationally feasible approach to perfect sampling for the posterior\ndoes not appear to be readily available. For the general cluster model with\n0 < c < 1, the limits of integration for αY (x) are diﬃcult to handle. If\nc = 0 this integral is over the entire window W . If c = 1 this integral\nis over the silhouette S(x). But for the general case no such simpliﬁca-\ntion seems available, and the resulting Papangelou conditional intensity is\nintractable. A fully Bayesian treatment in which the various hyperparam-\neters are assigned priors may also be diﬃcult to implement using perfect\nsampling.\n\n5.5 Leukemia Incidence in Upstate New York\n\nThe study region is comprised of 790 census tracts in an eight county region\nof upstate New York; it includes the cities of Syracuse in the north and\nBinghamton in the south. The 1980 U.S. census reported a total of 1,057,673\nresidents. Leukemia incidence was recorded by the New York Department of\nHealth during the years 1978–82, see Waller et al. (1992,1994). The data are\navailable from the Statlib archive (lib.stat.cmu.edu). In some instances\na case could not be associated with a unique census tract, resulting in many\nfractional counts. Our approach does not accommodate this type of data,\nso we follow Ghosh et al. (1999) and group the 790 census tracts into 281\nblocks in order to identify most of the cases with a speciﬁc block. Less\n\n\fLEUKEMIA INCIDENCE IN UPSTATE NEW YORK\n\n101\n\nthan 10% of all cases could not be identiﬁed with a speciﬁc block, and such\ncases are excluded from our analysis. The locations of the centroids of the\n\n5\n\n6\n\n11\n\n7\n\n10\n\n89\n\n12\n\n3\n4\n\nFigure 5.4 Left: Locations of 552 leukemia cases in upstate New York, along with\nan approximate outline of the eight county study region. The rectangular region\nis 1 × 1.2 square units. Right: contour plot of the population density λ(t), and the\nlocations of the 11 hazardous waste sites.\n\ncensus blocks are available, but precise locations of the leukemia cases are\nnot. Our methods require these precise locations, so we randomly dispersed\nthe cases throughout their corresponding census blocks. An approximation\nto the census blocks was achieved using the Voronoi tesselation (Green\nand Sibson 1978) with the Euclidean distance metric: each point in the\nregion was identiﬁed with the closest centroid. All the cases identiﬁed with\na particular centroid were then randomly dispersed in the block identiﬁed\nwith that centroid; if there was exactly one case in a block we placed\nit at the centroid. Five independent randomizations of the case locations\n(within census blocks) are used in our study; see the left panel of Figure\n5.4 for one such example. This provides an ad-hoc sensitivity analysis for\nour approach. The approximate study region is also indicated in the left\npanel of Figure 5.4, but to avoid edge eﬀects we consider the enlarged\nrectangular area (roughly 145 × 174 square kilometers) as the support for\nthe landmarks. Our analysis is based on the Neyman–Scott model with the\nleukemia intensity rate speciﬁed by\n(cid:4)\n\n(cid:5)\n\nn(x)(cid:12)\n\nµ(t|x) = λ(t)\n\n* +\n\nh(t|xi)\n\n,\n\nwhere λ(t) adjusts for population density, h(t|x) is the Thomas intensity\n(5.5), and * > 0 is a background leukemia incidence rate. Our earlier treat-\nment of the Neyman–Scott model extends without change to this form of\n\ni=1\n\n\f102\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\nthe model because λ(t) does not depend on x. We use a Strauss prior for\nthe landmarks x. For λ(t) we use a smoothed version of the population\ndensity based on the 1980 U.S. census (extrapolated to the large rectan-\ngular region); see the right panel of Figure 5.4. This plot also gives the\nlocations of",
    "chunk_order_index": 62,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-c131e6d3aa6060aaa02312c67c048006": {
    "tokens": 1200,
    "content": "102\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\nthe model because λ(t) does not depend on x. We use a Strauss prior for\nthe landmarks x. For λ(t) we use a smoothed version of the population\ndensity based on the 1980 U.S. census (extrapolated to the large rectan-\ngular region); see the right panel of Figure 5.4. This plot also gives the\nlocations of the 11 inactive hazardous waste sites suspected of causing ele-\nvated leukemia incidence rates. The original dimensions (kilometers) of the\nrectangular region in Figure 5.4 are divided by 145 for the purpose of this\nanalysis, resulting in a rectangular region which is 1 × 1.2 square units. For\nthe interaction radius in the Strauss prior we use r = 0.1 (approximately\n14.5 kilometers), and the interaction parameter is taken as γX = 0.1. The\nchoice of these parameter values is rather arbitrary, but recall from the\ntoy example (Section 5.4.1) that varying these values seemed to have little\neﬀect on the posterior distribution. In the Neyman-Scott model we specify\n* = 5.2 × 10−4, which is the average leukemia incidence rate of 5.2 cases\nper ten thousand residents of the study region. For the standard devia-\ntion of the Thomas intensity we choose σ = .01 (approximately 1.45 km.).\nThese hyperparameter values will remain ﬁxed throughout our analysis of\nthe New York leukemia data. In the context of the leukemia data and toxic\nwaste sites the choice of the prior hyperparameters is of great importance. If\nwe believe that the incidence locations are simply a function of population\ndensity, and are not inﬂuenced by any underlying sources (such as the waste\nsites), then the prior should place high probability on the empty conﬁgura-\ntion. This is certainly a reasonable (and perhaps conservative) assumption.\nShould the posterior indicate the existence of one or more landmarks (i.e.\nplace low probability on the empty conﬁguration), then one would have a\nstrong argument in favor of clustering. It may also be reasonable to place\nhigh prior probability on the existence of one landmark, but to posit the\nexistence of more than one landmark is probably stacking the deck a bit too\nmuch. It should be noted that the locations of the eleven toxic waste sites\nare not a part of our model. In our initial analysis we choose a prior which\nplaces high probability on the empty conﬁguration: βX = 0.113. Figure\n5.5 is based on the data shown in the left panel of Figure 5.4, and shows\nthe eﬀect of varying the landmark weight κ∗ on the number of posterior\npoints produced. The number of landmarks given by the prior distribution\nis included for reference. For each ﬁgure we used a Silicon Graphics work-\nstation to produce 1000 samples using the Kendall–Møller algorithm. (It\ntook less than one minute to produce the samples from the prior, and just\nover 4.5 hours for κ∗ = 0.23*.) It is clear from this ﬁgure that increasing the\nlandmark weight has little eﬀect on the number of posterior landmarks. In\nfact, the posterior probability of the empty conﬁguration is approximately\n80% for each value of κ∗, even though the prior probability of the empty\nconﬁguration is about 50%.\n\nFigure 5.6 is similar to Figure 5.5, except that we use βX = 0.5. The\n\n\fLEUKEMIA INCIDENCE IN UPSTATE NEW YORK\n\n103\n\n800\n\n600\n\n400\n\n200\n\n0\n1\n\n800\n\n600\n\n400\n\n200\n\n0\n1\n\n800\n\n600\n\n400\n\n200\n\n0\n1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0\n\n1\n\n2\n\n3\n\n4\n\nFigure 5.5 Histograms of the number of points in the prior and two posterior\ndistributions. Each plot is based on 1000 exact samples. The prior is Strauss,\nwith r = 0.1, βX = 0.113 and γX = 0.1. The likelihood is Neyman-Scott with a\nThomas intensity, (cid:1) = 5.2 × 10−4, σ = 0.01. Prior distribution; posterior with\nκ∗ = 0.1(cid:1); κ∗ = 0.23(cid:1).\n\nhistogram for the prior shows that most of the prior weight is placed on\nconﬁgurations comprised of a single landmark. Nevertheless, the posterior\ndistributions still strongly favor the empty conﬁguration. As the landmark\nweight κ∗ increases there is a slight movement towards conﬁgurations with\nat least one landmark. At large values of κ∗, limitations in computing\npower come into play. It took 146 hours to complete the simulation with\nκ∗ = 0.23*. Initial runs with κ∗ = 0.25* indicate that the time required for\na complete run is prohibitive, and the resulting histograms are virtually\nidentical to that for κ∗ = 0.23*. It is unfortunate that our exploration of\nthis data is limited in this manner. Based on the results seen in the toy\nexample of Section 5.4.1 and in the redwood seedling example of the next",
    "chunk_order_index": 63,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-a13d643e5311633d6df7ac054faf2e0d": {
    "tokens": 1200,
    "content": "= 0.23*. Initial runs with κ∗ = 0.25* indicate that the time required for\na complete run is prohibitive, and the resulting histograms are virtually\nidentical to that for κ∗ = 0.23*. It is unfortunate that our exploration of\nthis data is limited in this manner. Based on the results seen in the toy\nexample of Section 5.4.1 and in the redwood seedling example of the next\nsection, it seems likely that larger values of κ∗ would result in a signiﬁ-\ncant increase in the number of posterior landmarks. Figure 5.7 gives the\n\n700\n\n600\n\n500\n\n400\n\n300\n\n200\n\n100\n\n0\n1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n700\n\n600\n\n500\n\n400\n\n300\n\n200\n\n100\n\n0\n1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n700\n\n600\n\n500\n\n400\n\n300\n\n200\n\n100\n\n0\n1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\nFigure 5.6 Same as Figure 5.5 except that βX = 0.5.\n\nposterior intensity contour plots when βX = 0.5, for three values of κ∗. As\nκ∗ increases, the posterior landmarks concentrate in two small areas (close\nto Syracuse and Binghamton) even though the number of posterior land-\nmarks does not change signiﬁcantly (see Figure 5.6). Figure 5.8 shows the\nrelationship of the hazardous waste site locations to areas of high posterior\nlandmark intensity. Note that several of the waste sites (1, 2, 3, and 4) are\nlocated close to areas of high intensity. To assess the signiﬁcance of an\n\n\f104\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\nFigure 5.7 Intensity contour plots for posterior distributions with κ∗ = 0.1(cid:1), κ∗ =\n0.15(cid:1), and κ∗ = 0.2(cid:1). Each plot is based on 1000 exact samples. The prior is\nStrauss, with interaction radius r = 0.1, βX = 0.5 and γX = 0.1. The likelihood\nis Neyman-Scott with a Thomas intensity, (cid:1) = 5.2 × 10−4, σ = 0.01.\n\n 5\n\n 6\n\n11\n\n 7\n\n10\n\n 8 9\n\n 2\n\n 1\n\n 3\n 4\n\nFigure 5.8 Posterior intensity map for the leukemia data, Neyman–Scott model\nwith (cid:1) = 5.2 × 10−4, σ = 0.01, κ∗ = 0.23(cid:1), and a Strauss prior with interaction\nradius r = 0.1, βX = 0.5 and γX = 0.1. Locations of the 11 hazardous waste sites\nare included.\n\nelevated leukemia rate in the neighborhood of a given site, we compare the\n‘observed’ with the ‘expected’ posterior landmark distribution. The rele-\nvant null hypothesis here is that the leukemia cases form an inhomogeneous\nPoisson process with intensity ρλ(t), where ρ is the average leukemia rate\nthroughout the study region. To sample from the null distribution, we gen-\nerate an artiﬁcial dataset using independent Poisson counts for each census\ntract, then analyze the artiﬁcial data in the same way as the original data.\nFor the artiﬁcial data, histograms of the number of posterior landmarks\n(not shown) look almost identical to those in Figure 5.6, and intensity\nplots (also not shown) like those shown in Figure 5.7. In Figure 5.9 we\n\n\fLEUKEMIA INCIDENCE IN UPSTATE NEW YORK\n\n105\n\ncompare the observed and expected posterior probabilities of at least one\nlandmark within a given distance (0–7.25 kms) of site 1 (with the same hy-\nperparameters as in Figure 5.6). The 20 dotted lines correspond to samples\nfrom the null distribution (20 diﬀerent artiﬁcial datasets), and the 5 solid\nlines correspond to the data (ﬁve random dispersions of the leukemia cases\nthroughout their corresponding census blocks). For this site, it is clear that\nincreasing the landmark weight increases the disparity between the real\nand the simulated datasets. For κ∗ ≥ 2.0, these plots seem to provide some\nevidence of elevated leukemia rates in the neighborhood of site 1. (It should\nbe noted that the vertical scales are diﬀerent for each of the plots.) We re-\n\n0.035\n\n0.03\n\n0.025\n\n0.02\n\n0.015\n\n0.01\n\n0.005\n\n0\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n0.014\n\n0.012\n\n0.01\n\n0.008\n\n0.006\n\n0.004\n\n0.002\n\n0\n\n0\n\n0.045\n\n0.04\n\n0.035\n\n0.03\n\n0.025\n\n0.02\n\n0.015\n\n0.01\n\n0.005\n\n0\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n0.02\n\n0.018\n\n0.016",
    "chunk_order_index": 64,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-4a2d5e403bd5cf4e32c25672f31fc250": {
    "tokens": 1200,
    "content": "0.006\n\n0.004\n\n0.002\n\n0\n\n0\n\n0.045\n\n0.04\n\n0.035\n\n0.03\n\n0.025\n\n0.02\n\n0.015\n\n0.01\n\n0.005\n\n0\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n0.02\n\n0.018\n\n0.016\n\n0.014\n\n0.012\n\n0.01\n\n0.008\n\n0.006\n\n0.004\n\n0.002\n\n0\n\n0\n\n0.04\n\n0.035\n\n0.03\n\n0.025\n\n0.02\n\n0.015\n\n0.01\n\n0.005\n\n0\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\nFigure 5.9 Posterior observed (solid lines) and expected (dotted lines) probabilities\nof at least one landmark within a given distance (in kms.) of site 1. Neyman–Scott\nmodel with (cid:1) = 5.2 × 10−4, σ = 0.01, and a Strauss prior with interaction radius\nr = 0.1, βX = 0.5 and γX = 0.1. Top row: κ∗ = 0.1(cid:1); κ∗ = 0.15(cid:1); κ∗ = 0.2(cid:1).\nBottom row: κ∗ = 0.22(cid:1); κ∗ = 0.23(cid:1). Each plot is based on 1000 exact samples.\n\npeated the comparison shown in Figure 5.9 for each of the 11 hazardous\nwaste sites, and found no evidence of elevated leukemia rates in the neigh-\nborhood of any site other than site 1. The complete set of comparisons\ncan be seen in Loizeaux and McKeague (2001). Ghosh et al. (1999) found\nlittle evidence of elevated leukemia rates in the proximity of any of the\nwaste sites. They applied a hierarchical Bayes generalized linear model to\nestimate the leukemia incidence rate locally, and included the hazardous\nwaste site locations in their model (in particular, using the inverse distance\nto the nearest hazardous waste site as a covariate). Ahrens et al. (1999)\nfound increased rates at three of the sites (1, 5 and 7). Denison and Holmes\n(2001) found signiﬁcant evidence of increased leukemia rates in the neigh-\nborhoods of sites 1 and 2. Their Bayesian partition model assumes that the\n\n\f106\n\nPERFECT SAMPLING FOR POINT PROCESS CLUSTER MODELLING\n\nregion can be split into local areas in which the leukemia counts come from\nthe same distribution. The Voronoi tesselation (Green and Sibson 1978) is\nused to deﬁne these areas. Our results are mixed. On the one hand, the\nposterior distributions place approximately 50% of their mass on the empty\nconﬁguration. But on the other hand, a comparison of the actual data with\nartiﬁcial datasets based only on the population density shows a marked\ndiﬀerence at site 1.\n\n5.6 Redwood Seedlings Data\n\nThese data have been analyzed by Strauss (1975), Ripley (1977), Diggle\n(1978) and van Lieshout (1995), among others and was also used in the\nprevious chapter. Our results are shown in Figure 5.10. The prior hyperpa-\n\n7000\n\n6000\n\n5000\n\n4000\n\n3000\n\n2000\n\n1000\n\n0\n1\n\n7000\n\n6000\n\n5000\n\n4000\n\n3000\n\n2000\n\n1000\n\n0\n1\n\n7000\n\n6000\n\n5000\n\n4000\n\n3000\n\n2000\n\n1000\n\n0\n1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\nFigure 5.10 Features of the prior and two posterior distributions for the redwood\nseedling data using the Neyman–Scott model, (cid:1) = 0.1 and σ = 0.07. Top row: the\nStrauss prior, with interaction radius r = 0.2, βX = 0.124, and γX = 0.1. Middle\nrow: posterior with κ∗ = 0.5(cid:1). Bottom row: posterior with κ∗ = (cid:1). Left: histogram\nof the number of landmarks. Right: contour plot of the intensity. In each case\n10,000 exact samples were drawn using the Kendall–Møller algorithm.\n\nrameters have been chosen to produce empty landmark conﬁgurations with\nprobability 50%. For κ∗ = 0.5* the posterior shows a clear shift towards\n\n\fREDWOOD SEEDLINGS DATA\n107\nthe empty conﬁguration, but this tendency is reversed as κ∗ is increased\nto *. In addition, the intensity plots indicate that the posterior landmarks\nstart to collect around the data as κ∗ increases.\n\nAcknowledgements\n\nThis research was partially supported by NSA Grant MDA904-99-1-0070\nand NSF Grant 9971784. Equipment support was provided under ARO\nGrant DAAG55",
    "chunk_order_index": 65,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-85b3e6599cb00b0fb68918367f7406f3": {
    "tokens": 1200,
    "content": "towards\n\n\fREDWOOD SEEDLINGS DATA\n107\nthe empty conﬁguration, but this tendency is reversed as κ∗ is increased\nto *. In addition, the intensity plots indicate that the posterior landmarks\nstart to collect around the data as κ∗ increases.\n\nAcknowledgements\n\nThis research was partially supported by NSA Grant MDA904-99-1-0070\nand NSF Grant 9971784. Equipment support was provided under ARO\nGrant DAAG55-98-1-0102 and NSF Grant 9871196.\n\n\f\fCHAPTER 6\n\nBayesian Estimation and\nSegmentation of Spatial Point\nProcesses Using Voronoi Tilings\n\nS.D. Byers\n\nA.E. Raftery\n\n6.1 Introduction\n\nIn this chapter we consider Bayesian estimation and segmentation for non-\nhomogeneous Poisson point processes in two dimensions. This work turns\nout to be easily generalizable to higher dimensions and to have similarities\nwith work done in one dimension.\n\nThe principal motivation for the methods considered here can be found in\nMuise and Smith (1992), Dasgupta and Raftery (1998), Byers and Raftery\n(1998) and Allard and Fraley (1997). The simplest case is the segmenta-\ntion of a point process of inhomogeneous rate, for instance the isolation of\nregions of high density in a point process in the plane, or in a higher di-\nmensional space. Estimation of the rate is also an issue, one that might be\nintimately bound up with the segmentation as the segmentation methods\nmight serve as a (semi-)parametric method of rate estimation.\n\nIn Dasgupta and Raftery (1998) the assumption is made that the regions\nof high density are formed by a mixture of Gaussian distributions on a back-\nground Poisson process and model-based clustering Banﬁeld and Raftery\n(1993) is used to segment the data. This method is particularly suited to\nﬁnding very linear features or those approximated by linear forms. In By-\ners and Raftery (1998) and Allard and Fraley (1997) the point process is\nassumed to be one of piecewise constant rate, with only two distinct rates\nbeing present. The related methods of kth nearest neighbors and Voronoi\ntile areas, respectively, are used to segment the data.\n\nAll of these methods provide some form of classiﬁcation of the events in\nthe process into high or low density regions. The aim of this paper is to\nexplore methods of gaining more information, such as a region-based es-\ntimator with uncertainties and other complex posterior probabilities. The\nVoronoi tile area based method provides a region but this can be quite\ncrude, and has no uncertainties. Fully Bayesian extensions to the Gaussian\ncluster approach with solutions via MCMC were considered in Bensmail\n\n\f110\n\nBAYESIAN ESTIMATION OF SPATIAL POINT PROCESSES\n\net al. (1997). We intend to provide the analogous exploration for the ap-\nproaches in Byers and Raftery (1998) and Allard and Fraley (1997).\n\nFigure 6.1 shows some point process data from a mineﬁeld detection\nproblem that might be segmented into two parts, high density and low\ndensity. The second panel shows the data that are estimated to be in the\nhigher intensity region on the basis of their posterior probabilities. Section\n6.5 discusses this example further and compares other methods of segmen-\ntation.\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•",
    "chunk_order_index": 66,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-6f852902309387a23b35264242ec0b5c": {
    "tokens": 1200,
    "content": "•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n• •\n\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n••\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•",
    "chunk_order_index": 67,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-b49b6e4d82f71233d12fce26bbe27e55": {
    "tokens": 1200,
    "content": "•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n••\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n••\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n(a)\n\n(b)\n\nFigure 6.1 Left panel shows a point process on a region, right panel shows an\nestimate of the",
    "chunk_order_index": 68,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-64d9b7e69bcdc435af8a88455335e07d": {
    "tokens": 1200,
    "content": "•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n(a)\n\n(b)\n\nFigure 6.1 Left panel shows a point process on a region, right panel shows an\nestimate of the points in the high rate region of the data. The detection rate is\n97.0% while there are 4.2% false positives.\n\nThe formulation used in the methods examined here is described in Sec-\ntion 6.2. Section 6.3 deals with the speciﬁcs of intensity estimation while\nSection 6.4 deals with aspects of segmentation. Some examples are shown\nin Section 6.5 while Section 6.6 contains some discussion of this and future\nwork.\n\n6.2 Proposed Solution Framework\n\n6.2.1 Formulation\n\nThe proposed solution is to approximate a point process as a Poisson point\nprocess with piecewise constant rate. Thus the region under consideration,\nK\nS, will be partitioned up into sets Bk, k = 1, · · · , K such that\nk=1 Bk = S\nand Bi ∩ Bj = ∅, for all i (cid:4)= j. The sets will be generated and manipu-\nlated by constructing the Voronoi tiling of a set of synthetic generating\npoints, in general unrelated to the data points themselves. Section 6.2.2\n\n(cid:1)\n\n\fPROPOSED SOLUTION FRAMEWORK\n\n111\n\ngives a brief account of Voronoi tiling. This framework will be treated in\na Bayesian manner and solutions will be sought with Markov chain Monte\nCarlo methods.\n\nIn order to estimate the rate of a process as a function of space, each tile\nwill have its own rate. The posterior distribution of numbers of tiles, tile\npositions and rates on each tile can then provide an estimate of the rate\nand the variability of the estimate as a function of space. A motivation for\nusing this framework is that it has the potential to recover discontinuities in\nthe rate of the process while approximating smooth gradients in intensity.\nIn order to segment a point process according to intensity the tiles will\nbe grouped into two sets, each set having a diﬀerent rate. More than two\nsets could be used in order to allow segmentation into more groups; indeed\na variable number of sets could be used.\n\n6.2.2 Voronoi Tilings\nThe Voronoi tiling of a set of points {ck, k = 1, · · · , K} in the plane is\na partition of the plane into regions Bk, k = 1, · · · , K such that for all\nx ∈ Bk, d(x, ck) < d(x, cl), l (cid:4)= k. Voronoi tiles are always convex poly-\ngons. An overview of the history of Voronoi tilings with some applications\nand algorithms for computation can be found in Okabe et al. (2000). The\npartition generated is convenient in that it is easy to ﬁnd which set, or\ntile, a point not in the generating set belongs to simply by determining\nto which generating point it is closest. This partition is also convenient in\nterms of its speciﬁcation. Only the generating points need be speciﬁed to\nknow the tiling, with the possible addition of a window deﬁning the region\nunder consideration. This framework is similar to that of the simple im-\nage segmentation example illustrating reversible jump Markov chain Monte\nCarlo in Green (1995). There a point process in one dimension has its rate\nestimated with possibilities for segmentation using a method that might\nbe recast in a Voronoi tiling parameterization. Voronoi tilings extend to\nhigher dimensions and algorithms and code exists to ﬁnd them in general\ndimension.\n\n6.2.3 Markov Chain Monte Carlo Using Dynamic Voronoi Tilings\n\nIn the model we use a piecewise constant rate point process which will be\nspeciﬁed and controlled by the Voronoi tiling of a set of synthetic generating\npoints. In the MCMC algorithms used to explore posterior distributions,\nsimple changes in the tiling will enable movement around the state space.\nLocal changes can be made to a tiling by moving, adding or deleting a gen-\nerating point. Adding and deleting a point induces strictly local changes in\nterms of neighbor relations, but moving a generating point may theoreti-\ncally induce larger scale changes, regardless of how small the movement is.\n\n\f112\n\nBAYESIAN ESTIMATION OF SPATIAL POINT PROCESSES\n\nOn the other hand small movements of generating points can induce much\nmore subtle changes to the tiling than addition or deletion.\n\nThe task of computing Voronoi tilings we delegate to deldir, a package\nwritten by Rolf Turner at the University of New Brunswick. The driver\nroutines in RATFOR were used both for our MCMC and via the Splus\nstatistical package for display and interactive investigation purposes.\n\n6.3 Intensity Estimation\n\n6.3.1 Formulation\n\nA general Bayesian formulation for the Voronoi tiling model of the intensity\nof a point process is:\n\nLikelihood ∝\n\nK(cid:2)\n\nλnk\nk exp{−λkak}\n\nPriors\n\nk=1\nK ∼ Poisson(ν)\n{λk; k = 1, · · · , K}|K iid ∼",
    "chunk_order_index": 69,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-75a25e7d100363b4cb2d93dff6c876ba": {
    "tokens": 1200,
    "content": "package for display and interactive investigation purposes.\n\n6.3 Intensity Estimation\n\n6.3.1 Formulation\n\nA general Bayesian formulation for the Voronoi tiling model of the intensity\nof a point process is:\n\nLikelihood ∝\n\nK(cid:2)\n\nλnk\nk exp{−λkak}\n\nPriors\n\nk=1\nK ∼ Poisson(ν)\n{λk; k = 1, · · · , K}|K iid ∼ Gamma(a, b)\n{ ck; k = 1, · · · , K}|K iid ∼ U {S}.\n\nHere the ak are the areas of the Voronoi tiles, or the sets Bk, and the\nnk are the numbers of points on each tile. Note that the number of tiles is\nnot ﬁxed in the formulation above, though it could be held at some ﬁxed\nvalue. A hyperprior could be placed on the parameter ν, and ν could be\nupdated in the MCMC schedule; this would allow greater ﬂexibility in the\nability to tile the region.\n\nThe posterior distribution induced by the above formulation is\n\nπ(K, {λk, ck; k = 1, · · · , K}|y) ∝ νK\nK!\n\nK(cid:2)\n\nk=1\n\nλnk+a−1\nk\n\nexp{−λk(ak + b)}.\n\n6.3.2 MCMC Implementation\n\nIn order to ﬁt the models described here we use Markov chain Monte Carlo\nto simulate from the posterior distribution of the parameters given the data.\nThe algorithms are of the Metropolis-Hastings type (Metropolis et al. 1953,\nHastings 1970), which have as a special case the Gibbs sampler (Geman and\nGeman 1984). The samples obtained by these methods from the posterior\ndistributions can then be used to form estimates of the intensity of the\nprocess or other quantities of interest.\n\n\fINTENSITY ESTIMATION\n\nFixed Number of Tiles\n\n113\n\nFirst we consider the simple case where we use a ﬁxed number of tiles in\nthe partition. We ﬁrst note the form of the full conditional distributions of\nthe parameters:\n\nπ(λk| . . .) ∼ Gamma(nk + a, ak + b),\nK(cid:3)\n\nK(cid:2)\n\nπ(ck| . . .) ∝\n\nλnk+a−1\nk\n\nexp{−\n\nk = 1, · · · , K\n\nλk(nk + b)},\n\nk = 1, · · · , K.\n\nk=1\n\nk=1\n\nThe | · · · notation is used to denote conditioning on all other parameters\nand the data. In the full conditional for ck the inﬂuence of the diﬀerent\nvalues for the parameters is manifested implicitly in the values of ak and\nnk from the tiling induced by changes in ck.\n\nThe simplest sampler is one that employs a Gibbs step for each of the λk\nand then proposes moving one or more generating points in a Metropolis-\nHastings step. A simple proposal for moving a generating point is uniform\nin a small square centered at the current position, rendering the move of\nthe Metropolis type.\n\nMore general samplers might employ larger scale moves of generating\npoints accompanied by the adjustment of the rate on the tile according to\nwhere the proposal generating point sits. It is possible to move more than\none, or indeed all of the generating points. The following three schemes\nwere implemented and used together;\n\n• Propose movement of one generating point a small distance.\n\n• Propose movement of a generating point to anywhere in the region. This\nis more like deleting a generating point and then adding a new one, see\nthe next section. Also the intensity might be proposed to change.\n\n• Propose to move all generating points by very small amounts. This will\nhave the eﬀect of facilitating capture of detail at discontinuities in the\nintensity.\n\nWhichever of these proposals is tried, the basic elements of the move\nremain the same: propose movements of points, recompute the new tiling,\nﬁnd the acceptance probability for the new tiling versus the old tiling and\nupdate accordingly.\n\nFigure 6.2 shows two possible methods of altering the tiling by movement\nor deletion of a generating point. In panel (a) the point to be moved is\ncircled, its new position is shown with an empty circle. The changes to the\ntiling are shown with the dotted lines. In panel (b) a point to be deleted is\ncircled.\n\n\f114\n\nBAYESIAN ESTIMATION OF SPATIAL POINT PROCESSES\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n\n•\n\n•\n\n(a)\n\n(b)\n\nFigure 6.2 Examples of two types of proposal for altering the Voronoi tiling in the\nMCMC algorithm. (a) Proposed movement of a generating point from the ringed\npoint to the empty circle. (b) Deletion (or addition) of the ringed generating point.\nThe dotted lines indicate the induced changes to the tiling.\n\nVariable Number of Tiles\n\nIt is desirable to consider a variable number of tiles in the tiling for reasons\nof ﬂexibility and for mobility of the samplers. For instance, if too small a\nnumber of tiles is used, there might not be the ability to capture detail\nin the process. Regarding mobility, the addition or deletion of a tile can\ninduce large plausible changes in the conﬁguration. In order to sample",
    "chunk_order_index": 70,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-e3ae6b04358cdbfe709202864f290425": {
    "tokens": 1200,
    "content": "the induced changes to the tiling.\n\nVariable Number of Tiles\n\nIt is desirable to consider a variable number of tiles in the tiling for reasons\nof ﬂexibility and for mobility of the samplers. For instance, if too small a\nnumber of tiles is used, there might not be the ability to capture detail\nin the process. Regarding mobility, the addition or deletion of a tile can\ninduce large plausible changes in the conﬁguration. In order to sample\nfrom a target distribution with a variable number of variables, conventional\nMCMC must be augmented by reversible jump Markov chain Monte Carlo\n(Green 1995).\n\nSimilar moves will be made to those seen previously, but with the addi-\ntion of a pair of moves that propose addition or deletion of a tile, with some\nsuitable adjustment of the intensities on the tiles involved. An addition or\na deletion has only local eﬀects on the tiling but even small movements of\ntile generating points have the capability to change the tiling at long range.\nThis has implications for computational eﬃciency, and the use of Voronoi\ntilings in Green (1995) exploits this with the use of the incremental tiling\nalgorithm seen in Green and Sibson (1978).\n\nWe make the same type of addition and deletion steps as in the Voronoi\nexample of Green (1995); the proposal distributions and acceptance prob-\nabilities are given there. Brieﬂy, the position of a new generating point is\nsampled from the prior and the rate associated with the induced tile is\n\n\fINTENSITY SEGMENTATION\n115\nproposed as λ∗\nk+1 = ˜λk+1v where ˜λk+1 is the weighted geometric mean\nof the neighboring tiles and v is drawn from the distribution with density\nf (v) = 5v4/(1 + v5)2. The deletion move is the reverse of this construction.\n\n6.4 Intensity Segmentation\n\nThe intention in this section is to segment point processes in the plane\nbased on their intensities. Of particular interest is the case where a process\nis assumed to have two intensities. Thus the process has piecewise constant\nintensity, the region under consideration being partitioned into two dis-\njoint sets, each having an intensity. The two sets need not form connected\nregions.\n\nWe consider the case of two regions, one of intensity λ0, the other of\nintensity λ1. The object is to partition the region of interest into two regions\nand make statements about the uncertainty with which this is done and\nthe estimates of λ0 and λ1.\n\n6.4.1 Formulation\n\nHere S is the region under consideration, A0 is the area of the sub-region\nassigned rate µ0, in which N0 data points fall, while A1 is the area of\nthe sub-region with N1 data points which has rate µ0 + µ1. The rates are\nparameterized in this manner to give identiﬁability of the subregions; oth-\nerwise one might get swapping of the regions and the rates. In the mineﬁeld\ncontext these are a noise rate and a mine rate giving an intensity inside a\nmineﬁeld of µ0 + µ1 and outside of µ0. The classiﬁcation of the tiles will be\ncoded in the variables dk, indicating high or low rate. The positions of the\ntile generating points are {ck : k = 1, · · · , K}. The following formulation\nresults from the above considerations:\n\nLikelihood ∝ µN0\n\nPriors\n\n0 (µ0 + µ1)N1 exp{µ0A0 + (µ0 + µ1)A1}\nµ0, µ1 ∼ Gamma(a, b)\nK ∼ Poisson(ν)\n{dk; k = 1, · · · , K}|K ∼ Bernoulli(p)\n{ ck; k = 1, · · · , K}|K ∼ U {S}.\n\nFixed Number of Tiles\n\nHere, as in the estimation context, it is possible to use a restricted set of\nmodels and ﬁx the number of tiles used in tiling the region. In this case\none sweep of the MCMC algorithm might look like the following:\n\n• update the two rates of the process,\n\n\f116\n\nBAYESIAN ESTIMATION OF SPATIAL POINT PROCESSES\n\n• change the classiﬁcation of a tile from high to low, or vice versa,\n\n• move a generating point, or even more than one.\n\nThe posterior distribution π(µ0, µ1, {dk, ck; k = 1, · · · , K}|y) is propor-\n\ntional to\n\nµN0+a−1\n0\n\nµa−1\n1\n\n(µ0+µ1)N1 exp{µ0(A0+A1+b)+µ1(A1+b)}\n\nK(cid:2)\n\nk=1\n\npdk (1−p)1−dk .\n\nThus, writing ξ = exp{µ0(A0 + A1 + b) + µ1(A1 + b)} for notational con-\nvenience, the relevant full conditional distributions are given by\n\nπ(µ0, µ1| · · · ) ∝ µN0+a−1\n\n0\n\nµa−1\n1\n\nπ(dk| · · · ) ∝ pdk (1 − p)1−dk µN0+a−1\nπ(ck| · · · ) ∝ µN0+a−1\n\nµa−1\n1\n\n0\n\n0\n\n(µ0 + µ1)N1 × ξ.\n\n(",
    "chunk_order_index": 71,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-ba9b7e436c00bead4851646fff1455b3": {
    "tokens": 1200,
    "content": "by\n\nπ(µ0, µ1| · · · ) ∝ µN0+a−1\n\n0\n\nµa−1\n1\n\nπ(dk| · · · ) ∝ pdk (1 − p)1−dk µN0+a−1\nπ(ck| · · · ) ∝ µN0+a−1\n\nµa−1\n1\n\n0\n\n0\n\n(µ0 + µ1)N1 × ξ.\n\n(µ0 + µ1)N1 × ξ\nµa−1\n1\n\n(µ0 + µ1)N1 × ξ\n\nThe MCMC steps for the segmentation are similar to those for the es-\ntimation algorithm, but additional care needs to be exercised in order to\nretain mobility. The rates of the process are updated together in a bivariate\nHastings step as they may be negatively correlated. They are proposed by\nmultiplying by exp(U ), U ∼ Uniform(−d, d). This gives a simple proposal\nratio of the ratio of the new to the old values, leading to an acceptance\nprobability α = min{1, R}, where\n\nR(µ0, µ1; µ(cid:3)\n\n0, µ(cid:3)\n\n1) =\n\n(cid:4)\n\n(cid:5)\n\n(cid:4)\n\n(cid:5)\n\n(cid:4)\n\na\n\nN0\n\nµ(cid:3)\n1µ(cid:3)\n0\nµ1µ0\n× exp{−A0(µ(cid:3)\n\nµ(cid:3)\n1 + µ(cid:3)\n0\nµ1 + µ0\n\nµ(cid:3)\n0\nµ0\n0 − µ0) − (b + A1)(µ(cid:3)\n\nN1\n\n(cid:5)\n\n(6.1)\n\n1 + µ(cid:3)\n\n0 − µ1 − µ0)}.\n\nThe dk are proposed to their opposite value. This gives the acceptance ratio\nfor dk = 0 → d(cid:3)\n\nk = 1 of\n\nR(dk; d(cid:3)\n\nk) =\n\n(cid:5)−nk\n\n(cid:4)\n\nµ0\nµ0 + µ1\n\nexp(−µ1ak),\n\n(6.2)\n\nwhere nk is the number of points that fall on tile k and ak is the area of\ntile k. The reverse move has acceptance ratio equal to the inverse of this.\nA generating point’s movement is proposed as in the estimation algo-\nrithm with the possible addition of a change in classiﬁcation. The new tiling\nwill deﬁne A(cid:3)\n1 may be proposed. Then the\nacceptance probability for the movement of a tile becomes α = min{1, R},\nwhere\n\n1, while a new µ(cid:3)\n\n0 and A(cid:3)\n\n0 and µ(cid:3)\n\n\fEXAMPLES\n\nR(ck\n\n;\n\nc(cid:3)\nk) = (PR)\n\n× exp{−A(cid:3)\n\n0µ(cid:3)\n\n(cid:4)\n\n(cid:5)\n\na−1\n\nµ(cid:3)\n1µ(cid:3)\n0\nµ1µ0\n\n(cid:3)N (cid:1)\n0\nµ\n0\nµN0\n0\n0 + A0µ0 − (b + A(cid:3)\n\n1\n\n0)N (cid:1)\n(µ(cid:3)\n1 + µ(cid:3)\n(µ1 + µ0)N1\n1 + µ(cid:3)\n1)(µ(cid:3)\n\n0) + (b + A(cid:3)\n\n1)(µ1 + µ0)}.\n\n117\n\n(6.3)\n\nHere PR is the proposal ratio for any additional adjustments to the rates\nor the classiﬁcations. The proposal for the position (u(cid:3)\nk) is symmetric\nso does not appear in the acceptance probability.\n\nk, v(cid:3)\n\nVariable Number of Tiles\n\nAs in the estimation formulation it is desirable to allow a variable number\nof tiles in constructing the partition of the region. The extension is similar\nto previously, it involves the addition of an addition and deletion pair of\nmoves in the reversible jump MCMC framework.\n\nThe proposal for the position of a new generating point is uniform on the\nregion S as before. Now the new induced tile must be assigned to either\nthe high or low rate, the simplest choice being to generate this assignment\nrandomly from the prior. The two rates do not have to be changed but some\nperturbation based on the change in the two areas or a random variable\nmight be used. This leads to an acceptance ratio of the form,\n\nR =\n\n(cid:4)\n\n(cid:5)\n\na−1\n\nµ(cid:3)\n0µ(cid:3)\n1\nµ0µ1\n× exp{−bµ(cid:3)\n\n1\n\n0)N (cid:1)\n(µ(cid:3)\n1 + µ(cid:3)\n(µ1 + µ0)N1\n0 + µ(cid:3)\n0 + (µ(cid:3)\n\n0A(cid:3)\n\n1\np\n\nν\nk + 1\n\n|J|\n\n1)A1 − µ0A0 + (µ0 + µ1)A1}.\n\nHere J is the Jacobian for the transformation from µ0, µ1 to µ(cid:3)\n1, dk. The\nfactor of 1/p arises from the random assignment of dk while the Poisson\nprior for K yields the next term. In this case it is hard to ﬁnd a good\nproposal for addition of a point to the tiling.\n\n0, µ(cid:3)",
    "chunk_order_index": 72,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-a24f6bffcdc7b0cff805eea04fe50479": {
    "tokens": 1200,
    "content": "1 − µ0A0 + (µ0 + µ1)A1}.\n\nHere J is the Jacobian for the transformation from µ0, µ1 to µ(cid:3)\n1, dk. The\nfactor of 1/p arises from the random assignment of dk while the Poisson\nprior for K yields the next term. In this case it is hard to ﬁnd a good\nproposal for addition of a point to the tiling.\n\n0, µ(cid:3)\n\n6.5 Examples\n\n6.5.1 Simulated Examples\n\nA Sine Wave\n\nThe data shown in Figure 6.1(a) are from Byers and Raftery (1998). A\nregion of higher density is bounded by two sine waves. We applied the\nsegmentation method to these data to obtain the results in panel (b). The\nsinusoidal nature of the edges of the region is captured very well. The\ndetection rate is 97.0%, with 4.1% false positives. This result was obtained\nwith a ﬁxed number of tiles, speciﬁcally 100, but we chose that to be more\n\n\f118\n\nBAYESIAN ESTIMATION OF SPATIAL POINT PROCESSES\n\nthan we thought were needed. The add-delete steps had great diﬃculty\nbeing accepted. Greater detail in forming the proposals might improve the\nacceptance rate for jumps in the variable number of tiles model for these\ndata, but it seems that most of the problem is inherent.\n\nA Linear Feature\n\nThese data are from Dasgupta and Raftery (1998) and were used there to\nillustrate the mclust-em method. Figure 6.3(a) shows the data and Figure\n6.3(b) shows a probability map for the mineﬁeld with the lightest color be-\ning zero and the darkest being one. This can be used to yield a segmentation\nof the data or information about the region in general.\n\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•",
    "chunk_order_index": 73,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-cb60dcaaa06fd3f31ba44e9d5bd23881": {
    "tokens": 1200,
    "content": "•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n••\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n•\n\n•\n\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n•\n\n(a)\n\n•\n\n•\n\n•\n•\n•\n•\n\n(b)\n\nFigure 6.3 (a) Simulated mineﬁeld with clutter. (b) Pointwise posterior probabil-\nities of being inside the mineﬁeld.\n\n6.5.2 New Madrid Seismic Region\n\nData on earthquakes in the New Madrid seismic region are available from\nthe Center for Earthquake Research and Information (CERI) web site at\n<http://samwise.ceri.memphis.edu>. We obtained these data and se-\nlected all earthquakes of magnitude greater than 2.5 from 1974 to 1992.\nTo these data we applied the Bayesian intensity estimation and segmen-\ntation. The segmentation partitions the data into two regions, one near\nfaults with many earthquakes and one away from major faults with lower,\nbackground intensity. The intensity estimation will provide detailed infor-\nmation regarding the intensity of earthquakes as a function of space over\nthe region.\n\n\fDISCUSSION\n\n119\n\nFigure 6.4(a) shows the earthquake locations. It is clear that the intensity\nvaries in the region, in some places being very low and others quite high.\nFigure 6.4(b) shows the pointwise posterior probabilities being in a high-\nintensity area. In terms of detection of features the results are a linear\nsection joined to a polygonal region with a separate area oﬀ on the right\nof the region.\n\n•\n\n•\n\n•\n\n••\n\n•\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n• •\n\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n\n•\n\n•\n\n•\n\n•\n\n•\n••\n•••••\n••\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n••\n•\n•\n•\n•\n•\n•\n•\n• •\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n••\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•",
    "chunk_order_index": 74,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-a4f4d945a58b2eb79b7b7ffc6e8098be": {
    "tokens": 1200,
    "content": "••\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n••\n•\n•\n•\n•\n•\n•\n•\n• •\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n••\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n•\n\n•\n•\n\n•\n\n•\n•\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n•\n\n•\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n••\n•\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n•\n••\n•\n••\n•\n•\n•\n•\n•\n••\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n•\n\n••\n\n•\n•\n•\n•\n•\n\n•\n\n•\n\n•\n\n•\n•\n\n•\n\n•\n\n•\n\n(a)\n\n(b)\n\nFigure 6.4 (a) The New Madrid earthquake data, and (b) a Bayesian posterior\nprobability segmentation.\n\nFigure 6.5(a) shows the posterior mean estimate of the intensity of occur-\nrences in the region. The estimate shows inbuilt locally adaptive properties\nresulting from the ﬂexible locally constant rate formulation. For example,\nthe high intensity regions are captured with good detail and sharp edges.\nThere is an apparent diﬀerence between this and the results of existing\nnon-locally adaptive kernel smoothing methods. For example the above\nmethods implemented in the Splus spatial statistics module (Diggle 1983)\ndo not allow for a predominantly smooth estimate that also recovers the\nvery localized regions of high intensity. They also do not provide variabil-\nity estimates. Figure 6.5(b) shows the pointwise standard errors of the\nestimated intensity over the region.\n\n6.6 Discussion\n\nIn this paper we have introduced methods for segmenting and estimating\nthe rate of a spatial point process. They can represent local spatial ho-\nmogeneity while allowing for discontinuities in the intensity. We use them\n\n\f120\n\nBAYESIAN ESTIMATION OF SPATIAL POINT PROCESSES\n\n200\n\n100\n\n200\n\n200\n\n200\n\n200\n\n100\n\n200\n\n10001000\n\n3000\n\n2000\n\n100\n\n200\n\n1000\n\n100\n\n4000\n5000\n3000\n\n2000\n\n2000\n\n1000\n\n2000\n3000\n\n50\n\n100\n\n200\n\n200\n\n100\n\n100\n\n100\n\n5050\n\n200\n\n100\n\n50\n50\n\n(a)\n\n(b)\n\nFigure 6.5 (a) Posterior mean estimate of the intensity of the New Madrid data.\n(b) Pointwise posterior standard errors.\n\nfor Bayesian intensity estimation and segmentation, in both cases yielding\ninformation not supplied by other methods.\n\nThe segmentation use of the formulation can be regarded as similar in\nnature to that of Allard and Fraley (1997), but providing a wealth of prob-\nabilistic information instead of only classiﬁcations. The method of Stanford\nand Raftery (1997), in its search for purely curvilinear features encounters\nproblems for those in the form of an unstructured region, as evidenced in\nFigures 13 and 14 of their work. This is also the case in the S* parameter-\nization of mclust-em used in Dasgupta and Raftery (1998). The method\npresented here is a density-based method, as opposed to density and geom-\netry based, and so can capture (curvi)linear or bloblike features together\nwith no additional speciﬁcation.\n\nOther methods have been proposed that address some aspects of the\nproblems we are trying to solve here. The intensity of a spatial nonhomo-\ngeneous point process may be estimated by kernel or other nonparamet-\nric density estimation methods (Diggle 1985a, Scott 1992). Our proposal,\nwhich is also nonparametric, goes beyond this in that it provides formal\nprobabilistic statements of uncertainty about the intensity, and provides an\nexplicit model for segmentation and feature detection. Parametric models\nhave also been used for intensity estimation in nonhomogeneous Poisson\nprocesses (Ogata and Katsura 1988); our approach here makes no para-\nmetric assumptions about the functional form of the intensity.\n\nOften point process data come with some form of additional information\nin the form of marks. The formulation we are examining here is easily\n\n\fDISCUSSION\n\n121\n\nextendible to allow marks on the events in the process by use of a model for\nthe marks. In the mineﬁeld example a multivariate mark or a more simple\nexpression of conﬁdence might be applicable. For example with each data\npoint there might be a measurement mi ∈ (0, 1). Real mines might have\nhigher values while the noise points might have lower values. Marks in the\nmineﬁeld region could then be assumed distributed according to a mixture\ndistribution pf1(w) + (1 − p)f2(w) while those outside would be just f2(w).\nThis expresses the assumption that the data points in the mineﬁeld region\nare a mixture of noise and mines. Further work based on this formulation\nis under way.\n\n\f\fPART II\n\nSpatial process cluster modelling\n\n\f\fCHAPTER 7\n\nPartition Modelling\n\nJ.T.A.S. Ferreira D.G.T. Denison C.C. Holmes\n\n7.1 Introduction\n\nThis chapter serves as an introduction to the use of partition models to es-\ntimate a spatial process z(x) over some p-dimensional region of interest X .\nPartition models can be useful modelling tools as, unlike standard spatial\nmodels (e.g. kriging) they allow the correlation structure between points to\nvary over the space of interest. Typically, the correlation between points is\nassumed to",
    "chunk_order_index": 75,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-9af5d2bcd4a36a6d93b16e64049db305": {
    "tokens": 1200,
    "content": ".A.S. Ferreira D.G.T. Denison C.C. Holmes\n\n7.1 Introduction\n\nThis chapter serves as an introduction to the use of partition models to es-\ntimate a spatial process z(x) over some p-dimensional region of interest X .\nPartition models can be useful modelling tools as, unlike standard spatial\nmodels (e.g. kriging) they allow the correlation structure between points to\nvary over the space of interest. Typically, the correlation between points is\nassumed to be a ﬁxed function which is most likely to be parameterised by a\nfew variables that can be estimated from the data (see, for example, Diggle\net al. (1998)). Partition models avoid the need for pre-examination of the\ndata to ﬁnd a suitable correlation function to use. This removes the bias\nnecessarily introduced by picking the correlation function and estimating\nits parameters using the same set of data.\n\nSpatial clusters are, by their nature, regions which are not representative\nof the entire space of interest. Therefore it seems inappropriate to assume\na stationary covariance structure over X. The partition model relaxes this\nassumption by breaking up the space into regions where the data are as-\nsumed to be generated independently from locally parameterised models.\nThis can naturally place in a single region those points relating to an un-\nusual cluster, and these points do not necessarily have to inﬂuence the\nresponse function in nearby locations. Further, by assuming independence\nbetween the regions the response function at the cluster centre tends not\nto be oversmoothed.\n\nWe now describe the partition model and its implementation in a Bayesian\nframework, via Markov chain Monte Carlo (MCMC) methods. We ﬁrst give\nthe model used for Gaussian response data but also discuss how the frame-\nwork can be extended to count data (e.g. for disease mapping applications).\nFurther, when analysing count data we show how, when covariate informa-\ntion is available, we can incorporate this into the analysis. This method is\nshown to be useful for both linear and nonlinear modelling of the covariate\neﬀects.\n\n\f126\n\nPARTITION MODELLING\n\n50\n\n45\n\n40\n\n35\n\n30\n\n2\n\n25\n\nX\n\n20\n\n15\n\n10\n\n5\n\n0\n\n0\n\nR\n2\n\nR\n1\n\nR\n3\n\nR\n4\n\nR\n5\n\nR\n6\n\nR\n\n13\n\nR\n\n12\n\nR\n7\n\nR\n8\n\nR\n9\n\nR\n\n11\n\nR\n\n10\n\n5\n\n10\n\n15\n\n20\n\n25\nX\n1\n\n30\n\n35\n\n40\n\n45\n\n50\n\nFigure 7.1 An example of a Voronoi partition in two dimensions. The dots mark\nthe centres of the regions, which are sometimes known as tiles.\n\n7.2 Partition Models\n\nTo be able to describe partition models for the special case of spatial data\nanalysis we ﬁrst need to deﬁne exactly what the term means. We use a\ndeﬁnition similar to the original product partition models of Barry and\nHartigan (1993) which is given in Chapter 7 of Denison et al. (2002b)\n\nDeﬁnition A partition model is made up of a number of disjoint regions\nR1, . . . , Rk whose union is the domain of interest, so that Ri ∩Rj = ∅ for\nk\ni (cid:4)= j and\n1 Ri = X . The responses in each region, given parameters\nrelating to each region φ = (φ1, . . . , φk), are taken to be exchangeable\nand to come from the same class of distribution f .\n\n(cid:1)\n\nTo illustrate the idea consider Fig. 7.1. Here we show a two-dimensional\nregion split up by a partitioning method known as Voronoi tessellation\nwhich was introduced by Voronoi (1908) (for a modern view of Voronoi\ntessellations and their uses in spatial modelling see Okabe et al. (2000)).\nThe dots mark the midpoint of each region (or tile) and are known as\ncentres. Throughout this chapter we shall denote the centre of region i by\nci and write the collection of all centres as c = (c1, . . . , ck).\n\nNow, each region is deﬁned as the portion of space closer to a particular\ncentre than any other, with the lines giving the boundaries between regions.\nHence, we can deﬁne the ith region by Ri = {x ∈ X : D(x, ci) < D(x, cj)\n\n\fPARTITION MODELS\n\n127\n\nfor all j (cid:4)= i}, where D(·, ·) is some user-speciﬁed distance metric. The\nVoronoi tessellation is completely deﬁned by specifying a distance metric\nand the centres of the regions.\n\nThe choice of distance metric can be important, especially when there are\nmany predictors, but as spatial data is usually low-dimensional (typically\np = 2 or 3) the Euclidean distance, D2(x1, x2) =\ni=1(x1i − x2i)2, is\nadequate (see Denison et al. (2002b) for more discussion). This is the metric\nwe shall use throughout this chapter.\n\n(cid:2)\np\n\n7.2.1 Partitioning for Spatial Data\n\nA typical spatial dataset contains responses y1, . . . , yn at spatial locations\nx1, . . . , xn. The responses are assumed to be observed only in the presence\nof some additive error component so that the data are generated by\n\nyi = y + z(xi) + (",
    "chunk_order_index": 76,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-ec84a877cad9ac223eb79a4e7da47dfc": {
    "tokens": 1200,
    "content": "(2002b) for more discussion). This is the metric\nwe shall use throughout this chapter.\n\n(cid:2)\np\n\n7.2.1 Partitioning for Spatial Data\n\nA typical spatial dataset contains responses y1, . . . , yn at spatial locations\nx1, . . . , xn. The responses are assumed to be observed only in the presence\nof some additive error component so that the data are generated by\n\nyi = y + z(xi) + (cid:14)i,\n\n(cid:2)\n\nfor i = 1, . . . , n, y = 1\nyi and (cid:14)i is a random draw from some zero-mean\nn\nerror distribution which we shall assume has variance σ2 (the regression\nvariance). Here z(x) is some unknown spatial process which represents the\ndeviations of the mean level of the process from the overall empirical mean,\ny, for all x ∈ X . The aim of the analysis is to accurately approximate z\ngiven the observed dataset D = {yi, xi}n\n1 . This generally involves some sort\nof smoothing of the observed data, which has a greater variance than the\ntrue process z(x) if var((cid:14)i) > 0.\n\nSpatial smoothing, like smoothing in all regression contexts, involves a\ndelicate trade-oﬀ between the bias and variance of the resulting estimate to\nthe truth. We can see this by considering the mean-squared error between\nthe estimator (cid:3)z and truth z, given by\n\nM SE((cid:3)z, z) = E{((cid:3)z − z)2}\n\n= E{((cid:3)z − E((cid:3)z))2} + {E((cid:3)z) − z}2\n= var((cid:3)z) + bias((cid:3)z)2.\n\nHere we see that to minimise MSE we must tradeoﬀ ﬁdelity in the mean-\nlevel (bias) with the variance of the estimator. Further, low variance esti-\nmators tend to have high bias and vice versa, for ﬁxed MSE.\n\nNow let us see how this relates to the partition model for spatial data, but\nﬁrst we shall discuss some of the common assumptions often made about\nspatial data. The ﬁrst assumption nearly always made is that location\nmatters. Thus, if a large response value is observed at x, “nearby” points\nare more likely to also be large as their response values will be (positively)\ncorrelated with the value seen at x. The strength of the correlation in the\nresponses and the notion of “nearness” to x are both diﬃcult to quantify.\nHowever, by parameterising the correlation structure and assuming it is\n\n\f128\n\nPARTITION MODELLING\n\nindependent of x (an isotropic correlation function) we can use the data to\ngive us an idea of good values for the parameters in the correlation function.\nOnly considering stationary correlation functions, which do not vary with\nx, is restrictive. It does not allow for the possibility of discontinuities in\nz(x), something that often makes sense in spatial data analysis, e.g. a break\nin the response surface might be due to a change from a plateau to a moun-\ntainous region. Hence, instead of trying to model the correlation structure\ndirectly, we choose to focus our attention on the response function, z.\n\nPartition models give us a way of estimating z directly. Given a set of\ncentres c = (c1, . . . , ck) we can deﬁne a tessellation of X . Then, in each\nregion Ri we can assume that the response function is constant with level\nµi. This gives rise to a particularly simple form for (cid:3)z with high bias but\nlow variance, as the approximating function is so crude. However, we can\ndecrease the bias in (cid:3)z by allowing the centres to be chosen by the data in an\nattempt to capture the underlying spatial variability in the truth, z. This is\ndone with a view to placing more centres at locations with high variability\nand fewer where the function is relatively ﬂat. Further reductions in bias\ncan be achieved by allowing the estimate to be made up of a weighted sum\nof partition models, rather than just a single one, so that\n\n(cid:3)z(x) =\n\nJ(cid:4)\n\nj=1\n\nw(j)(cid:3)z(j)(x|c(j)),\n\n(7.1)\n\nwhere J is the number of models used to form the estimate, w(j) are the\nj w(j) = 1 and (cid:3)z(j) is the\nweights associated with each model such that\nestimate of the response function found with the jth set of centres c(j).\n\n(cid:2)\n\nVarious methods exist for producing suitable sets of estimating functions\n(cid:3)z(1), . . . , (cid:3)z(J), most notably bootstrapping and Markov chain Monte Carlo\n(MCMC). Bootstrapping ﬁts models on subsets of the data and then aver-\nages over those found, whereas MCMC relies on the setting up of a Markov\nchain designed so that its stationary distribution is the posterior distribu-\ntion p(c|D). In this paper we shall follow this second approach and adopt\na Bayesian approach to making inference.\n\n7.2.2 Bayesian Inference\n\nBayesian inference relies on Bayes Theorem\n\np(θ|D) ∝ p(D|θ)p(θ),\n\nto make inference about the distribution of some unknown vector of param-",
    "chunk_order_index": 77,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-73f1defc073da928835c6e7b2a4138d3": {
    "tokens": 1200,
    "content": "found, whereas MCMC relies on the setting up of a Markov\nchain designed so that its stationary distribution is the posterior distribu-\ntion p(c|D). In this paper we shall follow this second approach and adopt\na Bayesian approach to making inference.\n\n7.2.2 Bayesian Inference\n\nBayesian inference relies on Bayes Theorem\n\np(θ|D) ∝ p(D|θ)p(θ),\n\nto make inference about the distribution of some unknown vector of param-\neters, θ, in the light of observed data, D. In the context of partition models\nthe unknown parameters are the locations of the centres, c = (c1, . . . , ck),\nthe levels in each region, µ = (µ1, . . . , µ\nk), as well as the regression vari-\n\n\fPARTITION MODELS\n129\nance σ2. Note that the length of the vectors c and µ are of unknown,\nrandom length k.\n\nTo be able to determine the posterior distribution of the parameters we\nﬁrst need to assign prior distributions to all the unknowns. We do this\nhierarchically via the equality\n\np(θ) = p(k, c, µ, σ2) = p(µ|c, σ2)p(σ2)p(c|k)p(k).\n\nThe prior we choose to place on the levels µ in each partition, given c and\nσ2, is normal with mean zero and variance σ2v, for some prior constant\nv. The prior on the regression precision, σ−2, is taken to be Gamma with\nparameters a and b. The prior over the positions of centres, assuming that\nknots can be placed anywhere in some space T (of the same dimension as\nX ), is taken to be uniform over T . Finally we allow the number of centres\nto range from 1 to some prespeciﬁed maximum K. As we have little idea\nhow many centres are required to adequately approximate the truth we\ntake k ∼ U {1, . . . , K}, so the number of centres follows a discrete uniform\ndistribution. Typically we take K = n. In summary\n\np(k) =\n\np(c|k) =\n\n,\n\n1\nK\n1\n{Area(T )}k ,\n\nk = 1, . . . , K\n\nc ∈ T k\n\np(σ−2) = Gamma(σ−2|a, b),\nk(cid:5)\n\np(µ|c, σ2) =\n\nN (µi|0, σ2v),\n\nσ2 > 0\n\nµ ∈ Rk.\n\n1\n\nThis completes the prior speciﬁcation on the unknowns in the partition\nmodel. In reality, as k is a deterministic function of c (i.e. just the number\nof elements in c) it is equivalent to remove the prior on k and just think of\na prior on the centres such that\n\np(c) =\n\n1\nK\n\n1\n{Area(T )}k ,\n\nc ∈\n\nK(cid:6)\n\nk=1\n\nT k.\n\nThis simpliﬁes the notation and is the prior we shall use for the rest of the\npaper.\n\nNow, given the model parameters θ = (c, µ, σ2), we can write down the\nlikelihood of the data, p(D|θ), after assuming a speciﬁc form for the error\ndistribution. For the time being we shall assume that each (cid:14)i ∼ N (0, σ2)\nand that they are all mutually independent. Hence, we ﬁnd that\n(cid:8)\n\n(cid:7)\n\np(D|θ) = (2πσ2)−n/2 exp\n\n− 1\n2σ2\n\n(yi − y − µr(i))2\n\n,\n\nn(cid:4)\n\n1\n\n\f130\n\nPARTITION MODELLING\n\nfor k = 1, . . . , K and zero otherwise. Here r(i) is the index of the region\nthat the ith response is located in.\n\nThe priors we chose to take over the levels, µ, and the regression variance,\nσ2, aid our model in an important way. They are known as conjugate priors\nas they allow us to analytically determine the marginal likelihood\n\n(cid:9) ∞\n\n(cid:9)\n\np(D|c) =\n\np(D|µ, σ2, c)p(µ|σ2, c)p(σ2)dµdσ2\n\nRk\n\n0\n(2b)aΓ(a(cid:11))\nπn/2Γ(a)\n\n=\n\n(cid:10)\n\n(2b(cid:11))−a(cid:2)\nk\n1(ni + 1)1/2\n\n,\n\n(7.2)\n\nfor k = 1, . . . , K, and zero otherwise. Also, a(cid:11) = a + n/2 with\n\nb(cid:11) = b +\n\n1\n2\n\nk(cid:4)\n\ni=1\n\n\n\n\n(cid:4)\n\n\n\nj:r(j)=i\n\n(yj − y)2 − vn2\ni\n1 + vni\n\ny2\ni\n\n\n\n ,\n\nand ni is the number of points in region i and yi is the mean of those points\nin region i, i.e. ni =\n\nj:r(j)=i 1 and yi = n−1\n\nj:r(j)=i(yi − y).\n\n(cid:2)\n\n(cid:2)\n\nThe importance of using conjugate priors is that it allows us to reduce\nthe dimension of the posterior from which we wish to sample from as now",
    "chunk_order_index": 78,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-c983d7cae34bc4210c4d79d572ec4bda": {
    "tokens": 1200,
    "content": "\n ,\n\nand ni is the number of points in region i and yi is the mean of those points\nin region i, i.e. ni =\n\nj:r(j)=i 1 and yi = n−1\n\nj:r(j)=i(yi − y).\n\n(cid:2)\n\n(cid:2)\n\nThe importance of using conjugate priors is that it allows us to reduce\nthe dimension of the posterior from which we wish to sample from as now\nwe only need to determine\n\ni\n\np(c|D) ∝ p(D|c)p(c).\n\n(7.3)\n\nThus, the unknowns remaining are only the number of centres and their\nlocations. The dimension of this posterior is under half the dimension of\nall the unknowns, θ = (c, µ, σ2).\n\nNote that, conditional on θ, the partition model for Gaussian data can\n\nbe written as a linear model\n\nY = Bµ + (cid:8),\nwhere Y = (y1 − y, . . . , yn − y)(cid:3), µ and (cid:8) are column vectors of the levels\nand errors, respectively. Lastly, B is known as the basis function matrix of\ndimension n × k where each row contains a one in position r(i) and zeros\nelsewhere, i.e. Bij = 1 if j = r(i) and zero otherwise. Note that the form\nof this matrix is a deterministic function of the locations of the centres.\nIn this setup we know, from standard Bayesian linear model results (e.g.\nBernardo and Smith (1994), Denison et al. (2002b)), that the ﬁtted values\nof all the datapoints given c and k are (cid:3)Y = {(cid:3)z(x1|c), . . . , (cid:3)z(xn|c)}(cid:3), where\ngiven by\n\n(cid:3)Y = E(Y |D, c) = B(B(cid:3)B + V −1)−1B(cid:3)Y ,\n(7.4)\nwhere V = vI k, where I k is the k-dimensional identity matrix. When\nwriting S = B(B(cid:3)B + V −1)−1B(cid:3), so that (cid:3)Y = SY , we refer to S as the\nsmoothing matrix. The ith row of S gives the weight that each observed\nresponse has on the ith ﬁtted value (cid:3)z(xi|c). Thus, row i gives the equivalent\n\n\fPARTITION MODELS\n131\nkernel (Hastie and Tibshirani 1990) at the i observed location, xi. This\nallows us to determine the datapoints that have a signiﬁcant eﬀect on the\nestimated response at xi. We shall give examples of equivalent kernels later\non in Section 7.2.5 when we discuss the kernels induced by the prior we\nhave chosen for the partition model.\n\n7.2.3 Predictive Inference\n\nGiven all the unknown parameters, θ, from normal theory we know that\nthe posterior predictive distribution at a general point x ∈ X is given by\n\np(y|x, θ, D) = N (y|µx, σ2),\n\n(7.5)\n\nwhere µx is the level of the region that x lies in. Further, as we used\nconjugate priors for µ and σ2 we can integrate them with respect to their\nposterior distributions (e.g. see Denison et al. (2002b)) from (7.5) and we\nﬁnd that\n\n(cid:17)\n\n(cid:18)\n\n(cid:19)\n\n(cid:20)\n\np(y|x, c, D) = Student\n\nnxyx\nnx + v−1 , b(cid:11)\n\n1 +\n\n1\nnx + v−1\n\n, a(cid:11)\n\n,\n\n(7.6)\n\nwhere nx and yx are deﬁned similarly to µx.\n\nHowever, to obtain the posterior predictive distribution of the response\nat location x we must marginalise further over the posterior distribution\nof the centres and the number of them. That is, we need to determine\n\n(cid:9)\n\np(y|x, D) =\n\np(y|x, c, D)p(c|D)dc.\n\n(7.7)\n\nGenerally p(c|D) is not available in a computationally tractable form so\nwe need to approximate it. As we have mentioned before, Markov chain\nMonte Carlo methods can be used to simulate from this distribution and\nin the next section we will go into more details about this. In summary, an\napproximate sample of models (or vectors of centre locations) c(1), . . . , c(J)\nis generated from p(c|D) and the true posterior is approximated by a dis-\ncrete uniform distribution on this sample of J models. Each of these models\ngives rise to a separate model for the responses at x as z(j)(x) is given by\n\n(cid:3)z(j)(x) = E(y|c(j), D) =\n\nnxyx\nnx + v−1\n\nHence, the approximation to p(y|x, D) is a mixture of Student distributions\nand the overall estimate to the true spatial process, z(x), is\n\n(cid:3)z(x) =\n\n1\nJ\n\nJ(cid:4)\n\nj=1\n\n(cid:3)z(j)(x).\n\n\f132\n\nPARTITION MODELLING\n\n7.2.4 Markov Chain Monte Carlo Simulation\nWe now describe how to generate samples of models",
    "chunk_order_index": 79,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-69b86ac23e0137a530dd72391a2d44a5": {
    "tokens": 1200,
    "content": "+ v−1\n\nHence, the approximation to p(y|x, D) is a mixture of Student distributions\nand the overall estimate to the true spatial process, z(x), is\n\n(cid:3)z(x) =\n\n1\nJ\n\nJ(cid:4)\n\nj=1\n\n(cid:3)z(j)(x).\n\n\f132\n\nPARTITION MODELLING\n\n7.2.4 Markov Chain Monte Carlo Simulation\nWe now describe how to generate samples of models c(1), . . . , c(J) from the\nposterior of interest for partition models. We use a Markov chain Monte\nCarlo sampler (e.g. Gilks et al. (1996), Robert and Casella (1999)) which\nconstructs a Markov chain whose stationary distribution is p(c|D), the tar-\nget posterior. This is achieved using an algorithm which makes transitions\nfrom the current set of model parameters according to a known set of rules.\nThe most important of these are that the chain is irreducible and aperiodic.\nIn addition, when sampling from a parameter vector with random dimen-\nsion, as we are here, we also need the chain to be reversible (see Green\n(1995)).\n\nWe now give the basic algorithm for sampling from the partition model.\nNote that we shall refer to the comments included in the algorithm later\non in Section 7.4.2.\n\nReversible jump sampler\nSet t = 0 and initial values of parameters to c(0);\nREPEAT\n\n/*Draw auxiliary variables here*/\nSet u1 to a draw from a U (0, 1) distribution;\nIF u1 ≤ bk\n\nc(cid:3) = Birth-proposal(c(t));\n\nELSE IF bk < u1 ≤ bk + dk\n\nc(cid:3) = Death-proposal(c(t));\n\nELSE\n\nc(cid:3) = Move-proposal(c(t));\n\nENDIF;\nSet u2 to a draw from a U (0, 1) distribution;\nIF u2 < min{1, BF (c(cid:3), c(t))}\n\n/*ACCEPT NEW MODEL?*/\n\nc(t+1) = c(cid:3);\n\nELSE\n\nc(t+1) = c(t);\n\nENDIF;\n/*Sample other parameters now*/\nt = t + 1;\nTake every mth value of c(t) after initial burn-in to be in sample;\n\nEND REPEAT;\n\n\fPARTITION MODELS\n\n133\n\nIn the above algorithm bk and dk are the probabilities of attempting a\nBIRTH and DEATH step when there are currently k centres. The rest of\nthe probability (1 − dk − bk) is reserved for the MOVE step. We choose to\ntake bk = dk = mk = 1\n\n3 for all k.\n\nThe BIRTH step proposes to increase the number of centres by one while\nthe DEATH step does the reverse. The MOVE step proposes a change\nin location of one of the centres currently in the model. These proposed\nmodels are generated by their conditional priors as described in Denison et\nal. (2002b) so that the acceptance probability is the minimum of one and\nthe Bayes factor in favour of the proposed model over the current one, i.e.\n\n(cid:21)\n\n(cid:22)\n\n(cid:17)\n\nmin\n\n1, BF (c(cid:3), c(t))\n\n= min\n\n1,\n\n(cid:20)\n\n,\n\np(D|c(cid:3))\np(D|c(t))\n\n(which can be calculated using (7.2)). This particularly simple form of the\nacceptance probability results from the fact that we have chosen to control\nthe possible values of k (1 ≤ k ≤ K) through the deﬁnition of the likelihood\n(7.2). This is in contrast to the usual approach that alters bk, dk and mk\nfor values of k equal to 1 and K.\n\nIn summary, after the initial setting of the model parameters the al-\ngorithm proceeds by making random choices between proposing to add,\ndelete or remove a centre from the current tessellation. If the marginal\nlikelihood of the proposed model, c(cid:3), is greater than that for the current\nmodel, c(t), then the proposed model is accepted. If this is not the case then\nthe proposed model is accepted with the Bayes factor. After some number\nof burn-in iterations every mth model is taken to be in the generated sam-\nple. In the terminology of optimisation the MCMC algorithm performs a\nstochastic hill-climb, but because of the special way we make transitions\nwe can use its output to approximate integrals, rather than just to identify\nlocal modes.\n\n7.2.5 Partition Model Prior\n\nAlthough we have described how to use MCMC techniques to draw samples\nfrom the model posterior, p(c|D), it is also of interest to see the eﬀect that\nthe prior p(c) has on the inference. To do this we generate samples from\np(c), using the MCMC algorithm, which allows us to approximate the prior\npredictive distribution\n\n(cid:9)\n\np(y|x) =\n\np(y|x, c)p(c)dc,\n\nfor all values x ∈ X . In addition, as we can think of the partition model\nas a Bayesian linear model given c, we can look at the equivalent kernels\n(Hastie and Tibshirani 1990) at diﬀerent locations x ∈ X . These allow us\nto see the degree of smoothing that the model induces at diﬀerent points in\n\n\f134\nPARTITION MODELLING\nthe region of interest. For a location x and generated sample c(1), . . . , c(J),\nthe equivalent kernel is given by",
    "chunk_order_index": 80,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-6db79c5c9cae50d1970c5f26b1dd54ba": {
    "tokens": 1200,
    "content": "as a Bayesian linear model given c, we can look at the equivalent kernels\n(Hastie and Tibshirani 1990) at diﬀerent locations x ∈ X . These allow us\nto see the degree of smoothing that the model induces at diﬀerent points in\n\n\f134\nPARTITION MODELLING\nthe region of interest. For a location x and generated sample c(1), . . . , c(J),\nthe equivalent kernel is given by\n\nK(x, x(cid:3)) =\n\n1\nJ\n\nJ(cid:4)\n\nj=1\n\n(j)\nx(cid:1) = r\nχ(r\nArea(j)(r\n\n(j)\nx )\n(j)\nx )\n\n,\n\nx(cid:3) ∈ X ,\n\n(j)\nx is the index of the region that x belongs to with conﬁguration\nwhere r\n(j)\nx(cid:1) , and Area(j)(i) is the area of the ith region in the\nc(j), similarly for r\njth conﬁguration. Also, χ(·) is the indicator function that takes the value\none when the statement is true and zero otherwise.\n\n200\n\n150\n\n100\n\n50\n\n0\n\n0\n\n200\n\n150\n\n100\n\n50\n\n0\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n20\n\n40\n\n60\n\n80\n\n100\n\n200\n\n150\n\n100\n\n50\n\n0\n\n0\n\n200\n\n150\n\n100\n\n50\n\n0\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n20\n\n40\n\n60\n\n80\n\n100\n\n0.025\n\n0.02\n\n0.015\n\n0.01\n\n0.005\n\n0\n\nFigure 7.2 The equivalent kernels produced by the partition model prior at (5,5),\n(15,80), (50,25) and (40,160). The points at which the kernels have been deter-\nmined are shown by the diamonds.\n\nTo allow us to easily display the equivalent kernels at various values\nof x we can discretise the region of interest into a regular grid of points\nand approximate the areas required by the number of points that lie in\nthem. In this way we produced Fig. 7.2 using a 40×40 grid and taking\nX = [0, 100] × [0, 200]. Note how the prior induces spherical kernels (except\nfor the kernel for the boundary point) that are very similar to independent\nnormal kernels. Normal kernels have been used extensively before in spatial\ndata analysis so the partition model prior appears acceptable. Note that\nthe priors are not elliptical because of the diﬀerent scales on each axis.\n\n\fPIAZZA ROAD DATASET\n\n7.3 Piazza Road Dataset\n\n135\n\nTo illustrate the performance of the method on data where the response can\nbe assumed Gaussian we use the Piazza Road dataset studied in Higdon et\nal. (1999). The dataset is taken from an environmental monitoring study\ninto the spatial distribution of dioxin concentrations on the Piazza Road, a\npart of an EPA Superfund site in Missouri. The dataset was introduced by\nHigdon et al. (1999) as an example of one in which it is expected that the\nspatial dependence between points varies with location. The response of\nthe data was taken to be the natural logarithm of the dioxin concentration\nat the 600 spatial locations given.\n\nWe ran the MCMC simulation algorithm for 100,000 burn-in iterations\nand used 1 million further iterations to obtain the approximate sample of\nmodels, choosing every 100th to be in the generated sample. We used vague\npriors for the other parameters that we need to set, taking a = b = 0.01\nfor the Gamma prior on the regression variance and v = 10 for the prior\nvariance of the levels. This value of v was chosen as the range of the data\nwas around 6 and we wished that all the possible posterior values of the\nlevels, µi, were contained within one standard deviation of the mean of\ntheir prior distribution.\n\nIn the top-left plot of Fig. 7.3 we display the estimated log concentration\nfound using the partition model over a 40 × 40 grid. We see how the model\nallows for sharp diﬀerences between the mean level at points close together\nin space (the top-left portion of the plot) and also smooths well in regions\nwith little spatial variability (the bottom half of the plots).\n\nThe other three plots give the equivalent kernels for three of the points\nfrom Fig. 7.2. We notice now that none of these three posterior kernels\napproximates a radial relationship between distance and correlation. For\nexample, at (15,80) the points just below it are hardly used to estimate the\nmean value at (15,80). The three kernels are of very diﬀerent shape, one\nhorizontal, one vertical and one covers a large area. This highlights how\nthe partition model can adapt to the underlying response surface to allow\ndiﬀerent degrees of smoothing at diﬀerent locations, as well as the direction\nin which the most similar points lie.\n\n7.4 Spatial Count Data\n\nAlthough the observations in many spatial applications can be thought of\nas being generated from some true process together with Gaussian additive\nerrors, this is not always the case. One important such application is disease\nmapping (e.g. Clayton and Kaldor (1987), Elliott et al. (1999), Lawson\n(2001)) where the observations are counts of disease. As counts are, by\ntheir very nature, integer-valued it is inappropriate to assume Gaussian\nerrors. Even though by taking",
    "chunk_order_index": 81,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-e3a3f485c2d397368e26795045c37247": {
    "tokens": 1200,
    "content": "observations in many spatial applications can be thought of\nas being generated from some true process together with Gaussian additive\nerrors, this is not always the case. One important such application is disease\nmapping (e.g. Clayton and Kaldor (1987), Elliott et al. (1999), Lawson\n(2001)) where the observations are counts of disease. As counts are, by\ntheir very nature, integer-valued it is inappropriate to assume Gaussian\nerrors. Even though by taking the square-root of Poisson observations we\n\n\f136\n\n200\n\n150\n\n100\n\n50\n\n0\n\n0\n\n200\n\n150\n\n100\n\n50\n\n0\n\n0\n\n4\n\n3\n\n2\n\n1\n\n0\n\n1\n\n0.035\n\n0.03\n\n0.025\n\n0.02\n\n0.015\n\n0.01\n\n0.005\n\n200\n\n150\n\n100\n\n50\n\n0\n\n0\n\n200\n\n150\n\n100\n\n50\n\n0\n\n0\n\n50\n\n100\n\n50\n\n100\n\nPARTITION MODELLING\n\n0.035\n\n0.03\n\n0.025\n\n0.02\n\n0.015\n\n0.01\n\n0.005\n\n0.035\n\n0.03\n\n0.025\n\n0.02\n\n0.015\n\n0.01\n\n0.005\n\n50\n\n100\n\n50\n\n100\n\nFigure 7.3 The top-left ﬁgure is the surface ﬁtted by the partition model to the\nlogarithm of the dioxin concentrations in the Piazza Road dataset. The other\nthree ﬁgures are the equivalent kernels produced by the partition model at the\npoints (15,80) (top-right), (50,25) (bottom-left) and (40,160) (bottom-right). The\ndiamonds give the positions of these points and are also displayed in the top-left\nﬁgure (the colour of the diamonds is unimportant and was chosen to ensure that\nthey were visible over the background surface).\n\nobtain more normal-looking response data (see, for example, Clyde (1999))\nwe would prefer to model the counts directly but still use the partition\nmodel framework. One way to do this is to follow the ideas in Denison and\nHolmes (2001). Here a Bayesian partition model was used to obtain a map\nof the disease risk for a leukaemia dataset. The diﬀerence with the earlier\nwork we have seen is that the observations were modelled with a Poisson,\nrather than a Gaussian, distribution.\n\nOne limitation of the work of Denison and Holmes (2001) is that it\ndoes not allow for the incorporation of covariates into the model. However,\nin disease mapping applications, the main interest of the study is often\nthe relationship between the covariates and the relative risk. So, in this\nchapter, we extend the Bayesian partition model for disease mapping to\nallow for covariates with the spatial process being used to “soaking up”\nthe variation due to unobserved covariates. Before we get onto how to\n\n\fSPATIAL COUNT DATA\n\n137\n\nincorporate covariates we ﬁrst review the Poisson-Gamma model for disease\nmapping as outlined in Denison and Holmes (2001).\n\n7.4.1 The Poisson-Gamma Model for Disease Mapping\n\nIn a disease mapping context the spatial process under consideration is\nthe disease risk at every location x ∈ X . Alternatively, we can model the\nrelative risk which is more conveniently calibrated so that values greater\nthan one relate to more than average risk and vice versa for values less than\none. The data is usually available in the form D = (yi, Ni, xi)n\ni=1, where\nyi is the observed number of disease cases in the ith enumeration district\n(ED) (e.g. county, electoral ward), Ni is the number of susceptibles in the\nsame district and xi is the centroid of that ED. Then, if we denote by ξ0\nn\nthe observed mean risk, so that ξ0 =\n1 Ni), the expected risk at\nany point in the ith ED is Ei = ξ0Ni.\n\n(cid:2)\nn\n1 yi/(\n\n(cid:2)\n\nAgain we suggest using the partition model to produce estimates to the\nrelative risk, ξ(x), at all values x ∈ X . For rare diseases the Poisson model\nfor incidence can be adopted for which we assume that each observation,\nyi, is generated according to\n\np(yi|xi, Ni, c, µ) = P oisson{Eiξ(xi)},\nwhere ξ(xi) = µr(i), the relative disease level associated with the region of\nthe tessellation that xi resides in.\n\nAs before, if we use conjugate priors for the levels we ﬁnd that inference\nis considerably simpliﬁed and reduces to just determining p(c|D). This can\nbe done by taking the prior for the levels to be independent Gamma(γ1, γ2)\ndistributions, i.e.\n\np(µi) =\n\n(γ2)γ1\nΓ(γ1)\n\nµγ1−1\ni\n\nexp(−γ2µi),\n\nµi > 0,\n\nfor i = 1, . . . , k. Using results relating to the conjugate Poisson-Gamma\nmodel we can again determine the marginal likelihood of the data given just\nthe locations of the centres, c. We ﬁnd that the logarithm of the marginal\nlikelihood is given by\n\nlog p(D|c) = constant+\n\nk(cid:4)\n\n(cid:23)\n(cid:24)\nlog Γ(γ1 + niyi) − (γ1 + niyi) log(γ2 + niN i)\n\n,\n\ni=",
    "chunk_order_index": 82,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-8887f8e93faae9bb5b0cac4be7d7a6ce": {
    "tokens": 1200,
    "content": "relating to the conjugate Poisson-Gamma\nmodel we can again determine the marginal likelihood of the data given just\nthe locations of the centres, c. We ﬁnd that the logarithm of the marginal\nlikelihood is given by\n\nlog p(D|c) = constant+\n\nk(cid:4)\n\n(cid:23)\n(cid:24)\nlog Γ(γ1 + niyi) − (γ1 + niyi) log(γ2 + niN i)\n\n,\n\ni=1\n\nwhere again ni is the number of points in the ith region and yi is the\nmean of the observations in that tile. Similarly, N i is the mean number of\nsusceptibles in the ith tile.\n\nThe posterior predictive density, p(y|x, c, D) is also available in closed\nform and follows a Poisson-Gamma distribution (see Chapter 7, Denison\net al. (2002b)). Also note that similar analytic tractability is also found for\n\n\f138\n\nPARTITION MODELLING\n\ndiseases that are not rare when we use the Beta-Binomial model for the\ndisease risk.\n\nThe prior on c can be chosen in an identical way to the Gaussian case,\nhowever, we also need to set the γ1 and γ2 parameters. We have a lot of\ninformation about the range of values we expect for the relative risk and we\nneed to incorporate this in our choice for these parameters. For instance, the\nmean relative risk should be one (with no data we would expect the relative\nrisk in each area to be around one) which leads us to setting γ1 = γ2. This\nleaves us only one degree of freedom in our prior choice.\n\nA sensible assumption is that the relative risk in any region is more likely\nto be within 5 times the mean relative risk (one), than outside this range.\nThus, any value of γ1 for which\n\n(cid:9) 5\n\n0.2\n\n(γ1)γ1\nΓ(γ1)\n\nµγ1−1 exp(−γ1µ)dµ > 0.5,\n\nappears reasonable. This leads us to choosing values of c > 0.317. Denison\nand Holmes (2001) assign a uniform prior to the logarithm of c and sample\nit from the data and to minimise the number of user-set parameters.\n\nThis model is well-suited to estimating the disease risk over an area of\ninterest when there are no covariates, but problems arise when they are\npresent in the data. In this case the usual way to include covariates is\nthrough an exponential transform so that the relative risk surface is given\nby\n\nξ(x, xc) = µx exp(β1xc\n\n1 + . . . + βqxc\nwith x a general location, as before, and xc = (xc\nq) is a general\nvector of the q covariate values, measured at x. Technical diﬃculties arise\nwith this setup as there is now no conjugate prior for the coeﬃcients β =\n(β1, . . . , βq), so we cannot integrate them out. Instead we have to sample\nthem to make posterior inference and in the next section we detail how we\ntackle this problem.\n\n1, . . . , xc\n\nq),\n\n7.4.2 Disease Mapping with Covariates\n\nEﬃcient sampling methods for Bayesian generalized linear models are well-\nknown (see Dey et al. (2000) for an overview) so the ﬁrst step to incor-\nporating covariates is to rewrite the model in this form. First of all, we\ndeﬁne some notation. Let dx be a k-dimensional column vector with d\nhaving zeros everywhere except the component with the same index as\nthe region that x is located in. Also take δ = (log µ1, . . . , log µk)(cid:3) so that\nd(cid:3)\nxδ = log µx, the logarithm of the level associated with location x. We\ncan interpret d as a vector gives us the index of the region that x lies in\nand δ giving us the logarithm of the level in each of those regions. Now\ntake β = (β1, . . . , βp)(cid:3) and let b = (xc\nq)(cid:3). Here, β is the vector of\ncovariate coeﬃcients and b gives the covariate values associated with the\n\n1, . . . , xc\n\n\fSPATIAL COUNT DATA\n\n139\n\ngeneral datapoint at x. Hence, we can write\n\nlog ξ(x, z) = d(cid:3)\n\nxδ + b(cid:3)\n\nxβ,\n\n(7.8)\nand we assume that y ∼ P oisson(Eiξ(x, z)). Using the terminology of\ngeneralized linear models, we call the right hand side of (7.8) the linear\npredictor.\n\nWe wish to include a residual eﬀect in (7.8) which is used to capture\nextra-Poisson variation often present in disease mapping datasets with low\nnumber of counts. The residual component can be thought of as represent-\ning random eﬀects that are not captured by the covariates or the spatial\nmodel. The residual eﬀects form auxiliary variables which augment the\nspace over which we have to perform the sampling but greatly ease the\ncomputational convenience of the algorithm. However, to take advantage\nof this method we choose to place a prior over the logarithm of the levels\nin each region, δ, rather than levels themselves, µ, as before.\n\nThe priors",
    "chunk_order_index": 83,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-28e76f5a5911042163963d4900899e0f": {
    "tokens": 1200,
    "content": "as represent-\ning random eﬀects that are not captured by the covariates or the spatial\nmodel. The residual eﬀects form auxiliary variables which augment the\nspace over which we have to perform the sampling but greatly ease the\ncomputational convenience of the algorithm. However, to take advantage\nof this method we choose to place a prior over the logarithm of the levels\nin each region, δ, rather than levels themselves, µ, as before.\n\nThe priors that we adopt are\n\np(δ, β|σ−2)p(σ−2) = N (0, σ−2V )Gamma(τ1, τ2)\n\np(η|δ, β, σ−2) = N (B[δ β](cid:3), σ2I n)\n\n(7.9)\n(7.10)\n\nwhere V is a known constant matrix, B is the design matrix whose ith row\nis (dxi, bxi)(cid:3), and η = (η1, . . . , ηn) and σ2 are the auxiliary variables we\nhave chosen to introduce. With these extra variables we can write\n\nη = B\n\n+ (cid:8),\n\n(cid:18)\n\n(cid:19)\n\nδ\nβ\n\nwhere (cid:8) ∼ N (0, σ2I). So, by comparison with a Bayesian linear model\n(Lindley and Smith 1972), we see that we can think of the η as a vector of\nresponses observed with additive independent Gaussian errors. Hence, the\nform of the posterior distribution of δ and β given η is known, and we can\neven ﬁnd the marginal likelihood of the data given η and the centres, c.\nWe ﬁnd that\n\n|V (cid:11)|1/2\n|V |1/2 (τ (cid:11)\n2 )\n\n−τ (cid:2)\n\n1 ,\n\n(7.11)\n\np(D|c, k, η) ∝\n\nwhere τ (cid:11)\n\n1 = τ1 + n/2 and\n\nη(cid:3)η − (m(cid:11))(cid:3)(V (cid:11))−1m(cid:11)\n\n(cid:23)\n\n1\n2\n\nτ (cid:11)\n2 = τ1 +\nV (cid:11) = (B(cid:3)B + V −1)−1\nm(cid:11) = V (cid:11)B(cid:3)η.\n\n(cid:24)\n\nGiven the auxiliary variables η, everything else is simple to update as\nwe can use the standard algorithm given before for the Gaussian case. We\ncan propose to add, delete and move a centre and accept the proposed\nmodel with the ratio of marginal likelihoods, which can be found using\n\n\f140\n\nPARTITION MODELLING\n\n(7.11). However, one diﬀerence is that we must store current values of the\ncoeﬃcients and regression precision to allow us to update η. Hence, at the\nsecond comment in the algorithm, we draw them from their conditional\nposterior using\n\np(σ2|c, η, D) = Gamma(τ (cid:11)\n1 , τ (cid:11)\n2 )\np(δ, β|c, η, D) = N (m(cid:11), σ2V (cid:11)).\n\nxi\n\nxi\n\nδ + b(cid:3)\n\nNow we know how to sample p(c|η, D), p(δ, β, σ2|c, D) but we also need\nto sample η. A good way to do this is by using a Metropolis-Hastings up-\ndate (Metropolis et al. (1953), Hastings (1970)). This cycles through all\nthe elements of η in turn, proposing new ηi values from a normal distri-\nbution with mean d(cid:3)\nβ and variance σ2. The proposed value of ηi\nis then accepted with the minimum of one and the ratio of Poisson likeli-\nhoods as the proposal distribution is symmetric. If the residual variation σ2\nturns out to be small then this can aﬀect the updating as the conditional\ndistribution p(δ, β|c, η, D) will be highly peaked. In such cases we would\nrecommend updating via an independence-Metropolis algorithm with the\nproposal distribution taken as the normal approximation to the posterior\ndensity. That is, a normal distribution centred at the mode of p(δ, β|c, D)\nwith variance-covariance matrix taken to be the inverse Hessian at this\npoint.\n\nA further simple modiﬁcation of the model allows us to include or exclude\nthe measured covariates. Dropping a covariate is essentially identical to\nremoving a centre (they both remove a column from B) so BIRTH and\nDEATH steps for the covariates can be constructed which are very similar\nto those used for the centres. In addition, this general methodology can\nalso allow us to incorporate nonlinear models for the covariate eﬀects. For\ninstance, if we had just one covariate we could model the eﬀect of this\ncovariate, xc\n1, through a sum of truncated linear spline terms, as we can\nwrite\n\nq(cid:4)\n\nb(cid:3)\nxβ =\n\nβi(xc\n\n1 − ti)+,\n\n(7.12)\n\ni=1\n\nwhere (a)+ is equal to a when a > 0 and zero otherwise and t1, . . . , tq are\na set of unknown “knot” points. Here, the eﬀ",
    "chunk_order_index": 84,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-77a68f6d31e3a2ce863252db0cadca52": {
    "tokens": 1200,
    "content": "covariate, xc\n1, through a sum of truncated linear spline terms, as we can\nwrite\n\nq(cid:4)\n\nb(cid:3)\nxβ =\n\nβi(xc\n\n1 − ti)+,\n\n(7.12)\n\ni=1\n\nwhere (a)+ is equal to a when a > 0 and zero otherwise and t1, . . . , tq are\na set of unknown “knot” points. Here, the eﬀect of the covariate is consid-\nered to be a continuous piecewise linear function. Sampling q and the ti is\nidentical to sampling which covariates to include when we have more than\none of them, so this model does not present any new technical diﬃculties.\nFurther, it could also be used when we have more than one covariate in\na Bayesian generalized additive, or even a Bayesian multivariate adaptive\nregression spline, model (see Denison et al. (2002b) for more details). Nev-\nertheless in the next section, as the dataset we shall analyse has only one\ncovariate, we shall only use the truncated linear spline model in (7.12) to\nmodel its eﬀect.\n\n\fSPATIAL COUNT DATA\n\n141\n\n3.5\n\n3\n\n2.5\n\n2\n\n1.5\n\n1\n\n0.5\n\n0\n\nFigure 7.4 The standardised mortality ratio for the German lip cancer dataset.\n\n7.4.3 East German Lip Cancer Dataset\n\nWe now demonstrate the methodology outlined in the previous section on\nthe German lip cancer dataset studied in Lawson (2001). It concerns the\nnumber of deaths due to lip cancer in East Germany during the period\n1980–1989. The data consists of the expected number of cases, Ei, and\nthe observed number of cases, yi, in the 219 spatial regions that make up\nEast Germany. In Fig. 7.4 we plot the standardised mortality ratio (given\nby yi/Ei) in each region. Note that the white region halfway up the map\nand towards its right-hand side is West Berlin, for which no data exist.\nAs is typical with such data we see that there is wide variability between\nthe SMRs and no obvious spatial pattern emerges apart from the fact that\nrates seem to be lower in the south. The aim of the analysis is to smooth\nout this raw data to identify a more realistic model for the spatial variation.\nAs well as the expected and observed counts for the regions the data\nincludes information on a possibly important covariate AFF, the percentage\nof agricultural, ﬁsheries and forestry workers. This covariate was measured\nas it is thought that exposure to sunlight, which is an occupational hazard\nfor the workers included, is a risk factor for lip cancer.\n\nIn Fig. 7.5 and Fig. 7.6 we display the estimated relative risks in each\narea found using the Bayesian partition model outlined in Section 7.4.2\nwhen we run the model including, and not including, the information on\nthe covariate AFF. The prior parameters chosen were τ1 = τ2 = 10−5 and\nv = 2.52, so that approximately 95% of the prior probability on the levels\n\n\f142\n\nPARTITION MODELLING\n\nFigure 7.5 The estimated relative risk\nin each region for the model when the\ncovariate was not included and using\nthe same color-scale as in Fig. 7.4.\n\nFigure 7.6 Same as Fig. 7.5 but with\nthe covariate AFF included in the\nmodel.\n\nchanges the relative risk by at most a factor of 5. Note that, to ﬁt easily\nwithin the partition model framework, we take each piece of regional data\nas being given at the centroid of its region. Further, we assumed that the\neﬀect of the covariate can be accurately modelled by a truncated linear\nspline with an unknown number of knots. As might be expected, when we\ninclude the covariate we ﬁnd that the relative risk varies more spatially, due\nto neighbouring regions perhaps having very diﬀerent AFF values. This is\nespecially well demonstrated in the north-east region of the map where\nthere is considerable smoothing across the regions in Fig. 7.5, while there\nare far greater diﬀerences between the risks in the same area of Fig. 7.6.\n\nIn Fig. 7.7 we display the estimated relationship between the log of the\nrelative risk of lip cancer and the value of AFF. It appears that the covariate\nhas little eﬀect for values below 2 and after that the eﬀect is linear. However,\nwe should not use this ﬁgure to interpret that the eﬀect of AFF increases\nthe log relative risk by around 0.18 for values between 0 and 2. This is\nbecause the intercept of the graph is only very weakly identiﬁable by the\nprior as an increase in it, and a similar decrease in the mean eﬀect of the\nspatial component, leads to no change in the overall likelihood and probably\nonly a very small change in the prior. Note that the overall eﬀect of the\ncovariate appears smooth, even though each model produces a piecewise\n\n\fSPATIAL COUNT DATA\n\n143\n\nk\ns\ni\nr\n\ne\nv\ni\nt\na\ne\nr\n\nl\n\ng\no\n\nl\n\nn\n\ni\n\ne\ng\nn\na\nh\nC\n\n0.34\n\n0.",
    "chunk_order_index": 85,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-57a5213dc8c0e0a1319728d75a59ae7d": {
    "tokens": 1200,
    "content": "likelihood and probably\nonly a very small change in the prior. Note that the overall eﬀect of the\ncovariate appears smooth, even though each model produces a piecewise\n\n\fSPATIAL COUNT DATA\n\n143\n\nk\ns\ni\nr\n\ne\nv\ni\nt\na\ne\nr\n\nl\n\ng\no\n\nl\n\nn\n\ni\n\ne\ng\nn\na\nh\nC\n\n0.34\n\n0.32\n\n0.3\n\n0.28\n\n0.26\n\n0.24\n\n0.22\n\n0.2\n\n0.18\n\n0.16\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n3.5\n\n4\n\n4.5\n\nAFF\n\nFigure 7.7 The estimated relationship between the logarithm of the relative risk\nof disease and the covariate AFF (the % of agricultural, ﬁsheries and forestry\nworkers).\n\n0.05\n\n0.045\n\n0.04\n\n0.035\n\n0.03\n\n0.025\n\n0.02\n\n0.015\n\n0.01\n\n0.005\n\n0\n\nFigure 7.8 The equivalent kernel found using the partition model without the co-\nvariate.\n\nlinear curve. This is due to the posterior averaging over all the models in\nthe generated sample.\n\nFig. 7.8 gives the equivalent kernel which gives an indication of how\nimportant each area was to the darkest one near the centre of the map.\n\n \n \n \n \n\f144\n\nPARTITION MODELLING\n\nWe see that the prediction of the relative risk in this area is predominantly\nmade by those regions in the north-west. Even though regions south of it\nare nearby in distance terms, their relative risks are hardly used in ﬁnding\nthe estimated risk in the region of interest. Similar characteristics of the\npartition model were seen earlier in Fig. 7.3.\n\n7.5 Discussion\n\nWe have summarised some of the properties of Bayesian partition models\nthat make them particularly suitable for spatial modelling. Even though\nthe individual models of the response are discontinuous we have seen how,\nwhen the centre locations have been integrated out, this leads to a sensible\nprior on the dependence between neighbouring locations (i.e. a spherical\none with the correlation monotonically decreasing with distance). We have\nalso outlined a generalisation of the model that allows us to perform disease\nmapping, both with and without covariates. The same methodology also\nallows us to use nonlinear functions to model the eﬀect of the covariate on\nthe log relative risk of disease. Through the application of the model to two\ndatasets we have seen how it performs for both point-level data and that\ngiven in regions.\n\nIt is important to note that the simplicity of these methods is highly\ndependent on the assumption of independence between the process in each\nof the regions in the tessellation. Allowing dependence between them pre-\nvents us from integrating out the levels, signiﬁcantly complicating simula-\ntion from the posterior. Personally, we do not feel that we can accurately\nspecify a dependence structure which is consistent with our prior beliefs\nabout the levels/rates in neighbouring regions. In the absence of such in-\nformation we choose to assume independence between the levels. We also\nnote that this gives rise to the attractive prior dependence structure as seen\nin Fig. 7.2.\n\n7.6 Further Reading\n\nEarly work on the Bayesian partition models includes Yao (1984), Car-\nlin et al. (1992), Barry and Hartigan (1993) and Stephens (1994). These\nmethods generally involved splitting up a one-dimensional predictor space\ninto independent blocks, equivalently to a one-dimensional Voronoi tessel-\nlation. In a spatial context there are numerous examples of partition-like\nmodels, e.g. Byers (1992), Ghosh et al. (1997), Sambridge (1999a, 1999b)\nand Møller and Skare (2001). Other related work includes Silverman and\nCooper (1988), Phillips and Smith (1994), Aykroyd (1995), Green (1995),\nNicholls (1998) and Rue and Hurn (1999). These papers in image anal-\nysis tend to use speciﬁcally designed templates to partition the image of\ninterest.\n\n\fFURTHER READING\n\n145\n\nMore closely related to the work presented here are the papers on disease\nmapping given by Knorr-Held and Rasser (2000) and Green and Richardson\n(2000). Knorr-Held and Rasser (2000) deﬁne a partitioning structure on\nthe regions and cluster them into regions of identical risk. See also the\nfollow-up paper by Giudici et al. (2000). Instead, Green and Richardson\n(2000) model the relative risk using mixtures of Poisson distributions where\nthe probability of being assigned to each mixture depends on their spatial\nlocation.\n\nOther papers have utilised Voronoi tessellations to model point process\ndata thought to have been generated by a Poisson rate parameter that\nvaries across the space of interest. Similarly to the partition model intro-\nduced here, these assume that the rate is ﬁxed in each region. The papers\nby Heikkinen and Arjas (1998, 1999) suggested this method and used a\nspecially designed prior to model the relationship between the rates in\nneighbouring regions. An alternative approach is suggested in Chapter 6\nwho, similarly to the model outlined here, took the rates in each region to\nbe independent a priori.\n\nAcknowledgments\n\nThe authors would like to thank Leo Knorr-Held",
    "chunk_order_index": 86,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-821a888789c501c94dc6427fdd4d12b2": {
    "tokens": 1200,
    "content": "assume that the rate is ﬁxed in each region. The papers\nby Heikkinen and Arjas (1998, 1999) suggested this method and used a\nspecially designed prior to model the relationship between the rates in\nneighbouring regions. An alternative approach is suggested in Chapter 6\nwho, similarly to the model outlined here, took the rates in each region to\nbe independent a priori.\n\nAcknowledgments\n\nThe authors would like to thank Leo Knorr-Held for his comments on an\nearlier draft of this paper. The ﬁrst author was supported by grant SFRH\nBD 1399 2000 from Funda¸c˜ao para a Ciˆencia e Tecnologia, Portugal and\nthe second author acknowledges the support of an EPSRC grant.\n\n\f\fCHAPTER 8\n\nCluster Modelling for Disease Rate\nMapping\n\nR.E. Gangnon M.K. Clayton\n\n8.1 Introduction\n\nStatistical methods for analyzing spatial patterns of disease incidence or\nmortality have been of great interest over the past decade. To a large extent,\nthe statistical approaches taken fall into two classes: cluster detection or\ndisease mapping. In cluster detection, one typically adopts the hypothesis\ntesting framework, testing the null hypothesis of a common disease rate\nacross the study region against a “clustering” alternative (Whittemore et\nal. 1987, Kulldorﬀ and Nagarwalla 1995). In disease mapping, one typically\nuses Bayes or empirical Bayes methods to produce smoothed estimates\nof the cell-speciﬁc disease rates suitable for mapping (see, for example,\nClayton and Kaldor (1987) and Besag et al. (1991)). In this paper, we\ndescribe a method for inference that simultaneously addresses both the\ncluster detection and the disease mapping problems.\n\nMany Bayesian approaches to analyzing spatial disease patterns focus on\nmapping spatially smoothed disease rates (for example, Clayton and Kaldor\n(1987), Besag et al. (1991) and Waller et al. (1997a)). Mapping methods\nproduce stable estimates for cell-speciﬁc rates by borrowing strength from\nneighboring cells. These are most useful for capturing gradual, regional\nchanges in disease rates, and are less useful in detecting abrupt, local-\nized changes indicative of hot spot clustering. The models proposed by\nBesag et al. (1991) and Waller et al. (1997a) incorporate both spatially\nstructured (spatial correlation) and unstructured (extra-Poisson variation)\nheterogeneity in one model. The ability of these models to detect localized\nclusters is questionable, because they incorporate only a global clustering\nmechanism. In addition, typically, the spatially structured and unstruc-\ntured components of the heterogeneity are not separately identiﬁed by the\nlikelihood (Waller et al. 1997a).\n\nA few Bayesian approaches more directly address the disease cluster-\ning problem, including Lawson (1995), Lawson and Clark (1999b), and\nGangnon and Clayton (2000). Lawson (1995) proposes a point process\n\n\f148\n\nCLUSTER MODELLING FOR DISEASE RATE MAPPING\n\nmodel for detection of cluster locations when exact case (and control) lo-\ncations are known. Lawson (2000) describes an extension of this model to\nincorporate both localized clustering and general spatial heterogeneity of\ndisease rates. Lawson and Clark (1999b) describe the application of a point\nprocess clustering model to case count data through data augmentation.\nTo apply their model, one imputes locations for each member of the popu-\nlation at risk, typically by assuming a uniform spatial distribution within\neach cell, to produce a point process. One then proposes a clustering model\nfor the point process. Gangnon and Clayton (2000) propose a model for\nclustering using cell count data in which the study region is divided into\nseveral components: a large background area and a relatively small num-\nber of clusters where a common rate (or covariate-adjusted risk) is assumed\nwithin each component.\n\nKnorr-Held and Rasser (2000) and Denison and Holmes (2001) consider a\nnonparametric Bayesian framework for modelling cell count data. Although\nsuperﬁcially similar to the Gangnon and Clayton (2001) model in that cells\nare grouped into components of constant risk, the models of Knorr-Held\nand Rasser (2000) and Denison and Holmes (2001) serve a very diﬀerent\ngoal. In the models of Knorr-Held and Rasser (2000) and Denison and\nHolmes (2001), the components (or clusters) of cells primarily serve as a\ntool for estimating the underlying risk surface, not as parameters of direct\ninterest. In the model of Gangnon and Clayton (2000), the location and\ncomposition of the cluster of cells is of primary interest.\n\nIn Section 8.2, we describe the model for clustering originally proposed\nby Gangnon and Clayton (2000). In Section 8.3, we review a randomized\nvariant on a backwards selection algorithm useful for approximating the\nposterior distribution on cluster models. In Section 8.4, we illustrate the\nuse of these modelling techniques through the construction of maps of the\n1995 mortality rates from ﬁve cancers (breast, cervical, colon, lung and\nstomach) in the United States.\n\n8.2 Statistical Model\n\nConsider a study region divided into N subregions, or cells. A cell is typ-\nically a geopolitical subregion of the study region, e.g., a state within a\ncountry, a county",
    "chunk_order_index": 87,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-b193d3c482c2a76d60d20f682720f419": {
    "tokens": 1200,
    "content": "cluster models. In Section 8.4, we illustrate the\nuse of these modelling techniques through the construction of maps of the\n1995 mortality rates from ﬁve cancers (breast, cervical, colon, lung and\nstomach) in the United States.\n\n8.2 Statistical Model\n\nConsider a study region divided into N subregions, or cells. A cell is typ-\nically a geopolitical subregion of the study region, e.g., a state within a\ncountry, a county within a state, a census tract or block within a county.\nFor each cell i, we observe yi, the number of cases of disease (or deaths),\nand Ei, the expected number of cases (or deaths) calculated using either\ninternal or external standardization. We assume a Poisson model for the\ndata, i.e., yi ∼ Poisson(riEi), where ri is the standardized incidence (or\nmortality) ratio for cell i.\n\nTo draw inferences about ri, we propose a Bayesian model with a hi-\nerarchical prior. First, divide the cells into k + 1 groups, or components.\nCall one of these components the background and the other k compo-\n\n\fSTATISTICAL MODEL\n\n149\n\nnents clusters. Denote the set of cells belonging to the background by\nc0, and the sets of cells belonging to the clusters by c1, c2, . . . , ck. The\nk! models with the same cluster components are regarded as identical,\nand a unique representation is chosen (for example, we typically require\nthat min c1 < min c2 < . . . < min ck). Given a speciﬁc cluster model\nc0, c1, . . . , ck, we assume that cells belonging to component j share a com-\nk\nj=0 ρjI{i∈cj }.\nmon risk ratio ρj, i.e., ri =\n\nTo construct our model, we temporarily assume that c is known. Given\nthe arbitrary labeling of the clusters, it is sensible to utilize an exchangeable\nprior for ρ1, ρ2, . . . , ρk. Speciﬁcally, in our examples, we take ρ0 | c ∼\nGamma(α0, β0), and ρj | c ∼ Gamma(α, β), j = 1, 2, . . . , k.\n\nGiven y and c, ρ0, ρ1, . . . , ρk are independent, ρ0 | c, y ∼ Gamma(α0 +\ny•0, β0 + E•0), and ρj | c, y ∼ Gamma(α + y•j, β + E•j), j = 1, 2, . . . , k,\nyi · I{ci=j} is the total number of cases in cluster j, E•j =\n\nwhere y•j =\n\nN(cid:1)\n\n(cid:1)\n\nN(cid:1)\n\ni=1\n\nEi · I{ci=j} is the total expected number of cases in cluster j, and I{ci=j}\n\ni=1\nis 1 if ci = j and 0 if ci (cid:4)= j. The marginal likelihood of y given c is\n\np(y|c) =\n\nΓ(α0 + y•0)\nΓ(α0)\n\n·\n\nβα0\n0\n(β0 + E•0)α0+y•0\n\n·\n\nk(cid:2)\n\nj=1\n\nΓ(α + y•j)\nΓ(α)\n\n·\n\nβα\n(β + E•j)α+y•j\n\n·\n\nN(cid:2)\n\ni=1\n\nEyi\ni\nyi!\n\n.\n\n(8.1)\n\nThis closed-form expression for the marginal likelihood allows us to avoid\nexplicit consideration of the risk parameters in calculating the posterior\ndistribution over cluster models.\n\nNext, given k (i.e., the number of clusters), we deﬁne a prior distribution\nfor the cluster model c0, c1, . . . , ck using a product speciﬁcation. That is,\nthe prior probability of a particular cluster model is given by\n\n\n\n\n\np(c0, c1, . . . , ck|k) = exp\n\n−\n\nk(cid:5)\n\nj=1\n\nS(cj)\n\n ,\n\nwhere S is a function for scoring the prior probability of a cluster based on\nits geographic properties. The particular scoring function should be tailored\nto the speciﬁc application. For example, in an analysis of leukemia incidence\nin census tracts or blocks within an eight-county region of New York state,\nGangnon and Clayton (2000) develop a scoring function based on area and\nperimeter of clusters designed to detect small, circular clusters. For the\ncancer mortality atlas example in Section 8.4, we consider an alternative\nspeciﬁcation of the prior based on a simpler measure of cluster size.\n\nOur measure of cluster size requires only knowledge of the adjacency\nstructure amongst the cells. Knowledge of the adjacency structure amongst\n\n\f150\n\nCLUSTER MODELLING FOR DISEASE RATE MAPPING\n\nthe cells allows us to think of the map as an undirected graph. The distance\nbetween two cells in this graph is deﬁned to be the length of the shortest\npath between the two cells in the graph. For any cluster (i.e., connected\nsubgraph), we deﬁne the cluster size to be the maximum distance in the\nentire graph between any pair of cells belonging to the cluster; cluster size\nranges between 0 and smax, where smax is the diameter of",
    "chunk_order_index": 88,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-46e071c7458f0b941ff6d79cba8af2da": {
    "tokens": 1200,
    "content": "us to think of the map as an undirected graph. The distance\nbetween two cells in this graph is deﬁned to be the length of the shortest\npath between the two cells in the graph. For any cluster (i.e., connected\nsubgraph), we deﬁne the cluster size to be the maximum distance in the\nentire graph between any pair of cells belonging to the cluster; cluster size\nranges between 0 and smax, where smax is the diameter of the graph, i.e.,\nthe maximum distance between any pair of cells. (An alternative measure\nof cluster size would be the diameter of the induced connected subgraph\ngenerated by the cluster so that distances between cells are measured based\nonly on paths entirely contained within the cluster. Our deﬁnition of cluster\nsize has some operational advantages, and the diﬀerences between the two\ndeﬁnitions are generally quite small.)\n\nWe now discuss one possible scoring function for cluster size, which is\nmotivated by a scheme for randomly selecting a cluster. For this scheme,\nwe ﬁrst select a cluster size and then, conditional on the chosen cluster size,\nselect a cluster at random. First, the cluster size is chosen at random, with\nprobability ps, s = 0, 2, . . . , smax. The cluster is then selected at random,\nwith probability 1/ns from the ns clusters of the speciﬁed size. Thus, the\nprobability of selecting a cluster c of size s under this scheme is 1/(psns),\nand the corresponding scoring function is S(c) = − log(ps) − log(ns). Cal-\nculation of the ns can be computationally burdensome for even modest\nvalues of s because ns typically increases exponentially with s. For the ex-\nample in Section 8.4, we explicitly calculate n0 and n1 and use a rough\nextrapolation to approximate ns for larger values of s.\n\n8.3 Posterior Calculation\n\nGiven the large number of potential cluster models, we cannot, in practice,\nevaluate the desired posterior through direct enumeration. Instead, we pro-\npose using a randomized variant of an agglomerative clustering algorithm\n(or a backwards variable selection algorithm) to calculate an approximation\nto the posterior. The ﬁrst component of this algorithm is Occam’s window\n(Madigan and Raftery 1994, Raftery et al. 1997), which serves to reduce\nconsideration to a relatively small number of models over which a model\naverage can be computed.\n\nIn the symmetric version of Occam’s window, one excludes a model M\n\nfrom consideration if there exists another model M (cid:5) such that\n\np(M |data)\np(M (cid:5)|data)\n\n< 1/W\n\nfor a ﬁxed W . In the strict version of Occam’s window, one also excludes\na model M from consideration if there exists a sub-model Ms of M with\np(Ms|data) ≥ p(M |data). This second rule is an attempt at an implemen-\ntation of Occam’s razor, or the principle of parsimony.\n\n\fPOSTERIOR CALCULATION\n\n151\n\nIn most applications, we utilize the symmetric version of Occam’s win-\ndow. If the chosen W is suﬃciently large, the symmetric version of Oc-\ncam’s window only serves to truncate the far tails of the posterior and\nthus should not have an excessive impact on our inferences. On the other\nhand, the strict rule based on Occam’s razor, while intuitively appealing,\npotentially excludes from consideration very competitive models and thus\ncan have a dramatic eﬀect on our inferences. For example, let two models\nM0 and M1 have posterior probabilities of 0.51 and 0.49, respectively. If\nM0 is a sub-model of M1 and we use the strict version of Occam’s window,\nthe “posterior” probability of M0 becomes 1 and our large degree of uncer-\ntainty about the correct model is translated into certainty that the simpler\nmodel is correct.\n\nTo ﬁnd the models falling within the symmetric version of Occam’s win-\ndow (with parameter W ), we utilize a randomized search algorithm similar\nto both backwards elimination methods for variable selection or agglom-\nerative methods for clustering. In our algorithm, we start with one of the\nN saturated models, i.e., one of the models with N − 1 clusters, and re-\npeatedly merge adjacent components of the current model with the aim of\nproducing models with high posterior probability.\n\nGiven the size of the model space, we will not be able to determine\nwith certainty which mergers lead to better models. To address this, let\nc0, c1, . . . , ck be the components of the current model, and let pij be the\nposterior probability of the model obtained by merging ci and cj, i =\n0, 1, . . . , k − 1, j = i + 1, i + 2, . . . , k. Note that pij ≡ 0 for the components\nci and cj that are not adjacent to each other. The fundamental notion\nbehind our search algorithm is that the posterior density pij is a good\nproxy measure for the likelihood that merging ci and cj will eventually\nlead to models with high posterior probabilities. To justify this notion,\nnote that the posterior probability pij can be thought of as a measure of\nthe relative probability that the disease rates for components ci and cj are\nthe same, or equivalently that the cells in components ci and cj belong to\nthe same component in the true cluster model.\n\nIn practice, we select a merger of adjacent components using the following\n\nthree-step procedure",
    "chunk_order_index": 89,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-539de55dc83c757899ac84f5c695dad2": {
    "tokens": 1200,
    "content": "good\nproxy measure for the likelihood that merging ci and cj will eventually\nlead to models with high posterior probabilities. To justify this notion,\nnote that the posterior probability pij can be thought of as a measure of\nthe relative probability that the disease rates for components ci and cj are\nthe same, or equivalently that the cells in components ci and cj belong to\nthe same component in the true cluster model.\n\nIn practice, we select a merger of adjacent components using the following\n\nthree-step procedure.\n1. For each pair of adjacent components ci and cj, i < j, in the current\n\nmodel M , we calculate\n\nMij =\n\n=\n\npij\np(M )\nΓ(αi + y•i + y•j)Γ(αj)\nΓ(αi + y•i)Γ(α + y•j)\n\n(βi + E•i)αi+y•i(β + E•j)α+y•j\n(βi + E•i + E•j)αi+y•i+y•j βα ,\n\nwhere p(M ) is the posterior probability of the current model M and\n(αi, βi) = (α, β) for i > 0. We note that Mij depends the current model\n\n\f152\n\nCLUSTER MODELLING FOR DISEASE RATE MAPPING\n\nonly through the components ci and cj. Thus, after each merger, we\nneed only update the Mij if component ci or cj was involved in the\nmerger.\n\n2. Calculate the probability of merging components ci and cj, i < j, de-\nnoted by Pij, by truncating Mij using a symmetric Occam’s window\nwith parameter W (cid:5) (in most applications, we take W (cid:5) ≤ W ), i.e., calcu-\nlate and then normalize the values\n\nPij ∝ Mij\n\nif\n\nMij\n\nMij\n\nmax\n(i,j)\n\n≥ 1/W (cid:5)\n\n= 0\n\notherwise\n\nTruncating the merger probabilities using Occam’s window helps prevent\na large number of poor mergers from overwhelming a small number of\npromising mergers, and can, in practice, greatly speed the model search.\n3. Select the merger of adjacent components ci and cj, i < j, with proba-\n\nbility Pij.\nOur search algorithm proceeds by repeatedly applying the merger selec-\ntion step discussed above. To speed the search, we ﬁrst reduce its scope.\nInstead of beginning each new search from a saturated model, we ﬁrst build\na smaller, but still implausibly large, cluster model as a base (model) for\nmultiple searches. By starting searches from smaller base models, we in-\ncrease the number of good models that can be examined in a ﬁxed time\nperiod. Once searches from a given base stop producing new, good models,\nwe build a new base from which the search can proceed. We outline the\ndetails of the search algorithm with a single base (size). The extension to\nmultiple bases is straightforward.\n1. Start with one of the N saturated models which contain N − 1 clusters\nand a single background cell by selecting one of the N cells at random to\nN −1}.\nbe the background cell. Denote this model by Ms = {cs\n2. Repeatedly merge adjacent components of Ms using the merger selection\nprocedure described above to produce a model with k clusters. Denote\n}.\nthis model by Mb = {cb\n1, . . . , cb\nk\n3. Repeatedly merge adjacent components of Mb using the merger selection\nprocedure described above to produce a nested series of cluster models\nwith k − 1, k − 2, . . . , 2, 1 clusters.\n\n1, . . . , cs\n\n0, cs\n\n0, cb\n\n4. Update the current list of cluster models falling within the symmetric\nversion of Occam’s window (with parameter W ) to reﬂect the models\nfound in Step 3.\n\n5. Repeat Steps 3 and 4 until a prespeciﬁed stopping rule is satisﬁed.\n6. Repeat Steps 1-5 until a prespeciﬁed stopping rule is satisﬁed.\n\n\fEXAMPLE: U.S. CANCER MORTALITY ATLAS\n\n153\n\nPossible stopping rules for Steps 5 and 6 include stopping after a ﬁxed\nnumber of iterations or stopping after some number of consecutive failures\nto ﬁnd a new model falling within Occam’s window. We generally use an\nadaptive stopping rule based on sequential determination of whether the\nsuccess probability θ in a sequence of Bernoulli trials is zero. With a non-\ntrivial prior and loss function, the optimal Bayes sequential rule is to stop\nafter observing the ﬁrst success or when the posterior mean for θ is less than\nthe cost of the next observation (Gangnon 1998). In the former case, we\nwill begin a new sequence of searches with a diﬀerent θ; in the latter case,\nwe will stop the search. With good prior choices, we can quickly abandon\npoor bases and exhaustively sample good bases.\n\nUsing the approximate posterior distribution based on the models falling\nwithin Occam’s window, we can estimate various cell-speciﬁc quantities. For\nexample, a reasonable estimate for the cell-speciﬁc standardized incidence\n(or mortality) ratio r is its posterior mean\n\nˆri = E(ri|y) =\n\nE(ρci\n\n|y, c) · p(c|y), i = 1, 2, . . . , N .\n\n(cid:5)\n\nc\n\nIn contrast to estimates based on a single cluster model, the posterior",
    "chunk_order_index": 90,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-36c39d8542ab94e0623f9cb98c18e9f1": {
    "tokens": 1200,
    "content": ", we can estimate various cell-speciﬁc quantities. For\nexample, a reasonable estimate for the cell-speciﬁc standardized incidence\n(or mortality) ratio r is its posterior mean\n\nˆri = E(ri|y) =\n\nE(ρci\n\n|y, c) · p(c|y), i = 1, 2, . . . , N .\n\n(cid:5)\n\nc\n\nIn contrast to estimates based on a single cluster model, the posterior\nmeans will generally produce “fuzzy” edges of clusters, reﬂecting uncer-\ntainty about the exact composition of the clusters. A grayscale map of the\nˆri’s can eﬀectively demonstrate both cluster locations and cluster risks. In\ncases where the cluster borders are of primary interest, this map may be\nsupplemented by a map of the posterior probability that the cell belongs\nto a cluster,\n\n(cid:5)\n\np(ci > 0|y) =\n\np(c|y), i = 1, 2, . . . , N .\n\nc:ci>0\n\n8.4 Example: U.S. Cancer Mortality Atlas\n\nThe Centers for Disease Control and Prevention (CDC) provide access\nto the Compressed Mortality File (CMF), a county-level national mor-\ntality and population data base spanning the years 1979-98, through the\nCDC WONDER website (http://wonder.cdc.gov). From this data base, we\nobtained the number of adult (≥ 20 years old) deaths in 1995 from ﬁve can-\ncers for the 48 contiguous states and the District of Columbia (DC). The\nﬁve cancer sites were lung, female breast, cervical, colorectal and stomach.\nFor each state, an expected death count from each cancer was calculated\nby applying the 1995 national death rates from each cancer for subgroups\nbased on age, sex (where appropriate) and race to the state’s population.\nIn this series of analyses, we wish to identify regions of clustering of the\nstate-speciﬁc mortality rates within the maps. To guide the analysis, we use\na particular implementation of the scoring function discussed in Section 8.2.\nThe maximum distance between any two states measured within the cor-\n\n\f154\n\nCLUSTER MODELLING FOR DISEASE RATE MAPPING\n\nresponding graph is 11. So, the potential cluster sizes range between 0 and\n11. We select the cluster size uniformly from the available cluster sizes,\ni.e., ps = 1/11, s = 0, 1, . . . , 11. As noted previously, explicit calculation\nof the number of clusters is diﬃcult because the number of clusters grows\nexponentially along with the cluster size. Instead, we calculate only n0 and\nn1 explicitly. For larger values of s, we use the value ns = (s − 1)!csn0,\nwhere c = n1/n0. (This formula is the solution of the recurrence relation\nns = (s − 1)cns−1. In this formula, (s − 1)c represents the multiplicative\nincrease in the number of clusters as cluster size increases. The factor s − 1\nrepresents a crude approximation to the number of cells in the clusters so\nthat c is the “per cell” multiplier.) For the U.S. map, n0 = 49, n1 = 162\nand c = 3.31.\n\nFor these analyses, we make no prior assumptions regarding the direction\nof risks within clusters, and so use the same gamma prior for both the\nbackground risk and the cluster risk. A priori, we have no reason to believe\nthat the expected number of deaths given for each state is incorrect. This\nbelief leads us to specify a Gamma(γ, γ) prior for the risks for some γ > 0.\nGiven the relatively small number of clusters in most models, the data\nwill not provide enough information to reliably estimate γ. To evaluate the\nimpact of the choice of γ on our inference, we analyzed each data set using\nseveral diﬀerent values for γ (0.1, 0.5, 1, 2, 10). The choice of γ had little\nimpact on our inferences, and thus results are presented for γ = 1.\n\nFor the posterior approximations, we use a symmetric Occam’s window\nwith parameter W = 1000. To speed the search, we utilize two bases (or\nbase sizes), 48 clusters and 26 clusters. Thus, we implicitly assumed the\nmaximum number of clusters in a model belonging to Occam’s window\nwas 25. In practice, the number of clusters never approached this limit. If\nit had, we would have restarted the search with a larger second base.\n\nThe estimated cancer mortality risks by state are displayed in Figure 8.1\nfor (female) breast cancer, in Figure 8.2 for cervical cancer, in Figure 8.3\nfor colorectal cancer, Figure 8.4 for lung cancer and in Figure 8.5 for stom-\nach cancer. Each ﬁgure includes a grayscale map of the contiguous United\nStates. The grayscale indicates the estimated, or posterior mean, risk for\neach state. (The grayscale is consistent across the ﬁgures.) Below each\nmap, we provide equal-tailed 95% posterior intervals for the mortality risk\nin each state based on the model-averaged posterior distributions for the\nstate-speciﬁc mortality risks. (In these displays, the states are ordered by\nthe posterior mean risk.)\n\n8.4.1 Breast Cancer\n\nExamining Figure 8.1, we observe that states appear",
    "chunk_order_index": 91,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-47b83c01d35bc550f6d2024c64832a29": {
    "tokens": 1200,
    "content": "posterior mean, risk for\neach state. (The grayscale is consistent across the ﬁgures.) Below each\nmap, we provide equal-tailed 95% posterior intervals for the mortality risk\nin each state based on the model-averaged posterior distributions for the\nstate-speciﬁc mortality risks. (In these displays, the states are ordered by\nthe posterior mean risk.)\n\n8.4.1 Breast Cancer\n\nExamining Figure 8.1, we observe that states appear to fall into one of\nthree groups – a higher risk group of states in the Northeast and Midwest\nwith posterior mean mortality ratios of approximately 1.06, a lower risk\n\n\fEXAMPLE: U.S. CANCER MORTALITY ATLAS\n\n155\n\ngroup of states in the South and Midwest with posterior mean mortality\nratios of approximately 0.95, and a group of border states which could\npotentially belong to either group. The border states could be further sub-\ndivided into the states more likely to belong to the higher risk group (e.g.,\nMissouri, North Dakota, Montana, D.C. and Indiana) and states more likely\nto belong to the lower risk group (e.g., Oklahoma, South Dakota, West Vir-\nginia, Kansas, Idaho, Virginia, Nebraska, Washington). For states in the\nthird group, the uncertainty about cluster membership produces a bimodal\nposterior for the mortality ratio, which translates into very wide posterior\nintervals for the state-speciﬁc mortality risks.\n\n8.4.2 Cervical Cancer\n\nIn Figure 8.2, we observe clear evidence of a single cluster of states with\nelevated risk of cervical cancer mortality. Five states clearly belong to this\ncluster: Arkansas, Kentucky, West Virginia, Tennessee and Texas. The (pos-\nterior mean) increase in mortality associated with this cluster is approxi-\nmately 27%. Up to four other states – Indiana, Louisiana, Oklahoma and\nNew Mexico – are likely to also belong to this cluster, and up to ﬁve addi-\ntional states beyond those four could possibly belong to the cluster.\n\n8.4.3 Colorectal Cancer\n\nFor colorectal cancer (Figure 8.3), the states fall into three groups based\non the mortality risk levels. Note, however, that the majority of models in-\ncluded in Occam’s window contain four clusters indicating that some of the\nsimilar risk groups are disconnected. The higher risk group, with a posterior\nmean risk of approximately 1.12, consists of 14 states in the Northeast and\nMidwest. The lower risk group, with an approximate mortality risk of 0.90,\nconsists of a cluster of 3 states in the Southeast (Alabama, Florida, Geor-\ngia) and a cluster of 11 states in the West. The third medium risk group,\nwith an approximate colorectal cancer mortality risk of 1.00, consists of 8\nstates in the Midwest and South. The majority of the other states fall on\nthe border between two of these three groups and could conceivably belong\nto either group. Two states are clear exceptions to this rule – Louisiana and\nConnecticut. Louisiana is an isolated higher risk state within the two lower\nrisk groups; Connecticut is an isolated lower risk state within the North-\neast. The wide posterior intervals for these two states primarily reﬂect the\nuncertainty associated with estimates for state-speciﬁc risks, when we are\nunable to borrow strength from neighboring states.\n\n\f156\n\nCLUSTER MODELLING FOR DISEASE RATE MAPPING\n\n0.90\n\n1.00\n\n1.10\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\nRI\nOH\nNJ\nMI\nME\nDE\nMD\nMN\nND\nDC\nOK\nWY\nID\nNE\nNV\nKY\nIA\nCA\nSC\nNM\nGA\nCO\nUT\nMS\n\n|\n\n|\n|\n\n|\n\n|\n\n|\n\n|\n\n|\n\n|\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\nVT\nPA\nNY\nNH\nMA\nIL\nCT\nWI\nMO\nMT\nIN\nSD\nKS\nVA\nWA\nWV\nOR\nTN\nTX\nNC\nLA\nFL\nAR\nAZ\nAL\n\n0.90\n\n1.00\n\n1.10\n\nEstimated Risk (Relative to Expected)\n\nFigure 8.1 Estimated female breast cancer mortality risk (relative to expected\nnumber of deaths based on age-race distribution) by state (1995). Grayscale indi-\ncates posterior mean. Intervals are equal-tailed 95% posterior probability intervals.\nVertical lines indicate the posterior mean.\n\n\fEXAMPLE: U.S. CANCER MORTALITY ATLAS\n\n157\n\n0.90\n\n1.00\n\n1.10\n\n|\n\n|\n\n|\n\n|\n|\n|\n\nKY\nWV\nTX\nLA\nNM\nNE\nMO\nWY\nKS\nNV\nIA\nAZ\nWI\nVA\nSC\nPA\nOH\nNC\nNH\nMI\nMD\nGA\nDE\nMT\nUT\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\n1.50\n\n1.25\n\n|\n|\n|\n|\n|\n\n|\n\n|\n\nTN\nAR\nIN\nOK\nMS\nCO\nAL\nDC\nSD\nME\nID\nNJ\nWA\nVT\nRI\nOR\nND\nNY\nMN\nMA\nIL\nFL\nCA\nCT\n\n0.90\n\n1.00\n\n1.10\n\n1.25\n\n1.50\n\nEstimated Risk (Relative to Expected)\n\nFigure",
    "chunk_order_index": 92,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-ed8b32825962f4749abca1b70505014d": {
    "tokens": 1200,
    "content": "|\n|\n|\n|\n|\n|\n|\n|\n|\n\n1.50\n\n1.25\n\n|\n|\n|\n|\n|\n\n|\n\n|\n\nTN\nAR\nIN\nOK\nMS\nCO\nAL\nDC\nSD\nME\nID\nNJ\nWA\nVT\nRI\nOR\nND\nNY\nMN\nMA\nIL\nFL\nCA\nCT\n\n0.90\n\n1.00\n\n1.10\n\n1.25\n\n1.50\n\nEstimated Risk (Relative to Expected)\n\nFigure 8.2 Estimated cervical cancer mortality risk (relative to expected number\nof deaths based on age-race distribution) by state (1995). Grayscale indicates pos-\nterior mean. Intervals are equal-tailed 95% posterior probability intervals. Vertical\nlines indicate the posterior mean.\n\n\f158\n\nCLUSTER MODELLING FOR DISEASE RATE MAPPING\n\n0.80\n\n0.90\n\n1.00\n\n1.10\n\n1.25\n\nNJ\nNH\nNY\nOH\nIL\nMD\nKY\nDC\nLA\nIA\nWI\nVA\nNC\nSD\nSC\nCT\nND\nMT\nTX\nNM\nOR\nID\nCA\nGA\nAL\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\n|\n\n|\n\n|\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\n|\n\n|\n\n|\n|\n\n|\n\n|\n|\n\n|\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\n|\n|\n|\n\nVT\nMA\nPA\nDE\nME\nRI\nIN\nWV\nMO\nNE\nMI\nTN\nMN\nWY\nAR\nKS\nMS\nOK\nUT\nWA\nNV\nCO\nAZ\nFL\n\n0.80\n\n0.90\n\n1.00\n\n1.10\n\n1.25\n\nEstimated Risk (Relative to Expected)\n\nFigure 8.3 Estimated colorectal cancer mortality risk (relative to expected number\nof deaths based on age-sex-race distribution) by state (1995). Grayscale indicates\nposterior mean. Intervals are equal-tailed 95% posterior probability intervals. Ver-\ntical lines indicate the posterior mean.\n\n\fCONCLUSIONS\n\n8.4.4 Lung Cancer\n\n159\n\nFor lung cancer (Figure 8.4), we observe wide variations in mortality risks\nacross the entire United States. Models for lung cancer risks falling within\nOccam’s window contain between 12 and 18 clusters. The lowest lung can-\ncer mortality risk, by far, occurs in Utah (0.42); Colorado and New Mexico\nalso have relatively low risks. Lower than expected mortality risks are also\nevident across much of the North. The highest lung cancer mortality risks\noccur in Kentucky, Delaware and West Virginia. Other areas with higher\nthan expected risks are a cluster consisting of Arkansas, Louisiana, Ten-\nnessee, Missouri and Oklahoma and the state of Maine. Presumably, the\nlarge variations in lung cancer mortality risks across the map are due to\nsimilar variations in smoking rates across the country, but we do not cur-\nrently have the data needed to verify this conjecture.\n\n8.4.5 Stomach Cancer\n\nFor stomach cancer (Figure 8.5), we observe three prominent clusters, two\nwith higher than expected mortality and one with lower. The ﬁrst higher\nrisk cluster consists of eight states in the Northeast (three additional states\n– Delaware, Maryland and the District of Columbia could belong to this\ncluster). The second higher risk cluster is California (possibly joined by\nNevada). The lower risk cluster consists of 4–10 states in the center of the\ncountry.\n\n8.5 Conclusions\n\nIn this paper, we presented a model for spatial clustering of disease in\nwhich the region of space under study is partitioned into a single large\nbackground area and a relatively small number of clusters. We adopted a\nBayesian framework for inference, using a simple, but approximate, prior\nspeciﬁcation of the probabilities of various clusters to guide, but not nec-\nessarily limit, selection from the available models. We utilized a random-\nized version of an agglomerative clustering algorithm to ﬁnd models falling\nwithin the symmetric version of Occam’s window.\n\nIn Section 8.4, we illustrated the use of this modelling approach by con-\nstructing maps of the 1995 mortality rates from ﬁve cancers in the United\nStates. The examples in this section show that, with our cluster modelling\napproach, we can produce a map with many clusters, e.g., the map for lung\ncancer mortality (Figure 8.4), a map with few clusters, e.g., the map for\nstomach cancer mortality (Figure 8.5), and a map with only a single cluster,\ne.g., the map for breast cancer (Figure 8.1). The variety of diﬀerent map\nappearances tends to indicate that our estimates are an honest reﬂection of\nthe underlying data, not solely a reﬂection of our prior assumptions. This\n\n\f160\n\nCLUSTER MODELLING FOR DISEASE RATE MAPPING\n\nKY\nWV\nTN\nMO\nAR\nOH\nIL\nVA\nNC\nAL\nFL\nDC\nRI\nTX\nWA\nNJ\nNY\nCA\nWY\nKS\nMT\nND\nWI\nNM\nUT\n\n0.40\n\n0.50\n\n0.67\n\n|\n\n0.40\n\n0.50\n\n|\n|\n\n0.67\n\n0.80\n\n0.90\n\n1.00\n\n1.10\n\n1.25\n\n1.50\n\n|\n|\n\n|\n\n|\n\n|\n|\n|\n|\n|\n\n|\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\n|\n|\n|\n|\n\n|\n|\n|\n|\n\n|\n|\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\nDE",
    "chunk_order_index": 93,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-949ba62ecb5d12ddfa9244dd0eebf42f": {
    "tokens": 1200,
    "content": "0.40\n\n0.50\n\n0.67\n\n|\n\n0.40\n\n0.50\n\n|\n|\n\n0.67\n\n0.80\n\n0.90\n\n1.00\n\n1.10\n\n1.25\n\n1.50\n\n|\n|\n\n|\n\n|\n\n|\n|\n|\n|\n|\n\n|\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\n|\n|\n|\n|\n\n|\n|\n|\n|\n\n|\n|\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\nDE\nME\nOK\nLA\nMS\nIN\nMI\nSC\nGA\nMD\nPA\nNH\nMA\nNV\nOR\nVT\nCT\nAZ\nNE\nIA\nID\nSD\nMN\nCO\n\n0.80\n\n0.90\n\n1.00\n\n1.10\n\n1.25\n\n1.50\n\nEstimated Risk (Relative to Expected)\n\nFigure 8.4 Estimated lung cancer mortality risk (relative to expected number of\ndeaths based on age-sex-race distribution) by state (1995). Grayscale indicates\nposterior mean. Intervals are equal-tailed 95% posterior probability intervals. Ver-\ntical lines indicate the posterior mean.\n\n\fCONCLUSIONS\n\n161\n\n0.67\n\n0.80\n\n0.90\n\n1.00\n\n1.10\n\n1.25\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\n|\n\nVT\nNJ\nMA\nME\nCA\nDC\nDE\nTX\nNM\nKY\nOR\nVA\nSC\nND\nMS\nGA\nAL\nWI\nIN\nMO\nSD\nUT\nKS\nNE\n\n|\n\n|\n|\n|\n|\n\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n\n|\n\n|\n\n|\n|\n\n|\n\n|\n|\n|\n|\n\nRI\nNY\nNH\nCT\nPA\nNV\nMD\nIL\nLA\nWV\nAR\nTN\nWA\nOH\nNC\nMN\nFL\nAZ\nMI\nID\nMT\nWY\nCO\nOK\nIA\n\n0.67\n\n0.80\n\n0.90\n\n1.00\n\n1.10\n\n1.25\n\nEstimated Risk (Relative to Expected)\n\nFigure 8.5 Estimated stomach cancer mortality risk (relative to expected number\nof deaths based on age-sex-race distribution) by state (1995). Grayscale indicates\nposterior mean. Intervals are equal-tailed 95% posterior probability intervals. Ver-\ntical lines indicate the posterior mean.\n\n\f162\n\nCLUSTER MODELLING FOR DISEASE RATE MAPPING\n\ncontention is further supported by additional analyses of these data that\nwe have performed using either diﬀerent approximations for ns or diﬀerent\nmeasures of cluster size (Gangnon 1998). In all cases, although the results\ndiﬀered in some details, all of the major inferences were unaﬀected by the\nchosen prior.\n\n\fCHAPTER 9\n\nAnalyzing Spatial Data Using\nSkew-Gaussian Processes\n\nH. Kim B.K. Mallick\n\n9.1 Introduction\n\nSpatial statistics has become a tool-box of methods useful for attacking a\nrange of problems in scientiﬁc ﬁelds such as petroleum engineering, civil\nengineering, geography, geology, hydrology. The most useful technique for\nstatistical spatial prediction is kriging (Cressie 1993). Most theories related\nto spatial prediction assume that the data are generated from a Gaussian\nrandom ﬁeld. However non-Gaussian characteristics, such as (non-negative)\ncontinuous variables with skewed distribution, appear in many datasets\nfrom scientiﬁc ﬁelds. For example potential, porosity and permeability mea-\nsurements from petroleum engineering applications usually follow skewed\ndistribution. A common way to model this type of data is to assume that\nthe random ﬁeld of interest is the result of an unknown nonlinear transfor-\nmation of a Gaussian random ﬁeld. Trans-Gaussian kriging is the kriging\nvariant used for prediction in transformed Gaussian random ﬁelds, where\nthe normalizing transformation is assumed known. This approach has some\npotential weaknesses (De Oliveira et al. 1997, Azzalini and Capitanio 1999)\nsuch as:\n(i) the transformations are usually on each component separately, and\n\nachievement of joint normality is only hoped for;\n\n(ii) the transformed variables are more diﬃcult to interpret, especially\n\nwhen each variable is transformed by using a diﬀerent function;\n\n(iii) even though the normalizing transformation can be estimated by max-\nimum likelihood, it may be unwise to select a particular transformation;\n(iv) sometimes the back-transformed ﬁtted model is severely biased (Miller\n\n1984, Cressie 1993).\nAlternatively, we can use more general, ﬂexible parametric classes of\nmultivariate distributions to represent features of the dataset aiming to\nreduce the unrealistic assumptions. The pioneering work in this ﬁeld started\nwith Zellner (1976) who dealt with the regression model with multivariate\nStudent-t error terms.\n\n\f164\n\nANALYZING SPATIAL DATA USING SKEW-GAUSSIAN PROCESSES\n\nTo handle skewed data lognormal kriging may be used, but it can only be\napplied to data which follow a normal distribution after log transformation.\nHence, a more general distributional form is needed to deal with real data.\nAzzalini and Dalla Valle (1996) and Azzalini and Capitanio (1999) devel-\noped the skew-Gaussian distribution, which has many similar properties as\nnormal distribution.\n\nIn this chapter we suggest using skew Gaussian processes for prediction\nand illustrate the model on real data, obtaining satisfactory results. To",
    "chunk_order_index": 94,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-a7b38bae63d0f5401c55d928bb0b3130": {
    "tokens": 1200,
    "content": "be\napplied to data which follow a normal distribution after log transformation.\nHence, a more general distributional form is needed to deal with real data.\nAzzalini and Dalla Valle (1996) and Azzalini and Capitanio (1999) devel-\noped the skew-Gaussian distribution, which has many similar properties as\nnormal distribution.\n\nIn this chapter we suggest using skew Gaussian processes for prediction\nand illustrate the model on real data, obtaining satisfactory results. To\naccurately identify clusters, or peaks, in the true underlying spatial process\nwe need to be able to obtain good approximations of it. The accuracy of\nany model necessarily depends on the assumptions made by it. Here, as the\nresponses of many spatial processes are always non-negative, we present a\nmethod for analysing such data that generalizes lognormal kriging.\n\nThe chapter is organized as follows. In Section 9.2 we use a skew-Gaussian\nprocess to model a somewhat-skewed dataset. We employ a Markov chain\nMonte Carlo (MCMC) algorithm, an accept-reject algorithm with a latent\nvariable within the Gibbs sampler to generate samples outlined in Section\n9.2.3. In Section 9.3, we apply this model to the spatial prediction of ﬂow\npotential data for the North Burbank Field. We know that this dataset was\ngenerated by a skewed distribution after exploratory data analysis. Finally\nwe oﬀer a brief discussion in Section 9.4.\n\n9.2 Skew-Gaussian Processes\n\nIf we know that a dataset is generated from a somewhat-skewed distribution\nthen we can do an analysis directly using skewed distributions. One such\ndistribution is the skew-Gaussian one which was proposed by Azzalini and\nDalla Valle (1996). Another ﬂexible family is the lognormal distribution\nwhich only covers λ = 0 of a Box-Cox transformation (Box and Cox 1969).\nBox-Cox transformation is frequently used for “normalizing” positive data:\n\n(cid:1)\n\ngλ(x) =\n\nxλ−1\nλ\nlog(x)\n\nif λ (cid:1)= 0\nif λ = 0\n\n.\n\nThat is the log transformed data follows a normal distribution. The follow-\ning skew-Gaussian distribution can explain a wider class of skewed data.\n\nThe model we shall propose is a special case of Azzalini and Capitanio\n(1999), and it is proved that any linear combination of skew-Gaussian\nrandom variates is still skew-Gaussian. Hence it is natural to deﬁne the\nskew-Gaussian process based on the deﬁnition of the Gaussian process\n(Ripley 1981). A skew-Gaussian process (SGP) is a collection of random\nvariables Y x indexed by a set x ∈ X , where any ﬁnite collection of Y s\nhas a joint multivariate skew-Gaussian distribution. That is, every linear\ncombination has a skew-Gaussian distribution.\n\n\fSKEW-GAUSSIAN PROCESSES\n\n165\n\n9.2.1 The Model\n\nAzzalini and Capitanio (1999) proposed the multivariate skew-Gaussian\ndistribution. For simplicity, and to avoid the introduction of more param-\neters, we consider the following model. Let\n\nZ∗ = (Z(x0), Z (cid:3))(cid:3) ∼ SNn+1(F ∗β, σ2K ∗\nθ ,\n\nα\nσ\n\n1n+1)\n\nhave density\n\nf (z∗|η) = 2φn+1(z∗ − F ∗β; σ2K ∗\n\nθ )Φ\n\n(cid:3)\n(cid:1)\nn+1(z∗ − F ∗β)\n1\n\n,\n\n(cid:2)\n\nα\nσ\n\n(9.1)\n\nfor z∗ ∈ Rn+1 and where α ∈ R is known as the “shape” parameter (al-\nthough the actual skewness is regulated in a more complex way) with\nσ ∈ R+ a scale parameter. Further, η = (β(cid:3)\n, α)(cid:3) and denotes the\nset of model parameters and 1k is the k × k matrix with every entry one.\nNote that when α equals 0, (9.1) reduces to the Nn+1(F ∗β, σ2K ∗\nθ ) density.\nIn general, we observe Z = (Z(x1), · · · , Z(xn))(cid:3) and we shall focus on\nthe prediction of Z(x0), where x0 is an unknown spatial location. So the\ndistributional assumption of Z∗ is natural, where\nf (cid:3)(x0)\nF\n\nkθ(0)\nkθ\n\n, σ2, θ(cid:3)\n\nk(cid:3)\nθ\nKθ\n\nF ∗ =\n\n(9.2)\n\nθ =\n\nK ∗\n\n(cid:5)\n\n(cid:5)\n\n(cid:4)\n\n(cid:4)\n\n,\n\n,\n\nkθ(0) = Kθ(x0, x0), kθ = [Kθ(x0, xi)]n×1, F = [fj(xi)]n×q and Kθ is an\nn × n correlation matrix. Then Z = (Z(x1), Z(x2), · · · , Z(xn))(cid:3) is a real-\nization from the skew Gaussian random ﬁeld on Rn with similar parame-\nters to those for Z∗ but with F ∗ replaced by F , etc. Hence",
    "chunk_order_index": 95,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-4ad49e812538997f6ed42fff703b1a34": {
    "tokens": 1200,
    "content": "kθ = [Kθ(x0, xi)]n×1, F = [fj(xi)]n×q and Kθ is an\nn × n correlation matrix. Then Z = (Z(x1), Z(x2), · · · , Z(xn))(cid:3) is a real-\nization from the skew Gaussian random ﬁeld on Rn with similar parame-\nters to those for Z∗ but with F ∗ replaced by F , etc. Hence [f (x)](cid:3)β =\n(f1(x), · · · , fq(x))(cid:3)β. Furthermore σ2Kθ is positive deﬁnite matrix and\nσ2Kθ(x, y) = σ2Kθ((cid:9)x − y(cid:9)), where θ ∈ Θ is a p × 1 vector of struc-\ntural parameters, Θ is a subset of Rp, σ2 ∈ R+ and (cid:9) · (cid:9) denotes Euclidean\ndistance. Structural parameters control the range of correlation and/or the\nsmoothness of the random ﬁeld, where for every θ ∈ Θ, Kθ(·) is an isotropic\ncorrelation function, assumed to be continuous on θ.\n\nAs our working family of isotropic correlation functions, we use the gen-\neral exponential correlation function (Yaglom 1987, De Oliveira et al. 1997).\n\nKθ(l) = exp\n\n−νlθ2\n\n= θlθ2\n1 ,\n\n(9.3)\n\n(cid:6)\n\n(cid:7)\n\nwhere l represents Euclidean distance between two locations, ν > 0, θ1 =\ne−v ∈ (0, 1), and θ2 ∈ (0, 2] are unknown parameters.\n\nUsing Proposition 4 of Azzalini and Dalla Valle (1996), the marginal\ndistribution of z∗ turns out to be a skew-Gaussian distribution and the\nconditional distribution becomes a member of an extended skew-Gaussian\nclass of densities. These are given by the following expressions:\n\n\f166\n\nANALYZING SPATIAL DATA USING SKEW-GAUSSIAN PROCESSES\n\nf (z|η) = 2φn\n(cid:6)\nf (z(x0)|z, η) = φ1\n\n(cid:6)\n\n(cid:7)\n\nz − F β, σ2Kθ\nz(x0) − µ1.2, σ2K1.2\n(cid:6)\nΦ\n\nσ (z(x0) − µ1.2) + ϕ\n\nΦ (ϕ) ,\n(cid:7)\n\nα\n\n×\n\nΦ (ϕ)\n(cid:6)\n\nz ∈ Rn,\n\n(9.4)\n\n√\n\n(cid:7)\n\n1 + α2K1.2\n\n,\n\n(9.5)\n\n(cid:7)(cid:3)\n\n√\n/\n\nIn\n\n1 + α2K1.2,\n\nθ kθ and In denotes\n\nwhere z(x0) ∈ R, ϕ = α\nσ\nθK −1\nµ1.2 = f (cid:3)(x0)β + k\nthe n-dimensional identity matrix.\n\nz(z−F β), α(cid:3)\n\nα(cid:3)\n\n(cid:1)\n\nθ (z − F β), K1.2 = kθ(0) − k\n\nz = 1(cid:3)\n\nn+1\n\nK −1\n\nθ kθ\nθK −1\n\n(cid:1)\n\n9.2.2 Bayesian Analysis\n\nThe Bayesian model speciﬁcation requires prior distributions for all the\nunknown parameters. We shall assume prior independence so that the joint\nprior distribution\n\nπ(η) = π(β, σ2, θ, α) = π(β)π(σ2)π(θ)π(α),\n\nso that the posterior distribution is proportional to\n\nf (z|η)π(η) = f (z|β, σ2, θ, α)π(β)π(σ2)π(θ)π(α).\nLet the prior distribution on β and σ2 be Nq (β0, Σ0) and IG(α0, β0),\nrespectively. We will use the common notation for an inverse-gamma dis-\ntribution, so that if X ∼ IG(α, β) then the density is given by\n\nfX (x|α, β) =\n\nexp(−β−1/x)\nΓ(α)βαxα+1 ,\nwhere α, β > 0. Then the posterior distribution π(η|z) is proportional to\nΦ (ϕ) |Kθ|− 1\n\n2 π(β)π(θ)π(α),\n\nσ2|ασ2, βσ2\n\nx ∈ R+,\n\n(cid:6)\n\n(cid:7)\n\n(9.6)\n\nIG\nwhere ασ2 = n\n\n2 + α0 and\n\nβσ2 =\n\n(z − F β)(cid:3)K −1\n\n2β0\nθ (z − F β)β0 + 2\nFurthermore, full conditional distributions are given by\nπ(β|z, σ2, θ, α) ∝ Nq\n(cid:3)\n\nµβ, Σβ\n(cid:2)\n\n(cid:2)\n\n(cid:2)\n\n(cid:3)\n\n.\n\nΦ (ϕ) ,\n\nˆβ + Σ−1\n\n0 β0\n\n, Σβ =\n\nF (cid:1)K\n\n−1\nθ F\n\nσ2 + Σ−1\n\n0\n\nwhere µβ = Σβ\nˆβ",
    "chunk_order_index": 96,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-e7b727f94b23ab01e00baafeee041a85": {
    "tokens": 1200,
    "content": "π(β|z, σ2, θ, α) ∝ Nq\n(cid:3)\n\nµβ, Σβ\n(cid:2)\n\n(cid:2)\n\n(cid:2)\n\n(cid:3)\n\n.\n\nΦ (ϕ) ,\n\nˆβ + Σ−1\n\n0 β0\n\n, Σβ =\n\nF (cid:1)K\n\n−1\nθ F\n\nσ2 + Σ−1\n\n0\n\nwhere µβ = Σβ\nˆβ = (F\n\nK −1\n\n(cid:1)\n\n−1\nF (cid:1)K\nθ F\nσ2\nK −1\nθ\n\n(cid:1)\n\nθ F )−1F\n\nz,\nπ(σ2|z, β, θ, α) ∝ IG (ασ2, βσ2 ) Φ (ϕ) .\nπ(θ|z, β, σ2, α) ∝ |Kθ|− 1\n\n2 exp\n\n(cid:4)\n\n− 1\n2σ2 (z − F β)(cid:3)K −1\n\nθ (z − F β)\n\n(cid:3)−1\n\n(9.7)\n\n, and\n\n(9.8)\n\n(cid:5)\n\n\fSKEW-GAUSSIAN PROCESSES\n\nπ(α|z, β, σ2, θ) ∝ Φ (ϕ) π(α).\n\n×Φ (ϕ) π(θ).\n\n167\n\n(9.9)\n\n(9.10)\n\nWe can modify the prior distribution of α using mixture distributions by\n\nadding additional hyperpriors taking\n\nπ(α) = π(α|γ, p)π(γ|p)π(p).\n\nThe conditional prior of α is π(α|γ, p) = π(α|γ) = 0 if γ = 0 and equal to\nN (0, σ2\n0)Φ (ϕ), otherwise. Further, we assume γ|p ∼ Ber(p), p ∼ Beta(α0, α0)\nso E(p) = 1\n2 . We will use Ber(p) to denote the Bernoulli distribution with\nparameter p and Beta(α, β) the Beta distribution with parameter α and\nβ. Hence, the marginal prior distribution for α is\n\np(α|p) = (1 − p) I(α = 0) + p N (0, σ2\n\n0),\n\nwhere I(α = 0) denotes the indicator function, and hence it is a mixture\ndistribution. Therefore this model includes a Gaussian process as a special\ncase and (1−p) gives us the probability that the data is generated from this\nGaussian process. In this way the prediction will be made using a mixture\nof Gaussian and skew-Gaussian processes.\n\nThe full conditional distributions of α, γ, p are as follows, and the other\n\nfull conditional distributions are exactly the same as in (9.7)-(9.9).\n\nπ(α|z, γ, p, β, σ2, θ) ∝ π(α|γ)f (z|η),\n\nπ(γ|z, α, p, β, σ2, θ) ∝ π(α|γ)π(γ|p) ∝ Ber\n(cid:10)\n\n(cid:8)\n\n(cid:9)\n\nwhere a = 1 − p and b = (p/\n\n2πσ2\n\n0)exp\n\n−α2/(2σ2\n0)\n\n.\n\nπ(p|z, γ, α, β, σ2, θ) ∝ π(γ|p)π(p)\n\n(cid:4)\n\n(cid:5)\n\na\na + b\n\n(9.11)\n\n,\n\n(9.12)\n\nNote η contains all parameters which are η = (β(cid:3)\n, σ2, θ(cid:3)\nBayesian predictive distribution is given by f (z(x0)|z) ∝\nπ(η|z)dη.\n\n∝ Beta(α0 + γ, α0 + 1 − γ).\n\n(9.13)\n, α)(cid:3). Finally the\n(cid:11)\nη f (z(x0)|η, z)\n\n9.2.3 Computational Strategy\n\nThe posterior distribution is in a complicated form so we will use a Markov\nchain Monte Carlo (MCMC) technique (Gilks et al. 1996) to generate sam-\nples from the posterior distribution.\n\nTo generate samples from the posterior distribution π(η|z) where η =\n(β(cid:3)\n, σ2, θ(cid:3)\n, α)(cid:3) we will exploit the full conditional distributions, as usually\ndone in Gibbs sampling (Gelfand and Smith 1990). Since all the ﬁve full\nconditional distributions except π(θ|z, β, σ2, α) can be written as π(·) ∝\nψ(·)Φ(·), where ψ(·) is a density that can be sampled and Φ(·) is uniformly\n\n\f168\n\nANALYZING SPATIAL DATA USING SKEW-GAUSSIAN PROCESSES\n\nbounded, the probability of a move in the Metropolis-Hastings algorithm\nrequires only the computation of the Φ(·) function and is given by\n\nα(x, y) = min\n\n, 1\n\n.\n\n(9.14)\n\n(cid:4)\n\n(cid:5)\n\nΦ(y)\nΦ(x)\n\nThis is an eﬃcient solution when available (Chib and Greenberg 1995). The\nprobability of a move for θ is\n(cid:12)\n(cid:6)\n\n(cid:13)\n\n|Ky|",
    "chunk_order_index": 97,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-aa21fd4d085ed1e6ae1b906bf3fb2f9c": {
    "tokens": 1200,
    "content": "ropolis-Hastings algorithm\nrequires only the computation of the Φ(·) function and is given by\n\nα(x, y) = min\n\n, 1\n\n.\n\n(9.14)\n\n(cid:4)\n\n(cid:5)\n\nΦ(y)\nΦ(x)\n\nThis is an eﬃcient solution when available (Chib and Greenberg 1995). The\nprobability of a move for θ is\n(cid:12)\n(cid:6)\n\n(cid:13)\n\n|Ky|− 1\n|Kx|− 1\n\n2 exp\n\n2 exp\n\n(cid:6)\n\n− 1\n− 1\n\n2σ2 (z − F β)(cid:3)K −1\n2σ2 (z − F β)(cid:3)K −1\n\n(cid:7)\ny (z − F β)\n(cid:7)\nx (z − F β)\n\nΦ (ϕy)\nΦ (ϕx)\n\n, 1\n\n,\n\nα(x, y) = min\n\nα(cid:3)\n\nwhere ϕx (ϕy) is the same as ϕ having x (y) as an argument which is\nz(z − F β). To sample from the conditional distribution,\ndeﬁned as ϕ = α\nσ\nf (z(x0)|z, η), we introduce a truncated normal distribution (Robert, 1995).\nFinally we consider a generated value of f (z(x0)|z, η) as a sample from a\npredictive distribution by the composition method (Gelfand 1996, Tanner\n1996).\n\nThe techniques for mixture prior are similar to the previously discussed\nmethods except we need additional steps to generate α and the corre-\nsponding hyperparameters. To generate α, γ, p from the full conditional\ndistributions, we ﬁrst generate γ. If γ equals 0 then α equals 0 (likelihood\nf (z|η) is a Gaussian process), and we generate samples from π(α)Φ (ϕ)\notherwise. Sampling from γ, p is direct since we know the exact conditional\ndistributions.\n\nAnother possible way to generate samples from a predictive distribution\nis a Monte Carlo integration (Gelfand 1996, Tanner 1996, De Oliveira et\nal. 1997).\n\n9.3 Real Data Illustration: Spatial Potential Data Prediction\n\nThe dataset analyzed in this section is ﬂow potential data for the North\nBurbank Field in California. The ﬂow potential is a very important fac-\ntor in determining ﬂow velocity through porous media in the reservoir.\nFor instance, in a reservoir with high ﬂow potential, the ﬂuid velocity (of\noil/water/gas) will be fast, compared to other low ﬂow potential reservoirs.\nUsually petroleum engineers want to produce oil in the reservoir as fast as\npossible because they want to obtain maximum proﬁts through oil produc-\ntion from the reservoir, keeping the reservoir pressure. The original data\nhave been modiﬁed slightly (for conﬁdentiality reasons) by multiplying by,\nand adding, unspeciﬁed constants.\n\nA graphical description of the locations of the ﬂow potential data is\nshown in Fig. 9.1, with a histogram of the response values, ignoring posi-\ntion, given in Fig. 9.2. It looks like the dataset is generated from a skewed\ndistribution, so use of the skew-Gaussian process seems appropriate here.\n\n\fREAL DATA ILLUSTRATION: SPATIAL POTENTIAL DATA PREDICTION 169\n\ny\n\n0\n1\n\n8\n\n6\n\n4\n\n2\n\n0\n\n10\n\n10.2\n\n10.4\n\n10.3\n\n10.2\n\n10.7\n\n10.1\n\n10\n\n10.2\n\n10.4\n\n10.2\n\n10.1\n\n10.2\n\n10.2\n\n10\n\n10.4\n\n10.1\n\n10.4\n\n10.3\n\n10.3\n\n10\n\n11.5\n\n10.4\n\n12.2\n\n11.5\n\n11.5\n\n10.1\n\n10.1\n\n10.8\n\n11\n\n11.6\n\n12\n\n11.2\n\n10.4\n\n12.3\n\n10.3\n\n11.4\n\n11.6\n\n11.5\n\n11.3\n\n11\n\n10.8\n\n11.3\n\n12.8\n\n11.5\n\n10.6\n\n11\n\n10.2\n\n5\n\n)\nx\n(\nf\n\n0\n.\n1\n\n8\n.\n0\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n0\n.\n0\n\n1\n\nx\n\n0\n\n1\n\n5\n\n10.0\n\n10.5\n\n11.0\n\n11.5\n\n12.0\n\n12.5\n\n13.0\n\nPotential Data for the North Burbank Field\n\nFigure 9.1 The 48 observed locations of\nthe ﬂow potential data, including the\nresponse values.\n\nFigure 9.2 A histogram of the observed\nresponses.\n\nAnother possible family relates to lognormal kriging, which was commented\non earlier in Section 9.2. However, we ﬁnd that the log transformed data do\nnot follow a normal distribution, so it is not a good idea to use lognormal\nkriging here. In the absence of regression parameter information the mean\nfunction is assumed to be constant, so q = 1. In our practical usage, we\nadopt the general exponential isotropic correlation function (Yaglom 1987).\nIn the following we use the second parameterization in (9.3) since it eases\nthe assignment of non-informative priors",
    "chunk_order_index": 98,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-7bb8bcf3cc321c4820a19bb6fc317e8d": {
    "tokens": 1200,
    "content": "do\nnot follow a normal distribution, so it is not a good idea to use lognormal\nkriging here. In the absence of regression parameter information the mean\nfunction is assumed to be constant, so q = 1. In our practical usage, we\nadopt the general exponential isotropic correlation function (Yaglom 1987).\nIn the following we use the second parameterization in (9.3) since it eases\nthe assignment of non-informative priors and the MCMC methods. This\nis a ﬂexible family containing the exponential (θ2 = 1) and the squared\nexponential (θ2 = 2) correlation functions as two of its members. It is easy\nto compute and is parameterized by physically interpretable quantities. For\nthis family θ1 controls the range of correlation, viewed as the correlation\nbetween two observations and θ2 controls the smoothness of the random\nﬁeld. Another ﬂexible family is the Mat´ern class of correlation functions\nused by Handcock and Wallis (1993) and Handcock and Stein (1994).\n\nThe ﬁrst priors (SGP 1) are as follows. We assume β ∼ N (¯z, 100),\nσ2 ∼ IG(0.05, 0.05), θ1 ∼ U (0, 1), θ2 ∼ U (0, 2], and α ∼ N (0, 100) which\nare all independent. Hence this model also contains a Gaussian process as a\nspecial case because the values of α can be 0. Since there is no information\non θ1 and θ2 we assume uniform priors. Applying the MCMC method of\nSection 9.2.3, we get full conditional distributions. We summarize medians\nof full conditionals in Table 9.1.\n\nAfter getting full conditionals, we obtain values of each predictive den-\nsity function for Z(x0) for the locations x0 = (2.5, 2.5), (14.5, 5.5), (14, 9),\n(14, 2), (6, 9.5) and (7.8, 3.6) covering diﬀerent sections of the region of in-\n\n\f170\n\nANALYZING SPATIAL DATA USING SKEW-GAUSSIAN PROCESSES\n\nTable 9.1 Medians of full conditionals at (7.8,3.6) under SGP 1\n\nParameters median mean\n\nβ\n1/σ2\nα\nθ1\nθ2\n\n10.32\n0.03\n1.07\n0.98\n0.33\n\n10.40\n0.03\n1.21\n0.97\n0.34\n\n7\n\n16\n\n36\n\n22\n\n30\n\n23\n\n31\n\ny\n\n0\n1\n\n8\n\n6\n\n4\n\n2\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n8\n\n14\n\n37\n\n46\n\n5\n\n9\n\n12\n\n1\n\n0\n\n11\n\n13\n\n15\n\n21\n\n28\n\n17\n\n18\n\n19\n\n20\n\n24\n\n25\n\n29\n\n26\n\n27\n\n32\n\n33\n\n34\n\n35\n\n38\n\n47\n\n39\n\n42\n\n0\n\n1\n\nx\n\n40\n\n41\n\n43\n\n44\n\n45\n\n48\n\n1\n\n5\n\nFigure 9.3 Predicted positions with numbering 48 observed locations.\n\nterest. This is shown at Fig. 9.3. The predicted positions (marked with\n“•”) with numbering 48 locations are plotted at Fig 9.3. We ordered 48\nlocations in an arbitrary manner resulting in no eﬀect on the analysis.\n\nThe second priors (SGP 2) are only diﬀerent at generating the values\nof α. That is, P ∼ Beta(1, 1), γ|p ∼ Ber(p) and α|p ∼ (1 − p)I(α =\n0) + p N (0, 100). Notice that the mean of P is 1\n2 , which means a priori\nskewness or not is equally probable. Using similar generating technique at\nthe ﬁrst priors, we get full conditional distributions. If p is close to 1, then\nthe distribution of data is strictly skewed. If p is close to 0, then it is almost\nsymmetric. We also get predictive distributions for the same locations as\nSGP 1 and the results give us indistinguishable predictive inference. Table\n9.2 summarizes prediction intervals and medians for SGP 1 model. We used\n\n\fDISCUSSION\n\n171\n\nx0 = (2.5, 2.5)\n\nx0 = (14.5, 5.5)\n\nx0 = (14, 9)\n\n8\n\n10\n\n12\n\n14\n\nz(x0)\n\nx0 = (14, 2)\n\n)\n)\n0\nx\n(\nz\n(\nf\n\n)\n)\n0\nx\n(\nz\n(\nf\n\n0\n.\n1\n\n8\n.\n0\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n0\n.\n0\n\n0\n.\n1\n\n8\n.\n0\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n0\n0\n\n.\n\n)\n)\n0\nx\n(\nz\n(\nf\n\n)\n)\n0\nx\n(\nz\n(\nf\n\n0\n.\n1\n\n8\n.\n0\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n0\n.\n0\n\n0\n.\n1\n\n8\n.",
    "chunk_order_index": 99,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-bd7d84cf2b9edceb72bfa3ce90ea3dfa": {
    "tokens": 1200,
    "content": ".\n0\n\n0\n.\n0\n\n0\n.\n1\n\n8\n.\n0\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n0\n0\n\n.\n\n)\n)\n0\nx\n(\nz\n(\nf\n\n)\n)\n0\nx\n(\nz\n(\nf\n\n0\n.\n1\n\n8\n.\n0\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n0\n.\n0\n\n0\n.\n1\n\n8\n.\n0\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n0\n0\n\n.\n\n8\n\n10\n\n12\n\n14\n\nz(x0)\n\nx0 = (6, 9.5)\n\n8\n\n10\n\n12\n\n14\n\nz(x0)\n\nx0 = (7.8, 3.6)\n\n)\n)\n0\nx\n(\nz\n(\nf\n\n)\n)\n0\nx\n(\nz\n(\nf\n\n0\n.\n1\n\n8\n.\n0\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n0\n.\n0\n\n0\n.\n1\n\n8\n.\n0\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n0\n0\n\n.\n\n8\n\n10\n\n12\n\n14\n\n8\n\n10\n\n12\n\n14\n\n8\n\n10\n\n12\n\n14\n\nz(x0)\n\nz(x0)\n\nz(x0)\n\nFigure 9.4 Prediction densities for SGP 1.\n\nthe 95% central quantile intervals since the predictive densities are pretty\nsymmetric. Figure 9.5 shows the predicted map obtained by computing\nˆZ(s0) = median of (Z(s0)|Z) on every s0 of a 40 × 40 grid. As a measure of\npredictive uncertainty at any location s0 we use MAD (Median Absolute\nDeviation) which is equal to SIQR (Semi Inter Quartile Range) and .6745\nσ for a normal distribution. Figure 9.6 shows the map of this uncertainty\nmeasure.\n\n9.4 Discussion\n\nWe used the skew-Gaussian process for the spatial prediction of ﬂow po-\ntential data. From the ﬁnal predicted map given at 9.5, we can ﬁnd where\nthe highest ﬂow potential is located. This is an important factor in deter-\nmining ﬂow velocity through porous media in the reservoir. It performed\nadequately and can be used to model skewed data for which lognormal\nkriging cannot be used. So our method is a generalization of lognormal\n\n\f172\n\nANALYZING SPATIAL DATA USING SKEW-GAUSSIAN PROCESSES\n\nZ\n\n3\n1\n\n5\n.\n2\n1\n\n2\n1\n\n5\n.\n1\n1\n\n1\n1\n\n5\n.\n0\n1\n\n0\n1\n\n10\n\n8\n\n6\n\nY\n\n4\n\n2\n\n5\n\n10\n\nX\n\n15\n\nFigure 9.5 Predicted map.\n\nZ\n\n6\n.\n0\n\n5\n.\n0\n\n4\n.\n0\n\n3\n.\n0\n\n2\n.\n0\n\n1\n.\n0\n\n10\n\n8\n\n6\n\nY\n\n4\n\n15\n\n2\n\n5\n\n10\n\nX\n\nFigure 9.6 Uncertainty map related to the predicted map.\n\n\fDISCUSSION\n\n173\n\nTable 9.2 95% Prediction intervals and medians.\n\nLocation\n\nP.I.\n\nmedian\n\nSGP 1\n\n(2.5, 2.5)\n(14.5, 5.5)\n(14, 9)\n(14, 2)\n(6, 9.5)\n(7.8, 3.6)\n\n(9.67, 11.64)\n(9.18, 11.22)\n(9.23, 11.26)\n(10.33, 12.30)\n(9.16, 11.25)\n(10.95, 12.66)\n\n10.65\n10.18\n10.23\n11.32\n10.16\n11.83\n\nkriging in some sense. Furthermore it extends the results of usual Gaussian\nrandom ﬁelds which are a particular case of it. It can also test for presence\nof skewness in the data.\n\nIn Section 9.2, we chose one shape (skewness) parameter α and one\nscale parameter σ. Instead of those, we can consider a hierarchical model\nwith shrinkage eﬀect for the shape parameter vector and a diagonal matrix\nof scale parameters. To extend this idea the shape parameter vector and\nthe diagonal matrix of scale parameter can be regarded as a function of\ndistance, which is assumed at usual second order stationary condition.\n\nAcknowledgments\n\nWe thank H.J. Newton for helping us to write the MCMC programs.\n\n\f\fCHAPTER 10\n\nAccounting for Absorption Lines in\nImages Obtained with the Chandra\nX-ray Observatory\n\nD.A. van Dyk\n\nC.M. Hans\n\n10.1 Statistical Challenges of the Chandra X-ray Observatory\n\nIn recent years, new telescopes have dramatically improved the ability of\nastrophysicists to image X-ray sources. The Chandra X-ray Observatory,\nfor example, was launched by the space shuttle Columbia in July 1999 and\nprovides a high resolution tool that produces images at least thirty times\nsharper than any previous X-ray telescope. The X-rays themselves are pro-\nduced by matter that is heated to millions of degrees, e.g., by high magnetic\nﬁelds, extreme gravity, or explosive forces. Thus, the images provided by\nsuch high resolution instruments help astrophysicists to understand the hot\nand turbulent regions of the universe.\n\nUnlock",
    "chunk_order_index": 100,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-86242d558335115c9b572ed3d92f332a": {
    "tokens": 1200,
    "content": "the space shuttle Columbia in July 1999 and\nprovides a high resolution tool that produces images at least thirty times\nsharper than any previous X-ray telescope. The X-rays themselves are pro-\nduced by matter that is heated to millions of degrees, e.g., by high magnetic\nﬁelds, extreme gravity, or explosive forces. Thus, the images provided by\nsuch high resolution instruments help astrophysicists to understand the hot\nand turbulent regions of the universe.\n\nUnlocking the information in these images, however, requires subtle anal-\nysis. The detectors aboard Chandra collect data on each X-ray photon that\narrives at the detector. Speciﬁcally, the (two-dimensional) sky coordinates,\nthe energy, and the time of arrival of each photon are recorded. Because\nof instrumental constraints each of these four variables is discretized; the\nhigh resolution of Chandra means that this discretization is much ﬁner than\nwhat was previously available. For example, one of the instruments aboard\nChandra has 4096 × 4096 spatial pixels and 1024 energy bins. Because of\nthe discrete nature of the data, it can be compiled into a four-way table\nof photon counts. We refer to this four dimensional data as the image; it\nis a moving ‘colored’ picture. (Because of the high energy of X-rays the\n‘colors’ are not in the visible spectrum.) Spectral analysis models the one-\nway marginal table of the energy data; spatial analysis models the two-way\nmarginal table of sky coordinates; and timing analysis models the one-\nway marginal table of arrival times. As we shall see, however, because of\nsubtleties in the instrumentation and the data itself, spatial and spectral\nanalysis cannot be fully separated and both are crucial for a full under-\nstanding of the image; in other settings, similar concerns arise for spatial\nand temporal analysis (see Chapter 12).\n\n\f176\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nThe data gathered by Chandra, although high-resolution, present a num-\nber of statistical challenges to the astronomer. For spatial data, the images\nare convolved with instrument characteristics which blur the image. For ex-\nample, the point spread function characterizes the probability distribution\nof a photon’s recorded pixel location relative to its actual sky coordinates.\nThe situation is further complicated because the shape of the scatter dis-\ntribution varies across the detector; it is symmetric and relatively tight in\nthe center and becomes more asymmetric, irregular, and diﬀuse towards\nthe edge. Moreover, the scatter distribution can vary with the energy of\nthe incoming photon. Like the sky coordinates the energy of a photon is\nsubject to “blurring”; there is a distribution of potential recorded energies\ngiven the actual energy of a particular photon. Thus, we have three di-\nmensional blurring of the image. Given the sky coordinates and energy of a\nphoton, there is a distribution of the recorded sky coordinates and recorded\nenergy of the photon. Since there are, for example, 4096 × 4096 pixels on\nthe detector and 1024 energy bins, the resulting blurring matrix can have\nover 2.9 × 1020 cells. Clearly some simpliﬁcation is required. For spectral\nanalysis using a small region of the detector, the blurring of energies is\nmore-or-less constant, which results in a reasonably sized (1024 × 1024)\nmatrix. Thus, utilizing sparse matrix techniques results in eﬃcient compu-\ntation for marginal spectral analysis. Spatial analysis often involves only a\nsubset of the pixels, reducing the dimension of the problem. Also the blur-\nring matrix can be taken to be constant across a large number of pixels and\nenergy bins. Thus, we might divide the energy bins into 4 groups and the\npixels into 16 groups and assume the shape of the energy cross sky coor-\ndinate scatter is constant in each of the resulting 64 cells. Such techniques\naim at computational eﬃciency while hoping the compromise in precision\nis minor. A careful analysis of this trade oﬀ has yet to be tackled.\n\nAnother complication for image analysis involves the absorption of pho-\ntons and the so-called eﬀective area of the telescope. Depending on the en-\nergy of a photon, it has a certain probability of being absorbed, for example\nby the inter-stellar media between the source and the detector. Eﬀective\narea is an instrumental eﬀect, but has a similar eﬀect on the data—the\nprobability that a photon is recorded by the detector depends on its en-\nergy. Because the spectrum can vary across the source, the rate of this\nstochastic censoring also varies and can distort the image. Again, this em-\nphasizes that a careful analysis of the image must involve spectral analysis.\nIn this paper, we take up the task of modeling photon absorption—with\nthe understanding that it has direct implications for spatial analysis. In\nparticular, we introduce new models that aim to account for absorption\nlines in spectra. An absorption line is a narrow range of energies where a\nrelatively high proportion of photons are absorbed. Because these lines are\ncaused by an abundance of a particular element near the surface of the\n\n\fSTATISTICAL CHALLENGES OF THE CHANDRA X-RAY OBSERVATORY 177\n\nsource, it is possible for the intensity of an absorption line to vary across\nthe source, thus distorting the image.\n\nThe data are also degraded by the presence of background counts, X-ray\nphotons which arrive at the detector but do not correspond to the source\nof interest. In spectral analysis, a second observation that consists only of\nbackground counts",
    "chunk_order_index": 101,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-30a06613c57a42544cd24f31fbfd8825": {
    "tokens": 1200,
    "content": "near the surface of the\n\n\fSTATISTICAL CHALLENGES OF THE CHANDRA X-RAY OBSERVATORY 177\n\nsource, it is possible for the intensity of an absorption line to vary across\nthe source, thus distorting the image.\n\nThe data are also degraded by the presence of background counts, X-ray\nphotons which arrive at the detector but do not correspond to the source\nof interest. In spectral analysis, a second observation that consists only of\nbackground counts is compared with the primary observation. The back-\nground observation is obtained by looking into an area of space near the\nsource but which contains no apparent X-ray sources. After adjusting for\nexposure time, in some analyses the background observation is subtracted\nfrom the source observation, and the result is analyzed as if it were a source\nobservation free of background. This procedure is clearly questionable, es-\npecially when the number of counts per bin is small. It often leads to the\nrather embarrassing problem of negative counts and can have unpredictable\nresults on statistical inference. A better strategy is to model the counts in\nthe two observations as independent Poisson random variables, one with\nonly a background intensity and the other with intensity equal to the sum\nof the background and source intensities (Loredo 1993, van Dyk et al. 2001).\nA ﬁnal degradation of the data is known as pile up and poses a par-\nticularly challenging statistical problem. Pile-up occurs in X-ray detectors\n(generally charged coupled devices, i.e., CCDs) when two or more pho-\ntons arrive at the same location in the detector (i.e., in an event detection\nisland, which consists of several pixels) during the same time bin. Such\ncoincident events are counted as a single higher energy event or lost alto-\ngether if the total energy goes above the on-board discriminators. Thus, for\nbright sources pile-up can seriously distort the count rate, the spectrum,\nand the image. Moreover accounting for pile up is inherently a task of joint\nspectral-spatial modeling. A diﬀuse extended source may have no appre-\nciable pile up because the count rate is low on any one area of the detector.\nA point source with the same marginal intensity, however, may be subject\nto severe pile up. Model based methods for handling pile up are discussed\nin Kang et al. (2002); see also Davis (2001).\n\nWe propose using model-based Bayesian methods to handle these com-\nplex imaging problems; other Bayesian approaches to image analysis ap-\npear, for example, in Chapters 6, 7, 8, 11 and 14 of this volume. Models\ncan be designed to handle not only the complexity of the data collection\nprocess (e.g., blurring, eﬀective area of the instrument, background contam-\nination, and pile up) but also the complex spatial and spectral structures\nof the sources themselves. For example, as discussed in Section 10.2, we\nare interested in clustering photons into spatial and spectral features of\nthe source. Because of their complexity, the models are in turn complex\nand require sophisticated computational methods for ﬁtting. A Bayesian\nperspective is ideally suited to such highly structured models in terms of\nboth inference and computation. For example, the high dimensional pa-\nrameter space and numerous nuisance parameters highlight the attraction\n\n\f178\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nof Bayesian marginal posterior distributions of parameters or groups of pa-\nrameters. Astrophysicists are often interested in testing for the presence of\na particular model feature. Many such tests, such as testing for the presence\nof an additional point source in an image, correspond to testing whether\na parameter is on the boundary of its space. It is well known that the\nlikelihood ratio and related tests fail in this setting. However, appropriate\nBayesian model ﬁtting and model checking procedures are readily available\n(e.g. Protassov et al. 2001).\n\nFrom a computational point of view, such tools as the EM algorithm\n(Dempster et al. 1977a), the Data Augmentation Algorithm (Tanner and\nWong 1987), the Gibbs sampler (e.g. Gelfand and Smith 1990, Smith and\nRoberts 1993), and other Markov chain Monte Carlo methods are ide-\nally suited to highly structured models of this sort; see van Dyk (2002).\nThe modular structure of these algorithms matches the hierarchical struc-\nture of our models. For example, the Gibbs sampler samples one set of\nmodel parameters from their conditional posterior distribution given all\nother model parameters. This allows us to ﬁt one component of the over-\nall model at a time, conditional on the others. Thus, a complex model\nﬁtting task is divided into a sequence of much easier tasks. This modu-\nlar structure also allows us to take advantage of well known algorithms\nthat exist for ﬁtting certain components of our model. For example, using\nthe EM algorithm to handle a blurring matrix and background contami-\nnation in Poisson image analysis is a well known (and often rediscovered)\ntechnique (Richardson 1972, Lucy 1974, Shepp and Vardi 1982, Lange and\nCarson 1984, Fessler and Hero 1994, Meng and van Dyk 1997). Even though\nthis standby image reconstruction algorithm is unable to handle the rich-\nness of our highly structured model, we utilize it and its stochastic gener-\nalization as a step in our mode ﬁnding and posterior sampling algorithms.\nDetailing how we (or how we expect to) handle all of the modeling,\ncomputational, and inferential",
    "chunk_order_index": 102,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-c3a078883ceffd30bede912723657ceb": {
    "tokens": 1200,
    "content": "1982, Lange and\nCarson 1984, Fessler and Hero 1994, Meng and van Dyk 1997). Even though\nthis standby image reconstruction algorithm is unable to handle the rich-\nness of our highly structured model, we utilize it and its stochastic gener-\nalization as a step in our mode ﬁnding and posterior sampling algorithms.\nDetailing how we (or how we expect to) handle all of the modeling,\ncomputational, and inferential aspects of image analysis of Chandra data\nis well beyond the scope of this chapter. Instead, we outline some of our\nmodels to give the reader a ﬂavor of our Bayesian analysis and highly\nstructured models. In some cases, the details can be found in one of several\nreferences; in other cases, methods are still being developed. To give the\nreader a ﬂavor of the statistical details that are involved, however, we go\ninto some depth in our description of absorption lines.\n\nThe remainder of this chapter is organized into four sections. In Sec-\ntion 10.2 we outline our marginal spatial and spectral models, paying par-\nticular attention to the model based clustering. We discuss absorption lines\nin Section 10.3, describing the science behind them, the models and compu-\ntational methods we propose, and a simulation study which illustrates some\nof the statistical diﬃculties involved. In Section 10.4, we incorporate ab-\nsorption lines into the spectral model discussed in Section 10.2 illustrating\nour methods with a data set. Concluding remarks appear in Section 10.5.\n\n\fMODELING THE IMAGE\n\n179\n\nFigure 10.1 This X-ray image of the Crab Nebula is one of the ﬁrst images sent\nback by Chandra. The Crab Nebula is one of the youngest and most energetic of\nabout 1000 known pulsars; in fact this supernova remnant produces energy at the\nrate of 100,000 suns. The image illustrates the extended irregular spatial structure\nthat is typical of Chandra images (The image was adaptively smoothed; image\ncredit: the National Aeronautics & Space Administration (NASA), the Chandra\nX-ray Center (CXC), and the Smithsonian Astrophysical Observatory (SAO)).\n\n10.2 Modeling the Image\n\n10.2.1 Model-Based Spatial Analysis\nWe begin by modeling the true source counts in each pixel, X = {Xi+, i ∈\nI}, as independent Poisson random variables,\n\nXi+ ∼ P oisson(Λi+) for i ∈ I,\n(10.1)\nwhere I is the set of pixels and the ‘+’ in the subscript indicates that we are\nsumming over the time and energy bins; in the remainder of Section 10.2.1\nwe suppress the ‘+’. Because the data are degraded by factors such as image\nblurring and background contamination as discussed in Section 10.1, X is\nnot observed. Thus, we discuss both the constraints on Λ that we impose\nto represent structure in the image and how we model data distortion. We\nbegin with Λ.\n\nTo motivate our parameterization of Λ we examine several Chandra im-\nages. Figure 10.1 illustrates an X-ray image of the Crab Nebula, the rem-\nnant of a supernova explosion that was observed on Earth in 1054 A.D; im-\n\n\f180\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nFigure 10.2 X-ray image of the Cat’s Eye Nebula (left) observed by Chandra,\nand a composite X-ray/optical observed by Chandra and the Hubble Space Tele-\nscope (HST) (right). The image on the left shows a bright central star, which\ncorresponds to a high density cluster of photons. The composite image on the\nright illustrates the relative locations of hotter and cooler regions of the planetary\nnebula. (The X-ray image is adaptively smoothed. The color composite of optical\nand X-ray images was made by Zoltan G. Levay (Space Telescope Science In-\nstitute). The optical images were taken by J.P. Harrington and K.J. Borkowski\n(University of Maryland) with HST. Image credits: NASA, University of Illinois\nat Urbana-Champaign, Chu et al. (2001), and HST).\n\nage brightness corresponds to X-ray intensity. At the center of the nebula\nis a rapidly spinning pulsar that emits a pulse of photons thirty times per\nsecond. The Crab Nebula is a very bright X-ray source and illustrates the\nextended irregular structure that is typical of X-ray images. The structure\nin the extended source can sometimes be predicted from optical or radio\nimages but often contains unique features. For example, the jet that ex-\ntends towards the lower left from the center of the nebula was ﬁrst observed\nby Chandra. Although model based methods are not required to identify\nsome of the important structures in the Crab Nebula, such methods have\nbroad application for analyzing weaker X-ray sources, understanding how\nthe energy spectrum varies across a source, and identifying weak features\nin the source.\n\nA second image appears in Figure 10.2 and illustrates X-ray (left panel)\nand optical (right panel) images of the Cat’s Eye Nebula. A bright central\n\n\fMODELING THE IMAGE\n\n181\n\nFigure 10.3 Centaurus A, a nearby galaxy, as observed by Chandra. The several\nfeatures of the galaxy – a super-massive black-hole, a jet emanating from the core\nand the point-like sources scattered about the image – have been clearly resolved\nfor the ﬁrst time due to the imaging resolution of",
    "chunk_order_index": 103,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-2c2c5df4c1bbe49373f9378cd5ce557f": {
    "tokens": 1200,
    "content": "(left panel)\nand optical (right panel) images of the Cat’s Eye Nebula. A bright central\n\n\fMODELING THE IMAGE\n\n181\n\nFigure 10.3 Centaurus A, a nearby galaxy, as observed by Chandra. The several\nfeatures of the galaxy – a super-massive black-hole, a jet emanating from the core\nand the point-like sources scattered about the image – have been clearly resolved\nfor the ﬁrst time due to the imaging resolution of Chandra and illustrate the\nvariety of photon clusters that might be present in a Chandra image. (The image\nis adaptively smoothed and exposure corrected; image credit: NASA, SAO, and\nKraft et al. (2001)).\n\nstar is apparent in the center of the multi-million-degree nebula. Again\nthe nebula exhibits extended irregular structure that is only partially pre-\ndictable from the optical image. A ﬁnal image appears in Figure 10.3, this\none of a nearby elliptical galaxy, Centaurus A. The image shows a bright\ncentral source, which is believed to include a super-massive black hole, a\njet emanating from the center, and numerous point-like X-ray sources all\nsurrounded by a diﬀuse hot gas.\n\nFigures 10.1-10.3 illustrate the wide variety of images that we hope to\nmodel. A useful model must both allow for the extended diﬀuse nebula with\nits irregular and unpredictable structure and include one or more highly\nconcentrated X-ray emitter (i.e., point sources). An important objective is\nto cluster photons into these various sources. To accomplish this, we model\nXi as a mixture of independent Poisson random variables. In particular,\n\nΛi = λES\n\ni +\n\nK(cid:1)\n\nk=1\n\nλPS\nk pik for i ∈ I,\n\n(10.2)\n\n\fi\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\n182\nwhere λES\nrepresents the expected count due to smooth irregular extended\nsource in pixel i, K is the number of point sources, λPS\nis the total expected\nk\ncount due to point source k, and pik is the proportion of point source k\nthat falls in pixel i. The added point sources might be modeled as Gaussian\ndistributions, in which case pik is a bivariate Gaussian integral. We can\neasily handle larger elliptical Gaussian point sources, or more irregular\npoint source models. Information as to the location and spread of the point\nsource is often forthcoming (e.g., from optical or radio observations) and\nthus informative prior distributions are often available for these parameters.\nA Markov Random Field (MRF) model can be used to describe the irreg-\nular extended sources represented by λES\nin (10.2) (and perhaps irregular\nadded point sources). Our MRF models each pixel’s log intensity as a Gaus-\nsian deviate centered at the mean of the log intensities of its neighboring\npixels. In particular,\n\ni\n\nlog(λES\n\ni ) ∼ Normal\n\n\n 1\nni\n\n\n\n(cid:1)\n\nj∈∂(i)\n\nlog(λES\n\nj ),\n\nυ\nni\n\n for i ∈ I,\n\n(10.3)\n\nwhere ∂(i) is the set of pixels neighboring pixel i, ni is the number of pixels\nin ∂(i), and υ is the user-speciﬁed between pixel variance. This speciﬁca-\ntion allows for ﬂexibility in deﬁning each pixel’s neighborhood, as well as\nspecifying the variance of the Gaussian density. In principle, the variance\nparameter can be ﬁt or can be allowed to vary across the detector ﬁeld, so\nas to give the capacity for sharp edges. The variances themselves can then\nbe modeled, perhaps via a common prior distribution with ﬁtted hyperpa-\nrameters, letting the data in eﬀect determine the values of the smoothing\nparameter. An alternative to the MRF is the multiscale method proposed\nby Kolaczyk (1999), which aims to provide wavelet like models for Pois-\nson data and has performed well in a variety of applications (Nowak and\nKolaczyk 2000); the methods described in Chapters 6 and 7 may also be\nhelpful in identifying regions of relative homogeneity in an extended source.\nWe turn now to models for the degraded observed data. As discussed\nin Section 10.1, the observed counts are blurred because of instrumental\neﬀects and contaminated by background counts. Thus, we modify (10.2)\nto model the observed count in pixel i, Yi, as independent Poisson random\nvariables,\n\n\n\n\n\nYi ∼ P oisson\n\n(cid:1)\n\n\n\nj∈I\n\nMijΛj + θB\n\ni\n\n for i ∈ I,\n\n(10.4)\n\nwhere Mij is the probability that a photon with actual sky coordinates\ncorresponding to pixel j is recorded in pixel i, Λj is given in (10.2), and\nθB\ni the expected counts in pixel i attributed to background contamination.\nThe blurring matrix (Mij) and generally the background vector (θB\ni ) are\nassumed known from calibration. As discussed in Section 10.1, the model\n\n\fMODELING THE IMAGE\n\n183\n\ngiven in (10.4) is well known and has been the subject of much study. What\nis new here are the constraints we put on the source model and the spectral\nmodels to which we now turn",
    "chunk_order_index": 104,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-5760fe3020de2a628042becb142c8443": {
    "tokens": 1200,
    "content": "expected counts in pixel i attributed to background contamination.\nThe blurring matrix (Mij) and generally the background vector (θB\ni ) are\nassumed known from calibration. As discussed in Section 10.1, the model\n\n\fMODELING THE IMAGE\n\n183\n\ngiven in (10.4) is well known and has been the subject of much study. What\nis new here are the constraints we put on the source model and the spectral\nmodels to which we now turn.\n\n10.2.2 Model-Based Spectral Analysis\n\nIn this section we brieﬂy outline a class of spectral models; more details of\nthe models and the algorithms used to ﬁt them can be found in van Dyk et\nal. (2001), Protassov et al. (2001), and Sourlas et al. (2002). The spectral\nmodel aims to describe the distribution of the photon energies emanat-\ning from a particular source. Generally speaking, the distribution consists\nof several clusters of photons including a smooth continuum term and a\nnumber of added emission lines, which are narrow ranges of energy with\nmore counts than would be expected from the continuum. The continuum\nis formed by radiation of heat from the hot center of stars to the cold space\nthat surrounds them, a process known as thermal Bremsstrahlung. The\nemission lines are due to particular ions in the source and the abundance\nof the extra emission indicates the abundance of the ion in the source.\nKnown spectral lines can tell us about the speed at which the source is\nmoving by examining the Doppler shift of the line location.\n\nStatistically, the models are designed to summarize the relative frequency\nof the energy of photons arriving at the detector and to separate the pho-\ntons into clusters corresponding to the continuum and emission lines. In-\ndependent Poisson distributions are more appropriate to model the counts\nthan the commonly used normal approximation (e.g., χ2 ﬁtting), espe-\ncially for a high resolution detector. We parameterize the intensity in bin\nj ∈ J = {1, . . . , J}, as a mixture of the continuum term and K emission\nlines,\n\nΛj = δjλC(θC, Ej) +\n\nK(cid:1)\n\nk=1\n\nλE\nk pjk, j ∈ J ,\n\n(10.5)\n\nwhere δj is the width of bin j, λC(θC, Ej) is the continuum term and is a\nfunction of the continuum parameter, θC, Ej is the mean energy in bin j,\nλE\nk is the expected counts from emission line k, and pjk is the proportion of\nemission line k that falls in bin j. (Here and in the rest of the chapter we re-\nfer to the spectral margin, although this is suppressed in the notation.) The\nsmooth continuum term generally is parameterized according to physical\nmodels with several free parameters. Many of these models are amenable\nto standard statistical techniques, e.g., log linear models. Occasionally, a\nless parametric ﬁt is desired, in which case a one dimensional Markov ran-\ndom ﬁeld can be applied. The emission lines are generally parameterized\nas Gaussian or t distributions.\n\nAs discussed in Section 10.1, the counts are degraded by background\ncontamination, instrument (i.e., the detector) response, and photon absorp-\n\n\f184\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\ntion. Instrument response is a characteristic of the detector that results in\na blurring of the photons, i.e., a photon that arrives in bin j has probability\nMlj of being detected in observed bin l ∈ L = {1, . . . , L}. The L × J ma-\ntrix {Mlj}, which may not be square, is determined by calibration of the\ndetector and presumed known. Because of these degradations, we model\nthe observed counts as independent Poisson variables with parameters\n\nΞl =\n\nJ(cid:1)\n\nj=1\n\nMljΛjdjα(θA, Ej) + θB\nl ,\n\nl ∈ L,\n\n(10.6)\n\nwhere α(θA, Ej) is the probability that a photon of energy Ej is not ab-\nsorbed, θB\nis the Poisson intensity of the background which is often known\nl\nfrom calibration in space, and dj is the known eﬀective area for photons\nwith energy Ej, with dj normalized so that maxj dj = 1. In the absorp-\ntion model α(θA, Ej) is typically taken to be a generalized linear model\nwith θA denoting the model parameter. The absorbed photons form one or\nmore clusters that are completely unobserved. An important special case\ninvolves so-called absorption lines, which are the topic of the remainder of\nthe chapter.\n\n10.3 Absorption Lines\n\n10.3.1 Scientiﬁc Background\n\nAbsorption lines are downward spikes in the spectral continuum, which\nrepresent wavelengths where photons from the continuum have been ab-\nsorbed by atoms of elements in the source. Because the speciﬁc energies\nat which photons are absorbed are unique to each element, examining ab-\nsorption lines of a source can help to determine its composition. In order\nto motivate the physical models we employ and the statistical models we\nformulate, we begin with some scientiﬁc background. Photons are emitted\nfrom the hot center of a source (e.g., a star) in a continuous spectrum, and\ndue to their high energy radiate toward the relatively colder region near the\n“surface” of the source (e.g., the corona of a star). In these cooler regions\nthe continuum",
    "chunk_order_index": 105,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-62549418b904f5e51b6ded96d6d39263": {
    "tokens": 1200,
    "content": "can help to determine its composition. In order\nto motivate the physical models we employ and the statistical models we\nformulate, we begin with some scientiﬁc background. Photons are emitted\nfrom the hot center of a source (e.g., a star) in a continuous spectrum, and\ndue to their high energy radiate toward the relatively colder region near the\n“surface” of the source (e.g., the corona of a star). In these cooler regions\nthe continuum photons are in a higher energy state than their surroundings\nand thus are readily absorbed by surrounding atoms to keep the energy of\nthe system in balance. When this occurs, the absorbing atom necessarily\nenters a higher, less stable, energy state. Any given atom, however, prefers\na lower, more stable energy conﬁguration, so with high likelihood the atom\nwill shed the excess energy and return to its original state.\n\nIf the energy of the absorbed photon is eventually released by the ab-\nsorbing atom, one may wonder why we observe a dip in the continuum. The\nanswer is in part due to two processes called collisional deexcitation and\nradiative deexcitation. In collisional deexcitation the excited atom collides\nwith another atom, and the “extra” energy due to the absorbed photon is\n\n\fABSORPTION LINES\n\n185\n\nconverted into kinetic energy. The previously excited atom is thus back to\nits original state, and we still observe a downward spike in the continuum.\nIn radiative deexcitation the atom simply emits a photon of energy equal\nto the absorbed photon. However, the chance that we observe this photon\nwith the detector is very small: there are many possible directions which the\nemitted photon can take, and the probability is minute that its path will\nbe along our line of observation. Therefore, even though the excited atoms\neventually return to lower energy states, we still observe an absorption line.\nAbsorption lines can be parameterized in terms of their location, width,\nand intensity. The location, µ, denotes the center of the absorption line and\nis of interest because the absorption wavelength (or equivalently, energy)\nindicates the absorbing element. Absorption lines generally have some pos-\nitive width, σ2, because they are “broadened” by several eﬀects. One of\nthese eﬀects, Doppler broadening, occurs because the velocity at which a\nphoton is moving when it is absorbed is a random variable, causing us to\nobserve a Doppler “shifted” absorption energy. This causes some photons\nto appear to be absorbed at a slightly higher energy and others at a slightly\nlower energy, hence the broadening of absorption lines. The third parameter\nis the intensity parameter, λA. Astronomers often refer to the absorption\nmechanism that produces a line with small λA as being “optically thin,”\nwhich means that the line does not absorb all of the continuum photons at\nits peak; an example appears in plot (a) of Figure 10.4. The intensity and\nwidth parameters together give an indication of the structure of the line,\nfrom which astronomers can learn about the relative concentration of the\nabsorbing element in the source.\n\n10.3.2 Statistical Models\n\nIn terms of the model speciﬁcation in Section 10.2.2, formulating an ab-\nsorption model requires us to specify the probability that a photon is not\nabsorbed as a function of energy, i.e., α(θA, Ei) in (10.6). Generally there\nmay be several types of absorption that act independently, e.g., absorption\nby the inter-stellar media over a broad energy range along with several\nrelatively narrow absorption features. Thus, we can specify α(θA, Ei) as a\nproduct,\n\nα(θA, Ei) =\n\nJ A(cid:6)\n\nj=1\n\nαj(θA\n\nj , Ei),\n\n(10.7)\n\nwhere J A is the number of independent absorption components.\n\nFor simplicity, we focus on the case when J A = 1 with the understanding\nthat we can repeatedly apply the methods we describe to handle multiple\ncomponents. This is a particularly useful exercise because of the modular\nstructure of our model and ﬁtting algorithms. For example, the Gibbs sam-\npler ﬁts the model one component at a time. Thus, a method for ﬁtting the\n\n\f186\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\n(a)\n\n(b)\n\n)\nd\ne\nb\nr\no\ns\nb\na\nT\nO\nN\n\n(\nr\n\nP\n\n8\n\n.\n\n0\n\n4\n\n.\n\n0\n\n0\n0\n\n.\n\n8\n\n.\n\n0\n\n4\n\n.\n\n0\n\n0\n0\n\n.\n\n0.6\n\n1.0\n\n1.4\n\n1.8\n\n0.6\n\n1.0\n\n1.4\n\n1.8\n\nEnergy in keV\n\nEnergy in keV\n\nFigure 10.4 Two examples of the physical ﬂexibility of α(Ej, θA). The vertical\naxis is the probability that a photon is not absorbed by the line, which is the\nprobability that a photon is observed.\n\nspectral models described in Section 10.2.2 without absorption lines (see\nvan Dyk et al. 2001) can be combined with the methods described here to\nﬁt the entire model, as we discuss below and illustrate in Section 10.4.\n\nThere are several models for absorption lines used by astrophysicists;\nsome lines are modeled with ﬂat edges on one side, and others are taken to\nhave a symmetric or even Gaussian shape. Here, we limit our attention",
    "chunk_order_index": 106,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-d596c0c5350a356ce69d9a92cc5ea7c8": {
    "tokens": 1200,
    "content": "in Section 10.2.2 without absorption lines (see\nvan Dyk et al. 2001) can be combined with the methods described here to\nﬁt the entire model, as we discuss below and illustrate in Section 10.4.\n\nThere are several models for absorption lines used by astrophysicists;\nsome lines are modeled with ﬂat edges on one side, and others are taken to\nhave a symmetric or even Gaussian shape. Here, we limit our attention to\na speciﬁc but important formulation of an absorption line; van Dyk et al.\n(2001) discuss models for absorption over a broad range of energy. Speciﬁ-\ncally, we consider the exponentiated Gaussian form described by Freeman\net al. (1999),\n\n(cid:7)\n\n(cid:8)\n\nα(θA, Ei) = exp\n\n−λA exp\n\n−(Ei − µ)2\n2σ2\n\n(cid:9)(cid:10)\n\n,\n\n(10.8)\n\nboth because it is accepted as a useful description of physical phenomena\nand because, as discussed is Section 10.3.3, it is computationally tractable;\nsee also Hans and van Dyk (2002). In this model, the absorption line pa-\nrameter is θA = (µ, σ2, λA), where µ is the location parameter, σ2 is the\nwidth parameter and λA is the intensity parameter. This parameterization\nis attractive for both physical and, as discussed below, statistical reasons.\nFrom a physical perspective, (10.8) provides a ﬂexible way to describe the\n\n \n\fABSORPTION LINES\n\n187\n\nabsorption line. The inner exponential quantity gives the line a somewhat\nGaussian shape, while the outer exponential and the intensity parameter\ncontrol the strength of the line. Figure 10.4 illustrates this ﬂexibility. Notice\nthat in plot (a), the absorption line maintains a Gaussian shape but never\nreaches α(θA, Ei) = 0, where all the photons from the continuum would\nbe absorbed. For this plot, µ = 1.25, σ2 = 0.002 and λA = 1.5. Plot (b)\nshows the outer limits of the line maintaining a Gaussian shape while all of\nthe photons from the continuum are absorbed over the central bins; here,\nµ = 1.25, σ2 = 0.002 and λA = 85.\n\nYl\n\n(10.9)\n\nWe specify the likelihood of the observed counts as\nindep.∼ P oisson(Ξl) for l ∈ L,\nwith Ξl given in (10.6). (Currently, it is common practice to account for\nabsorption lines by modeling Yl as independent Gaussian random variables\nwith mean Ξl, for example, via χ2 ﬁtting. Such models are inappropriate for\nhigh-resolution, low-count detectors.) To complete the speciﬁcation of the\nmodel, prior distributions must be assigned to the absorption line parame-\nters. When prior information is available either from previous observations\nor other scientiﬁc knowledge, we use parameterized independent prior dis-\ntributions on (σ2, µ, λA); in particular we use scaled inverse χ2, Gaussian,\nand gamma distributions respectively. Improper prior distributions should\nonly be used with great care; there is a possibility of an improper poste-\nrior distribution when we consider the more general model described in\nSection 10.2.2.\n\nData Augmentation. We can augment model (10.9) to a larger, only par-\ntially observed sample space, which simpliﬁes computation. The basic data\naugmentation is the idealized image that is undistorted by blurring, back-\nground contamination, or absorption,\n\nindep.∼ P oisson(Λi) for i ∈ I,\nwith Λi given in (10.5). To account for absorption, we introduce an inter-\nmediate data augmentation, the idealized image after absorption,\n\n(10.10)\n\nXi\n\nZi|Xi, θA indep.∼ Binomial\n\n(10.11)\nwhere α(θA, Ei) is the probability that a photon in not absorbed and is\ngiven in (10.8). Combining (10.10) with (10.11) and marginalizing over Xi\nyields\n\nfor i ∈ I,\n\n(cid:12)\n(cid:11)\nXi, α(θA, Ei)\n\nZi|θA indep.∼ P oisson[Λiα(θA, Ei)] for i ∈ I.\n(10.12)\nOrdinarily we treat both X = {Xi, i ∈ I} and Z = {Zi, i ∈ I} as missing\ndata, along with a number of other quantities; see van Dyk et al. (2001). For\nthe remainder of Section 10.3, however, we focus attention on absorption\nlines and treat Z as observed data and X as the unobserved idealized\n\n\f188\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nimage. In particular, we act as if there were no blurring of photon energies\nor background contamination and assume Λ = {Λi, i ∈ I} is speciﬁed with\nno unknown parameters. All of these simpliﬁcations are to focus attention\non absorption lines and will be relaxed in Section 10.4.\n\nA Generalized Linear Model. The model speciﬁed in (10.11) can be for-\nmulated as a generalized linear model (McCullagh and Nelder 1989) using\nthe link function, ηi = − log",
    "chunk_order_index": 107,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-d4b40ebf67503c34b3af5c111c40921c": {
    "tokens": 1200,
    "content": "and assume Λ = {Λi, i ∈ I} is speciﬁed with\nno unknown parameters. All of these simpliﬁcations are to focus attention\non absorption lines and will be relaxed in Section 10.4.\n\nA Generalized Linear Model. The model speciﬁed in (10.11) can be for-\nmulated as a generalized linear model (McCullagh and Nelder 1989) using\nthe link function, ηi = − log[− log α(θA, Ei)], where α is given in (10.8). In\nthis case,\n\nηi = − log\n\n(cid:14)\n\n(cid:13)\n\nΛA\n\n+\n\n(Ei − µ)2\n2σ2\n\n=\n\nλA\n\n− log\n\n1\n2σ2\n(10.13)\ni . We can identify the coeﬃcients of the generalized\n\n− µ\nσ2\n\nEi +\n\nE2\ni\n\n+\n\n+\n\nµ2\n2σ2\n\nis linear in Ei and E2\nlinear model with β = (β0, β1, β2)(cid:3), via the invertible transformation\n\n(cid:13)\n\n(cid:14)\n\n(cid:9)\n\n(cid:15)\n\n(cid:16)\n\n(cid:8)\n\n(cid:9)\n\n(cid:8)\n\nβ2 =\n\n1\n2σ2 ,\n\nβ1 = − µ\nσ2 ,\n\nβ0 = − log\n\n(cid:14)\n\n(cid:13)\n\nλA\n\n+\n\nµ2\n2σ2 .\n\n(10.14)\n\n10.3.3 Model Fitting\n\nOur goal is to base inference on summaries of the posterior distribution,\n(cid:17)\n\n(cid:17)\n\np(θA|Z) =\n\np(θA, X|Z)dX ∝\n\np(Z|θA, X)p(X)p(θA)dX,\n\n(10.15)\n\nwhere the factors under the ﬁnal integral are given in (10.11), (10.10),\nand the prior distribution of θA respectively. Because of the complexity of\n(10.15) we resort to iterative methods to summarize the posterior distribu-\ntion. Here we discuss both an EM algorithm that can be used to compute\nthe posterior mode and MCMC methods that can be used to obtain a sam-\nple from the posterior distribution. Both of these methods are based on\nthe data-augmentation scheme discussed in Section 10.3.2. In particular,\nboth computational tools take advantage of the fact that the two condi-\ntional distributions, p(X|Z, θA) and p(θA|Z, X), are well-known statistical\nmodels. Simple probability calculus shows that the ﬁrst is\n(cid:12)\n(cid:11)\nλi(1 − α(θA, Ei))\n\nXi|Zi, θA indep.∼ Zi + P oisson\n\n(10.16)\n\n.\n\nThe second is the posterior distribution under the generalized linear model\ndescribed in Section 10.3.2.\n\nEM Algorithm. The EM algorithm is a well-known iterative method for\ncomputing marginal posterior modes, such as the mode of p(θA|Z) as ex-\npressed in (10.15). Starting with some starting value θA\n(0), EM proceeds by\ncomputing\n\nθA\n(t+1) = argmaxθA E\n\n(cid:15)\n\n(cid:18)\n(cid:18)\n(cid:18)Z, θA\nlog p(θA|Z, X)\n(t)\n\n(cid:16)\n\nfor t = 1, 2, . . .\n\n(10.17)\n\n\fABSORPTION LINES\n\n189\n\nThis procedure is guaranteed to increase the log posterior at each iteration\nand takes a particularly simple form in this case. The expectation in (10.17)\ncan be written as\n\n(cid:18)\n(cid:18)\n(cid:18)Z, θA\nXi log[α(θA, Ei)] + (Zi − Xi) log[1 − α(θA, Ei)] + log p(θA)\n(t)\n\n(cid:1)\n\ni∈I\n\n(cid:19)\n\nE\n\n(cid:20)\n\n.\n\n(10.18)\nSince (10.18) is linear in X, we can simply replace the missing data by its\nexpectation under model (10.16) and update the parameter by ﬁtting the\ngeneralized linear model, e.g., via Newton-Raphson; see Hans (2001) for\ndetails.\n\nMCMC Methods. The posterior distribution in (10.15) can be summarized\nvia Monte Carlo by obtaining a sample from p(θA, X|Z) and discarding the\ndraws of X. We obtain a sample from the joint posterior distribution using\nthe Gibbs sampler, an iterative algorithm that constructs a Markov chain\nwhich under mild regularity conditions converges to the joint posterior\ndistribution (for convergence results see Roberts 1996).\n\nWe implement the following Gibbs sampler: given a starting value θA\n\n(0),\n\nwe iterate,\nSTEP1: Draw X(t+1) from p(X|Z, θA\nSTEP2: Draw θA\nFor suﬃciently large T0 we can consider {θA\n(t), X(t), t = T0, . . . , T } to be a\nsample from (10.15) and summarize the posterior via Monte Carlo integra-\ntion.\n\n(t+1) from p(θA|Z, X(t+1)).\n\n(t)),\n\nSTEP 1 in the Gibbs sampler can be easily accomplished according to\n(10.16). Although the probability distribution in STEP 2 is not of a standard\nform, we can use the Metropolis",
    "chunk_order_index": 108,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-7da6ecd94a8f43270272e76a44e77119": {
    "tokens": 1200,
    "content": "(t), X(t), t = T0, . . . , T } to be a\nsample from (10.15) and summarize the posterior via Monte Carlo integra-\ntion.\n\n(t+1) from p(θA|Z, X(t+1)).\n\n(t)),\n\nSTEP 1 in the Gibbs sampler can be easily accomplished according to\n(10.16). Although the probability distribution in STEP 2 is not of a standard\nform, we can use the Metropolis-Hastings algorithm within each iteration of\nthe Gibbs sampler to construct a Markov chain with stationary distribution\nas given in STEP 2. We construct the Metropolis-Hastings jumping distribu-\ntion using a wide-tailed approximation of the target density given in STEP 2.\nThe wide tails enable the sampler to jump across the parameter space, and\nif the approximation is good many proposals will be accepted. Our choice\nfor the jumping density is a multivariate location-scale t-distribution with\n4 degrees of freedom. We use the posterior mode of p(θA|Z, X) (e.g, as com-\nputed in the M-step of EM) and the corresponding second derivative matrix\nto construct the center and scale of the jumping distribution respectively.\nThus, the jumping distribution does not change within a single iteration of\nthe Gibbs sampler. Because the Metropolis-Hastings algorithm is computa-\ntionally quick once the jumping distribution has been computed, we iterate\nﬁve times within each iteration of the Gibbs sampler, using the ﬁnal draw\nas the draw for STEP 2 of the Gibbs sampler. This strategy has negligible\ncosts but potentially can improve the overall convergence properties of the\nMarkov chain.\n\n\f190\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nSimulated Data\n\nModel\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n..\n.\n..\n....\n..\n.\n.\n.\n.\n...\n..\n..\n.\n.\n.\n..\n.\n..\n.\n.\n.\n.\n..\n..\n..\n..\n.\n..\n.\n.\n.\n.\n.\n...\n...\n.\n....\n.\n.\n..\n.\n.\n.\n....\n.....\n.....\n.\n.\n.\n....\n..\n..\n.\n.\n.\n.\n.\n.\n..\n.\n........\n..........\n.\n.\n..\n.\n.........\n..\n...\n.............\n.......................\n.\n.\n......\n.\n.......\n..........\n.\n..\n...................\n..........................................................................................................................................\n.\n..............................\n....\n..................\n...................................................................................................................................................................................................................................................................................................................................................................................................\n..........\n.\n\nn\nb\n\ni\n\nr\ne\np\n\ns\nt\nn\nu\no\nc\n\n0\n0\n2\n\n0\n5\n1\n\n0\n0\n1\n\n0\n5\n\n0\n\nn\nb\n\ni\n\nr\ne\np\n\ns\nt\nn\nu\no\nc\n\nd\ne\nt\nc\ne\np\nx\ne\n\n0\n0\n1\n\n0\n8\n\n0\n6\n\n0\n4\n\n0\n2\n\n0\n\n2\n\n4\n\n6\n\n8\n\n1.0\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n2.0\n\nEnergy (keV)\n\nEnergy (keV)\n\nFigure 10.5 Data simulated with λA = 50. The plot on the right shows the expected\nnumber of counts per bin in the area of the absorption line.\n\n10.3.4 A Simulation-Based Example\n\nIn this section we investigate how the characteristics of the ﬁtted ab-\nsorption line are aﬀected by its actual parameters. We use a series of\nsimulated data sets, generated according to (10.5) over the energy range\n[0.63 keV, 8.85 keV] using a bin width of 0.01 keV, giving a total of 822 bins.\n1 E−θC\nThe continuum model was taken to be a power law, λC(θC, E) = θC\n2 ,\nwith the physically reasonable parameters θC\n2 = 2.23. We sim-\nulated ﬁve datasets with the same line location, µ = 1.5 keV, and width,\nσ2 = 0.0003, but diﬀering intensities, λA = 1, 5, 10, 25, and 50. The data\nset generated with λA = 50 is illustrated in Figure 10.5; the absorption\nline covers about ten bins. We used a ﬂat prior distribution on θA in all\nanalyses.\n\n1 = 80 and θC\n\nFor each analysis we ﬁrst ran the EM algorithm from ﬁve starting values\ndispersed about the parameter space to search for posterior modes. We\nthen used these modes to select starting values for three MCMC samples.\nWe begin with our analysis of the data set illustrated in Figure 10.5, gen-\nerated with λA = 50. We ﬁt the model to the data in two ways: ﬁrst we\nallowed all three parameters in θA to be ﬁt and second we ﬁt only µ and\nλA, ﬁxing σ2 at 0.0003. The convergent values of EM for all ﬁve starting\nvalues for both ﬁtting schemes appear in Table 10.1, which illustrates the\n\n \n \n \n \n \n\fABSORPTION LINES\n\n191\n\nRun\n\n(i)\n(ii)\n(iii)\n(iv)\n(v)\n\nFit µ, σ2, and λA\nσ2 × 104\n\nλA\n\n3.77\n3.77\n3.77\n3.77\n3.77\n\n26.09\n26.09\n26.09\n26.09\n26.09\n\n%(θ)\n\n29936.3\n29936.3\n29936.3\n29936.3\n29936",
    "chunk_order_index": 109,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-9ff140235d7091f8437011e05a7a7b52": {
    "tokens": 1200,
    "content": "191\n\nRun\n\n(i)\n(ii)\n(iii)\n(iv)\n(v)\n\nFit µ, σ2, and λA\nσ2 × 104\n\nλA\n\n3.77\n3.77\n3.77\n3.77\n3.77\n\n26.09\n26.09\n26.09\n26.09\n26.09\n\n%(θ)\n\n29936.3\n29936.3\n29936.3\n29936.3\n29936.3\n\nµ\n\n1.50\n1.50\n1.50\n1.50\n1.50\n\nFit only µ and λA\n%(θ)\nµ\n\nλA\n\n1.30\n1.97\n1.50\n2.50\n1.00\n\n0.23\n0.30\n52.09\n0.63\n0.15\n\n29651.5\n29650.6\n29950.2\n29654.1\n29650.5\n\nthe EM algorithm for various\n(0), λA\n\nstarting val-\nTable 10.1 Convergence of\nues with λA = 50 for the underlying model (µ(0), σ2\n(0)) chosen as:\n(i) (1.25, 5×10−4,45); (ii) (2.0,2.0×10−3,80); (iii) (1.46,2.5×10−4,25); (iv)\n(2.5,8.0×10−2,100) and (v) (1.0,5.0×10−5,10). The left side of the table shows\nconvergence for the model which ﬁts all three parameters, and the right side shows\nconvergence when σ2 is ﬁxed at 3×10−4. The reported log-likelihood, (cid:8)(θ), does\nnot include the normalizing constant.\n\nmulti-modal character of the posterior distribution. The natural Poisson\nvariability of the photon counts can lead to random dips in the continuum\nwhich are not due to an absorption line, but create modes in the posterior\ndistribution. Given our knowledge of the true model, the four small values\nof λA, and the value of the loglikelihood at each of these modes, it is evident\nthat there is one major mode due to the absorption line and four minor\nmodes that result from random ﬂuctuations in the continuum. In practice\nthese minor modes cause two diﬃculties. Computationally, MCMC sam-\nplers can get caught in a minor, relatively uninteresting mode. Thus, we\ngenerally recommend using the EM algorithm to ﬁrst identify interesting\nmodes and then construct MCMC starting values aiming to sample from\nthese modes; see also Gelman et al. (1995). Secondly, it can be diﬃcult to\ndistinguish actual absorption lines from chance Poisson ﬂuctuations in the\ncontinuum. The standard formulation of a formal hypothesis test involves a\nnull value (i.e., no absorption line) that is on the boundary of the parame-\nter space. Thus, the standard null distribution of the likelihood ratio test is\ninappropriate. In this case, we recommend using model checking techniques\nsuch as posterior predictive p-values to help distinguish between random\nﬂuctuations and weak lines; see e.g., Protassov et al. (2001).\n\nA sample from the posterior distribution was generated by running each\n(cid:21)\nof three MCMC chains for 2500 iterations. We discarded the initial 500\nˆR (Gelman and Rubin 1992) on the\ndraws of each chain and computed\nˆR\nremaining draws to determine convergence to stationarity. Values of\nclose to one signify that the several chains represent draws from the same\ndistribution; values for three estimands (µ, σ2 and log(λA)) are reported in\n\n(cid:21)\n\n\f192\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nmu\n\nsig2\n\nlog(intens)\n\n0\n0\n3\n\n0\n0\n2\n\n0\n0\n1\n\n0\n\n0\n0\n0\n4\n\n0\n0\n0\n2\n\n0\n\n8\n.\n0\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n0\n.\n0\n\n1.496\n\n1.500\n\n1.504\n\n0.0002\n\n0.0004\n\n0.0006\n\n2\n\n3\n\n4\n\n5\n\nmedian = 1.4998 \n 95% CI = [1.497 , 1.502]\n\nmedian = 3.7e-4 \n 95% CI = [2.5e-4 , 5.27e-4]\n\nmedian = 3.1516 \n 95% CI = [2.3246 , 4.3794]\n\nFigure 10.6 6000 draws from the posterior distribution of θA for the data gener-\nated with λA = 50; the median and 95% credible intervals are reported. On the\noriginal scale, the posterior median for the intensity parameter is 23.374 with\n95% CI = [10.223 , 79.794].\n\n(cid:21)\n\nˆR statistic and visual inspection of the chains indicate\nTable 10.2. The\ngood mixing. Figure 10.6 illustrates the marginal posterior distributions of\nµ, σ2, and log(λA) and reports their median and 95% credible intervals;\nthe true value of each is contained in its interval.\n\nFinally, we repeat the above analyses for the datasets generated with\nλA =",
    "chunk_order_index": 110,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-264218b2da5d4b121ab380c586bc4aeb": {
    "tokens": 1200,
    "content": "CI = [10.223 , 79.794].\n\n(cid:21)\n\nˆR statistic and visual inspection of the chains indicate\nTable 10.2. The\ngood mixing. Figure 10.6 illustrates the marginal posterior distributions of\nµ, σ2, and log(λA) and reports their median and 95% credible intervals;\nthe true value of each is contained in its interval.\n\nFinally, we repeat the above analyses for the datasets generated with\nλA = 25, 10, 5, and 1; see Table 10.2. Figure 10.7 shows that 95% credi-\nble intervals cover the true parameter value in all cases. We also notice a\nnegative association between the estimates of σ2 and λA; when σ2 is under-\nestimated, λA is overestimated and vice versa. In either case, the expected\nabsorption count is maintained.\n\n10.4 Spectral Models with Absorption Lines\n\n10.4.1 Combining Models and Algorithms\n\nIn this section we relax the model simpliﬁcations of Section 10.3.2, ﬁtting\nabsorption lines and the continuum jointly in the presence of background\ncontamination, absorption due to the inter-stellar media, and blurring of\nphoton energies. The idealized spectrum after absorption, Z, is treated as\none level in a hierarchical data augmentation scheme; the observed data,\n\n\fSPECTRAL MODELS WITH ABSORPTION LINES\n\n193\n\nmodel\n\nsummary\n\nµ\n\nσ2\n\nlog(λA)\n\nλA\n\nλA = 50\n\nλA = 25\n\nλA = 10\n\nλA = 5\n\nλA = 1\n\nmedian\nlower\nupper\n(cid:21)\nˆR\n\nmedian\nlower\nupper\n(cid:21)\nˆR\n\nmedian\nlower\nupper\n(cid:21)\nˆR\n\nmedian\nlower\nupper\n(cid:21)\nˆR\n\nmedian\nlower\nupper\n(cid:21)\nˆR\n\n1.4998\n1.497\n1.502\n\n1.0002\n\n1.5008\n1.499\n1.503\n\n1.0000\n\n1.4993\n1.498\n1.502\n\n1.0061\n\n1.4992\n1.497\n1.502\n\n1.0008\n\n1.5005\n1.494\n1.507\n\n1.0026\n\n3.7×10−4\n2.5×10−4\n5.27×10−4\n1.0000\n3.61×10−4\n2.53×10−4\n4.99×10−4\n1.0000\n2.54×10−4\n2.03×10−4\n3.89×10−4\n1.0000\n2.28×10−4\n1.58×10−4\n3.17×10−4\n1.0000\n3.46×10−4\n1.97×10−4\n6.22×10−4\n1.0024\n\n3.1516\n2.3246\n4.3794\n\n1.0003\n\n2.7186\n2.0737\n3.6074\n\n1.0054\n\n2.4543\n1.8867\n3.1804\n\n1.0000\n\n1.9280\n1.5022\n2.5070\n\n1.0007\n\n0.02317\n-0.3654\n0.3469\n\n23.374\n10.223\n79.794\n\n1.0023\n\n15.159\n7.954\n36.871\n\n1.0182\n\n11.639\n6.597\n24.056\n\n1.0001\n\n6.876\n4.492\n12.268\n\n1.0006\n\n1.023\n0.694\n1.415\n\n1.0006\n\n1.0007\n\nTable 10.2 Posterior summaries for data generated according to ﬁve simulation\nmodels where lower and upper relate to the lower and upper bounds of the 95%\nconﬁdence interval for the parameter.\n\nY , is modeled as in (10.9). Because of the modular structure of our compu-\ntational tools, it is not diﬃcult to compose posterior sampling and mode\nﬁnding algorithms in this more general setting. Using the notation of Sec-\ntion 10.3.2, the joint probability model factors as\n\np(X, Y, Z, θA, θ−A) = p(Y |Z, θ−A)p(Z|X, θA)p(X|θ−A)p(θ−A)p(θA),\n\n(10.19)\nwhere Y is the observed data, X is the ideal data, Z is the ideal data\nafter absorption, and θ−A are all model parameters not involved in the\nabsorption line. The ﬁrst factor on the right-hand side of (10.19) represents\nthe eﬀects of blurring, background, eﬀective area of the instrument, and any\nother absorption components in the model; the second factor represents the\n\n\f194\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nµ\n\nσ2\n\nlog(λA) - log(true value)\n\nV\ne\nk\n\n5\n0\n5\n.\n1\n\n0\n0\n5\n.\n1\n\n5\n9\n4\n.\n1\n\n2\n^\nV\ne\nk\n\n7\n0\n0\n0\n.\n0\n\n4\n0\n0\n0\n.\n0\n\n1\n0",
    "chunk_order_index": 111,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-e9c3a5e57ba617956dc3eb4c128c22eb": {
    "tokens": 1200,
    "content": "194\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nµ\n\nσ2\n\nlog(λA) - log(true value)\n\nV\ne\nk\n\n5\n0\n5\n.\n1\n\n0\n0\n5\n.\n1\n\n5\n9\n4\n.\n1\n\n2\n^\nV\ne\nk\n\n7\n0\n0\n0\n.\n0\n\n4\n0\n0\n0\n.\n0\n\n1\n0\n0\n0\n.\n0\n\nT\nX\nE\nT\n\n2\n\n1\n\n0\n\n1\n-\n\n2\n-\n\n3\n-\n\n1\n\n5\n\n10\n\n25\n\n50\n\n1\n\n5\n\n10\n\n25\n\n50\n\n1\n\n5\n\n10\n\n25\n\n50\n\nLine Intensity\n\nLine Intensity\n\nLine Intensity\n\nFigure 10.7 Medians and 95% credible intervals for the ﬁve simulations. The hor-\nizontal axes represent the ﬁve simulations. Intervals in the third graph are trans-\nlated (by substracting by the logarithm of the true value) so as to be comparable.\nIn each case the dashed lines are the true values.\n\nabsorption line; the third factor is the distribution of the ideal data given\nin (10.10); and the last two factors are independent prior distributions.\nThus, we can construct a two step Gibbs sampler, perhaps with Metropolis-\nHastings approximations, to obtain a sample from p(X, Z, θ−A, θA|Y ) as\nfollows:\nSTEP 1: Draw (θA\n\n(t), θ−A\n\n(t) ) from\n\np(θA, θ−A|X, Y, Z) = p(θA|X, Y, Z)p(θ−A|X, Y, Z)\n\nSTEP 2: Draw (X(t), Z(t)) from\n\np(X, Z|Y, θA, θ−A) = p(X|Y, Z, θA, θ−A)p(Z|Y, θA, θ−A)\n\n= p(X|Z, θA, θ−A)p(Z|Y, θA, θ−A)\n\n(10.20)\n\nThe equalities follow from the factorization in (10.19). Because the draws\nof θA and of X are exactly as described in Section 10.3 while the draws of\nθ−A and Z are given in van Dyk et al. (2001) we can easily implement this\nMCMC sampler. EM can be adapted using similar arguments.\n\n\fSPECTRAL MODELS WITH ABSORPTION LINES\n\n195\n\n10.4.2 An Example\n\n1 E\n\nTo explore the eﬀect of an absorption line on the spectral model of Sec-\ntion 10.2.2 we analyze the X-ray spectrum of Quasar S5 0014+813 (K¨uhr\net al. 1981), using data observed with the ASCA instrument in 1993 (Elvis\net al. 1994). We used all 512 of the instrument energy bins, except for the\nunreliable bins below ∼ 0.5 keV or above ∼ 10 keV. We model the contin-\n−θC\nuum as a power law, i.e., λC(θC, Ej) = θC\n2\n, and add an inter-stellar\nj\n1 , E) = exp(−θA\nabsorption component, α1(θA\n1 /E). We account for back-\nground by setting θB\nl equal to the (rescaled) counts in the corresponding\nbin of the background observation. Because the data are relatively informa-\ntive for θC and θA\n1 , we use ﬂat prior distributions on a variance stabilizing\ntransformation of each parameter. A sample from the posterior distribution\nwas obtained by running three MCMC chains according to the algorithm\ndescribed in van Dyk et al. (2001) for 1000 iterations each. (We use the\nnesting methods described by van Dyk and Meng (2000) to reduce the\nautocorrelation in the resulting chains and produce three draws per itera-\ntion.) We then combined the last 2000 draws of each chain to form a sample\nof 6000 draws. The marginal posterior distributions of θC\n1 are\nrepresented by the shaded histograms in Figure 10.8.\n\n2 and θA\n\n1 , θC\n\nTo explore the eﬀect of an absorption line on our analysis, we manu-\nally subtracted counts from nine adjacent bins near 1 keV to simulate an\nabsorption line:\n\noriginal counts\naltered counts\n\n30\n15\n\n30\n10\n\n28\n5\n\n24\n0\n\n31\n0\n\n37\n0\n\n28\n5\n\n26\n10\n\n29\n15\n\nUsing the altered data we reﬁt the model exactly as described above (not\naccounting for the absorption line), yielding the marginal posterior distri-\nbutions depicted by the histogram with dashed lines in Figure 10.8. The\npresence of the unaccounted for absorption feature has both increased the\nposterior variance of all three parameters and has shifted the distributions\naway from their “true” values. Clearly inference based on this posterior is\nbiased by the non-ignorable missing data caused by the absorption line.\nThus, we reﬁt the altered data, this time accounting for the absorption\nline component as described in Section 10.4. (We use a gamma prior on\nλA with E(λA) = var(λA) = 2.) The new marginal posterior (solid lines",
    "chunk_order_index": 112,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-db8edc6f2a1a5704bb9ceb5b6b2f48ee": {
    "tokens": 1200,
    "content": "three parameters and has shifted the distributions\naway from their “true” values. Clearly inference based on this posterior is\nbiased by the non-ignorable missing data caused by the absorption line.\nThus, we reﬁt the altered data, this time accounting for the absorption\nline component as described in Section 10.4. (We use a gamma prior on\nλA with E(λA) = var(λA) = 2.) The new marginal posterior (solid lines\nin Figure 10.8) match the original marginal posterior distributions closely;\nthe bias caused by the absorption line has been removed.\n\nFigure 10.9 shows the cumulative probability of membership of four\nclusters as a function of energy. The clusters correspond to the photons\nobserved by the detector, photons lost to instrument response, photons\nabsorbed by the inter-stellar media, and photons absorbed in the absorp-\ntion line. Although these clusters are not speciﬁcally spatial in character,\nif the source were diﬀuse, we might expect their relative density to vary\n\n\f196\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nC\nθ\n1\n\nC\nθ\n2\n\nA\nθ\n1\n\n0\n2\n0\n0\n0\n.\n0\n\n0\n1\n0\n0\n0\n.\n0\n\n0\n.\n0\n\n0\n.\n2\n\n0\n.\n1\n\n0\n.\n0\n\n2\n.\n1\n\n8\n.\n0\n\n4\n.\n0\n\n0\n.\n0\n\n10000\n\n30000\n\n50000\n\n2.0\n\n2.5\n\n3.0\n\n3.5\n\n4.0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\nFigure 10.8 Marginal posterior distributions. The shaded histograms represent the\n“true” model with no absorption line present. The dashed lines show the bias that\nan absorption line introduces to the parameter estimates, and the solid lines show\nthe posterior distributions after the absorption line has been accounted for.\n\nacross the source. Three of these clusters are completely unobserved—they\nare clusters within the idealized data, Y . Similar computations can sepa-\nrate the background, continuum, and emission line photon clusters, all of\nwhich are at least partially observed. If we conﬁne our attention to the ob-\nserved photons, the background, continuum, and emission line clusters are\nall sub-clusters of cluster ‘A’ in Figure 10.9. We use the posterior means\nof the model parameters to produce Figure 10.9; posterior variability can\neasily be used to compute error bars for the cluster probabilities.\n\n10.5 Discussion\n\nThe statistical and computational challenges of image analysis in high en-\nergy astrophysics are truly immense. Accounting for the spatial, spectral,\nand temporal structure in the data along with the complexities in the pho-\nton redistribution matrix, pile-up, background contamination, and photon\nabsorption requires highly structured models and sophisticated computing.\nCurrent work focuses on incorporating these complexities one at a time,\ntaking advantage of the modular structure in both our models and compu-\ntational techniques. The preliminary methods are useful for special classes\n\n\fDISCUSSION\n\n197\n\ns\ne\ni\nt\ni\nl\ni\n\nb\na\nb\no\nr\nP\n\nr\ne\nt\ns\nu\nC\n\nl\n\n0\n.\n1\n\n8\n.\n0\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n0\n.\n0\n\nD\n\nC\n\nB\n\n8\n\nA\n\n4\n\n6\nEnergy\n\n0\n\n2\n\n10\n\n12\n\nFigure 10.9 Cumulative Cluster Probabilities. The ﬁgure displays the cumulative\nprobabilities of four photon clusters as a function of Energy. Cluster ‘A’ contains\nobserved photons; ‘B’ contains photons lost to instrumental response; ‘C’ contains\nphotons absorbed by the smooth absorption term, α1, e.g., due to the interstellar\nmedia, and ‘D’ contains photons absorbed in the absorption line. The relative\nsize of the clusters vary dramatically as a function of Energy (the probabilities\nare computed using the posterior mean of the model parameters).\n\nof images (e.g., the spectral models can be applied directly to point sources)\nbut need to be extended to be useful for more sophisticated images. Com-\nbining the spectral and spatial models is a particular area of active work.\nEven within the much less complicated problem of accounting for absorp-\ntion lines, there are sophisticated statistical and computational challenges.\nHandling the highly multi-modal posterior distribution will only become\nmore complex as the overall model incorporates more of the features of the\nsource and data collection mechanism. In some cases, the choice of prior dis-\ntribution can be quite important and careful prior speciﬁcation along with\nsensitivity analysis is required. In general, however, we expect the three\nsteps of ﬁrst exploring the posterior distribution with mode ﬁnding algo-\nrithms, second ﬁtting the model via MCMC, and ﬁnally checking the model\nusing posterior predictive checks to be a practical strategy. Thus far, we\nhave found that directly modeling the stochastic features in the underlying\nimages and data collection to be both powerful statistically and tractable\ncomputationally, and thus, a fruitful strategy for image reconstruction.\n\n \n\f198\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nAcknowledgements\n\nThis work is a product of the collaborative eﬀort of the Astro-Statistics\nGroup at Harvard University whose members include A. Connors, D. Esch,\nP. Freeman, H. Kang, V. L. Kashyap, R. Protassov, D. Rubin, A. Siemigi-\nn",
    "chunk_order_index": 113,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-54524841dc0225868e44a31782b84a16": {
    "tokens": 1200,
    "content": "ly, and thus, a fruitful strategy for image reconstruction.\n\n \n\f198\n\nACCOUNTING FOR ABSORPTION LINES IN IMAGES\n\nAcknowledgements\n\nThis work is a product of the collaborative eﬀort of the Astro-Statistics\nGroup at Harvard University whose members include A. Connors, D. Esch,\nP. Freeman, H. Kang, V. L. Kashyap, R. Protassov, D. Rubin, A. Siemigi-\nnowska, E. Sourlas , and Y. Yu. The authors gratefully acknowledge fund-\ning for this project partially provided by NSF grant DMS-01-04129 and by\nNASA Contract NAS8-39073 (CXC).\n\n\fCHAPTER 11\n\nSpatial Modelling of Count Data: A\nCase Study in Modelling Breeding\nBird Survey Data on Large Spatial\nDomains\n\nC.K. Wikle\n\n11.1 Introduction\n\nThe North American Breeding Bird Survey (BBS) is conducted each breed-\ning season by volunteer observers (e.g. Robbins et al. 1986). The observers\ncount the number of various species of birds along speciﬁed routes. The col-\nlected data are used for several purposes, including the study of the range of\nbird species, and the variation of the range and abundance over time (Link\nand Sauer 1998). Such studies usually require spatial maps of relative abun-\ndance. Traditional methods for producing such maps are somewhat ad hoc\n(e.g., inverse distance methods) and do not always account for the special\ndiscrete, positive nature of the count data (e.g. Sauer et al. 1995). In ad-\ndition, corresponding prediction uncertainties for maps produced in this\nfashion are not typically available. Providing such uncertainties is critical\nas the prediction maps are often used as “data” in other studies and for\nthe design of auxiliary sampling plans.\n\nWe consider the BBS modeling problem from a hierarchical perspective,\nmodeling the count data as Poisson, conditional on a spatially varying\nintensity process. The intensities are then assumed to follow a log-normal\ndistribution with ﬁxed eﬀects and with spatial and non-spatial random\neﬀects. Model-based geostatistical methods for generalized linear mixed\nmodels (GLMMs) of this type have been available since the seminal work of\nDiggle et al. (1998). However, implementation is problematic when there are\nlarge data sets and prediction is desired over large domains. We show that\nby utilizing spectral representations of the spatial random eﬀects process,\nBayesian spatial prediction can easily be carried out on very large data sets\nover extensive prediction domains. General discussion of the role of such\nBayesian hierachical random eﬀect modelling is given in 1, and approaches\nto spatio-temporal modelling are found here in 12.\n\n\f200\n\nSPATIAL MODELLING OF COUNT DATA\n\nThe BBS sampling unit is a roadside route 39.2 km in length. Over each\nroute, an observer makes 50 stops, at which birds are counted by sight and\nsound for a period of 3 minutes. Over 4000 routes have been included in\nthe North American survey, but not all routes are available each year. As\nmight be expected due to the subjectivity involved in counting birds by\nsight and sound, and the relative experience and expertise of the volunteer\nobservers, there is substantial observer error in the BBS survey (e.g. Sauer\net al. 1994).\n\nIn this study, we are concerned with the relative abundance of the House\nFinch (Carpodacus mexicanus). Figure 11.1 shows the location of the sam-\npling route midpoints and observed counts over the continental United\nStates (U.S.) for the 1999 House Finch BBS. The size of the circle radius\nis proportional to the number of birds observed at each site. This ﬁgure\nsuggests that the House Finch is more prevalent in the Eastern and West-\nern U.S. than in the interior. Indeed, this species is native to the Western\nU.S. and Mexico. The Eastern population is a result of a 1940 release of\ncaged birds in New York. The birds were being sold illegally in New York\nCity as “Hollywood Finches” and were supposedly released by dealers in\nan attempt to avoid prosecution. Within three years there were reports of\nthe birds breeding in the New York area. Because the birds are proliﬁc\nbreeders and their juveniles disperse over long distances, the House Finch\nquickly expanded to the west (Elliott and Arbib 1953). Simultaneously, as\nthe human population on the west coast expanded eastward (and corre-\nspondingly, changed the environment) the House Finch expanded eastward\nas well. By the late 1990s, the two populations met in the Central Plains\nof North America.\n\nFrom Figure 11.1 it is clear that there are many regions of the U.S. that\nwere not sampled in the 1999 House Finch BBS. Our interest here is to\npredict abundance over a relatively dense network of spatial locations, every\nquarter degree of latitude and longitude. The network of prediction grid\nlocations includes 228 points in the longitudinal and 84 in the latitudinal\ndirection, for a total of 19,152 prediction grid locations.\n\n11.2 The Poisson Random Eﬀects Model\nConsider the model for the count process y(x) given a spatially varying\nmean process λ(x):\n\ny(x)|λ(x) ∼ P oisson(λ(x)).\n\n(11.1)\n\nThe log of the spatial mean process is given by:",
    "chunk_order_index": 114,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-3a9ad451d0776bb1ddc7ec21e61a9cf3": {
    "tokens": 1200,
    "content": "prediction grid\nlocations includes 228 points in the longitudinal and 84 in the latitudinal\ndirection, for a total of 19,152 prediction grid locations.\n\n11.2 The Poisson Random Eﬀects Model\nConsider the model for the count process y(x) given a spatially varying\nmean process λ(x):\n\ny(x)|λ(x) ∼ P oisson(λ(x)).\n\n(11.1)\n\nThe log of the spatial mean process is given by:\n\nlog(λ(x)) = µ + z(x) + η(x),\n(11.2)\nwhere µ is a deterministic mean component, z(x) is a spatially correlated\nrandom component, and η(x) is an uncorrelated spatial random compo-\n\n\fTHE POISSON RANDOM EFFECTS MODEL\n\n201\n\nFigure 11.1 Observation locations for 1999 BBS of House Finch (Carpodacus\nmexicanus). Radius and color are proportional to the observed counts.\n\nnent. In general, the ﬁxed component µ might be related to spatially vary-\ning covariates (such as habitat) and could include “regression” terms. We\nwill consider the simple constant mean formulation in this application. The\ncorrelated process, z(x), is necessary in this application because we have\nsubstantial prior belief that the counts at “nearby” routes are correlated.\nFrom a scientiﬁc point of view, this is likely due (at least in part) to the fact\nthat the birds are attracted to speciﬁc habitats, and we know that habitat\nis correlated in space. Typically, one can view the z-process as accounting\nfor the eﬀects of “unknown” covariates, since it induces spatial structure\nin the λ-process, and thus the observed counts. In that sense, maps of the\nz-process may be interesting and lead to greater understanding as to the\npreferred habitat of the modeled bird species (e.g. Royle et al. 2001). The\nrandom component η(x) accounts for observer eﬀects. A major concern in\nthe analysis of BBS data is the known observer bias, as discussed previ-\nously. Typically, we can assume that since the observers produce counts on\ndiﬀerent routes, they are independent with regard to space.\n\nThe above discussion suggests that we might model z(x) as a Gaussian\nrandom ﬁeld with zero mean and covariance given by cθ(x, x(cid:1)), where θ\nrepresents parameters (possibly vector-valued) of the covariance function\nη), where cov(η(x), η(x(cid:1))) = 0 if\nc. In addition, we assume η(x) ∼ N (0, σ2\nx (cid:3)= x(cid:1).\n\nAs presented, the Poisson spatial model follows the framework for gener-\n\n\f202\n\nSPATIAL MODELLING OF COUNT DATA\n\nalized geostatistical prediction formulated in Diggle et al. (1998). An exam-\nple of this approach applied to the BBS problem can be found in Royle et\nal. (2001). However, implementation in that case was concerned with rela-\ntively small data sets and over limited geographical regions. The Gaussian\nrandom ﬁeld-based Bayesian hierarchical approach becomes increasingly\ndiﬃcult to implement as the dimensionality of the data and number of pre-\ndiction locations increases. Consequently, such an approach is not feasible\nat the continental scale and high resolution that we require in the present\napplication. However, as outlined in Royle and Wikle (2001), one can still\nuse the Bayesian GLMM methodology in these high-dimensional settings\nif one makes use of spectral representations. This approach is summarized\nin the next section.\n\n11.2.1 Spectral Formulation\n\nLet {xi}m\ni=1 be the set of data locations, at which counts y(xi) were ob-\nserved. Further, let {xj}n\nj=1 be the set of prediction locations, which may,\nbut need not, include some or all of the m data locations. We now rewrite\nthe mean-process model (11.2):\n\nlog(λ(xi)) = µ + k(cid:1)\n\n(11.3)\nwhere zn is an n × 1 vector representation of z-process at the prediction\nlocations, and the vector ki relates the log-mean process at observation\nlocation xi to one or more elements of the z-process at prediction locations\n(e.g. Wikle et al. 1998, Wikle et al. 2001). We then assume:\n\nzn + η(xi),\n\ni\n\nzn = Ψα + (cid:5),\nwhere Ψ is an n×p matrix, ﬁxed and known, α is a p×1 vector of coeﬃcients\nwith α ∼ N (0, Σα), and (cid:5) ∼ N (0, σ2\nI). We let Ψ consist of spectral basis\n(cid:8)\n≡ [ψ1,k, . . . , ψn,k](cid:1)\nfunctions [ψj,k]n,p\nthen ψ(cid:1)\nj = 0 if k (cid:3)= j and 1, otherwise. In this case, we say that α are\nψ\nk\nspectral coeﬃcients. From a hierarchical perspective, we can write:\n\nj=1,k=1 that are orthogonal. That is, if ψ\n\n(11.4)\n\nk\n\nzn|α, σ2\n\n(cid:8)\n\n∼ N (Ψα, σ2\n(cid:8)\n\nI)\n\n(11.5)\n\nand\n\nα|Σα ∼ N",
    "chunk_order_index": 115,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-d0d8f067362c35096a91010ec74950d7": {
    "tokens": 1200,
    "content": ", otherwise. In this case, we say that α are\nψ\nk\nspectral coeﬃcients. From a hierarchical perspective, we can write:\n\nj=1,k=1 that are orthogonal. That is, if ψ\n\n(11.4)\n\nk\n\nzn|α, σ2\n\n(cid:8)\n\n∼ N (Ψα, σ2\n(cid:8)\n\nI)\n\n(11.5)\n\nand\n\nα|Σα ∼ N (0, Σα).\nIn general, the covariance function for the α-process depends on some pa-\nrameters θ; we denote this covariance by Σα(θ). The modeling motivation\nfor the hierarchy is apparent if we note that the random z-process can be\nwritten zn ∼ N (0, Σz(θ) + σ(cid:8)I), where σ2\n(cid:8) accounts for the “nugget eﬀect”\ndue to small scale variability. Given (11.4), the covariance function for the\nz-process can be written, Σz(θ) = ΨΣα(θ)Ψ(cid:1).\n\n(11.6)\n\nIn principle, any set of orthogonal spectral basis functions could be used\n\n\fTHE POISSON RANDOM EFFECTS MODEL\n\n203\n\nfor Ψ. For example, one could use the leading variance modes of the co-\nvariance matrix Σz. Such modes are just the eigenvectors that diagonalize\nthe spatial covariance matrix and thus are just principal components. These\nspatial principal components are known as Empirical Orthogonal Functions\n(EOFs) in the geostatistical literature (e.g. Obled and Creutin 1986, Wikle\nand Cressie 1999). Such a formulation is advantageous because it allows for\nnon-stationary spatial correlation and dimension reduction (p << n). An-\nother possibility would be to use Fourier basis functions in Ψ. This could\napply if the prediction locations were deﬁned in continuous space or on a\ngrid. However, as we will demonstrate, if we choose a grid implementation,\none need not actually form the matrix Ψ, which would be problematic for\ngrid sizes of order 105 as we consider here. That is, the operation Ψα is ac-\ntually an inverse Fourier transform operation on the vector α. On a discrete\nlattice, one can use Fast Fourier Transform (FFT) procedures to eﬃciently\nimplement this transform without having to make or store the matrix of\nbasis functions. In this case, p = n. If the z-process is stationary, the use of\nFourier basis functions suggests that the matrix Σα(θ) is diagonal (asymp-\ntotically). For situations where it is more appropriate to assume that the\nprocess is nonstationary and the prediction locations can be thought of\nas a discrete grid, one could consider a wavelet basis function for Ψ. In\nthis case, the operation Ψα is just an inverse discrete wavelet transform\nof α; again, Ψ need not be constructed directly. Depending on the class\nof wavelets chosen, the matrix Σα(θ) may be diagonal (asymptotically) or\nnearly so.\n\nIn the hierarchical implementation, the parameterization of Σα(θ) is\nespecially critical. For example, with wavelet basis functions, we might\nassume a fractional scaling behavior in the variance of the diﬀerent wavelet\nscales. This is particularly useful when the process is known to exhibit such\nbehavior, such as turbulence examples in atmospheric science (e.g. Wikle\net al. 2001). Alternatively, we might assume a common stationary class for\nthe z-process, such as the Mat´ern class of covariance functions,\n\nc(dij) = φ(θ1dij)θ2 Kθ2(θ1dij), φ > 0, θ1 > 0, θ2 > 0,\n\n(11.7)\n\nwhere dij is the distance between two spatial locations, Kθ2 is the modiﬁed\nBessel function, θ2 is related to the degree of smoothness of the spatial\nprocess, θ1 is related to the correlation range, and φ is proportional to\nthe variance of the process (e.g. page 48, Stein 1999). The corresponding\nspatial spectral density function at frequency ω is,\n\nf (ω; θ1, θ2, φ, g) =\n\n2θ2−1φΓ(θ2 + g/2)θ1\n2\nπg/2(θ1\n\n+ ω2)θ2+g/2 ,\n\n2θ2\n\n(11.8)\n\nwhere g is the dimension of the spatial process (e.g. page 49, Stein 1999).\nThus, if one chooses Fourier basis functions for Ψ and assumes the Mat´ern\nclass, then Σα(θ) should be diagonal (asymptotically) with diagonal ele-\n\n\f204\n\nSPATIAL MODELLING OF COUNT DATA\n\nments corresponding to f given by (11.8). If not known, one must specify\nprior distributions for θ and φ at the next level of the model hierarchy.\n\n11.2.2 Model Implementation and Prediction\n\nm(cid:1)\n\nThe hierarchical Poisson model with a spectral spatial component is sum-\nmarized as follows. The joint likelihood for all observations y (an m × 1\nvector) is\n\n[y|λ] =\n\nP oisson(λ(xi)),\n\n(11.9)\n\nwhere λ is an m × 1 vector, corresponding to the locations of the vector y.\nThe joint prior distribution for log(λ(xi)) is:\n\ni",
    "chunk_order_index": 116,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-7b960ec6e3358916b4dd3327ef5b598e": {
    "tokens": 1200,
    "content": "2 Model Implementation and Prediction\n\nm(cid:1)\n\nThe hierarchical Poisson model with a spectral spatial component is sum-\nmarized as follows. The joint likelihood for all observations y (an m × 1\nvector) is\n\n[y|λ] =\n\nP oisson(λ(xi)),\n\n(11.9)\n\nwhere λ is an m × 1 vector, corresponding to the locations of the vector y.\nThe joint prior distribution for log(λ(xi)) is:\n\ni=1\n\n[log(λ)|µ, γ, zn, σ2\n\n(11.10)\nwhere 1 is an m × 1 vector of ones, log(λ) is the m × 1 vector with elements\nlog(λ(xi)), K is an m×n matrix with rows k(cid:1)\ni, and γ is a scaling coeﬃcient\n(introduced for computational reasons as discussed below). Then, let\n\nn] = N (µ1 + γKzn, σ2\n\nI),\n\nη\n\n[zn|α, σ2\n\ne ] = N (Ψα, σ2\n\ne\n\nI),\n\n(11.11)\n\nand allow the spectral coeﬃcients to have distribution,\n\n[α|Rα(θ1)] = N (0, Rα(θ1)),\n(11.12)\nwhere Rα(θ1) is a diagonal matrix. For the BBS illustration presented here,\nwe let θ2 = 1/2 in (11.7) (i.e., we assume the covariance model is exponen-\ntial) but assume the dependence parameter θ1 is random. Note that as a\nconsequence of including the γ parameter in (11.10) we are able to spec-\nify the conditional covariance of α as the diagonalization of a correlation\nmatrix rather than a covariance matrix (see discussion below). Finally, to\ncomplete the model hierarchy, we assume the remaining parameters are\nindependent and specify the following prior distributions:\nσ2\nγ ∼ U [0, b],\nη\n∼ IG(qe, re),\nwhere IG( ) refers to an inverse gamma distribution, and U [\n] a uniform\ndistribution. For the BBS House Finch data we select qη = 0.5, qe = 1,\nrη = 2, re = 10, µ0 = 0, σ2\nµ = 10, b = 100, u1 = 1, and u2 = 100 (note,\nour parameterization of the exponential is r(d) ∝ exp(−θ1d), where d is\nthe distance). These hyperparameters correspond to rather vague proper\npriors.\n\nµ ∼ N (µ0, σ2\nµ),\nσ2\ne\n\nθ1 ∼ U [u1, u2],\n\n∼ IG(qη, rη),\n\n(11.14)\n\n(11.13)\n\nThe alternative to specifying γ in (11.10) is to let the conditional co-\nvariance of α be σ2\nRα(θ1). However, as is often the case for Bayesian\nα\nspatial models that are deep in the model hierarchy (and thus, relatively\nfar from the data), the MCMC implementation has diﬃculty converging\n\n\f205\n\nTHE POISSON RANDOM EFFECTS MODEL\nbecause of the tradeoﬀ between the spatial process variance, σ2\nα, and the\ndependence parameter, θ1. By allowing the z-process to have unit variance,\nas in the above formulation, we need not estimate σ2\nα (which is 1 in this\ncase). The variance in the spatial process is then achieved through γ. In\nsituations where the implied assumption of homogeneous variance is un-\nrealistic, a more complicated reparameterization would be required. Note\nthat the γ parameterization also aﬀects the interpretation of the variance\nof the z-process (i.e., σ2\n\n(cid:8) /γ2).\nOur goal is the estimation of the joint posterior distribution,\ne , µ|y] ∝ [y| log(λ)][log(λ)|µ, zn, σ2\n[log(λ), zn, θ1, γ, σ2\n× [α|θ1][θ1][γ][µ][σ2\n\nη][zn|α, σ2\ne ]\nη][σ2\ne ]\n\ne = σ2\n\nη, σ2\n\nAlthough this distribution cannot be analyzed directly, we are able to use\nMCMC approaches as suggested by Diggle et al. (1998) to draw samples\nfrom this posterior and appropriate marginals. In particular, we utilized\na Gibbs sampler with Metropolis-Hastings sampling of log(λ) and θ1 (see\nRoyle et al. 2001). Perhaps more importantly, we would like estimates from\nthe posterior distribution of λn, the λ-process at prediction grid locations.\nThe key diﬃculty in the traditional (non-spectral) geostatistical formula-\ntion is the dimensionality of the full-conditional update for the z-process\ngiven all other parameters. As we show below, this is no longer a serious\nproblem if we make use of the spectral representation.\n\nSelected Full-Conditional Distributions\n\nAs mentioned above, for the most part the full-conditional distributions\nfollow those outlined generally in Diggle et al. (1998) and speciﬁcally, those\nin Royle et al. (2001). However, the spectral representation allows simpler\nforms for the zn and α full-conditionals.\n\ne + K(cid:1)Kγ2/σ2\n\nThe full-conditional distribution for zn can be shown to be:",
    "chunk_order_index": 117,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-08459738873f01014df2eebfa68b6345": {
    "tokens": 1200,
    "content": "representation.\n\nSelected Full-Conditional Distributions\n\nAs mentioned above, for the most part the full-conditional distributions\nfollow those outlined generally in Diggle et al. (1998) and speciﬁcally, those\nin Royle et al. (2001). However, the spectral representation allows simpler\nforms for the zn and α full-conditionals.\n\ne + K(cid:1)Kγ2/σ2\n\nThe full-conditional distribution for zn can be shown to be:\nzn|· ∼ N (S−1\n\naz, S−1\nz ),\nη and az = Ψα/σ2\n\n(11.15)\ne + K (cid:1)(log(λ) − µ1)γ/σ2\nwhere Sz = I/σ2\nη.\nIn our case, K is an incidence matrix (a matrix of ones and zeros) such\nthat each observation is only associated with one prediction grid location\n(a reasonable assumption at the resolution presented here). Thus, K(cid:1)K\ncan be shown to be a diagonal matrix with 1’s and 0’s along the diagonal.\nAlthough the matrix Sz is very high-dimensional (order 105 × 105), it is\ndiagonal and trivial to invert. In addition, Ψα can be calculated by the\ninverse FFT function (a fast operation) and zn is updated as simple uni-\nvariate normal distributions. In practice, we update these simultaneously\nin a matrix language implementation.\n\nz\n\nSimilarly,\n\nα|· ∼ N (S−1\nα\n\naα, S−1\n\nα ),\n\n(11.16)\n\n\fSPATIAL MODELLING OF COUNT DATA\n\ne + Rα(θ1)−1) and aα = Ψ(cid:1)zn/σ2\n\n206\nwhere Sα = (Ψ(cid:1)Ψ/σ2\ne . At ﬁrst glance,\nthis appears problematic due to the Ψ(cid:1)Ψ and Rα(θ1)−1 terms in the full-\nconditional variance. However, since the spectral operators are orthogonal,\nΨ(cid:1)Ψ = I and the matrix Rα(θ1)−1 is diagonal as discussed previously.\nFurthermore, Ψ(cid:1)zn is just the FFT operation on zn and is very fast. Thus,\n(11.17)\n\ne + Rα(θ1)−1)−1Ψ(cid:1)zn/σ2\n\ne + Rα(θ1)−1)−1)\n\nα|· ∼ N ((I/σ2\n\ne , (I/σ2\n\nand can be sampled as individual univariate normals, or easily in a block\nupdate.\n\nPrediction\nTo obtain predictions of λn, the λ-process at the prediction grid locations,\nwe sample from\n[log(λ(t)\nn )|z(t)\n\n] = N (µ(t)1 + γ(t)z(t)\n\nn , γ(t), µ(t), σ2 (t)\n\nn , σ2 (t)\n\n(11.18)\n\nI),\n\nη\n\nη\n\nwhere 1 is n × 1 and µ(t), γ(t), z(t)\nMCMC simulation. We obtain λ(t)\n\nn , σ\n\nare the t-th samples from the\nn by simply exponentiating these samples.\n\n2 (t)\nη\n\nImplementation\n\nThe MCMC simulation must be run long enough to achieve precise estima-\ntion of model parameters and predictions. For the BBS House Finch data,\nthe MCMC simulation was run for 200,000 iterations after a 50,000 burn-in\nperiod. For sake of comparison, the algorithm took approximately 0.5 sec-\nonds per iteration with a MATLAB implementation on a 500 MHz Pentium\nIII processor running Linux. Considering there are nearly 20,000 prediction\nlocations and relatively strong spatial structure, this is quite fast. We ex-\namined many shorter runs to establish burn-in time and to evaluate model\nsensitivity to the ﬁxed parameters and starting values. The model does not\nseem overly sensitive to these parameters.\n\n11.3 Results\n\nThe posterior mean and posterior standard deviation for the scalar param-\neters are shown in Table 11.1.\n\nFigure 11.2 shows the posterior mean for the gridded z-process. We note\nthe agreement with the data shown in Figure 11.1. One might examine this\nmap to indentify possible habitat covariates that are represented by the\nspatial random ﬁeld. One possibility in this case might be elevation and\npopulation, both of which are thought to be associated with the prevalence\nof the House Finch.\n\nWe note that the prediction grid extends beyond the continental United\nStates. Clearly, estimates over ocean regions are meaningless with regard\nto House Finch data. These estimates are a result of the large-scale Fourier\n\n\fCONCLUSION\n\n207\n\nTable 11.1 Posterior mean and standard deviation of univariate model parame-\nters.\n\nPosterior\n\nPosterior\nStandard\nMean Deviation\n\nParameter\n\nµ\nγ\nσ2\nη\nσ2\ne\nθ1\n\n0.74\n1.41\n0.84\n0.23\n14.78\n\n0.105\n0.138\n0.100\n0.064\n4.605\n\ncoeﬃcients in the model. Fortunately, the map of posterior standard devi-\nations for this process, shown in Figure 11.3, indicates that these regions\nwith no-data are highly suspect. This is also true of the northern plains\nregion, which has few observations. Of course, having the prediction grid\nextend over the ocean is not ideal in this case, but the FFT-based algo-\nrithm requires rectangular grids. We could",
    "chunk_order_index": 118,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-78a4ef6b1802cbeded294556630be8ed": {
    "tokens": 1200,
    "content": ".064\n4.605\n\ncoeﬃcients in the model. Fortunately, the map of posterior standard devi-\nations for this process, shown in Figure 11.3, indicates that these regions\nwith no-data are highly suspect. This is also true of the northern plains\nregion, which has few observations. Of course, having the prediction grid\nextend over the ocean is not ideal in this case, but the FFT-based algo-\nrithm requires rectangular grids. We could control for the land-sea eﬀect\nby having an indicator covariate or possibly, a regime-speciﬁc model. Such\nmodiﬁcations would be simple to implement in the hierarchical Bayesian\nframework presented here. However, simulation studies have shown that\nthese are not necessary and if desired, one could simply mask the water\nportions of the map for presentation.\n\nFinally, Figure 11.4 and Figure 11.5 show the posterior mean and stan-\ndard deviation of the λ-process on the prediction grid. These plots show\nclearly that the posterior standard deviation is proportional to the pre-\ndicted mean, as expected with Poisson count data. In addition, the stan-\ndard errors are also high in data sparse regions, as we expect.\n\n11.4 Conclusion\n\nIn summary, we have demonstrated how the Bayesian implementation of\ngeostatistical-based GLMM Poisson spatial models can be implemented in\nproblems with very large numbers of prediction locations. By utilizing rel-\natively simple spectral transforms and associated orthogonality and decor-\nrelation, we are able to implement the modeling approach very eﬃciently\nin general MCMC algorithms.\n\nAcknowledgement\n\nThis research has been supported by a grant from the U.S. Environmental\nProtection Agency’s Science to Achieve Results (STAR) program, Assis-\n\n\f208\n\nSPATIAL MODELLING OF COUNT DATA\n\nFigure 11.2 Posterior mean of zn for the 1999 BBS House Finch data.\n\nFigure 11.3 Posterior standard deviation of zn for the 1999 BBS House Finch\ndata.\n\ntance Agreement No. R827257-01-0. The author would like to thank Andy\nRoyle for providing the BBS data and for helpful discussions.\n\n\fCONCLUSION\n\n209\n\nFigure 11.4 Posterior mean of gridded λn for the 1999 BBS House Finch data.\n\nFigure 11.5 Posterior standard deviation of λn for the 1999 BBS House Finch\ndata.\n\n\f\fPART III\n\nSpatio-temporal cluster modelling\n\n\f\fCHAPTER 12\n\nModelling Strategies for\nSpatial-Temporal Data\n\nJ.T. Kent\n\nK.V. Mardia\n\n12.1 Introduction\n\nSpatial-temporal modelling has largely been developed through applica-\ntions in geostatistics, hydrology and meteorology. More recent activities in\nthe area include environment monitoring, tracking, functional MRI, health\ndata and facial analysis. For a recent snapshot of activities, see Mardia et\nal. (1999). Motivated by these applications, the ﬁeld has adopted various\nmodelling strategies. Current thinking in the ﬁeld has been surveyed by\nHaslett (1989), Goodall and Mardia (1994), Kyriakidis and Journel (1999),\nMardia et al. (1998), Wikle and Cressie (1999) and Brown et al. (2000).\n\nThe ideas behind these spatial-temporal models can be broadly cross-\n\nclassiﬁed according to\n(a) their motivation,\n(b) their underlying objectives and\n(c) the scale of data.\nUnder (a) the motivations for models can be classiﬁed into four classes: (i)\nextensions of time series methods to space (ii) extension of random ﬁeld and\nimaging techniques to time (iii) interaction of time and space methods and\n(iv) physical models. Under (b) the main objectives can be viewed as either\ndata reduction or prediction. Finally, under (c) the available data might be\nsparse or dense in time or space respectively, and the modelling approach\noften takes this scale of data into account. In addition, the data can be\neither continuously indexed or discretely indexed in space and/or time.\nBased on these considerations, especially (i) – (iii), we will describe several\nmodelling strategies in detail and discuss their implementation. In Chapter\n1 in this volume, space-time modelling concepts are introduced, while in\nChapter 14, space-time modelling with a focus on object recognition is\npresented.\n\nFor simplicity we assume that the data take the form of a regular array\n\nin space-time. That is, we have one-dimensional observations\n\nyij,\n\ni = 1, . . . , n, j = 1, . . . , m,\n\n(12.1)\n\n\f214\nMODELLING STRATEGIES FOR SPATIAL-TEMPORAL DATA\nat sites xi ∈ Rd and at times tj ∈ R. Typically, d = 1, 2, or 3 for observa-\ntions on the line, in the plane or in 3D space. However, we do not usually\nassume that the sites are regularly-spaced in Rd.\n\nThe objective is to model the data as\n\n0), σ2\n\n(cid:11)ij ∼ N (0, σ2\n\nyij = z(xi, tj) + (cid:11)ij,\n\n(12.2)\nwhere {z(x, t), x ∈ Rd, t ∈ R} is a stochastic or deterministic space-time\nprocess. We usually assume the error terms (cid:11)ij are independent, identically\ndistributed. In the language of geostatistics,",
    "chunk_order_index": 119,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-8f294913211fee97b3f6268069e2446c": {
    "tokens": 1200,
    "content": "the data as\n\n0), σ2\n\n(cid:11)ij ∼ N (0, σ2\n\nyij = z(xi, tj) + (cid:11)ij,\n\n(12.2)\nwhere {z(x, t), x ∈ Rd, t ∈ R} is a stochastic or deterministic space-time\nprocess. We usually assume the error terms (cid:11)ij are independent, identically\ndistributed. In the language of geostatistics, such error terms are often\nknown as a “nugget eﬀect”. Once a smooth process ˆz(x, t) has been ﬁtted,\nit can be used for interpolation and prediction. Both sites and times may\nbe either continuously or discretely indexed according to context.\n\n0 ≥ 0,\n\nFinally, we comment on notation. In general we use boldface to indi-\ncate vectors, e.g. γ. In particular, sites in Rd will be denoted by x with\ncomponents (x[1], . . . , x[d]).\n\n12.2 Modelling Strategy\n\nA key property of much spatial-temporal data is spatial-temporal continu-\nity; that is, observations at nearby sites and times will tend to be similar\nto one another. This underlying smoothness of a process z(x, t) can be\ncaptured in the following ways:\n• parametrically, using a ﬁnite-dimensional space of regression or drift\n\nfunctions, or\n\n• nonparametrically, using autocorrelation to make nearby values similar.\nBoth of these approaches can be applied in space and/or time. Letting\nD and C stand for a “drift” and “correlation” approach, respectively, the\nfollowing types of models can be considered:\n(a) (D-D) Tensor products of drift in time and drift in space. This ap-\n\nproach is explored in Section 3.\n\n(b) (D-C) Drift in space and correlation in time. The Kriged Kalman ﬁlter\nmodel of Mardia et al. (1998) and Wikle and Cressie (1999) exempliﬁes\nthis approach; see Section 4.\n\n(c) (C-D) Correlation in space and drift in time. Not explored here.\n\n(d) (C-C) Joint correlation in space and time. Examples of this approach\ninclude space-time autoregressive and related models (Section 6.8 Cressie\n1993) in discrete space-time and the “diﬀusion-injection” model in con-\ntinuous space-time (pp. 430–433 Whittle 1986).\nThe density of data points in space and time can guide the choice of\nmodelling strategy. When the data are sparse, there is often a preference\nfor drift-style models, as there is not enough information to ﬁt an auto-\ncorrelation structure. Of course a disadvantage of regression models is that\n\n\fD-D (DRIFT-DRIFT) MODELS\n\n215\n\nthe class of ﬁtted curves and surfaces can be rather inﬂexible, especially\nfor prediction and extrapolation.\n\nOn the other hand, when the data are rich, autocorrelation models be-\ncome more feasible and ﬂexible. In particular, they allow for more adaptive\nprediction and extrapolation. It is well-known that there is a close link be-\ntween the use of autocorrelation models and the use of splines to ﬁt curves\nand surfaces to discrete data; see, e.g., Kent and Mardia (1994), Chapter\n3 of Wahba (1990) and pp. 180–183 of Cressie (1993). Thus, the use of\nautocorrelation models has a nonparametric ﬂavour to it.\n\n12.3 D-D (Drift-Drift) Models\n\nIn this section we consider models which involve drift functions in space\nx ∈ Rd and time t ∈ R. There are three ingredients to these models:\n\n(a) F : a p-dimensional vector space of functions Rd → R, specifying how\nthe random ﬁeld can vary spatially. Let {f(α)(x) : α = 1, . . . p} denote\na basis.\n\n(b) G : a q-dimensional vector space of functions R → R specifying how\nthe random ﬁeld can vary temporally. Let {g(β)(t) : β = 1, . . . q} denote\na basis.\n\n(c) r : a rank, r > 0 representing complexity of the model.\n\nBoth F and G will usually include the constant function to accommodate\nan intercept term. From these ingredients we form a deterministic spatial-\ntemporal process of the form\n\np(cid:1)\n\nq(cid:1)\n\nz(x, t) =\n\naαβf(α)(x)g(β)(t),\n\n(12.3)\n\nα=1\nwhere the p × q matrix of coeﬃcients A = (aαβ) has rank r.\n\nβ=1\n\nLet the matrix F (n × p) denote the values of the spatial basis functions\nat the sites xi, i = 1, . . . , n. Similarly, let the matrix G(m × q) denote the\nvalues of the temporal basis functions at the times tj, j = 1, . . . , m. Thus,\nthe model (12.2) takes the form\n\nY = F A GT + E,\n\n(12.4)\n\nwhere Y = (yij) and E = ((cid:11)ij). If the basis functions are chosen so that\nF and G have orthonormal columns, then A can be estimated using the\ndominant r components in a singular value decomposition of F T Y G (Kent",
    "chunk_order_index": 120,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-76f1935b4ee362136cbbe3bb45564bd7": {
    "tokens": 1200,
    "content": "the times tj, j = 1, . . . , m. Thus,\nthe model (12.2) takes the form\n\nY = F A GT + E,\n\n(12.4)\n\nwhere Y = (yij) and E = ((cid:11)ij). If the basis functions are chosen so that\nF and G have orthonormal columns, then A can be estimated using the\ndominant r components in a singular value decomposition of F T Y G (Kent\net al. 2001), though if an intercept term is separated out, estimation can\nbe a bit more involved.\n\nIn this section we shall explore various choices for the space of drift\n\nfunctions and give an example.\n\n\f216\n\nMODELLING STRATEGIES FOR SPATIAL-TEMPORAL DATA\n\nChoices of Drift Functions\n\n(a) Polynomials. Low order polynomials form the simplest choice. They\ndo not depend on the choice of sites (for F) or on the choice of times\n(for G). A disadvantage, especially for high order, is that they are rather\nwild in their oscillatory behavior and they grow rapidly as |x| → ∞ or\nt → ∞, which can lead to unrealistic extrapolations and predictions.\n(b) Trigonometric functions. Fourier expansions can be very useful for\n\ndata which are periodic in space.\n\n(c) Principal kriging functions. These are a set of functions in space or\ntime adapted to the locations of the sites or times, respectively, and are\narranged from coarse scale to ﬁne scale in terms of variation.\n\nNext we describe how to constuct the principal kriging functions. For\nsimplicity we largely focus on functions of time. There are two main ingre-\ndients in the construction. First is a vector space of functions G0 of dimen-\nsion q0 ≥ 0 called the “null space”, and which will form a subspace of G.\nSecond is a “potential” function τ (t), say, which is conditionally positive\ndeﬁnite with respect to G0. That is, for all distinct times t(k), k = 1, . . . , k0\nand all vectors of coeﬃcients δ = (δk, k = 1, . . . , k0) (cid:13)= 0,\n\nk0(cid:1)\n\nk1,k2=1\n\nδk1δk2τ (t(k1) − t(k2)) > 0\n\n(cid:2)\n\nwhenever\n\nk0\n\nk=1 δkg(t(k)) = 0 for all g ∈ G0.\n\nGiven the data times tj, j = 1, . . . , m, deﬁne T (m × m) by\n\nT = (τ (ti − tj)).\nNext deﬁne an m×q0 “drift” matrix U by ujβ = g0β(tj), where {g0β(t), β =\n1, . . . , q0} is a basis of functions in G0. It is assumed that the data times\nare suitably spaced so that this matrix is of full rank q0. These matrices\ncan be combined into an (m + q0) × (m + q0) matrix\n\n(cid:3)\n\n(cid:4)\n\nwith partitioned inverse\n\nK =\n\nT\nU T\n\nK −1 =\n\n(cid:3)\n\nB A\nAT C\n\n.\n\nU\n0\n\n(cid:4)\n\n,\n\nsay,\n\nwhich, in particular, deﬁnes the matrices B and A. Denote the eigenvectors\nof B by γ\nk, k = 1, . . . , n, with the eigenvalues written in nondecreasing\norder. The ﬁrst q0 eigenvalues of B are 0 and the corresponding eigenvectors\nare given by the q0 columns of U . Finally, let τ 0(t) denote the vector\nfunction of t with jth element τ0(t)j = τ (t−tj), j = 1, . . . , m, and let u0(t)\ndenote the vector function of t with βth component g0β(t), β = 1, . . . , q0.\n\n\fD-D (DRIFT-DRIFT) MODELS\n\n217\n\nThe kth principal kriging function is deﬁned by\n\n(P KF )\ng\nk\n\n(t) = γT\n\nk (Bτ 0 + Au0(t)).\n\nIt turns out that the principal kriging functions depend only on the span\nof the columns of U , not on the set of basis functions used to construct\n(P KF )\n(t) is an interpolating function with\nU . Also, it can be shown that g\nk\n(P KF )\ngk(tj) = (γ\nk)j. The vector space G is deﬁned to be the span of {g\n(t) :\nβ\n1 ≤ β ≤ q}, where q is a speciﬁed dimension, q0 ≤ q ≤ m. For further\ndetails see, for example, Mardia et al. (1996).\n\nOne possible common choice for τ (t) is any valid covariance function\nfor a stationary stochastic process in time, for which any null space of\nfunctions G0 will suﬃce. Another possible choice is τ (t) = |t|3, which is\nconditionally positive deﬁnite whenever G0 contains the linear functions,\nspan(1, t). In this case it turns out that the kth principal kriging function\nis an interpolating cubic spline which minimizes the penalty functional\n\nΦ(g) =\n\n(cid:5) ∞\n\n(cid:6)\n\n−∞\n\n(cid:7)2\n\ndt.\n\nd",
    "chunk_order_index": 121,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-507de20852a488ec277f7774a2b3eb6b": {
    "tokens": 1200,
    "content": "functions G0 will suﬃce. Another possible choice is τ (t) = |t|3, which is\nconditionally positive deﬁnite whenever G0 contains the linear functions,\nspan(1, t). In this case it turns out that the kth principal kriging function\nis an interpolating cubic spline which minimizes the penalty functional\n\nΦ(g) =\n\n(cid:5) ∞\n\n(cid:6)\n\n−∞\n\n(cid:7)2\n\ndt.\n\nd2g(t)\ndt2\n\nsubject to the constraints g(tj) = (γ\nk)j, j = 1, . . . , m. This example moti-\nvates the alternative name “principal spline” for a principal kriging func-\ntion.\n\nA plot of some principal splines for n = 10 equally spaced time points\nis given in Figure 12.1. Note how the functions appear to mimic the qual-\nitative behavior of the successive polynomials in t. However, note that\nthe principal splines grow only linearly as |t| → ∞, more slowly than the\nquadratic and higher order polynomials.\n\nPrincipal splines can also be constructed for two-dimensional data at\nsites xi, i = 1, . . . , n. In this case it is common to use the thin-plate spline\npenalty\n\n(cid:5) (cid:8)(cid:6)\n\n∂2f\n∂x[1]2\n\n(cid:7)2\n\n(cid:6)\n\n+ 2\n\n∂2f\n∂x[1]∂x[2]\n\n(cid:7)2\n\n(cid:7)2\n\n(cid:6)\n\n+\n\n∂2f\n∂x[2]2\n\n(cid:9)\n\ndx\n\nΦ(f ) =\n\nwhere the integral is over R2 and x = (x[1], x[2]) denotes the components\nof x. The above construction of principal splines can be carried out with\nlittle change in this setting as well. Replace the potential function by τ (x) =\n|x|2 log |x|, x ∈ R2, and the null space by G0 = span(1, x[1], x[2]).\n\nPrincipal splines in R2 were introduced by Bookstein (1989) in the con-\ntext of deformations in shape analysis, and he used the term “principal\nwarps”. The matrix B was called the “bending energy matrix”.\n\nPrincipal splines have some advantages over polynomials. First they grow\nless quickly than polynomials outside the domain of the data (linearly for\ncubic splines) and so are more stable for extrapolation. Second, they are\n\n\f218\n\nMODELLING STRATEGIES FOR SPATIAL-TEMPORAL DATA\n\n)\nt\n(\ng\n\n)\nt\n(\ng\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n2\n\n.\n\n0\n\n6\n0\n\n.\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n2\n\n.\n0\n\n6\n.\n0\n\n)\nt\n(\ng\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n2\n\n.\n\n0\n\n6\n0\n\n.\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\nt\n(a)\n\nt\n(b)\n\n)\nt\n(\ng\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n2\n\n.\n0\n\n6\n.\n0\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\nt\n(c)\n\nt\n(d)\n\nFigure 12.1 First four principal cubic splines for n = 10 equally spaced time\npoints: (a) and (b) are the constant and linear function corresponding to the null\nspace G0; (c) and (d) are analogous to a quadratic and cubic function.\n\nadaptive to the given arrangement of times or sites, so that they can rep-\nresent more detailed behavior where the times or sites are most dense.\n\nExample – Growth in Rat Skulls\n\nChapter 7 of Bookstein (1991) analyzes a set of rat data on which 8 land-\nmarks have been identiﬁed on a two-dimensional midsagittal section of the\ncalvarium (the skull without the lower jaw). These measurements have been\nrepeated at m=8 times on each of 18 rats. The purpose of the analysis is to\nmodel the growth of the calvarium. In this case F, in a minor variation of\nthe above framework, is given by a vector space of mappings from R2 to R2,\nto represent deformations. Before any further analysis, it is necessary to do\na Procrustes registration of these conﬁgurations of landmarks in order to\nfocus on shape changes. After this registration there are n = 12 degrees of\n\n\fD-D (DRIFT-DRIFT) MODELS\n\n219\n\nfreedom remaining in the 8 landmarks × 2 components = 16 total degrees\nof freedom.\n\nIn this example we took F to be a full 12-dimensional subspace generated\nby pairs of principal thin-plate splines (after adjusting for Procrustes regis-\ntration) and G to be a full 7-dimensional subspace generated by the princi-\npal cubic splines (after removing 1 degree of freedom for a 12-dimensional\nintercept term). A good ﬁt was obtained by taking the rank r = 2. A plot\nof the data and the ﬁtted models with r = 1 and r = 2 are given in Figure\n12.2",
    "chunk_order_index": 122,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-e1467eb5b2e05d964774f5f133d50789": {
    "tokens": 1200,
    "content": "thin-plate splines (after adjusting for Procrustes regis-\ntration) and G to be a full 7-dimensional subspace generated by the princi-\npal cubic splines (after removing 1 degree of freedom for a 12-dimensional\nintercept term). A good ﬁt was obtained by taking the rank r = 2. A plot\nof the data and the ﬁtted models with r = 1 and r = 2 are given in Figure\n12.2. See Kent et al. (2000,(2001)) for further analysis.\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n0\n0\n\n.\n\n2\n\n.\n0\n\n6\n.\n0\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n0\n.\n0\n\n2\n\n.\n0\n\n6\n.\n0\n\n*\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n0\n0\n\n.\n\n2\n\n.\n0\n\n6\n.\n0\n\n*\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n\n0.6\n\n0. 2 0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.6\n\n0. 2 0.0\n\n0.2\n\n0.4\n\n0.6\n\n(a)\n\n(b)\n\n*\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n\n6\n.\n0\n\n4\n.\n0\n\n2\n.\n0\n\n2\n\n.\n0\n\n6\n.\n0\n\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n\n*\n\n0.6\n\n0. 2 0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.6\n\n0. 2\n\n0.2 0.4 0.6\n\n(c)\n\n(d)\n\nFigure 12.2 Fitted growth models for the rat data: (a) raw data, averaged over\nindividuals, (b) rank 1 model , (c) rank 2 model , all with the growth patterns blown\nup by a factor of 5 for clarity. Each “∗” represents a landmark of the Procrustes\nmean shape, and each closed circle represents the position of a landmark at the\ninitial time. Part (d) shows the grid deformation, without an expansion factor,\nbetween the initial and ﬁnal times for the rank 2 model.\n\n\f220\n\nMODELLING STRATEGIES FOR SPATIAL-TEMPORAL DATA\n\n12.4 D-C (Drift-Correlation) Models\n\nIn this section we modify (12.3) to get a process continuous in space and dis-\ncrete in time. The vector space of spatial functions F remains unchanged,\nbut for the time component, we replace the deterministic functions by a\nβ aαβg(β)(t) by a stochastic pro-\nvector AR process, replacing the terms\ncess vα(t) plus an error term. Thus,\np(cid:1)\n\n(cid:2)\n\nz(x, t) =\n\nf(α)(x)vα(t) + ζ(x, t), x ∈ Rd, t ∈ Z,\n\n(12.5)\n\nα=1\n\nwhere the vector v(t) = (vα(t), α = 1, . . . , p) satisﬁes the ﬁrst order vector\nAR model\n\nv(t) = P v(t − 1) + η(t), η ∼ Np(0, Ση).\n(12.6)\nThe error term ζ(x, t) is assumed to come from a process independent\nin time, but with spatial covariance σζ(x). Also, the ζ(x, t)-process is in-\ndependent of the η(t)-process. When specialized to the data sites, (12.5)\nbecomes\n\nz(t) = F v(t) + ζ(t),\n\nvar(ζ(t)) = Σζ = (σζ(xi1\n\n− xi2)),\n\n(12.7)\n\nwhere z(t) = (z(xi, t), i = 1, . . . , n) and where the drift matrix F (n×p) has\nthe same meaning as in the last section. Thus the parameters of the model\nare P (p×p), Σζ(n×n), and Ση(p×p). The two covariance matrices must be\nsymmetric positive deﬁnite, but P can be an arbitrary square matrix. The\nmatrix F is speciﬁed ahead of time and is not a parameter. For simplicity,\nΣ(cid:16) in (12.2) is dropped as a separate parameter and is incorporated into\nΣζ.\n\nIdentiﬁability\n\nIn the existing work on this model, one preliminary question has been\noverlooked, namely, whether the parameters are identiﬁable. That is, do\nthe parameters determine the second moment structure of z(t). If ||P || < 1\n(where || · || denotes the largest eigenvalue in absolute value), then the\nmodel (12.5)–(12.6) for z(x, t) is stationary. In this section we shall show\nthat if in addition (a) P is nonsingular and (b) F has full rank p, then the\nsecond moment structure of z(t),\n\nAh = E{z(t)zT (t − h)},\n\nh ∈ Z, h ≥ 0,\n\nis determined by the parameters.\n\nFirst let F = U LV T be the singular value decomposition of F , where\nU (n×p) and V (p×p) are column orthonormal, and L(p×p) is diagonal with\npositive elements. Set F − = V L−1U T to be the Moore-Penrose generalized\ninverse of F , so that in particular",
    "chunk_order_index": 123,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-a4580f1d90a88e318b506786843fff9b": {
    "tokens": 1200,
    "content": "zT (t − h)},\n\nh ∈ Z, h ≥ 0,\n\nis determined by the parameters.\n\nFirst let F = U LV T be the singular value decomposition of F , where\nU (n×p) and V (p×p) are column orthonormal, and L(p×p) is diagonal with\npositive elements. Set F − = V L−1U T to be the Moore-Penrose generalized\ninverse of F , so that in particular F −F = Ip. Set z(cid:3)(t) = F −z(t), ζ(cid:3)\n(t) =\n\n\fD-C (DRIFT-CORRELATION) MODELS\nζ = F − Σζ(F −)T . Then\nF −ζ(t), Σ(cid:3)\n\nz(cid:3)(t) = v(t) + ζ(cid:3)\n\n(t).\n\nDeﬁne the matrix autocovariances\n\nh = E{z(cid:3)(t)z(cid:3)T (t − h)}, Bh = E{v(t)vT (t − h)},\nA(cid:3)\nA straightforward recursive expansion of (12.6) shows that\n\nh ≥ 0.\n\n221\n\n(12.8)\n\n(12.9)\n\nB0 =\n\n∞(cid:1)\n\nj=0\n\nP jΣη(P T )j, Bh = P hB0,\n\nh > 0,\n\n(12.10)\n\nand substituting (12.8) in (12.9) yields\n0 = B0 + Σζ, A(cid:3)\n\nA(cid:3)\n\n(12.11)\nKnowing the second moments {Ah, h ≥ 0} of the z(t)-process determines\nthe second moments {A(cid:3)\nh, h ≥ 0} of the z(cid:3)(t)-process. Provided P is non-\nsingular, these quantities determine P , e.g. through\n\nh = Bh, h > 0.\n\n2(A(cid:3)\n\nP = A(cid:3)\nOnce P has been determined, B0 can be found using B0 = P −1A(cid:3)\n1 from\n(12.10)–(12.11). Further, Ση can be found from P and B0 through the\nidentity B0 = Ση + P B0P T , which in turn can be derived from (12.10).\nFinally, Σζ can be determined from the identity A0 = F B0F T + Σζ.\n\n(12.12)\n\n1)−1.\n\nIf P is singular, this approach breaks down. Indeed it is not possible to\nguarantee identiﬁablity in this case without some further restrictions on\nthe parameters.\n\nAn Environmental Example\n\nMardia et al. (1998) analyzed m = 707 daily sulphur dioxide readings from\nMarch 29th 1983 to March 6th 1985. There are n = 14 monitored sites in\nLeeds and its vicinity; see Figure 12.3. This dataset is a part of a larger\ncollection recorded in the UK from 1950s up to the present. The sites largely\nsplit into two clusters, an urban area (Leeds) and a rural area. During this\nperiod a clean air act was introduced. The rural area is a mining area which\nis close to a power station and the clean air act was not fully applied. One\naim is to investigate whether there is any movement of pollution between\nthe two areas.\n\nThe KKF model was implemented in Mardia et al. (1998) using principal\n\nkriging functions in space based on the covariance function\n\nτ (x) = e−(1.3)\n\n√\n\n|x|,\n\nwith a 3-dimensional null space given by the linear functions. It was found\nthat using polynomials for the drift space did not ﬁt the data as well as\n\n\f222\n\nMODELLING STRATEGIES FOR SPATIAL-TEMPORAL DATA\n\nthe principal kriging functions. Also, Σζ was taken to be diagonal, which\nboth simpliﬁes the model and allows for some modest nonstationarity.\n\nVarious exploratory analyses were carried out using maximum likelihood\nestimation for some parameters. A small sequence of ﬁtted surfaces is plot-\nted in Figure 12.4. One conclusion which stands out from this ﬁgure is that\non days 324 (15th Feb. 1984) and 325, there is a sudden jump in the overall\npollution level. Curiously, over this period, highest levels are in Leeds and\nthe lowest levels are in the mining area, the opposite of the typical spatial\npattern at other times.\n\n11\n\n10\n\n 9\n\n 8\n\n12\n\n 7\n\n 6\n\n40\n\n35\n\n30\n\ni\n\ng\nn\nh\nt\nr\no\nN\n\n14\n\n26\n\n13\n\n31\n\n36\nEasting\n\n 5\n\n 3\n\n 2\n\n 4\n\n 1\n\n41\n\nFigure 12.3 Map of the sites for the environmental example. Leeds is in the upper\nleft and the main mining areas are in the lower right.\n\n12.5 C-C (Correlation-Correlation) Models\n\nIn this section we develop a spatial-temporal model that is wholly stochas-\ntic. In discrete time and space, a spatial-temporal autoregressive model\n\n\fC-C (CORRELATION-CORRELATION) MODELS\n\n223\n\n318\n\n0.115\n\n319\n\n0.168\n\n320\n\n0.183\n\n321\n\n-0.001\n\n322\n\n1.121\n\n323\n\n1.267\n\n324\n\n1.754\n\n325\n\n1.",
    "chunk_order_index": 124,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-645e285061dce96f9e8e252b89e754da": {
    "tokens": 1200,
    "content": ") Models\n\nIn this section we develop a spatial-temporal model that is wholly stochas-\ntic. In discrete time and space, a spatial-temporal autoregressive model\n\n\fC-C (CORRELATION-CORRELATION) MODELS\n\n223\n\n318\n\n0.115\n\n319\n\n0.168\n\n320\n\n0.183\n\n321\n\n-0.001\n\n322\n\n1.121\n\n323\n\n1.267\n\n324\n\n1.754\n\n325\n\n1.532\n\n326\n\n1.147\n\nFigure 12.4 Fitted surfaces for 9 time points 318, 319, ..., 326, based on 5 prin-\ncipal kriging functions. The time label appears at the lower left of each plot. At\nthe lower right is a second label giving the distance of the mean of the surface at\nthis time from the overall mean of the data.\n\ntakes the form\n\nz(x, t + 1) =\n\n(cid:1)\n\nu\n\nwuz(x + u, t) + ζ(x, t), x ∈ Zd, t ∈ Z,\n\n(12.13)\n\nwhere u varies in a neighborhood of the origin including u = 0, and the\nweights wu represent a “smearing” or “blurring” eﬀect, so that z(x, t + 1)\ndepends not just on z(x, t), but also on spatially neighboring values. The\nζ(x, t) are assumed to be a stationary process over space (often indepen-\ndent in this discrete setting) and independent for diﬀerent times. Often the\nweights wu are taken to be nonnegative. In this case a necessary condition\nfor stationarity is\n\nu wu < 1.\n\n(cid:2)\n\nOne possibility is for the weights to depend just on nearest neighbors,\n\ne.g. in two dimensions,\n\nw0 = δ1, w(±1,±1) = δ2,\n\n\f224\n\nMODELLING STRATEGIES FOR SPATIAL-TEMPORAL DATA\n\nwith δ1 + 4δ2 < 1.\n\nA version of this process that is continuous in space and discrete in time\n\nis given by\n\n(cid:5)\n\nz(x, t + 1) =\n\nz(x − u)φ(u) du − ψ2z(x, t) + ζ(x, t)\n\n(12.14)\n\nwhere φ(u) denotes the density function of the Nd(0, λ2I) distribution and\nfor each integer t, ζ(x, t) represents a process which is spatially stationary\nand independent for diﬀerent times. Also, the parameter ψ2 represents a\ndamping term. Provided 0 < ψ2 < 1, the process will be stationary in\nspace-time.\n\nLetting time also be continuous leads to a continuous spatial-temporal\nprocess which can be described in terms of a stochastic partial diﬀerential\nequation\n\n∂z(x, t)\n∂t\n\n=\n\nσ2\n\n1\n2\n\nd(cid:1)\n\nl=1\n\n∂z2(x, t)\n∂2x[l]\n\n−ρ2z(x, t)+ζ(x, t), x ∈ Rd, t ∈ R. (12.15)\n\nThe simplest choice for ζ(x, t) is now a continuous space-time version of\nwhite noise, which makes sense only as a generalized random function. See,\nfor example, Whittle (1986), Jones and Zhang (1997) and Brown et al.\n(2000) for this and related processes. It is necessary to take the damping\nterm ρ2 > 0 to ensure stationarity of the process.\n\n12.6 A Uniﬁed Analysis on the Circle\n\nPerhaps the simplest setting in which to compare these diﬀerent modelling\napproaches is on a circle. Let x ∈ [0, 2π) represent sites on the circle, and\nlet time be continuous (for the D-D model) or discrete (for the D-C and\nC-C models). A natural set of functions for F is the set of sines and cosines\nup to order p(cid:3), say, so that p = 2p(cid:3) + 1 (one degree of freedom for the\nconstant term cos(0 · x) = 1, and two degrees of freedom for each order\nα ≥ 1, cos αx and sin αx).\n\nThus, the D-D model takes the form\n\nz(x, t) = gc0(t) +\n\np(cid:1)(cid:1)\n\nα=1\n\n{gcα(t) cos(αx) + gsα(t) sin(αx)} ,\n\n(12.16)\n\nwhere the coeﬃcients gcα(t), gsα(t) ∈ G are time-varying nonrandom Fourier\ncoeﬃcients.\n\nThe model D-C is similar, but the coeﬃcients are now random processes\n\nand time is discrete. Thus,\n\nz(x, t) = vc0(t) +\n\np(cid:1)(cid:1)\n\nα=1\n\n{vcα(t) cos(αx) + vsα(t) sin(αx)} + ζ(x, t),\n\n(12.17)\n\n\fDISCUSSION\n\n225\n\nwhere the {ζ(x, t)} are stationary on the circle and independent for diﬀerent\ntimes.\n\nHere the set of {vcα(t), vsα(t)} follows a vector AR(1) process. If P\nand Ση are diagonal, these AR(1) processes are independent. Typically\nvc0(t) includes a nonzero mean to allow for an overall mean eﬀect",
    "chunk_order_index": 125,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-87298607a35ff6b33820a7f2afcb2a7e": {
    "tokens": 1200,
    "content": "(x, t),\n\n(12.17)\n\n\fDISCUSSION\n\n225\n\nwhere the {ζ(x, t)} are stationary on the circle and independent for diﬀerent\ntimes.\n\nHere the set of {vcα(t), vsα(t)} follows a vector AR(1) process. If P\nand Ση are diagonal, these AR(1) processes are independent. Typically\nvc0(t) includes a nonzero mean to allow for an overall mean eﬀect in the\nspatial-temporal process, but the other coeﬃcients have mean 0. Further,\nsince {ζ(x, t)} is stationary on the circle, it can be shown that if z(x, t) is\nrepresented in a Fourier series, then its Fourier coeﬃcients up to order p(cid:3)\nfollow independent ARMA(1,1) processes.\n\nLast we turn to the C-C models. The periodic version of the continuous-\nspace discrete-time model (12.14) can be given an inﬁnite Fourier series\nrepresentation\n\nz(x, t) = zc0(t) +\n\n∞(cid:1)\n\nα=1\n\n{zcα(t) cos(αx) + zsα(t) sin(αx)} .\n\n(12.18)\n\nThe coeﬃcients satisfy the independent AR(1) models,\n\nzc0(t + 1) = (1 − ψ2)zc0(t) + ζc0,\nzcα(t + 1) = exp(− 1\n2\nzsα(t + 1) = exp(− 1\n2\n\nα2λ)zcα + ζcα,\n\nα2λ)zsα + ζsα, α ≥ 1,\n\n(12.19)\n\nα) distributions. The variances σ2\n\nwhere ζcα, ζsα are the Fourier coeﬃcients of ζ(x, t), with independent\nN (0, σ2\nα are the Fourier coeﬃcients of the\nstationary covariance function on the circle of ζ(x, t) for each t. The ex-\nponential terms arise as Fourier coeﬃcients of the wrapped normal dis-\ntribution (page 50 Mardia and Jupp 2000). Thus, except for the range of\nsummation, this model is a special case of (12.17) with P and Ση diago-\nnal and Σζ = 0 in (12.17). As in that setting, a nonzero mean is usually\nincluded for zc0. Note that the role of the error terms ηcα, ηsα in the\nconstruction of the AR(1) processes vcα, vsα below (12.17) using (12.6) is\nanalogous to the role of the error terms ζcα, ζsα to construct the AR(1)\nprocesses for zcα, zsα in (12.19).\n\n12.7 Discussion\n\nWe have tried to give a uniﬁed strategy to space-time modelling by distin-\nguishing between drift and autocorrelation. More practical examples need\nto be studied to compare the merits of diﬀerent approaches. However, there\nare also other considerations that can be used to guide a modelling strategy.\nHere is a brief summary of some of the issues.\n\n1. Instead of our stochastic process approach to C-C models, it is possible\n\n\f226\n\nMODELLING STRATEGIES FOR SPATIAL-TEMPORAL DATA\n\nto specify directly the space-time autocovariance structures; e.g. Cressie\nand Huang (1999) and Glasbey (1998).\n\n2. The simplest such models are separable in space and time; see, for ex-\nample, Mardia and Goodall (1993) and Kyriakidis and Journel (1999).\n\n3. Physical considerations, e.g. in meteorological data, can be used to guide\n\nmodel formulation (Wikle et al. 2001).\n\n4. There have also been important advances in Bayesian hierarchical mod-\nelling; see, for example, Handcock and Wallis (1994), Wikle et al. (2001),\nand Chapter 11.\n\n5. We have not discussed the subject of space-time point patterns. For\na recent work see, for example, Smith and Robinson (1997) and other\nchapters in this volume, for example Chapter 14.\n\nAcknowledgement\n\nWe wish to express our thanks to Sujit Sahu for helpful comments.\n\n\fCHAPTER 13\n\nSpatio-Temporal Partition Modelling:\nAn Example from Neurophysiology\n\nPeter Schlattmann\n\nJ¨urgen Gallinat Dankmar B¨ohning\n\n13.1 Introduction\n\nNeurophysiology tries to understand the function of the brain. Frequently\nactivation experiments using positron emission tomography (PET) or mag-\nnetic resonance imaging (MRI) are undertaken to map the activation of\ncertain areas of the brain following an experimental stimulus. Such func-\ntional mapping experiments produce data consisting of three-dimensional\nimages where voxel values are indicative of regional neuronal activity. Usu-\nally no prior knowledge is available and thus the analysis proceeds at the\nvoxel level.\n\nIn this setting images of statistics are formed where each voxel has an\nassociated value of a simple statistic. These statistics express the activation\nat the voxel level. Many eﬀorts have been undertaken in order to provide\nmethods for the classiﬁcation of individual voxels in neuro-imaging. More\nprecisely this attempt deals with two problems at a time: For one to assess\nif there are any functional diﬀerences in an activation experiment and sec-\nondly to ﬁnd methods which allow to address",
    "chunk_order_index": 126,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-e60d45a39b912889e888d9ad0ae5d0f9": {
    "tokens": 1200,
    "content": "where each voxel has an\nassociated value of a simple statistic. These statistics express the activation\nat the voxel level. Many eﬀorts have been undertaken in order to provide\nmethods for the classiﬁcation of individual voxels in neuro-imaging. More\nprecisely this attempt deals with two problems at a time: For one to assess\nif there are any functional diﬀerences in an activation experiment and sec-\nondly to ﬁnd methods which allow to address the activity of a voxel at a\ncertain location.\n\nOne of the earliest attempts was the approach by Duﬀy et al. (1981)\nwho apply z-scores or t-scores to EEG scalp data. Friston et al. (1990)\nuse an ANOVA model and Holmes et al. (1996) use a randomization test\nin order to investigate these two questions. In the following we describe\nthe application of methods from spatial epidemiology (Schlattmann and\nB¨ohning 1993) and meta analysis (B¨ohning et al. 1998, B¨ohning 1999)\nto the neuro-imaging problem. A review of spatial partition modelling is\nfound in Chapter 7 in this volume.\n\n13.2 The Neurophysiological Experiment\n\nAn interesting tool to investigate cerebral activity in the time range of mil-\nliseconds are auditory evoked potentials (AEPs) which occur after acoustic\nstimulation of an individual. One of the most prominent AEP is the N1-\n\n\f228\n\nSPATIO-TEMPORAL PARTITION MODELLING\n\ncomponent with a characteristic potential distribution over the head sur-\nface. From the physiological and pathophysiological point of view it is of\nspecial interest to locate the generators of this potential providing a more\ndetailed knowledge about normal or disturbed brain function. Therefore,\na method which locates the cerebral generators of the N1-component from\nthe potential distribution on the surface of the head, is of theoretical and\npractical interest (Gallinat and Hegerl 1994).\n\nThe neurophysiological experiment comprised 22 healthy individuals who\nwere repeatedly presented an auditory stimulus. Evoked responses were\nrecorded with 32 electrodes referred to the central electrode labeled Cz.\nSubjects were seated with closed eyes in a slightly reclined chair with a\nhead rest. An auditory oddball paradigm was employed with frequent non-\ntargets (175 double clicks) and rare targets (55 tones, 1000 Hz). Tones\n(83 dB SPL, 40 ms duration with 10 ms rise- and 10 ms fall time, ISI\nbetween 2 and 5.5 s) generated by a PC-stimulator with Creative Labs\nSoundblaster 16, were presented to both ears in a pseudorandomized order\nby headphones. Subjects were asked to press a button with their dominant\nhand in response to target stimuli. Data were collected with a sampling\nrate of 250 Hz and an analogous bandpass ﬁlter (0,16 – 50 Hz). 350 ms\nprestimulus and 800 ms poststimulus periods were evaluated for 55 target\nstimuli. For artifact suppression, all trials were automatically excluded from\naveraging when the voltage exceeded ±100µV in any one of the 32 channels\nat any time point of the averaging period. For each subject, the remaining\nsweeps were averaged separately for the target stimuli.\n\n13.3 The Linear Inverse Solution\n\nThe major advantage of EEG recordings is given in the fact that changes\nin time may be observed on a millisecond time scale whereas PET or func-\ntional MRI studies can only produce results on a time scale of seconds.\nFurthermore EEG activity is produced directly by the electrical activity\nwith which the brain communicates, rather than the indirect correlates as\nregional blood ﬂow or glucose metabolites, that are imaged by the alter-\nnative functional modalities. The problem to solve is localizing electrical\nsources within the brain which has attracted the EEG community for some\ntime now.\n\nBy tesselating the cortex in N disjoint regions using the Talairach atlas\nby Talairach and Tournoux (1988) the cortex is divided into N = 2394\ncubic areas (voxels). For each of these voxels the probability of belonging\nto a certain anatomic area may be given. Representing the sources in each\nregion by a current dipole oriented normal to the surface with amplitude ji\nthe EEG inverse problem can be expressed in terms of a linear model. The\nlinear forward model relating the N sources j to the M EEG electrodes\n\n\fTHE MIXTURE MODEL\n\n229\n\ncan be written as\n\nΦ = Kj + (cid:3)\nwhere the ith row of the M xN transfer matrix K may be viewed as the\nprojection of the lead ﬁeld (sensitivity) of the ith electrode. The jth col-\numn of K speciﬁes the gain vector for the jth dipole moment. The term (cid:3)\ndescribes noise such as background brain activity or modeling errors. Evi-\ndently since N (cid:2) M the Matrix K is not of full rank and thus the simple\nminimum norm solution ˆj = (K T K)−1KΦ for ˆj is not a suitable solution\nof the inverse problem. Frequently a Tikhonov regularization (Tikhonov\nand Arsenin 1977) which introduces a penalty term is applied to regu-\nlarize the solution. The basic idea is to introduce additional information.\nInstead of minimizing only the norm (cid:3)Φ − Kj(cid:3)2 we introduce additional\ninformation using a functional of j and a Lagrange multiplier λ.\n\n(cid:",
    "chunk_order_index": 127,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-8c5ee6a3f02116fa5d64e318a4782e68": {
    "tokens": 1200,
    "content": "ˆj is not a suitable solution\nof the inverse problem. Frequently a Tikhonov regularization (Tikhonov\nand Arsenin 1977) which introduces a penalty term is applied to regu-\nlarize the solution. The basic idea is to introduce additional information.\nInstead of minimizing only the norm (cid:3)Φ − Kj(cid:3)2 we introduce additional\ninformation using a functional of j and a Lagrange multiplier λ.\n\n(cid:3)Φ − Kj(cid:3)2 + λ(cid:3)Ij(cid:3)2\n\nThe solution is given by:\n\nˆj =\n\n(cid:1)\nKT K + λI\n\n(cid:2)−1 KΦ\n\nThe parameter λ may be found by trial and error using the trade oﬀ curve\nbetween a purely data driven solution and a purely functional driven so-\nlution. Instead of assuming constant activity by introducing the identity\nmatrix I more elaborate functionals of j are possible. Here we use the\nsolution proposed by Pascal-Marqui et al. (1994) who apply the discrete\nLaplace operator B to the sources j. The idea here is that neighboring\nvoxels have similar activity, which is quite compatible with neurophysiol-\nogy. Introducing a diagonal weight matrix W with wii = (cid:3)K i(cid:3) they solve\nthe constrained minimization problem:\n\nmin(cid:3)W Bj(cid:3)2\nunder the constraint Φ = Kj with respect to j. Using Lagrange multipliers\nthe solution is given by:\n\nˆj = T Φ\n\nwith T = (W BBT W )−1K T (K(W BBT W )K T )−1Φ\n\nApplying this algorithm to the measured scalp data for a single point\nin time we obtain the data structure for a given individual as shown in\nTable 13.1.\n\n13.4 The Mixture Model\n\n13.4.1 Initial Preparation of the Data\n\nOnce the inverse solution is determined for each point in time two diﬀerent\ntime points can be considered in order to quantify the activation due to the\nauditory stimulus. Let Ai(l) denote the current density before activation\n\n\f230\n\nSPATIO-TEMPORAL PARTITION MODELLING\n\nTable 13.1 Data structure of the inverse solution\n\nVoxel\n\nx-coord.\n\ny-coord.\n\nz-coord.\n\nˆji(x10−3)\n\n1\n2\n3\n. . .\n2394\n\n-52\n-45\n-38\n. . .\n-17\n\n-11\n-11\n-11\n. . .\n10\n\n-41\n-41\n-41\n. . .\n71\n\n1.748\n1.887\n1.959\n. . .\n3.10\n\nand Bi(l) the current density after the stimulus for the ith subject at the lth\nvoxel. In the present study we chose A to be the baseline before the stimulus\nand B as the time point 84 milliseconds after the auditory stimulus. That\nmeans for each subject we do have a set of independent mean diﬀerence\nimages for each subject i,\nj = 1, . . . , m and\nat voxels l = 1, . . . , N .\n\ni = 1, . . . , n at repetition j,\n\n∆i(l) =\n\nm(cid:3)\n\nj=1\n\n1\nm\n\n(Bij(l) − Aij(l)) i = 1, . . . , n,\n\nj = 1, . . . , m l = 1, . . . , N\n\nThe mean and variance images of these data are estimated as ¯∆(l) and\nS2(l) respectively:\n\nul := ¯∆(l) =\n\n1\nn\n\nn(cid:3)\n\ni=1\n\n∆i(l)\n\nl := S2(l) =\nσ2\n\n1\nn − 1\n\nn(cid:3)\n\ni=1\n\n[∆i(l) − ¯∆(l)]2\n\nThus at each voxel l we do have a mean value with corresponding variance\naveraged over the n individuals.\n\n13.4.2 Formulation of the Mixture Model\n\nThe ﬁrst question mentioned in the introduction, i.e. is there any activation\ntranslates into investigation of unobserved heterogeneity. This implies that\nthere are subpopulations of voxels which show diﬀerent activation after\nstimulus. A natural choice to investigate unobserved population hetero-\ngeneity is given in ﬁnite mixture models. Frequently we assume a density\nf (j, µ) for the phenomenon of interest. The parameter µ denotes the pa-\nrameter of the population, whereas u is in the sample space U, a subset of\nthe real line. Frequently this model is too strict and a natural assumption\nwould be the heterogeneous case, where we assume that the population\nof interest consists of several subpopulations denoted by µ1, µ2, . . . , µk. In\n\n\fTHE MIXTURE MODEL\n\n231\n\ncontrast to the homogenous case we have the same type of density for each\nsubpopulation but diﬀerent parameters µj in the jth subpopulation. In\nthe sample u1, u2, . . . , uN it is not observed to which subpopulation the\ninformation belongs. Therefore this phenomenon is called unobserved het-\nerogeneity. Now let a latent variable Z describe population membership.\nThen the joint density f (u, z) may be written as:\n\nf (u, z) = f (u|z)f (z) = f (u|µz)pz\n(",
    "chunk_order_index": 128,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-07f592cd39f852ef2d14060320c9ec30": {
    "tokens": 1200,
    "content": "jth subpopulation. In\nthe sample u1, u2, . . . , uN it is not observed to which subpopulation the\ninformation belongs. Therefore this phenomenon is called unobserved het-\nerogeneity. Now let a latent variable Z describe population membership.\nThen the joint density f (u, z) may be written as:\n\nf (u, z) = f (u|z)f (z) = f (u|µz)pz\n(13.1)\nwhere f (u|z) is the density conditionally on membership in subpopulation\nz. Thus the unconditional density f (u) is given by the marginal density\nsumming over the latent variable\n\nf (u, P ) =\n\nk(cid:3)\n\nj=1\n\nf (u|µj)pj\n\n(13.2)\n\nIn this case pj is the probability of belonging to the j-th subpopulation\nhaving parameter µj. As a result the pj are subject to the constraints\npj ≥ 0 and p1 + · · · + pk = 1. Thus (13.2) denotes a mixture distribution\nwith mixing kernel f (ui|µj, σ2\n\n(cid:4)\n\ni ) and mixing distribution\n. . . µk\npk\n. . .\n\nµ1\np1\n\n(cid:5)\n\nP ≡\n\n(13.3)\n\n1√\n\ni ) =\n\nin which weights p1, . . . , pk are given to parameters µ1, . . . , µk. Here we\ndeﬁne f (ui, µj, σ2\ni ). Thus in analogy to\nmeta-analysis we consider the individual voxel as a study of over n individ-\nuals and use the normal density with ﬁxed variance σ2\ni considered as known.\nEstimation of the parameters of the mixing distribution P is predominantly\ndone using maximum-likelihood (ML). Given a sample of:\n\n2 (ui − µj)2/σ2\n\nexp(− 1\n\n2πσ2\ni\n\niid∼ f (u|P ),\n\nui\n\ni = 1, . . . , N\n\nwe are interested in ﬁnding the ML estimates of P which maximize the log\nlikelihood function:\n\nl (P ) = log L(P ) =\n\nlog\n\nN(cid:3)\n\nk(cid:3)\n\nf (ui, µj, σ2\n\ni )pj\n\ni=1\n\nj=1\n\nPlease note that also the number of components k needs to be estimated\nas well. Two cases must be distinguished: In the ﬂexible support size case\nP may vary in the set of all probability measures Ω. This guarantees that\nΩ is a convex set and that l (P ) is a concave functional on the set of all\ndiscrete probability measures. This is the basis for the strong results of non-\nparametric mixture distributions. An eﬃcient algorithmic solution is given\nby the VEM algorithm which looks on a ﬁxed grid of parameters for grid\npoints with positive support without the need to make an initial assump-\ntion about the number of components k. Details may be found in B¨ohning\n\n\f232\n\nSPATIO-TEMPORAL PARTITION MODELLING\n\nTable 13.2 ML estimates of the ﬁnite mixture model\nWeights ˆpj Parameter ˆµj (x10−3)\n\n0.0062\n0.0269\n0.0589\n0.1089\n0.1564\n0.2443\n0.2616\n0.1212\n0.0156\n\n0.380\n0.667\n0.952\n1.282\n1.639\n2.084\n2.615\n3.350\n4.652\n\net al. (1992) and B¨ohning (1999). The solution of the VEM-algorithm may\nthen be used as starting values for the EM-algorithm by Dempster et al.\n(1977b) which gives a solution for the ﬁxed support size case.\n\nApplying the mixture algorithm, i.e. the combination of the VEM and\nthe EM-algorithm as outlined before leads to a mixture distribution with\nten components. In order to estimate the number of components we apply\nthe nonparametric bootstrap, as described by Schlattmann and B¨ohning\n(1997). This leads to a ﬁnal solution with nine components as shown in\nTable 13.2. The estimation of the mixture model has been done with the\nsoftware C.AMAN (B¨ohning et al. 1992, B¨ohning 1999) which can handle in\nits UNIX-version large data sets as the present one with 2394 data points.\n\nThe ﬁrst question of interest in activation experiments deals with het-\nerogeneity of activation. Clearly for these data we ﬁnd heterogeneity of\nactivation. There are a total of nine subpopulations ranging from a sub-\npopulation mean of 0.38x10−3 to 4.652x10−3. Evidently, there are about\n14% of the voxels which show a rather strong activation after 84 ms post\nauditory stimulus.\n\n13.5 Classiﬁcation of the Inverse Solution\n\nThe second objective of neurophysiological activation studies is to identify\nthe activation status of the individual voxel. Classiﬁcation of the individual\nvoxel is straightforward in the ﬁnite mixture model setting. The ith voxel\nmay simply be categorized applying Bayes’ theorem as follows:\n\n\fCLASSIFICATION OF THE INVERSE SOLUTION\n\n233\n\nFigure 13.1 Talairach slice of the acoustic cortex\n\nP rP (",
    "chunk_order_index": 129,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-468e94d474e1ccff11498aa1b05fc973": {
    "tokens": 1200,
    "content": ".5 Classiﬁcation of the Inverse Solution\n\nThe second objective of neurophysiological activation studies is to identify\nthe activation status of the individual voxel. Classiﬁcation of the individual\nvoxel is straightforward in the ﬁnite mixture model setting. The ith voxel\nmay simply be categorized applying Bayes’ theorem as follows:\n\n\fCLASSIFICATION OF THE INVERSE SOLUTION\n\n233\n\nFigure 13.1 Talairach slice of the acoustic cortex\n\nP rP (Zij = 1 | Ui = ui) =\n\n(cid:6)\n\nP r(Ui = ui | Zij = 1)P r(Zij = 1)\nl P r(Ui = ui | Zil = 1)P r(Zil = 1)\n\n=\n\nˆpjf (ui, ˆµj, σ2\ni )\n(cid:6)\nl ˆplf (ui, ˆµl, σ2\ni )\n\nThe individual voxel is now categorized into the category for which the\nprobability of belonging becomes maximal. Figure 13.1 shows a slice out of\nthe Talairach atlas where the classiﬁcation has been performed in this way.\nDue to the relatively large number of components and the property of the\nsoftware LORETA only to provide a continuous scale for the display of the\ndata we focus on the areas with high activity.\n\nIn terms of interpretation we ﬁnd several areas which show strong acti-\nvation which are consistent with neurophysiological knowledge. The source\nanalysis of the N1-component revealed two main areas of activity namely\nthe superior temporal lobe on both sides, which contain the primary and\nsecondary auditory cortex. This localization is in agreement with intrac-\nerebral recordings in humans (Knight et al. 1988) as well as neuro-imaging\nstudies (Tzourio et al. 1997) employing auditory stimulation. The greater\nleft than right activity observed in the present data is in line with a pre-\nvious magnetencephalographic study (Elberling et al. 1982) and may be\ndue to the known anatomical asymmetry of the superior temporal cortex\n\n\f234\n\nSPATIO-TEMPORAL PARTITION MODELLING\n\nwith a larger area on the left side (Galaburda and Sanides 1980) The pre-\nsented method is a useful tool linking surface measured potentials to their\ngenerating cerebral structures.\n\n13.6 Discussion\n\nThe statistical evaluation of activation experiments is quite important in\nneuro-imaging. For functional imaging techniques such as PET, functional\nMRI and electrophysiological methods based on the inverse solution there\nis the need to identify heterogeneity in space after an activation in time.\nThe ﬁnite mixture model presented here allows a model-based classiﬁcation\nof the individual voxel which requires only few assumptions due to its semi-\nparametric nature. The mixing distribution P is nonparametric and only\nthe mixing kernel f (x, µ, σ2) requires a parametric assumption. This ap-\nproach to the classiﬁcation of the individual voxel may be performed unsu-\npervised, i.e. using the mixture algorithm and the nonparametric bootstrap\nthe analysis may be performed in an automated way. Likewise the stability\nof the classiﬁcation may be investigated using the parametric bootstrap\n(McLachlan and Basford 1988). This approach can also be applied to the\ndata of a single individual. This allows in contrast to other methods classi-\nﬁcation of individual PET or MRI images. In this case the variance of the\nindividual subpopulations needs to be estimated. In general the likelihood is\nunbounded in this case, thus either a common variance is ﬁxed or estimates\nbased on local maxima of the EM-algorithm can be applied. However, the\nproperties of these estimates still need to be investigated thoroughly.\n\nOne drawback of the method is given by the fact, that it assumes inde-\npendence of the observations. Although heterogeneity may mimic autocor-\nrelation and vice versa, as is well known from the area of disease mapping,\nno particular correlation structure can be modeled. Work is in progress to\nextend the methodology to hidden Markov random ﬁelds which allows the\nintroduction of more sophisticated correlation structures.\n\n\fCHAPTER 14\n\nSpatio-Temporal Cluster Modelling of\nSmall Area Health Data\n\nA.B. Clark and A.B. Lawson\n\n14.1 Introduction\n\nThe spatial analysis of small area health data is a topic which has de-\nveloped greatly in the last decade. In this development, there has been\nconsiderable interest in the analysis of clustering of disease. This has come\nabout in response to a need within public health to be able to analyse\ndisease maps with a view to establishing whether clustering exists, particu-\nlarly where a possible environmental hazard may be related to the adverse\ndisease outcome. Much of the methodology developed in this area has fo-\ncussed on hypothesis testing and little has focussed on statistical modelling\nof clustering. Recent reviews of these developments can be found in Law-\nson and Kulldorﬀ (1999), and Lawson (2001), Chapter 6. There are many\nadvantages to modelling of clusters, not least of which is the ﬂexibility\nto introduce covariates and to be able to include a range of descriptive\nparameters within the ﬁtting process. While relatively little development\nof spatial models has been witnessed, the analysis of clustering in spatio-\ntemporal small area health data has seen even less development.\n\nIn Chapter 1 of this volume, an introduction of the concepts of cluster\n\nmodelling are presented.\n\n14.2 Basic Cluster Modelling approaches\n\nIn this section we examine some basic approaches to clustering. A basic\nworking",
    "chunk_order_index": 130,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-dffceeb048cb335ae9a81595e3b96426": {
    "tokens": 1200,
    "content": "to introduce covariates and to be able to include a range of descriptive\nparameters within the ﬁtting process. While relatively little development\nof spatial models has been witnessed, the analysis of clustering in spatio-\ntemporal small area health data has seen even less development.\n\nIn Chapter 1 of this volume, an introduction of the concepts of cluster\n\nmodelling are presented.\n\n14.2 Basic Cluster Modelling approaches\n\nIn this section we examine some basic approaches to clustering. A basic\nworking deﬁnition of clustering is given by Knox (1989) as: ‘a geographi-\ncally bounded group of occurrences of suﬃcient size and concentration to\nbe unlikely to have occurred by chance’. In this deﬁnition, it is implied that\ncloseness of cases of disease is a criteria which is submitted to a statistical\ntest of some kind. The deﬁnition is based on case event data, i.e. where\nthe locations of cases of disease are known and are to be analysed. Here\nwe will consider two basic data forms: case events and counts of disease\ncases within arbitrary administrative units (such as census tracts or zip\ncodes). In Knox’s deﬁnition there is no restriction on the form of the ‘clus-\n\n\f236\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\nter’. In the situation where counts are to be considered then an equivalent\ndeﬁnition could be: ‘a geographically bounded group of regions with disease\ncounts of suﬃcient size and concentration to be unlikely to have occurred\nby chance’. It is also implicit in the deﬁnition that spatial variation in the\npopulation ‘at risk’ from the disease of interest is taken into consideration\nwithin the statistical testing procedure.\n\nHere, as well as distinguishing between case event and count data, we\nalso introduce the distinction between methods which assess the overall\nclustering tendency of the disease map (general or non-speciﬁc clustering)\nand those methods which aim to assess where clusters occur on maps (spe-\nciﬁc clustering). Our focus in cluster modelling is on speciﬁc clustering and\nmethods for modelling the locations of clusters.\n\n14.2.1 Case Event Data Models\n\nFor case event data, often the spatial distribution of the population ‘at\nrisk’ is represented by the distribution of a control disease. In this situa-\ntion, many cluster testing procedures use distance measures between cases\nand neighbouring cases, or between cases and control disease events as their\nbasic tool for describing the clustering behaviour of the cases. In the situa-\ntion where counts of disease are examined, it is the level of count and levels\nwithin neighbouring regions that determine whether a group of regions is\nregarded as a cluster.\n\nInter-Event versus Hidden Process Modelling\n\nInitially we will consider a disease map consisting of spatial coordinates of\nthe location of cases of disease. Often such case event data can be considered\nto form a point process, and further it is also assumed that a conditional\nﬁrst order intensity can be speciﬁed for the events of the process. This\nintensity which is usually assumed to be continuous over space, speciﬁes\nthe local aggregation of cases on the map, and can be a function of a variety\nof factors. For example, spatial covariates may aﬀect the distribution of\ncases (e.g. environmental pollution gradients). Alternatively, the intensity\ncould be deﬁned at an arbitrary location of s conditionally as a function\nof a hidden process of cluster centres, or of the locations cases around the\narbitrary location. We deﬁne the intensity at s as:\n\nλ(s|{cj\n\n}, {xi}, θ),\nwhere {xi} is the realisation of n cases, {cj\n} is a set of m putative clus-\nter ‘centres’ and θ is a p−valued parameter vector. We could also include\ndependence on covariates here but this is not considered in the general spec-\niﬁcation at this point. We envisage that clustering can be modelled by the\nappropriate speciﬁcation of this intensity. In descriptive clustering studies\n\n(14.1)\n\n\fBASIC CLUSTER MODELLING APPROACHES\n\n237\n\noften the degree of local aggregation is assessed via the estimation of the\nequivalence of a spatial covariance function (for point events this would be\na K(t) function (Diggle 1983)). Here, we attempt to consider clustering via\nthe intensity function, the nature of the clustering often being controlled by\nprior distributions for important clustering parameters. The speciﬁcation\nin equation (14.1) can be simpliﬁed by considering two general models for\nclustering: models where dependence is deﬁned by the locations of cases of\ndisease (inter-event models) and models where dependence is with an un-\nobserved process of ‘centres’ (hidden process models). Inter-event models\ncan be speciﬁed by:\n\nwhereas hidden process models can be speciﬁed by:\n\nλ(s|{xi}, θ),\n\nλ(s|{cj\n\n}, θ).\n\n(14.2)\n\n(14.3)\n\nFor inter-event models the intensity at any case event must be speciﬁed\nconditionally on the other events : λ(xi|{x}−i, θ), where {x}−i denotes the\ncase event set with the i th event removed. Notice that the inter-event mod-\nels deﬁned here are close in form to nonparametric approaches to clustering\nwhere, for example, the local density of events is deemed to be a smooth\nfunction of the locations of other events (Kelsall and Diggle 1998). A vari-\nant of these models could specify dependence on control disease events, but",
    "chunk_order_index": 131,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-874be0d8cc7fe067a180d8597e8dcb20": {
    "tokens": 1200,
    "content": "−i, θ), where {x}−i denotes the\ncase event set with the i th event removed. Notice that the inter-event mod-\nels deﬁned here are close in form to nonparametric approaches to clustering\nwhere, for example, the local density of events is deemed to be a smooth\nfunction of the locations of other events (Kelsall and Diggle 1998). A vari-\nant of these models could specify dependence on control disease events, but\nwe assume here that variation in the population background is included\nelsewhere within the parameterisation of the λ(.) function.\n\nAn example of an inter-event model which could be envisaged is:\n\nλ(s|{xi}, θ) = ρ.g(s).[η+\n\nh(s − xi; θ)/g(xi)].\n\n(14.4)\n\n(cid:1)\n\n{xi}\n\nHere, g(s) is a function representing the background ‘at risk’ population,\nη is a constant (usually 1.0) which allows the null hypothesis of cases dis-\ntributed from the background variation alone, h(.) is a prespeciﬁed cluster\ndistribution function which describes the relationship between locations\nand events. Clearly in this speciﬁcation the localised intensity is a func-\ntion of the spatial aggregation of the realisation of cases. Modiﬁcations of\nthe summation component could be envisaged where nearest neighbours or\nneighbours within a distance range could be included only in the sum. In\nfact the distance range (δx) for the neighbourhood sum could be regarded\nas a clustering parameter, thus:\n\nλ(s|{xi}, θ) = ρ.g(s).[η+\n\nh(s − xi; θ)/g(xi)].\n\n(14.5)\n\n(cid:1)\n\n{xi∈ δx}\n\nAnother possible variant, is to hypothesise that the intensity in (14.4) is\nvalid and the θ parameters consist, at least in part, of a set of cluster spread\nparameters {κi} i = 1, ..., n, one for each observation. Here the spread\n\n\f238\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\nparameters, describing localised aggregation of cases, would be unknown\nand have to be estimated.\n\nEstimation for these inter-event models is complicated by the fact that for\nany realisation the likelihood is not readily available due to the conditioning\non the other events. It is possible to formulate a Bayesian hierarchical model\nfor these intensities, and this can help to identify model components but the\nconditioning in the likelihood doesn’t allow simple progress. One possibility\nis to assume a pseudo-likelihood for the data, given that small area disease\nclusters are likely to be weakly expressed and that ignoring the correlation\nin the pseudo-likelihood should not be serious for such weak correlation.\n\nThe alternative form of cluster model, that of the hidden process model,\n\nis typically speciﬁed thus:\n\nλ(s|{cj}, θ) = ρ.g(s).[η+\n\nm(cid:1)\n\nj=1\n\nh(s − cj; θ)].\n\nwhere ρ is a scaling parameter representing the relative frequency of cases\nto controls. Here, the {cj} form a hidden process, usually a point process,\nso that they represent unobserved locations. Usually both the {cj} and m\nare unknown and must be estimated.\n\nThe idea of a hidden process is not limited to a set of point locations.\nInstead, some other form of object process could be considered. For exam-\nple, if clusters were considered to be of linear form, then a line segment\nprocess could be included. Further still, a mixture of hidden processes could\nbe conceived (e.g. point and line clusters representing diﬀuse and road or\nriverside clusters, or a non-speciﬁc random eﬀect component and a cluster\nprocess).\n\nOther forms of hidden process could be considered. For example, it is\npossible to consider that the non-spatial marginal distribution of risk con-\nsists of a mixture of risk levels and a map of risk can be classiﬁed into\nwell-deﬁned risk classes or partitions. For count data, this has been pro-\nposed by Schlattmann and B¨ohning (1993) and Knorr-Held and Rasser\n(2000). It has also been used to provide a nonparametric trend model for\ncounts (Denison and Holmes (2001), see also Chapter 7 in this volume).\nIn the above models it is often natural or necessary to introduce prior dis-\ntributions for the components of models (e.g. the number and location of\ncluster centres; the number of and level of risk in partitions). Hence, it is of-\nten necessary to design a Bayesian hierarchical modelling approach to clus-\nter analysis. Posterior sampling via Markov chain Monte Carlo (MCMC)\nalgorithms is often employed and for mixture problems with unknown num-\nbers of components (cluster locations or risk levels), reversible jump (RJ)\nor birth-death (BD) MCMC usually has to be employed (Knorr-Held and\nRasser 2000, Stephens 2000, Cressie and Lawson 2000).\n\n\fBASIC CLUSTER MODELLING APPROACHES\n\n239\n\n14.2.2 Small Area Count Data Models\n\nFor small area count data a variety of clustering models can be envisaged.\nThe inter-event models of equations (14.4-14.5) can be modiﬁed straightfor-\nwardly to the count case. For example, for i = 1, ..., n regions, one version\nof model (14.4) could be deﬁned for counts as:\n\nn(cid:1)\n\nE(yi) = ρei[α +\n\nyj",
    "chunk_order_index": 132,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-76ef45308d20bed4a9984d240d77793e": {
    "tokens": 1200,
    "content": "Small Area Count Data Models\n\nFor small area count data a variety of clustering models can be envisaged.\nThe inter-event models of equations (14.4-14.5) can be modiﬁed straightfor-\nwardly to the count case. For example, for i = 1, ..., n regions, one version\nof model (14.4) could be deﬁned for counts as:\n\nn(cid:1)\n\nE(yi) = ρei[α +\n\nyj\nej\n\nh(xi − xj; κj)],\n\nj=1\nwhere xi is the centroid of the i th region, and yi, ei the observed and\nexpected count in the i th region respectively, and clustering is controlled\nby κj parameters assigned locally.\n\nPartition models have also been proposed as speciﬁc cluster models, al-\nthough they appear to be better suited to nonparametric trend estimation,\nas they do not parameterise cluster locations themselves. A further possi-\nbility is to conceive of groupings of regions controlled by a prior distribution\nwhich controls the cluster form. This has been advocated by Gangnon and\nClayton (2000) and Chapter 8, in this volume.\n\n14.2.3 Spatio-Temporal Extensions to Cluster Models\n\nIn principle, it is straightforward to extend many of the cluster models\nin Section 14.2 to spatio-temporal settings. For example, if the approach\nutilising ﬁrst order intensities is used, then we can deﬁne a spatio-temporal\nﬁrst order intensity as\n\nλ(s,t|{xi,ui}, {Φ}, θ),\nwhere {xi,ui} are the set of case events indexed by location (xi) and time\nof occurrence/diagnosis (ui), and {Φ} is a set of cluster terms which may\nbe deﬁned for spatial, or temporal or spatio-temporal cluster eﬀects. Many\ninteresting issues arise in this context concerning appropriate parameter-\nisation of these terms, as there could potentially be a large number of\ninteractions between space and time. Finally an interesting feature of mod-\nels with temporal components is the fact that conditioning on previous\nobserved events is possible. For example, the inter-event models used could\nbe deﬁned as either\n\nλ(s, t|{xi,ui}, {Φ}, θ),\n\nor\n\nλ(s,t|{xi,ui : ui < t}, {Φ}, θ),\nor a combination of these dependencies could be assumed, depending on\nwhether the model exploits this conditioning or not. In the next section a\nhidden process space-time model is deﬁned and applied to a birth abnor-\nmality case study.\n\n\f240\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\n14.3 A Spatio-Temporal Hidden Process Model\n\nIn this section, we propose a model that can be used to study the spatio-\ntemporal distribution of small area health data (disease incidence or preva-\nlence) either at individual case level (i.e. date and location of\nthe cases\nknown) or at some aggregate level where the count of disease is only avail-\nable within a space-time unit. The model proposed here, has components\nwhich represent localised increases in excess risk (i.e. clustering).\n\nCurrent methodology for the assessment of spatio-temporal clustering\ndates back to the work of Knox (1964) who essentially reduced the problem\nto a 2 way contingency table consisting of the numbers of cases and controls\nthat are cross-classiﬁed as being close in time and being close in space for\na predeﬁned distance. Mantel (1967) generalised Knox’s test by deﬁning\ntemporal closeness and spatial closeness for a number of distances and\nthen summing over the distances. Recent work by Diggle and coworkers\n(Diggle et al. 1995) who use Ripley’s K(t) function is similar in spirit to\nKnox’s test. More recently Kulldorﬀ and Nagarwalla (1995) have developed\na spatio-temporal scan test. However, all these tests have disadvantages. For\nexample, they cannot allow for covariates, Knox’s test requires an arbitrary\nspatial and temporal lag to be deﬁned, and they are subject to bias from\nthe choice of study region. In addition, with the exception of the scan test,\nthey are designed for the assessment of overall spatio-temporal clustering\nand not the detection of the locations of clusters in space-time.\n\nThe methods developed here are based on spatio-temporal mixture mod-\nels, and are illustrated using a data set of post-coded birth abnormalities\nin Tayside, Scotland, between January 1991 and December 1995.\n\n14.4 Model Development\n\nIn this case study, we consider the situation where the residential loca-\ntion of cases and the time of birth is known and an appropriate point\nprocess model is considered. These deﬁne the coordinates of the locations\nin space-time as {xi,ui}. We consider a realisation of n such case events\n{xi,ui}i = 1, ...., n within spatial window A and temporal window T . We\nassume that the data can be modelled using a modulated heterogeneous\nPoisson process with ﬁrst order intensity λ(s, t). With this intensity we need\nto take account of the underlying variation in population. For example, if\nwe were dealing with Sudden Infant Death Syndrome then we would need\nto allow for the diﬀering number of live births throughout the study region.\nThis modulation, or ‘at risk’ background, is assumed to act multiplicatively\non the intensity. Thus we assume an intensity of the form",
    "chunk_order_index": 133,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-2e0a48e2f617e43dcfaf8b7ba395d65a": {
    "tokens": 1200,
    "content": "a modulated heterogeneous\nPoisson process with ﬁrst order intensity λ(s, t). With this intensity we need\nto take account of the underlying variation in population. For example, if\nwe were dealing with Sudden Infant Death Syndrome then we would need\nto allow for the diﬀering number of live births throughout the study region.\nThis modulation, or ‘at risk’ background, is assumed to act multiplicatively\non the intensity. Thus we assume an intensity of the form\n\nλ(s, t) = g(s,t).r(s, t; z),\n\n(14.6)\n\n\fMODEL DEVELOPMENT\n\n241\n\nwhere g(., .) is the background of the disease, r(., .; z) is the relative risk\nfunction at {s, t} which can depend on measured covariates z, which may\n(or may not) be spatially deﬁned, or on underlying cluster centre locations\n(unspeciﬁed for brevity). The particular parameterisation of r(.) depends\nupon the application of interest. For example, for focused clustering z could\ninclude the distance and angle from a putative health hazard (Lawson\n1993b, Diggle 1990) but might also include some temporal component.\nNotice that g(.,.) is a nuisance function of which we must take account,\nin order to make reasonable inferences about λ(s,t), but which is not the\nprimary focus of the analysis.\n\nFor clustering we consider the intensity to be increased around notional\ncluster centres. Our aim is to estimate these putative centres both in their\nlocations and number. We consider these centres to be the primary under-\nlying source of heterogeneity in the excess risk. This approach is distinct\nfrom general random eﬀect modelling of spatio-temporal risk variation (see\ne.g. Zia et al. (1997), Waller et al. (1997b), and also Chapters 11 and 12 in\nthis volume) which assumes that heterogeneity is a random disturbance in\nthe level of the intensity. Often this disturbance is modelled by a log Gaus-\nsian prior distribution within a hierarchical Bayesian formulation. That\napproach cannot directly model locations of clusters and also makes global\nassumptions about the nature of heterogeneity which may not always be\ntenable, e.g. in sparse disease incidence studies.\n\nWe can envisage three diﬀerent types of increased risk in our cluster\n\nmodel formulation:\n\n1. The disease may increase for a period of time and then return to its\nprevious level throughout the whole spatial study region. We shall call\nthis a temporal cluster.\n\n2. The disease may be elevated in a region of space throughout the whole\n\nstudy period. We shall call this a spatial cluster.\n\n3. The disease may be elevated in a region of space and for a period of\n\ntime. We shall call this a spatio-temporal cluster.\n\nEach of these types of cluster is deﬁned by its persistence properties,\nthat is, a temporal cluster must persist over the full study region, a spatial\ncluster must persist over the full time period and a spatio-temporal cluster\nis non-persistent. This has implications for the choice of both study region\nand period. If the study region is too large we may not detect a temporal\ncluster and if the period is too long we may not detect a spatial cluster.\nIt is for these reasons that the choice of study period and region is still\nof importance in a modelling framework just as with a hypothesis testing\nframework.\n\nIf we further assume that these three cluster types act independently and\n\n\f242\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\nadditively on the ﬁrst order intensity of the process we may write\n\nλ(s, t) = g(s,t). exp(βT z)m{c1, c2, c3, s,t},\n\n(14.7)\n\nwhere\n\nm{c1, c2, c3, s,t} = {1 + α1\n\nns(cid:1)\n\ni=1\n\nK(s − c1i) + α2\n\nnt(cid:1)\n\ni=1\n\nK(t − c2i)\n\n+α3\n\nnst(cid:1)\n\ni=1\n\nK((s,t) − c3i)},\n\nwhere {c1i}, i = 1, ..., ns are the spatial cluster centres, {c2i}, i = 1, ..., nt\nare the temporal cluster centres, {c3i}, i = 1, ..., nst are the spatio-temporal\ncluster centres. The ‘weights’ {αj}, j = 1, 2, 3 represent the increase in\nrelative risk invoked by the cluster centres. In addition, βT z is a linear\npredictor, a function of additional covariates, which can be included in the\nmodel formulation. These covariates could be spatial or temporal trend, or,\nfor example area level deprivation indices. The cluster distribution function\nK(.) describes the density of cases around the centre. This can take a\nvariety of forms. For example, we may assume that it is more likely for\ncases to occur near the cluster centre. The constant term (one) allows the\nintensity to reduce to the ‘at risk’ background level as we get further away\nfrom the cluster centres (in both space and time). Notice also that as we get\nfurther away in time, both the temporal and spatio-temporal components\ndecay to zero and we are left with pure spatial clustering.\n\nThe formulation above has the advantage of providing a ﬂexible mod-\nelling strategy for diﬀerent types of clustering. For example, if it were\nthought the data only exhibited temporal clustering we could",
    "chunk_order_index": 134,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-070ac159aa2145848f6052fb7c0889d8": {
    "tokens": 1200,
    "content": "risk’ background level as we get further away\nfrom the cluster centres (in both space and time). Notice also that as we get\nfurther away in time, both the temporal and spatio-temporal components\ndecay to zero and we are left with pure spatial clustering.\n\nThe formulation above has the advantage of providing a ﬂexible mod-\nelling strategy for diﬀerent types of clustering. For example, if it were\nthought the data only exhibited temporal clustering we could set α1 = α3 =\n0. Further, because we examine posterior samples of the cluster centres and\nnumber of centres, within a Bayesian sampling algorithm, we can examine\na variety of posterior conﬁgurations of number and location of centres, and\noverlays of these realisations can provide evidence for diﬀerent spatial and\ntemporal scales of clustering. Further extensions of this approach could\ninclude cluster distribution functions which have spatially-dependent vari-\nances which allow variable sizes of clusters, or the inclusion of conventional\nrandom eﬀects (in addition to cluster terms). The extensions have been de-\nscribed for the spatial case by Lawson (1995) and Lawson (2000). However,\nin this paper, we conﬁne our attention to the simpler case where clusters\nhave a constant variance parameter (though the variance is sampled as a\nparameter in the posterior sampling algorithm), and no additional random\neﬀects are admitted.\n\nThe properties of this model and its associated inference, in space, are\ndiscussed at length in Lawson and Clark (1999b). It should also be noted\nthat the application of this type of modelling is not restricted to epi-\n\n\fMODEL DEVELOPMENT\n\n243\n\ndemiology but can also be made to problems in geosciences (Cressie and\nLawson 2000) and the approach may also have application in other ﬁelds\nsuch as astrostatistics.\n\n14.4.1 Estimation of g(s,t)\n\nThe estimation of the background intensity, g(s,t), must be considered\nsince it is a nuisance function of which we need take account. It is natural\nto consider some nonparametric estimate of g(s,t), as we do not wish to\nmake inferences on g(s,t). This estimate is often based on the spatial dis-\ntribution of some measure of the ‘at risk’ background. In early work on fo-\ncused clustering, Diggle (1990) and Lawson and Williams (1994) suggested\nconditioning on such an estimated background, i.e. a plug-in estimate was\nused. However, subsequent inference did not take account of the underly-\ning variability in this estimation. In response to this problem, Diggle and\nRowlingson (1993) proposed a model based on the location of cases and the\ndistribution of the locations of a control disease, and suggested a regression\nmodel which conditioned out the g(s,t) from the analysis.\n\nLawson and Clark (1999a) proposed a Bayesian method which allows\nthe exploration of the full joint posterior distribution of the smoothing\nparameter in the nonparametric estimator of g(s,t). Lawson and Williams\n(1994) compared, in the spatial case, the use of a control disease with the\nuse of a population-based estimate of risk and concluded that the results\nobtained diﬀered.\n\nIt should be noted that all of these methods assume that the background\nsmoothing is constant over the whole study region. However, if a study re-\ngion is split into highly populated areas (e.g. cities) and sparsely populated\nareas (e.g. rural areas) then it might be more appropriate to model the\nsmoothing adaptively e.g. as a nearest neighbour estimator. Similar prob-\nlems exist in multivariate density estimation near the edge of the parameter\nspace, Simonoﬀ (1993) Chapter 4.\n\nIf the spatial distribution of a control disease is available, it is matched\nto the case disease based on the age-sex ‘at risk’ distribution of the case\ndisease, but unaﬀected by the phenomenon under investigation. Then it is\npossible to estimate the space-time background function g(s,t) nonpara-\nmetrically as in the spatial case. In that case we could employ: a nonpara-\nmetric density estimate of the space-time variation in the control disease,\nsuch as\n\n(cid:3)\n\n(cid:2)\n\n(cid:3)\n\n(cid:2)\n\nˆg(s,t) =\n\n(cid:1)\n\nw1\n\nj\n\ns − vj\nh1\n\nw2\n\nt − τj\nh2\n\n,\n\n(14.8)\n\nwhere w1 and w2 are kernel functions, h1 and h2 are smoothing parameters\nand {vj, τj} is the space-time coordinates of a realisation of a control dis-\nease. Note that in this formulation there is a diﬀerent smoothing constant\n\n\f244\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\nin time and space but that there is equal smoothing in both spatial di-\nrections. It is well known that such multivariate kernel density estimation\nsuﬀers from the ‘curse of dimensionality’. For that reason, other simpler\nalternatives might be considered necessary. If the disease is rare, and there\nis little information about any space-time interaction, one possibility is to\nconsider a separable estimator of the form:\ns − vj\nh1\n\nˆg(s,t) = g01(s).g02(t) =\n\nt − τj\nh2\n\n(14.9)\n\n(cid:1)\n\n(cid:1)\n\nw2\n\nw1\n\n(cid:2)\n\n(cid:3)\n\n(cid:3)\n\n(cid:2)\n\n.\n\n.\n\nj\n\nj\n\nAn estimator as speciﬁ",
    "chunk_order_index": 135,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-add03789b5f3912d01c8ceaf0aebbaa8": {
    "tokens": 1200,
    "content": "little information about any space-time interaction, one possibility is to\nconsider a separable estimator of the form:\ns − vj\nh1\n\nˆg(s,t) = g01(s).g02(t) =\n\nt − τj\nh2\n\n(14.9)\n\n(cid:1)\n\n(cid:1)\n\nw2\n\nw1\n\n(cid:2)\n\n(cid:3)\n\n(cid:3)\n\n(cid:2)\n\n.\n\n.\n\nj\n\nj\n\nAn estimator as speciﬁed as (14.8) or (14.9) can be substituted into\nthe model (14.7) to fully specify the intensity. A likelihood, conditional on\nobserving n events, can be derived for this model and can be expressed as\n(cid:5)\n\n(cid:2)(cid:5)\n\n(cid:3)−n\n\nˆg(xi, ui).r(xi, ui; z).\n\nˆg(p, q)r(p, q; z)dqdp\n\n.\n\n(14.10)\n\nA\n\nT\n\nn(cid:4)\n\nL =\n\ni=1\n\nThe Prior Distribution for Cluster Centres\n\nThe cluster centres themselves form a point process, however this process\nis not observed. In this model formulation there are three cluster com-\nponents, each with unknown number and locations of centres. This can\nbe represented as a mixture problem with an unknown number of com-\nponents and component locations. Without further ancillary information,\nassumptions must be made to allow the estimation of such parameters. It\nis conventional that spatial components such as cluster centres have spatial\nprior distributions and the number of centres must also have some prior\ndistribution. It is possible to assume a spatially uniform prior distribution\nfor locations and a Poisson(δ) distribution for the number, say. Alterna-\ntively, to prevent reconstructions with multiple response (in our sampling\nalgorithms), some inhibition in the prior distribution of centres could be\nassumed, see van Lieshout and Baddeley (1995) for further discussion of\nmultiple response problems. Indeed cluster centre estimation will not be\neﬃcient or ‘convergent’ without (slight) inhibition of centres. A Strauss\nprior distribution (see for example Chapter 4 in this volume) provides a\njoint prior distribution for both the locations and number of centres. The\nStrauss prior distribution, for the spatial case, is deﬁned for a realisation\nof m centres, thus:\n\nf (c) ∝ bmγR(c),\nwhere, b is a rate parameter, γ an inhibition parameter, R an inhibition\ndistance and R(c) is the number of R − close pairs in the realisation of\ncentres. There are three parameters in this deﬁnition. If such prior dis-\ntributions are employed for all cluster types, independently, there will be\nnine parameters. Both R and γ, which control the degree of inhibition, are\nhighly correlated, and are usually ﬁxed at values representing weak inhi-\n\n(14.11)\n\n\fMODEL DEVELOPMENT\n\n245\n\nbition. The rate parameter, b, can also be ﬁxed. The parameters values\nassumed for these parameters are detailed in Section 14.6.3. Other choices\nof the prior distribution can be envisaged and are discussed, at length, in\nChapter 4 in this volume.\n\nChoice of Cluster Distribution Function\n\nThe cluster distribution function describe how cases are spread around a\ncluster centre. A variety of possibilities exist for this function. It is common\nto use a radial distribution function with a Gaussian form, although a\nuniform distribution within a disc is also possible. The variance parameter\nof the cluster distribution function determines the spatial scale or spread\nof the clusters. Here we assume these to be constant for each cluster of the\nsame type. The practical eﬀects of this are that cluster centres located in\nthe built-up areas will dominate (since the clusters will be less dispersed\nthan in rural areas) and hence we may not pick up centres located in rural\nareas.\n\nIt should be noted that the choice of cluster distribution function is, in\nall probability, of secondary importance to the estimation of the variance\nparameter. The radial symmetric Gaussian distribution is used throughout\nand is given by\n\n1\n2πκ\nwhere κ is the cluster variance, see Chapter 4 of this volume.\n\n. exp{− (cid:6)s − c(cid:6)2\n\nK(s − c) =\n\n/2κ},\n\n(14.12)\n\nOther Prior Distributions and the Posterior Distribution\n\nWith the likelihood given by equation (14.10) and with the background in-\ntensity incorporated the prior distributions that need to be speciﬁed are for\nthe cluster centres (location and number), and the weights. For the weight\nvector it is convenient to adopt reasonably uninformative and independent\nexponential prior distributions:\n\ng(α1, α2, α3) = exp(−α1 − α2 − α3),\n(14.13)\ni.e. each weight is exponentially distributed with mean 1. Note that the\nweights are not constrained to sum to one. When covariates are included\nin the model, then the regression parameters associated with these are as-\nsumed to have uninformative uniform prior distributions on suitable ranges.\nFor the location and number of cluster centres we adopt the Strauss inhi-\nbition prior distributions:\n\nπ(c1) ∝ bns\nπ(c2) ∝ bnt\nπ(c3) ∝ bnst\n\n1 γR(c1),\n2 γR(c2),\n3 γR(c3),\n\n(14.14)\n\n\f246\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\nwhere b is a rate parameter, γ is an interaction parameter and",
    "chunk_order_index": 136,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-1a3bf9e632da3aace9229d78073fa3ce": {
    "tokens": 1200,
    "content": "ranges.\nFor the location and number of cluster centres we adopt the Strauss inhi-\nbition prior distributions:\n\nπ(c1) ∝ bns\nπ(c2) ∝ bnt\nπ(c3) ∝ bnst\n\n1 γR(c1),\n2 γR(c2),\n3 γR(c3),\n\n(14.14)\n\n\f246\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\nwhere b is a rate parameter, γ is an interaction parameter and R(c) is the\nnumber of R-close pairs in c. As mentioned previously one of the main uses\nof such priors is to prevent multiple centres having the same location. It\nis possible to assume a joint Strauss inhibition prior for the spatial cluster\ncentres and the spatial part of the spatio-temporal cluster centres, similarly\nwe can specify the joint prior for the temporal cluster centres and the tem-\nporal part of the spatio-temporal cluster centres. This formulation would\nprevent spatial and spatio-temporal cluster centers existing at the same lo-\ncation in space and similarly would prevent temporal and spatio-temporal\ncluster centers existing at the same point in time. However, it was found\nthat this did not unduly eﬀect the results in Section 14.6 and is hence not\napplied.\n\nThe resulting joint posterior distribution for the model can be speciﬁed\n\nas proportional to:\n\n(cid:6)\n\n(cid:7)\n(cid:8)\nn\nˆg(xi,ui) exp(βT zi){1 + M1(xi) + M2(ui) + M3((xi,ui))}\ni=1\n(cid:9)\nT ˆg(p,q) exp(βT z)(1 + M1(p) + M2(q) + M3((p,q))dqdp}−n\n1 γR(c1) × bnt\n3 γR(c3).\n\n(cid:9)\n{\n× exp(−α1 − α2 − α3) × bns\n\n2 γR(c2) × bnst\n\nA\n\nWhere\n\nM1(s) = α1\n\nM2(t) = α2\n\nns(cid:1)\n\nj=1\nnt(cid:1)\n\nj=1\n\nK(s − c1j),\n\nK(t − c2j),\n\nM3((s,t)) = α3\n\nnst(cid:1)\n\nK((s,t) − c3j).\n\nj=1\nNotice that the complexity of the problem increases drastically if we\nallow any of the Strauss parameters to vary, since the normalising constant\nis a function of the Strauss parameters. Possible solutions to this include\nusing various approximations to the Strauss prior distributions. This is,\nhowever, not pursued here. In Section 14.5, we discuss the algorithm used\nto sample the centres and related parameters. The formulation used here\nis speciﬁed in Section 14.6.\n\n14.4.2 Region Counts\n\nIn the data example examined here, the sparseness of the incidence of cases\nand lack of orderliness supports the aggregation of cases into counts within\nsmall areas. Here we have aggregated to postcode sectors (5 digits) and\n\n\fMODEL DEVELOPMENT\n\n247\n\ncalendar months. Because of this aggregation, we have considered modelling\nthe situation where count data aggregation of the basic point process model\nis employed.\n\nCount data are derived from aggregating case-event data to arbitrary\nregions. This type of data is routinely collected and normally used for large\nscale studies (e.g. cancer atlases). A large number of models exist for dealing\nwith this type of data (see e.g. Lawson (2001)). Most of these models make\nthe assumption that we observe a count within a spatio-temporal cell, say\n{yit} i = 1, ...., m, t = 1, ....., T , and a set of expected counts, say {eit}\ni = 1, ...., m, t = 1, ....., T . The distribution of the counts is usually assumed\nto be:\n\nyit|{θit} (cid:2) Poisson(eit.θit),\n(14.15)\nand modelling concentrates on the relative risks {θit}. These models, al-\nthough widely used, have been the subject of recent criticism (for example\nLawson and Cressie (2000)). In this section we extend the case-event model\nof the previous section to deal with count events aggregated into space-time\ncells.\n\nIntegrated Intensity\n\nIf the cases form a heterogeneous modulated Poisson process with inten-\nsity given by equation (14.6), then the number of cases in arbitrary (non\noverlapping) regions {Ai} and time intervals {δt} are independent Poisson\nrandom variables with parameter\n\n(cid:5)\n\n(cid:5)\n\nmit = Λ(Ai, δt|c1, c2, c3) =\n\nλ(s, t)dtds.\n\n(14.16)\n\nAi\n\nδt\n\nThis approach has a number of advantages over model (14.15).\n1. It does not involve the deﬁnition of a neighbourhood structure, which is\n\noften assumed for conventional count data models.\n\n2. It takes account of both the size and shape of the study region.\n3. In model (14.15), a decoupling approximation is made, i.e. whereby it is\nassumed that everyone lives at the centroid of each region, see Lawson\nand Cressie (2000) for more details.\nThe integration is easily done if we have a control disease for which we\nhave the exact spatial and temporal location. However this will rarely occur\nin practice and we will normally have just the count in the region. This\nmeans that",
    "chunk_order_index": 137,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-f0827e215267617ae0a279977a853630": {
    "tokens": 1200,
    "content": "region.\n3. In model (14.15), a decoupling approximation is made, i.e. whereby it is\nassumed that everyone lives at the centroid of each region, see Lawson\nand Cressie (2000) for more details.\nThe integration is easily done if we have a control disease for which we\nhave the exact spatial and temporal location. However this will rarely occur\nin practice and we will normally have just the count in the region. This\nmeans that we must approximate the integral as\n\n(cid:5)\n\n(cid:5)\n\nmit (cid:3) eit exp(βT z).\n\n{1 + α1M1(s) + α2M2(t) + α3M3((s,t))}dtds\n\nAi\n\nδt\n\nConditional on the total count (say N ) the likelihood is then of multinomial\nform.\n\n\f248\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\n14.5 The Posterior Sampling Algorithm\n\nThe use of iterative sampling algorithms is now widespread in complex sta-\ntistical modelling. The most popular technique, Markov chain Monte Carlo\n(MCMC), is a method which allows one to iteratively draw samples from\nthe posterior distribution. Given the sample values it is then possible to\ndraw inferences about the joint or marginal distributions of each parameter.\nThe extension of MCMC algorithms to the situation where the parame-\nter space varies is not straightforward. However, Geyer and Møller (1994),\nGreen (1995) and Richardson and Green (1997) have suggested possible\nmethodology. Models ﬁtted here can be viewed as variable parameter mix-\nture models. For such mixture problems, drawing inferences from these\nchains is more diﬃcult since you may visit components a relatively small\nnumber of times.\n\nThe model presented here consists of a number of parameters which can\nbe updated using standard MCMC techniques (Carlin and Louis 1996).\nHowever, for both case event or count data applications, the cluster centres\nneed to be updated using variable parameter space MCMC techniques,\nsuch as reversible jump MCMC. For our problem, this can be done using\na birth-death-shift algorithm as described in Geyer and Møller (1994) and\nsummarized below.\n\nConsider a set of points v= (v1, .., vn) then an algorithm using iterative\nupdates via births and deaths of points can be speciﬁed. Updates for this\ncan be made set by one of the following steps\n\n1. BIRTH: (or addition) The addition of a randomly selected new point.\nThe location of the new point (say u) generated from a density b(u|v)\n(that usually depends on the location of the other points).\n\n2. DEATH: (or deletion) The removal of an existing point (say vi), the\n\npoint is chosen from a distribution d(vi|v).\n\n3. SHIFT: (or random displacement) The random movement of one point\n(say vi), this is chosen from the current set with equal probability and\nis moved to u with density s(vi, u).\n\nThe birth (B) -death (D) -shift (S) steps are incorporated in a Metropolis-\nHastings algorithm where each type of transition (B,D,S) has a probability\nof being chosen. Here, q is deﬁned as the birth probability and p is deﬁned\nas the probability of a shift transition. The transitions (B,D,S) are deﬁned\nas :(1 − p)qb(u|v); (1 − p)(1 − q)d(v|v); ps(u, v) respectively.\n\nThe Metropolis-Hastings acceptance ratios for these moves are given by\n\nBIRT H : LR x P R x\n\nDEAT H : LR x P R x\n\n.\n\n1 − q(v ∪ u)\nq(v)\nq(v \\ vi)\n1 − q(v)\n\nd(u|v ∪ u)\nb(u|v)\nb(vi|v \\ vi)\nd(vi|v)\n\n,\n\n.\n\n,\n\n\fDATA EXAMPLE: SCOTTISH BIRTH ABNORMALITIES\ns(u, vi)\ns(vi, u)\n\nSHIF T : LR x P R x\n\n,\n\n249\n\nwhere LR is the likelihood ratio, and PR is the prior ratio. This algorithm,\nand other steps used for other parameters are detailed in the Appendix.\nExtensions to using exact sampling techniques, such as those described in\nChapter 5 in the volume, are certainly possible but are not pursued here.\n\n14.5.1 Goodness-of-Fit Measures for the Model\n\nAs a model choice criterion the Bayesian Information Criterion (BIC) is\nwidely used in Bayesian and hierarchical models as it asymptotically ap-\nproximates a Bayes factor. In a model with log-likelihood l(θ) the BIC value\nis estimated from the output of an MCMC algorithm by\n\n2ˆl(θ∗) − p ln n,\n\nwhere p is the number of parameters, n is the number of data points and\n\nˆl(θ∗) =\n\n1\nG\n\nG(cid:1)\n\ni=1\n\nl(θ∗\n\ni ),\n\nthe averaged log-likelihood over G posterior samples of θ. In our model\nwe do not have a ﬁxed number of parameters. Here we replace p by ˆp, the\naverage number of parameters in the G posterior samples of θ. We can thus\nconsider this setup as calculating a BIC value for every posterior sample\nand averaging the value over the sample.\n\nNotice that, recently, the Deviance Information Criterion (DIC) has been\n\nproposed by Spiegelhalter et al. (1999). This is deﬁ",
    "chunk_order_index": 138,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-9274cf1fea92f641567d60b1b7a897c4": {
    "tokens": 1200,
    "content": "of θ. In our model\nwe do not have a ﬁxed number of parameters. Here we replace p by ˆp, the\naverage number of parameters in the G posterior samples of θ. We can thus\nconsider this setup as calculating a BIC value for every posterior sample\nand averaging the value over the sample.\n\nNotice that, recently, the Deviance Information Criterion (DIC) has been\n\nproposed by Spiegelhalter et al. (1999). This is deﬁned as\n\nDIC = 2Eθ|x{D} − D{Eθ|x(θ)},\n\nwhere D(.) is the deviance of the model and x is the observed data. This\nuses the average of the posterior samples of θ to produce an expected value\nof θ. However, if this parameter is a spatial (or temporal) location over\nvarying dimensional space then the average may not be a useful summary\nmeasure of the posterior distribution.\n\n14.6 Data Example: Scottish Birth Abnormalities\n\n14.6.1 Introduction\n\nThe data set that we consider is the location of birth abnormalities in Tay-\nside (Scotland) between January 1991 and December 1995. The birth ab-\nnormalities examined consists of all abnormalities recorded at birth on hos-\npital births records (Scottish Morbidity Record scheme: SMR2 database).\nWhile abnormalities vary in both type and aetiology, the variation in space\n\n\f250\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\nand time of total abnormalities may give indications as to possible diﬀeren-\ntials in health service provision or in environmental exposure risk. Potential\nmaterial exposure to harmful environmental agents, lifestyle variation and\ndiagnostic practice are possible determinants. Following aggregation, the\ndata form a set of counts in months (60) and in postcode sectors (92).\nIn addition to the counts of abnormalities, also available is the count of\nlive births for the same units. The live birth count is used to provide an\nestimate of the variation in the population background, which we need\nto take account of when assessing the excess variation in the abnormal-\nity count. Deprivation indices for the post code sectors were also available\n(Carstairs 1981). These may yield evidence for lifestyle variation or depri-\nvation links.\n\n14.6.2 Exploratory Analysis\nA time series plot of the standardised mortality ratio (SMR)∗ is given below\n(Figure 14.1) and shows only slight evidence of a possible increase in time,\nbut also suggests two possible clusters around 20 and 50 months.\n\n4\n.\n1\n\n2\n.\n1\n\n0\n.\n1\n\n8\n.\n0\n\n6\n.\n0\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\n60\n\nMonths since January 1991\n\nFigure 14.1 A time series plot of the Standardised Mortality Ratio, deﬁned as\nSM Rt = mt ∗\nmt where mt is the number of live births in month t and\nnt is the number of birth abnormalities in month t.\n\nnt/\n\n(cid:10)\n\n(cid:10)\n\nThis suggests that a cluster model in the temporal marginal distribution\n\ncould be appropriate.\n\n∗\n\nThe SMR mortality ratio for the ith region is here deﬁned as the ratio of the observed\ncount to the expected count, where the expected count is (mit/m··) ∗ n··. The dot\nstands for summation over the relevant subscript.\n\n\fDATA EXAMPLE: SCOTTISH BIRTH ABNORMALITIES\n\n251\n\nF\nC\nA\n\n0\n1\n\n.\n\n8\n0\n\n.\n\n6\n0\n\n.\n\n4\n0\n\n.\n\n2\n0\n\n.\n\n0\n0\n\n.\n\n.\n\n4\n0\n-\n\n•\n\n0\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n5\n\n•\n\n•\n\n•\n\n10\n\n•\n\n•\n\nLag\n\n•\n\n•\n\n•\n\n•\n\n•\n\n15\n\nFigure 14.2 The autocorrelation function of temporal for each month from 1/1/91\nuntil 31/12/95 SM Rt with 5% signiﬁcance level.\n\nFigure 14.3 A plot of the spatial SMR in Tayside 1991-1995 deﬁned as SM Ri =\nmi ∗\n\nmi.\n\nni/\n\n(cid:10)\n\n(cid:10)\n\nThe temporal structure of the number of live births and the number of\nbirth abnormalities is diﬀerent in a number of respects. Firstly, the number\nof births is declining with time whereas the number of abnormalities is not.\nSecondly, the number of live births shows evidence of seasonality whereas\nthe number of abnormalities does not. Also the temporal autocorrelation\nfunction of the SMR (Figure 14.2) reveals that although no seasonality is\n\n\f252\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\npresent some short term autocorrelation exists, adding to the evidence of\nclustering.\n\nA map of the spatial SMRs reveals some striking features. Firstly, the\nsmall SMRs in the rural (north-west) area and high SMRs in the city areas\n(Dundee and Perth). Secondly, elevated SMRs tend to cluster in the middle\nof the map (Figure 14.3).\n\nThe SMRs for each year are given in Figures 14.4 to 14.8. These show\nthat the SMR are highly variable in space-time and might suggest possible\nclusters in space-time.\n\nVariation in deprivation across the area was also examined, not shown,\nand peaks in urban areas were marked however little association was found\nwith the rate of birth abnormalities.\n\n14.6.3 Model Fitting Results\n\nWe ﬁtted the count model to the set of observed birth abnormalities, where\nthe space-time units are postcode sector and calendar month. The",
    "chunk_order_index": 139,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-b942b4c3fb22cfce5bd7d32b300636d0": {
    "tokens": 1200,
    "content": "to 14.8. These show\nthat the SMR are highly variable in space-time and might suggest possible\nclusters in space-time.\n\nVariation in deprivation across the area was also examined, not shown,\nand peaks in urban areas were marked however little association was found\nwith the rate of birth abnormalities.\n\n14.6.3 Model Fitting Results\n\nWe ﬁtted the count model to the set of observed birth abnormalities, where\nthe space-time units are postcode sector and calendar month. The control\nused was the number of live births in the same space-time unit. Following\nthe exploratory analysis, we included the Carstairs deprivation index (dep),\nand x coordinate and the y coordinate as possible covariates for spatial\ntrend, but did not include a temporal trend as this did not appear to\nbe important. All the variables were standardised prior to analysis. The\nresulting full model was:\n\n(cid:5)\n\n(cid:5)\n\nmit (cid:3) eit.\n\nexp{β1x + β2y + β3.dep}{1 + α1\n\nns(cid:1)\n\nk=1\n\nK(x − c1k)\n\nAi\n\nδt\n\n+α2\n\nnt(cid:1)\n\nk=1\n\nK(t − c2k) + α3\n\nnst(cid:1)\n\nk=1\n\nK((x,t) − c3k)}dtdx.\n\n(14.17)\n\nThe Strauss parameters (bi and γ in equation 14.14) were set at 0.2 for each\nradius parameter and 3 for the rate parameter (i.e. b1 = b2 = b3 = 3). The\ninhibition distance parameter was set to 0.1 (measured on the unit square).\nThese settings were motivated by prior beliefs concerning the range of\npotential inhibition and exploratory analysis of the form of cluster variation\npossible. These settings lead to relatively strong inhibition of centres, which\nwe would favour here as we wish to ensure well separated cluster estimates\nand we believe a priori that a small number of centres exist in the pattern.\nThe weights were given exponential prior distributions with mean 1 as these\nwere assumed a priori to take values less than 1, and the β parameters were\ngiven uniform prior distributions on large ranges, as we have no strong prior\npreference for the values of these parameters.\n\nThe Metropolis-Hastings steps were run until convergence, which was\nusually achieved within the ﬁrst 20,000 iterations, and then for a further\n\n\fDATA EXAMPLE: SCOTTISH BIRTH ABNORMALITIES\n\n253\n\nFigure 14.4 A plot of the SMR in Tay-\nside for 1991, with SMR and legend as\ndeﬁned in Figure 14.3.\n\nFigure 14.5 A plot of the SMR in Tay-\nside for 1992, with the SMR and legend\nas deﬁned in Figure 14.3.\n\nFigure 14.6 A plot of the SMR in Tay-\nside for 1993, with SMR and legend as\ndeﬁned in Figure 14.3.\n\nFigure 14.7 A plot of the SMR in Tay-\nside for 1994, with the SMR and legend\nas deﬁned in Figure 14.3.\n\nFigure 14.8 A plot of the SMR in Tayside for 1995, with the SMR and legend as\ndeﬁned in Figure 14.3.\n\nperiod of time. Multiple starting points were examined. Convergence mon-\nitoring was carried out using Geweke’s criterion and also parameter sum-\nmaries. Details of the algorithm are given in the appendix. The posterior\nsample estimates are based on the last 500 iterations, after convergence. A\nvariety of subset models were examined (ﬁtted separately). In Table 1 the\nresults of ﬁtting subsets with one component removed are presented.\n\n\f254\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\nT able 1: Model BIC values and the estimated number of cluster centres\nusing the last 500 iterations of the RJMCMC algorithm\n\nModel\n\nfull\n\nno deprivation\n\nno x-coordinate\n\nno y-coordinate\n\n2ˆl(θ∗)\n\n-27740.36\n\n-27723.70\n\n-27712.79\n\n-27785.42\n\nns\n\n6.8\n\n6.7\n\n8.6\n\n7.8\n\nno spatial clustering\n\n-28007.71\n\n-\n\nno temporal clustering\n\n-27759.02\n\nno spatio-temporal clustering\n\n-27781.62\n\n6.7\n\n6.0\n\nnt\n\n4.0\n\n5.0\n\n2.1\n\n2.1\n\n5.0\n\n-\n\nnst\n\n9.0\n\nBIC\n\n-55712.7\n\n14.0\n\n-55718.8\n\n10.0\n\n-55656.8\n\n6.4\n\n6.4\n\n9.0\n\n-55766.6\n\n-56163.6\n\n-55700.9\n\n2.1\n\n-\n\n-55684.9\n\nThis table shows some interesting features. Notice how the number of\nspatial and temporal clusters change only slightly in each model, whereas\nthe number of spatio-temporal clusters changes dramatically.\n\nOur results indicate a lack of any relationship between the level of depri-\nvation of an area and the number of birth abnormalities within that area.\nA strong gradient from the west coast to the east, strong evidence spatio-\ntemporal clustering, but a lack of both spatial and temporal clustering.\n\nThe estimated weights, given in Table 2, demonstrate the importance of\n\nthe temporal component over other components.\n\nT able 2 : The posterior expectation of the weight parameters\nestimated using the",
    "chunk_order_index": 140,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-57cfd6c020335465e61c8a93272d9ece": {
    "tokens": 1200,
    "content": "changes dramatically.\n\nOur results indicate a lack of any relationship between the level of depri-\nvation of an area and the number of birth abnormalities within that area.\nA strong gradient from the west coast to the east, strong evidence spatio-\ntemporal clustering, but a lack of both spatial and temporal clustering.\n\nThe estimated weights, given in Table 2, demonstrate the importance of\n\nthe temporal component over other components.\n\nT able 2 : The posterior expectation of the weight parameters\nestimated using the last 500 iterations of the RJMCMC\nAlgorithm\n\nModel\n\nfull\n\nα1\n\nα2\n\nα3\n\n0.57\n\n2.02\n\n0.17\n\nno deprivation\n\n0.75\n\n1.92\n\n0.12\n\nno x-coordinate\n\n1.05\n\n1.32\n\n0.37\n\nno y-coordinate\n\n1.88\n\n0.80\n\n0.38\n\nno spatial clustering\n\n0.00\n\n2.66\n\n0.03\n\nno temporal clustering\n\n0.22\n\n0.00\n\n0.05\n\nno spatio-temporal clustering\n\n0.05\n\n0.16\n\n0.00\n\nThis table demonstrates that the temporal clustering pattern is relatively\n\n\fDATA EXAMPLE: SCOTTISH BIRTH ABNORMALITIES\n\n255\n\n0.030\n\n0.025\n\n0.020\n\n0.015\n\n0.010\n\n0.005\n\n0.000\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\n60\n\n70\n\nmonth\n\nFigure 14.9 A kernel smoothed estimate of the locations of cluster centres in time,\nbased on the last 500 iterations.\n\nunchanged in any of the models, although in the no-spatial-clustering model\nwe see that its importance increases.\n\nThe location of the cluster centres in time is given in Figure 9. This shows\nthat the most likely location of a cluster is after 50 months, and the next\ntwo most likely locations near the start of the temporal window. This may\nhowever be an artifact of the intensity estimation method. The location of\nthe cluster centres in space is given in Figure 10. This shows a cluster in\nthe north-west of Tayside and other possible centres in rural locations.\n\nThe results compare well with the exploratory analysis. The temporal\npeaks in the SMR (Figure 14.3) are not present in the results although\nneither of these two peaks has an SMR which diﬀers signiﬁcantly from 1.0.\nThe regression parameters also show the urban/rural eﬀect and little rela-\ntionship between deprivation and birth abnormalities. It should be noted\nhowever that without the deprivation index as a covariate we have a greater\nnumber of spatio-temporal clusters.\n\n\fSPATIO-TEMPORAL CLUSTER MODELLING\n\n6e-010\n\n0\n1\ne-0\n2e-010\n8\n\n6e-010\n\n2e-010\n\n256\n\n5\nx 10\n\n8.4\n\n8.2\n\n8\n\n7.8\n\n7.6\n\n7.4\n\n7.2\n\n8e-010\n\n1.5\n\n2\n\n2.5\n\n3\n\n3.5\n\n5\nx 10\n\nFigure 14.10 A kernel smoothed estimate of the locations of cluster centres in\nspace, based on the last 500 iterations. The bounding polygon is an approximation\nto the external bounding polygon of the study region.\n\n14.7 Discussion\n\nWe have introduced a new model for the analysis of small area health data\nat both the case-event level or aggregated count level. This model allows\na general framework for clustering in the spatio-temporal domain. With\nonly slight modiﬁcations it can include known cluster centres, e.g. waste\nincinerators, it can also allow for the examination of diﬀerent types of\nclustering avoiding any multiple testing problems. We have also discussed\nhow one can assess the goodness-of-ﬁt of a clustering model.\n\nWhile one can never replace a carefully designed (and executed) case-\ncontrol study with any observational data, the development of realistic\nmodels for clustering can suggest the need for further study. The inclu-\nsion of covariates into such models is of prime importance, indeed in our\nformulation the cluster terms represent unmeasured covariates. However,\nit is often diﬃcult to obtain covariates which can represent unobserved\n\n\fDISCUSSION\n\n257\n\nheterogeneities and resort has to be made to crude measures such as the\nKafadar-Tukey urbanisation index or Cairstairs deprivation index. The nu-\nmerical values of covariates is usually hard to obtain, usually one has co-\nvariates measured at some aggregate level which may not correspond to\nthe subdivision by postcodes. For such cases useful models for covariate\nmeasurement error would be needed.\n\nWithin the modelling framework presented here further reﬁnements are\npossible, for example one could remove the need for a constant cluster\nvariance and allow the clusters to vary in size in the relevant domain of\ninterest. We have not considered edge eﬀects here, but these can be taken\ninto account by weighting the likelihood or using an external guard area.\nThe model here is computationally intensive, but given recent advances\nin computer technology we do not feel that this is a major drawback. Also\nthe extension of this work into the development of a spatio-temporal surveil-\nlance alarm system would be of great public health importance and is a\nlong term research aim.\n\nOur results compare favourably with the results of previous studies on\nbirth abnormalities, for example Dolk et al. (1998). They found little evi-\ndence of an association with",
    "chunk_order_index": 141,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-6e2f9b01d07e7eb8e40873674aa42683": {
    "tokens": 1200,
    "content": "ly intensive, but given recent advances\nin computer technology we do not feel that this is a major drawback. Also\nthe extension of this work into the development of a spatio-temporal surveil-\nlance alarm system would be of great public health importance and is a\nlong term research aim.\n\nOur results compare favourably with the results of previous studies on\nbirth abnormalities, for example Dolk et al. (1998). They found little evi-\ndence of an association with deprivation and a rural-urban gradient, albeit\nof a diﬀerent form. Some limitations of our study are, ﬁrstly, we are dealing\nwith total abnormalities without diﬀerentiation into diﬀerent types. This\nis the subject of future work. We have also not looked at the diﬀerences\nbetween health authority areas (which could lead to diﬀerential diagno-\nsis/treatment outcomes). Clearly in a fuller study such diﬀerences could\nalso be included in the analysis.\n\nIt should also be noted that the models proposed here are speciﬁcally\ndesigned for the assessment of the location and number of clusters in space,\ntime and space-time whereas other studies in space-time disease incidence\nexamine random eﬀect models for the variation (e.g. Xia and Carlin 1998).\nWhile these models can account for extra-variation and correlation in the\nrelative risk, they do not provide a mechanism, and are not designed, for\nthe estimation of cluster locations. Those models are appropriate for the\ngeneral modelling of levels of variation in disease incidence.\n\nIn summary, we believe that the methodology proposed here can provide\na relevant basis for cluster studies and can provide enhanced capability to\ndetect cluster locations and number.\n\nAppendix: Metropolis-Hastings BDS algorithm\n\nThe algorithm introduced in Section 14.5 depended upon the choice of a\nbirth density, a death distribution and a shift density. The mixing of the\nalgorithm is dependent upon both the choice of these functions and the\nproportion of time we choose to update using a birth, death or shift.\n\n\f258\n\nSPATIO-TEMPORAL CLUSTER MODELLING\n\nWhile all these may depend upon the number of points and their location,\n\nfor simplicity, we have chosen the following:\n\n1. We propose a birth, death or shift with equal probability, i.e. p =\n\n0.33, q = 0.5 and\n\n2. If we propose a birth we propose the new location at random throughout\n\nthe study area unit.\n\n3. If we propose a death we choose the location from the current set with\n\nequal probability.\n\n4. If we propose a shift we choose a point from the current set with equal\nprobability and shift it to a new location chosen at random on the study\narea unit.\nWith this choice the ratios are, for a generic set of cluster centres {ci},i =\n\n1, ...., nc, given by\n\nBirth : LR x P R x 2 x\n\nDeath : LR x P R x\n\nShift\n\n: LR x P R.\n\n1\n2\n\n1\nnc ,\nx nc,\n\nNotice that the birth ratio decreases as nc increases and the death ratio\n\nincreases as nc increases.\n\nOur overall algorithm, at each step of the chain, is:\n\n1. update α1, α2, α3 using a Gaussian jumping kernel centered around the\n\ncurrent value and a ﬁxed width,\n\n2. update β1, β2, β3 using a Gaussian jumping kernel centered around the\n\ncurrent value and small variance,\n\n3. update c1 using the birth death shift algorithm deﬁned above,\n4. update c2 using the birth death shift algorithm deﬁned above,\n5. update c3 using the birth death shift algorithm deﬁned above.\n\nAcknowledgements\n\nThe authors wish to acknowledge the support of an EU Biomed2 concerted\naction grant, number BMH4-CT96-0633, and the Information and Statistics\nDivision of the National Health Service (Scotland) for the provision of the\ndata.\n\n\fReferences\n\nAdler, R. (1981). The Geometry of Random Fields, Wiley, New York.\nAhrens, C., Altman, N., Casella, G., Eaton, M., Hwang, J. T. G., Staudenmayer,\nJ. and Stefanscu, C. (1999). Leukemia clusters and TCE waste sites in upstate\nNew York: How adding covariates changes the story, Technical report, School\nof Operations Research, Cornell University.\n\nAllard, D. and Fraley, C. (1997). Non-parametric maximum likelihood estimation\nof features in spatial point process using Voronoi tessellation, J. Amer. Statist.\nAssoc. 92: 1485–1493.\n\nArak, T., Cliﬀord, P. and Surgailis, D. (1993). Point-based polygonal models for\n\nrandom graphs, Adv. Appl. Prob. 25: 348–372.\n\nAykroyd, R. G. (1995). Partition models in the analysis of autoradiographic im-\n\nages, Appl. Statist. 44: 441–454.\n\nAzzalini, A. and Capitanio, A. (1999). Statistical applications of the multivariate\n\nskew normal distribution, J. Roy. Statist. Soc. B 61: 579–602.\n\nAzzalini, A. and Dalla Valle, A. (1996). The multivariate skew-normal distribution,\n\nBiometrika 83: 715–726.\n\nBaddeley, A. J. (1999). Spatial sampling and censoring, in O. Bar",
    "chunk_order_index": 142,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-b9b9ecd3db17ab5f9ccb32d75b7ab95b": {
    "tokens": 1200,
    "content": "A. and Capitanio, A. (1999). Statistical applications of the multivariate\n\nskew normal distribution, J. Roy. Statist. Soc. B 61: 579–602.\n\nAzzalini, A. and Dalla Valle, A. (1996). The multivariate skew-normal distribution,\n\nBiometrika 83: 715–726.\n\nBaddeley, A. J. (1999). Spatial sampling and censoring, in O. Barndorﬀ-Nielsen,\nW. S. Kendall and M. N. M. van Lieshout (eds), Stochastic geometry, likelihood,\nand computation, Boca Raton: Chapman & Hall.\n\nBaddeley, A. J. and Møller, J. (1989). Nearest-neighbour Markov point processes\n\nand random sets, International Statistical Review 57: 89–121.\n\nBaddeley, A. J. and van Lieshout, M. N. M. (1993). Stochastic geometry models\nin high-level vision, in K. V. Mardia and G. K. Kanji (eds), Statistics and\nImages, Advances in Applied Statistics, a supplement to the Journal of Applied\nStatistics, Vol. 20, Carfax Publishing, Abingdon, chapter 11, pp. 231–256.\nBaddeley, A. J. and van Lieshout, M. N. M. (1995). Area-interaction point pro-\n\ncesses, Annals of the Institute of Statistical Mathematics 46: 601–619.\n\nBaddeley, A. J., Fisher, N. I. and Davies, S. J. (1993). Statistical modelling and\nprediction of fault processes, in P. J. Hatherly, J. Shepherd, B. J. Evans and\nN. I. Fisher (eds), Integration of methods for the prediction of faulting, Sydney:\nAustralian Coal Industry Research, chapter 6, pp. 143–176.\n\nBaddeley, A. J., Møller, J. and Waagepetersen, R. P. (2000). Non- and semi-\nparametric estimation of interaction in inhomogeneous point patterns, Statis-\ntica Neerlandica 54: 329–350.\n\nBaddeley, A. J., van Lieshout, M. N. M. and Møller, J. (1996). Markov properties\n\nof cluster processes, Advances in Applied Probability 28: 346–355.\n\nBanﬁeld, J. D. and Raftery, A. E. (1993). Model-based Gaussian and non-Gaussian\n\nclustering, Biometrics 49: 803–821.\n\n\f260\n\nREFERENCES\n\nBarry, D. and Hartigan, J. A. (1993). A Bayesian analysis for changepoint prob-\n\nlems, J. Amer. Statist. Assoc. 88: 309–319.\n\nBartlett, M. S. (1975). The Statistical Analysis of Spatial Pattern, Chapman and\n\nHall, London.\n\nBendrath, R. (1974). Veralgemeinerung eines Satzes von R.K. Milne, Mathema-\n\ntische Nachrichten 59: 221–228.\n\nBenes, V., Bodlak, K., Møller, J. and Waagepetersen, R. P. (2001). Bayesian anal-\nysis of log Gaussian Cox process models for disease mapping, In preparation.\nBensmail, H., Celeux, G., Raftery, A. E. and Robert, C. P. (1997). Inference in\n\nmodel-based cluster analysis, Statist. Comp. 7: 1–10.\n\nBernardinelli, L., Clayton, D. G., Pascutto, C., Montomoli, C., Ghislandi, M. and\nSongini, M. (1995). Bayesian analysis of space-time variation in disease risk,\nStatistics in Medicine 14: 2433–2443.\n\nBernardo, J. M. and Smith, A. F. M. (1994). Bayesian Theory, Chichester: Wiley.\nBesag, J. E. (1994). Discussion on the paper by Grenander and Miller, Journal of\n\nthe Royal Statistical Society B 56: 591–592.\n\nBesag, J. E., York, J. C. and Molli´e, A. (1991). Bayesian image restoration, with\ntwo applications in spatial statistics (with discussion), Ann. Inst. Statist. Math.\n43: 1–59.\n\nBest, N. G. and Wakeﬁeld, J. C. (1999). Accounting for inaccuracies in population\ncounts and case registration in cancer mapping studies, Journal of the Royal\nStatistical Society 162: 363–382.\n\nBest, N. G., Arnold, R., Thomas, A., Waller, L. A. and Conlon, E. (1998). Bayesian\nmodels for spatially correlated disease and exposure data, in J. Bernardo,\nJ. Berger, A. Dawid and A. Smith (eds), Bayesian Statistics 6.\n\nBest, N. G., Ickstadt, K. and Wolpert, R. L. (2000). Spatial Poisson regression\nfor health and exposure data measured at disparate resolutions, Journal of the\nAmerican Statistical Association 95: 1076–1088.\n\nBinder, D. A. (1978). Bayesian cluster analysis, Biometrika 65: 31–38.\nBithell, J. (1990). An application of density estimation to geographical epidemi-\n\nology, Statistics in Medicine 9: 691–701",
    "chunk_order_index": 143,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-7cb8e92384d3919fca50f0091ea19a54": {
    "tokens": 1200,
    "content": ". and Wolpert, R. L. (2000). Spatial Poisson regression\nfor health and exposure data measured at disparate resolutions, Journal of the\nAmerican Statistical Association 95: 1076–1088.\n\nBinder, D. A. (1978). Bayesian cluster analysis, Biometrika 65: 31–38.\nBithell, J. (1990). An application of density estimation to geographical epidemi-\n\nology, Statistics in Medicine 9: 691–701.\n\nBlackwell, P. G. (1998). Bayesian inference for a random tessellation process, Tech-\nnical report, Probability and Statistics Report 485/98, University of Sheﬃeld.\nB¨ohning, D. (1999). C.A.MAN-Computer Assisted Analysis of Mixtures and Ap-\n\nplications, Chapman and Hall.\n\nB¨ohning, D., Dietz, E. and Schlattmann, P. (1998). Recent developments in com-\n\nputer assisted mixture analysis., Biometrics 54: 283–303.\n\nB¨ohning, D., Schlattmann, P. and Lindsay, B. G. (1992). C.A.MAN- computer\nassisted analysis of mixtures: Statistical algorithms., Biometrics 48: 283–303.\nBookstein, F. L. (1989). Principal warps: thin-plate splines and the decompo-\nsition of deformations, IEEE Transactions on Pattern Analysis and Machine\nIntelligence 11: 567–585.\n\nBookstein, F. L. (1991). Morphometric Tools for Landmark Analysis: Geometry\n\nand Biology, Cambridge University Press, Cambridge.\n\nBox, G. E. P. and Cox, D. R. (1969). An analysis of transformations, J. Roy.\n\nStatist. Soc. B 26: 211–246.\n\nBreslow, N. and Clayton, D. G. (1993). Approximate inference in generalised linear\n\n\fREFERENCES\n\n261\n\nmixed models, Journal of the American Statistical Association 88: 9–25.\nBrix, A. (1999). Generalized gamma measures and shot-noise Cox processes, Ad-\n\nvances in Applied Probability 31: 929–953.\n\nBrix, A. and Chadoeuf, J. (2000). Spatio-temporal modeling of weeds and shot-\n\nnoise G Cox processes. Submitted.\n\nBrix, A. and Diggle, P. J. (2001). Spatio-temporal prediction for log-Gaussian Cox\n\nprocesses, Journal of the Royal Statistical Society. To appear.\n\nBrix, A. and Møller, J. (2001). Space-time multitype log Gaussian Cox pro-\ncesses with a view to modelling weed data, Scandinavian Journal of Statistics\n28: 471–488.\n\nBrown, P. E., Kaaresen, K. F., Roberts, G. O. and Tonellato, S. (2000). Blur-\ngenerated non-separable space-time models, Journal of the Royal Statistical\nSociety, Series B 62: 847–860.\n\nByers, J. A. (1992). Dirichlet tessellation of bark beetle spatial attack points, J.\n\nAnim. Ecol. 61: 759–768.\n\nByers, S. D. and Besag, J. E. (2000). Inference on a collapsed margin in disease\n\nmapping, Statistics in Medicine 19: 2243–2249.\n\nByers, S. D. and Raftery, A. E. (1998). Nearest neighbor clutter removal for\nestimating features in spatial point processes, J. Amer. Statist. Assoc. 93: 577–\n584.\n\nCai, Y. and Kendall, W. S. (1999). Perfect implementation of simulation for\nconditioned Boolean model via correlated Poisson random, Technical report,\nDepartment of Statistics, Warwick University.\n\nCarlin, B. P. and Louis, T. A. (1996). Bayes and Empirical Bayes Methods for\n\nData Analysis, Chapman and Hall, London.\n\nCarlin, B. P., Gelfand, A. E. and Smith, A. F. M. (1992). Hierarchical Bayesian\n\nanalysis of changepoint problems, Appl. Statist. 41: 389–405.\n\nCarstairs, V. (1981). Small area analysis and health service research, Community\n\nMedicine 3: 131–139.\n\nCarter, D. S. and Prenter, P. M. (1972). Exponential spaces and counting pro-\n\ncesses, Z. Wahr. verw. Geb. 21: 1–19.\n\nCasella, G., Mengersen, K. L. and Robert, C. P. (1999). Perfect slice samplers for\nmixtures of distributions, Technical report, Department of Statistics, Glasgow\nUniversity.\n\nChatﬁeld, C. and Collins, A. J. (1980).\n\nIntroduction to multivariate analysis,\n\nLondon: Chapman & Hall.\n\nChaudhuri, P. and Marron, J. S. (1999). SiZer for exploration of structure in\n\ncurves, J. Amer. Statist. Assoc. 94: 807–823.\n\nChaudhuri, P. and Marron, J. S. (2000). Scale space view of curve estimation,\n\nAnn. Statist. 28: 408–428.\n\nCheng, M. Y. and Hall, P. (1997). Calibrating the excess mass and dip tests of\n\nmodality, J. Roy. Statist. Soc. B",
    "chunk_order_index": 144,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-c515ab60f05e388b5388eba1457aee51": {
    "tokens": 1200,
    "content": "ves, J. Amer. Statist. Assoc. 94: 807–823.\n\nChaudhuri, P. and Marron, J. S. (2000). Scale space view of curve estimation,\n\nAnn. Statist. 28: 408–428.\n\nCheng, M. Y. and Hall, P. (1997). Calibrating the excess mass and dip tests of\n\nmodality, J. Roy. Statist. Soc. B 60: 579–589.\n\nChessa, A. G. (1995). Conditional simulation of spatial stochastic models for reser-\n\nvoir heterogeneity, PhD thesis, Technical University of Delft.\n\nChib, S. and Greenberg, E. (1995). Hierarchical analysis of sur models with exten-\nsions to correlated serial errors and time-varying parameter models, J. Econo-\nmetrics 68: 339–360.\n\n\f262\n\nREFERENCES\n\nChil`es, J. P. (1989). Mod`elisation g´eostatistique de r´eseaux de fractures, in\n\nM. Armstrong (ed.), Geostatistics, Dordrecht: Kluwer, pp. 57–76.\n\nChristensen, O. F. and Waagepetersen, R. P. (2001). Bayesian prediction of spatial\n\ncount data using generalised linear mixed models, Submitted.\n\nChristensen, O. F., Møller, J. and Waagepetersen, R. P. (2000). Geometric ergodic-\nity of Metropolis-Hastings algorithms for conditional simulation in generalised\nlinear mixed models, Technical Report R-00-2010, Department of Mathemat-\nical Sciences, Aalborg University. Methodology and Computation in Applied\nProbability. To appear.\n\nChu, Y., Guerrero, M., Gruendl, R. A., Williams, R. M. and Kaler, J. B. (2001).\nChandra Reveals the X-Ray Glint in the Cat’s Eye, The Astrophysical Journal\n(Letters) 553: L69–L72.\n\nClayton, D. G. and Bernardinelli, L. (1992). Bayesian methods for mapping disease\nrisk, in P.Elliott, J. Cuzick, D. English and R. Stern (eds), Geographical and\nEnvironmental Epidemiology: Methods for Small-Area Studies, Oxford Univer-\nsity Press.\n\nClayton, D. G. and Kaldor, J. (1987). Empirical Bayes estimates of age-\nstandardized relative risks for use in disease mapping, Biometrics 43: 671–681.\nClyde, M. (1999). Bayesian model averaging and model search stratergies (with\ndiscussion), in J. M. Bernardo, J. O. Berger, A. P. Dawid and A. F. Smith\n(eds), Bayesian statistics 6, Oxford: Clarendon Press.\n\nColes, P. and Jones, B. (1991). A lognormal model for the cosmological mass\ndistribution, Monthly Notices of the Royal Astronomical Society 248: 1–13.\nCox, D. R. (1955). Some statistical models related with series of events, J. Roy.\n\nStatist. Soc. B 17: 129–164.\n\nCox, D. R. and Isham, V. (1980). Point Processes, Chapman and Hall, London.\nCressie, N. A. C. (1993). Statistics for Spatial Data, 2nd edn, London: Chapman\n\n& Hall.\n\nCressie, N. A. C. and Huang, H.-C. (1999). Classes of nonseparable, spatio-\ntemporal stationary covariance functions, Journal of the American Statistical\nAssociation 94: 1330–1340.\n\nCressie, N. A. C. and Lawson, A. B. (2000). Hierarchical probability mod-\nels and bayesian analysis of mine locations, Advances in Applied Probability\n32(2): 315–330.\n\nCressie, N. A. C. and Mugglin, A. (2000). Spatio-temporal hierarchical modelling\nof an infectious disease from (simulated) count data, in J. Bethlehem and\nP. van der Heijden (eds), Compstat 2000, Physica verlag, Heidelberg.\n\nDaley, D. J. and Vere-Jones, D. (1988). An Introduction to the Theory of Point\n\nProcesses, Springer-Verlag, New York.\n\nDasgupta, A. and Raftery, A. E. (1998). Detecting features in spatial point\nprocesses with clutter via model-based clustering, J. Amer. Statist. Assoc.\n93: 294–302.\n\nDavis, J. E. (2001). Event Pileup in Charged Coupled Devices, The Astrophysical\n\nJournal p. to appear.\n\nDe Bonet, J. S. (1997). Multiresolution sampling procedure for analysis and syn-\n\nthesis of texture images, Computer Graphics Proceedings, pp. 361–368.\n\nDe Oliveira, V., Kedem, B. and Short, D. S. (1997). Bayesian prediction of trans-\n\n\fREFERENCES\n\n263\n\nformed Gaussian random ﬁelds, J. Amer. Statist. Assoc. 92: 1422–1433.\nDeibolt, J. and Robert, C. P. (1994). Estimation of ﬁnite mixture distributions\n\nthrough Bayesian sampling, J. Roy. Statist. Soc. B 56: 363–375.",
    "chunk_order_index": 145,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-1e85a52eaaf61ab17587473aee29184a": {
    "tokens": 1200,
    "content": "em, B. and Short, D. S. (1997). Bayesian prediction of trans-\n\n\fREFERENCES\n\n263\n\nformed Gaussian random ﬁelds, J. Amer. Statist. Assoc. 92: 1422–1433.\nDeibolt, J. and Robert, C. P. (1994). Estimation of ﬁnite mixture distributions\n\nthrough Bayesian sampling, J. Roy. Statist. Soc. B 56: 363–375.\n\nDempster, A. P., Laird, N. M. and Rubin, D. B. (1977a). Maximum likelihood\nfrom incomplete data via the EM algorithm (with discussion), Journal of the\nRoyal Statistical Society, Series B, Methodological 39: 1–37.\n\nDempster, A. P., Schatzoﬀ, M. and Wermuth, N. (1977b). A simulation study of\nalternatives to ordinary least squares, J. Amer. Statist. Assoc. 72: 77–106.\nDenison, D. G. T., Adams, N. M., Holmes, C. C. and Hand, D. J. (2002a). Bayesian\n\npartition modelling, Comp. Statist. Data Anal. (to appear).\n\nDenison, D. G. T. and Holmes, C. C. (2001). Bayesian partitioning for estimating\n\ndisease risk, Biometrics 57: 143–149.\n\nDenison, D. G. T., Holmes, C. C., Mallick, B. K. and Smith, A. F. M. (2002b).\nBayesian Methods for Nonlinear Classiﬁcation and Regression, Chichester:\nJohn Wiley. (to appear).\n\nDey, D. K., Ghosh, S. K. and Mallick, B. K. (eds) (2000). Generalised Linear\n\nModels: A Bayesian perspective, New York: Marcel Dekker.\n\nDiggle, P. J. (1978). On parameter estimation for spatial point processes, J. Roy.\n\nStatist. Soc. B 40: 178–181.\n\nDiggle, P. J. (1983). Statistical analysis of spatial point processes, London: Aca-\n\ndemic Press.\n\nDiggle, P. J. (1985a). A kernel method for smoothing point process data, App.\n\nStatist. 34: 138–147.\n\nDiggle, P. J. (1985b). A kernel method for smoothing point process data, Applied\n\nStatistics 34: 138–147.\n\nDiggle, P. J. (1990). A point process modelling approach to raised incidence of a\nrare phenomenon in the vicinity of a prespeciﬁed point, Jour. Royal Statist.\nSoc. A 153: 349–362.\n\nDiggle, P. J. and Rowlingson, B. (1993). A conditional approach to point process\nmodelling of elevated risk, Technical Report MA93/83, Lancaster University.\nDiggle, P. J., Chetwynd, A., Haggvist, R. and Morris, S. (1995). Second-order anal-\nysis of space-time clustering, Statistical Methods in Medical Research 4: 124–\n136.\n\nDiggle, P. J., Fiksel, T., Grabarnik, P., Ogata, Y., Stoyan, D. and Tanemura,\nM. (1994). On parameter estimation for pairwise interaction processes, Int.\nStatist. Rev. 62: 99–117.\n\nDiggle, P. J., Tawn, J. A. and Moyeed, R. A. (1998). Model-based geostatistics\n\n(with discussion), Appl. Statist.\n\nDolk, H., Bushby, A., Armstrong, B. and Walls, P. H. (1998). Geographical varia-\ntion in anopthalmia and microthalmia in England,1988-1994, British Medical\nJournal 317: 905–910.\n\nDonoho, D. (1988). One sided inference about functionals of a density, Ann. Statist.\n\n16: 1390–1420.\n\nDryden, I. and Mardia, K. V. (1997). The Statistical Analysis of Shape, Wiley,\n\nNew York.\n\nDuda, R. O., Hart, P. E. and Stork, D. G. (2001). Pattern Classiﬁcation, second\n\nedn, Wiley, New York.\n\n\f264\n\nREFERENCES\n\nDuﬀy, P. H., Bartels, P. H. and Burchﬁeld, J. (1981). Signiﬁcance probability\nmapping: An aid in the topographic analysis of brain electrical activity, Elec-\ntroencephalogr Clin Neurophysiol 60: 455–463.\n\nElberling, C., Bak, C., Kofoed, B., Lebech, J. and Saermark, K. (1982). Auditory\nmagnetic ﬁelds from the human cerebral cortex: location and strength of an\nequivalent current dipole., Acta Neurol Scand 65: 553–569.\n\nElliott, J. J. and Arbib, R. S. (1953). Origin and status of the house ﬁnch in the\n\neastern united states, Auk 70: 31–37.\n\nElliott, P., Wakeﬁeld, J. C., Best, N. G. and Briggs, D. G. (1999). Spatial Epi-\n\ndemiology: Methods and Applications, Oxford: University Press",
    "chunk_order_index": 146,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-74bcbd38cf8ede612bc61dbe64bf3b5e": {
    "tokens": 1200,
    "content": "65: 553–569.\n\nElliott, J. J. and Arbib, R. S. (1953). Origin and status of the house ﬁnch in the\n\neastern united states, Auk 70: 31–37.\n\nElliott, P., Wakeﬁeld, J. C., Best, N. G. and Briggs, D. G. (1999). Spatial Epi-\n\ndemiology: Methods and Applications, Oxford: University Press.\n\nElvis, M., Matsuoka, M., Siemiginowska, A., Fiore, F., Mihara, T. and Brinkmann,\nW. (1994). An ASCA GIS spectrum of S5 0014 + 813 at z = 3.384, Astro-\nphysical Journal 436: L55–L58.\n\nEveritt, B. S., Landau, S. and Leese, M. (2001). Cluster Analysis, fourth edn,\n\nArnold, London.\n\nFan, J. Q. and Gijbels, I. (1996). Local polynomial modelling and its applications,\n\nLondon: Chapman and Hall.\n\nFessler, J. A. and Hero, A. O. (1994). Space-alternating generalized expectation-\nmaximization algorithm, IEEE Transactions on Signal Processing 42: 2664–\n2677.\n\nFisher, N. I. and Marron, J. S. (2001). Mode testing via the excess mass estimate,\n\nBiometrika. (to appear).\n\nFisher, N. I., Mammen, E. and Marron, J. S. (1994). Testing for multimodality,\n\nComp. Statist. Data Anal. 18: 499–512.\n\nFraley, C. and Raftery, A. E. (1998). How many clusters? which clustering method?\nanswers via model-based cluster analysis, Computer Journal 41: 578–588.\nFreeman, P. E., Graziani, C., Lamb, D. Q., Loredo, T. J., Fenimore, E. E., Mu-\nrakami, T. and Yashida, A. (1999). Statistical analysis of spectral line candi-\ndates in gamma-ray burst GRB 870303, The Astrophysical Journal 524: 753–\n771.\n\nFriston, K. J., Frith, C. D., Liddle, P. F., Dolan, R. J., Lammertsma, A. A. and\nFrackowiak, R. S. J. (1990). The relationship between global and local changes\nin PET scans, Journal of cerebral blood ﬂow and metabolism 10: 458–466.\nGalaburda, A. and Sanides, F. (1980). Cytoarchitectonic organization of the hu-\n\nman auditory cortex, J Comp Neurol 190: 597–610.\n\nGallinat, J. and Hegerl, U. (1994). Dipole source analysis. linking scalp potentials\nto their generating neuronal structures., Pharmacopsychiatry 27: 52–53.\nGangnon, R. E. (1998). Disease Rate Mapping via Cluster Models, PhD thesis,\n\nUniversity of Wisconsin, Madison WI.\n\nGangnon, R. E. and Clayton, M. K. (2000). Bayesian detection and modeling of\n\nspatial disease clustering, Biometrics 56: 922–935.\n\nGangnon, R. E. and Clayton, M. K. (2001). A weighted average likelihood ratio\ntest for spatial clustering of disease, Statistics in Medicine 20: 2977–2987.\nGelfand, A. E. (1996). Model determination using sampling-based methods, in\nW. R. Gilks, S. Richardson and D. J. Spiegelhalter (eds), Markov Chain Monte\nCarlo in Practice, London: Chapman & Hall, pp. 145–161.\n\nGelfand, A. E. and Carlin, B. P. (1993). Maximum likelihood estimation for con-\n\n\fREFERENCES\n\n265\n\nstrained or missing data models, Can. J. Statist. 21: 303–311.\n\nGelfand, A. E. and Smith, A. F. M. (1990). Sampling-based approaches to cal-\nculating marginal densities, Journal of the American Statistical Association\n85: 398–409.\n\nGelman, A. and Rubin, D. B. (1992). Inference from iterative simulations using\n\nmultiple sequences (with discussion), Statistical Science 7: 457–472.\n\nGelman, A., Carlin, J. B., Stern, H. S. and Rubin, D. B. (1995). Bayesian Data\n\nAnalysis, Chapman & Hall, London.\n\nGeman, S. and Geman, D. (1984). Stochastic relaxation, Gibbs distributions and\nthe Bayesian restoration of images, IEEE Trans. Patt. Anal. Mach. Intelligence\n6: 721–740.\n\nGeyer, C. J. (1999).\n\nin\nO. Barndorﬀ-Neilsen, W. S. Kendall and M. N. M. van Lieshout (eds), Stochas-\ntic Geometry: Likelihood and Computation, CRC Press, New York, chapter 3.\nGeyer, C. J. and Møller, J. (1994). Simulation procedures and likelihood inference\n\nLikelihood inference for spatial point processes,\n\nfor spatial point processes, Scan. J. Statist. 21: 84–88.\n\nGhosh, M., Natarajan, K., Stroud, T. and Carlin, B. P",
    "chunk_order_index": 147,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-9b3b02de710497ec4cf17e60fd565f19": {
    "tokens": 1200,
    "content": "eds), Stochas-\ntic Geometry: Likelihood and Computation, CRC Press, New York, chapter 3.\nGeyer, C. J. and Møller, J. (1994). Simulation procedures and likelihood inference\n\nLikelihood inference for spatial point processes,\n\nfor spatial point processes, Scan. J. Statist. 21: 84–88.\n\nGhosh, M., Natarajan, K., Stroud, T. and Carlin, B. P. (1998). Generalized linear\nmodels for small-area estimation, Journal of the American Statistical Associ-\nation 93: 273–282.\n\nGhosh, M., Natarajan, K., Waller, L. A. and Kim, D. (1999). Hierarchical Bayes\nGLMs for the analysis of spatial data: An application to disease mapping, J.\nStatist. Plan. Inf. 75: 305–318.\n\nGhosh, S., Nowak, Z. and Lee, K. (1997). Tessellation-based computational meth-\nods for the characterization and analysis of heterogeneous microstructures,\nComposites Sci. Tech. 57: 1187–1210.\n\nGilks, W. R., Richardson, S. and Spiegelhalter, D. J. (1996). Markov chain Monte\n\nCarlo in practice, London: Chapman and Hall.\n\nGiudici, P., Knorr-Held, L. and Rasser, G. (2000). Modelling categorical covariates\nin Bayesian disease mapping by partition structures, Statist. Med. 19: 2579–\n2593.\n\nGlasbey, C. A. (1998). A spatio-temporal model of solar radiation microclimate,\nin K. V. Mardia, R. G. Aykroyd and I. L. Dryden (eds), Proceedings in Spatial\nTemporal Modelling and its Applications, Leeds University Press, pp. 75–78.\n\nGodtliebsen, F., Marron, J. S. and Chaudhuri, P. (2001a). Signiﬁcance in scale\nspace, Technical report, Department of Statistics, University of North Carolina.\nGodtliebsen, F., Marron, J. S. and Chaudhuri, P. (2001b). Signiﬁcance in scale\nspace for bivariate density estimation, J. Comp. Graph. Statist. (to appear).\nGood, I. J. and Gaskins, R. A. (1980). Density estimation and bump-hunting\nby the penalized maximum likelihood method exempliﬁed by scattering and\nmeteorite data (with discussion), J. Amer. Statist. Assoc. 75: 42–73.\n\nGoodall, C. R. and Mardia, K. V. (1994). Challenges in multivariate spatial mod-\nelling, Proceedings 17th International Biometric Conference, Hamilton, On-\ntario, pp. 8–12.\n\nGrandell, J. (1976). Doubly Stochastic Poisson Processes, Springer-Verlag, Berlin.\nGreen, P. J. (1995). Reversible jump Markov chain Monte Carlo computation and\n\nBayesian model determination, Biometrika 82: 711–732.\n\nGreen, P. J. and Murdoch, D. J. (1999). Exact sampling for Bayesian inference:\n\n\f266\n\nREFERENCES\n\ntowards general purpose algorithms, in J. M. Bernardo, J. O. Berger, A. P.\nDawid and A. F. M. Smith (eds), Bayesian Statistics 6, Oxford: Oxford Uni-\nversity Press.\n\nGreen, P. J. and Richardson, S. (2000). Spatially correlated allocation models for\ncount data, Technical report, Department of Statistics, Bristol University.\nGreen, P. J. and Sibson, R. (1978). Computing Dirichlet tessellations in the plane,\n\nComp. J. 21: 168–173.\n\nH¨aggstr¨om, O., van Lieshout, M. N. M. and Møller, J. (1999). Characterisation and\nsimulation results including exact simulation for some spatial point processes,\nBernoulli 5: 641–659.\n\nHaldorsen, H. H. (1983). Reservoir characterization procedures for numerical sim-\n\nulation, PhD thesis, University of Texas, Austin.\n\nHand, D. J. (1981). Discrimination and Classiﬁcation, Chichester: Wiley.\nHandcock, M. S. and Stein, M. L. (1994). An approach to statistical spatial-\ntemporal modeling of meteorological ﬁelds, J. Amer. Statist. Assoc. 89: 368–\n390.\n\nHandcock, M. S. and Wallis, J. R. (1993). A Bayesian analysis of kriging, Tech-\n\nnometrics 35: 403–410.\n\nHandcock, M. S. and Wallis, J. R. (1994). An approach to statistical spatial-\ntemporal modeling of meteorological ﬁelds (with discussion), Journal of the\nAmerican Statistical Association 89: 368–390.\n\nHans, C. M. (2001). Accounting for Absorption Lines in High Energy Spectra via\nBayesian Modelling, PhD thesis, Harvard University, Dept. of Statistics.\nHans, C. M. and van Dyk, D. A. (2002). Accounting for absorption lines in\nhigh energy spectra, Statistical Challenges in Modern Astronomy III (Editors:\nE. Feigelson and G. Babu), Springer–Verlag",
    "chunk_order_index": 148,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-a43a872c93f6e258e15ba99e169ebcc6": {
    "tokens": 1200,
    "content": "89: 368–390.\n\nHans, C. M. (2001). Accounting for Absorption Lines in High Energy Spectra via\nBayesian Modelling, PhD thesis, Harvard University, Dept. of Statistics.\nHans, C. M. and van Dyk, D. A. (2002). Accounting for absorption lines in\nhigh energy spectra, Statistical Challenges in Modern Astronomy III (Editors:\nE. Feigelson and G. Babu), Springer–Verlag, New York.\n\nHartigan, J. A. and Hartigan, P. M. (1985). The DIP test of multimodality, Ann.\n\nStatist. 13: 70–84.\n\nHartigan, J. A. and Mohanty, S. (1992). The RUNT test from multimodality, J.\n\nClassiﬁcation 9: 63–70.\n\nHaslett, J. (1989). Space time modelling in meteorology — a review, Bulletin of\n\nthe International Statistical Institute 51: 229–246.\n\nHastie, T. J. and Tibshirani, R. J. (1990). Generalized Additive Models, London:\n\nChapman & Hall.\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and\n\ntheir applications, Biometrika 57: 97–109.\n\nHeikkinen, J. and Arjas, E. (1998). Non-parametric Bayesian estimation of a\n\nspatial Poisson intensity, Scan. J. Statist. 25: 435–450.\n\nHeikkinen, J. and Arjas, E. (1999). Modeling a Poisson forest in variable elevation:\n\nA nonparametric Bayesian approach, Biometrics 55: 738–745.\n\nHigdon, D., Swall, J. and Kern, J. (1999). Non-stationary spatial modeling, in\nJ. M. Bernardo, J. O. Berger, A. P. Dawid and A. F. M. Smith (eds), Bayesian\nStatistics VI, Oxford: Clarendon Press.\n\nHjort, N. L. and Omre, H. (1994). Topics in spatial statistics, Scan. J. Statist.\n\n21: 289–357.\n\nHodder, I. and Orton, C. (1976). Spatial analysis in archeology, Cambridge: Cam-\n\nbridge University Press.\n\n\fREFERENCES\n\n267\n\nHolmes, A. P., Blair, R. C., Watson, D. G. and Ford, I. (1996). Nonparametric\nanalysis of statistic images from functional mapping experiments, Journal of\ncerebral blood ﬂow and metabolism 16: 7–22.\n\nHuang, F. and Ogata, Y. (2001). Comparison of two methods for calculating the\npartition functions of various spatial statistical models, Australian and New\nZealand J. Statist. 43: 47–65.\n\nHurn, M. (1998). Confocal ﬂourescence microscopy of leaf cells: an application of\n\nbayesian image analysis, Appl. Statist. 47: 361–377.\n\nHurn, M., Husby, O. and Rue, H. (2001). Image analysis, in P. Green, N. Hjort and\nS. Richardson (eds), Highly Structured Stochastic Systems, Oxford University\nPress, London, chapter 7.\n\nHyndman, R. J., Bashtannyk, D. M. and Grunwald, G. K. (1996). Estimating and\n\nvisualizing conditional densities, J. Comp. Graph. Statist. 5: 315–336.\n\nIzenman, A. J. and Sommer, C. (1988). Philatelic mixtures and multimodal den-\n\nsities, J. Amer. Statist. Assoc. 83: 941–953.\n\nJones, R. H. and Zhang, Y. (1997). Models for continuous stationary space-time\nprocesses, in T. G. Gregoire, D. R. Brillinger, P. J. Diggle, E. Russek-Cohen,\nW. G. Warren and R. D. Wolﬁnger (eds), Modelling Longitudinal and Spatially\nCorrelated Data, Springer-Verlag, New York, pp. 289–298.\n\nJournel, A. G. and Huijbregts, C. J. (1978). Mining geostatistics, Academic Press.\nKang, H., van Dyk, D. A., Yu, Y., Siemiginowska, A., Connors, A. and Kashyap, V.\n(2002). New MCMC methods to address pile-up in the Chandra x-ray obser-\nvatory, Statistical Challenges in Modern Astronomy III (Editors: E. Feigelson\nand G. Babu), Springer–Verlag, New York.\n\nKaufman, L. and Rousseeuw, P. J. (1990). Finding groups in data: An introduction\n\nto cluster analysis, New York: Wiley.\n\nKelly, F. P. and Ripley, B. D. (1976). On Strauss’s model for clustering, Biometrika\n\n63: 357–360.\n\nKelsall, J. and Diggle, P. J. (1995a). Kernel estimation of relative risk, Bernouilli\n\n1: 3–16.\n\nKelsall, J. and Diggle, P. J. (1995b). Non-parametric estimation of spatial variation\n\nin relative risk, Statistics in Medicine 14: 233",
    "chunk_order_index": 149,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-2a0476234f9c002d67720c67b3b41876": {
    "tokens": 1200,
    "content": ". D. (1976). On Strauss’s model for clustering, Biometrika\n\n63: 357–360.\n\nKelsall, J. and Diggle, P. J. (1995a). Kernel estimation of relative risk, Bernouilli\n\n1: 3–16.\n\nKelsall, J. and Diggle, P. J. (1995b). Non-parametric estimation of spatial variation\n\nin relative risk, Statistics in Medicine 14: 2335–2342.\n\nKelsall, J. and Diggle, P. J. (1998). Spatial variation in risk of disease: a nonpara-\n\nmetric binary regression approach, Applied Statistics 47: 559–573.\n\nKendall, W. S. (1998). Perfect simulation for the area-interaction point process,\nin L. Accardi and C. C. Heyde (eds), Probability towards the year 2000, World\nScientiﬁc Press.\n\nKendall, W. S. and Møller, J. (2000). Perfect simulation using dominating pro-\ncesses on ordered spaces, with application to locally stable point processes,\nAdv. Appl. Prob 32: 844–865.\n\nKendall, W. S. and Th¨onnes, E. (1999). Perfect simulation in stochastic geometry,\n\nPattern Recognition 32: 1569–1586.\n\nKent, J. T. and Mardia, K. V. (1994). The link between Kriging and thin plate\nsplines, in F. P. Kelly (ed.), Probability, Statistics and Optimization: A Tribute\nto Peter Whittle, Wiley, Chichester, pp. 325–339.\n\nKent, J. T., Mardia, K. V., Morris, R. J. and Aykroyd, R. G. (2000). Procrustes\ngrowth models for shape, Proceedings of the First Joint Statistical Meeting New\n\n\f268\n\nDelhi, India, pp. 236–238.\n\nREFERENCES\n\nKent, J. T., Mardia, K. V., Morris, R. J. and Aykroyd, R. G. (2001). Functional\nmodels of growth for landmark data, in K. V. Mardia and R. G. Aykroyd (eds),\nProceedings in Functional and Spatial Data Analysis, Leeds University Press,\npp. 109–115.\n\nKingman, J. F. C. (1993). Poisson Processes, Clarendon Press, Oxford.\nKnight, R. T., Scabini, D., Woods, D. L. and Clayworth, C. (1988). The eﬀects of\nlesions of superior temporal gyrus and inferior parietal lobe on temporal and\nvertex components of the human AEP, Electroencephalogr Clin Neurophysiol\npp. 499–509.\n\nKnorr-Held, L. (2000). Bayesian modelling of inseparable space-time variation in\n\ndisease risk, Statistics in Medicine 19: 2555–2567.\n\nKnorr-Held, L. and Besag, J. E. (1998). Modelling risk from a disease in time and\n\nspace, Statistics in Medicine. to appear.\n\nKnorr-Held, L. and Rasser, G. (2000). Bayesian detection of clusters and discon-\n\ntinuities in disease maps, Biometrics 56: 13–21.\n\nKnox, E. G. (1964). The detection of space-time interactions, Applied Statistics\n\n13: 25–29.\n\nKnox, E. G. (1989). Detection of clusters, in P. Elliott (ed.), Methodology of\nenquiries into disease clustering, Small Area Health Statistics Unit, London,\npp. 17–20.\n\nKolaczyk, E. D. (1999). Bayesian multi-scale models for poisson processes, Journal\n\nof the American Statistical Association 94: 920–933.\n\nKraft, R. P., Kregenow, J. M., Forman, W. R., Jones, C. and Murray, S. S. (2001).\nChandra Observations of the X-Ray Point Source Population in Centaurus A,\nThe Astrophysical Journal 560: 675–688.\n\nK¨uhr, H., Witzel, A., Pauliny-Toth, I. I. K. and Nauber, U. (1981). A catalogue\nof extragalactic radio sources having ﬂux densities greater than 1 Jy at 5 GHz,\nAstronomy and Astrophysics, Supplement Series 45: 367–430.\n\nKulldorﬀ, M. and Nagarwalla, N. (1995). Spatial disease clusters:detection and\n\ninference, Statistics in Medicine 14: 799–810.\n\nKyriakidis, P. C. and Journel, A. G. (1999). Geostatistical space-time models: A\n\nreview, Mathematical Geology 31: 651–684.\n\nLange, K. and Carson, R. (1984). Em reconstruction algorithms for emission and\ntransmission tomography, Journal of Computer Assisted Tomography 8: 306–\n316.\n\nLangford, I., Leyland, A., Rashbash, J., Goldstein, H., McDonald, A. and Ben-\ntham, G. (1999). Multilevel modelling of area-based health data, in A. B.\nLawson, A. Biggeri, D. Boehning, E. Lesaﬀre, J.-F. Viel and R. Bertollini\n(eds), Disease mapping and Risk Assessment for Public Health Decision Mak-\ning, Wiley, chapter",
    "chunk_order_index": 150,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-6e061561c0de5071d761c855d2a11cef": {
    "tokens": 1200,
    "content": "I., Leyland, A., Rashbash, J., Goldstein, H., McDonald, A. and Ben-\ntham, G. (1999). Multilevel modelling of area-based health data, in A. B.\nLawson, A. Biggeri, D. Boehning, E. Lesaﬀre, J.-F. Viel and R. Bertollini\n(eds), Disease mapping and Risk Assessment for Public Health Decision Mak-\ning, Wiley, chapter 16, pp. 217–227.\n\nLantu´ejoul, C. (1997). Conditional simulation of object-based models, in D. Jeulin\n(ed.), Advances in theory and applications of random sets, World Scientiﬁc\nPublishing, pp. 271–288.\n\nLast, G. (1990). Some remarks on conditional distributions for point processes,\n\nStochastic Processes and their Applications 34: 121–135.\n\nLawson, A. B. (1993a). Discussion contribution, Journal of the Royal Statistical\n\n\fREFERENCES\n\nSociety B 55: 61–62.\n\n269\n\nLawson, A. B. (1993b). On the analysis of mortality events associated with a\n\nprespeciﬁed ﬁxed point, J. Roy. Statist. Soc. A 156: 285–298.\n\nLawson, A. B. (1995). Markov chain Monte Carlo methods for putative pollu-\ntion source problems in environmental epidemiology, Statistics in Medicine\n14: 2473–2486.\n\nLawson, A. B. (1997). Some spatial statistical tools for pattern recognition, in\nA. Stein, F. W. T. P. de Vries and J. Schut (eds), Quantitative Approaches\nin Systems Analysis, Vol. 7, C. T. de Wit Graduate School for Production\nEcology, pp. 43–58.\n\nLawson, A. B. (2000). Cluster modelling of disease incidence via RJMCMC meth-\n\nods: a comparative evaluation, Statistics in Medicine 19: 2361–2376.\n\nLawson, A. B. (2001). Statistical Methods in Spatial Epidemiology, Wiley, New\n\nYork.\n\nLawson, A. B. and Clark, A. (1999a). Markov chain Monte Carlo methods for clus-\ntering in case event and count data in spatial epidemiology, in M. E. Halloran\nand D. Berry (eds), Statistics and Epidemiology: Environment and Clinical\nTrials, Springer verlag, New York, pp. 193–218.\n\nLawson, A. B. and Clark, A. (1999b). Markov chain Monte Carlo methods for\nputative sources of hazard and general clustering, in A. B. Lawson, D. Bohn-\ning, A. Biggeri, J.-F. Viel and R. Bertollini (eds), Disease Mapping and Risk\nAssessment for Public Health, Wiley WHO, chapter 9.\n\nLawson, A. B. and Clark, A. (2001). Spatial mixture relative risk models applied\n\nto disease mapping, Statitsics in Medicine. in press.\n\nLawson, A. B. and Cressie, N. A. C. (2000). Spatial statistical methods for en-\nvironmental epidemiology, in C. R. Rao and P. K. Sen (eds), Handbook of\nStatistics:Bio-Environmental and Public Health Statistics, Vol. 18, Elsevier,\npp. 357–396.\n\nLawson, A. B. and Kulldorﬀ, M. (1999). A review of Cluster Detection Meth-\nods, in A. B. Lawson, D. B´’ohning, E. Lesaﬀre, A. Biggeri, J.-F. Viel and\nR. Bertollini (eds), Disease Mapping and Risk Assessment for Public Health,\nWiley, chapter 7.\n\nLawson, A. B. and Williams, F. L. R. (1993). Applications of extraction mapping\n\nin environmental epidemiology, Statistics in Medicine 12: 1249–1258.\n\nLawson, A. B. and Williams, F. L. R. (1994). Armadale: a case study in environ-\nmental epidemiology, Journal of the Royal Statistical Society A 157: 285–298.\nLawson, A. B., B¨ohning, D., Lessafre, E., Biggeri, A., Viel, J.-F. and Bertollini, R.\n(eds) (1999). Disease Mapping and Risk Assessment for Public Health, Wiley.\nLindeberg, T. (1994). Scale-Space Theory in Computer Vision, Dordrecht: Kluwer.\nLindley, D. V. and Smith, A. F. M. (1972). Bayes estimates for the linear model\n\n(with discussion), J. Roy. Statist. Soc. B 34: 1–41.\n\nLink, W. A. and Sauer, J. R. (1998). Estimating population change from count\ndata: application to the North American breeding bird survey, Ecological Ap-\nplications 8: 258–268.\n\nLoizeaux, M. and McKeague, I. W. (2001). Perfect sampling for posterior land-\nmark distributions with an application to the detection of disease clusters, IMS\nLecture Notes - Monograph Series: Volume 37, pp. 321–331.\n\n\f270\n\nREFERENCES\n\nLoredo, T. J. (1993). Promise of Bayesian inference for astrophysics, Statisti-\ncal Challenges in Modern Astronomy (Editors: E. Feig",
    "chunk_order_index": 151,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-feb4f00ff0275a20bd5702092ad78fed": {
    "tokens": 1200,
    "content": "–268.\n\nLoizeaux, M. and McKeague, I. W. (2001). Perfect sampling for posterior land-\nmark distributions with an application to the detection of disease clusters, IMS\nLecture Notes - Monograph Series: Volume 37, pp. 321–331.\n\n\f270\n\nREFERENCES\n\nLoredo, T. J. (1993). Promise of Bayesian inference for astrophysics, Statisti-\ncal Challenges in Modern Astronomy (Editors: E. Feigelson and G. Babu),\nSpringer-Verlag, New York, pp. 275–306.\n\nLucas, P. (2001). Expert knowledge and its role in learning bayesian networks in\nmedicine: An appraisal, in S. Quaglioni, P. Barahona and S. Andreassen (eds),\nArtiﬁcial Intelligence in Medicine, Springer Verlag, New York, pp. 156–166.\nLucy, L. B. (1974). An iterative technique for the rectiﬁcation of observed distri-\n\nbutions, The Astrophysical Journal 79: 745–754.\n\nLund, J. and Th¨onnes, E. (2000). Perfect simulation for point processes given\nnoisy observations, Technical report, Department of Statistics, University of\nWarwick.\n\nLund, J., Penttinen, A. and Rudemo, M. (1999). Bayesian analysis of spatial point\npatterns from noisy observations, Technical report, Department of Mathemat-\nics and Physics, The Royal Veterinary and Agricultural University.\n\nMadigan, D. and Raftery, A. E. (1994). Model selection and accounting for model\nuncertainty in graphical models using Occam’s window, Journal of the Amer-\nican Statistical Association 89: 1535–1546.\n\nMantel, N. (1967). The detection of disease clustering and a generalised regression\n\napproach, Cancer Research 27: 209–220.\n\nMardia, K. V. and Goodall, C. R. (1993). Spatial-temporal analysis of multivariate\nenvironmental monitoring data, in G. P. Patil and C. R. Rao (eds), Multivariate\nEnvironmental Statistics, Elsevier, pp. 347–386.\n\nMardia, K. V. and Jupp, P. E. (2000). Directional Statistics, Wiley, Chichester.\nMardia, K. V., Aykroyd, R. G. and Dryden, I. L. (eds) (1999). Spatial Temporal\nModelling and Its Applications, Proceedings of the 18th LASR Workshop, Leeds\nUniversity Press.\n\nMardia, K. V., Goodall, C. R., Redfern, E. J. and Alonso, F. J. (1998). The Kriged\n\nKalman ﬁlter (with discussion), TEST 7: 217–252.\n\nMardia, K. V., Kent, J. T. and Bibby, J. M. (1979). Multivariate analysis, London:\n\nAcademic Press.\n\nMardia, K. V., Kent, J. T., Little, J. and Goodall, C. R. (1996). Kriging and\n\nsplines with derivative information, Biometrika 83: 207–221.\n\nMarshall, R. J. (1991). A review of methods for the statistical analysis of spatial\n\npatterns of disease, J. Roy. Statist. Soc. A 154: 421–441.\n\nMat´ern, B. (1960). Spatial Variation, Meddelanden fran Statens Skogforskningsin-\n\nstitut, Band 49, No. 5.\n\nMat´ern, B. (1986). Spatial Variation, Lecture Notes in Statistics. Springer-Verlag,\n\nBerlin.\n\nMatheron, G. (1975). Random sets and integral geometry, New York: Wiley.\nMcCullagh, P. and Nelder, J. A. (1989). Generalized Linear Models (Second edi-\n\ntion), Chapman & Hall, London.\n\nMcLachlan, G. J. and Basford, K. E. (1988). Mixture models: Inference and Ap-\nplications to Clustering., Statistics: Textbooks and Monographs, 84. New York\netc.: Marcel Dekker, Inc. xi, 253 p. .\n\nMeng, X.-L. and van Dyk, D. A. (1997). The EM algorithm – an old folk song sung\nto a fast new tune (with discussion), Journal of the Royal Statistical Society,\nSeries B, Methodological 59: 511–567.\n\n\fREFERENCES\n\n271\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H. and Teller, E.\n(1953). Equations of state calculations by fast computing machines, J. Chem.\nPhys. 21: 1087–91.\n\nMiller, D. M. (1984). Reducing transformation bias in curve ﬁtting, Amer. Statist.\n\n38: 124–126.\n\nMilne, R. K. (1970). Identiﬁcability for random translations of Poisson processes,\nZeitschrift f¨ur Wahrscheinlichkeitstheorie und verwandte Gebiete 15: 195–201.\nMinnotte, M. C. (1997). Nonparametric testing of the existence of modes, Ann.\n\nStatist. 25: 1646–1660.\n\nMinnotte, M. C. and Scott, D. W. (1993). The mode tree: a tool for visualization\n\nof nonparametric density features, J. Comp. Graph.",
    "chunk_order_index": 152,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-54d1bfdcd5dc34085b27fa10ad4bd020": {
    "tokens": 1200,
    "content": "itschrift f¨ur Wahrscheinlichkeitstheorie und verwandte Gebiete 15: 195–201.\nMinnotte, M. C. (1997). Nonparametric testing of the existence of modes, Ann.\n\nStatist. 25: 1646–1660.\n\nMinnotte, M. C. and Scott, D. W. (1993). The mode tree: a tool for visualization\n\nof nonparametric density features, J. Comp. Graph. Statist. 2: 51–68.\n\nMira, A., Møller, J. and Roberts, G. O. (2001). Perfect slice sampler, J. Roy.\n\nStatist. Soc. B 63: 593–606.\n\nMøller, J. (1989). On the rate of convergence of spatial birth-and-death processes,\n\nAnn. Inst. Statist. Math. 41: 565–581.\n\nMøller, J. (1999). Markov chain Monte Carlo and spatial point processes, in O. E.\nBarndorﬀ-Nielsen, W. S. Kendall and M. N. M. van Lieshout (eds), Stochastic\nGeometry: Likelihood and Computations, Chapman and Hall/CRC, pp. 141–\n172.\n\nMøller, J. (2001a). A comparison of spatial point process models in epidemiolog-\nical applications, in P. J. Green, N. L. Hjort and S. Richardson (eds), Highly\nStructured Stochastic Systems, Oxford University Press, Oxford. To appear.\nMøller, J. (2001b). A review of perfect simulation in stochastic geometry, IMS\n\nLecture Notes - Monograph Series: Volume 37, pp. 333–355.\n\nMøller, J. and Nicholls, G. K. (1999). Perfect simulation for sample-based infer-\n\nence, Technical report, Department of Mathematics, University of Auckland.\n\nMøller, J. and Skare, O. (2001). Bayesian image analysis with coloured Voronoi\ntessellations and a view to applications in reservoir modelling, Technical report,\nDepartment of Mathematical Sciences, Aalborg University.\n\nMøller, J. and Waagepetersen, R. P. (2001). Simulation based inference for spa-\ntial point processes, in M. B. Hansen and J. Møller (eds), Spatial Statistics\nand Computational Methods, Lecture Notes in Statistics, Springer-Verlag. To\nappear.\n\nMøller, J., Syversveen, A. and Waagepetersen, R. P. (1998). Log Gaussian Cox\n\nprocesses, Scandinavian Journal of Statistics 25: 451–482.\n\nMuise, R. and Smith, C. (1992). Nonparametric mineﬁeld detection and localiza-\ntion, Technical report, Naval Surface Warfare Center, Coastal Systems Station.\nM¨uller, D. W. and Sawitzki, G. (1991). Excess mass estimates and tests for mul-\n\ntimodality, J. Amer. Statist. Assoc. 86: 738–746.\n\nNeyman, J. and Scott, E. L. (1958). Statistical approach to problems of cosmology,\n\nJournal of the Royal Statistical Society B 20: 1–43.\n\nNicholls, G. K. (1998). Bayesian image analysis with Markov chain Monte Carlo\nand coloured continuum triangulation models, J. Roy. Statist. Soc. B 60: 643–\n659.\n\nNowak, R. D. and Kolaczyk, E. D. (2000). A bayesian multiscale framework for\npoisson inverse problems, IEEE Transactions on Information Theory 46: 1811–\n1825.\n\n\f272\n\nREFERENCES\n\nObled, C. and Creutin, J. D. (1986). Some developments in the use of empirical\northogonal functions for mapping meteorological ﬁelds, J. Climate and Applied\nMeteorology 25: 1189–1204.\n\nOgata, Y. and Katsura, K. (1988). Likelihood analysis of spatial inhomogeneity\n\nfor marked point patterns, Ann. Inst. Statist. Math. 40: 29–39.\n\nOhser, J. and M¨ucklich, F. (2000). Statistical Analysis of Microstructures in Ma-\n\nterials Science, Wiley, New York.\n\nOkabe, A., Boots, B., Sugihara, K. and Chiu, S.-N. (2000). Spatial tessellations:\nConcepts and applications of Voronoi diagrams, 2nd edn, Chichester: Wiley.\n\nPascal-Marqui, R. M., Michel, C. and Lehmann, D. (1994). Low resolution elec-\ntromagnetic tomography. a new method for localizing electrical activity., In-\nternational Journal of Psychophysiology 18: 49–65.\n\nPenttinen, A. and Stoyan, D. (1989). Statistical analysis for a class of line segment\n\nprocesses, Scan. J. Statist. 16: 153–168.\n\nPhillips, D. B. and Smith, A. F. M. (1994). Bayesian faces via hierarchical template\n\nmodeling, J. Amer. Statist. Assoc. 89: 1151–1163.\nPreston, C. J. (1976). Random ﬁelds, Springer Verlag.\nPreston, C. J. (1977). Spatial birth-and-death processes, Bull. Int. Statist. Inst.\n\n46: 371–391.\n\nPropp, J. G",
    "chunk_order_index": 153,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-6fb324b446aa041951dba54dec5e7fda": {
    "tokens": 1200,
    "content": "Smith, A. F. M. (1994). Bayesian faces via hierarchical template\n\nmodeling, J. Amer. Statist. Assoc. 89: 1151–1163.\nPreston, C. J. (1976). Random ﬁelds, Springer Verlag.\nPreston, C. J. (1977). Spatial birth-and-death processes, Bull. Int. Statist. Inst.\n\n46: 371–391.\n\nPropp, J. G. and Wilson, D. B. (1996). Exact sampling with coupled Markov chains\nand applications to statistical mechanics, Random Structures and Algorithms\n9: 223–252.\n\nProtassov, R., van Dyk, D. A., Connors, A., Kashyap, V. and Siemiginowska, A.\n(2001). Statistics: Handle with care – detecting multiple model components\nwith the likelihood ratio test, The Astrophysical Journal p. submitted.\n\nRaftery, A. E., Madigan, D. and Hoeting, J. A. (1997). Bayesian model averaging\nfor linear regression models, Journal of the American Statistical Association\n92: 179–191.\n\nReiss, R. D. (1993). A course on point processes, Springer Verlag.\nRichardson, S. (2001). Spatial models in epidemiological applications, in P. J.\nGreen, N. L. Hjort and S. Richardson (eds), Highly Structured Stochastic Sys-\ntems, Oxford University Press, Oxford. To appear.\n\nRichardson, S. and Green, P. J. (1997). On Bayesian analysis of mixtures with un-\nknown number of components, Journal of the Royal Statistical Society 59: 731–\n792.\n\nRichardson, W. H. (1972). Bayesian-based iterative methods of image restoration,\n\nJournal of the Optical Society of America 62: 55–59.\n\nRipley, B. D. (1976). The second-order analysis of stationary point processes,\n\nJournal of Applied Probability 13: 255–266.\n\nRipley, B. D. (1977). Modelling spatial patterns (with discussion), J. Roy. Statist.\n\nSoc. B 39: 172–212.\n\nRipley, B. D. (1979). On tests of randomness for spatial point patterns, J. Roy.\n\nStatist. Soc. B 41: 368–374.\n\nRipley, B. D. (1981). Spatial Statistics, Wiley.\nRipley, B. D. (1988). Statistical Inference for Spatial Processes, Cambridge: Cam-\n\nbridge University Press.\n\nRobbins, C. S., Bystrak, D. A. and Geissler, P. H. (1986). he breeding bird survey:\n\n\fREFERENCES\n\n273\n\nits ﬁrst ﬁfteen years, 1965-1979, Technical report, USDOI, Fish and Wildlife\nService Resource Publication 157. Washington, D.C.\n\nRobert, C. P. and Casella, G. (1999). Monte Carlo statistical methods, New York:\n\nSpringer.\n\nRoberts, G. O. (1996). Markov chain concepts related to sampling algorithms.,\nMarkov Chain Monte Carlo in Practice (Editors: W. R. Gilks, S. Richardson,\nand D. J. Spiegelhalter), Chapman & Hall, London.\n\nRoberts, G. O. and Tweedie, R. L. (1996). Exponential convergence of Langevin\n\ndiﬀusions and their discrete approximations, Bernoulli 2: 341–363.\n\nRossky, P. J., Doll, J. D. and Friedman, H. L. (1978). Brownian dynamics as smart\n\nMonte Carlo simulation, Journal of Chemical Physics 69: 4628–4633.\n\nRoyle, J. A. and Wikle, C. K. (2001). Large-scale modeling of breeding bird survey\n\ndata, Under review.\n\nRoyle, J. A., Link, W. A. and Sauer, J. R. (2001). Statistical mapping of count\nsurvey data, in J. M. Scott, P. J. Heglund, M. Morrison, M. Raphael, J. Hau-\nﬂer and B. Wall (eds), Predicting Species Occurrences: Issues of Scale and\nAccuracy, Covello, CA: Island Press. (to appear).\n\nRue, H. and Hurn, M. (1999). Bayesian object identiﬁcation, Biometrika 86: 649–\n\n660.\n\nRuelle, D. (1969). Statistical mechanics, New York: Wiley.\nSambridge, M. (1999a). Geophysical inversion with a neighbourhood algorithm -\n\nI. search a parameter space, Geophys. J. Int.\n\nSambridge, M. (1999b). Geophysical inversion with a neighbourhood algorithm -\n\nII. appraising the ensemble, Geophys. J. Int.\n\nSantal´o, L. (1976). Integral Geometry and Geometric Probability, Addison–Wesley,\n\nReading, MA.\n\nSauer, J. R., Pendleton, G. W. and Orsillo, S. (1995). Mapping of bird distributions\nfrom point count surveys, in C. J. Ralph, J. R. Sauer and S. Droege (eds),\nMonitoring Bird Populations by Point Counts, USDA Forest Service, Paciﬁc\nSouthwest Research Station, pp. 151–160.\n\nSauer, J. R., Peterjohn, B. G. and Link, W. A. (1994). Observer diﬀerences in the\n\nNorth American breeding bird survey, Auk 111",
    "chunk_order_index": 154,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-492a453bcb92b6213271b45ce40b439b": {
    "tokens": 1200,
    "content": "distributions\nfrom point count surveys, in C. J. Ralph, J. R. Sauer and S. Droege (eds),\nMonitoring Bird Populations by Point Counts, USDA Forest Service, Paciﬁc\nSouthwest Research Station, pp. 151–160.\n\nSauer, J. R., Peterjohn, B. G. and Link, W. A. (1994). Observer diﬀerences in the\n\nNorth American breeding bird survey, Auk 111: 50–62.\n\nSchlattmann, P. and B¨ohning, D. (1993). Mixture models and disease mapping,\n\nStatistics in Medicine 12: 1943–1950.\n\nSchlattmann, P. and B¨ohning, D. (1997). On Bayesian analysis of mixtures with\nan unknown number of components. Contribution to a paper by S. Richardson\nand P.J. Green, J. R. Stat. Soc., Ser. B 59(4): 782–783.\n\nScott, D. W. (1992). Multivariate Density Estimation: Theory, Practice and Vi-\n\nsualization, New York: Wiley.\n\nSerra, J. (1982). Image analysis and mathematical morphology, London: Academic\n\nPress.\n\nShepp, L. A. and Vardi, Y. (1982). Maximum likelihood reconstruction for emission\n\ntomography, IEEE Transactions on Image Processing 2: 113–122.\n\nSilverman, B. W. (1981). Using kernel density estimates to investigate multimodal-\n\nity, J. Roy. Statist. Soc. B 43: 97–99.\n\nSilverman, J. F. and Cooper, D. B. (1988). Bayesian clustering for unsupervised es-\ntimation of surface and texture models, IEEE Trans. Patt. Anal. Mach. Intell.\n\n\f274\n\n10: 482–495.\n\nREFERENCES\n\nSimonoﬀ, J. (1993). Smoothing Methods in Statitsics, Springer Verlag, New York.\nSmith, A. F. M. and Roberts, G. O. (1993). Bayesian computation via the Gibbs\nsampler and related Markov chain Monte Carlo methods, Journal of the Royal\nStatistical Society, Series B, Methodological 55: 3–23.\n\nSmith, R. L. and Robinson, P. J. (1997). A Bayesian approach to the modeling of\nspatial-temporal precipitation data, in C. Gatsonis, J. S. Hodges, R. E. Kass,\nR. McCulloch, P. Rossi and N. D. Singpurwalla (eds), Case Studies in Bayesian\nStatistics. Vol III, Springer-Verlag, New York, pp. 237–269.\nSnyder, D. L. (1975). Random Point Processes, Wiley, New York.\nSourlas, N., van Dyk, D. A., Kashyap, V., Drake, J. and Pease, D. (2002). Bayesian\nspectral analysis of “MAD” stars., Statistical Challenges in Modern Astronomy\nIII (Editors: E. Feigelson and G. Babu), Springer–Verlag, New York.\n\nSpiegelhalter, D. J., Best, N. G. and Carlin, B. P. (1999). Bayesian deviance,\nthe eﬀective number of parameters and the comparison of arbitrarily complex\nmodels, Journal of the Royal Statistical Society. submitted.\n\nStanford, D. and Raftery, A. E. (1997). Principal curve clustering with noise,\nTechnical report, Department of Statistics, University of Washington, Seattle.\nStein, M. L. (1999). Interpolation of Spatial Data: Some Theory for Kriging, New\n\nYork: Springer-Verlag.\n\nStephens, D. A. (1994). Bayesian retrospective multiple-changepoint identiﬁcation,\n\nAppl. Statist. 43: 159–178.\n\nStephens, M. (2000). Bayesian Analysis of Mixture Models with an Unknown\nNumber of Components-an alternative to reversible jump methods, Annals of\nStatistics.\n\nStoica, R. S., Descombes, X. and Zerubia, J. (2000). A Gibbs point process for\nroad extraction in remotely sensed images, Technical report, Research Report\n3923, INRIA Sophia Antipolis.\n\nStoica, R. S., Descombes, X., van Lieshout, M. N. M. and Zerubia, J. (2001).\nAn application of marked point processes to the extraction of linear networks\nfrom images, in J. Mateu and F. Montes (eds), Spatial statistics: case studies,\nAdvances in Ecological Sciences, Volume 13, Southampton: WIT Press.\n\nStoyan, D. and Stoyan, H. (1994). Fractals, Random Shapes and Point Fields,\n\nWiley, Chichester.\n\nStoyan, D. and Stoyan, H. (2000).\n\nImproving ratio estimators of second order\npoint process characteristics, Scandinavian Journal of Statistics 27: 641–656.\nStoyan, D., Kendall, W. S. and Mecke, J. (1995). Stochastic Geometry and Its\n\nApplications, second edn, Wiley, Chichester.\n\nStrauss, D. J. (1975). A new model for clustering, Biometrika 63: 467–475.\nSun, D., Tsutakawa, R. and Kim, H. (2000). Spatio-temporal interaction with\n\ndisease mapping, Statistics in Medicine. to appear.\n\nTalairach, J",
    "chunk_order_index": 155,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-e91d6d318d674b181a4879219288f0d1": {
    "tokens": 1200,
    "content": ". and Mecke, J. (1995). Stochastic Geometry and Its\n\nApplications, second edn, Wiley, Chichester.\n\nStrauss, D. J. (1975). A new model for clustering, Biometrika 63: 467–475.\nSun, D., Tsutakawa, R. and Kim, H. (2000). Spatio-temporal interaction with\n\ndisease mapping, Statistics in Medicine. to appear.\n\nTalairach, J. and Tournoux, P. (1988). Co-planar Stereotaxic Atlas of the Human\n\nBrain., Thieme Medical Publishers, Stuttgart New York.\n\nTanner, M. A. (1996). Tools for Statistical Inference, New York: Springer-Verlag.\nTanner, M. A. and Wong, W. H. (1987). The calculation of posterior distributions\nby data augmentation (with discussion), Journal of the American Statistical\nAssociation 82: 528–550.\n\n\fREFERENCES\n\n275\n\nter Haar Romeny, B. M. (2001). Front-End Vision and Multiscale Image Analysis,\n\nDordrecht: Kluwer.\n\nThomas, M. (1949). A generalization of Poisson’s binomial limit for use in ecology,\n\nBiometrika 36: 18–25.\n\nTikhonov, A. N. and Arsenin, V. Y. (1977). Solutions of Ill-posed problems, Wiley,\n\nChichester New York.\n\nTitterington, D. M., Smith, A. F. M. and Makov, U. E. (1985). Statistical Analysis\n\nof Finite Mixture Distributions, New York: John Wiley.\n\nTzourio, N., Massioui, F. E., Crivello, F., Joliot, M., Renault, B. and Mazoyer, B.\n(1997). Functional anatomy of human auditory attention studied with PET,\nNeuroimage 5: 63–77.\n\nvan Dyk, D. A. (2002). Hierarchical models, data augmentation, and Markov\nchain Monte Carlo, Statistical Challenges in Modern Astronomy III (Editors:\nE. Feigelson and G. Babu), Springer–Verlag, New York.\n\nvan Dyk, D. A. and Meng, X.-L. (2000). Algorithms based on data augmenta-\ntion, Computing Science and Statistics: Proceedings of the 31st Symposium on\nthe Interface (Editors: M. Pourahmadi and K. Berk), Interface Foundation of\nNorth America, Fairfax Station, VA, pp. 230–239.\n\nvan Dyk, D. A., Connors, A., Kashyap, V. and Siemiginowska, A. (2001). Analysis\nof energy spectra with low photon counts via Bayesian posterior simulation,\nThe Astrophysical Journal 548: 224–243.\n\nvan Lieshout, M. N. M. (1995). Stochastic geometry models in image analysis and\n\nspatial statistics, Technical report, CWI tract 108, Amsterdam.\n\nvan Lieshout, M. N. M. (2000). Markov Point Processes and Their Applications,\n\nImperial College Press, London.\n\nvan Lieshout, M. N. M. and Baddeley, A. J. (1995). Markov chain monte carlo\nmethods for clustering of image features, Proceedings of the 5th IEE Inter-\nnational Conference on Image Processing and Its Applications, IEE Press,\npp. 241–245.\n\nvan Lieshout, M. N. M. and Baddeley, A. J. (1996). A nonparametric measure of\nspatial interaction in point patterns, Statistica Neerlandica 50: 344–361.\nvan Lieshout, M. N. M. and van Zwet, E. W. (2001). Exact sampling from con-\nditional Boolean models with applications to maximum likelihood inference,\nAdv. Appl. Prob 33: 339–353.\n\nvan Lieshout, M. N. M., Molchanov, I. S. and Zuyev, S. A. (2001). Clustering\nmethods based on variational analysis in the space of measures, Biometrika.\n(to appear).\n\nVoronoi, M. G. (1908). Nouvelles applications des param`etres continus `a la th´eorie\n\ndes formes quadratiques, J. Reine Angew. Math. 134: 198–287.\n\nWahba, G. (1990). Spline models for observational data, Vol. 59, SIAM: Philadel-\n\nphia.\n\nWaller, L. A., Carlin, B. P., Xia, H. and Gelfand, A. E. (1997a). Hierarchical\nspatio-temporal mapping of disease rates, Journal of the American Statistical\nAssociation 92: 607–617.\n\nWaller, L. A., Carlin, B. P., Xia, H. and Gelfand, A. E. (1997b). Hierarchical\nspatio-temporal mapping of disease rates, Journal of the American Statistical\nAssociation 92: 607–617.\n\n\f276\n\nREFERENCES\n\nWaller, L. A., Turnbull, B. W., Clark, A. and Nasca, P. (1992). Chronic disease\nsurveillance and testing of clustering of disease and exposure: application to\nleukemia incidence and TCE-contaminated dump sites in upstate New York,\nEnvironmetrics 3: 281–300.\n\nWaller, L. A., Turnbull, B. W.,",
    "chunk_order_index": 156,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-dc5e1f58e9abcc0f56496c1dac5fd8c7": {
    "tokens": 1200,
    "content": ": 607–617.\n\n\f276\n\nREFERENCES\n\nWaller, L. A., Turnbull, B. W., Clark, A. and Nasca, P. (1992). Chronic disease\nsurveillance and testing of clustering of disease and exposure: application to\nleukemia incidence and TCE-contaminated dump sites in upstate New York,\nEnvironmetrics 3: 281–300.\n\nWaller, L. A., Turnbull, B. W., Clark, A. and Nasca, P. (1994). Spatial pat-\ntern analyses to detect rare disease clusters, in N. Lange, L. Ryan, L. Billard,\nD. Brillinger, L. Conquest and J. Greenhouse (eds), Case Studies in Biometry,\nNew York: John Wiley, pp. 1–23.\n\nWand, M. P. and Jones, M. C. (1995). Kernel smoothing, London: Chapman &\n\nHall.\n\nWhittemore, A., Friend, N., Brown, B. W. and Holly, E. A. (1987). A test to\n\ndetect clusters of disease, Biometrika 74: 31–35.\n\nWhittle, P. (1986). Systems in Stochastic Equilibrium, Wiley, Chichester.\nWidom, B. and Rowlinson, J. S. (1970). A new model for the study of liquid-vapor\n\nphase transitions, J. Chem. Phys. 52: 1670–1684.\n\nWikle, C. K. and Cressie, N. A. C. (1999). A dimension reduction approach to\n\nspace-time Kalman ﬁltering, Biometrika 86: 815–829.\n\nWikle, C. K., Berliner, L. M. and Cressie, N. A. C. (1998). Hierarchical Bayesian\nspace-time models, Environmental and Ecological Statistics 5: 117–154.\nWikle, C. K., Milliﬀ, R. F., Nychka, D. and Berliner, L. M. (2001). Spatiotemporal\nhierarchical Bayesian modeling: Tropical ocean surface winds, J. Amer. Statist.\nAssoc. 96: 382–397.\n\nWilson, D. B. (2000). How to couple from the past using a read-once source of\n\nrandomness, Random Structures and Algorithms 16: 85–113.\n\nWolpert, R. L. and Ickstadt, K. (1998). Poisson/gamma random ﬁeld models for\n\nspatial statistics, Biometrika 85: 251–267.\n\nWood, A. T. A. and Chan, G. (1994). Simulation of stationary Gaussian processes\nin [0, 1]d, Journal of Computational and Graphical Statistics 3: 409–432.\nXia, H. and Carlin, B. P. (1998). Spatio-temporal models with errors in covariates:\nMapping ohio lung cancer mortality, Statistics in Medicine 17: 2025–2043.\nYaglom, A. M. (1987). Correlation Theory of Stationary and Related Random\n\nFunctions I. Basic Results., New York: Springer-Verlag.\n\nYao, Y. C. (1984). Estimation of a noisy discrete-time step function: Bayes and\n\nempirical Bayes approaches, Ann. Statist. 12: 1434–1447.\n\nZellner, A. (1976). Bayesian and non-Bayesian analysis of the regression model\n\nwith multivariate Student-t error terms, J. Amer. Statist. Assoc.\n\nZia, H., Carlin, B. P. and Waller, L. A. (1997). Hierarchical models for mapping\n\nOhio lung cancer rates, Environmetrics 8: 107–120.\n\n\fIndex\n\nabsorption line, 195\nabsorption lines, 178, 184\nadaptive coupling from the past, 81\nagglomerative clustering, 150, 159\narea interaction process, 89\nARMA processes, 225\nasymmetric volcano, 30\nauditory evoked potentials, 227\n\nbandwidth, 28\nbasis functions\nFourier, 203\northogonal spectral, 202\nwavelet, 203\n\nBayes Factor, 133, 249\nBayesian Information Criterion,\n\n249, 254\n\nBayesian linear model, 130, 133\nBayesian partition model, 144\nBBS House Finch data, 206\nBeta-binomial model, 138\nbinomial process, 41\nBirth Abnormalities, 249, 257\nBirth Death Shift Algorithm, 238,\n\n248\n\nbirth rate, 75, 76\nbirth-death process, 93\n\nSpatial, 75\n\nBoolean model, 62, 63, 88, 91\nbootstrapping, 128\nbump hunting, 24\nbus paradox, 62\n\ncluster, 31\ncluster analysis\nBayesian, 72\n\ncluster model\n\nBayesian, 87\nCox, 78\n\ncluster process\n\nCox, 37, 67, 68, 71, 72, 75\nCox-Matern, 80, 84\nIndependent, 67\nMatern, 69\nMat´ern, 47\nmodiﬁed Thomas, 69\nNeyman-Scott, 45\nPoisson, 45\nPoisson-Thomas, 77\n\ncluster size, 150, 154\ncomplete data, 75\ncomplete data process, 63",
    "chunk_order_index": 157,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-01445669daffe2c940893a09f98d9e77": {
    "tokens": 1200,
    "content": "37, 67, 68, 71, 72, 75\nCox-Matern, 80, 84\nIndependent, 67\nMatern, 69\nMat´ern, 47\nmodiﬁed Thomas, 69\nNeyman-Scott, 45\nPoisson, 45\nPoisson-Thomas, 77\n\ncluster size, 150, 154\ncomplete data, 75\ncomplete data process, 63\ncontour lines, 23\nconvex hull, 65\ncount process, 200\ncoupling from the past (CFTP),\n\n80, 87, 93\n\ncovariance\n\nstationary, 125\n\nCox process, 41\n\nlog Gaussian (LGCP), 48\nlog Gaussian(LGCP), 39\nShot noise G (SNGCP), 49\nshot-noise G (SNGCP), 39\n\ncurvature, 28, 29, 35\n\nchain mixing, 192\nChandra, 175\n\ndata augmentation, 148, 187\ndeath rate, 75\n\n\f278\n\nINDEX\n\ndeprivation index, 250, 252, 257\nDeviance Information Criterion,\n\nHessian matrix, 28\nhierarchical data augmentation,\n\n249\n\ndimension reduction methods, 23\ndisease mapping, 66, 135, 147\ndominating process, 93\n\nearthquake data, 27\nearthquakes, 27\nEast german lip cancer dataset, 141\nedge eﬀects, 62, 64\neigenvalues, 28\nEM algorithm, 79, 178, 188, 190,\n\n194, 232, 234\n\nempirical orthogonal functions\n\n(EOFs), 203\n\nEPA Superfund, 135\nepicenters, 27\nextrapolation, 61\n\nFast Fourier Transform, 203\nfaults, 61\nFFT function, 205\nﬁnite mixture models, 66\n\nGaussian, 28\ngeneralised area-interaction\n\nprocess, 85\n\ngeneralised linear mixed models,\n\n199\n\ngeneralised linear model, 138, 188\ngeneralized inverse, 220\ngeostatistics, 214\n\nmodel-based, 199\ngerm grain models, 63\ngerm process, 67\ngerm-grain model, 68\ngerm-grain models, 66, 67\nGibbs sampler, 112, 164, 167, 185,\n\n189\n\n192\n\nHouse Finch, 200\n\nimage processing, 61\nImportance sampling, 79\nimproper posterior distribution,\n\n187\n\nimproper prior distribution, 187\ninterpolation, 61\ninverse problem\nEEG, 228\n\nkernel\n\nGaussian, 29\n\nkernel density estimates, 24\nkernel density estimation, 244\nkernel window, 27\nKnox’s Test, 240\n\nlabel allocation function, 72\nland mines, 66\nlandmarks, 218\nLangevin-Hastings algorithm, 56\nLH, see Langevin-Hastings\n\nalgorithm, 56\n\nline segment process, 62\nLORETA, 233\n\nmagnetic resonance imaging, 227\nMALA, see Metropolis-adjusted\n\nLangevin algorithm, 56\n\nmarginal posterior distribution, 195\nmark correlation, 64\nmarked point process, 63\nmarked process, 16\nMarkov Chain Monte Carlo, 66,\n\n111, 128, 194, 238, 238, 248, 249\nchains, 195\nMetropolis-Hastings Algorithm,\n\nhard core process, 73\n\n168, 252\n\n\fINDEX\n\nReversible Jump, 132, 238, 248,\n\n254\n\nMarkov random ﬁeld model, 182\nMat´ern covariance function, 203\nMelbourne temperature data, 31,\n\n34, 35\n\nMetropolis-adjusted Langevin\n\nalgorithm, 56\n\nMetropolis-Hastings algorithm,\n\n112, 189\n\nmine ﬁeld detection, 66\nminimum contrast estimation, 37,\n\n52\n\nmissing data, 61\nmixing kernel, 231\nmixture model, 167, 181, 229\nMonte Carlo maximum likelihood,\n\n64, 78\n\nmovie, 28, 33, 36\nmultiscale method, 182\n\nneuro-imaging, 227, 233\nneurophysiology, 227\nNew York leukaemia incidence\n\ndata, 100\n\nNeyman-Scott model, 95\nnonparametric bootstrap, 232\nNorth American Breeding Bird\n\nSurvey, 199\n\nnugget eﬀect, 202, 214\n\nOccam’s window, 150, 153, 154\nocclusion, 62\norphans, 68, 70\n\npair correlation function, 44, 48\npairwise interaction process, 62\nparametric bootstrap, 234\npartition model, 125, 128, 136\nperfect sampling, 87\nphoton absorption, 176\nPiazza Road dataset, 135\npoint process, 148\n\n279\n\nCox, 69\nﬁnite, 67\ninhomogeneous Poisson, 68\nMarkov, 72, 75\nPoisson, 67, 69\n\nPoisson point process, 66, 109\nPoisson process, 41, 62, 89, 109,\n\n240, 247\n\nPoisson spatial model, 201\nPoisson-gamma model, 137\nPoisson-gamma process, 50\npositron emission",
    "chunk_order_index": 158,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-a183ef23366c8f67a1d7ac0a5738d87e": {
    "tokens": 1200,
    "content": "Cox, 69\nﬁnite, 67\ninhomogeneous Poisson, 68\nMarkov, 72, 75\nPoisson, 67, 69\n\nPoisson point process, 66, 109\nPoisson process, 41, 62, 89, 109,\n\n240, 247\n\nPoisson spatial model, 201\nPoisson-gamma model, 137\nPoisson-gamma process, 50\npositron emission tomography, 227\nposterior predictive distribution,\n\n131\n\nposterior predictive p-values, 191\nprincipal components, 203\nprincipal kriging functions, 216, 221\nprincipal splines, 217\npure silhouette model, 88, 91, 95\n\nrandom closed set, 62\nrandom ﬁeld, 62, 215\n\nGaussian, 163, 173, 201\nMarkov, 62\nskew Gaussian, 165\n\nRandom Imputation Principle, 72\nrandom thinning models, 63\nrat skulls, 218\nRedwood data, 76\nrepulsion, 73\n\nS3, 27–31, 35, 36\nsaddle point, 29\nsampling bias, 62, 64, 67, 74\nscale-space, 23, 24, 27, 29, 36\nScan Test, 240\nscatter distribution, 176\nsemiparametric model, 234\nSigniﬁcance of zero crossings, 24\nsimilarity measure, 66\nsingular value decomposition, 215\nSiZer, 24, 36\n\n\f280\n\nINDEX\n\nskew Gaussian process, 164, 168,\n\nX-ray sources, 175\n\nzero crossing of the derivative, 24\n\n171\n\nskew-Gaussian distribution, 164\nsmall area health data, 135, 147,\n\n235\n\nsmoothed histogram, 23, 24\nspace-time process, 214\nspatial mean process, 200\nspatial-temporal autoregressive\n\nmodel, 222\n\nSpatial-temporal modelling, 213\nspatially-varying covariates, 201\nspectral coeﬃcients, 202\nstandardised mortality ratio, 141,\n\n250–252, 255\n\nstochastic censoring, 176\nstochastic geometry, 62\nStrauss process, 73, 89, 244–246,\n\n252\n\nstreamlines, 27, 30, 32, 34\nsulphur dioxide, 221\nsurface shape, 30\n\nthin-plate splines, 219\nTikhonov regularization, 229\nTrans-Gaussian kriging, 163\ntruncated Langevin-Hastings\n\nalgorithm, 56\n\ntruncated linear spline model, 140\ntypical grain, 63\n\nU.S. Cancer Mortality Atlas, 153\nunobserved heterogeneity, 231\n\nvector AR process, 220\nVEM algorithm, 231\nvolcano, 31\nVoronoi tesselation, 101, 111, 112,\n\n126, 145\n\nVoronoi tile, 109\nvoxel, 227, 230, 232\n\nwrapped normal distribution, 225\n\n\fAuthor Index\n\nAdams, N M 11\nAdler, R 48\nAhrens, C 88, 105\nAllard, D 109, 110, 120\nAlonso, F J 5, 213, 214, 221\nAltman, N 88, 105\nArak, T 66\nArbib, R S 200\nArjas, E 42, 60\nArmstrong, B 257\nArnold, R 5\nArsenin, V Y 229\nAykroyd, R G 144, 215, 219\nAzzalini, A 163, 164, 165\n\nBaddeley, A J 4, 5, 44, 55, 61, 62,\n64, 66, 67, 68, 72, 73, 75, 76, 77,\n85, 87, 89, 90, 91, 92, 244\n\nBak, C 233\nBanﬁeld, J D 10, 109\nBarry, D 126, 144\nBartels, P H 227\nBartlett, M S 46\nBasford, K E 234\nBashtannyk, D M 32\nBendrath, R 68\nBenes, V 42, 48, 56\nBensmail, H 109\nBentham, G 5\nBerliner, L M 5, 202, 203, 226\nBernardinelli, L 3, 5, 19\nBernardo, J M 130\nBesag, J E 2, 5, 18, 19, 56, 147\nBest, N G 2, 5, 58, 135, 249\nBibby, J M 66\nBinder, D A 10, 72\n\n281\n\nBithell, J 6, 13\nBlackwell, P G 66\nBlair, R C 227\nBodlak, K 42, 48, 56\nB¨ohning, D 6, 227, 231, 232, 238\nBookstein, F L 217, 218\nBoots, B 111, 126\nBox, G E P",
    "chunk_order_index": 159,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-364c75f9a6d3831a5228a0cc697b32a4": {
    "tokens": 1200,
    "content": "Binder, D A 10, 72\n\n281\n\nBithell, J 6, 13\nBlackwell, P G 66\nBlair, R C 227\nBodlak, K 42, 48, 56\nB¨ohning, D 6, 227, 231, 232, 238\nBookstein, F L 217, 218\nBoots, B 111, 126\nBox, G E P 164\nBreslow, N 5, 17\nBriggs, D G 2, 135\nBrinkmann, W 195\nBrix, A 39, 41, 48, 49, 50, 51, 52,\n\n53, 58\n\nBrown, B. W. 147\nBrown, P E 213, 224\nBurchﬁeld, J 227\nBushby, A 257\nByers, J A 144\nByers, S D 5, 109, 110, 117\nBystrak, D A 199\n\nCai, Y 88\nCapitanio, A 163, 164, 165\nCarlin, B P 5, 19, 64, 78, 144, 147,\n\n241, 248, 249, 257\n\nCarlin, J B 191\nCarson, R 178\nCarstairs, V 250\nCarter, D S 89\nCasella, G 55, 88, 105, 132\nCeleux, G 109\nChadoeuf, J 39\nChatﬁeld, C 66\nChaudhuri, P 11, 23, 24, 27, 28,\n\n29, 32\n\nCheng, M Y 24\n\n\f282\n\nChessa, A G 62\nChetwynd, A 240\nChib, S 168\nChil`es, J P 61, 62, 66\nChiu, S-N 111, 126\nChristensen, O F 56\nChu, Y 180\nClark, A 5, 87, 100, 147, 148, 242,\n\n243\n\nClayton, D G 3, 5, 17, 19, 135,\n\n147\n\nClayton, M K 5, 12, 147, 148, 149,\n\n239\n\nClayworth, C 233\nCliﬀord, P 66\nClyde, M 136\nColes, P 39, 48\nCollins, A J 66\nConlon, E 5\nConnors, A 177, 178, 183, 186, 187,\n\n191, 194, 195\nCooper, D B 144\nCox, D R 4, 37, 67, 164\nCressie, N A C xiii, 3, 5, 8, 11,\n19, 61, 63, 66, 163, 202, 203, 213,\n214, 215, 226, 238, 243, 247\n\nCreutin, J D 203\nCrivello, F 233\n\nDaley, D J 37, 39, 51, 65, 67, 68,\n\n69, 70, 71, 89, 91\n\nDalla Valle, A 164, 165\nDasgupta, A 66, 68, 109, 118, 120\nDavies, S J 61, 66, 67\nDavis, J E 177\nDe Bonet, J S 61\nDe Oliveira, V 163, 165, 168\nDeibolt, J 66, 72\nDempster, A P 79, 178, 232\nDenison, D G T 11, 88, 105, 126,\n127, 130, 131, 133, 136, 137, 138,\n140, 148, 238\nDescombes, X 62\n\nAUTHOR INDEX\n\nDietz, E 227\nDiggle, P J 2, 3, 4, 5, 6, 11, 13,\n15, 17, 37, 41, 44, 48, 52, 53, 69,\n76, 77, 79, 106, 119, 120, 125,\n199, 202, 205, 237, 240, 241, 243\n\nDolan, R J 227\nDolk, H 257\nDoll, J D 56\nDonoho, D 24\nDrake, J 183\nDryden, I 4\nDuda, R O 6, 7\nDuﬀy, P H 227\n\nEaton, M 88, 105\nElberling, C 233\nElliott, J J 200\nElliott, P 2, 135\nElvis, M 195\nEveritt, B S 6, 7\n\nFan, J Q 29\nFenimore, E E 186\nFessler, J A 178\nFiksel, T 79\nFiore, F 195\nFisher, N I 24, 61, 66, 67\nFord, I 227\nForman, W R 181\nFrackowiak, R S J 227",
    "chunk_order_index": 160,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-bc6a27421c6b89dfec58f545c90c16c8": {
    "tokens": 1200,
    "content": "Elvis, M 195\nEveritt, B S 6, 7\n\nFan, J Q 29\nFenimore, E E 186\nFessler, J A 178\nFiksel, T 79\nFiore, F 195\nFisher, N I 24, 61, 66, 67\nFord, I 227\nForman, W R 181\nFrackowiak, R S J 227\nFraley, C 10, 109, 110, 120\nFreeman, P E 186\nFriedman, H L 56\nFriend, N. 147\nFriston, K J 227\nFrith, C D 227\n\nGalaburda, A 234\nGallinat, J 228\nGangnon, R E 5, 12, 147, 148, 149,\n\n153, 162, 239\nGaskins, R A 24\nGeissler, P H 199\n\n\fAUTHOR INDEX\n\n283\n\nGelfand, A E 5, 19, 64, 78, 144,\n\n147, 167, 168, 178, 241\n\nGelman, A 191\nGeman, D 112\nGeman, S 112\nGeyer, C J 5, 11, 55, 64, 78, 79,\n\n93, 248\n\nGhislandi, M 5, 19\nGhosh, M 5, 88, 100, 105\nGhosh, S 144\nGijbels, I 29\nGilks, W R 4, 55, 132, 167\nGiudici, P 145\nGlasbey, C A 226\nGodtliebsen, F 11, 27, 28, 29, 32\nGoldstein, H 5\nGood, I J 24\nGoodall, C R 5, 213, 214, 217, 221,\n\n226\n\nGrabarnik, P 79\nGrandell, J 37\nGraziani, C 186\nGreen, P J 10, 88, 101, 106, 111,\n\n114, 132, 144, 145, 248\n\nGreenberg, E 168\nGruendl, R A 180\nGrunwald, G K 32\nGuerrero, M 180\n\nH¨aggstr¨om, O 85, 88, 89, 93\nHaggvist, R 240\nHaldorsen, H H 62\nHall, P 24\nHand, D J 11, 69\nHandcock, M S 169, 226\nHans, C M 186, 189\nHart, P E 6, 7\nHartigan, J A 24, 126, 144\nHartigan, P M 24\nHaslett, J 213\nHastie, T J 131, 133\nHastings, W K 112, 140\nHegerl, U 228\n\nHeikkinen, J 42, 60\nHero, A O 178\nHigdon, D 2, 135\nHjort, N L 62\nHodder, I 66\nHoeting, J A 150\nHolly, E A 147\nHolmes, A P 227\nHolmes, C C 11, 88, 105, 126, 127,\n130, 131, 133, 136, 137, 138, 140,\n148, 238\n\nHuang, F 79\nHuang, H-C 226\nHuijbregts, C J 61\nHurn, M 5, 87, 144\nHusby, O 5\nHwang, J T G 88, 105\nHyndman, R J 32\n\nIckstadt, K 39, 50, 51, 57, 58, 59,\n\n60\n\nIsham, V 4, 67\nIzenman, A J 24\n\nJoliot, M 233\nJones, B 39, 48\nJones, C 181\nJones, M C 27, 29\nJones, R H 224\nJournel, A G 61, 213, 226\n\nKaaresen, K F 213, 224\nKaldor, J 135, 147\nKaler, J B 180\nKang, H 177\nKashyap, V 177, 178, 183, 186, 187,\n\n191, 194, 195\nKatsura, K 120\nKaufman, L 66\nKedem, B 163, 165, 168\nKelly, F P 76\nKelsall, J 6, 11, 13, 15, 237\nKendall, W S 37, 43, 47, 62, 63,\n\n\f284\n\nAUTHOR INDEX\n\n64, 65, 68, 69, 80, 81, 83, 85, 86,\n87, 88, 90, 93, 94\n\nKent, J T 66, 215, 217, 219\nKern, J 2, 135\nKim, D 88, 100, 105\nKim, H 5, 19\nKing",
    "chunk_order_index": 161,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-266d4d035f9d70909c8abc24d17dab1b": {
    "tokens": 1200,
    "content": "62, 63,\n\n\f284\n\nAUTHOR INDEX\n\n64, 65, 68, 69, 80, 81, 83, 85, 86,\n87, 88, 90, 93, 94\n\nKent, J T 66, 215, 217, 219\nKern, J 2, 135\nKim, D 88, 100, 105\nKim, H 5, 19\nKingman, J F C 39, 65\nKnight, R T 233\nKnorr-Held, L 5, 6, 12, 19, 145,\n\n148, 238\n\nKnox, E. G. 235, 240\nKofoed, B 233\nKolaczyk, E D 182\nKraft, R P 181\nKregenow, J M 181\nK¨uhr, H 195\nKulldorﬀ, M 147, 235, 240\nKyriakidis, P C 213, 226\n\nLaird, N M 178\nLamb, D Q 186\nLammertsma, A A 227\nLandau, S 6, 7\nLange, K 178\nLangford, I 5\nLantu´ejoul, C 62\nLast, G 65\nLawson, A B 2, 5, 11, 12, 13, 15,\n55, 62, 66, 77, 87, 135, 141, 147,\n148, 235, 238, 241, 242, 243, 247\n\nLebech, J 233\nLee, K 144\nLeese, M 6, 7\nLehmann, D 229\nLeyland, A 5\nLiddle, P F 227\nLindeberg, T 23, 29\nLindley, D V 139\nLindsay, B G 231, 232\nLink, W A 199, 200, 201, 202, 205\nLittle, J 217\nLoizeaux, M 105\nLoredo, T J 177, 186\n\nLouis, T A 248\nLucas, P 6\nLucy, L B 178\nLund, J 67\n\nMadigan, D 150\nMakov, U E 69\nMallick, B K 126, 127, 130, 131,\n\n133, 137, 140\nMammen, E 24\nMantel, N 240\nMardia, K V 4, 5, 66, 213, 214,\n\n215, 217, 219, 221, 226\n\nMarron, J S 11, 23, 24, 27, 28, 29,\n\n32\n\nMarshall, R J 66\nMassioui, F E 233\nMat´ern, B 47, 69\nMatheron, G 62, 64\nMatsuoka, M 195\nMazoyer, B 233\nMcCullagh, P 188\nMcDonald, A 5\nMcKeague, I W 105\nMcLachlan, G J 234\nMecke, J 37, 43, 47, 62, 63, 64,\n\n65, 68, 69, 90\n\nMeng, X-L 178, 195\nMengersen, K L 88\nMetropolis, N 112\nMichel, C 229\nMihara, T 195\nMiller, D M 163\nMilliﬀ, R F 202, 203, 226\nMilne, R K 68\nMinnotte, M C 24\nMira, A 88\nMohanty, S 24\nMolchanov, I S 67\nMøller, J 5, 11, 38, 39, 41, 42, 44,\n48, 49, 52, 53, 55, 56, 59, 60, 72,\n73, 75, 76, 79, 80, 81, 83, 85, 87,\n88, 89, 90, 93, 94, 144, 248\n\n\fAUTHOR INDEX\n\nMolli´e, A 2, 18, 147\nMontomoli, C 5, 19\nMorris, R J 215, 219\nMorris, S 240\nMoyeed, R A 3, 5, 17, 125, 199,\n\n202, 205\n\nM¨ucklich, F 44\nMugglin, A 19\nMuise, R 109\nM¨uller, D W 24\nMurakami, T 186\nMurdoch, D J 88\nMurray, S S 181\n\nNagarwalla, N 147, 240\nNasca, P 100\nNatarajan, K 5, 88, 100, 105\nNauber, U 195\nNelder, J A 188\nNeyman, J 38, 45, 87\nNicholls, G K 88, 144\nNowak, R D 182\nNowak, Z 144\nNychka, D 202, 203, 226\n\nObled, C 203\nOgata, Y 79, 120\nOhser",
    "chunk_order_index": 162,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-7b0bccfe5166837219b3adca4f553da5": {
    "tokens": 1200,
    "content": "5, 88, 100, 105\nNauber, U 195\nNelder, J A 188\nNeyman, J 38, 45, 87\nNicholls, G K 88, 144\nNowak, R D 182\nNowak, Z 144\nNychka, D 202, 203, 226\n\nObled, C 203\nOgata, Y 79, 120\nOhser, J 44\nOkabe, A 111, 126\nOmre, H 62\nOrsillo, S 199\nOrton, C 66\n\nPascal-Marqui, R M 229\nPascutto, C 5, 19\nPauliny-Toth, I I K 195\nPease, D 183\nPendleton, G W 199\nPenttinen, A 64, 67\nPeterjohn, B G 200\nPhillips, D B 144\nPrenter, P M 89\nPreston, C J 72, 75, 76\n\n285\n\nPropp, J G 80, 87, 93\nProtassov, R 178, 183, 191\n\nRaftery, A E 10, 66, 68, 109, 110,\n\n117, 118, 120, 150\n\nRashbash, J 5\nRasser, G 6, 12, 145, 148, 238\nRedfern, E J 5, 213, 214, 221\nReiss, R D 65\nRenault, B 233\nRichardson, S 4, 10, 55, 59, 60,\n\n132, 145, 167, 248\nRichardson, W H 178\nRipley, B D 2, 4, 44, 72, 73, 75,\n\n76, 86, 106, 164\nRobbins, C S 199\nRobert, C P 55, 66, 72, 88, 109,\n\n132\n\nRoberts, G O 88, 178, 189, 213,\n\n224\n\nRobinson, P J 226\nRosenbluth, A W 112\nRosenbluth, M N 112\nRossky, P J 56\nRousseeuw, P J 66\nRowlingson, B 243\nRowlinson, J S 85\nRoyle, J A 201, 202, 205\nRubin, D B 178, 191\nRudemo, M 67\nRue, H 5, 144\nRuelle, D 72\n\nSaermark, K 233\nSanides, F 234\nSantal´o, L 47, 65, 66\nSauer, J R 199, 200, 201, 202, 205\nSawitzki, G 24\nScabini, D 233\nSchatzoﬀ, M 79, 232\nSchlattmann, P 6, 227, 231, 232,\n\n238\n\nScott, D W 13, 14, 15, 24, 29, 120\n\n\f286\n\nScott, E L 38, 45, 87\nSerra, J 63, 64, 65, 66\nShepp, L A 178\nShort, D S 163, 165, 168\nSibson, R 101, 106, 114\nSiemiginowska, A 177, 178, 183,\n\n186, 187, 191, 194, 195\n\nSilverman, B W 24\nSilverman, J F 144\nSimonoﬀ, J 243\nSkare, Ø 144\nSmith, A F M 69, 126, 127, 130,\n131, 133, 137, 139, 140, 144, 167,\n178\n\nSmith, C 109\nSmith, R L 226\nSnyder, D L 4\nSommer, C 24\nSongini, M 5, 19\nSourlas, N 183\nSpiegelhalter, D J 4, 55, 132, 167,\n\n249\n\nStanford, D 120\nStaudenmayer, J 88, 105\nStefanscu, C 88, 105\nStein, M L 61, 169, 203\nStephens, D A 144\nStephens, M 5, 11, 238\nStern, H S 191\nStoica, R S 62\nStork, D G 6, 7\nStoyan, D 37, 43, 47, 62, 63, 64,\n\n65, 68, 69, 79, 90\n\nAUTHOR INDEX\n\nTalairach, J 228\nTanemura, M 79\nTanner, M A 168, 178\nTawn, J A 3, 5, 17, 125, 199, 202,\n\n205\n\nTeller, A H 112\nTeller, E 112\nter Haar Romeny, B M 23\nThomas, A 5\nThomas, M 47\nTh¨onnes, E 62, 67, 93\nTibshirani, R J 131, 133\nTikhonov, A N 229",
    "chunk_order_index": 163,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-ff3d4fe76a3ea98c39bd0dfe432babd2": {
    "tokens": 794,
    "content": "Tawn, J A 3, 5, 17, 125, 199, 202,\n\n205\n\nTeller, A H 112\nTeller, E 112\nter Haar Romeny, B M 23\nThomas, A 5\nThomas, M 47\nTh¨onnes, E 62, 67, 93\nTibshirani, R J 131, 133\nTikhonov, A N 229\nTitterington, D M 69\nTonellato, S 213, 224\nTournoux, P 228\nTsutakawa, R 5, 19\nTurnbull, B W 100\nTzourio, N 233\n\nvan Dyk, D A 177, 178, 183, 186,\n\n187, 191, 194, 195\n\nvan Lieshout, M N M 5, 38, 55,\n62, 67, 68, 70, 72, 73, 77, 80, 85,\n87, 88, 89, 90, 91, 92, 93, 106,\n244\n\nvan Zwet, E W 62\nVardi, Y 178\nVere-Jones, D 37, 39, 51, 65, 67,\n\n68, 69, 70, 71, 89, 91\n\nVoronoi, M G 126\n\nStrauss, D J 72, 73, 76, 87, 89,\n\nWaagepetersen, R P 11, 39, 41, 42,\n\n106\n\nStroud, T 5\nSugihara, K 111, 126\nSun, D 5, 19\nSurgailis, D 66\nSwall, J 2, 135\nSyversveen, A 11, 39, 41, 48, 49,\n\n52, 53, 56\n\n44, 48, 49, 52, 53, 56\n\nWahba, G 215\nWakeﬁeld, J C 2, 5, 135\nWaller, L A 5, 19, 88, 100, 105,\n\n147, 241\n\nWallis, J R 169, 226\nWalls, P H 257\nWand, M P 27, 29\nWatson, D G 227\nWermuth, N 79, 232\n\n\f287\n\nAUTHOR INDEX\n\nWhittemore, A. 147\nWhittle, P 214, 224\nWidom, B 85\nWikle, C K 5, 202, 203, 213, 214,\n\n226\n\nWilliams, F L R 13, 243\nWilliams, R M 180\nWilson, D B 80, 87, 88, 93\nWitzel, A 195\nWolpert, R L 39, 50, 51, 57, 58,\n\n59, 60\n\nWong, W H 178\nWoods, D L 233\n\nXia, H 5, 19, 147, 241, 257\n\nYaglom, A M 165, 169\nYao, Y C 144\nYashida, A 186\nYork, J C 2, 18, 147\nYu, Y 177\n\nZellner, A 163\nZerubia, J 62\nZhang, Y 224\nZia, H 5, 19, 241\nZuyev, S A 67",
    "chunk_order_index": 164,
    "full_doc_id": "doc-29dd7e687fb631c05088db7e630df902"
  },
  "chunk-5f38df294d28d0cd18facac8a231ec4f": {
    "tokens": 1200,
    "content": "Asian Journal of Computer Science And Information Technology 3: 1 (2013) 1 - 8. \n\nContents lists available at www.innovativejournal.in \n\nAsian Journal of Computer Science and Information Technology \n\nJournal homepage: http://www.innovativejournal.in/index.php/ajcsit \n\nSPATIAL CLUSTERING ALGORITHMS - AN OVERVIEW \n\nBindiya M Varghese1, Unnikrishnan A1, Poulose Jacob K2 \n\nNPOL Kochi, India. \nCUSAT Kochi, India. \n\nARTICLE INFO \n\nABSTRACT \n\nCorresponding Author: \nBindiya M Varghese  \nNPOL Kochi, India \nbindiyabhi@gmail.com \n\nAn Overview of known spatial clustering algorithms The space of interest can \nbe the two-dimensional abstraction of the surface of the earth or a man-made \nspace  like  the  layout  of  a  VLSI  design,  a  volume  containing  a  model  of  the \nhuman brain, or another 3d-space representing the arrangement of chains of \nprotein  molecules.  The  data  consists  of  geometric  information  and  can  be \neither  discrete  or  continuous.  The  explicit  location  and  extension  of  spatial \nobjects define implicit relations of spatial neighborhood (such as topological, \ndistance  and  direction  relations)  which  are  used  by  spatial  data  mining \nalgorithms. Therefore, spatial data mining algorithms are required for spatial \ncharacterization and spatial trend analysis. Spatial data mining or knowledge \ndiscovery  in  spatial  databases  differs  from  regular  data  mining  in  analogous \nwith the differences between non-spatial data and spatial data. The attributes \nof a spatial object stored in a database may be affected by the attributes of the \nspatial  neighbors  of  that  object.  In  addition,  spatial  location,  and  implicit \ninformation  about  the  location  of  an  object,  may  be  exactly  the  information \nthat can be extracted through spatial data mining. \n\n2013, AJCSIT, All Right Reserved. \n\nINTRODUCTION \n\nSpatial  data  means  data  related  to  space  (Güting, \n1994).  The  space  of  interest  can  be  the  two-dimensional \nabstraction of the surface of the earth or a man-made space \nlike  the  layout  of  a  VLSI  design,  a  volume  containing  a \nmodel  of \nthe  human  brain,  or  another  3d-space \nthe  arrangement  of  chains  of  protein \nrepresenting \nmolecules. The data consists of geometric information and \ncan  be  either  discrete  or  continuous.  The  explicit  location \nand extension of spatial objects define implicit relations of \nspatial  neighborhood  (such  as  topological,  distance  and \ndirection  relations)  which  are  used  by  spatial  data  mining \nalgorithms.  Therefore,  spatial  data  mining  algorithms  are \nrequired  for  spatial  characterization  and  spatial  trend \nanalysis.  Spatial  data  mining  or  knowledge  discovery  in \nspatial  databases  differs  from  regular  data  mining  in \nanalogous  with  the  differences  between  non-spatial  data \nand spatial data. The attributes of a spatial object stored in \na database may be affected by the attributes of the spatial \nneighbors  of  that  object.  In  addition,  spatial  location,  and \nimplicit information about the location of an object, may be \nexactly  the  information  that  can  be  extracted  through \nspatial  data  mining  (Usama  Fayyad,  Gregory  Piatetsky-\nshapiro,Padhraic Smyth., 1996).  \nSpatial data \n\nSpatial  data  consists  of  data  that  have  a  spatial \ncomponent. Spatial objects can be made up of points, lines, \nregions,  rectangles,  surfaces,  volumes,  and  even  data  of \nincludes  time.  The  spatial \nhigher  dimension  which \n\n1 \n\nis \n\nimplemented  with  a  specific \n\nlocation \ncomponent \nattribute such as address or implicitly done by partitioning \nthe  database  based  on  location.  Geographic  Information \nsystems  (GIS),  biomedical  applications  including  medical \nimaging, agricultural science etc. produces large volume of \nspatial data. \nSpatial Clustering \nClustering  is  a  descriptive  task  that  seeks  to  identify \nhomogeneous groups of objects based on the values of their \nattributes  (Ester,  M.,  Frommelt,  A.,  Kriegel,  H.-P.,  and \nSander,  J,  1998).  In  spatial  data  sets,  clustering  permits  a \ngeneralization  of  the  spatial  component \nlike  explicit \nlocation  and  extension  of  spatial  objects  which  define \nimplicit  relations  of  spatial  neighborhood.  Current  spatial \nclustering  techniques  can  be  broadly  classified  into  three \ncategories;  partitional,  hierarchical  and \nlocality-based \nalgorithms. \nPartition based algorithms \nGiven a set of objects and a clustering criterion, partitional \nclustering  obtains  a  partition  of  objects  into",
    "chunk_order_index": 0,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-1ea8e1853cc00ab6a48a80b98483f28f": {
    "tokens": 1200,
    "content": "explicit \nlocation  and  extension  of  spatial  objects  which  define \nimplicit  relations  of  spatial  neighborhood.  Current  spatial \nclustering  techniques  can  be  broadly  classified  into  three \ncategories;  partitional,  hierarchical  and \nlocality-based \nalgorithms. \nPartition based algorithms \nGiven a set of objects and a clustering criterion, partitional \nclustering  obtains  a  partition  of  objects  into  clusters  such \nthat  the  objects  in  a  cluster  is  more  similar  to  the  objects \ninside  the  cluster  than  to  objects  in  different  clusters. \nPartitional clustering algorithms attempt to decompose the \ndataset directly into a set of k disjoint clusters, provided k \nis the number of initial clusters. An iterative optimization is \ndone  to  emphasize  the  local  structure  of  data,  which \ninvolves  minimizing  some  measure  of  dissimilarity  in  the \nthe \nobjects  within \n\nthe  cluster,  while  maximizing \n\n \n  \n \n \n \n \n \n \n \n\fBindiya et.al/ Spatial Clustering Algorithms- An overview \n\nJ.  \n\nℜ\n\nspeciﬁed  criterion function   \n\ndissimilarity of different clusters. Partitional algorithms are \ngenerally  iterative  in  nature  and  converge  to  some  local \noptima.  Given  a  set  of  data  points      xi  ∈ \nd,  i  =  1,…,N  , \npartitional clustering algorithms aim to organize them into   \nK    clusters  {C1,  …,  CK}  while  maximizing  or  minimizing  a \npre-\nK-mediod \nK-medoids  algorithms  are  partitional  algorithm  which \nattempt  to  minimize  squared  error,  the  distance  between \npoints labeled to be in a cluster and a point designated as \nthe center of that cluster. A medoid can be defined as that \nobject  of  a  cluster,  whose  average  dissimilarity  to  all  the \nobjects  in  the  cluster  is  minimal  i.e.  it  is  a  most  centrally \nlocated  point  in  the  given  data  set.  In  contrast  to  the  k-\nmeans algorithm k-medoids chooses data points as centers. \nPAM \n(PAM)  algorithm \nThe  Partitioning  around  medoid \nrepresents  a  cluster  by  a  medoid  (Ng,  Raymond  T.  and \nJiawei  Han.,  1994).  PAM  is  based  on  the  search  for  k \nrepresentative  objects  among  the  objects  of  the  data  set. \nThese  objects  should  represent  various  aspects  of  the \nstructure  of  the  data  are  often  called  centrotypes.  In  the \nPAM algorithm the representative objects are the so-called \nmedoid  of  the  clusters  (Kaufman  and  Rousseeuw,  1987). \nAfter finding a set of k representative objects, the k clusters \nare constructed by assigning each object of the data set to \nthe nearest representative object.  \nInitially,  a  random  set  of  K  items  is  taken  to  be  the  set  of \nmedoids. Then, at each step, all items other than the chosen \nmedoids  from  the  input  sample  set  are  examined  one  by \none  to  see  if  they  should  be  the  new  medoids.  The \nalgorithm chooses the new set of medoids which improves \nthe overall quality of the clustering and replaces the old set \nof medoids with them.  \nLet Ki be the cluster represented by the medoid ti. To swap \nwith  a  non  medoid  th,  the  cost  change  of  an  item  tj \nassociated  with  the  of  exchange  of  ti  with  th,  Cjih  has  to  be \ncomputed. (M. Ester, H.-P. Kriegel, S. Jörg, and X. Xu, 1996). \nThe  total  impact  to  quality  by  a  medoid  change  TCjih  is \ngiven by TCjih = \nThe k-medoid methods are very robust to the existence of \noutliers.  Also,  Clusters    found  by    K-medoid  methods    do \nnot    depend  on    the    order    in  which    the    objects    are \nexamined.  They  are  invariant  with  respect  to  translations \nand orthogonal transformations of data points.  PAM does \nnot  scale  well \nits \ncomputational complexity. For each iteration, the cost TCjih \nhas to be computed for k(n-k) pair of objects. Thus the total \ncomplexity  per  iteration  is  k(n-k)2  ,  thereby  making  PAM \nnot an alternative for large databases. \nCLARA \n\nlarge  datasets  because  of \n\n𝑛\n𝑗=1\n∑\n\n𝐶𝑗𝑖ℎ\n\nto \n\n. \n\nCLARA  (Clustering  Large  Applications)  improves \non the time complexity of PAM (Ng, Raymond T. and Jiawei \nHan.,",
    "chunk_order_index": 1,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-052592aed0a18ce4096be08df5f32eac": {
    "tokens": 1200,
    "content": "per  iteration  is  k(n-k)2  ,  thereby  making  PAM \nnot an alternative for large databases. \nCLARA \n\nlarge  datasets  because  of \n\n𝑛\n𝑗=1\n∑\n\n𝐶𝑗𝑖ℎ\n\nto \n\n. \n\nCLARA  (Clustering  Large  Applications)  improves \non the time complexity of PAM (Ng, Raymond T. and Jiawei \nHan.,  1994).  CLARA  relies  on  sampling.  PAM  is  applied  to \nlarge  datasets.  For  better \nsamples  drawn  from  the \napproximations, CLARA draws multiple samples and gives \nbest clustering as the result. For accuracy, the quality of a \nclustering  is  measured  based  on  the  average  dissimilarity \nof  all  objects  in  the  entire  data  set,  and  not  only  of  those \nobjects in the samples. \nThe  method  used  in CLARA, which was  first described by \nKaufman  and  Rousseeuw  (1986),  is  based \n  the  \nselection of   five    (or  more)    random    samples  of   objects. \nThe    size    of    the    samples    depends    on    the    number    of  \nclusters.  For  a clustering  into  k  clusters,  the  size  of  the  \n\n  on \n\n2 \n\nsamples  is  given  by  40 + 2k. [2]. for  CLARA,  by  applying  \nPAM  just  to  the  samples, each iteration  is  of O(k(40  +  \nk)2 +  k(n  -  k)).  This explains why CLARA is more efficient \nthan PAM for large values of n. \nCLARANS \nCLARANS \n(Clustering  Large  Applications  based  on \nRandomized Search) improves on CLARA by using multiple \ndifferent samples (Ng, Raymond T. and Jiawei Han., 1994). \nWhile CLARA draws a sample of nodes at the beginning of a \nsearch, CLARANS draws a sample of neighbors in each step \nof a search. This has the benefit of not confining a search to \na  localized  area.  In  addition  to  the  normal  input  to  PAM, \nCLARANs  uses  two  additional  parameters;  numlocal  and \nmaxneighbor. Numlocal indicates the number of samples to \nbe  taken.  The  numlocal  also  indicates  the  number  of \nclustering to be made since a new clustering has to be done \non  every  sample.  Maxneighbor  is  the  number  of  neighbors \nof a  node to which  any specific  node can  be  compared.  As \nmaxneighbor  increases,  CLARANs  resemble  PAM,  because \nall  nodes  are  to  be  examined.  J.  Han  et  al  shows  the  good \nthe  parameters  are  numlocal  =  2  and \nchoice \nmaxneighbor  =  max \n((0.0125  x  k(n-k)),250).  The \ndisadvantage of CLARANS is that it assumes all data are in \nmain memory. \nSDCLARANS \nSpatial dominant CLARANS assumes the data set to contain \nspatial  and  non-spatial  components  (Ng,  Raymond  T.  and \nJiawei  Han.,  1994).  The  general  approach  is  to  cluster \nspatial components using CLARANS and then examines the \nnon-spatial  within  each  cluster  to  derive  a  description  of \nthat  cluster.  For  mining  spatial  attributes,  a  tool  named \nDBLEARN is used (Jiawei Han , Yandong Cai , Nick Cercone, \n1992 ).  From  a  learning  request, DBLEARN  first  extracts  \na set of  relevant  tuples  via  SQL  queries.  Then  based on  \nthe  generalization  hierarchies  of  attributes,  it  ,iteratively  \ngeneralizes    the    tuples.    SDCLARANS  is  a  combination  of \nCLARANS and DBLEARN. \nNSDCLARANS \n\nfor \n\nOpposite  to  SDCLARANS,  NSDCLARANS  considers \nthe  non-spatial  attributes  in  the  first  phase  (Jiawei  Han  , \nYandong Cai , Nick Cercone, 1992 ). DBLEARN  is applied to  \nthe    non-spatial    attributes,  until    the    final    number    of  \ngeneralized  tuples  fall below a certain  threshold. For each \ngeneralized  tuple  obtained  above,  the  spatial  components \nof the tuples represented by the current generalized tuple \nare collected, and CLARANS is applied. \nK-Mean \nK-means  is  one  of  the  simplest  unsupervised  learning \nalgorithms  used  for  clustering.  K-means  partitions  n \nobservations  into  k  clusters  in  which  each  observation \nbelongs  to  the  cluster  with  the  nearest  mean.  This \nalgorithm  aims  at  minimizing  an  objective  function",
    "chunk_order_index": 2,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-7ec78a482b473313c37e830c53a6c786": {
    "tokens": 1200,
    "content": ", and CLARANS is applied. \nK-Mean \nK-means  is  one  of  the  simplest  unsupervised  learning \nalgorithms  used  for  clustering.  K-means  partitions  n \nobservations  into  k  clusters  in  which  each  observation \nbelongs  to  the  cluster  with  the  nearest  mean.  This \nalgorithm  aims  at  minimizing  an  objective  function,  in  this \ncase  a  squared  error  function.  The  algorithm  aims  to \nminimize \n\nthe  objective \n\nfunction \n\n=\n\n where \n\nis  a  chosen  distance  measure \n−\n2\n2\nbetween  a  data  point \n,  is  an \n𝑐𝑗�\n𝑐𝑗�\nindicator  of  the  distance  of  the  n  data  points  from  their \n𝑗\n𝑥𝑖\nrespective cluster centres. \nDENCLUE \n\nand  the  cluster  centre \n\n�𝑥𝑖\n\n𝑐𝑗\n\n−\n\n∑\n\n𝐽\n\n𝑛\n∑ �𝑥𝑖\n𝑖=1\n\n𝑘\n𝑗=1\n\n𝑗\n\n𝑗\n\nDENCLUE \n\n(Density  basted  Clustering) \nlocality-based \n\nis  a \ngeneralization \nand \npartitioning, \nhierarchical  or  grid-based  clustering  approaches  (A. \nHinneburg  and  D.  A.  Keim,  1998).  The  influence  of  each \ndata  point  can  be  modeled  formally  using  a  mathematical \n\nof \n\n \n \n\fBindiya et.al/ Spatial Clustering Algorithms- An overview \n\nfunction called influence function. This influence function is \napplied  to  each  data  point.  The  algorithm  models  the \noverall  point  density  analytically  using  the  sum  of  the \ninfluence  functions  of  the  points.  An  example  influence \n\n(\n\n,\n\n)\n\nfunction  can  be  a  Gaussian  function    fGauss  (x,y)=   \n. \n2\nThe  density  function  which  results  from  a  guassian \n\n𝑧\n𝑦\n2𝜎2\n\n−\n\n𝑑\n\n(\n\n,\n\n)\n\n𝑒\n\n2\n\n𝑑\n\n−\n\n𝑥\n\n𝑦\n𝑧\n2𝜎2\n\n) =  \n\n𝐷\n𝑓𝐺𝑢𝑎𝑠𝑠\n\n𝑁\n𝑖=1\n∑ 𝑒\n\n(\n.  Clusters \ninfluence  function  is       \ncan  then  be  determined  mathematically  by  identifying \ndensity  attractors.  Density  attractors  are  local  maxima  of \nthe  overall  density  function.  These  can  be  either  center-\ndefined  clusters,  similar  to  k-means  clusters,  or  multi-\ncenter-defined  clusters,  that  is  a  series  of  center-defined \nclusters linked by a particular path which identify clusters \nof  arbitrary  shape.  Clusters  of  arbitrary  shape  can  also  be \ndefined  mathematically.  The  mathematical  model  requires \ntwo parameters, α and ξ. α is a parameter which describes \na  threshold  for  the  influence  of  a  data  point  in  the  data \nspace  and  ξ  is  a  parameter  which  sets  a  threshold  for \ndetermining whether a density-attractor is significant. \n\nThe  three  major  advantages  for  this  method  of \nhigher-dimensional  clustering  claimed  by  the  authors  are \nthat  the  algorithm  provides  a  firm  mathematical  base  for \nfinding  arbitrary  shaped  clusters  in  high-dimensional \ndatasets.    Also,  result  show  good  clustering  properties  in \ndata  sets  with  large  amounts  of  noise  and  significantly \nfaster than existing algorithms. \nHierarchical \n\nA sequence is said to be a hierarchical clustering if \nthere exists 2 samples, c1 and c2, which belong in the same \ncluster at some level k and remain clustered together at all \nhigher  levels  >  k.  The  hierarchy  is  represented  as  a  tree, \ncalled  a  dendrogram,  with  individual  elements  at  one  end \nand a single cluster containing every element at the other. \nHierarchical  clustering  algorithms  are  either  top-down  or \nbottom-up.  Bottom-up  algorithms  called  hierarchical \nagglomerative  clustering,  treat  each  object  as  a  singleton \ncluster  at  the  outset  and  then  successively  merge  (or \nagglomerate)  pairs  of  clusters  until  all  clusters  have  been \nmerged \ninto  a  single  cluster.  Top-down  or  divisive \nclustering  proceeds  by  splitting  clusters  recursively  until \nindividual objects s are reached. \nAgglomerative algorithms \nCURE \n\nCURE \n\nidentifies  clusters  having  non-spherical \nshapes  and  wide  variances  in",
    "chunk_order_index": 3,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-3c1da7b6f22de20819c8b03a12efea8f": {
    "tokens": 1200,
    "content": "(or \nagglomerate)  pairs  of  clusters  until  all  clusters  have  been \nmerged \ninto  a  single  cluster.  Top-down  or  divisive \nclustering  proceeds  by  splitting  clusters  recursively  until \nindividual objects s are reached. \nAgglomerative algorithms \nCURE \n\nCURE \n\nidentifies  clusters  having  non-spherical \nshapes  and  wide  variances  in  size  (Sudipto  Guha  ,  Rajeev \nRastogi  ,  Kyuseok  Shim,  1998).    CURE  is  a  bottom-up \nhierarchical  clustering  algorithm,  but  instead  of  using  a \ncentroid-based  approach  or  an  all-points  approach  it \nemploys a method that is based on choosing a well-formed \ngroup  of  points  to  identify  the  distance  between  clusters. \nCURE  achieves  this    by    representing    each  cluster    by    a  \ncertain  fixed  number  of  points  that  are  generated  by  \nselecting  well  scattered  points  from  the  cluster. In fact, \nCURE  begins  by  choosing  a  constant  number,  c  of  well \nscattered  points  from  a  cluster.  These  points  are  used  to \nidentify the shape and size of the cluster. The next step of \nthe  algorithm  shrinks  the  selected  points  toward  the \ncentroid of the cluster using some pre- determined fraction \nα.  These  scattered  points  after  shrinking  are  used  as \nrepresentatives of the cluster.  The clusters with the closest \npair of  representative  points  are  the  clusters  that  are  \nmerged    at  each    step   of   CURE’s    hierarchical   clustering  \nalgorithm.  CURE    is    less  sensitive    to    outliers    since  \nshrinking    the    scattered    points    toward    the    mean  \n\n3 \n\nreduces  the      adverse    effects    due    to    outliers    since \noutliers are  typically  further  away  from  the  mean  and  \nare thus  shifted  a  larger  distance  due  to  the  shrinking.   \nThe  kinds  of  clusters  identified  by  CURE  can be  \ntuned  by  varying  α:  between  0  and  1.  CURE  reduces to  \nthe  centroid-based  algorithm  if  α =  1,  while  for  α =  0, it  \nbecomes    similar    to    the    all-points    approach.    CURE’s  \nhierarchical  clustering  algorithm  have a space complexity \nlinear  to the  input  size  n  and  has  a  worst-case  time  \ncomplexity    of  O(n2  log  n).  For  lower  dimensions  the \ncomplexity  is  further  reduced  to  O(n2).  The  overview  of \nCURE  algorithm  can  be  diagrammatically  represented  as \n[12] \n\nFigure 1 Overview of CURE \nROCK \nROCK  (Robust  Clustering  using  links)  implements  a  new \nlinks  to  measure  the  similarity/proximity \nconcept  o \nbetween  a  pair  of  data  points  (Sudipto  Guha,  Rajeev \nRastogi,  Kyuseok  Shim,  1999).  A  pair  of  data  points  are \nconsidered  neighbors  if  their  similarity  exceeds  a  certain \nthreshold. The number of links between a pair of points is \nfor  the  points.  Points \nthen  the  common  neighbors \nbelonging  to  a  single  cluster  will  have  a  large  number  of \ncommon  neighbors.  Let  sim(pi,pj)  be  a  similarity  function \nthat is normalized and captures the closeness between the \npair of points pi and pj. The sim assumes values between 0 \nand 1. Given a threshold θ between 0 and 1, a pair of points \n(pi, pj) is defined to be neighbors if sim (pi,pj) > θ. Link (pi,pj), \nthe  number  of  common  neighbors  between  the  pair  of \npoints  pi  and  pj.  The  criterion  function  is  to  maximize  the \nsum of link(pq,pr) for data pairs pq, pr belonging to a single \ncluster  and  at  the  same  time,  minimize  the  sum  of \nlink(pq,ps)  for  pq  and  ps  in  different  clusters.  i.e.  Maximize \n)\n  where  cluster  Ci  denotes \n\n (\n\n𝑙𝑖𝑛𝑘\n\n𝑝𝑞\n1+2𝑓\n\n∈\n\n𝐶𝑖\n\n𝑛𝑖\n\n𝑞𝑝𝑟\n\n𝑝\n∑\n\n𝑘\ncluster  i  of  size  n.  The  worst  case  time  complexity  of  the \n∑ 𝑛𝑖 ∗\n𝑖=1\nalgorithm",
    "chunk_order_index": 4,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-3d10d94a57bb207466f421e05102bdaa": {
    "tokens": 1200,
    "content": "�𝑘\n\n𝑝𝑞\n1+2𝑓\n\n∈\n\n𝐶𝑖\n\n𝑛𝑖\n\n𝑞𝑝𝑟\n\n𝑝\n∑\n\n𝑘\ncluster  i  of  size  n.  The  worst  case  time  complexity  of  the \n∑ 𝑛𝑖 ∗\n𝑖=1\nalgorithm  is  O  (n2  +  nmmma  +  n2  log  n),  where  mm  is  the \nmaximum number of neighbors, ma is the average number \nof neighbors, and n is the number of data points. The space \ncomplexity is O( min{n2, nmmma}) \nCHAMELEON \nCHAMLEON  measures  the  similarity  based  on  a  dynamic \nmodel  (George  Karypis  ,  Eui-Hong  (Sam)  Han  ,  Vipin \nKumar,  1999).  Two  clusters  are  merged  only  if  the  inter-\nconnectivity  and  closeness  between  two  clusters  are  high \nrelative  to  the  internal  inter-connectivity  of  the  clusters \nthe  clusters. \nand  closeness  of  data  points  within \nCHAMELEON  operates  on  a  sparse  graph  in  which  nodes \nrepresent  data  items,  and  weighted  edges  represent \nsimilarities  among  the  data  items.  This  sparse  graph \nrepresentation of the data set allows CHAMELEON to scale \nto  large  data  sets.  CHAMELEON  finds  the  clusters  in  the \ndata  set  by  using  a  two  phase  algorithm.  During  the  first \nphase, CHAMELEON uses a graph partitioning algorithm to \ncluster  the  data  items  into  a  large  number  of  relatively \nsmall  sub-clusters.  During  the  second  phase,  it  uses  an \nagglomerative hierarchical clustering algorithm to find the \n\n,   \n (\n\n)\n𝑝𝑟\n𝜃\n\n \n \n \n \n \n\fBindiya et.al/ Spatial Clustering Algorithms- An overview \n\ngenuine  clusters  by  repeatedly  combining  together  these \n\nsub-clusters.\n\nFigure 2  Overview of CHAMELEON algorithm \n\nCHAMELEON’s  sparse  graph  representation  of  the  data \nitems  is  based  on  the  k-nearest  neighbor  graph  approach. \nEach  vertex  of  the  k-nearest  neighbor  graph  represents  a \ndata item, and there exists an edge between two vertices, if \ndata items corresponding to either of the nodes are among \nthe  k-most  similar  data  points  of  the  data  point \ncorresponding to the other node. CHAMELEON determines \nthe  similarity  between  each  pair  of  clusters  Ci  and  Cj  by \nlooking  both  at  their  relative  inter-connectivity  RI(Ci,  Cj) \nand  their  relative  closeness  RC(Ci  ,Cj  ).  CHAMELEON’s \nhierarchical clustering algorithm selects to merge the pair \nof clusters for which both RI (Ci ,Cj ) and RC(Ci ,Cj) are high; \ni.e.,  it  selects  to  merge  clusters  that  are  well  inter-\nconnected  as  well  as  close  together  with  respect  to  the \ninternal  inter-connectivity  and  closeness  of  the  clusters. \nThe relative inter-connectivity between a pair of clusters Ci \n-connectivity between \nand Cj \nCi  and  Cj  normalized  with  respect  to  the  internal  inter-\nconnectivity  of  the  two  clusters  Ci  and  Cj.  The  absolute \ninter-connectivity  between  a  pair  of  clusters  Ci  and  Cj  is \n\nis deﬁned as the absolute inter\n\nconnect  vertices  in  Ci  to  vertices  in  Cj  .  This  is  essentially \ndeﬁned  to  be  as  the  sum  of  the  weight  of  the  edges  that \nthe edge-cut of the cluster, EC{Ci ,Cj } containing both Ci and Cj \nsuch that the cluster is broken into Ci and Cj . The relative \ninter-connectivity  between  a  pair  of  clusters  Ci  and  Cj  is \n ,\n\n }\n\n{\n\ngiven  by  RI(Ci,  Cj)  = \n\n  which  normalizes  the \n\n𝐶𝑖\n\n�𝐸𝐶\n�𝐸𝐶𝐶𝑖\n\n𝐶𝑗\n�\n�𝐸𝐶𝐶𝑗\n\n�+\nabsolute inter-connectivity with the average internal inter-\n2\nconnectivity  of  the  two  clusters.    The  relative  closeness \nbetween a pair of clusters Ci and Cj is computed as, \n\n�\n\nRC(Ci \n\n,Cj  )  = \n\n{\n\n ,\n\n }\n\n𝑆̅𝐸𝐶\n\n𝐶𝑖\n\n𝐶𝑗\n\n,  where \n\nand \n\n𝑆̅",
    "chunk_order_index": 5,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-7337eb5e843ef217a356c8494bcf5ff3": {
    "tokens": 1200,
    "content": "�𝑗\n\n�+\nabsolute inter-connectivity with the average internal inter-\n2\nconnectivity  of  the  two  clusters.    The  relative  closeness \nbetween a pair of clusters Ci and Cj is computed as, \n\n�\n\nRC(Ci \n\n,Cj  )  = \n\n{\n\n ,\n\n }\n\n𝑆̅𝐸𝐶\n\n𝐶𝑖\n\n𝐶𝑗\n\n,  where \n\nand \n\n𝑆̅𝐸𝐶𝐶𝑖\n\n ,\n\n�𝐶𝑗�\n\n�𝐶𝑗�\n\n𝑆̅𝐸𝐶𝐶𝑗\n\n𝑆̅𝐸𝐶𝐶𝑖 +\n\n�𝐶𝑖�\n�𝐶𝑖�+\n\n�𝐶𝑗�\nare the average weights of the edges that belong in the \n\n�𝐶𝑖�+\nmin-cut  bisector  of  clusters  Ci  and  Cj  ,  respectively,  and \n𝑆̅𝐸𝐶𝐶𝑗\n } is  the  average  weight  of  the  edges  that  connect \n{\nvertices  in  Ci  to  vertices  in  Cj  .  The  overall  complexity  of \n𝑆̅𝐸𝐶\nCHAMELEON’s two-phase clustering algorithm is O(nm + n \nlog n + m2 log m). \nDivisive Algorithms \nSTING \n\n𝐶𝑗\n\n𝐶𝑖\n\nStatistical Information Grid-based method exploits \nthe  clustering  properties  of  index  structures  (Wei  Wang  , \nJiong Yang , Richard R. Muntz, 1997). The  spatial  area  is  \ndivided into  rectangular  cells which  forms  a  hierarchical  \nstructure. Each cell  at a high  level  is partitioned  to  form  \na  number  of  cells    of    the    next    lower    level.    Statistical \ninformation  of  each  cell  is \n  calculated  and  stored \nbeforehand  and  is  used  to  answer  queries.  For  each  cell, \ntwo  types  of  parameters  are  considered;  attribute-\ndependent and attribute-independent parameters.  The  \n\n4 \n\nattribute-  independent  parameter  are  the  number  of \nobjects  (points)  in  this  cell,  say  n.  Attribute-dependent \nparameters are  \n\n•  m: mean  of all  values  in  this  cell \n• \n\ns:  standard  deviation    of    all    values  of    the \nattribute  in this  cell  \n\n•  min: the  minimum  value  of  the attribute  in  this  \n\ncell  \n\n•  max: the maximum  value  of  the attribute  in  this  \n\ncell  \n\n•  distribution \n\nthe  type  of  distribution  that  the \n\nattribute  value  in  this  cell  follows. \nClustering  operations  are  performed  using  a  top-\ndown method, starting with the root. The relevant cells are \ndetermined  using  the  statistical  information  and  only  the \npaths from those cells down the tree are followed. Once the \nleaf  cells  are  reached,  the  clusters  are  formed  using  a \nbreadth-first  search,  by  merging  cells  based  on  their \nproximity  and  whether  the  average  density  of  the  area  is \ngreater than some specified threshold. The  computational  \ncomplexity  is  O(K),  where  K  is the number  of  grid  cells  \nat    the    lowest    level.    Usually  K  <<  N,  where  N  is  the \nnumber of objects. \nSTING+ \n\nSTING+  is  an  approach  to  active  spatial  data \nmining, which takes advantage of the rich research results \nof  active  database  systems  and  the  efficient  algorithms  in \nSTING (Wei Wang , Jiong Yang , Richard R. Muntz, 1997)for \npassive spatial data mining (Wei Wang, Jiong Yang, Richard \nMuntz,  1999)\nadjacent  leaf  level  cells.  Also,  object  density  and  attribute \n.    A  region  in  STING+  is  deﬁned  as  a  set  of \n in terms of leaf level cells. \n\nconditions in STING+ are deﬁned\nnumber  of  objects  in  this  cell  divided  by  the  area  of  this \nThe density of a leaf level cell is deﬁned as the ratio of the \ncell. A region is said to have a certain density c if and only if \nthe density of every leaf level cell in this region is at least c. \n\nConditions  on  attribute  values  are  deﬁned  in  a  similar \nuser.  One  condition  is  an  absolute  condition,  i.e.,  the \nmanner.  Two  kinds  of  conditions  can  be  speciﬁed  by  the \ncondition  is  satisfied  when  a  certain  state  is  reached.  The \nother  type  of  condition  is  a  relative  condition,  i.e.,  the \ncondition is satisfied when a certain degree of change has",
    "chunk_order_index": 6,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-7da45ed78e73cedeac77a08e2b4c1fe5": {
    "tokens": 1200,
    "content": "user.  One  condition  is  an  absolute  condition,  i.e.,  the \nmanner.  Two  kinds  of  conditions  can  be  speciﬁed  by  the \ncondition  is  satisfied  when  a  certain  state  is  reached.  The \nother  type  of  condition  is  a  relative  condition,  i.e.,  the \ncondition is satisfied when a certain degree of change has \nbeen  detected.  Therefore,  four  categories  of  triggers  are \nsupported by STING+; \n\n1.  Region-trigger:  absolute  condition  on  certain \n\nregions \n\n2.  Attribute-trigger:  absolute  condition  on  certain \n\nattributes \n\n3.  Region  trigger:  relative  condition  on  certain \n\nregions \n\n4.  Attribute  trigger:  relative  condition  on  certain \n\nattributes. \n\n \n \n \n \n \n \n \n \n \n \n\fBindiya et.al/ Spatial Clustering Algorithms- An overview \n\nBIRCH \n\nBalanced  Iterative  Reducing  and  Clustering  using \nHierarchies,  is  designed  for  clustering  large  amount  of \nmultidimensional  metric  data  points  (Tian  Zhang  ,  Raghu \nRamakrishnan  ,  Miron  Livny,  1996).  It  requires  only  one \nscan  of  the  entire  database  and  uses  only  a  limited \nmemory. BIRCH uses a hierarchical data structure called a \nCF-tree,  or  Clustering-Feature-tree  that  captures  the \nneeded  information.  A  clustering-feature  vector  CF  is  a \ntriple  that  stores  the  information  maintained  about  a \n,  SS}  contains  the  number  of \ncluster.  The  triple  CF=  {N, \ndata points in the cluster, N, and \n, the linear sum of the N \ndata points, i.e.\n, and SS, the square-Sum of the N data \n\n𝐿𝑆����⃗\n\n𝑁\n∑ 𝑋𝚤���⃗\n𝑖=1\n2\n\n𝑁\n∑ 𝑋𝚤���⃗\n𝑖=1\n\n.  A CF-tree is a height balanced tree with \npoints i.e. \na  branching  factor  B.  each  internal  node  contains  a  CF \ntriple  for  each  of  its  children.  Each  leaf  node  also \nrepresents  a  cluster  and  contains  a  CF  entry  for  each  sub \ncluster  in  it.  A  sub  cluster  in  a  leaf  node  must  have  a \ndiameter no greater than a given threshold value T.  \n\n𝐿𝑆����⃗\n\ninitial \n\nin-memory  CF-tree \n\nIn  the  pre-clustering  phase,  the  entire  database  is \nis  built, \nscanned  and  an \nrepresenting  dense  regions  of  points  with  compact \nsummaries  or  sub-clusters  in  the  leaf  nodes.  Phase  2, \nrescans the leaf nodes entries to build a smaller CF-tree. It \ncan  be  used  to  remove  outliers  and  make  larger  clusters \nfrom sub-clusters. Phase 3 attempts to compensate for the \norder-dependent  input.  It  uses  either  an  existing  centroid \nbased clustering algorithm, or a modification of an existing \nalgorithm  applied  to  the  sub-clusters  at  the  leaves  as  if \nthese  sub-clusters  were  single  points.  The  pre-clustering \nalgorithm is both incremental and approximate.  \n\nBIRCH  is  linear  in  both  space  and  I/O  time.  The \nchoice of threshold value is vital to an efficient execution of \nthe algorithm. The worst case complexity of BIRCH can be \nO(n2). \n\nFigure 3 Overview of BIRCH \n\nGrid Based \nWAVE CLUSTER \n\nWaveCluster  is  a  clustering  approach  based  on \nwavelet transforms (Gholamhosein Sheikholeslami , Surojit \nChatterjee , Aidong Zhang, 2000). WaveCluster is based on \nthe  representation  of  spatial  object  as  a  feature  vector \nwhere  each  element  of  the  vector  corresponds  to  one \nnumerical  attribute.    These  feature  vectors  of  the  spatial \ndata  can  be  represented  in  the  spatial  area,  which  is \ntermed feature space, where each dimension of the feature \nspace  corresponds  to  one  of  the  features.  For  an  object \nwith n numerical  attributes,  the  feature  vector  will  be \n\n5 \n\none    point    in    the    n-dimensional    feature    space.  The \ncollection  of  objects  in  the  feature  space  composes  an  n-\ndimensional  signal.    The  high    frequency    parts    of    the  \nsignal  correspond  to  the  regions  of  the  feature  space \nwhere    there    is  a  rapid    change  in    the    distribution    of \nobjects,    that    is",
    "chunk_order_index": 7,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-301a930950417d7d3541dbe1d490aded": {
    "tokens": 1200,
    "content": "point    in    the    n-dimensional    feature    space.  The \ncollection  of  objects  in  the  feature  space  composes  an  n-\ndimensional  signal.    The  high    frequency    parts    of    the  \nsignal  correspond  to  the  regions  of  the  feature  space \nwhere    there    is  a  rapid    change  in    the    distribution    of \nobjects,    that    is    the    boundaries    of  clusters.  The  low  \nfrequency  parts  of  the  n-dimensional signal  which  have  \nhigh  amplitude  correspond  to  the  areas of  the  feature  \nspace  where    the    objects    are    concentrated,    i.e.,    the  \nclusters  themselves.  \nThe WaveCluster Algorithm is given below \n\n1.  Quantize feature space, and then assign objects to \n\nthe units.  \n\n2.  Apply wavelet transform on the feature space.  \n3.  Find  the  connected components  (clusters)  in  the \nsub  bands  of    transformed    feature    space,  at  \ndifferent  levels.  \n\n4.  Assign label to the units.  \n5.  Make the lookup table.  \n6.  Map the objects to the clusters. \n\nThe  complexity  of  generating  clusters  is  O(n)  and \nis  not \nfind \nimpacted  by  Outliers.  WaveCluster  can \narbitrarily shaped clusters and does not need to know the \ndesired number of clusters. \nBANG \n\nBANG structure adapts to the distribution of items \nso that the dense areas have larger number of smaller grids \nand less dense areas have a few large ones (Erich Schikuta , \nMartin  Erhart,  1997).  BANG  organizes  the  value  space \ncontaining the patterns. The patterns are treated as points \nin  a  k-dimensional  value  space  and  are  inserted  into  the \nBANG-Structure  (E.  Schikuta,  1996).  These  points  are \nstored  accordingly  to  their  pattern  values  preserving  the \ntopological distribution. The BANG-structure partitions the \nvalue  space  and  administers  the  points  by  a  set  of \nsurrounding  rectangular  shaped  blocks.  These  blocks  are \nthen sorted based on their density, which is the number of \nitems in the grid divided by its area. Based on the number \nof  clusters  needed,  the  grids  with  the  highest  density  are \ntreated as cluster centre.  \nCLIQUE \n\n“automatic \n\nCLIQUE,  named  for  Clustering  In  Quest,  the  data \nmining  research  project  at  IBM  Almaden  and  is  an  grid-\nbased  approach  for  high  dimensional  data  sets  that \nprovides \nclustering  of  high \nsub-space \ndimensional  data”  (Rakesh  Agrawal  ,  Johannes  Gehrke  , \nDimitrios Gunopulos , Prabhakar Raghavan, 1998). CLIQUE \nidentifies  dense  clusters \nin  subspaces  of  maximum \ndimensionality.    It  generates  cluster  descriptions  in  the \nform  of  DNF  expressions  that  are  minimized  for  ease  of \ncomprehension.    It  produces  identical  results  irrespective \nof  the  order  in which  input  records  are  presented  and  \ndoes  not    presume    any  specific  mathematical    form    for  \ndata  distribution. \nCLIQUE algorithm consists of the following steps; \n\nIdentification of subspaces that contain clusters.  \nIdentification of clusters.  \n\n1. \n2. \n3.  Generation of minimal description for the clusters. \nThe  initial  phase  of  the  algorithm  partitions  the \ndata  space  S  into      non-overlapping  rectangular  units, \nwhere  S=  S    =    A1    x    A2    x    .  .  .  x    Ad    a    d-dimensional \nnumerical    space..    The  units  are  obtained  by  partitioning \nevery dimension into  ξ intervals of equal length, which is \nan  input  parameter.  Each    unit    u    is    the    intersection    of  \none  interval  from  each attribute. The  selectivity of  a  unit  \n\n \n\fBindiya et.al/ Spatial Clustering Algorithms- An overview \n\nis    defined    to    be    the    fraction    of    total    data    points \ncontained  in  the  unit.  A unit  u  is dense,  if  selectivity(u) \nis    greater    than    τ,    where    the    density    threshold    τ    is  \nanother  input    parameter.  Similarly  all  the  units  in  all \nsubspaces of the original d-dimensional space are defined.  \nA  cluster  is  a  maximal  set  of  connected  dense  units  in \nk-dimensions.    Region  in  k  dimensions  is  an  axis-parallel \nrectangular k-dimensional set. A  region  can  be  expressed  \nas a  DNF  expression  on  intervals  of  the  domains  Ai. A  \nregion  R  contained  in  a  cluster  C",
    "chunk_order_index": 8,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-42d80b56c8f39727e138397cd37a6902": {
    "tokens": 1200,
    "content": "are defined.  \nA  cluster  is  a  maximal  set  of  connected  dense  units  in \nk-dimensions.    Region  in  k  dimensions  is  an  axis-parallel \nrectangular k-dimensional set. A  region  can  be  expressed  \nas a  DNF  expression  on  intervals  of  the  domains  Ai. A  \nregion  R  contained  in  a  cluster  C  is  said  to be  maximal  \nif  no  proper  superset  of  R  is  contained  in  C.A  minimal  \ndescription  of  a  cluster  is  a  non-redundant covering  of  \nthe  cluster  with  maximal  regions.   \n\n  time \n\nThe  running \n\n  the  algorithm \n\nis  the  \nexponential  in  the highest  dimensionality  of  any  dense  \nunit. The algorithm makes k passes over the database. Thus \nthe  time  complexity  is      O(ck    +    m    k)    for    a    constant    c \nwhere k is the highest dimensionality of any dense unit and \nm  is  the  number  of  input  points.  This  algorithm  can  be \nimproved by pruning the set of dense units to those that lie \nin  “interesting”  subspaces  using  a  method  called  MDL-\nbased  pruning  or  minimal  description  length.  Subspaces \nwith  large  coverage  of  dense  units  are  selected  and  the \nremainder is pruned. \nMOSAIC \n\nfitness \n\n  have \n\n  been \n\nfunction \n\nMOSAIC  greedily  merges  neighboring  clusters \n(Jiyeon Choo, \nmaximizing  a  given \nRachsuda Jiamthapthaksin , \nChun-sheng Chen, \nOner Ulvi Celepcikay, Christian Giusti and Christoph F. Eick, \n2007).      MOSAIC    uses    Gabriel    graphs    to    determine  \nwhich    clusters    are  density-  based  neighboring    and  \napproximates  non-convex  shapes  as  the  unions  of  small \nclusters  that \n  a  \nrepresentative-based    clustering  algorithm.  The  Gabriel \ngraph of a set of points S in the Euclidean plane expresses \none  notion  of  proximity  or  nearness  of  those  points. \nMOSAIC  constructs  the  Gabriel  graph  for  a  given  set  of \nrepresentatives,  and  then  uses  the  Gabriel  graph  to \nconstruct  a  Boolean  merge-candidate  relation \nthat \ndescribes  which  of  the    initial    clusters    are    neighboring.  \nThis  merge \nthen  updated \nis \ncandidate \nincrementally when clusters are merged. \nDensity Based Algorithms \nDBSCAN \n\n  computed \n\nrelation \n\n  using \n\n Density  based  Spatial  Clustering  of  Applications \nwith noise (DBSCAN) creates clusters with a minimum size \nand  density  (M. Ester,  H.-P.  Kriegel,  S. Jörg,  and  X. Xu, \n1996). Density is defined as the number of points within a \ncertain  distance  of  each  other.  The  algorithm  uses  two \nparameters,  Eps  and  MinPts  to  control  the  density  of  the \ncluster. Minpts, indicates the minimum number of points in \nany cluster.  \nDefinitions: The Eps-neighborhood of a point is defined by \nNEps  (p)  =  {  q ∈D |    dist(p,  q)≤Eps  }.    The  distance  function \ndist(p,  q)  determines  the  shape  of  the  neighborhood. \nAlgorithm  DBSAN  does  not  require  the  desired  number  of \ncluster as initial input. Two kinds of points in a cluster are \nspecified  in  the  algorithm,  i.e.  core  points;  points  inside  of \nthe  cluster  and  border  points;  points  on  the  border  of  the \ncluster.  An  Eps-neighborhood  of  a  border  point  contains \nsignificantly less points than an Eps-neighborhood of a core \npoint. For every point p in a cluster C there is a point q in C \nso that p is inside of the Eps-neighborhood of q and NEps(q) \ncontains at least MinPts points. A point p is directly density-\nreachable from a point q wrt. Eps, MinPts if  \n\n6 \n\n1)  p \n2) \n\n(\n\n) \n\n) \n\n𝐶𝑜𝑟𝑒\n\n𝑝𝑜𝑖𝑛𝑡\n\n𝑐𝑜𝑛𝑑𝑖𝑡𝑖𝑜𝑛\n\n∈\n�𝑁𝐸𝑝𝑠\n\n)\n(\n𝑁𝐸𝑝𝑠\n�\n𝑞\n\n𝑞\n≥ 𝑀𝑖𝑛𝑝𝑡𝑠\n\n (\nDirectly  density-reachable  is  symmetric  for  a  pair  of  core \npoints  and  it  is  not  symmetric  if  one  core  point  and  one",
    "chunk_order_index": 9,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-f17813889dc1342dc9393d12c6e35a5c": {
    "tokens": 1200,
    "content": "�𝐸𝑝𝑠\n\n)\n(\n𝑁𝐸𝑝𝑠\n�\n𝑞\n\n𝑞\n≥ 𝑀𝑖𝑛𝑝𝑡𝑠\n\n (\nDirectly  density-reachable  is  symmetric  for  a  pair  of  core \npoints  and  it  is  not  symmetric  if  one  core  point  and  one \nborder  point  are  involved.    A  point  p  is  density-reachable \nfrom  a  point  q  wrt.  Eps  and  MinPts  if  there  is  a  chain  of \npoints  p1,  ...,  pn,    p1  =  q,  pn  =  p  such  that  pi+1  is  directly \ndensity-reachable  from  pi.  A  point  p  is  density-  connected \nto a point q wrt.  Eps and MinPts if there is a point o such \nthat both, p and q are density-reachable from o wrt. Eps and \nMinPts.  A  cluster  C  wrt.  Eps  and  MinPts  is  a  non-empty \nsubset  of  D,  where  D  is  a  database  of  points,  satisfy  the \nfollowing conditions: \n\n1)  ∀  p,  q:  if  p ∈  C  and  q  is  density-reachable  from  p \nwrt. Eps and MinPts, then q ∈ C. (Maximality) \n2)  ∀ p, q ∈ C: p is density-connected to q wrt. EPS and \n\nMinPts. (Connectivity) \n\nThe noise is defined as the set of points in the database D \nnot  belonging  to  any  cluster  Ci  ,  i.e.  noise  =  {p ∈D  | ∀  i:  p \n∉Ci}. \nAlgorithm:  DBSCAN  starts  with  an  arbitrary  point  p  and \nretrieves  all  points  density-reachable  from  p  wrt.  Eps  and \nMinPts.  If  p  is  a  core  point,  this  procedure  yields  a  cluster \nwrt.  Eps  and  MinPts.  If  p  is  a  border  point,  no  points  are \ndensity-reachable from p and DBSCAN visits the next point \nof  the  database.  Merge  two  clusters,  if  two  clusters  of \ndifferent  density  are  “close”  to  each  other.  The  algorithm \nmay  need  to  be  called  recursively  with  a  higher  value  for \nMinPts  if  “close”  clusters  need  to  be  merged  because  they \nare  within  the  same  Eps  threshold.  The  expected  time \ncomplexity of DBSCAN is O(n log n).  \nGDBSCAN \n\nGDBSCAN  -  can  cluster  point  objects  as  well  as \nspatially  extended  objects  according  to  both,  their  spatial \nand their non-spatial attributes (Jörg Sander , Martin Ester , \nHans-Peter  Kriegel \n,  Xiaowei  Xu,  1998).  GDBSCAN \ngeneralizes DBSCAN in two important ways. Any notion of \na neighborhood of an object can be used, if the definition of \nthe  neighborhood  is  based  on  a  binary  predicate  which  is \nsymmetric  and  reflexive.  Instead  of  simply  counting  the \nobjects  in  the  neighborhood  of  an  object,  other  measures \ncan  be  used  for  example,  considering  the  non-spatial \nattributes such as the average income of a city, to define the \n“cardinality” of that neighborhood. \n\nTo  find  a  density-connected  set,  GDBSCAN  starts \nwith an arbitrary object p and retrieves all objects density-\nreachable  from  p  with  respect  to  NPred;  neighborhood  of \nthe  object  and  MinWeight;  minimum  weighted  cardinality. \nIf  p  is  a  core  object,  this  procedure  yields  a  density-\nconnected set with respect to NPred and MinWeight . If p is \nnot  a  core  object,  no  objects  are  density-reachable  from  p \nand p is assigned to Noise, where Noise is defined as the set \nof  objects  in  the  database  D  not  belonging  to  any  density-\nconnected  set  Ci.  This  procedure  is  iteratively  applied  to \neach object p which has not yet been classified. \nOPTICS \n\nrepresenting \n\nits  density-based \n\nOPTICS  creates  an  augmented  ordering  of  the \ndatabase \nclustering \nstructure (Ankerst, Mihael, Markus M. Breunig, Hans-Peter \nKriegel,  and  Jörg  Sander,  1999).  Let  DB  be  a  database \ncontaining  n  points.  The  OPTICS  algorithm  generates  an \nordering  of \ncor",
    "chunk_order_index": 10,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-f9c12b7d388c63c07bf26c4fef4cb461": {
    "tokens": 1200,
    "content": "ing \n\nits  density-based \n\nOPTICS  creates  an  augmented  ordering  of  the \ndatabase \nclustering \nstructure (Ankerst, Mihael, Markus M. Breunig, Hans-Peter \nKriegel,  and  Jörg  Sander,  1999).  Let  DB  be  a  database \ncontaining  n  points.  The  OPTICS  algorithm  generates  an \nordering  of \ncorresponding  reach  ability-values  r:{1..n}→  R≥0.  OPTICS \n}  →DATABASE  and \nthe \ndoes  not  assign  cluster  memberships. \nalgorithm  store  the  order  in  which  the  objects  are \n\nthe  points  o:{1..n\n\nInstead, \n\n \n \n \n \n \n\fBindiya et.al/ Spatial Clustering Algorithms- An overview \n\nto \n\nassign \n\nprocessed and the information which would be used by an \nextended  DBSCAN \ncluster \nalgorithm \nmemberships. This information consists of only two values \nfor  each  object:  the  core-distance  and  a  reachability \ndistance.  The  core-distance  of  an  object  p  is  simply  the \nsmallest  distance  ε’  between  p  and  an  object  in  its  ε-\nneighborhood  such  that  p  would  be  a  core  object  with \nrespect  to  ε’  if  this  neighbor  is  contained  in  Nε(p). \nis  UNDEFINED.  The \nOtherwise, \nreachability-distance of an object p with respect to another \nobject  o  is  the  smallest  distance  such  that  p  is  directly \ndensity-reachable from o if o is a core object. Depending on \nthe  size  of  the  database,  the  cluster-ordering  can  be \nrepresented  graphically  for  small  data  sets  or  can  be \nrepresented  using  appropriate  visualization  technique  for \nlarge data sets. \nDBCLASD \n\ncore-distance \n\nthe \n\nDistribution  Based  Clustering  of  Large  Spatial \nDatabases  (DBCLASD)  is  another  locality-based  clustering \nalgorithm, but unlike DBSCAN, the algorithm assumes that \nthe  points  inside  each  cluster  are  uniformly  distributed \n(Xiaowei  Xu  ,  Martin  Ester  ,  Hans-Peter  Kriegel  ,  Jörg \nSander,  1998).  Three  parameters  are  defined  in  the \nalgorithm;  NNS(q),  NNDist  (q  ),  and  NNDistSet(S).  Let  q  be  a \nquery  point  and  S  be  a  set  of  points.  Then  the  nearest \nneighbor of q in S, denoted by NNS(q), is  a point p  in  S- {q} \nwhich has the minimum distance to q. The distance from q \nto  its  nearest  neighbor  in  S  is  called  the  nearest  neighbor \ndistance  of  q,    NNDist  (q  )for  short.  Let  S  be  a  set  of  points \nand ei  be the elements of S. The nearest neighbor distance \nset of S, denoted by NNDistSet(S), or distance set for short, is \nthe  multi-set  of  all  values.  The  probability  distribution  of \nthe  nearest  neighbor  distances  of  a  cluster  is  analysed \nbased on the assumption that the points inside of a cluster \nare  uniformly  distributed,  i.e.  the  points  of  a  cluster  are \ndistributed  as  a  homogeneous  Poisson  point  process \nrestricted to a certain  part  of the  data  space. A grid-based \nrepresentation  is  used to  approximate the  clusters as  part \nof the probability calculation.  DBCLASD is an incremental \nalgorithm.  Points  are  processed  based  on  the  points \npreviously seen, without regard for the points yet to come \nwhich  makes \nthe  clusters  produced  by  DBCLASD \ninput  order.  The  major  advantage  of \ndependent  on \nDBCLASD is that it requires no outside input which makes \nit  attractive  for  larger  data  sets  and  sets  with  larger \nnumbers of attributes. \nOthers \nSParClus \nSpaRClus  (Spatial  RelationshipPattern-Based  Hierarchical \nClustering) to cluster image data is based on an algorithm, \nSpIBag (Spatial Item Bag Mining), which discovers frequent \nspatial patterns in images (S. Kim, X. Jin, and J. Han, 2008). \nSpIBag  is  invariant  on  semi-a\nne  transformations.  Semi-\nne  transformation  is  a  way  to  express  or  detect  shape \na\nﬃ\ninternally  SpIBag \npreserving \nﬃ\nalgorithm  to  mine  frequent  patterns,  and  generates  a \nhierarchical  structure  of  image  clusters  based  on  their \nrepresentative  frequent  patterns.  When  SpIBag  algorithm \ngenerates  a  frequent  n-pattern  p,  SpaRClus",
    "chunk_order_index": 11,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-29f96dbfe90095a299c5367f646ca291": {
    "tokens": 1200,
    "content": "a  way  to  express  or  detect  shape \na\nﬃ\ninternally  SpIBag \npreserving \nﬃ\nalgorithm  to  mine  frequent  patterns,  and  generates  a \nhierarchical  structure  of  image  clusters  based  on  their \nrepresentative  frequent  patterns.  When  SpIBag  algorithm \ngenerates  a  frequent  n-pattern  p,  SpaRClus  computes  a \n and decides if p \nscoring function of its support image set  \nwill  be  used  or  not  to  join  with  other  n-patterns,  which \nenables more pruning power than using SpIBag alone. \nC2P \nC2P,  Clustering  based  on  Closest  Pairs,  exploits  spatial \naccess  methods  for  the  determination  of  closest  pairs \n\nimages.  SpaRClus  uses \n\n𝐼𝑝�\n\n(Nanopoulos, A., Theodoridis, Y., and Manolopoulos, 2001). \nC2P consists of two main phases. The first phase efficiently \ndetermines a number of sub-clusters. The first phase of C2P \nhas as input n points and produces m sub-clusters, and it is \niterative.  The  first  phase  of  C2P  has  the  objective  of \nefficiently  producing  a  number  of  sub-clusters  which \ncapture the shape of final clusters. Therefore, it represents \nclusters  with their  center  points.  The second  phase  uses  a \ndifferent  cluster  representation  scheme  to  produce  the \nfinal  clustering.  The  second  phase  performs  the  final \nclustering by using the sub-clusters of the first phase and a \ndifferent cluster representation scheme. The second phase \nmerges two clusters at each step in order to better control \nthe  clustering  procedure.  The  second  phase \nis  a \nspecialization of the first, i.e., the latter can be modified in: \na)  finding  different  points  to  represent  the  cluster  instead \nthe center point, b) finding at each iteration only the closest \npair  of  clusters  that  will  be  merged,  instead  of  finding  for \neach  cluster  the  one  closest  to  it.  The  time  complexity  of \nC2Pfor  large  datasets  is  O(nlog  n),  thus  it  scales  well  to \nlarge inputs. \nDBRS+ \nDensity-Based  Spatial  Clustering \nin  the  Presence  of \nObstacles  and  Facilitators  (DBRS+)  aims  to  cluster  spatial \ndata  in  the  presence  of  both  obstacles  and  facilitators \n(Wang,  X.,  Rostoker,  C.,  and  Hamilton,  H.  J,  2004).  The \nauthors  claim \nthat  without  preprocessing,  DBRS+ \nprocesses  constraints  during  clustering.  It  can  also  find \nclusters with arbitrary shapes and varying densities. DBRS \nthree \nis  a  density-based  clustering  method  with \nparameters,  Eps,  MinPts,  and  MinPur.  DBRS  repeatedly \npicks  an  unclassified  point  at  random  and  examines  its \nneighborhood,  i.e.,  all  points  within  a  radius  Eps  of  the \nchosen point.  The purity of the neighborhood is defined as \nthe  percentage  of  the  neighbor  points  with  the  same  non-\nspatial property as the central point. If the neighborhood is \nsparsely populated (≤MinPts) or the purity of the points in \nthe neighborhood is too low (≤MinPur) and disjoint with all \nknown clusters, the point is classified as noise.  Otherwise, \nif any point in the neighborhood is part of a known cluster, \nthis neighborhood is joined to that cluster, i.e., all points in \nthe neighborhood are classified as being part of the known \ncluster.   If neither of these two possibilities applies, a new \ncluster  is  begun  with  this  neighborhood. \n  The  time \ncomplexity  of  DBRS  is  O(n  log  n)  if  an  R-tree  or  SR-tree  is \nused to store and retrieve all points in a neighborhood. \n\nCONCLUSION \n\nThe main objective of spatial data mining is to find \npatterns  in  data  with  respect  to  its  locational  significance. \nThe scope of spatial mining increases as the data generated \nfrom  various  sources  which  are  geographically  referenced \nincreases. Every aspects of applications like health services, \nmarketing,  environmental  agencies  make  use  of  spatial \nmining  to  find  information  contained  within.  The  major \nchallenges  in  spatial  data  mining  are  that  the  spatial  data \nrepositories  are  tend  to  be  very  large  and  the  range  and \ndiversity  in  representing  the  spatial  and  non-spatial  data \nattributes in the same canvas. Though the above discussed \nclustering  algorithms  try  to  resolve  issues  like  scalability \nand complexity, it can be observed",
    "chunk_order_index": 12,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-102eff186e1caa963280987f37500530": {
    "tokens": 1200,
    "content": "major \nchallenges  in  spatial  data  mining  are  that  the  spatial  data \nrepositories  are  tend  to  be  very  large  and  the  range  and \ndiversity  in  representing  the  spatial  and  non-spatial  data \nattributes in the same canvas. Though the above discussed \nclustering  algorithms  try  to  resolve  issues  like  scalability \nand complexity, it can be observed that a perfect clustering \nalgorithm  which  comprehends  all  the  issues  with  the \ndataset is an idealistic notion. Current research progresses \non  more  dynamic,  adaptive  and  innovative  methods  that \ndecipher  meaningful  patterns  that  effectively  satisfy  the \nrequirements  of  dealing  huge  volumes  of  data  of  higher \n\n7 \n\n \n\fBindiya et.al/ Spatial Clustering Algorithms- An overview \n\ndimensionality,  insensitive  to  large  noises,  unaffected  by \nthe  order  of  input,  and  having  no  prior  knowledge  of  the \ndomain. \n\nREFERENCES \n1.  A.  Hinneburg  and  D.  A.  Keim.  (1998).  An  Efficient \nApproach to Clustering in Large Multimedia Databases \nwith  Noise.  International  Conference  on  Knowledge \nDiscovery and Data Mining, (pp. 58-65). \n\n2.  Ankerst,  Mihael,  Markus M.  Breunig,  Hans-Peter \nKriegel,  and  Jörg  Sander.  (1999).  OPTICS:  ordering \npoints to identify the clustering structure. SIGMOD Rec. \n28 , (pp. 49-60). \n\n3.  E.  Schikuta.  (1996).  Grid-Clustering:  An  Efficient \nHierarchical  Clustering  Method  for  Very  Large  Data \nSets.  Proceedings  of  the  13th  International  Conference \non Pattern Recognition, (pp. 101-105). \n\n4.  Erich  Schikuta  ,  Martin  Erhart.  (1997).  The  BANG-\nClustering \nSystem:  Grid-Based  Data  Analysis. \nProceedings  of  the  Second  International  Symposium  on \nAdvances  in  Intelligent  Data  Analysis,Reasoning  about \nData, (pp. 513-524). \n\n5.  Ester,  M.,  Frommelt,  A.,  Kriegel,  H.-P.,  and  Sander,  J. \n(1998).  Algorithms  for  characterization  and  trend \ndetection  in  spatial  databases.  Int.  Conf.  on  Knowledge \nDiscovery and Data Mining, (pp. 44-50). New York City, \nNY. \n\n9. \n\n6.  George  Karypis  ,  Eui-Hong  (Sam)  Han  ,  Vipin  Kumar. \n(1999).  Chameleon:  Hierarchical  Clustering  Using \nDynamic Modeling. Computer, 32, 68-75. \n\n,  Surojit  Chatterjee \n\n7.  Gholamhosein  Sheikholeslami \n\n, \nAidong  Zhang.  (2000).  WaveCluster:  a  wavelet-based \nclustering  approach  for  spatial  data  in  very  large \ndatabases.  The  VLDB  Journal  —  The  International \nJournal on Very Large Data Bases, 8(3-4), 289-304. \n8.  Güting,  R.  H.  (1994).  An  Introduction  to  Spatial \nIssue  on  Spatial \n\nDatabase  Systems.  VLDB:Special \nDatabase System, 3(4). \nJiawei  Han  ,  Yandong  Cai  ,  Nick  Cercone.  (1992  ). \nKnowledge  Discovery  in  Databases:  An  Attribute-\nOriented  Approach.  Proceedings \nthe  18th \nInternational Conference on Very Large Data Bases, (pp. \n547-559). \n10.  Jiyeon Choo, \n\nChun-\nsheng Chen,  Oner Ulvi Celepcikay,  Christian Giusti  and \nChristoph F. Eick.  (2007).  C.F.:  MOSAIC:  A  proximity \nclustering. \ngraph \nInternational  Conferenceon  Data  Warehousing  and \nKnowledge Discovery. Springer Berlin/Heidelberg. \n11.  Jörg  Sander  ,  Martin  Ester  ,  Hans-Peter  Kriegel  , \nXiaowei Xu. (1998). Density-Based Clustering in Spatial \nIts \nDatabases:  The  Algorithm  GDBSCAN \nApplications.  Data  Mining  and  Knowledge  Discovery, \n2(2), 169-194. \n\nRachsuda Jiamthapthaksin , \n\nagglomerative \n\napproach \n\nand \n\nfor \n\n12.  M. Ester,  H.-P.  Kriegel,  S. Jörg,  and  X. Xu.  (1996).  A \ndensity-based  algorithm  for  discovering  clusters  in \nlarge  spatial  databases  with  noise.  Proceedings  of  2nd \nInternational  Conference  on  Knowledge  Discovery  and \nData Mining",
    "chunk_order_index": 13,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-663581d1f4517f5c81108648d8871315": {
    "tokens": 1200,
    "content": "apthaksin , \n\nagglomerative \n\napproach \n\nand \n\nfor \n\n12.  M. Ester,  H.-P.  Kriegel,  S. Jörg,  and  X. Xu.  (1996).  A \ndensity-based  algorithm  for  discovering  clusters  in \nlarge  spatial  databases  with  noise.  Proceedings  of  2nd \nInternational  Conference  on  Knowledge  Discovery  and \nData Mining , (pp. 226-231). \n\n13.  M. Ester,  H.-P.  Kriegel,  S. Jörg,  and  X. Xu.  (1996).  A \ndensity-based  algorithm  for  discovering  clusters  in \n\nof \n\n8 \n\nlarge  spatial  databases  with  noise.  Proceedings  of  2nd \nInternational  Conference  on  Knowledge  Discovery  and \nData Mining (KDD-96), (pp. 226-231). \n\n, \n\n14.  Nanopoulos,  A.,  Theodoridis,  Y.,  and  Manolopoulos. \n(2001).  C  2  P:  Clustering  based  on  Closest  Pairs.  In \nProceedings  of  the  27th  international  Conference  on \nVery Large Data Bases , (pp. 331--340). \n\n15.  Ng,  Raymond  T.  and  Jiawei  Han.  (1994).  Efficient  and \nEffective  Clustering  Methods  for  Spatial  Data  Mining. \nProceedings  of  the  20th  International  Conference  on \nVery  Large  Data  Bases.  (pp.  144-155).  San  Francisco, \nCA: USA: Morgan Kaufmann Publishers Inc. \n\n16.  Rakesh  Agrawal \n\nJohannes  Gehrke \n\n,  Dimitrios \nGunopulos  ,  Prabhakar  Raghavan.  (1998).  Automatic \nsubspace  clustering  of  high  dimensional  data  for  data \nmining  applications.  Proceedings  of  the  1998  ACM \nSIGMOD  international  conference  on  Management  of \ndata, (pp. 94-105). Seattle, Washington, United States. \n17.  S.  Kim,  X.  Jin,  and  J.  Han.  (2008).  SpaRClus:  Spatial \nRelationship  Pattern-Based  Hierarchical  Clustering. \nSIAM  International  Conference  on  Data  Mining  -  SDM, \n(pp. 49-60). \n\n18.  Sudipto Guha , Rajeev Rastogi , Kyuseok Shim. (1998). \nCURE:  an  efficient  clustering  algorithm  for  large \ndatabases.  Proceedings  of  the  1998  ACM  SIGMOD \ninternational  conference  on  Management  of  data,  (pp. \n73-84). Seattle. \n\n19.  Sudipto  Guha,  Rajeev  Rastogi,  Kyuseok  Shim.  (1999). \nROCK:  A  Robust  Clustering  Algorithm  for  Categorical \ninternational \nAttributes.  Proceedings  of  the  15th \nConference  on  Data  Engineering  (pp.  512-521).  IEEE \nComputer Society . \n\n20.  Tian  Zhang  ,  Raghu  Ramakrishnan  ,  Miron  Livny. \n(1996). BIRCH: an efficient data clustering method for \nvery  large  databases.  Proceedings  of  the  1996  ACM \nSIGMOD  international  conference  on  Management  of \ndata, (pp. 103-114). Montreal, Canada. \n\n21.  Usama  Fayyad,  Gregory  Piatetsky-shapiro,Padhraic \nSmyth. (1996). Knowledge Discovery and Data Mining: \nTowards a Unifying Framework. \n\n22.  Wang,  X.,  Rostoker,  C.,  and  Hamilton,  H.  J.  (2004). \nDensity-based  spatial  clustering  in  the  presence  of \nobstacles  and  facilitators.  European  Conference  on \nPrinciples  and  Practice  of  Knowledge  Discovery  in \nDatabases  (pp.  446-458).  Pisa,  Italy:  J.  Boulicaut,  F. \nEsposito, F. Giannotti, and D. Pedreschi, Eds. \n\n23.  Wei  Wang  ,  Jiong  Yang  ,  Richard  R.  Muntz.  (1997). \nSTING:  A  Statistical  Information  Grid  Approach  to \nSpatial  Data  Mining.  Proceedings  of \nthe  23rd \nInternational Conference on Very Large Data Bases, (pp. \n186-195). \n\n24.  Wei Wang, Jiong Yang, Richard Muntz. (1999). STING+: \nAn Approach to Active Spatial Data Mining. Proceedings \nof \nInternational  Conference  on  Data \nEngineering, (pp. 116-125). \n\nthe  15th \n\n25.  Xiaowei  Xu  ,  Martin  Ester  ,  Hans-Peter  Kriegel  ,  Jörg \nSander. \nClustering \nAlgorithm  for  Mining  in  Large",
    "chunk_order_index": 14,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-fa44177f659677640817a86714cb7e0c": {
    "tokens": 141,
    "content": ", Jiong Yang, Richard Muntz. (1999). STING+: \nAn Approach to Active Spatial Data Mining. Proceedings \nof \nInternational  Conference  on  Data \nEngineering, (pp. 116-125). \n\nthe  15th \n\n25.  Xiaowei  Xu  ,  Martin  Ester  ,  Hans-Peter  Kriegel  ,  Jörg \nSander. \nClustering \nAlgorithm  for  Mining  in  Large  Spatial  Databases. \nProceedings  of  the  Fourteenth  International  Conference \non Data Engineering, (pp. 324-331). \n\nDistribution-Based \n\n(1998).",
    "chunk_order_index": 15,
    "full_doc_id": "doc-c82115e2a4dc2b5b601f4e491fd36341"
  },
  "chunk-d08d75eca8f82ab85da41f6e3bb9ce99": {
    "tokens": 1200,
    "content": "Background and Domain Experience\nThe expert interviewed has extensive experience in both academia and industry, with over a decade working on applied spatial analysis. Their work has spanned diverse domains, from institutional research in universities to large-scale ecological and environmental modeling in the private sector. Throughout this career, spatial clustering has been central, particularly as spatial statistics and data science evolved to address large, complex datasets. The expert has developed and deployed spatial clustering solutions for ecological land, coastal, marine, and benthic units, demonstrating the broad applicability of these methods to real-world scientific challenges.\n\nFoundational Perspectives on Spatial Clustering\nNature of Clustering:\nClustering is described fundamentally as a dimension reduction technique rather than a traditional statistical test. The process does not strictly require a statistical background for its application, yet familiarity with statistical concepts—especially related to distributional assumptions, variable scaling, and significance—substantially aids both data preparation and interpretation of results. Clustering methods are recognized as diverse, with approaches varying depending on the analysis goal and data structure.\n\nStatistical and Mathematical Foundations:\n\nUnderstanding data distributions is necessary, particularly the spread and shape of data for each variable to ensure fair representation in the clustering process.\n\nThe notion of multidimensionality is emphasized: clustering frequently occurs in high-dimensional spaces (sometimes with 10 or more variables), not just in geographic (2D) space.\n\nThe measurement of distance (e.g., Euclidean or alternative metrics) in high-dimensional attribute space is a core concern, and practitioners must be able to conceptualize the impact of distance calculations on cluster assignment.\n\nStandardization and normalization of variables are critical so that no single feature dominates the clustering output; the consequences of these transformations must be understood by analysts.\n\nData Engineering and Preparation:\n\nPreprocessing steps are essential: handling missing values, checking for reasonable ranges, and standardizing variables.\n\nData should be copied locally for efficient iterative analysis, especially when working with large remote datasets or online services.\n\nThe selection of input variables must be purposeful, aligning with the goal of the clustering (e.g., ecological meaning, resilience measurement, or accident pattern detection). Overly processed or composite index variables can obscure underlying structure and reduce the interpretability and usefulness of clustering.\n\nInterpreting and Evaluating Spatial Clustering Results\nCriteria for Success:\n\nClusters must be interpretable and meaningful in the context of the domain. For example, ecological clustering should distinguish between distinct biomes such as deserts, forests, and coastal regions; community resilience clustering should reflect real differences in vulnerability or adaptive capacity.\n\nThe “smell test” (informal but domain-informed plausibility check) is applied, where analysts compare the clustering output with their understanding of well-known areas. If deserts and rainforests are merged into a single cluster, the result is likely not meaningful.\n\nStatistical separability between clusters is assessed, often using parallel box plots to examine distributions of variables within each cluster.\n\nIt is important to distinguish statistically significant differences (which may be detectable with large sample sizes but are of little practical value) from practically significant differences (which correspond to real-world, actionable distinctions).\n\nDetermining the Number of Clusters:\n\nThe optimal number of clusters is often informed by domain knowledge—what does the expert expect, roughly, to find? This is not about precise counts but about being in the right order of magnitude (the “ballpark”).\n\nStatistical approaches are used in parallel: running clustering with a range of cluster counts (e.g., from 3 to 50), then using the pseudo F statistic or similar metrics to detect peaks, which suggest natural divisions in the data. These statistical signals are interpreted in the context of domain expectations and the granularity of analysis needed.\n\nVariable Importance and Cluster Drivers:\n\nUnderstanding which variables drive clustering is essential. Box plots are used to visualize the mean and spread of each variable in each cluster, looking for substantial separation.\n\nCanonical correlation analysis or other advanced multivariate techniques can reveal which attributes most influence cluster assignments, though such features may not always be available in standard GIS software and may require third-party tools.\n\nMulticollinearity is avoided—variables that are highly correlated or redundant are removed to ensure distinct axes of clustering.\n\nPractical Advice and Workflow\nGeneralized Workflow for Spatial Clustering:\nDefine the Analysis Objective:\nClearly articulate the question to be answered (e.g., finding homogeneous ecological regions, identifying community resilience profiles, or mapping traffic collision patterns).\n\nVariable Selection and Data Engineering:\n\nChoose relevant variables, avoiding composites or indices when possible.\n\nClean data: handle missing values, check ranges, standardize/normalize as needed.\n\nAssess and remove multicollinearity.\n\nPreliminary Data Exploration:\n\nVisualize each variable spatially and statistically to detect pre-existing spatial structure or outliers.\n\nPerform simple mapping (e.g., graduated color mapping) to identify possible clusters visually.\n\nChoose Clustering Method and Parameters:\n\nStart with common algorithms (e.g., K-means) and consider others as appropriate (e.g., K-medoids, DBSCAN for density-based clustering, spatially constrained clustering).\n\nSelect distance metrics and transformation methods based on data structure and analysis needs.\n\nIterative Clustering and Evaluation:\n\nRun clustering for a range of cluster numbers, evaluating each using both statistical indices and visual inspection.\n\nRerun clustering with different random seeds to ensure robustness and reproducibility.\n\nExamine the impact of parameter choices (distance metrics, initial seeds).\n\nInterpretation and Validation:\n\nAssess cluster interpretability: do clusters correspond to real-world, recognizable patterns?\n\nUse statistical plots and, where needed, advanced analyses to understand variable importance.\n\nRe-express results in original variable space for ease of interpretation.\n\nRefinement and Reporting:\n\nAdjust variable selection or clustering method as needed.\n\nDocument the rationale for choices made at each step.\n\nPresent results with clear visualizations and explanations.\n\nSpecial Considerations for Spatial Data\nFor spatial event data (e.g., traffic accidents), direct clustering may be limited by data sparsity or attribute incompleteness; enriching datasets with additional contextual variables (weather, road conditions,",
    "chunk_order_index": 0,
    "full_doc_id": "doc-ab69e57c241281b8d581edf43612d4de"
  },
  "chunk-1ec99e348c78d7e5246fc32666c03615": {
    "tokens": 777,
    "content": "needed, advanced analyses to understand variable importance.\n\nRe-express results in original variable space for ease of interpretation.\n\nRefinement and Reporting:\n\nAdjust variable selection or clustering method as needed.\n\nDocument the rationale for choices made at each step.\n\nPresent results with clear visualizations and explanations.\n\nSpecial Considerations for Spatial Data\nFor spatial event data (e.g., traffic accidents), direct clustering may be limited by data sparsity or attribute incompleteness; enriching datasets with additional contextual variables (weather, road conditions, temporal context) can improve clustering relevance.\n\nSpatial aggregation (e.g., creating hexagons or other areal units) can be used but risks loss of important granular information; trade-offs must be considered.\n\nSpatial constraints can be explicitly included in some clustering algorithms to ensure geographically contiguous clusters when this is meaningful for the problem at hand.\n\nLimits of Clustering and Alternatives\nNot all problems benefit from clustering. For datasets already extensively pre-processed into indices or for situations where no clear grouping is expected, simple visualization or descriptive statistics may be more appropriate.\n\nClustering should not be applied “by default”; its appropriateness must be judged based on the question, data, and desired outcome.\n\nSometimes density-based clustering (e.g., DBSCAN) or even non-clustering approaches (such as spatial smoothing or regression) may better answer the research question.\n\nExpert Expectations for AI Systems Supporting Spatial Clustering\nAn ideal AI-powered assistant for spatial clustering should:\n\nGuide users through the entire workflow, beginning with problem definition, appropriateness assessment, and method selection.\n\nAdvise on variable selection, data transformation, and the pros and cons of different clustering methods.\n\nAssist in detecting and handling data quality issues (missing values, outliers, redundancy).\n\nSuggest and help execute dimensionality reduction where appropriate, explaining implications for interpretability.\n\nProvide statistical and visual tools for evaluating clustering results, including guidance on choosing cluster numbers and assessing separation.\n\nHelp users interpret outputs, particularly in terms of variable importance and real-world meaning.\n\nSuggest alternatives (e.g., simple mapping or density analysis) if clustering is not appropriate for the data or question.\n\nEmphasize reproducibility by tracking parameter choices, random seeds, and analytical steps.\n\nPresent results in forms understandable to both technical and non-technical stakeholders.\n\nIllustrative Scenarios\nEcological Clustering: When clustering ecological regions, meaningful results separate distinct biomes. Variables such as temperature, precipitation, and land cover must be chosen to reflect the ecological processes at work, and results validated against known geography and expert knowledge.\n\nCommunity Resilience Profiling: If working with composite indices of resilience, careful scrutiny is required to determine if clustering adds value or simply re-labels already analyzed data. Clustering may be more useful when based on underlying demographic or socioeconomic variables.\n\nTraffic Collision Analysis: For spatial point events, additional enrichment and spatial aggregation may be needed. Clustering may reveal hotspots or recurring patterns, but over-aggregation can obscure causative factors.\n\nGeneral Best Practices and Recommendations\nAlways tie variable selection and cluster interpretation back to the domain question.\n\nUse clustering as an objective tool, but validate results with domain knowledge and real-world plausibility.\n\nBe wary of clustering on composite or already-indexed variables, as this often limits interpretability and practical insight.\n\nRecognize the iterative nature of clustering: expect to repeat steps, refine variables, and adjust cluster counts based on ongoing evaluation.\n\nStrive for parsimony: fewer, more informative variables lead to better, more interpretable clusters.\n\nDocument all decisions for transparency and reproducibility.\n\nSummary:\nEffective spatial clustering combines statistical and domain knowledge, purposeful data engineering, iterative evaluation, and critical interpretation. The process is as much about asking the right questions and understanding the data as it is about applying algorithms. AI systems built to support spatial analysis must facilitate the entire analytical workflow, offer meaningful guidance, and help users critically assess the value and limits of clustering approaches.",
    "chunk_order_index": 1,
    "full_doc_id": "doc-ab69e57c241281b8d581edf43612d4de"
  },
  "chunk-70bfc0431925259bbd8931208ae49238": {
    "tokens": 1200,
    "content": "J. R. Statist. Soc. B (1990)\n52, No.\n\nI, pp. 73-104\n\nSpatial Clustering for Inhomogeneous Populations\n\nBy JACK CUZICKt and ROBERT EDWARDS\n\nImperial Cancer Research Fund, London, UK\n\n[Read before the American Statistical Association at an Out-of-Town meeting of\nThe Royal Statistical Society in Washington DC on Monday, August Zth, 1989]\n\nSUMMARY\nA new method for detecting spatial clustering of events in populations with non-uniform\ndensity is proposed. The method is based on selecting controls from the population at risk\nand computing inter point distances for the combined sample. Nonparametric tests are\ndeveloped which are based on the number of cases among the k nearest neighbours of each\ncase and the number of cases nearer than the k nearest control. The performance of these\ntests is evaluated analytically and by simulation and the method is applied to a data set\non the locations of cases of childhood leukaemia and lymphoma in a defined geographical\narea. In particular the impact on power of the choice of k and of the ratio of cases to controls\nis examined. Modifications of the procedure to study distances from predefined objects,\nto match for known risk factors which would produce unwanted clustering and issues related\nto estimation are also discussed.\n\nKeywords: CLUSTERING; NEAREST NEIGHBOUR GRAPHS; POINT PROCESSES\n\nI.\n\nINTRODUCTION\n\nThe study of spatial aggregation or clustering has a long history in geography, ecology,\nastronomy and related subjects, and much of this material is collected and summarized\nin books (Cliff and Ord, 1981; Ripley, 1981; Unwin, 1981; Diggle, 1983) and discussion\npapers (Besag, 1974; Ripley, 1977). Methods for detecting clustering (or excessive\nregularity) can be grouped into three categories:\n\n(a) methods based on cell counts,\n(b)\n(c)\n\nadjacencies of cells with 'high' counts and\ndistance methods.\n\nAll these have disadvantages when examining evidence for localized spatial clustering\nof disease in human populations.\n\nThe basic cell count method is the quadrat procedure in which a square grid is\nplaced over a map of the region of interest and the number of events in each square\nis counted. The null hypothesis is that the points are a sample from a homogeneous\nPoisson process so that the cell counts are independent Poisson variates with a common\n(unknown) parameter. Departures from this can be measured by the index of dispersion\n(variance-to-mean ratio), a x2 test for heterogeneity of cell counts or tests based on\nthe empirical distribution function. In epidemiological applications the cells are not\narbitrary squares but usually are defined by pre-existing administrative boundaries and\ncomputation of the expected counts requires detailed knowledge of the population\naccording to age and sex in each cell and use of national or regional age- and sex \nspecific disease rates. Tests are again based on Poisson statistics but the parameters\n\nt Address for correspondence: Department of Mathematics, Statistics and Epidemiology, Imperial Cancer Research\n\nFund, PO Box 123, Lincoln's Inn Fields, London, WC2A 3PX, UK.\n\n© 1990 Royal Statistical Society\n\n0035-9246/90/52073\n\n$2.00\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f74\n\nCUZICK AND EDWARDS\n\n[No.1,\n\nare different for different cells so that tests based on the empirical distribution function\nmust be referred to a compound Poisson distribution. Recently Urquhart (Committee\non Medical Aspects of Radiation in the Environment, 1988) has developed an algorithm\nfor assembling small areas into regions of roughly constant expected numbers. Also\nOpenshaw et al. (1988) have considered a method of multiple overlapping circles in\nwhich observed and expected numbers are computed for circles with centres at every\npoint of a fine grid and for a variety of radii. This method seems difficult to evaluate\nanalytically.\n\nThe two main problems with these methods are the difficulty in obtaining accurate\nexpected cell counts on a grid sufficiently fine to be useful and in the definition of\nthe cell boundaries, which in many cases is attempted after the events have been\nrecorded. Furthermore, when expected numbers are much less than unity, a single\ncase will generate a significant result for that cell. Also, when cases are rare, failure\nto account for nearby cases in neighbouring cells represents a significant loss of power.\nAn allied approach which partly overcomes the last problem is to examine the\nadjacencies of cells with 'large' counts. Various ad hoc methods have been used to\ndefine such cells such as a significance level or",
    "chunk_order_index": 0,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-adac19d922c1c1404227fd94d862e679": {
    "tokens": 1200,
    "content": "the events have been\nrecorded. Furthermore, when expected numbers are much less than unity, a single\ncase will generate a significant result for that cell. Also, when cases are rare, failure\nto account for nearby cases in neighbouring cells represents a significant loss of power.\nAn allied approach which partly overcomes the last problem is to examine the\nadjacencies of cells with 'large' counts. Various ad hoc methods have been used to\ndefine such cells such as a significance level or an observed-to-expected ratio. Once\ndefined the cells can be analysed by the classical join count method of Moran (1948).\nOther statistics based on adjacencies have been suggested by Barnes et al. (1987).\nIn general distance methods are based on the distribution of distances between pairs\nof points, and usually only the distances to the nearest neighbour (NN) pairs are\nconsidered (Clark and Evans, 1955; Lewis, 1980). Tests based on the distance from\na randomly chosen co-ordinate to the nearest point have also been used (Ripley, 1981).\nThese techniques assume that, in the absence of clustering, points are uniformly\ndistributed in space (arise from a homogeneous Poisson process) and thus they are\nnot directly applicable to studies of disease patterns. Whittemore et al. (1987) have\nproposed a test based on the average difference between all pairs of cases that does\nallow for non-uniform population densities. Cases are first aggregated into cells to\ncompute expected numbers, however, so this is a hybrid between distance and\nadjacency methods.\n\nThese problems have limited the use of spatial clustering methods in disease studies\nand attention has been redirected towards methods for assessing space-time clustering\nin which 'coincidences in space' are correlated with 'coincidences in time'. Many\nmethods have been developed (pinkel and Nefzger, 1959; Knox, 1964a,b; Ederer et al.,\n1966; Barton and David, 1966;Mantel, 1967) and, although they are certainly useful for\ninfectious diseases with a short incubation period, Chen et al. (1984) have shown that\nthey have very low power against the type of clustering anticipated for cancer, infectious\ndiseases with long latency periods and other chronic diseases. Clustering methods\nbased on acquaintance networks have also been developed (Pike and Smith, 1974).\nIn this paper a new class of distance methods is proposed which does not require\nthe population to be uniformly distributed in the absence of clustering or its (age \nand sex-specific) density to be known in advance. Instead, a group of controls is selected\nfrom the population at risk and statistics are based on whether the NN(s) to each\ncase is another case or a control. The practical method chosen for selecting controls\nneeds careful consideration but they might be taken from electoral lists, census\ninformation or, if children are being studied, school records or birth notices. The\nimportant point is that the controls should be a representative sample of the entire\npopulation with the same age and sex distribution as the cases. The null hypothesis\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990)\n\nSPATIAL CLUSTERING\n\n75\n\nof no clustering then reduces to a statement that cases and controls are sampled at\nrandom from the same (age- and sex-adjusted) population.\n\nIn the next section a family of tests is described. The means, variances and asymptotic\ndistribution under the null hypothesis of no clustering are studied in Section 3. The\nfollowing section examines the tests' behaviour analytically under an idealized clustering\nmodel. Simulation results for a more realistic model, an example and some possible\nextensions are discussed in the remaining sections.\n\n2. TEST DESCRIPTION\n\nIn mathematical terms the null hypothesis of no clustering assumes that the location\nof cases of disease follows a non-homogeneous Poisson process whose intensity, the\nexpected disease density, is a function of the (age- and sex-specific) population density.\nIf this population density is known the expected disease density can be computed\nfrom national or regional age- and sex-specific rates of disease, but generally it is not\nknown or is difficult to compute on a local scale. The following procedure only requires\nthat we are able to take a sample from the population. Assume that no cases are\nobserved in some predefined region [} and denote their location by (XI, ... , xno)'\nPutting aside the question of age and sex adjustment for the moment, from all\nindividuals at risk in [} select at random a set of nl 'controls' and denote their location\nby (Yl, ... , Ynl)' Let (Zl, ... , Zn,",
    "chunk_order_index": 1,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-0853d7259e88ff73bbbcd098f057d99f": {
    "tokens": 1200,
    "content": "procedure only requires\nthat we are able to take a sample from the population. Assume that no cases are\nobserved in some predefined region [} and denote their location by (XI, ... , xno)'\nPutting aside the question of age and sex adjustment for the moment, from all\nindividuals at risk in [} select at random a set of nl 'controls' and denote their location\nby (Yl, ... , Ynl)' Let (Zl, ... , Zn, n = no+ nl) denote the locations of the points\nin the combined sample when the indices have been randomly permuted so that the\nz: contain no information about group membership. For i= 1, ... , n define\nO. = r1 if z, is a case\n\nlo if z. is a control\nand let Po = no/n be the percentage of cases in the combined sample. We consider\nthe following test statistics.\n\n(l)\n\nI\n\nFor each i, let\n\n2.1. Nearest Neighbour Test\n\nThe NN test is then given by\n\nI\n\nd.= r1 if the NN to z, is a case\n\nlo if the NN to z. is a control.\n\nn\n\nT= ~ s.a..\n\ni= I\n\n(2)\n\nFor the example shown in Fig. 1 and Table 1, we obtain T= 4.\n\n2.2.\n\nk Nearest Neighbours Test\n\nThis idea is readily extended to count for each case, the number of cases among\nits k NNs. Such a test might be expected to be more powerful than equation (2) when\nthere are relatively few but large clusters, as opposed to many smaller clusters.\nFor each point Zi, let df be the number of k NNs which are cases. The test statistic\n\nis then given by\n\nn\nTk= ~ oidf\ni=I\nwhich reduces to equation (2) when k = 1. For the example in Fig. 1 and k = 2, T2 = 8.\nIn this form Tk can be seen to be a sum of dependent hypergeometric variables.\n\n(3)\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f76\n\nCUZICK AND EDWARDS\n\n[No.1,\n\n8\n\n.~ .9\n./\n\nr\n\n.6\n\n14\n\n0 15\n\n.--\n/o~\"\n\n12\n\n2\n\n•\n\n\\\n\n/0 3\n\n0\n\n~05\n\n0\n4\n\n.11\n\n\\\n\n010\n\nFig. 1. Fictitious example illustrating the computation of quantities needed to compute Tk and Tt:\n• ~ cases; 0, controls\n\nTABLE 1\nQuantities needed to compute test statistics for the example illustrated in Fig. It\n\nPoint\n\nCase\nindicator,\n0;\n\nIndex of 7 NNs\n(nearest first)\n\nd,\n\nd Z\n\nI\n\nd r\n\nI\n\nZ\nvi\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n0\n1\n0\n0\n0\n1\n1\n1\n1\n0\n1\n0\n0\n1\n0\n\n3, 2, 4, 5, 6, 8, 7\n3, 8, I, 6, 7, 9, 4\n2, I, 6, 8, 4, 5, 7\n5, I, 3, 6, 2,11,7\n4, 6, 3, 11, 1, 7, 2\n7, 5, 3, 8, 9, 11, 2\n9,8,6,3,2,12,11\n7, 9, 6, 2, 3, 5, 1\n7,8,6,12, 14, 11,3\nII,",
    "chunk_order_index": 2,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-4a4df8f3472698b9384a4db41c55ffa7": {
    "tokens": 1200,
    "content": ", 2,11,7\n4, 6, 3, 11, 1, 7, 2\n7, 5, 3, 8, 9, 11, 2\n9,8,6,3,2,12,11\n7, 9, 6, 2, 3, 5, 1\n7,8,6,12, 14, 11,3\nII, 13, 12,5, 15, 14,6\n12, 10, 13, 6, 5, 7, 14\n11, 14, 13, 15,9,7, 6\n12, 15, 14, 11, 10, 9, 6\n15,12,13,9, 11,7,6\n14, 13, 12, 11, 9, 7, 10\n\n0\n0\n1\n0\n0\n1\n1\n1\n1\n1\n0\n1\n0\n0\n1\n\n1\n1\n1\n0\n1\n1\n2\n2\n2\n1\n0\n2\n0\n0\n1\n\n0\n0\n1\n0\n0\n1\n3\n4\n3\n1\n0\n2\n0\n0\n1\n\n1\n1\n3\n0\n1\n1\n4\n4\n5\n1\n0\n2\n0\n0\n1\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\ntT,=L:o;d;=4; N s=lO; N t=12; E(T])=3.0; var(T,)=2.26; z=0.67.\nTZ=L:0idT=8; N;=24; Nf=36; E(Tz)=6.0; var(Tz)=3.57; Z= 1.06.\nTrun = L:o;c( = 11; E( Trun ) = 4.67; var(Trun) = 10.49; Z= 1.96.\nT~nv = L:o j vT = 15; E( T~nv) = 9.34.\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990]\n\nSPATIAL CLUSTERING\n\n2.3. Run Length Test\n\nAnother possibility for detecting rare large clusters is\n\nn\n\nTrun = ~ oid [\n\ni= 1\n\n77\n\n(4)\n\nwhere d[ is the number of consecutive cases encountered beginning at z, and\nexamining successively distant points from z. and stopping when a control\nis\nencountered. For the example of Fig. 1, Tr un = 11.\n\n2.4.\n\nInverse Sampling k Nearest Neighbours\n\nAn extension of the run length test is to allow a fixed number of controls in the\nrun sequence. Here we would count the number of cases denoted \"f which are closer\nto the index case than the k nearest control and sum this over all cases to obtain a\nstatistic denoted\n\nFor the example of Fig. 1, T1 nv = 15.\n\n.\n\nn\nT/cnv = ~ oi\"f.\n\ni= 1\n\n2.5. General Rank-based Procedures\nThe previous procedures are all based on the sequence of zeros and ones determined\nfrom the case-control status of successive NNs to each case. More general procedures\nare imaginable and an adaption of Stone's (1988) approach, for example, might prove\nuseful.\n\n3. DISTRIBUTION UNDER NULL HYPOTHESIS\n\nTo compute the means and variances of the Tk a more elaborate notation is\nrequired. Let T/ i be the set of indices of the {ZjJ which are k NNs to z, and let aij = 1\nif j E T/ i and aij = 0 otherwise. Then equation (3) can be rewritten as\n\nt; = ~ ~ aijoiOj\nj\n\ni\n\n(5)\n\nwhere i and j range from 1, ... , n, and 0i is defined by equation (1). In this form\nTk can be seen to be a join count statistic (Moran, 1948; Cliff and Ord, 1981) except\nthat\nthe aij are not symmetric. This is easily overcome by replacing aij by\nHaij + aji) which does not affect Tk. However, certain new questions arise here\nbecause the investigator must choose k and the ratio Po= no/ n. Indeed much of the\nnovelty of the method stems from the decision to obtain controls initially. NN tests\nhave also been considered by Rogers (1976), Schilling (1986) and Henze (1988) in\nthe context of multivariate two-sample tests for independent observations. The tests\ncan also be viewed as measures of association between graphs. Some general work\nin the area can be found in Friedman and Rafsky (1983).\n\nWe now compute the moments of the permutational distribution of the Tk\nconditional on the locations of the {ZiJ. These could be obtained from Moran's (1948)\nformula (see Cliff and Ord (1981» by first symmetrizing the aij, but it is useful to\nderive them directly to see how the topological features of the graph defined by the\n\nl",
    "chunk_order_index": 3,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-34c41a08ec514e4fec91649bf4acf92a": {
    "tokens": 1200,
    "content": ". Some general work\nin the area can be found in Friedman and Rafsky (1983).\n\nWe now compute the moments of the permutational distribution of the Tk\nconditional on the locations of the {ZiJ. These could be obtained from Moran's (1948)\nformula (see Cliff and Ord (1981» by first symmetrizing the aij, but it is useful to\nderive them directly to see how the topological features of the graph defined by the\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f78\n\nCUZICK AND EDWARDS\n\n[No. I,\n\naij come into play. Because we condition on the k NN graph, the aij are non-random\nand we only need the permutational moments of the 0i. Since i I Tli, aii = 0, and for\ni =I},\n\nso that\n\nl ' j\n\nE(o.o.)= no(nO-l) =P,\n\nn n-l\n\nE(Tk) =p~ ~aij=pkn.\nj\n\ni\n\nFor higher moments define\n\nj no-I\nPj'=p(j)= II - - ,\n\n1=0 n-I\n\n(6)\n\nso thatpo=noln andPI=p as given before.\n\nTo compute the conditional variance, first compute\n\nE(T/() = ~ ~ ~ ~E(OiOjOIOm)aijalm.\n\nDefine\n\ni\n\nj im\n\nN s = ~ ~ aijaji\ni\nj\nas the number of ordered pairs for which the k NN relation is symmetric, i.e. } E n.\nand i ET'fj (note that each pair counts twice),\n\nNt = ~ ~ ~ aijalj\ni oF I\nas the number of ordered triples (i,), I), t.i. 1distinct, such that} E in and} E TIl (note\nthat N t = L,7j (7j -\nl ) where the in-degree 7j=L,iaij is the number of edges directed\ntowards zj, i.e. the number of points for which Zj is a k NN) and\n\nN u = ~ ~ ~ aija/i\nNI\nas the number of ordered triples (i,), I), i.I, 1 distinct, such that} ET'fi and i ET'f/. It\nis easily seen that N u = k 2n - N s .\n\nThen\n\nE(T/() = ~ Eo(cx)\n\nCiELl\n\nwhere zi is the set of all ordered four-tuples, cx = u.), I, m) and\n\nP I if cx has 2 distinct elements\nEo(cx) =E(OiOjOIOm)= P2 if cx has 3 distinct elements\nP3 if cx has 4 distinct elements.\n\n[\n\nWhen n ~ 3, we partition ..1 into the following disjoint sets:\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990]\n\nSPATIAL CLUSTERING\n\n79\n\n(a) a has two distinct elements-\n\n.1\" ={(i, i. i, J)}; 1.1\" I=kn\nL1I2={(i, i. j, I)};\nlL1d =Ns ;\n\n(b) a has three distinct elements-\n\n.121 = {(i, j, I, I)}; 1.1211 = N u\n.122 = {(i, j, I, J)}; 1.1221 =Nt\nL123={(i,j,\nL124={(i, j, j, m)}; 1.124\\ =Nu ;\n\ni, m)}; 1L1231=k(k-1)n\n\n(c) a has four distinct elements",
    "chunk_order_index": 4,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-3450550246919803c4dad642d2fcd914": {
    "tokens": 1200,
    "content": "(b) a has three distinct elements-\n\n.121 = {(i, j, I, I)}; 1.1211 = N u\n.122 = {(i, j, I, J)}; 1.1221 =Nt\nL123={(i,j,\nL124={(i, j, j, m)}; 1.124\\ =Nu ;\n\ni, m)}; 1L1231=k(k-1)n\n\n(c) a has four distinct elements-\n\n1.131 = 1.11- (k2n + Ns+Nt+ 2Nu ) = k 2(n 2 - 3n) +Ns-Nt .\n\nThus for n~3 we have E(Tf)=L:\\L1ijjpi so that\n\nvar(h) = (kn +Ns)PI (1- PI) +{(3k2 - k)n + N t-2Ns}(P2 - PI)\n\n-{k2(n 2-3n)+N\n\ns-Ntl(PI-P3).\n\nWhen no is large we obtain the asymptotic expression\n\nI\nno var(Tk)~ Po(1-po) l k+ n -Po k + n-n\n\n(2 N s\n\nN s\n\nI\n\nNt ) }\n\n(7)\n\n(8)\n\nwhere we have used PI - P3 ~ 4n - I Pb(1 - Po).\n\nFor data analysis, the observed values of N, and N, should be used in computing\nconditional moments. However, for design it is useful\nto have an idea of their\nasymptotic values. The ratios Ni /n and N, In will in general depend on the form of\nthe intensity process, although the work of Clark and Evans (1955) suggests that the\ndependence is fairly weak. When k = 1 and the underlying process is uniform\n\nN sln--+67r/(87r + 3312) ~ 0.6215\n(Clark and Evans, 1955) and Ntln--+E{T/Tj-1)}~0.633.For k= 1 the asymptotic\ndistribution of Tj in the uniform case as n--+ 00 is given in Table 2 and is based on\ncalculations outlined in Appendix A. It follows that\n\nno I var(TI )--+Po(1- Po)(1.622 - 0.988po).\n\nTABLE 2\nDistribution of the in-degree T for a uniform distribution on the entire plane, and k = 1\n\nm\n\nPr(T=m)\n\nStandard error of estimate\n\nClark and Evans simulation\n\n0\n1\n2\n3\n4\n5\n6 or more\n\n0.284\n0.463\n0.221\n3.04xlO- 2\n6.56xlO- 4\n1.90 x 10- 7\n0.0\n\n0.881 x 10- 4\n0.177xlO- 3\n0.102x 10- 3\n0.283 X 10- 4\n0.261 X 10- 5\n0.157x 10- 7\n0.0\n\n0.297\n0.453\n0.225\n0.D25\n0.000\n0.000\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f80\n\nCUZICK AND EDWARDS\n\n[No.1,\n\nFor some purposes it is useful\n\nto consider linear combinations of the Ti: To\ncompute the variance of these tests, the covariance between different TkS is needed.\nLet aij(k) be unity if } is a k NN of i and zero otherwise and let\n\nNs(k, I) = ~ ~ aij(k) aji(l)\nNt(k, I) = ~ ~ ~ aij(k) amj(l).\ni e m\n\nThen by calculations similar to those for computing the variance of the Tk we find\nthat for k s; 1\ncov(Tk> Tt) ={kn + Ns(k, l)Jpl (1- PI> + {(3kl- k)n +Nt(k, I) - 2Ns(k,\n-{k/(n2-3n) + Ns(k, I)-Nt(k, l)J(PI-P3)\n\nl)J(P2 - PI)\n\n(9)\n\nand for no large the following approximation holds:\n\n-I\n\nno cov\n\n(T T)\nI\nk »\n\n(1\n\n=:::. Po\n\n- Po\n\n) lk Ns(k, I)\n\n+\n\n- Po\n\n+\n\n[kl Ns(k, I) Nt(k, I)] ]\n\n-\n\n.\n\nn\n\nn\nthe limiting values of Ns(k,\n\nn\n\nWhen the",
    "chunk_order_index": 5,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-5a16fe5c625d02aae7a15530f8a494df": {
    "tokens": 1200,
    "content": "(k, I)-Nt(k, l)J(PI-P3)\n\nl)J(P2 - PI)\n\n(9)\n\nand for no large the following approximation holds:\n\n-I\n\nno cov\n\n(T T)\nI\nk »\n\n(1\n\n=:::. Po\n\n- Po\n\n) lk Ns(k, I)\n\n+\n\n- Po\n\n+\n\n[kl Ns(k, I) Nt(k, I)] ]\n\n-\n\n.\n\nn\n\nn\nthe limiting values of Ns(k,\n\nn\n\nWhen the intensity process is uniform,\nI)/n and\nNt(k, I)/n are derived in Appendixes Band C and values for k = 1= 1, ... , 10 are\ngiven in Table 3. The arguments of Henze (1988) can be used to show that the same\nasymptotic results hold for non-uniform but smooth intensity processes.\n\nAsymptotic normality of the joint distribution of any finite set of Tk is established\nunder the null hypothesis in Appendix D. This result relies on a bound for the 7j\nfor any k. When k= 1 Clark and Evans (1955) showed that 7j~6 and their approach\ncan be used to show that 7j ~ 6k for any k.\n\nTo see this consider all points ZI, ... , Zm for which an arbitrary point Zo sited\nat the origin is a k NN, and set ri = II z,II, i = 1, . . ., m. Let WI be the Zi with the largest\nri and let R I be this radius. Delete all other z, in the sphere S(WI, RI> and of the\nremaining z, let W2 be the one with the largest ri and denote this radius by R2. Delete\nall other z, in S(W2, R2)' Continue the process until all the z, have been used. Since\nR I > R2 ... , Wi q: S(Wj, Rj) for i <i so no previous Wi is ever deleted. The argument\nof Clark and Evans can then be used to show that the process stops after at most six\ncycles. Since Zo is a k NN to each Wi, each circle contains at most k points (including\nthe centre) so that the total number of points is less than or equal to 6k. This bound\ncan no doubt be improved but 7j = 4k is achievable as can be seen by considering\nthe graph with points at the origin and at (0, ± 3m ) , (± 3m , 0), m = 0, 1, 2, ....\n\nTABLE 3\nComputation of limiting values of Ns/n and Nr/n for a uniform\ndistribution on the entire planet\n\nk\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\nlim Ns(k, k)/n\n\nlim Ndk, kt/n\n\n0.6215\n1.4211\n2.2731\n3.1503\n4.0431\n4.9468\n5.8585\n6.7766\n7.6998\n8.6273\n\n0.6332\n3.1737\n7.6969\n14.2159\n22.7335\n33.2505\n45.7671\n60.2835\n76.7997\n95.3158\n\ntSee Appendixes Band C.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990]\n\nSPATIAL CLUSTERING\n\n81\n\nTo check the adequacy of the normal approximation third and fourth moments\nof Tk can be computed. This can be achieved by first symmetrizing the aij and using\nthe formulae in Cliff and Ord (1981), pp. 40-41. These forms are not enlightening\nand are not repeated here.\n\nIt is of interest to consider the limiting case when the expected disease density is\nknown exactly. This corresponds to the situation in which the control-case ratio tends\nto infinity. Thus PI tends to zero and to normalize we choose k tending to infinity\nso that PI k remains constant. If A(Z) denotes the expected disease density and no is\nthe total number of observed cases, the analogue of the statistic Tk is obtained as\nfollows. For each case i choose a circle Sj=S(rj, Zj) of radius r., centred at zi, such\nthat the expected number of cases within the circle is k, given that the total number\nof cases is no, i.e. choose r, so that fJ-(S(rj, Zj» = k where for any set B\n\nfJ-(B)=no1 A(z)dz/ 1A",
    "chunk_order_index": 6,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-c0a461bb4852bd19c1e0a11343aa2198": {
    "tokens": 1200,
    "content": "of the statistic Tk is obtained as\nfollows. For each case i choose a circle Sj=S(rj, Zj) of radius r., centred at zi, such\nthat the expected number of cases within the circle is k, given that the total number\nof cases is no, i.e. choose r, so that fJ-(S(rj, Zj» = k where for any set B\n\nfJ-(B)=no1 A(z)dz/ 1A(z)dz.\n\nB\n\n[}\n\nNow let 0; be the observed number of cases within S; and define the one-sample\n\nversion of Tk as\n\nno\nUk= ~ (OJ-k)\n\ni=1\nwhere i indexes cases only. The test Uk is also the natural one-sample limit for Tlny\nIt follows easily that E(Uk)=O and\n\nvar(Uk) = 11 {fJ-(S} n S2)-fJ-(S}) fJ-(S2)}A(Z}) A(Z2) dzj dZ2·\n\n.\n\nAsymptotic normality follows from writing\n\nUk =i~ ~{lIZi-Zjl < r(Zi) + IIZi-Zjl < r(Zj)} - nok,\n\nit-j\n\nwhere r(Zj) = rt is a random variable depending only on zi, and from use of standard\nresults on U-statistics (Hoeffding, 1948). Higher order corrections are given by Bickel\net al. (1986). For the runs test\n\nno- I\n\nno- I\n\nE(Trun)=n ~ Pr(dr~J) Pr(oj=1)=n ~ Pj\n\nj=1\n\nj=1\n\n=no(no-1)/(n} + 1)\n\nwhere Pj is defined in equation (6). (The last equality can be proven by induction\non no; see Matuszewski (1962).) Also\n\nvar(Tru n ) = ~ ~ ~ ~p(1 + k+ 1- nil) - PkPI\n\ni\n\nj\n\nk\n\nI\n\nwhere nil is the number of common points among the k NNs to Zj and 1 NNs to Zj\nincluding Zj and Zj ..\n\nMore generally Tkny is the sum of (correlated) negative hypergeometric variables\n\n(Johnson and Kotz, 1969) and similar arguments give\n\nny)\n\nE(Tl\n\n= kno(no - 1)/(n} + 1).\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\fCUZICK AND EDWARDS\n\n82\n[No.1,\nThe permutational variance of T1nv becomes unwieldy for k > 1 and is more easily\nsimulated.\nWeare unable to establish asymptotic normality for the Jinv, but this seems likely.\nIf true, a larger n will be needed before this becomes an effective approximation.\n\n4. POWER AGAINST ALTERNATIVE CLUSTERED MODELS\n\nSchilling (1986) and Henze (1988) have shown that k NN tests are n l 12 consistent\nwhen cases and controls are independent samples from different distributions. Here\nwe are interested in alternatives more of the form of a Neyman cluster process for\nwhich these results are not applicable. If we consider a process on the unit square,\nthe appropriate normalization of the cluster dispersion distribution is Op(n - 1/2) as\nthe number of cases tends to infinity. We have not been able to show consistency\nagainst such alternatives in general, but we focus on specific examples.\n\n4.1. Analytical Results for Idealized Alternative\nTo compare the efficacy of tests Tk with various values of k and various\nproportions 1 - Po of controls, it is necessary to prescribe an alternative model in\nwhich clustering takes place. To obtain some analytical results we consider the following\nidealized model: cases and controls are chosen independently with a uniform density\nover a sufficiently smooth region so that boundary effects can be ignored. A small\nproportion q of the cases is then chosen at random and each is replaced with m cases\nsited so close to each other that each point has the remaining m - 1 points as its m - 1\nNNs. To keep the total number of cases fixed, noq(m - 1) of the remaining cases are\nrandomly deleted. We shall be interested in small q and large no and will use a\nstandard measure of test efficacy, i.e.\n\ne(Tk)= lim no l ~ /var(Tdl\n(\n\nn--+oo\n\nGE T )2\nuq\n\n.\n\nq=O\n\nThe value of no I var(Tk) is given in terms of Ns/n and",
    "chunk_order_index": 7,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-49ee9aaa13cbbf8fe32a9a624e1a6800": {
    "tokens": 1200,
    "content": "NNs. To keep the total number of cases fixed, noq(m - 1) of the remaining cases are\nrandomly deleted. We shall be interested in small q and large no and will use a\nstandard measure of test efficacy, i.e.\n\ne(Tk)= lim no l ~ /var(Tdl\n(\n\nn--+oo\n\nGE T )2\nuq\n\n.\n\nq=O\n\nThe value of no I var(Tk) is given in terms of Ns/n and Ns /n in expression (8) and\nthe asymptotic values of these ratios are calculated in Appendixes Band C and\nTable 3 for a uniform distribution. To evaluate E(Tk), call a case which has been\nreplaced by a cluster a special case. Then for k s; m - 1 by considering separately\n\n(a) the special cases,\n(b) the non-special cases for which one of the j NNs is a special case and\n(c) the non-special cases for which the jth NN is a non-special case and all j - 1\n\nNNs are controls or non-special cases, j = 1, ... , k\n\nwe find that for no large\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\nE(Td = kmqnn\n\nk\n\nk\n\n+no(1-mq)lj~/POq+ j~l pot I-mq+(m-l)poq}[I-U-l)POq]l +O(q2)\n\n=no [Pok + qk{m(1- po)2 + ~Po(1- Po)(k + I)J] + O(q2).\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990]\n\nSPATIAL CLUSTERING\n\n83\n\nFor k~m we must also split parts (b) and (c) according to whether j~m-1 or\n\nm ~j ~ k, to obtain\n\nE(Tk) = mqnoitm -1) + (k- m + 1)po}\n\n+ no(1- mq)[ :~>POq+po[1- mq+ (m -1)POq} [1- (j -l)POq}\n+ jtm mpoq+Po[1- mq+ (m -l)POq} [1- (m -1)POq}] + O(q2)\n\n= no{pok+qm(m -1)(1- Po)(1-1Po)} + O(q2)\n\nso that in general we obtain\n\n_1 aE(Tk) I\nBq\nno\n\n= [km(1-po)2+1P0(1-PO)k(k+ 1),\n\nq=o m(m-1)(1-po)(1-1PO),\n\nk~m-1,\n\n(10)\n\nk~m.\n\nUsing equations (8) and (10), for the NN test (k= 1), we obtain the efficacy as\n\ne(T)= 1-po{m(1-po)+Po}2 .\n\nPo\n\n1.622-0.988po\n\nThe efficacy for more general k can be obtained similarly and representative values\nof e(Tk) are computed in Table 4. In general the efficacy increases with decreasing\nPo, indicating that more information can be obtained from a fixed number of cases\nif more controls are taken. The increase appears very rapid when Po is near zero,\nbut its validity is limited in this region for two reasons. Firstly, when P6n remains\nbounded as n- 00, Tk has a Poisson limit and the efficacy calculated is not valid as\n\nTABLE 4\nEfficacy of Tk for various values of k, m and Po for the idealized model of Section 4.1t\n\nm\n\nPo\n\n2\n\n4\n\n8\n\n16\n\n1\nT\n1\nT\nI\nT\nI\nT\n1\nT\n1\nT\nI\nT\nI\nT\nI\nT\nI\nT\nI\nT\nI\nT\n\nJ\n\n2.0\n4.3\n9.1\n\n5.5\n13.9\n32.5\n\n18.0\n49.7\n122.4\n\n64.1\n187.3\n474.8\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\nk\n\n1.0\n2.1\n4.4\n\n13.2\n30.0\n66.0\n\n39.3\n101.9\n241.7\n\n133.3\n373.3\n924.0\n\n0.6\n1.4\n2.8\n\n23.2\n49.0\n102.4\n\n64.6\n158.8\n365.2\n\n209.2\n566.5\n137",
    "chunk_order_index": 8,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-19ea8a647b20c20a960e2612429ebd98": {
    "tokens": 1200,
    "content": "7\n\n8\n\nk\n\n1.0\n2.1\n4.4\n\n13.2\n30.0\n66.0\n\n39.3\n101.9\n241.7\n\n133.3\n373.3\n924.0\n\n0.6\n1.4\n2.8\n\n23.2\n49.0\n102.4\n\n64.6\n158.8\n365.2\n\n209.2\n566.5\n1376.2\n\n0.5\n1.0\n2.1\n\n17.3\n36.3\n75.7\n\n94.2\n221.0\n494.4\n\n292.3\n768.7\n1836.8\n\n0.4\n0.8\nI.7\n\n13.8\n28.8\n60.0\n\n128.4\n289.0\n629.7\n\n383.2\n980.6\n2307.6\n\n0.3\n0.7\n1.4\n\n11.4\n23.9\n50.0\n\n167.7\n362.9\n771.6\n\n482.1\n1202.9\n2789.7\n\n0.3\n0.6\n1.2\n\n9.7\n20.3\n42.3\n\n212.2\n443.2\n920.3\n\n589.5\n1435.9\n3283.6\n\n0.2\n0.5\n1.0\n\n8.5\n17.7\n36.8\n\n185.1\n386.2\n801.4\n\n705.6\n1679.9\n3789.9\n\ntNumbers refer to e(Tk ) for Po values of t t and ~ corresponding to I. 2 and 4 controls per case\n\nrespecti vely,\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\fCUZICK AND EDWARDS\n\n[No.1,\n84\nit assumes Po fixed and n large. Secondly the very tight clustering assumed for the\nalternative model becomes less realistic for a large number of controls per case because\nthe NNs of clustered special cases are less likely to be other members of the cluster.\nIn practice little is gained by taking Po<L corresponding to more than four\ncontrols per case unless the number of cases is quite small.\n\n4.2. Monte Carlo Results for More Realistic Model\nWe consider the following model over the unit square. Cases and controls are chosen\nindependently from a uniform distribution. A small proportion q of cases is then\nsampled, and each of these is replaced with m cases chosen from a bivariate Gaussian\ndistribution with mean at the location of the case, independent co-ordinates and\nvariance a2 . Finally of the remaining cases noq(m - 1) are then deleted at random\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\npower\n\n0.0\n\n0.02 0.04\n\n0.06 0.08\n\n0.10\n\n0.12 0.14\n\n0.16 0.18\n\n0.20\n\n0.22\n\n0.24\n\nq\n\nFig. 2. Power of T 1 as a function of q for various values of a 2: no = 50; Po =i; m = 2\n\npower\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n0.0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\nq\n\nFig. 3. Power of T} as a function of q for various values of a 2: no = 50; Po =i; m = 4\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1",
    "chunk_order_index": 9,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-b860ce69ed428a35fbf4db771a6a62dc": {
    "tokens": 1200,
    "content": "i\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990]\n\nSPATIAL CLUSTERING\n\n85\n\nto keep the total number of cases fixed. The values of m and q are restricted so that\nmq < 1. The case a2 = 0 corresponds to the idealized model of the previous subsection.\nPoints lying outside the unit square are projected back on to the boundary. Power\ncurves for Tk for certain values of k, m, q, a2 and for different numbers of controls\nwhen 50 cases are available are given in Figs 2-5. Each point is based on 1000\nsimulations, except that the null distribution is based on 10000 simulations. Fig. 2\nexamines the loss of power for TI, as a 2 increases with one control per case and\nm=2. Very little power is lost when a2~0.0001, but a great deal is lost for a2~0.001.\nA similar conclusion can be drawn from Fig. 3 for T3 when m = 4, although the loss\nof power is less abrupt and is not severe at a 2 = 0.001 but becomes so when a2 =0.01.\nFig. 4 examines the power of Tk, k=I, ... , 4, Trun and J1nv' for m=4, a2=0.001\nand one control per case. T3 and T4 have almost identical characteristics and both\nare better than T 1 or T2. The superiority of T3 over T4 observed when a 2= 0 is no\n\n1.0\n\n0.8\n\n... 0.6\n\n;\n&. 0.4\n\n0.2\n\nT,\n\n_\n\nTz - -\n•••••••••••••\nT,\nT.\n_\nT ....\n\n_\n\nTz\"' -\n\n' ' ' -\n\n0.0 L -__---:~---~~---:_\".:~--__:_~---':\"\":\":~--__:_~\n0.12\nq\n\n0.16\n\n0.24\n\n0.08\n\n0.20\n\n0.04\n\nFig. 4. Power of T\" T2 , T3 , T4 , Trun and T1nv as a function of q: no= 50; Po= i; m = 4;\n0- 2 = 0 .001\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\n...\n\nGI\n~\n0\nQ,\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n1 Control per case\n\n2 Controls per case\n\n4 Controls per case\n\n6 Controls per case\n\n0.02\n\n0.04\n\n0.06\n\n0.08\n\n0.10\n\n0.12\n\n0.14\n\n0.16\n\n0.18\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\nq\nFig. 5. Power of T3 as a function of q for various numbers of controls: no= 50; Po= L m = 4;\n2 = 0.001\n\n0\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f86\n\nCUZICK AND EDWARDS\n\n[No.1,\n\nlonger apparent. Trun is seen to be most powerful when clusters are rare (q small)\nbut loses efficiency as they become more common. D.nv is always less powerful than\nT3, T4 or Trun . Fig. 5 examines the power of T3 as a function of number of controls\nper case, confirming the value of up to four controls per case when a 2 = 0.001.\n\n4.3. Results for Real Data\n\nThe following example was kindly supplied by Dr Ray Cartwright and Dr Freda\nAlexander and is part of a large study of clustering of leukaemia and lymphoma\nthroughout a large part of England and Wales. The data consist of 62 cases of\nchildhood leukaemia and lymphoma diagnosed in North Humberside between 1974\nand 1986 (Fig. 6). 141 controls were selected at random from entries on the birth\nregister for January 7th or June 7th for each of the years 1974-",
    "chunk_order_index": 10,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-6cd9adacb1e0ce45031b2aef0979c45f": {
    "tokens": 1200,
    "content": "Freda\nAlexander and is part of a large study of clustering of leukaemia and lymphoma\nthroughout a large part of England and Wales. The data consist of 62 cases of\nchildhood leukaemia and lymphoma diagnosed in North Humberside between 1974\nand 1986 (Fig. 6). 141 controls were selected at random from entries on the birth\nregister for January 7th or June 7th for each of the years 1974-86. Centroids of postal\ncodes of home addresses were used to obtain grid references for mapping. The values\nof Tko their means and variances under the null hypothesis, normalized deviates and\napproximate P values are given in Table 5 for k = 1, ... , 10. Simulated significance\nlevels based on 1000 simulations are also given. The agreement between simulated\nand asymptotically estimated significance levels is adequate.\n\nThis example highlights the importance of choosing the correct value of k. For\nthis case a value of k near 3, corresponding to a cluster of about size 4, appears to\ngive the most significant results. This information is very useful from a descriptive\npoint of view but formal significance testing requires either foreknowledge of the\nbest k or some adjustment for multiple testing. Experience with further data sets may\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\nFig. 6. Distribution of 62 cases of childhood leukaemia and lymphoma diagnosed between 1974 and\n1986 in the North Humberside area\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990]\n\nSPATIAL CLUSTERING\n\n87\n\nTABLE 5\nCalculation oj Ti, k=l, . . ., 10, Trun , T1nv and Tcom b jor the leukaemia and lymphoma data\nshown in Fig. 6\n\nTest\n\nObserved\nvalue\n\nExpected\nvalue\n\nVariance\n\nNominal z\n\nNominal\nP value\n\nMonte Carlo\nP value\n\nT1\nT2\nT3\nT4\nr,\nT6\nT7\nTg\nTg\nT IO\nT, un\nT inv\n2\nTcomb+\n\n25\n53\n77\n96\n115\n128\n144\n160\n177\n194\n40\n83.5\n22.19\n\n18.7\n37.4\n56.2\n74.9\n93.6\n112.3\n131.1\n149.8\n168.5\n187.2\n26.6\n53.27\n17.85\n\n17.45\n35.56\n53.97\n73.43\n92.53\n111.85\n132.33\n154.29\n179.20\n204.32\n72.1\n138.6t\n4.0\n\n1.51\n2.62\n2.83\n2.46\n2.22\n1.48\n1.12\n0.82\n0.63\n0.48\n1.58\n2.57\n2.17\n\n0.066\n0.004\n0.002\n0.007\n0.013\n0.07\n0.13\n0.21\n0.26\n0.32\n0.06\n0.005\n0.015\n\n0.055\n0.006\n0.003\n0.007\n0.009\n0.055\n0.12\n0.20\n0.26\n0.31\n0.07\n0.013\n0.024\n\n[Simulated variance.\n+Test specified in equation (II) with k taking values I, 2, 4 and 8.\n\ngive an idea of which value of k is likely to be best. In the absence of this knowledge\na method for combining the information from different TkS is needed. If we assume\nthat the h are multivariate normal and compute the score test for the alternative\nthat the means of the Tk are a mixture of shifts all in the same direction then we\nfind that a linear combination of the TkS should be used. If the mixing distribution\ngives equal weight to alternatives in which one Tk has its mean shifted by an amount\na var- 1I2(Tk) and the others are unchanged then we arrive at a statistic of the form\n\nTcomb = 1' 17\n\n-1/2\n\nT\n\n(11)\n\n) , for some subset of size m of the Tb 17=COV(TkI' . . . ,\n) , which can be computed from equation (9), and l' =(1, ... , 1). It is easily\n\nwhere T=(TkI' . . . , Tkm\nTkm\nseen that under the null hypothesis",
    "chunk_order_index": 11,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-ee8a02ad764181c9a883b9c030669dd7": {
    "tokens": 1200,
    "content": "then we arrive at a statistic of the form\n\nTcomb = 1' 17\n\n-1/2\n\nT\n\n(11)\n\n) , for some subset of size m of the Tb 17=COV(TkI' . . . ,\n) , which can be computed from equation (9), and l' =(1, ... , 1). It is easily\n\nwhere T=(TkI' . . . , Tkm\nTkm\nseen that under the null hypothesis\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\nE(Tcomb) = np, ~ ~j7jk\n\nk\nvar(Tcomb) = m,\n\nj\n\nwhere tjk are the elements of the matrix 17- 112 , and that\n\n[Tcomb - E(Tcomb)]lvarIl2 (Tcomb)\nis asymptotically standard normal. This approach to combining statistics is similar\nto that used by O'Brien (1984). The performance of T comb with k taking values of\n1, 2, 4 and 8 for this data set is shown in Table 5.\n\n5. EXTENSIONS OF METHOD\n\n5.1.\n\nTies\n\nIn some cases it is not possible to compute exact grid references of cases and controls\nbut they can be placed into an element of a fine partition of cells. The centroid of\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f88\n\nCUZICK AND EDWARDS\n\n[No.1,\n\nthe cell is then a reasonable surrogate for the location of the event, but ties may now\noccur. Ties are only relevant if they make it uncertain whether a case is a k NN of\nanother case. In this case the aij values are no longer always zero or unity but should\nreflect the probability that a point is a k NN to some other point. For example if\nk = 4 and the third, fourth and fifth NNs are tied then aij= ~. Correction to the\nvariance is unlikely to be necessary unless ties are very common but can be\naccomplished by treating the (aij), after symmetrization, as a general weight matrix\nas in Cliff and Ord (1981).\n\n5.2. Clustering around Specified Point Sources or Features\nThis paper has dealt exclusively with testing for clustering of the case points among\nthemselves. The ideas are easily adapted to clustering around prespecified point sources\n(such as nuclear power-stations) or other more complicated shapes such as river\nestuaries, high voltage power lines or main highways. In this instance, the features\nare specified in advance and distances are measured from cases and controls to the\nnearest feature. A simple approach is then to look at the number of cases among\nthe k nearest distances, where here k is fairly large, e.g. some small proportion a,\nsay 5OJo or 10%, of the total sample size. Tests using weight functions, based either\non distances or their ranks, could also be used.\n\nAn attractive approach is given by Stone (1988) who suggested the statistic (with\n\nKo= 1)\n\nmax\nKo,,;;.k,,;;.Kl\n\nk\n\nk :' ~ s,\n\ni=l\n\nwhere the 0i are ordered by increasing distance from the source.\n\n5.3. Adjustment for Covariates\nIn some circumstances clustering will occur because known differences in risk have\nspatial structure. A simple example is the relation of chronic diseases such as cancer\nwith age. It is known that older people are not distributed with the same spatial\ndistribution as the rest of the population. In other instances a disease may be known\nto be more common in rural than in urban areas, again leading to a predictable type\nof clustering if the reference area contains both types of region. A solution to this\nlies in choosing the control sample to reflect all known factors that would lead to\nuninteresting clustering. This is a matching exercise which can be carried out either\nby stratification of the cases and population from which the control sample is taken\nor by matching one or more controls to each case. When the population gradients\nbetween different strata are not too dissimilar it is probably adequate to ignore the\nmatching when computing and normalizing Tk or Ii.nv. However, when they are large\nthe mean and variance will be affected. When each case has the same number of\nindividually matched controls, a simple procedure is to omit all its matched controls\nwhen determining the k NNs of a case. Then under the null hypothesis all other points\nare equally likely to be a case and asymptotic normality can be established with minor\nmodifications to the mean and variance.\n\nWhen the cases are coarsely stratified the same procedure could be applied, but a loss\nof power is likely to be due to failure to detect intrastr",
    "chunk_order_index": 12,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-0eb5fdd02ac3e86fc620545170a2240a": {
    "tokens": 1200,
    "content": "number of\nindividually matched controls, a simple procedure is to omit all its matched controls\nwhen determining the k NNs of a case. Then under the null hypothesis all other points\nare equally likely to be a case and asymptotic normality can be established with minor\nmodifications to the mean and variance.\n\nWhen the cases are coarsely stratified the same procedure could be applied, but a loss\nof power is likely to be due to failure to detect intrastratum clustering. Alternatively\nthe clustering statistic could be computed separately for each stratum and then\ncombined, but then interstratum clustering would not be detected. A possible\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990]\n\nSPATIAL CLUSTERING\n\n89\n\ncompromise is to choose k NNs and to compute the statistic as usual, but when\ncomputing means and variances to determine the number of points in each k\nneighbourhood that are from each stratum and to adjust accordingly. For example,\nif z, lies in stratum},}= 1, ... , J, (nj, nOj) denote the total number of points and\nnumber of cases respectively in stratum}, and YJij is the number of points in the k\nneighbourhood of z, which belong to stratum} (excluding z; itself), then, under a\npermutational distribution of cases in each stratum,\n\nwhere Sj is the set of indices of {zil in stratum}. A similar correction can be computed\nfor the variance.\n\nMore work is needed to determine how sensitive these statistics are to this sort of\n\nheterogeneity and which matching procedure is most efficient.\n\n5.4. Estimation\nEstimation is an area requiring more work. Clustering models comprise three main\n\nfeatures:\n\n(a) the frequency of clusters,\n(b) the size (possibly random) of individual clusters and\n(c) the probability that two points in the same cluster are NNs.\n\nReliable estimates of all three components of such a model are unlikely unless the\ndata set is very large. A more realistic goal might be to try to estimate a parameter\nreflecting the 'proportion of cases due to clustering', but even this is not without\ndifficulties. Consider a model in which a proportion 71\"0 of the cases come from a\ncluster (of size at least 2) and that for such cases the probability that the NN (among\nall other cases and controls) is from the same cluster is 71\"1. Under this model one\nhas approximately that\n\nE(T)::= no 71\"0\n\n71\"1 + (1- 7I\"J)\n\nl [\n\nno - n ]\nn-s n.:\n\nn - 1]\nc + (1- 71\"0) _0__\nn-l\n\nwhere nc is the average size of a cluster. When n is large and nc remains bounded\n\nE(T)::= no{po + 71\"071\"1 (1 - Po) I\n\nso that (T - nopo)/no(1- Po) is an estimate of 71\"071\"1, which might sensibly be taken\nas a measure of the total percentage of cases due to clustering. Of course 71\"1 depends\non Po, the proportion of cases in the total sample, so different estimates will arise\nunless Po is standardized (say to Po = D in the procedure. Unfortunately this\ndependence of 71\"1 on Po is a function of the details of the model so that\nstandardization for different values of Po is not generally possible.\nA graphical procedure for identifying likely clusters is also needed. This might be\nbased on large summands in Jinv and this might be one place where T1nv is more\nuseful than the direct statistics Ti:\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ",
    "chunk_order_index": 13,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-58df04474867c0b5e3848ae16afb1ce6": {
    "tokens": 1200,
    "content": "e\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f90\n\nCUZICK AND EDWARDS\n\n[No. I,\n\nAPPENDIX A:\nEVALUATION OF DISTRIBUTION OF RANDOM VARIABLE T FOR k= 1\n\nAll the calculations in this and the subsequent appendixes are for a uniform density of\n\npoints {z;! over the entire plane or a region increasing to fill the plane.\n\nWe evaluate the distribution of T= L;i aU (which does not depend on)) by first computing\nthe factorial moments M,=E{T(T-I) . . . (T-I+ I)}, I~ 1. Since Pr(T~6)=0, M,=O for 1~6.\nAlso Mo=M, = 1. We consider the case of a unit uniform intensity on the entire plane. Then\nby considering an arbitrary point and setting up a co-ordinate system so that it is sited at\n..• , z\" which are\nthe origin, M, equals the integral over the set of 1points in the plane Z\"\ncloser to the origin than to each other, of the probability that there are no points in the set\nUJ= I Sj' where Sj is a closed circle with centre at Zj and radius rj = Ilzj II. In symbols\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\nwhere m denotes Lebesgue measure and\n\ni> 1, and multiplying the integrand by I, rescaling so that z/=zjlr\"\nBy taking rj:S; r\"\nj = 2, ... , I, writing Z, in polar co-ordinates (r, , 0I> and integrating out dr, dO, we find that\n\nwhere B=Bon{IIZjll :s; 1, j=2, ... , I} and Z, is fixed at (1, 0).\n\nWe now evaluate m(U}= I Sj)' First it is not difficult to show that for any (z\" ZZ, Z3, Z4)\n\nsuch that Ilzi-Zjll ~ max (ri , rj), iv i, i, j= 1, ... ,4, then\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\nso that\n\nIn general\n\nthe threefold intersection SinSjnSk is either {OJ or reduces to a twofold\nintersection (Fig. 7). In particular if (Oi, OJ, Ok) are the polar angles associated with (Zi' Zj,\nZk) respectively and the points are labelled so that Oi < OJ < Ok then\n\nSinSk\n\nSinSj\nSjnSk\n{OJ\n\nifOk-Oi:S;\"Jr\n\nifOj-Oi~\"Jr\n\nifOk-Oj~\"Jr\n\notherwise, i.e. {OJ-Oi<\"Jr, 0k-Oj<\"Jr, 0k-Oi>\"Jrj\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990]\n\nSPATIAL CLUSTERING\n\n91\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nFig. 7.\n\nIllustration of the region U}=tSj for 1=4\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\nFig. 8.\n\nIllustration of the region SI USz, components of SIns2 , and quantities used in Appendix A",
    "chunk_order_index": 14,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-1eedfc8049126c1285d19a40409301bc": {
    "tokens": 1200,
    "content": "s\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\nFig. 8.\n\nIllustration of the region SI USz, components of SIns2 , and quantities used in Appendix A\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f92\n\nCUZICK AND EDWARDS\n\n[No.1,\n\nSince m(Si) = 7frl, the evaluation of the integrand is reduced to computing m(SinS). This\nis given in the following lemma.\n\nLemma. For i = 1, 2, let Zi ER 2 have polar co-ordinates (r., (}i) and let S, be a sphere centred\nat Zi with radius rio Assume that r2~rl' let (3 = rs/r, and cP=I(}2-(}II. Then m(SlnS2)=\n7fTf f«(3, cP) where\n\na I = 2 tan - I (\n\n(3 sin cP\n1- (3 cos cP\n\n)\n\nand al +a2+2cP=27f.\n\nProof. m(SlnS2) is the sum of the areas of the two shaded regions shown in Fig. 8, and\n\nthese can be computed by elementary means.\n\nThe M, are now computed by Monte Carlo methods. The points Z2, ... , z, are sampled\nfrom a uniform distribution on the unit sphere and, if they are contained in B, the integrand\nis computed exactly. Otherwise this sample contributes nothing. In practice M\" 1= 2, ... , 5,\nwere evaluated simultaneously, leading to correlated estimates of the M,. The linear relation\nbetween M, and Pm = Pr(T= m) was then inverted to compute the Pm' m = 0, ... , 5, and the\nsample covariance matrix for the M, was used to derive standard errors. The results are shown\nin Table 2.\n\nAPPENDIX B: COMPUTATION OF limn~oo NAk, I)/n\n\nFor an arbitrary point at the origin, we compute E tvf1(k, I), the expected number of points\nwhich are k NNs to this point and for which the point at the origin is an 1NN. For regions\nwith reasonable boundaries, it is easily seen that Ns(k, I)/n will approach this value as n\nbecomes large. For a point ZER 2 let SI denote the closed circle with radius r= Ilzll centred\nat the origin and S2 denote the closed circle centred at z with radius r.\n\nLet A =SI '-S2' B=S2 '-SI and C=SlnS2 so that SIUS2=AUBUC and A, Band Care\n\ndisjoint. Then, if N(A) denotes the number of points in some set A and k ~ I,\n\nEN<j(k, 1)=IPr(N(SI) < k, N(S2) < I) dz\n\nk- I r\n\n= m~oJ Pr(N(A) <k-m, N(B)<I-m, N(C)=m) dz\n\nk-I k-m-I l s - m-s ; r\n\n= ~\n\n~\n\nm=O i=O\n\n~ J Pr(N(A)=l) Pr(N(B)=j) Pr(N(C)=m) dz.\n)=0\n\n(12)\n\nNow, elementary geometry gives that m(A) = m(B) = (1- a)7fr2 and m(C) = a7fr2 where\n\n.J3\n2\na= - - -\n27f\n3\n\nand use of the fact that N(A), N(B) and N(C) are independent Poisson variates allows us\nto conclude that equation (12) equals\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990]\n\nk-I\n2:\nm=O\n\nk-m- I I-m- I 11 {(I\n\n2:\n\n2:\nj=O\n\ni=O\n\nSPATIAL CLUSTERING\n\n93\n\n)\n-~,7rr\n\n2}i {(I\n\nl.\n\n)\n-~,7rr\nJ.\n\n2}j (\n\n2)m\n\nau,\nm.\n\nexp[-7rr2(2-a)jrdrdO.\n\nFinally the change of variable X= 7rr2 and use of the fact that\n\nt\"\"x k exp(-x) dx=k!\n\ngives\n\nk - I k - m - I 1-",
    "chunk_order_index": 15,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-c64658b4a58e951692d2ae363bbb1cd2": {
    "tokens": 1200,
    "content": "SPATIAL CLUSTERING\n\n93\n\n)\n-~,7rr\n\n2}i {(I\n\nl.\n\n)\n-~,7rr\nJ.\n\n2}j (\n\n2)m\n\nau,\nm.\n\nexp[-7rr2(2-a)jrdrdO.\n\nFinally the change of variable X= 7rr2 and use of the fact that\n\nt\"\"x k exp(-x) dx=k!\n\ngives\n\nk - I k - m - I 1- m - I (1 _ a)i +jam U +j + m) !\n2:\n2:\n2-a m=O i=O\n\n(2-a)i+j+m i! j! m!\n\n2:\nj=O\n\nwhich is\n(2-a)-'==0.6215. For k large and n/k large Ns/n - k.\n\n(2 - a) -,\n\ntimes a trinomial probability. When k = 1= 1 this\n\nreduces\n\nto\n\nAPPENDIX C: COMPUTATION OF limn~oo Nt(k, I)/n\nAs when k =1= 1, it is easily shown that, for k ~ I, Nt(k, I)/n--->E [ 7(k){ 7(1) - IlJ as n---> 00,\nwhere 7(k) is the number of points whose k or lower NN is an arbitrary point at the origin.\nFor any points Zi E R 2, i = 1, 2, at distances r, from the origin let S, be closed spheres centred\nat Zi with radius rio In this case we must distinguish whether Z, ES2 and/or Z2ESI' If we define\nA, B, C and N(') as in Appendix B, then a similar argument shows that\n\nE[7(k){7(1)-I}] =\n\nk- I k-m- I I-m- I\n2:\n2:\nm=O i=O\n\n2:\nj=o\n\nJ'l Pr(N(A) =i-ad Pr(N(B) =j - (2) Pr(N(C) = m) dZI dz2 ,\n\nR2 X R2\n(ZI;<OZ21\n\n(13)\n\nwhere 01 and 02 are the indicator functions of Z2ES, and Z, ES2 respectively and Pr(N(') = - 1)\nis taken to be zero. First consider the set where rl ~ r2. Define (3 = ri/r. and ¢ as the absolute\nvalue of the angle between the vectors ZI and Z2' Since (3 ~ 1, only the combinations {ZI E S2,\nZ2ESt!, [ZI t S2, Z2ESt! and {ZI t S2, zd St! are possible and correspond to II ZI - z211 ~ II r211,\nII r211 < II ZI - z211 ~ II rl II and Ilzl - z211 > II rl II respectively, which in turn can be expressed as\ncos¢~(2(3)-I, (2(3)-I<COS¢~!(3 and cos¢>!(3 respectively. The set where rl<r2\ncan be reduced to this case by interchanging the indices k and I. Elaboration allows equation\n(13) to be rewritten as\n\n~l k f ( k-f;-' I-~-I + I-~-I k-f;-'\nj=o\n7r m=O\n\nj=o\n\ni=O\n\ni=O\n\n)U+j+m+ I)!\n\ni! j! m!\n\n\\1\\11\"\nXJOJ lfr l\n\n(3{I-j(¢, (3)}i{(32_j(¢, (3)}jj(¢, (3)m d¢d(3\n\n[1+(32_j(¢, (3)ji+j+m+2\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f94\n\nCUZICK AND EDWARDS\n\n[No.1,\n\nk-m-Z I-m-l\n\nl-m-2 k-m-l\n\n~\ni=O\n\n~ + ~\ni=O\nj=o\n\n~\nj=o\n\nU + j + m + I)!\ni! j! m!\n\n)\n\nX II 11Jr1\nJo J1JrO\n\n{j[ 1 - j(rj>, {j)}i [{j2 - j(rj>, (j) Vj(rj>, {j)m drj> d{j\n\n[1 +{j2_ j(rj>, {j)}i+j+m+2\n\nX,I\n\nJIIZ Jo\n\n11Jr°{j[I-j(rj>, {j)}i[{j2_j",
    "chunk_order_index": 16,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-1ade3a9de25c12e49e6e8186ab516517": {
    "tokens": 1200,
    "content": "II 11Jr1\nJo J1JrO\n\n{j[ 1 - j(rj>, {j)}i [{j2 - j(rj>, (j) Vj(rj>, {j)m drj> d{j\n\n[1 +{j2_ j(rj>, {j)}i+j+m+2\n\nX,I\n\nJIIZ Jo\n\n11Jr°{j[I-j(rj>, {j)}i[{j2_j(rj>, {jWj(rj>, {j)m drj>d{jl\n\n[1 +/J2-j(rj>, (j)}i+j+m+2\n\nwhere 1Jr1 = cos -I G{j) and 1Jr0 = cos -1(1I2{j) for {j ~ Land 1Jr0 = 0 for {j < i. By convention\nthe last two terms are zero when k = 1= 1 giving the simpler form\n\nE[T(1)[T(1)-I}]=MZ=.! 1\n\n71\" Jo J1JrI! I + {j 2_ j (rj> , {j)}2\n\n{jdrj>d{j\n\n=0.633.\n\n1171\"\n\nIt is easily checked that Nt(k, l)/n - kl for k large and n/llarge.\n\nAPPENDIX D: CENTRAL LIMIT THEOREM FOR t;\n\nWhen the 0i are independent and identically distributed, asymptotic normality of\nTk = ~ aijo;oj has been established by many researchers under progressively weaker conditions.\nThe best results are those of Guttorp and Lockhart (1988) who show that, if au = 0, aij is\nsymmetric and Eor< 00, then tr A4/(tr A2)2->0 implies that Tk is asymptotically normal, where\n(A)ij = aij and tr denotes the trace. If the aij are normalized so tr A2 = 1 this is equivalent to\nassuming that all the eigenvalues of A tend to zero. A simple necessary condition for this is\n\n(14)\n\nIn our case the matrix A is not symmetric and must be replaced by i(A +A'). Condition\n(14) can then be verified by noting that\n\nand\n\n~ tr(A+A ')2>i tr(AA ')=ikn.\n\nThe random variables 0; defining Tk in equation (5) are not independent, so we must apply\nthe following device of Steck (1957) (see also Morris (1975)) to complete the proof of\nasymptotic normality for Ti . Redefine the 0; to be independent and identically distributed with\nPr(oi=I)=I-Pr(o;=O)=p for any O<p<1. The joint asymptotic normality of (Xn,\nYn)=(~aijoiOj, ~o;) after centring and rescaling is easily established as before by using the\nCramer-Wold device. Asymptotic normality of Tk then follows from Steck's result if it can\nbe shown that\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1990]\n\nSPATIAL CLUSTERING\nrPnCA, v)=E{exp(iAUn) I Vn =v)\n\n95\n\nfamily in (n,\n\nfixed A. Here\nv) on bounded sets\nis an equicontinuous\nUn=n-II2(Yn-EYn) and Vn=n-\nn. This can be checked as follows. For each\npermissible value of v (= In -112, I integer) choose sites at random to be cases, so that Vn = v.\nLet Told= L; L;ai/j/)j' Now choose L1n l 12 integer additional sites at random to be cases so\nthat now Vn = V+.1. Define 0{ to be unity if one of these new choices makes Zi a case. If\nTnew = L; L;aij( s, + 0{)(OJ + 0]) then\n\nI12X\n\nfor\n\nall\n\nI rPn(A, v) - rPn(A, v +.1) 1 = 1E [exp{iAn-II2(Told - ETo1d)) - exp{iAn -112(Tnew - ETnew ) ) ] I\n~ An- l12 [EI L; L;aij{oioj -E(Oi O])) 1\n\n+EI L; L;aij{o{oj-E(O{Oj)) I +EI L; L;aij{o{oj-E(o{oj)) 1 ]\n\nfrom",
    "chunk_order_index": 17,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-a02a9ff3e621627953b31b087b141cce": {
    "tokens": 1200,
    "content": ", v +.1) 1 = 1E [exp{iAn-II2(Told - ETo1d)) - exp{iAn -112(Tnew - ETnew ) ) ] I\n~ An- l12 [EI L; L;aij{oioj -E(Oi O])) 1\n\n+EI L; L;aij{o{oj-E(O{Oj)) I +EI L; L;aij{o{oj-E(o{oj)) 1 ]\n\nfrom which equicontinuity is easily verified.\n\nThis result can be extended to prove asymptotic joint normality of the h by considering\n\narbitrary linear combinations and using the Cramer-Wold device in the standard way.\n\nREFERENCES\n\nBarnes, N., Cartwright, R. A., O'Brien, C., Roberts, B., Richards, I. D. G. and Bird, C. C. (1987)\nSpatial patterns in electoral wards with high lymphoma incidence in Yorkshire Health Region. Br.\nJ. Cancer, 56, 169-172.\n\nBarton, D. E. and David, F. N. (1966) The random intersection of two graphs. In Research Papers\n\nin Statistics (ed. F. N. David), pp. 455-459. New York: Wiley.\n\nBesag, J. (1974) Spatial interaction and the statistical analysis of lattice systems (with discussion). J.\n\nR. Statist. Soc. B, 36, 192-236.\n\nBickel, P. J., Gotze, F. and van Zwet, W. R. (1986) The Edgeworth expansion for U-statistics of degree\n\ntwo. Ann. Statist., 14, 1463-1484.\n\nChen, R., Mantel, N. and Klingberg, M. (1984) A study of three techniques for space-time clustering\n\nin Hodgkins disease. Statist. Med., 3, 173-184.\n\nClark, P. J. and Evans, F. C. (1955) On some aspects of spatial pattern in biological populations. Science,\n\n121, 397-398.\n\nCliff, A. D. and Ord, J. K. (1981) Spatial Processes, Models and Application. London: Pion.\nCommittee on Medical Aspects of Radiation in the Environment (1988) Investigation oj the Possible\nIncreased Incidence oj Leukaemia in Young People near the Dounreay Nuclear Establishment,\nCaithness, Scotland. London: Her Majesty's Stationery Office.\n\nDiggle, P. J. (1983) Statistical Analysis oj Spatial Point Patterns. London: Academic Press.\nEderer, F., Myers, M. H. and Mantel, N. (1966) A statistical problem in space and time: do leukemia\n\ncases come in clusters? Biometrics, 20, 626-638.\n\nFriedman, J. H. and Rafsky, L. C. (1983) Graph-theoretic measures of multivariate association and\n\nprediction. Ann. Statist., 11, 377-391.\n\nGuttorp, P. and Lockhart, R. A. (1988) On the asymptotic distribution of quadratic forms in uniform\n\norder statistics. Ann. Statist., 16, 433-449.\n\nHenze, N. (1988) A multivariate two-sample test based on the number of nearest neighbor type\n\ncoincidences. Ann. Statist., 16, 772-783.\n\nHoeffding, W. (1948) A class of statistics with asymptotically normal distributions. Ann. Math. Statist.,\n\n19, 293-325.\n\nJohnson, N. L. and Kotz, S. (1969) Discrete Distributions, p. 157. New York: Wiley.\nKnox, E. G. (1964a) The detection of space-time interactions. Appl. Statist., 13, 25-29.\n- - (1964b) Epidemiology of childhood leukaemia in Northumberland and Durham. Br. J. Prevo\n\nSoc. Med., 18, 17-24.\n\nLewis, M. S. (1980) Spatial clustering in childhood leukaemia. J. Chron. Dis., 33, 703-712.\nMantel, N. (1967) The detection of disease clustering and a generalized regression approach. Cancer\n\nRes., 27, 209-220.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f96\n\nCUZICK AND EDWARDS\n\n[No. I,\n\nMatuszewski, T. 1. (1962) Some properties of Pascal distribution population.",
    "chunk_order_index": 18,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-5d3f0443631f567d74e05632c874ffda": {
    "tokens": 1200,
    "content": "e\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f96\n\nCUZICK AND EDWARDS\n\n[No. I,\n\nMatuszewski, T. 1. (1962) Some properties of Pascal distribution population. J. Am. Statist. Ass., 57,\n\n172-174; correction, 57, 919.\n\nMoran, P. A. P. (1948) The interpretation of statistical maps. J. R. Statist. Soc. B, 10, 243-251.\nMorris, C. (1975) Central limit theorems for multinomial sums. Ann. Statist., 3, 165-188.\nO'Brien, P. C. (1984) Procedures for comparing samples with multiple endpoints. Biometrics, 40,\n\n1079-1087.\n\nOpenshaw, S., Craft, A. W., Charlton, M. and Birch, J. M. (1988) Investigation of leukaemia clusters\n\nby use of a geographical analysis machine. Lancet, 272-273.\n\nPike, M. C. and Smith, P. G. (1974) A case-control approach to examine diseases for evidence of\n\ncontagion, including diseases with long latent periods. Biometrics, 30, 263-279.\n\nPinke1, D. and Nefzger, D. (1959) Some epidemiological features of childhood leukemia in the Buffalo,\n\nN. Y. area. Cancer, 12, 351-358.\n\nRipley, B. D. (1977) Modelling spatial patterns (with discussion). J. R. Statist. Soc. B, 39, 172-212.\n- - (1981) Spatial Statistics. New York: Wiley.\nRogers, W. H. (1976) Some convergence properties of k-nearest neighbor estimates. PhD Thesis.\n\nDepartment of Statistics, Stanford University.\n\nSchilling, M. F. (1986) Multivariate two-sample tests based on nearest neighbors. J. Am. Statist. Ass.,\n\n81, 799-806.\n\nSteck, G. P. (1957) Limit theorems for conditional distributions. Univ. Calif. Pub/. Statist., 2, 237-284.\nStone, R. A. (1988) Investigations of excess environmental risks around putative sources: statistical\n\nproblems and a proposed test. Statist. Med., 7, 649-660.\n\nUnwin, D. (1981) Introductory Spatial Analysis. London: Methuen.\nWhittemore, A. S., Friend, D., Brown, B. W. and Holly, E. A. (1987) A test to detect clusters of disease.\n\nBiometrika, 74, 631-635.\n\nDISCUSSION OF THE PAPER BY CUZICK AND EDWARDS\n\nSir David Cox (Nuffield College, Oxford): The story goes that the task of the proposer of the vote\nof thanks is to lull the authors into a sense of false security, thereby ensuring maximum impact for\nthe seconder's searching criticisms. It would be interesting to test this on historical data, developing\nsuitable measures of asperity and preferably correcting for the ages of those concerned in view of the\ndistressing tendency for mildness to increase with age. In the present case I welcome the paper and have\npleasure in congratulating the authors.\n\nIt is natural to consider related one-dimensional problems, these being different according to whether\nthe space is directional (time) or non-directional. An example of the former arising in particular in some\nindustrial contexts is as follows. Events of type A, e.g. breakdowns of a machine, occur irregularly\nand relatively frequently. Occasionally, especially when the local rate of occurrence of A is high, events\nof type B occur in a way outside the investigator's control. For example, events B might be modifications\ndesigned to reduce failures. On the basis of data on the two types of event what can be said about the\neffect of B on the occurrence of events A? One approach is as follows (Cox, 1955). Let k be a suitable\ninteger, e.g. 4. For each type B event calculate tb and ta , the times to the kth preceding A event and\nto the kth subsequent A event. Now take a number of longish sections of time without B events and\nchoose at random an origin from which to calculate control values of tb and ta • Then plot log ta against\nlog tb distinguishing B points from control data. From any structure in the resulting plots tentative\nconclusions of various kinds can be drawn. For example, if following each type B event the local Poisson\nrate of type A events is restored to an effectively constant value the variance of log ta should conform\nwith that of the log-chi-squared distribution with 2k degrees of freedom (Bartlett and Kendall, 1946).\nOverdispersion is a large theme in the analysis of data that are initially explicitly or implicitly in a\nsingle parameter family. In one sense overdispersion is a form of clustering and I am not clear how the\nauthors' methods perform in the presence of what from some points of view would be rejected as\nuninteresting. Slightly related is the possible desirability of spatial stratification in the sampling of controls,\ncomputing statistics separately from each stratum, combining statistics much as in the Mantel-Haenszel\nstatistic.",
    "chunk_order_index": 19,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-7b0e0b852a1bc7cf32fc4005e48ae8dd": {
    "tokens": 387,
    "content": "analysis of data that are initially explicitly or implicitly in a\nsingle parameter family. In one sense overdispersion is a form of clustering and I am not clear how the\nauthors' methods perform in the presence of what from some points of view would be rejected as\nuninteresting. Slightly related is the possible desirability of spatial stratification in the sampling of controls,\ncomputing statistics separately from each stratum, combining statistics much as in the Mantel-Haenszel\nstatistic.\n\nFinally there is the important issue of estimation discussed briefly at the end of the paper. It is a big\nadvantage of a test if it also estimates something meaningful, even if the estimate is meaningful only\nunder highly idealized circumstances. I hope that the authors will develop further their ideas on this point.\n\nI have pleasure in proposing a cordial vote of thanks.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\nb\na\nr\nt\ni\nc\ne\n5\n2\n1\n7\n3\n7\n0\n2\n7\n9\n0\n8\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5",
    "chunk_order_index": 20,
    "full_doc_id": "doc-44b0b82b004cab74dad033faccd3aaa5"
  },
  "chunk-378765978299b68daeb50d9fc4ffb8f0": {
    "tokens": 1200,
    "content": "J. R. Statist. Soc. A (1997)\n160, Part 1, pp. 87–105\n\nSome Methods for Investigating Spatial Clustering, with\nEpidemiological Applications\n\nBy N. H. ANDERSON{ and D. M. TITTERINGTON\n\nUniversity of Glasgow, UK\n\n[Received November 1994. Final revision May 1996]\n\nSUMMARY\nThe paper considers the problem of identifying spatial clustering, for instance of one group\nof individuals in relation to the spatial distribution of another. First, some of the literature\nis reviewed, some operational problems of practical investigations are discussed and a data\nset is introduced that involves a group of laryngeal cancer patients and a group of lung\ncancer patients in south Lancashire. Two techniques, an integrated squared difference\nstatistic and a two-dimensional version of the scan statistic, are then outlined, some of their\nproperties are discussed and they are applied to the data set. The ﬁnal section takes stock of\nthe data analysis and the characteristics of the techniques.\n\nKeywords: CANCER; DENSITY ESTIMATION; DISEASE CLUSTERING; EPIDEMIOLOGY; SCAN\n\nSTATISTIC; SPATIAL CLUSTERING\n\n1.\n\nINTRODUCTION\n\nStudies of spatial clustering have been employed frequently in epidemiological\ninvestigations of malignant disease, especially varieties of leukaemia in children\n(Doll, 1989; Kinlen, 1988). Evidence of spatial clustering around sources of envir-\nonmental pollution suggests that the risk of developing the disease was raised in\nthose areas and further investigations could then be carried out to determine the\nunderlying mechanism. The beneﬁts of this work would be seen both in terms of\nprevention,\ni.e. by removing the leukaemogenic agent, and, more generally, by\nimproving knowledge of the disease’s aetiology (Gardner, 1989; Wakeford et al.,\n1989). It is intended that the research discussed here should be relevant to a wide\nrange of applications, although the context of epidemiological clustering stimulated\nthis work and therefore inﬂuences our terminology. In particular, we describe the\npoint locations of the units or events of primary interest as ‘cases’, apply the term\n‘controls’ to point locations of a second type of event that provide ancillary infor-\nmation on the area under investigation and use ‘zones’ for small administrative\nsubregions, such as civil wards, parishes, counties or census enumeration districts,\nthat may contribute to the estimation of the population at risk.\n\nMarshall’s (1991) wide review of techniques for detecting spatial clustering\nidentiﬁed three families of methods; see also Besag and Newell (1991). The ﬁrst\nfamily consists of techniques for detecting clustering around a ﬁxed point. A recent\ncomprehensive review of these techniques can be found in Hills and Alexander\n\n{Address for correspondence: Department of Statistics, University of Glasgow, University Gardens, Glasgow, G12\n\n8QW, UK.\nE-mail: niall@stats.gla.ac.uk\n\n& 1997 Royal Statistical Society\n\n0964^1998/97/160087\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f88\n\nANDERSON AND TITTERINGTON\n\n[Part 1,\n\n(1989), and particular techniques are covered in Black (1984), Black et al. (1991),\nSchulman et al. (1988), Stone (1988), Diggle (1990), Lawson and Williams (1994) and\nLyon et al. (1981). The second family contains techniques for detecting clustering\nbehaviour more generally: the spatial distribution of cases is investigated for any\nevidence of a pattern that does not appear to be induced by the underlying spatial\ndistribution of the population. Within this general deﬁnition, there is a further\ndivision between methods that take account of the variability in population density\nthrough zone totals (Whittemore et al., 1987; Black et al., 1991; Turnbull et al., 1990;\nAlexander, 1991) and those that employ a sample of controls (Cuzick and Edwards,\n1990; Bithell, 1990; Diggle and Chetwynd, 1991). The third, and smallest, family of\nmethods provides exploratory techniques for investigating possible clusters, without\nassigning any causal explanation to regions so classiﬁed (Openshaw et al., 1987,\n1988; Openshaw, 1990; Besag and Newell, 1991).\n\nFinally in this section, we note that several researchers have considered the\ndi(cid:129)culties that are inherent in epidemi",
    "chunk_order_index": 0,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-81b796b9bd4a035e48834b1081d73a19": {
    "tokens": 1200,
    "content": "gle and Chetwynd, 1991). The third, and smallest, family of\nmethods provides exploratory techniques for investigating possible clusters, without\nassigning any causal explanation to regions so classiﬁed (Openshaw et al., 1987,\n1988; Openshaw, 1990; Besag and Newell, 1991).\n\nFinally in this section, we note that several researchers have considered the\ndi(cid:129)culties that are inherent in epidemiological studies of spatial clustering (Besag\nand Newell, 1991; Bithell and Stone, 1989; Gardner, 1989; Hills and Alexander, 1989;\nWakeford, 1990; Wakeford et al., 1989). Several concerns have been identiﬁed.\n\n(a) With human data, there may be numerator (case) or denominator (population\nat risk) inaccuracies; see the contributions of Besag et al. and Openshaw and\nCraft to Draper (1991).\n\n(b) The spatial scale at which the study is carried out may be extremely important.\nIf it is too coarse, a small scale or local clustering e(cid:128)ect may be swamped; if it\nis too ﬁne, then clustering at a coarser scale is unlikely to be detected.\n\n(c) Zones may not reﬂect the true distribution of population very accurately, and\nthe results of techniques based on zone counts are likely to be sensitive to\ndi(cid:128)erent partitionings.\n\n(d) An interpretation of signiﬁcance is very di(cid:129)cult when conﬁrmatory tests are\nused subsequently to preliminary experimentation or in the presence of prior\nknowledge—the study of the geographical distribution of, say, leukaemia\nnear sources of environmental pollution is prone to post hoc hypothesis\nformulation.\n\nFor a further review of issues such as data quality, problems of interpretation,\n\nmethodology and case-studies, see the various papers in Elliot et al. (1992a).\n\nIn the following section, we describe a data set consisting of point locations of\ncases of laryngeal and lung cancer. This is used subsequently to demonstrate the\napplication of two methods of detecting spatial clustering: the integrated squared\ndi(cid:128)erence (ISD) statistic (in Section 3) and the scan statistic (in Section 4). Section 5\ndiscusses the results of the two analyses and, more generally, the characteristics of the\nISD and scan statistics.\n\n2. LARYNGEAL CANCER DATA\n\nIn Sections 3.2 and 4.5, the ISD and scan statistics are used to analyse a real data\nset, which was provided by Professor P. J. Diggle and Dr A. C. Gatrell of the\nUniversity of Lancaster. The data set consists of two samples of point locations in\nthe Chorley and South Ribble Health Authority district in Lancashire, England. The\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1997]\n\nSPATIAL CLUSTERING\n\n89\n\nﬁrst sample locates the 58 cases of laryngeal cancer recorded between 1974 and 1983.\nThe second sample acts as a control group and consists of all 978 cases of lung cancer\npresenting in the same area and time period. (Diggle (1990) has plotted the raw data.)\nAddresses with the same postcode were assigned the same grid reference, so the\ncontrols data set has a number of co-ordinate points at which there are two or more\nobservations.\n\nA small group of four cases of laryngeal cancer (located near the grid co-ordinates\n(35600, 41400) in Fig. 1 of Diggle (1990)) seemed anomalous when the two samples\nwere compared, because the density of lung cancer in that area appeared to be much\nlower than that of laryngeal cancer. This gave rise to some concern, since an\nindustrial waste incinerator, located at Charnock Richard, very close to the four\ncases, had been operating between 1972 and 1980 (Diggle et al., 1990). The aim of the\noriginal analysis in Diggle (1990) was to investigate the possibility of a link between\nthis putative source of environmental pollution and the apparent local increase in\nrisk of cancer of the larynx.\n\nDiggle (1990) analysed the Lancashire data by developing a semiparametric multi-\nplicative model for the intensity function (cid:21)(cid:133)x(cid:134) of the inhomogeneous Poisson process\nfrom which cases of laryngeal cancer are assumed to derive, in terms of",
    "chunk_order_index": 1,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-b1b2a5acd60859f4be1c96e302f46a3a": {
    "tokens": 1200,
    "content": "0) was to investigate the possibility of a link between\nthis putative source of environmental pollution and the apparent local increase in\nrisk of cancer of the larynx.\n\nDiggle (1990) analysed the Lancashire data by developing a semiparametric multi-\nplicative model for the intensity function (cid:21)(cid:133)x(cid:134) of the inhomogeneous Poisson process\nfrom which cases of laryngeal cancer are assumed to derive, in terms of the distance\nfrom the point location representing the incinerator. The factors of (cid:21)(cid:133)x(cid:134) in the model\nrepresented the overall intensity of events per unit area, the variation in intensity due\nto the spatial heterogeneity of the population at risk (estimated by a kernel method\nfrom the control sample) and a parametric model for the dependence of intensity on\ndistance from the point source. The analysis suggested that the four cases previously\nidentiﬁed could be connected, in some way, to the operation of the plant. The scale of\nthe clustering e(cid:128)ect appeared to be quite small, however, as it was sensitive to the\nremoval of one or two of the four cases in the group. Similar results were obtained by\nDiggle and Rowlingson (1994), who extended the approach of Diggle (1990) by\nconditioning on the locations of both cases and controls.\n\n3.\n\nINTEGRATED SQUARED DIFFERENCE STATISTIC\n\nHere we compare two kernel density estimates (KDEs),\n\nevents, and ^f2(·), from the controls, using the ISD between them:\n\n^f1(·), calculated from the\n\n3.1.\n\nIntroduction\n\n(cid:133) (cid:26)\n\n(cid:27)2\n\nTh1h2\n\n(cid:136)\n\n^f1(cid:133)x(cid:134) (cid:255) ^f2(cid:133)x(cid:134)\n\ndx:\n\n(cid:133)3:1(cid:134)\n\nExpression (3.1) is a natural analogue of the integrated square error (ISE) of a single\nKDE,\n\n(cid:133)\n\nISE (cid:136)\n\nf ^f (cid:133)x(cid:134) (cid:255) f (cid:133)x(cid:134)g2 dx,\n\n(cid:133)3:2(cid:134)\n\na commonly used, global performance measure. With h1 (cid:136) h2 (cid:136) h, the ISD is the\nanalogue of a statistic proposed by Hall and Hart (1990) for nonparametric\nregression.\n\nHall (1984) provided a central limit theorem for equation (3.2), using methods\nemployed in Anderson (1994) to demonstrate the asymptotic normality of equation\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f90\n\nANDERSON AND TITTERINGTON\n\n[Part 1,\n\n(3.1), under certain conditions, and to compute the corresponding asymptotic means\nand variances. Real applications, however, will involve the analysis of data sets that\nare ﬁnite and possibly quite small, e.g. 50 or 100 events. For some such examples,\nAnderson and Titterington (1994) showed clearly, using simulation,\nthe\nasymptotic formulae for the means and variances, and the asymptotic normality\nitself, are not adequate. Anderson (1994) reached a similar conclusion in the context\nof Hall’s (1984) theory for the one-sample statistic, ISE. Anderson et al. (1994)\nlooked at modiﬁcations of the ISD statistic that improve its theoretical performance.\nSome progress might be made by using a log-normal or (cid:31)2-approximation to the\nasymptotic distribution of ISD. In practice, however, its use as a test statistic will be\nsimpliﬁed by incorporating a Monte Carlo assessment of signiﬁcance, as we illustrate\nin Section 3.2.\n\nthat\n\nThe ISD statistic will, of course, be sensitive to both excesses and deﬁcits of cases\ncompared with controls. A beneﬁt of this is that equation (3.1) may be useful in a\nbroad range of problems, i.e. as a two-sample goodness-of-ﬁt statistic. However, for\nmost investigations of spatial clustering, an ISD statistic may be less powerful than a\nmeasure that detects di(cid:128)erences in only one direction. Thus, we might compare three-\n^f1 (cid:255) ^f2 and (cid:133) ^f",
    "chunk_order_index": 2,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-a140dbc1b76fb9c7af19ef7ac8e8dec9": {
    "tokens": 1200,
    "content": "t of this is that equation (3.1) may be useful in a\nbroad range of problems, i.e. as a two-sample goodness-of-ﬁt statistic. However, for\nmost investigations of spatial clustering, an ISD statistic may be less powerful than a\nmeasure that detects di(cid:128)erences in only one direction. Thus, we might compare three-\n^f1 (cid:255) ^f2 and (cid:133) ^f1 (cid:255) ^f2(cid:134)2, since the former quantity indicates the\ndimensional plots of\nsign, and the latter the relative magnitude, of peaks due to large local di(cid:128)erences\nbetween the two kernel estimates.\nInstead of the ISD statistic Th1h2\n\nwe could look at other measures of the deviation\nbetween two KDEs, the most obvious choice, perhaps, being the maximum L1-\ndistance between the two estimates, maxx2A j ^f1(cid:133)x(cid:134) (cid:255) ^f2(cid:133)x(cid:134)j, where A is the region of\ninterest. This statistic may have greater power than Th1h2\nto detect small clusters.\nHowever, obtaining distributional results, whether exact or asymptotic, could be very\ndi(cid:129)cult, and, therefore, it might be necessary to use a bootstrap signiﬁcance test.\n\n3.2. Application of Integrated Squared Di(cid:128)erence Statistic to Cancer Data\n\n3.2.1. Preliminaries\n\nDiggle and Marron (1988) demonstrated that the smoothing parameter chosen for\nthe kernel estimation of the intensity function of an inhomogeneous Poisson process\nby the method of Diggle (1985) is the same as that selected for kernel estimation of\nthe density function by least squares cross-validation (LSCV) (Bowman, 1984). This\nis a useful result, since LSCV is not straightforward for the controls. The replicated\nco-ordinates, discussed in Section 2, cause the LSCV choice of smoothing parameter\nto be 0 (Silverman (1986), pages 51–52).\n\nThe bandwidth selection procedure of Diggle (1985) was derived by assuming that\n\na uniform kernel is to be used, i.e.\n(cid:26)\n\nK(cid:133)x(cid:134) (cid:136)\n\n(cid:25)(cid:255)1,\n0,\n\nxTx 4 1,\notherwise,\n\nfor the two-dimensional case. With this approach, Diggle (1990) obtained h (cid:136) 0:3 km\nfor the controls data. With a general kernel, the smoothing parameter hu, for a\nuniform K(·), must be scaled by the root-mean-squared radial distance of the new\nkernel; thus\n\nhnew (cid:136) (cid:133)2c(cid:134)(cid:255)1=2hu,\n\n(cid:133)3:3(cid:134)\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1997]\n\nSPATIAL CLUSTERING\n\n91\n\nwhere c is the quantity E(cid:133)X TX(cid:134) for the new non-uniform kernel. For example, the\n2, giving hnew (cid:136) hu, c (cid:136) 2 for a bivariate Gaussian\nbivariate uniform kernel has c (cid:136) 1\n3 for the bivariate Epan-\nkernel, giving hnew (cid:136) hu=2, as in Diggle (1990), and c (cid:136) 1\nechnikov kernel (Silverman (1986), p. 76) that we use in Section 3.2.2. The controls’\nbandwidth h2 should be of the form h2 (cid:136) kn(cid:255)1=6\nwith n2 (cid:136) 978 and k some constant.\nThus, under the null hypothesis, and given h2,\n\n2\n\n1\n\n(cid:133)3:4(cid:134)\n\nh1 (cid:136) h2n1=6\nwhere n1 (cid:136) 58, would be a suitable choice of smoothing parameter for the cases.\n\n2 n(cid:255)1=6\n\n,\n\nThe available data come from a ﬁnite bounded region A. The degree of uncertainty\nabout the quality of a density estimate increases near the boundary, and its accuracy\nmay be quite poor if some such ‘edge e(cid:128)ect’ is present. The inﬂuence of the area\noutside A",
    "chunk_order_index": 3,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-aa60c5d762e2ff21235a478577441394": {
    "tokens": 1200,
    "content": "6\nwhere n1 (cid:136) 58, would be a suitable choice of smoothing parameter for the cases.\n\n2 n(cid:255)1=6\n\n,\n\nThe available data come from a ﬁnite bounded region A. The degree of uncertainty\nabout the quality of a density estimate increases near the boundary, and its accuracy\nmay be quite poor if some such ‘edge e(cid:128)ect’ is present. The inﬂuence of the area\noutside A can be reduced by using a kernel of bounded support, or by reﬂecting the\ndata in the boundary in some way, but implementation of both of these proved very\ndi(cid:129)cult with the south Lancashire data. Also, the ISD statistic may be less sensitive\nto edge e(cid:128)ects than, for example, the scan statistic to be discussed in the next section;\nunder the null hypothesis, the two types of event come from the same f (·), so the\nbiases in the two estimates near the boundary should have the same sign and similar\nmagnitude.\n\nIn view of these di(cid:129)culties, values of the test statistic were obtained by crude\nMonte Carlo integration (Rubinstein (1981), pages 115–121), using a cuboid\nenvelope of volume V and base B on the (x, y) plane. A large number (R (cid:136) 106) of\nindependent random vectors (xi, yi(cid:134), i (cid:136) 1, : : :, R, was generated uniformly within\nthe envelope. For each vector, a successful trial was recorded if\n\nyi 4 f ^f1(cid:133)xi(cid:134) (cid:255) ^f2(cid:133)xi(cid:134)g2 (cid:17) I(cid:133)xi(cid:134),\nand then the value of the integral (interpreted as the volume under the surface I(x))\nwas estimated by rV/R, where r was the number of successes. An approximate 95%\nconﬁdence interval for the value of the integral was\n\nrV\nR\n\n(cid:6) 1:96\n\nVfr(cid:133)R (cid:255) r(cid:134)g1=2\nR3=2\n\n.\n\n(cid:133)3:5(cid:134)\n\n3.2.2. Analysis\n\nAs noted in Section 3.2.1, Diggle (1990) obtained a bandwidth of h2 (cid:136) 0:3 km for\nthe lung cancer data by using a bivariate uniform kernel function. From equation\n(3.3), this is equivalent to a smoothing parameter of h2 (cid:136) 0:367 km for a bivariate\nEpanechnikov kernel. For the laryngeal cancer cases, equation (3.4) then gives\nh1 (cid:136) 0:588 km.\n\nThese values were used for the perspective plot of the squared di(cid:128)erence between\nthe two surfaces, i.e. a plot of I(x), shown in Fig. 1. The diagram takes the point of\nview of an observer to the south-west of the region of interest. The surfaces were\nevaluated over a 51 (cid:2) 51 grid and the x- and y-axes have been converted to\nkilometres. Two pronounced spikes are visible, one at approximately the location of\nthe four cases mentioned in Section 2 and the other just to the north-east of this\nposition. Fig. 2, which represents the surface ^f1(cid:133)x(cid:134) (cid:255) ^f2(cid:133)x(cid:134), shows that the former\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f92\n\nANDERSON AND TITTERINGTON\n\n[Part 1,\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\nFig. 1. Squared di(cid:128)erence surface for laryngeal cancer data, with smoothing parameters h1 (cid:136) 0:588 km\nand h2 (cid:136) 0:367 km (viewed from the south-west)\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne",
    "chunk_order_index": 4,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-198239f0a563293147dfd25ee576bd2b": {
    "tokens": 1200,
    "content": "cid:136) 0:588 km\nand h2 (cid:136) 0:367 km (viewed from the south-west)\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\nFig. 2. Case (cid:255) control di(cid:128)erence surface for laryngeal cancer data, with smoothing parameters\nh1 (cid:136) 0:588 km and h2 (cid:136) 0:367 km (viewed from the south-west)\n\npeak is due to a relatively greater density of cases in that area, whereas the latter is\nattributable to an excess of controls. With the dimensions of a suitable envelope\nestimated from the data used to produce Fig. 1, the corresponding rejection method\n, using a sample of R (cid:136) 106 random vectors, was 0.024,\nMonte Carlo estimate of Th1h2\nwith an approximate 95% conﬁdence interval from equation (3.5) of (0.023, 0.025).\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1997]\n\nSPATIAL CLUSTERING\n\n93\n\nThe signiﬁcance of this observed value of the test statistic was assessed by a Monte\nCarlo test implemented with the smoothed bootstrap, a technique described by\nSilverman (1986), pages 144–147, and Silverman and Young (1987). This procedure\nwas preferred to the standard bootstrap, because, in general, the ‘with replacement’\nresampling scheme of the standard bootstrap produces simulated data sets con-\ntaining repeated values, making the resulting kernel density estimates more noisy. The\n(cid:136) 0:024, as\nsmoothed bootstrap samples were drawn from the 978 controls. For Th1h2\ngiven above, the corresponding p-value was 0.79, when 99 bootstrap replications were\nemployed. (In this test, and in subsequent analyses, each bootstrapped statistic was\ncalculated with the same bandwidths as the observed value.)\n\nIt is interesting to compare Figs 1 and 2 with Fig. 3, which is a plot of the type\n\nproposed by Bithell (1990). The surface drawn is P(x), where\n\nin which\n\nP(cid:133)x(cid:134) (cid:136)\n\n^(cid:26)(cid:133)x(cid:134)\n1 (cid:135) ^(cid:26)(cid:133)x(cid:134)\n\n,\n\n^(cid:26)(cid:133)x(cid:134) (cid:136)\n\n^fcases(cid:133)x(cid:134) (cid:135) !\n^fcontrols(cid:133)x(cid:134) (cid:135) !\n\n(cid:133)3:6(cid:134)\n\nand ! (cid:136) 0:1 K(cid:133)0(cid:134). For the bivariate Epanechnikov kernel, ! (cid:136) 0:064. The surface in\nFig. 3 is noisy, because of the variability in the two KDEs; however, the two\nstrongest features seem to correspond with those observed in Figs 1 and 2, with an\nexcess of laryngeal cancer at the location of the four-case ‘cluster’, and a control\nexcess to the north-east.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\nFig. 3. Plot of equation (3.6) with smoothing parameters h1 (cid:136) 0:588 km and h2 (cid:136) 0:367 km (ratio\nconstant ! (cid:136) 0:064; viewed from the south-west)\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f94\n\nANDERSON AND TITTERINGTON\n\n[Part 1,\n\nTo investigate sensitivity to the values of\n\nthe\nsigniﬁcance test was repeated for KDEs of the cases and",
    "chunk_order_index": 5,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-f127b509d5ea60744a072ded6a7f343f": {
    "tokens": 1200,
    "content": "3.6) with smoothing parameters h1 (cid:136) 0:588 km and h2 (cid:136) 0:367 km (ratio\nconstant ! (cid:136) 0:064; viewed from the south-west)\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f94\n\nANDERSON AND TITTERINGTON\n\n[Part 1,\n\nTo investigate sensitivity to the values of\n\nthe\nsigniﬁcance test was repeated for KDEs of the cases and controls that were\ncalculated with bandwidths of the form\n\nthe smoothing parameters,\n\nh(cid:133)new(cid:134)\ni\n\n(cid:136) (cid:22)hi,\n\n(cid:133)3:7(cid:134)\n\nfor i (cid:136) 1, 2 and (cid:22) (cid:136) 1:5, 2.0, 2:5, : : :, 5:5, where h1 (cid:136) 0:588 km and h2 (cid:136) 0:367 km.\nIn general, a comparison of the two kernel estimates suggested that the density of\nlaryngeal cancer near the four-case group of particular interest was greater in relation\nto that of the surrounding area than the density of controls in the same region.\nHowever, as (cid:22) increased, the prominence of the peak at that location in the squared\ndi(cid:128)erence surface decreased, until, by (cid:22) (cid:136) 4, the most signiﬁcant feature was the\ncontrol excess spike to the north-east. This behaviour was echoed by the sequence\nof plots of equation (3.6). Table 1 lists the p-values for the Monte Carlo tests\ncorresponding to each value of (cid:22) and shows a trend towards signiﬁcant p-values with\nincreasing (cid:22), apparently because of a lack of cases to the north-east of the group that\noriginally gave rise to concern.\n\nThe results of Diggle et al. (1990) suggested that the scale of association with the\nincinerator was quite small, extending over a distance of only about 3–4 km from the\nfacility. To investigate this, the ISD between the two KDEs, based on the full data,\nwas calculated for a reduced area of 5 km (cid:2) 5 km around the group of four cases,\nnamely [12.5, 17.5] (cid:2) [2.5, 7.5] on the kilometre scale. The relevant section of the\nsquared di(cid:128)erence surface is shown in Fig. 4. With the same type of signiﬁcance test\nas before, the p-value of 0.72 was relatively similar to the original ﬁgure of 0.79.\nComparable results were obtained with larger smoothing parameters: for (cid:22) (cid:136) 4 in\nequation (3.7), for example, the new p-value of 0.49 was actually an increase from the\noriginal 0.26. Thus, there appeared to be no signiﬁcant evidence of clustering in the\nlaryngeal cancer data, even in the immediate vicinity of the incinerator. Of course,\npost hoc selection of a subregion in this way is not valid inferentially, but it is useful\nfor an example.\n\n4. TWO-DIMENSIONAL SCAN STATISTIC\n\n4.1.\n\nIntroduction\n\nThe one-dimensional scan statistic was originally proposed as a measure of\nclustering in time by Naus (1965a, 1966) and a recent review was provided by Naus\n(1988); see also Anderson and Titterington (1995). Taking the time interval of\ninterest to be the interval (0, 1], and assuming that N events are distributed within it,\nthe scan statistic is the maximum number of points that can be included in [x (cid:255) d, x],\n\nTABLE 1\nResults of smoothed bootstrap signiﬁcance tests of the south Lancashire data using bandwidths from\nequation (3.7) with di(cid:128)erent (cid:22){\n\n(cid:22)\np-value\n\n1\n0.79\n\n1.5\n0.88\n\n2\n0.77\n\n2.5\n0.61\n\n3\n0.45\n\n3.5\n0.30\n\n4\n0.26\n\n4.5\n0.13\n\n5\n0.06\n\n5.5\n0.08\n\n{Monte Carlo test based on 99 replications.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5",
    "chunk_order_index": 6,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-6b6c9cbfc295222a26e75a0ea88bad1c": {
    "tokens": 1200,
    "content": "1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1997]\n\nSPATIAL CLUSTERING\n\n95\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\nFig. 4. Squared di(cid:128)erence surface for the central 5 km (cid:2)5 km area of the laryngeal cancer data, with\nsmoothing parameters h1 (cid:136) 0:588 km and h2 (cid:136) 0:367 km (viewed from the south-west)\n\nwhere x is allowed to vary over (d, 1] and d (<1) is a prespeciﬁed constant. Clearly,\nlarge values of this statistic may indicate some form of clustering.\n\nFor a two-dimensional version, it is natural to generalize the unit interval to the\nunit square, [0, 1] (cid:2) [0, 1], and the scanning interval to a u (cid:2) v rectangle, as ﬁrst\nproposed by Naus (1965b). Let N events be distributed within the unit square and let\nnxy be the number of points within the rectangle [x (cid:255) u, x] (cid:2) [y (cid:255) v, y]. The two-\ndimensional scan statistic is\n\nSuv (cid:136) max\nx2(cid:137)u; 1(cid:138)\ny2(cid:137)v; 1(cid:138)\n\n(cid:133)nxy(cid:134):\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\nWe write the tail probability Pr(cid:133)Suv 5 njN; u, v) as P(cid:133)njN; u, v). The relevant null\nhypothesis is that the N events are assumed to be sampled from a uniform\ndistribution on [0, 1] (cid:2) [0, 1].\n\nA two-dimensional version of the algorithm in Anderson and Titterington (1995)\nfor calculating the scan statistic can be developed easily. Each event location is used\nin turn as a reference point for a one-dimensional scan, with the ﬁrst count being\nmade in the square with the top right-hand corner located at the reference event, and\nsubsequent counts being made when new events enter the square as it scans\nhorizontally to the right; the scan ﬁnishes when the current reference point leaves the\nwindow at its top left-hand corner. The next event in the sequence is then selected as\nthe reference point, and the process is repeated.\n\nIn a longer version of this paper, Anderson and Titterington (1994) investigated\nthe two-dimensional scan statistic in detail. Here we present a summary of their\nﬁndings about the simulation of critical values (Section 4.2), the evaluation of\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f96\n\nANDERSON AND TITTERINGTON\n\n[Part 1,\n\nempirical power (Section 4.3) and how to modify the method to cope with a non-\nuniform null distribution (Section 4.4).\n\n4.2. Simulation of Critical Values\nAnderson and Titterington (1994) concentrated on the case of a square scanning\nwindow with u (cid:136) v (cid:136) d. Table 2 displays empirical 5% critical values and the\nsimulated upper tail probability to which each corresponds. The results are derived\nfrom the empirical frequency distribution of 1000 replications, with the co-ordinates\nof events being simulated by sampling from the uniform distribution on the unit\nsquare. Some tail probabilities are inevitably much less than 0.05, especially for small\nd, because of the restriction of the statistic to integer values.\n\n4.3.\n\nInvestigation of Empirical Power\n\nIn the investigation of power, signiﬁcance testing within the simulation stages was\nimplemented with the usual randomized rule for attaining a test with a prescribed\nsigniﬁcance level from discrete data (Gibbons, 1986). For each individual simulation,\n1000 sets of artiﬁcial data were generated. The probability density function (PDF) of\nthe locations of the events was\n\np U(cid:133)0, 1(cid:138) (cid:135) (cid:133)1 (cid:255) p",
    "chunk_order_index": 7,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-dea7db88eb8ec9d51cd2846372b6ad27": {
    "tokens": 1200,
    "content": "within the simulation stages was\nimplemented with the usual randomized rule for attaining a test with a prescribed\nsigniﬁcance level from discrete data (Gibbons, 1986). For each individual simulation,\n1000 sets of artiﬁcial data were generated. The probability density function (PDF) of\nthe locations of the events was\n\np U(cid:133)0, 1(cid:138) (cid:135) (cid:133)1 (cid:255) p(cid:134) U(cid:133)k (cid:255) (cid:15), k (cid:135) (cid:15)(cid:138),\n\n(cid:133)4:1(cid:134)\n\nfor p 2 {0.8, 0.9, 0.95}, (cid:15) (cid:136) 0:025 and k 2 {0.5, 0.75}. U(a, b] is the bivariate uniform\nPDF on the square with lower left-hand corner (a, a) and top right-hand corner\n(b, b).\n\nThe power was, naturally, greater for smaller p, corresponding to larger expected\nproportions of events in the cluster. Smaller scanning squares were more powerful,\nand the best performance was achieved for d (cid:136) 1=16. As the cluster deﬁned by\nexpression (4.1) has approximate dimensions 0.05 (cid:2) 0.05, the greatest power occurs if\nthe scanning square has roughly the same area as the cluster.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\nTABLE 2\nEmpirical 5% critical values for the two-dimensional scan statistic, as sample quantiles from\n1000 simulated realizations{\n\nN\n\n20\n\n50\n\n100\n\n150\n\nCritical values for the following values of d:\n\n1/2\n\n1/4\n\n1/8\n\n1/16\n\n1/32\n\n1/64\n\n13\n(0.021)\n24\n(0.046)\n41\n(0.043)\n58\n(0.033)\n\n7\n(0.032)\n12\n(0.014)\n18\n(0.039)\n23\n(0.043)\n\n5\n(0.013)\n7\n(0.018)\n10\n(0.009)\n12\n(0.014)\n\n4\n(0.007)\n5\n(0.007)\n6\n(0.032)\n7\n(0.014)\n\n3\n(0.008)\n4\n(0.003)\n4\n(0.049)\n5\n(0.011)\n\n3\n(<0.001)\n3\n(0.014)\n4\n(0.003)\n4\n(0.002)\n\n{Actual, empirical signiﬁcance levels are given in parentheses.\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1997]\n\nSPATIAL CLUSTERING\n\n97\n\n4.4. Modiﬁcation to Cope with Non-uniform Null Distribution\n\nIn practice, factors such as geographical features and rural–urban variation ensure\nthat the distribution of controls is not uniform (Bithell, 1990; Diggle, 1990). A\nmethod for accommodating this with the one-dimensional scan statistic was\ndescribed by Weinstock (1981). Anderson and Titterington (1995) have discussed\npractical implementation, and, here, we extend their approach to two dimensions.\n\nThe region under consideration is taken to be [0, A] (cid:2) [0, B]. So far, the ‘no-\n\nclustering’ density has been the two-dimensional uniform PDF\n\n(cid:26)\nf (cid:133)x, y(cid:134) (cid:136) (cid:133)AB(cid:134)(cid:255)1,\n\n0,\n\n0 4 x 4 A,\n\n0 4 y 4 B,\n\nelsewhere;\n\n(cid:133)4:2(cid:134)\n\nwith A (cid:136) B (cid:136) 1. Under condition (4.2), the probability content of a d-sided square\nwithin [0, A] (cid:2) [0, B] is d 2=AB. To maintain this for general f (·, ·), the length of the\nside of the scanning square with top right-hand corner at co-ordinates (x, y) should\nbe (cid:14), where (cid:14) satisﬁes\n\n(cid:133)x\n\n(cid:133)y\n\nf (cid:133)s, t(cid:134) ds dt (cid:255) d 2=AB (cid:136) 0:\n\n(cid:133)4:3(cid:134)\n\nx(cid",
    "chunk_order_index": 8,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-80be6abab34c1260989f965582bf706f": {
    "tokens": 1200,
    "content": ", ·), the length of the\nside of the scanning square with top right-hand corner at co-ordinates (x, y) should\nbe (cid:14), where (cid:14) satisﬁes\n\n(cid:133)x\n\n(cid:133)y\n\nf (cid:133)s, t(cid:134) ds dt (cid:255) d 2=AB (cid:136) 0:\n\n(cid:133)4:3(cid:134)\n\nx(cid:255)(cid:14)\n\ny(cid:255)(cid:14)\n\nAnderson and Titterington (1994) approximated the solution of equation (4.3) by\nusing a combination of a numerical integration rule and Taylor expansions of f (·, ·):\nthe numerical integration, based on Simpson’s rule, leads to a linear combination of\nevaluations of f (·, ·) that are then expanded using Taylor’s theorem.\n\nIf f (·, ·) is known and integrable, it is possible to compare approximations with the\n\nexact result from equation (4.3). For instance, if\n\nf (cid:133)x, y(cid:134) (cid:136) 1\n4\n\nU(cid:133)x, y(cid:134) (cid:135) 3\n4\n\nB(cid:133)x, y(cid:134),\n\n(cid:133)4:4(cid:134)\n\nwhere U(x, y) is the uniform PDF on the unit square and B(x, y) is the PDF for co-\nordinates that are independently Be(3, 3), then equation (4.3) is a polynomial of\ndegree 10. According to the heuristic rule of Anderson and Titterington (1995), the\nchosen (cid:14) is the smallest real positive zero. A simulation study was carried out to\ncompare the accuracy of the approximations, relative to exact solution of equation\n(4.3). Anderson and Titterington (1994) described how the best approximation\nturned out to be based on third-order Taylor expansions. The results associated with\nthis approximation are referred to as ‘approximate’ in Table 3: note the comparison\nwith the exact results, labelled as ‘equation (4.3)’. To compute the scan statistic, the\nalgorithm described in Section 4.1 is used, with the modiﬁcation that (cid:14) is recomputed\nwhenever new events are encountered in any horizontal scan. Note also that, in the\nbulk of Table 3, the values are very similar to those in Table 2, which is based on\nuniformly distributed data.\n\nIn practice, the controls’ density f (·, ·) is unknown, and Anderson and Titterington\n\n(1994) tried a KDE within the approximate approach. They used the kernel\n\n(cid:26)\n\nK3(cid:133)x(cid:134) (cid:136) 4(cid:25)(cid:255)1(cid:133)1 (cid:255) xTx(cid:134)3,\n0,\n\notherwise,\n\nxTx < 1,\n\nsuggested by Silverman (1986), p. 76, and chose the smoothing parameter tradi-\ntionally, to minimize the approximate mean integrated square error of the estimator,\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f98\n\nANDERSON AND TITTERINGTON\n\n[Part 1,\n\nTABLE 3\nSimulated 5% scan statistic critical values (100 replications) with the exact null distribution (4.4), and the\nexact, equation (4.3), or approximate correction methods, and also the latter based on density estimates\nfrom 100, 200, 400 and 800 controls\n\nN\n\nMethod\n\nCritical values for the following values of d:\n\n1/4\n\n1/8\n\n1/16\n\n1/32\n\n1/64\n\n20\n\n50\n\n100\n\n150\n\nEquation (4.3)\nApproximate\n100\n200\n400\n800\nEquation (4.3)\nApproximate\n100\n200\n400\n800\nEquation (4.3)\nApproximate\n100\n200\n400\n800\nEquation (4.3)\nApproximate\n100\n200\n400\n800\n\n7\n8\n13\n10\n10\n9\n12\n11\n40\n26\n22\n19\n19\n18\n90\n56\n46\n39\n23\n24\n132\n103\n74\n54\n\n5\n5\n5\n5\n5\n5\n7\n7\n9\n8\n7\n7\n10\n10\n82\n51\n25\n13\n12\n11\n117\n77\n47\n29\n\n4\n4",
    "chunk_order_index": 9,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-a0408c7b47fba63a141ae2c77b6fd631": {
    "tokens": 1200,
    "content": "7\n8\n13\n10\n10\n9\n12\n11\n40\n26\n22\n19\n19\n18\n90\n56\n46\n39\n23\n24\n132\n103\n74\n54\n\n5\n5\n5\n5\n5\n5\n7\n7\n9\n8\n7\n7\n10\n10\n82\n51\n25\n13\n12\n11\n117\n77\n47\n29\n\n4\n4\n4\n4\n4\n4\n5\n5\n5\n5\n5\n5\n6\n6\n7\n6\n6\n7\n7\n7\n8\n8\n7\n7\n\n3\n3\n3\n3\n3\n3\n4\n4\n4\n4\n4\n4\n5\n4\n5\n4\n5\n5\n5\n5\n6\n5\n5\n5\n\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n\nassuming that the true distribution was known (Silverman (1986), p. 85). Table 3\nshows critical values at the 5% level based on the scan statistic for 20, 50, 100 or 150\nevents and 100, 200, 400 or 800 controls. Overall, the approximation is poor for large\nd, but the values for small d, d < 1=16, are close to those from exact solution of\nequation (4.3). The accuracy increases with the number of controls, Nc; with\nNc 5 400, the correct values are quite closely achieved for d 4 1=16.\n\n4.5. Application of Scan Statistic to Cancer Data\nThe scan statistic was applied to the south Lancashire data, adapting to a non-\nuniform null density ( f in equation (4.3)) represented by a kernel estimate of the lung\ncancer PDF. The value of (cid:14) in equation (4.3) was obtained using the approximation\nmethod in Section 4.4. The KDE was again based on an Epanechnikov kernel, with\nthe smoothing parameter h2 (cid:136) 1:835 km, chosen by taking (cid:22) (cid:136) 5 in equation (3.7). It\nwas hoped that the smoother estimate produced by a bandwidth larger than that\nsuggested by the approach discussed in Section 3.2.1 would improve the reliability of\nthe calculation of (cid:14).\n\nIn our problem, and in spite of the reported good agreement between Tables 2 and\n3, the procedure is not formally distribution free. Accordingly, it is appropriate to\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1997]\n\nSPATIAL CLUSTERING\n\n99\n\nassess the signiﬁcance of an observed value of the scan statistic by a Monte Carlo\nprocedure, based on an appropriate base-line distribution for the test statistic. The\nbase-line must correspond to the population of controls, which we represent by a\ndensity estimate, constructed from the 978 cases of lung cancer that are available.\nThe base-line (null) distribution of the scan statistic is therefore constructed as\nfollows. For the south Lancashire data, transformed to a kilometre scale (so that the\nstudy area represents approximately a 25 km (cid:2) 25 km square), each simulation\nrequires 58 events to be simulated from the density estimate calculated from the\ncontrols (as described above). For each such sample, and for a prescribed size d for\nthe nominal length of the side of the scanning square, the scan statistic was evaluated\nusing the approximation method of Section 4.4. Table 4 displays empirical null\ndistributions, based on 1000 replications, for the scan statistic for a sample of size 58,\ngiven scanning squares of nominal size 0.25, 0.50, 0.75, 1.0, 2.0 and 3.0 km. For\nlarger d, inaccuracies caused by the Taylor expansions a(cid:128)ected the calculation of the\nscanning square dimensions, and, thus, the relevant scan statistics were unreliable.\nTable 5 displays, for the same values of d as in Table 4, the observed scan statistics\nfrom the laryngeal cancer data, along with the corresponding p-values, computed\nwith reference to Table 4. The p-values for d (cid:136) 0:25 and d (cid:136) 2:0 give a hint",
    "chunk_order_index": 10,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-7e75d46b9002ec7fc8a1b1d309830dce": {
    "tokens": 1200,
    "content": ":128)ected the calculation of the\nscanning square dimensions, and, thus, the relevant scan statistics were unreliable.\nTable 5 displays, for the same values of d as in Table 4, the observed scan statistics\nfrom the laryngeal cancer data, along with the corresponding p-values, computed\nwith reference to Table 4. The p-values for d (cid:136) 0:25 and d (cid:136) 2:0 give a hint of\n\nTABLE 4\nEmpirical null distributions of the scan statistic for the south Lancashire data, with d being the constant in\nequation (4.3){\n\nScan statistic\n\nFrequencies for the following values of d:\n\nd=0.25\n\nd=0.5\n\nd=0.75\n\nd=1.0\n\nd=2.0\n\nd=3.0\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n>9\n\n904\n81\n2\n2\n1\n1\n2\n3\n2\n2\n\n717\n263\n2\n0\n1\n3\n1\n3\n1\n9\n\n511\n462\n5\n0\n1\n1\n2\n8\n0\n10\n\n297\n669\n11\n2\n1\n0\n2\n1\n3\n16\n\n6\n783\n128\n13\n8\n3\n4\n4\n3\n48\n\n0\n447\n372\n60\n16\n13\n11\n10\n4\n67\n\n{From 1000 simulations, events being simulated from the KDE of the controls.\n\nTABLE 5\nObserved scan statistics\nsouth\nLancashire data and corresponding p-values,\nfor given values of d in equation (4.3)\n\nthe\n\nfor\n\nd\n\n0.25\n0.5\n0.75\n1\n2\n3\n\nScan statistic\n\np-value\n\n2\n2\n2\n2\n4\n4\n\n0.096\n0.283\n0.489\n0.703\n0.083\n0.181\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f100\n\nANDERSON AND TITTERINGTON\n\n[Part 1,\n\nsomething ‘signiﬁcant’, but overall the scan statistics seem to be typical of those\nexpected under the null hypothesis and, therefore, provide little convincing evidence\nof clustering of laryngeal cancer. The essential discreteness of the scan statistic is a\nmajor contributory factor to the large variations in the p-values.\n\nThe methodology discussed here does involve various approximations: the true\ndensity of the controls is approximated by a density estimate, the null distribution of\nthe test statistic is approximated by an empirical version and the method of calcu-\nlating the scan statistic is itself an approximate procedure. However, at some level,\nthe p-values can claim some respectability, in terms of their relationship with the\ncontrol population, through the available sample of controls.\n\n4.6. Generalizations\nSince signiﬁcance testing for the scan statistic will usually be accomplished by\nsimulation, it would be possible to extend the method to use scanning windows of\ndi(cid:128)erent shapes. For example, it might be thought to be more appealing to use a\nrotation invariant scanning circle, which would give a test procedure with similarities\nto the geographical analysis machine of Openshaw et al. (1987, 1988) and the\nvariation thereof described in Section 12.2 of Draper (1991). This resemblance would\nbecome stronger if the scanning procedure were repeated for a range of radii, with\nthe intention of exploring the scale at which clustering might be taking place.\nHowever, even the use of a circle implies spatial isotropy. Other shapes could be\nintroduced to increase the power for speciﬁc alternative hypotheses, e.g. a rectangle\nor ellipse aligned with the direction of the prevailing wind, to test hypotheses\nregarding air dispersion of pollutants. Whatever type of window is used, the\ncomputational challenge is to design an e(cid:129)cient algorithm for the scan statistic; see\nAppendix A for a sketch of how to do this for a circular window. Although we have\nnot implemented this for the Chorley–Ribble data, we have critically assessed our use\nof a square window by reanalysing the data with squares oriented at four di(cid:128)erent\nangles, relative to north, corresponding to the compass directions east (the original\nanalysis), east-north-east, north-east and north-north-east. The resulting values of\nthe scan statistic varied very little, suggesting that use of a scanning square was\nadequate for these data; see Table 6.\n\nTABLE",
    "chunk_order_index": 11,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-d4f6f52a42ef44735d8f05caeb50800b": {
    "tokens": 1200,
    "content": "Ribble data, we have critically assessed our use\nof a square window by reanalysing the data with squares oriented at four di(cid:128)erent\nangles, relative to north, corresponding to the compass directions east (the original\nanalysis), east-north-east, north-east and north-north-east. The resulting values of\nthe scan statistic varied very little, suggesting that use of a scanning square was\nadequate for these data; see Table 6.\n\nTABLE 6\nObserved scan statistics for the south Lancashire data, for four directions of\nlisted with the corresponding square\norientation of\n\nthe scanning square,\n\ndimension targets d\n\nd\n\nValues of scan statistic for the following directions of orientation:\n\nEast\n\nEast-north-east\n\nNorth-east\n\nNorth-north-east\n\n0.25\n0.5\n0.75\n1\n2\n3\n\n2\n2\n2\n2\n4\n4\n\n2\n2\n2\n3\n4\n4\n\n2\n2\n3\n3\n4\n4\n\n2\n2\n2\n3\n4\n4\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1997]\n\nSPATIAL CLUSTERING\n\n101\n\n5. CONCLUDING DISCUSSION\n\n5.1. Discussion of Analysis of Cancer Data\nThe conclusion reached by Diggle (1990) and Diggle et al. (1990) was that there\nwas a local increase in the risk of laryngeal cancer in the area around the incinerator,\nbut that the magnitude and extent of the e(cid:128)ect was very di(cid:129)cult to quantify. The\nISD statistic provided some evidence of a di(cid:128)erence between the case and control\ndensities, although this seemed to be attributable to a region with a greater relative\ndensity of controls, rather than to the clustering of laryngeal cancer, and was not\nstatistically signiﬁcant. The analysis based on the scan statistic found no evidence of\nclustering for any of the choices of d.\n\nThe semiparametric method of Diggle (1990) seems to be more e(cid:128)ective than either\nfor the south Lancashire data set, no doubt because the\nthe scan statistic or Th1h2\nmodel for the intensity (cid:21)(cid:133)x(cid:134) involves the location of the incinerator site. Global\nmeasures are, however, often appropriate, as in the detection of clustering on a larger\nscale or early in an investigation, before a putative point source has been identiﬁed.\nKelsall and Diggle (1995a) evaluated the logarithm of the ratios of (univariate)\nKDEs of the squared distances of the cases and controls from the incinerator and\nfound only a small but ‘non-signiﬁcant’ increase in risk near the site. In extending\nthis to a two-dimensional approach, Kelsall and Diggle (1995b) used KDEs to\nestimate the spatial log-density ratio. They applied a Monte Carlo test to an extended\ndata set and obtained a signiﬁcant result just at the incinerator location, although the\noverall test was not signiﬁcant.\n\nAny post hoc analysis must be interpreted with care. Using Stone’s (1988) method,\nElliot et al. (1992b) examined nine other incinerator sites as well as the incinerator at\nCharnock Richard and found no evidence for excessive laryngeal cancer at any site.\nFurthermore, an important caveat that must be issued about all analyses of these\ndata concerns the extent to which the lung cancer controls are surrogates for the\npopulation at risk, given that ‘background’ incidence rates of lung cancer and\nlaryngeal cancer appear to vary (Smans et al., 1992). One possible advantage of using\nlung cancer as a control is that ‘smoking’ is a major common risk factor, so that this\nbecomes, in e(cid:128)ect, an adjustment for smoking behaviour.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU",
    "chunk_order_index": 12,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-d5c726a670ab5205d1524851fd48e84f": {
    "tokens": 1200,
    "content": "p\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\n5.2. Scan and Integrated Squared Di(cid:128)erence Statistics in General\nThe ISD statistic is likely to have lower power against clustering (in the sense of\nan increase in ‘risk’) than a statistic deﬁned, explicitly, to search for this feature.\nHowever, the ISD statistic should be useful for more general comparisons of two\nspatial patterns of events, and so it merits consideration. Although the asymptotic\nis normal, in practice a Monte Carlo implementation of the\ndistribution of Th1h2\nbootstrap seems to be the most feasible approach to hypothesis testing. The south\nLancashire data analysis suggests that the statistic could fail to detect a small scale\ncluster if the associated increase in density of the cases is masked by the bias of the\ncorresponding KDE, or if the di(cid:128)erence in the biases of the two KDEs reduces the\nprominence of the peak in the squared di(cid:128)erence surface in the region of the\naggregation.\n\nOur results indicate that the smoothing parameters employed in the calculation\nshould be larger than those that would be used simply to estimate the den-\nof Th1h2\nsity, but it would clearly be desirable to ﬁnd some objective method of selecting\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f102\n\nANDERSON AND TITTERINGTON\n\n[Part 1,\n\nsmoothing parameters. A possible line of enquiry is o(cid:128)ered by the results of\nJones and Sheather (1991), who considered the nonparametric estimation of the\nfunctionals\n\n(cid:133)\n\nf (cid:133)m(cid:134)(cid:133)x(cid:134)2 dx,\n\nm (cid:136) 0, 1, 2, : : :,\n\n(cid:133)5:1(cid:134)\n\nwhere a superscript ‘(m)’ represents an mth-order derivative, by replacing f (·) with its\nKDE. The smoothing parameter suitable for estimating expression (5.1) is di(cid:128)erent\nfrom that appropriate for estimating f (·), and the same may be true for the ISD\nis qualitatively similar to expression (5.1) for m (cid:136) 0. If the\nstatistic, since Th1h2\ntwo smoothing parameters are taken to be equal and ﬁxed, i.e. independent of\nsample size, then an asymptotic argument and empirical results in Anderson et al.\n(1994) show that the power is increased for a number of clustering alternatives.\n^f1(·) and ^f2(·)\nFurthermore, as the smoothing parameters increase, the biases of\nincrease but may largely cancel out, which could improve the sensitivity of the ISD\ntest. This also suggests that we take h1 (cid:136) h2. However, tests of signiﬁcance may still\nbe a(cid:128)ected by KDEs with large variability.\n\nEmpirical\n\ninvestigations of the power of the two-dimensional scan statistic\nsuggested that the probability of detecting a genuine cluster would be maximized by\nsetting the size of the scanning window to approximately that of the cluster itself. In\npractice, of course, the extent of any cluster will be unknown, but one might carry\nout signiﬁcance tests for a range of values of the square size constant d and apply a\ncorrection for multiple testing at each stage.\n\nThe approximate method seems to be reliable if either the target size of the\nscanning window is very small or if higher order terms are retained in the approx-\nimation. Otherwise, a more robust algorithm would be desirable. One possibility uses\na piecewise constant approximation to the density estimate of f (·, ·) in equation (4.3),\nconstructed from values of the KDE, denoted by eij, calculated at each point (i, j) of a\nvery ﬁne square grid of mesh size g, say, overlaying the region of interest. The volume\nunder the KDE bounded by a square W is easily approximated, by summing the\ncontributions g2eij for each grid point contained within W. Hence, the length of the\nside of a scanning square at a particular location can be set to (m (cid:255) 1)g, where m is\nthe maximum number of grid points in each axis direction allowing an approximate\nvolume, as deﬁned above, that does not exceed d 2=AB. Alternatively, instead of\nbasing the modiﬁcation on Weinstock (1981), it might be possible to allow for a non-\nuniform null distribution in other ways, e.g. by using a cartogram (Schulman et al.,\n1988) or a bootstrap signiﬁcance test (Hinkley, 1988) based on a second set of\ncontrols",
    "chunk_order_index": 13,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-f11345fca3c79f9044a7fd6be68899dd": {
    "tokens": 1200,
    "content": "approximate\nvolume, as deﬁned above, that does not exceed d 2=AB. Alternatively, instead of\nbasing the modiﬁcation on Weinstock (1981), it might be possible to allow for a non-\nuniform null distribution in other ways, e.g. by using a cartogram (Schulman et al.,\n1988) or a bootstrap signiﬁcance test (Hinkley, 1988) based on a second set of\ncontrols, which would be necessary to ensure that resampling was carried out under\nthe null hypothesis (Hall and Wilson, 1991).\n\nBoth the ISD and the scan statistics may be a(cid:128)ected by the boundary of the study\nregion. The e(cid:128)ect on the ISD statistic from the absence of information outside this\nregion should be less, because both estimates should be in error by approximately the\nsame amount. The scan statistic will normally depend on a single KDE: that for the\ncontrols. To avoid inaccuracies near the boundary, the KDE could be based on a\nsample of controls from a region much larger than, but containing, the region from\nwhich cases were obtained. A more complex alternative would be to incorporate\nsome form of edge correction.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1997]\n\nSPATIAL CLUSTERING\n\nACKNOWLEDGEMENTS\n\n103\n\nThe authors are indebted to Professor P. J. Diggle and Dr A. C. Gatrell for\ngranting access to the Lancashire cancer data. They are also very grateful to\nProfessor Diggle, for many helpful comments on an earlier version of this material,\nto Dr F. E. Alexander, for much encouragement and insight into the general topic of\ndisease clustering, and to the reviewers for their many helpful suggestions. Much of\nthis work was done while NHA held a research studentship from the UK Science and\nEngineering Research Council.\n\nAPPENDIX A: CALCULATION OF SCAN STATISTIC FOR CIRCULAR SCANNING\nWINDOW OF DIAMETER d\n\n(a) Identify the locations (x1, x2) of a pair of cases that are no more than distance d\n\napart.\n\n(b) Construct the (two) circles of diameter d for which x1 and x2 lie on the circumference.\n(c) Identify the numbers of cases that lie on or inside each of the two circles and let n12 be\n\nthe larger of those two numbers.\n\n(d) Repeat (a)–(c) for all relevant pairs of locations and report the largest of the resulting\n\nn12-values as being the scan statistic.\n\nREFERENCES\n\nAlexander, F. E. (1991) Investigations of localised spatial clustering and extra-Poisson variation. In The\nGeographical Epidemiology of Childhood Leukaemia and Non-Hodgkin Lymphomas in Great Britain,\n1966–83 (ed. G. Draper). London: Her Majesty’s Stationery O(cid:129)ce.\n\nAnderson, N. H. (1994) A test statistic for comparing two kernel density estimates. Technical Report 94-\n\n5. Department of Statistics, University of Glasgow, Glasgow.\n\nAnderson, N. H., Hall, P. and Titterington, D. M. (1994) Two-sample test statistics for measuring\ndiscrepancies between two multivariate probability density functions using kernel-based density\nestimates. J. Multiv. Anal., 50, 41–54.\n\nAnderson, N. H. and Titterington, D. M. (1994) Methods for investigating spatial clustering, with\nepidemiological applications. Technical Report 94-9. Department of Statistics, University of Glasgow,\nGlasgow.\n\n— (1995) A comparison of two statistics for detecting clustering in one dimension. J. Statist.\n\nComputn Simuln, 53, 103–125.\n\nBesag, J. and Newell, J. (1991) The detection of clusters in rare diseases. J. R. Statist. Soc. A, 154, 143–\n\n155.\n\nBithell, J. F. (1990) An application of density estimation to geographical epidemiology. Statist. Med., 9,\n\n691–701.\n\nBithell, J. F. and Stone, R. A. (1989) On statistical methods for analysing the geographical distribution\n\nof cancer cases near nuclear installations. J. Epidem. Commty Hlth, 43, 79–85.\n\nBlack, D. (1984) Investigation of the Possible Increased Incidence of Cancer in West Cumbria. London:\n\nHer Majesty’s Stationery O(cid:129)ce.\n\nBlack, R. J., Sharp, L.",
    "chunk_order_index": 14,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-aaef47a3d43db627e073d81f1e387ce2": {
    "tokens": 1200,
    "content": "701.\n\nBithell, J. F. and Stone, R. A. (1989) On statistical methods for analysing the geographical distribution\n\nof cancer cases near nuclear installations. J. Epidem. Commty Hlth, 43, 79–85.\n\nBlack, D. (1984) Investigation of the Possible Increased Incidence of Cancer in West Cumbria. London:\n\nHer Majesty’s Stationery O(cid:129)ce.\n\nBlack, R. J., Sharp, L. and Urquhart, J. D. (1991) An analysis of the geographical distribution of\nchildhood leukaemia and non-Hodgkin lymphomas in Great Britain using areas of approximately\nequal population size. In The Geographical Epidemiology of Childhood Leukaemia and Non-Hodgkin\nLymphomas in Great Britain, 1966–83 (ed. G. Draper). London: Her Majesty’s Stationery O(cid:129)ce.\nBowman, A. W. (1984) An alternative method of cross-validation for the smoothing of density\n\nestimates. Biometrika, 71, 353–360.\n\nCuzick, J. and Edwards, R. (1990) Spatial clustering for inhomogeneous populations (with discussion).\n\nJ. R. Statist. Soc. B, 52, 73–104.\n\nDiggle, P. J. (1985) A kernel method for smoothing point process data. Appl. Statist., 34, 138–147.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f104\n\nANDERSON AND TITTERINGTON\n\n[Part 1,\n\n— (1990) A point process modelling approach to raised incidence of a rare phenomenon in the\n\nvicinity of a prespeciﬁed point. J. R. Statist. Soc. A, 153, 349–362.\n\nDiggle, P. J. and Chetwynd, A. G. (1991) Second order analysis of spatial clustering for inhomogeneous\n\npopulations. Biometrics, 47, 1155–1163.\n\nDiggle, P. J., Gatrell, A. C. and Lovett, A. A. (1990) Modelling the prevalence of cancer of the larynx in\npart of Lancashire: a new methodology for spatial epidemiology. In Spatial Epidemiology (ed. R. W.\nThomas). London: Pion.\n\nDiggle, P. J. and Marron, J. S. (1988) Equivalence of smoothing parameter selectors in density and\n\nintensity estimation. J. Am. Statist. Ass., 83, 793–800.\n\nDiggle, P. J. and Rowlingson, B. S. (1994) A conditional approach to point process modelling of\n\nelevated risk. J. R. Statist. Soc. A, 157, 433–440.\n\nDoll, R. (1989) The epidemiology of childhood leukaemia. J. R. Statist. Soc. A, 152, 341–351.\nDraper, G. (ed.) (1991) The Geographical Epidemiology of Childhood Leukaemia and Non-Hodgkin\n\nLymphomas in Great Britain, 1966–83. London: Her Majesty’s Stationery O(cid:129)ce.\n\nElliot, P., Cuzick, J., English, D. and Stern, R. (eds) (1992a) Geographical and Environmental\n\nEpidemiology: Methods for Small-area Studies. Oxford: Oxford University Press.\n\nElliot, P., Hills, M., Beresford, J., Kleinschmidt, I., Jolley, D., Pattenden, S., Rodrigues, L., Westlake,\nA. and Rose, G. (1992b) Incidence of cancers of the larynx and lung near incinerators of waste\nsolvents and oils in Great Britain. Lancet, 339, 854–858.\n\nGardner, M. J. (1989) Review of reported increases of childhood cancer rates in the vicinity of nuclear\n\ninstallations in the UK. J. R. Statist. Soc. A, 152, 307–325.\n\nGibbons, J. D. (1986) Randomized tests. In Encyclopedia of Statistical Sciences, vol. 7 (eds S. Kotz,\n\nN. L. Johnson and C. B. Read), pp. 548–549. New York: Wiley.\n\nHall, P. (1984) Central limit theorem for integrated square error of multivariate nonparametric density\n\nestimators. J. Multiv. Anal.,",
    "chunk_order_index": 15,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-d1dcd73f0fa823dada33609adf37b7cb": {
    "tokens": 1200,
    "content": "A, 152, 307–325.\n\nGibbons, J. D. (1986) Randomized tests. In Encyclopedia of Statistical Sciences, vol. 7 (eds S. Kotz,\n\nN. L. Johnson and C. B. Read), pp. 548–549. New York: Wiley.\n\nHall, P. (1984) Central limit theorem for integrated square error of multivariate nonparametric density\n\nestimators. J. Multiv. Anal., 14, 1–16.\n\nHall, P. and Hart, J. D. (1990) Bootstrap test for di(cid:128)erence between means in nonparametric regression.\n\nJ. Am. Statist. Ass., 85, 1039–1049.\n\nHall, P. and Wilson, S. R. (1991) Two guidelines for bootstrap hypothesis testing. Biometrics, 47, 757–\n\n762.\n\nHills, M. and Alexander, F. (1989) Statistical methods used in assessing the risk of disease near a source\n\nof possible environmental pollution: a review. J. R. Statist. Soc. A, 152, 353–363.\n\nHinkley, D. V. (1988) Bootstrap methods. J. R. Statist. Soc. B, 50, 321–337.\nJones, M. C. and Sheather, S. J. (1991) Using non-stochastic terms to advantage in kernel-based\n\nestimation of integrated squared density derivatives. Statist. Probab. Lett., 11, 511–514.\nKelsall, J. E. and Diggle, P. J. (1995a) Kernel estimation of relative risk. Bernoulli, 1, 3–16.\n— (1995b) Non-parametric estimation of spatial variation in relative risk. Statist. Med., 14, 2335–\n\n2342.\n\nKinlen, L. J. (1988) Evidence for an infective cause for childhood leukaemia: a Scottish new town\n\ncompared to nuclear reprocessing sites. Lancet, ii, 1323–1326.\n\nLawson, A. B. and Williams, F. L. R. (1994) Armadale: a case-study in environmental epidemiology.\n\nJ. R. Statist. Soc. A, 157, 285–298.\n\nLyon, J. L., Klauber, M. R., Gra(cid:128), W. and Chiu, G. (1981) Cancer clustering around point sources of\n\npollution: assessment by a case-control methodology. Environ. Res., 25, 29–34.\n\nMarshall, R. J. (1991) A review of methods for the statistical analysis of spatial patterns of disease. J. R.\n\nStatistic. Soc. A, 154, 421–441.\n\nNaus, J. I. (1965a) The distribution of the size of the maximum cluster of points on a line. J. Am. Statist.\n\nAss., 60, 532–538.\n\n— (1965b) Clustering of random points in two dimensions. Biometrika, 52, 263–267.\n— (1966) Some probabilities, expectations and variances for the size of largest clusters and smallest\n\nintervals. J. Am. Statist. Ass., 61, 1191–1199.\n\n— (1988) Scan statistics. In Encyclopedia of Statistical Sciences, vol. 8 (eds S. Kotz, N. L. Johnson\n\nand C. B. Read), pp. 281–285. New York: Wiley.\n\nOpenshaw, S. (1990) Automating the search for cancer clusters: a review of problems, progress and\n\nopportunities. In Spatial Epidemiology (ed. R. W. Thomas). London: Pion.\n\nOpenshaw, S., Charlton, M. and Craft, A. (1988) Searching for leukaemia clusters using a Geographical\n\nAnalysis Machine. Pap. Regl Sci. Ass., 64, 95–106.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5\n\n \n \n \n \n \n \n \n \n \n \n \n \n\f1997]\n\nSPATIAL CLUSTERING\n\n105\n\nOpenshaw, S., Charlton, M., Wymer, C. and Craft, A. (1987) A Mark 1 Geographical Analysis\nMachine for the automated analysis of point data sets. Int. J. Geogr. Inform. Syst., 1, 335–358.\n\nRubinstein, R. Y. (1981) Simulation and the Monte Carlo Method. New York: Wiley.\nSchulman, J., Selvin, S",
    "chunk_order_index": 16,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-612f7f994d45346fd840a02bb349ba25": {
    "tokens": 771,
    "content": "105\n\nOpenshaw, S., Charlton, M., Wymer, C. and Craft, A. (1987) A Mark 1 Geographical Analysis\nMachine for the automated analysis of point data sets. Int. J. Geogr. Inform. Syst., 1, 335–358.\n\nRubinstein, R. Y. (1981) Simulation and the Monte Carlo Method. New York: Wiley.\nSchulman, J., Selvin, S. and Merrill, D. W. (1988) Density Equalised Map Projections: a method for\n\nanalysing clustering around a ﬁxed point. Statist. Med., 7, 491–505.\n\nSilverman, B. W. (1986) Density Estimation for Statistics and Data Analysis. London: Chapman and\n\nHall.\n\nSilverman, B. W. and Young, G. A. (1987) The bootstrap: to smooth or not to smooth? Biometrika, 74,\n\n469–479.\n\nSmans, M., Muir, C. S. and Boyle, P. (eds) (1992) Atlas of Cancer Mortality in the European Economic\n\nCommunity. Lyon: International Agency for Research on Cancer.\n\nStone, R. A. (1988) Investigations of excess environmental risks around putative sources: statistical\n\nproblems and a proposed test. Statist. Med., 7, 649–660.\n\nTurnbull, B. W., Iwano, E. J., Burnett, W. S., Howe, H. L. and Clark, L. C. (1990) Monitoring for\nclusters of disease: application to leukaemia incidence in upstate New York. Am. J. Epidem., 132,\nsuppl. 1, S136–S143.\n\nWakeford, R. (1990) Some problems in the interpretation of childhood leukaemia clusters. In Spatial\n\nEpidemiology (ed. R. W. Thomas). London: Pion.\n\nWakeford, R., Binks, K. and Wilkie, D. (1989) Childhood leukaemia and nuclear installations. J. R.\n\nStatist. Soc. A, 152, 61–86.\n\nWeinstock, M. J. (1981) A generalised Scan Statistic test for the detection of clusters. Int. J. Epidem., 10,\n\n289–293.\n\nWhittemore, A. S., Friend, N., Brown, B. W. and Holly, E. A. (1987) A test to detect clusters of disease.\n\nBiometrika, 74, 631–635.\n\nl\n\nD\no\nw\nn\no\na\nd\ne\nd\n\nf\nr\no\nm\nh\n\nt\nt\n\np\ns\n:\n/\n/\n\ni\n\na\nc\na\nd\ne\nm\nc\n.\no\nu\np\n.\nc\no\nm\n\nl\n\n/\n\n/\n\n/\n\n/\n\n/\n\n/\nj\nr\ns\ns\ns\na\na\nr\nt\ni\nc\ne\n1\n6\n0\n1\n8\n7\n7\n1\n0\n2\n3\n7\n4\nb\ny\nU\nn\nv\ne\nr\ns\ni\nt\ny\no\n\ni\n\nf\n\ni\n\nT\ne\nx\na\ns\nL\nb\nr\na\nr\ni\ne\ns\nu\ns\ne\nr\no\nn\n1\n2\nJ\nu\nn\ne\n2\n0\n2\n5",
    "chunk_order_index": 17,
    "full_doc_id": "doc-8d0089c208c5e3097daef98f413d9a46"
  },
  "chunk-4f70d67e410d4a68e18cd17d98f52084": {
    "tokens": 1200,
    "content": "Automobile Status ReportSouth Point Hyundai Genesis4610 S IH 35 Frontage RdAustin, TX 78745South Point Hyundai Genesis ZEPING LIU5127866656zpl.geo@gmail.com2022 Hyundai SONATADate May 27, 2025VIN 5NPEG4JA5NH148140Mileage 15001RO# 884676Prepared ForCONOR LOGANCONOR@SOUTHPOINTAUTO.COM5124420300Service Advisor\fSouth Point Hyundai GenesisService CommitmentExcellence at every turn... and every straightawayOur dealership's primary goal is to satisfy every customer at every opportunity. You visitour service department regularly, and we have developed a number of ways to makeyour visit more comfortable and informative. We know that you want straight answers,and that’s the only way we will deliver it to you.We understand that your knowledge of your vehicle and its necessary repairs isprobably not on par with the understanding that your technician has. In order to besure that his findings and reporting is as clear and concise as possible, we use thisVehicle Information Booklet as a tool to help us communicate your vehicle's conditionto you.Our technicians are the most qualified to work on your vehicle. They have trainedextensively, and partake in continuing education regularly to be sure that they are up todate on any changes and improvements handed down from the manufacturer. Ourservice advisors strive to make your experience with us a pleasant one. They are here toattend to your automotive needs as well as communicate effectively with yourtechnician and you.Please make yourself comfortable in our waiting area. Watch some TV, use your laptopwith our free WI-FI access or just relax and enjoy the quiet. Our courtesy shuttle cantake you shopping, to a movie or home if you prefer.We appreciate your business and will continue to strive for excellence in everything wedo for you.\fMulti-Point Inspection FormZEPING LIUVIN 5NPEG4JA5NH148140Advisor CONOR LOGANTechnician Eloy GarciaCreated On 5/27/2025RO# 884676Checked and OK at this timeMay Require Future AttentionRequires immediate attentionBulbs and LightsWindshield Washer Spray / Wiper Operation/ Wiper Blades / Including Rear (if applicable)Windshield / Window ConditionUpholstery / Carpet / Floor Mats / Mirrors /TrimEmergency Brake AdjustmentHorn OperationFuel Tank Cap GasketClutch Operation (if equipped)Cabin/HEPA Filter (if equipped)Interior / ExteriorBattery Terminals / Cables / MountingsCheck Condition of Battery (Storage CapacityTest if Applicable)Battery PerformanceFluids: Oil / Coolant / Power Steering / BrakeFluid / WasherEngine Air FilterBelts / Tensioners (condition andadjustment)Cooling System Hoses / Heater Hoses / AirConditioning Hoses and ConnectionsRadiator Core / Air Conditioning Condenser(if equipped)Under HoodShock Absorbers / SuspensionSteering Gear Box / Linkage and Boots / BallJoints / Dust CoversMuffler / Exhaust Pipes / MountingsEngine Oil and/or Fluid LeaksDrive Shaft Boots / Constant Velocity Boots /U-joints / Transmission Linkage (if equipped)Transmission / Differential / Transfer Case(Check Fluid Level, Fluid Condition and FluidLeaks)Fuel Lines and Connections / Fuel Tank Band/ Fuel Tank Vapor Vent System HosesInspect Nuts and Bolts on Body ChassisUnder Vehicle9LF9RF9LR9RR10Spare Tire (if applicable)35LF/RF Tire Pressure35LR/RR Tire PressureTread Depth (measured in 1/32\")LFRFLRRRAbnormal Wear Pattern of Tires9LF9RF9LR9RRCheck Brake Linings (measured in millimeters)State Inspection StickerState InspectionPrepared By\fInitial ConcernsThe service(s) listed below are therecommendations made by your technicianEloy G as the repair necessary to resolve yourinitial concern.Red: requires immediate attention.Yellow: in need of attention soon.*Battery Replacement: BATTERYDEAD DUE TO BREAK IN IGNITIONWAS LEFT ON POISSBLEItem DescriptionThe battery, in conjunction with the alternator,supplies power for engine cranking and electricalpower needed for the lights, stereo, and all otherelectrical components.ReasonIf the battery is not replaced periodically, thebattery will fail. Also, a defective battery cancontribute to starter failure.Battery[Other]: DAMAGED IGNITION KEYHOUSINGItem DescriptionSpeak with your service advisor for moreinformation on this recommended service.Reason[Other]: DAMAGED LOWER STEERINGCOLUMN COVER ASSY.Item DescriptionSpeak with your service advisor for moreinformation on this recommended service.Reason[Other]: REKEY NEW IGNITON KEYAND CYLINDER\fItem DescriptionSpeak with your service advisor for moreinformation on this recommended service.ReasonDoor Glass Replacement: RIGHTREAR DOOR GLASS BROKENItem DescriptionThis is the replacement process for the glasswindow of the door of the vehicle.ReasonIf not replaced broken glass can be not only aninconvenience, but also a safety hazard as brokenor jagged pieces of glass can remain exposed untilthe new window has been replaced.[Other]: IGNTION COMPLETE KEYCYLINDER AT STEERING COLUMNDAMAGEDItem DescriptionSpeak with your service advisor for moreinformation on this recommended service.ReasonAdditional ServiceRecommendationsIn the process of inspecting your vehicle forsafety and reliability, your technician Eloy Gmade the following observations andrecommends that you do the necessary repairsto resolve these issues.Red: requires immediate attention.Yellow: in need of attention soon.\fRepair EstimateService AdvisorCONOR LOGAN (9449)CONOR@SOUTHPOINTAUTO.COMPREPARED FORZEPING LIUDate 05/27/2025 05:40 PM2022 Hyundai SONATAVIN 5NPEG4JA5NH148",
    "chunk_order_index": 0,
    "full_doc_id": "doc-e025b4870c852c28f56dc326587d1ce0"
  },
  "chunk-3d29072677a1552e569073c5788ab7d7": {
    "tokens": 332,
    "content": "and reliability, your technician Eloy Gmade the following observations andrecommends that you do the necessary repairsto resolve these issues.Red: requires immediate attention.Yellow: in need of attention soon.\fRepair EstimateService AdvisorCONOR LOGAN (9449)CONOR@SOUTHPOINTAUTO.COMPREPARED FORZEPING LIUDate 05/27/2025 05:40 PM2022 Hyundai SONATAVIN 5NPEG4JA5NH148140Mileage 15,001RO# 884676$3137.43Subtotal$54.95Shop Charges$143.25Tax$3335.63TotalService NamePrice[Primary]: 55HYZ01 : DIAGNOSE NO START$259.95*Battery Replacement: BATTERY DEAD DUE TO BREAK IN IGNITION WAS LEFT ON POISSBLE$406.43[Other]: DAMAGED IGNITION KEY HOUSING$1072.50[Other]: DAMAGED LOWER STEERING COLUMN COVER ASSY.$276.90[Other]: REKEY NEW IGNITON KEY AND CYLINDER$242.56Door Glass Replacement: RIGHT REAR DOOR GLASS BROKEN$762.65[Other]: IGNTION COMPLETE KEY CYLINDER AT STEERING COLUMN DAMAGED$116.44[Primary]: 34HYZHE02 : 25 POINT INSPECTION$0.00Printed on May 27, 2025Quote expires on June 26, 2025South Point Hyundai Genesis4610 S IH 35 Frontage RdAustin, TX 78745877-850-6166",
    "chunk_order_index": 1,
    "full_doc_id": "doc-e025b4870c852c28f56dc326587d1ce0"
  },
  "chunk-336e487cfea88c0648dec81b7291e275": {
    "tokens": 1200,
    "content": "The Handbook of Geographic Information ScienceTHO_A01  19/03/2007  11:07  Page i\fBlackwell Companions to GeographyBlackwell Companions to Geographyis a blue-chip, comprehensive series cover-ing each major subdiscipline of human geography in detail. Edited and contributedto by the disciplines’ leading authorities each book provides the most up to dateand authoritative syntheses available in its ﬁeld. The overviews provided in eachCompanion will be an indispensable introduction to the ﬁeld for students of alllevels, while the cutting-edge, critical direction will engage students, teachers, andpractitioners alike.Published1.A Companion to the CityEdited by Gary Bridge and Sophie Watson2.A Companion to Economic GeographyEdited by Eric Sheppard and Trevor J. Barnes3.A Companion to Political GeographyEdited by John Agnew, Katharyne Mitchell, and Gerard Toal (Gearoid O Tuathail)4.A Companion to Cultural GeographyEdited by James S. Duncan, Nuala C. Johnson, and Richard H. Schein5.A Companion to TourismEdited by Alan A. Lew, C. Michael Hall, and Allan M. Williams6.A Companion to Feminist GeographyEdited by Lise Nelson and Joni Seager7.The Handbook of Geographic Information ScienceEdited by John P. Wilson and A. Stewart FotheringhamTHO_A01  19/03/2007  11:07  Page ii Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fThe Handbook of GeographicInformation ScienceEdited byJohn P. WilsonandA. Stewart FotheringhamTHO_A01  19/03/2007  11:07  Page iii Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f© 2008 by Blackwell Publishing LtdBLACKWELL PUBLISHING350 Main Street, Malden, MA 02148-5020, USA9600 Garsington Road, Oxford OX4 2DQ, UK550 Swanston Street, Carlton, Victoria 3053, AustraliaThe right of John P. Wilson and A. Stewart Fotheringham to be identiﬁed as the Authors of the Editorial Material in this Work has been asserted in accordance with the UK Copyright, Designs, and Patents Act 1988.All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by any means, electronic, mechanical, photocopying, recording or otherwise, except as permitted by the UK Copyright, Designs, and Patents Act 1988, without the prior permission of the publisher.First published 2008 by Blackwell Publishing Ltd12008Library of Congress Cataloging-in-Publication DataThe handbook of geographic information science / edited by John P. Wilson and A. StewartFotheringham.p. cm. — (Blackwell companions to geography)Includes bibliographical references and index.ISBN 978-1-4051-0795-2 (hardback : alk. paper) — ISBN 978-1-4051-0796-9 (pbk. : alk. paper)1.Geography—Data processing.2.Geographic information systems.I.Wilson, John P. (JohnPeter), 1955–II.Fotheringham, A. Stewart.G70.2.H3562008910.285—dc222007008297A catalogue record for this title is available from the British Library.Set in 10/12pt Sabonby Graphicraft Limited, Hong KongPrinted and bound in Singaporeby Utopia Press Pte LtdThe publisher’s policy is to use permanent paper from mills that operate a sustainable forestry policy, and which has been manufactured from pulp processed using acid-free and elementarychlorine-free practices. Furthermore, the publisher ensures that the text paper and cover board used have met acceptable environmental accreditation standards.For further information onBlackwell Publishing, visit our website:www.blackwellpublishing.comTHO_A01  19/03/2007  11:07  Page iv Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fContentsList of FiguresviiiList of ContributorsxivGeographic Information Science: An Introduction1Part IData Issues91The Availability of Geographic Data: The Current Technical and Institutional Environment11David J. Cowen2Social Data35David J. Martin3Remote Sensing49Brian G. Lees4Spatialization61André Skupin and Sara I. Fabrikant5Uncertainty in Spatial Databases80Ashley Morris6On the Identiﬁcation of Uncertainties in Spatial Data and Their Quantiﬁcation with Probability Distribution Functions94James D. Brown and Gerald B. M. HeuvelinkPart IIDatabase Trends and Challenges1097Object-Oriented Database Management Systems111Shashi Shekhar and Ranga Raju Vatsavai8Adding the Z Dimension144Michael F. HutchinsonTHO_A01  20/03/2007  14:",
    "chunk_order_index": 0,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0595f356d691980614a030576f827f87": {
    "tokens": 1200,
    "content": "Spatial Databases80Ashley Morris6On the Identiﬁcation of Uncertainties in Spatial Data and Their Quantiﬁcation with Probability Distribution Functions94James D. Brown and Gerald B. M. HeuvelinkPart IIDatabase Trends and Challenges1097Object-Oriented Database Management Systems111Shashi Shekhar and Ranga Raju Vatsavai8Adding the Z Dimension144Michael F. HutchinsonTHO_A01  20/03/2007  14:46  Page v Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fviCONTENTS9Adding Time into Geographic Information System Databases169May Yuan10Geospatial Data Integration185Craig A. Knoblock and Cyrus ShahabiPart IIIVisualization19711Mapping in a Digital Age199William E. Cartwright12Generalization of Spatial Databases222William A. Mackaness13Geographic Information Systems and Surfaces239Nicholas J. Tate, Peter F. Fisher, and David J. Martin14Fuzzy Classiﬁcation and Mapping259Vincent B. Robinson15Rule-Based Mapping273A-Xing Zhu16Multivariate Geovisualization292Mark Gahegan17Virtual Reality in Geographic Information Systems317Michael BattyPart IVKnowledge Elicitation33518Inference and Spatial Data337Chris Brunsdon19Geographic Data Mining and Knowledge Discovery352Harvey J. Miller20The Geospatial Semantic Web367Frederico FonsecaPart VSpatial Analysis37721Quantitative Methods and Geographic Information Systems379Martin E. Charlton22Spatial Cluster Analysis395Geoffrey M. Jacquez23Terrain Analysis417Yongxin Deng, John P. Wilson, and John C. Gallant24Dynamic Modeling436Jochen AlbrechtTHO_A01  20/03/2007  14:46  Page vi Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fCONTENTSviiPart VIGeographic Information Systems and Society44725Institutional Geographic Information Systems and Geographic Information Partnering449David L. Tulloch26Participatory Geographic Information Systems466Daniel Weiner and Trevor M. Harris27Geographic Information Systems and Participatory Decision Making481Piotr Jankowski and Timothy L. Nyerges28Surveys of People and Place494Peter H. Dana29Geographic Information Science, Personal Privacy, and the Law519George C. H. Cho30Geographic Information Systems in Education540Joseph J. KerskiPart VIIFuture Trends and Challenges55731Web-based Geographic Information Systems559Christopher B. Jones and Ross S. Purves32Location-based Services and Geographic Information Systems581Allan J. Brimicombe33Geographic Information Science: The Grand Challenges596Michael F. Goodchild34Geographic Information Science: Where Next?609Andreas Reuter and Alexander ZipfIndex620THO_A01  20/03/2007  14:46  Page vii Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFigures0.1Geographic Information Science (GISc): An Overview21.1Geographic data marketplace131.2Data ﬂow to and from government161.3Fundamental issues in spatial data transfer181.4The Spatial Data Transfer Standard181.5Content standard for digital geospatial metadata221.6FGDC decision tree231.7FGDC steps to create a clearinghouse241.8Geospatial One-Stop261.9US Fish and Wildlife Service Wetlands Mapper271.10The National Map281.11The National Map Seamless Data Distribution System Viewer291.12The National Atlas311.13The Geography Network322.1Comparison of principal social data sources383.1Some typical platforms and instrument packages504.1Census-based visualization of trajectories of Texas counties654.2Cases of convergence and divergence in a spatialization of Texas county trajectories654.3Scatter plots derived from demographic data for US states664.4Spatializations derived from 32 demographic variables664.5Portion of a spatialization of conference abstracts694.6Procedure for deriving a spatialization from AAG conference abstracts704.7Conference abstract as unstructured text714.8Conference abstract in semi-structured form as part of an XML ﬁle714.9Application of spring model layout and pathﬁnder network scaling734.10The tree map method744.11Use of GIS in implementing scale-dependent spatialization74THO_A01  19/03/2007  11:07  Page viii Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFIGURESix5.1Case in which the points are stored in the database and connected in order from the last point back to the ﬁrst point845.",
    "chunk_order_index": 1,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-427973f26133d78656a3a18f0eb7f8b8": {
    "tokens": 1200,
    "content": "linelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFIGURESix5.1Case in which the points are stored in the database and connected in order from the last point back to the ﬁrst point845.2Case in which the segments between the points are connected in no particular order847.1Evolution of databases1127.2Census blocks with boundary ID:10501157.3Four tables required in a relational database with overlapping attributes1157.4Three-layer architecture1187.5An OGIS proposal for building blocks of spatial geometry in UML notation1197.6The buffer of a river and points within and outside the resultant buffer1358.1Contour, point elevation, and streamline data1488.2Minimum curvature gridding of point elevation data with spurious sinks or depressions1538.3Spurious sinks removed from the surface in Figure 8.2 by the drainage enforcement algorithm1548.4Contours and inferred stream lines and ridge lines derived by the ANUDEM procedure1558.5Plot of root mean square slope of a DEM versus DEM resolution1568.6Spline model of annual mean precipitation over topography1619.1Examples of representations of temporal information in a relational data model1749.2Examples of representations of spatio-temporal information in a GIS environment1759.3A conceptual framework for a three-domain model17710.1A wrapper converts the New York State Property Database intostructured data that can then be integrated with other sources18710.2Automatic conﬂation of vector data with imagery18910.3Integrating and reasoning about the property tax data, satellite imagery, and road vector data to identify the structures in an image19010.4Automatic conﬂation of maps with imagery19210.5Results of conﬂating MapQuest map with imagery19210.6Integration of train schedules with vector data and maps19411.1CEEFAX weather map20211.2Minitel “kiosk”20211.3Aspen Movie MapProject20411.4Surrogate walk from the Domesday Community disc20511.5Territorial evolution of Canada20611.6Ashdowne’s Virtual Atlas– initial text interface20711.7Perry-Castañeda Library, The University of Texas at Austin map of Australia20811.8CIA World Fact Book map of Australia20911.9MapQuest – Victoria, Australia21011.10Bodleian Library: Plan for rebuilding...London – J Evelyn 1666211THO_A01  19/03/2007  11:07  Page ix Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fxFIGURES11.11LandChannel, Government of Victoria21111.12WhereIs map information21211.13Australian Coastal Atlas21411.14National Atlas of Canada Quick Maps21511.15Atlas of Switzerland21611.16WAP-enabled cellular telephone delivering map information from Webraska21712.11:25,000, 1:100,000, and 1:250,00022412.2Generalization as a sequence of modeling operations22512.3Model and cartographic generalization acting in unison to reveal different qualities about The Tower of London22512.4Generalization in the context of automated solutions22712.5The choice, sequence, and degree of application of various methods enable synthesis of different solutions22912.6Transformations with decreasing map scale, and corresponding scale bands for a topographic map23112.7Examples drawn from paper maps of building generalization at various scales23112.8Decision tree for key buildings23212.9Different products according to theme and scale derived from the same source23313.1Sample frame for soil fertility characteristics24213.2Sample frame for LiDAR data24313.3A TIN generated from the points displayed in Figure 13.224513.4LiDAR derived raster hillshade, TIN, and TIN hillshade24613.5Perspective surface views and TINS with and without adaptive LOD proportional to the viewpoint24713.6Kernel estimation of a reference-interval function24813.7An isoline visualization or contour map24913.8A ﬁlled contour visualization of the same area as is shown in Figure 13.725013.9A psuedo-3D view of the same general area as is shown in Figure 13.725113.10A slope map of the same area as is shown in Figure 13.725213.11Hillshaded maps of the same area as is shown in Figure 13.725313.12A navigable 3D view of the area around the University of Leicester25414.1A simple example of typical results from using the FCM algorithm26515.1Knowledge-based approach to rule-based mapping under GIS27515.2Example of descriptive knowledge expressed as a rule for rule-based mapping27515.3A distribution of Soil Series Basco in Pleasant Valley, Wisconsin, USA28015.4The metrics of a fuzzy membership function28115.5Three basic forms of membership functions282THO_A01  19/03/2007  11:07  Page x Downloaded from https://onlinelibrary.wiley.com/doi/ by",
    "chunk_order_index": 2,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4da174298297ebd75d9e88e768907e32": {
    "tokens": 1200,
    "content": "-based approach to rule-based mapping under GIS27515.2Example of descriptive knowledge expressed as a rule for rule-based mapping27515.3A distribution of Soil Series Basco in Pleasant Valley, Wisconsin, USA28015.4The metrics of a fuzzy membership function28115.5Three basic forms of membership functions282THO_A01  19/03/2007  11:07  Page x Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFIGURESxi15.6The predicted distribution of Soil Series Basco in Pleasant Valley,Wisconsin, USA based on a fuzzy implementation of the rule in Figure 15.228515.7Predicted distribution of soil series in Pleasant Valley, Wisconsin, USA based on a Boolean implementation of the rules in Figure 15.828715.8Descriptive rules for soils in Pleasant Valley, Wisconsin, USA28715.9Predicted distribution of soil series in Pleasant Valley, Wisconsin, USA based on a fuzzy implementation of the rules in Figure 15.828815.10Uncertainty map associated with the soil map produced under the fuzzy implementation of the rules for the Pleasant Valley area28916.1Thematic map of population by county for the conterminous 48 states of the USA29716.2Visualization of changes in population growth and immigrant population using proportional circles29816.3Which inner circle seems bigger? A visual illusion concerning the size of circles29816.4Characterization of oil reservoirs through time29916.5A parallel coordinate plot (PCP) showing demographic and related information for the 48 conterminous US states30016.6Multiple scatterplots and bivariate maps of demographics and cancer-related data, organized in a matrix30116.7Scatterplot matrix showing land cover data and decision tree rules used in classifying the data30216.8A surface produced by clustering US states based on their demographic properties30316.9The city of London during the seventeenth century30416.10A concept map depicting events that have shaped the landscape of central Pennsylvania30516.11A visualization of 100 census variables showing correlation and entropy30617.1The basic geometric model built in ArcSceneand an example of a ﬁnely rendered building imported into the scene32117.2A geographic “sea” showing the intensity of retail activity layered onto the 3D geometry of central London32317.3A typical ﬂy-through in virtual London32417.4Porting the digital model and various panoramas into a virtual world32617.5The Arthur interface32717.6Geographic visualization of web trafﬁc32917.7Interfaces to GIS using 3D globes33017.8Constructing the Simulacra33217.9Printing the virtual city using CAD/CAM technology33318.1The location of study area (LHS) and the houses in the samples (RHS)34218.2Posterior distribution for δ=µ1−µ2345THO_A01  19/03/2007  11:07  Page xi Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fxiiFIGURES19.1A concept hierarchy for location35519.2A data cube for trafﬁc data attributed by date, time of day, and station35619.3Trafﬁc map cube visualization by date, time of day, and station36019.4Trafﬁc map cube visualization by date, time of day, and geographic location36122.1Cluster morphology of cancer incidence on Long Island40522.2Cluster change and persistence40622.3Cluster change and persistence continued40722.4Cluster change and persistence continued40822.5Disparity clusters41022.6Information frames provide cogent summaries of the properties of spatial cluster statistics41223.1Schematic diagram showing site-speciﬁc, local, and regional interaction as a function of time41923.2Watershed modeling with GIS and WEPP42423.3Scale effects of terrain analysis43024.1Eight possible ATC commands for a single aircraft44025.1A conceptual diagram of multipurpose land information systemdevelopment45326.1The relations of GIS, participation, and the Internet in the case studies47028.1CCARC Central American mapping projects49628.2CCARC Nicaraguan map detail with large point symbols and line hatching indicating survey imprecision49928.3Tiling and overlaps in CCARC Nicaraguan Bloques50028.4Draft map of Krukira with straight lines between points50128.5Sketch map of Auka, Honduras50228.6Topographic map of Auka, Honduras50428.7Waterproof kit contents50528.8DGPS receiver and pocket PC with ArcPad data collection software51028.9GPS waterproof notebook pages51128.10Position types: Direct, indirect, registered, and estimated51228.11Land use categories and symbols for Nicaragua51328.12Land use categories and symbols for Honduras51428.13Final map of Auka, Honduras51528.14Land use differences in overlap between Ahuas and Wawina, Honduras51630.1PC monitor in Texas high school showing series of themes for Africa54130.2Dimensions of",
    "chunk_order_index": 3,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f40c6cf3b0ec52c8b3a824c36ea87fb7": {
    "tokens": 1200,
    "content": "data collection software51028.9GPS waterproof notebook pages51128.10Position types: Direct, indirect, registered, and estimated51228.11Land use categories and symbols for Nicaragua51328.12Land use categories and symbols for Honduras51428.13Final map of Auka, Honduras51528.14Land use differences in overlap between Ahuas and Wawina, Honduras51630.1PC monitor in Texas high school showing series of themes for Africa54130.2Dimensions of GIS education54230.3Student displaying the results of his GIS analysis in 3D55231.1Example from the Pont map collection56131.2City of Vallejo economic development information system56331.3Options for thematic map and resulting presentation of Scottish census data564THO_A01  19/03/2007  11:07  Page xii Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFIGURESxiii31.4The interface of the USGS seamless data distribution system56631.5An example search for data with GeoXWalk56731.6Three-tier web GIS architecture57031.7Open web services framework57231.8Interoperating web map Services57331.9Two representations of the same data using different style layerdescriptors and an extract from the SLD57431.10A thin client and a thick client57631.11Ordnance Survey MasterMap data displayed as SVG57631.12Example of the use of SVG57732.1The technological niche of LBS58332.2Experimental PDA interface for LBS that provides map, text and voice wayﬁnding instructions58532.3Basic system architecture for LBS58634.1Object-centric location models616THO_A01  19/03/2007  11:07  Page xiii Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fContributorsJochen AlbrechtDepartment of Geography, Hunter College, City University of New York, 695 Park Avenue, New York, NY 10021, USA. E-mail: jochen@geo.hunter.cuny.eduMichael BattyCentre for Advanced Spatial Analysis, University College London, 1–19Torrington Place, London WC1E 6BT, UK. E-mail: mbatty@geog.ucl.ac.ukAllan J. BrimicombeCentre for Geo-Information Studies, University of East London, Longbridge Road, Dagenham, Essex RM8 2AS, UK. E-mail: a.j.brimicombe@uel.ac.ukJames D. BrownInstitute for Biodiversity and Ecosystem Dynamics, Universiteit van Amsterdam, Nieuwe Achtergracht 166, 1018 WV Amsterdam, The Netherlands.E-mail: brown@science.uva.nlChris BrunsdonDepartment of Geography, University of Leicester, University Road, LeicesterLE1 7RH, UK. E-mail: cb179@lei.ac.ukWilliam E. CartwrightSchool of Mathematical and Geospatial Sciences, RMIT University, Melbourne,Victoria 3001, Australia. E-mail: w.cartwright@rmit.edu.auMartin E. CharltonNational Centre for Geocomputation, National University of Ireland, Maynooth,Ireland. E-mail: martin.charlton@may.ieTHO_A01  19/03/2007  11:07  Page xiv Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fCONTRIBUTORSxvGeorge C. H. ChoDivision of Health, Design and Science, University of Canberra, Canberra, ACT 2601, Australia. E-mail: george.cho@canberra.edu.auDavid J. CowenDepartment of Geography, University of South Carolina, Columbia, SC 29208,USA. E-mail: cowend@gwm.sc.eduPeter H. DanaPO Box 1297, Georgetown, TX 78627, USA. E-mail: pdana@pdana.comYongxin DengDepartment of Geography, Western Illinois University, Macomb, IL 61455-1390,USA. E-mail: Y-Deng2@wiu.eduSara I. FabrikantDepartment of Geography, University of Zurich, Winterthurestrasse 190, CH-8057 Zurich, Switzerland. E-mail: sara@geo.unizh.chPeter F. FisherSchool of Informatics, City University, Northampton Square, London, EC1V0HB, UK. E-mail: pff1@soi.city.ac.ukFrederico FonsecaSchool of Information Sciences and Technology, Pennsylvania State University,University Park, PA 16802-6823, USA. E-mail: fredfonseca@ist.psu.eduA. Stewart FotheringhamNational Centre for Geocomputation, National University of Ireland, Maynooth,Ireland. E-mail: stewart.fotheringham@may.ieMark GaheganGeoVISTA Center, Department of Geography, Pennsylvania State University,University",
    "chunk_order_index": 4,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-5aba194093078a7e9c3e7f024a2b5d99": {
    "tokens": 1200,
    "content": "1@soi.city.ac.ukFrederico FonsecaSchool of Information Sciences and Technology, Pennsylvania State University,University Park, PA 16802-6823, USA. E-mail: fredfonseca@ist.psu.eduA. Stewart FotheringhamNational Centre for Geocomputation, National University of Ireland, Maynooth,Ireland. E-mail: stewart.fotheringham@may.ieMark GaheganGeoVISTA Center, Department of Geography, Pennsylvania State University,University Park, PA 16802, USA. E-mail: mng1@psu.eduJohn C. GallantCSIRO Land and Water, GPO Box 1666, Canberra ACT 2601, Australia. E-mail: john.gallant@csiro.auMichael F. GoodchildNational Center for Geographic Information and Analysis, Department ofGeography, University of California, Santa Barbara, CA 93106-4060, USA. E-mail: good@geog.ucsb.eduTrevor M. HarrisDepartment of Geology and Geography, West Virginia University, Morgantown,WV 26506, USA. E-mail: trevor.harris@mail.wvu.eduTHO_A01  19/03/2007  11:07  Page xv Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fxviCONTRIBUTORSGerard B.M. HeuvelinkLaboratory of Soil Science and Geology, Wageningen University and Research Centre, PO Box 37, 6700 AA, Wageningen, The Netherlands. E-mail: gerard.heuvelink@wur.nlMichael F. HutchinsonCentre for Resource and Environmental Studies, Australian National University,Canberra ACT 0200, Australia. E-mail: hutch@cres.anu.edu.auGeoffrey M. JacquezBioMedware, Inc., 515 North State Street, Ann Arbor, MI 48104-1236, USA. E-mail: jacquez@biomedware.comPiotr JankowskiDepartment of Geography, San Diego State University, 5500 Campanile Drive,San Diego, CA 92182-4493, USA. E-mail: piotr@typhoon.sdsu.eduChristopher B. JonesDepartment of Computer Science, Cardiff University, Newport Road, PO Box 916, Cardiff, Wales CF24 3XF, UK. E-mail: c.b.jones@cs.cardiff.ac.ukJoseph J. KerskiEnvironmental Systems Research Institute, Inc., 1 International Court,Broomﬁeld, CO 80021-3200, USA. E-mail: jkerski@esri.comCraig A. KnoblockInformation Sciences Institute, University of Southern California, Marina delRey, CA 90292, USA. E-mail: knoblock.isi.eduBrian G. LeesSchool of Physical, Environmental and Mathematical Sciences, University of New South Wales at the Australian Defence Force Academy, Canberra, ACT 2600, Australia. E-mail: b.lees@adfa.edu.auWilliam A. MackanessSchool of Geosciences, University of Edinburgh, Drummond Street, Edinburgh,Scotland, EH8 9XP, UK. E-mail: william.mackaness@ed.ac.ukDavid J. MartinSchool of Geography, University of Southampton, Highﬁeld, Southampton SO17 1BJ, UK. E-mail: d.j.martin@soton.ac.ukHarvey J. MillerDepartment of Geography, University of Utah, Salt Lake City, UT 84112-9155,USA. E-mail: harvey.miller@geog.utah.eduTHO_A01  19/03/2007  11:07  Page xvi Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fCONTRIBUTORSxviiAshley MorrisSchool of Computer Science, Telecommunications, and Information Systems, DePaul University, Chicago, IL 60604, USA. E-mail:amorris@cti.depaul.eduTimothy L. NyergesDepartment of Geography, University of Washington, Seattle, WA 98195-3550,USA. E-mail: nyerges@u.washington.eduRoss S. PurvesDepartment of Geography, University of Zurich – Irchel, Winterthurerstr. 190,CH-8057 Zurich, Switzerland. E-mail: rsp@geo.unizh.chAndreas ReuterEuropean Media Laboratory, Schloss-Wolfsbrunnenweg 33, 69118 Heidelberg,Germany. E-mail: andreas.reuter@eml.orgVincent B. RobinsonDepartment of Geography, University of Toronto, Mississauga, Ontario L5L1C6, Canada. E-mail: vbr@eratos.erin.utoronto.caCyrus ShahabiIntegrated Media Systems Center, Viterbi School of Engineering, University of Southern California, Los Angeles, CA 90089-2561, USA. E-mail:cshahabi@pollux.usc.eduShashi ShekharDepartment of Computer Science and Engineering, University of Minnesota,Minneapolis, MN 55455, USA. E-mail: shekhar@.cs.umn.eduAndré SkupinDepartment of Geography, San Diego State University,",
    "chunk_order_index": 5,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ce00fe5d8005cd16cc3f522e9d07f4a2": {
    "tokens": 1200,
    "content": "onto.caCyrus ShahabiIntegrated Media Systems Center, Viterbi School of Engineering, University of Southern California, Los Angeles, CA 90089-2561, USA. E-mail:cshahabi@pollux.usc.eduShashi ShekharDepartment of Computer Science and Engineering, University of Minnesota,Minneapolis, MN 55455, USA. E-mail: shekhar@.cs.umn.eduAndré SkupinDepartment of Geography, San Diego State University, San Diego, CA 92182-4493, USA. E-mail: skupin@mail.sdsu.eduNicholas J. TateDepartment of Geography, University of Leicester, Leicester LE1 7RH, UK. E-mail: n.tate@le.ac.ukDavid L. TullochCenter for Remote Sensing and Spatial Analysis, Rutgers, State University of New Jersey, New Brunswick, NJ 08904, USA. E-mail:dtulloch@crssa.rutgers.eduRanga Raju VatsavaiDepartment of Computer Science and Engineering, University of Minnesota,Minneapolis, MN 55455, USA. E-mail: vatsavai@cs.umn.eduTHO_A01  19/03/2007  11:07  Page xvii Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fxviiiCONTRIBUTORSDaniel WeinerDepartment of Geology and Geography, West Virginia University, Morgantown,WV 26506, USA. E-mail: daniel.weiner@mail.wvu.eduJohn P. WilsonDepartment of Geography, University of Southern California, Los Angeles, CA 90089-0255, USA. E-mail: jpwilson@usc.eduMay YuanDepartment of Geography, University of Oklahoma, Norman, OK 73019-1007,USA. E-mail: myuan@ou.eduA-Xing ZhuDepartment of Geography, University of Wisconsin, Madison, WI 53706-1404,USA. E-mail: azhu@facstaff.wisc.eduAlexander ZipfDepartment of Geoinformatics and Surveying, University of Applied Sciences FHMainz, 561156 Mainz, Germany. E-mail: zipf@geoinform.fh-mainz.deTHO_A01  19/03/2007  11:07  Page xviii Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGeographic Information Science: An IntroductionA. Stewart Fotheringham and John P. WilsonGIS, the acronym for Geographic Information Systems, has been around since the1980s. Although one can impute a number of characteristics from the use of thisacronym, at the heart of the term “systems” lies a computer software package forstoring, displaying, and analyzing spatial data. Consequently, the use of the termGIS implies an objector tool which one can use for exploring and analyzing datathat are recorded for speciﬁc locations in geographical space (see Cowen [1988]for an early article articulating this type of deﬁnition and Foresman [1998] for a richand varied account of the history of Geographic Information Systems). Conversely,Geographic Information Science or GI Science, or more simply GISc, represents amuch broader framework or modus operandi for analyzing spatial data. The term GIScience emphasizes more the methodologybehind the analysis of spatial data (seeBurrough [1986] for what was perhaps the ﬁrst GIS text to promote such a frame-work and Chrisman [1999] for an article advocating an extended deﬁnition of GISalong these same lines). Indeed, one could deﬁne GI Science as: any aspect of thecapture, storage, integration, management, retrieval, display, analysis, and modelingof spatial data. Synonyms of GI Science include Geocomputation, GeoInformatics,and GeoProcessing.1The Breadth of GI ScienceUnder this deﬁnition, GI Science is clearly an extremely broad subject and capturesany aspect connected with the process of obtaining information from spatial data.A feeling for this breadth can be seen in Figure 0.1 which describes a schematic ofsome of the elements that make up GI Science. At the top level, GI Science is con-cerned with the collection or capture of spatial data by such methods as satelliteremotely sensed images, GPS, surveys of people and/or land, Light Detection AndRanging (LiDAR), aerial photographs, and spatially encoded digital video.2The keyelement here is to capture not only attribute information but also accurate informa-tion on the location of each measurement of that attribute. For instance, we mightTHO_A02  19/03/2007  11:08  Page 1 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f2A. STEWART FOTHERINGHAM AND JOHN P. WILSONask people some information on themselves during a survey but we would also like",
    "chunk_order_index": 6,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-2599a406d992b29bd82926102f9ffb51": {
    "tokens": 1200,
    "content": "onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f2A. STEWART FOTHERINGHAM AND JOHN P. WILSONask people some information on themselves during a survey but we would also like to record some aspect of the location of that individual – this might be thelocation at which the survey took place, or the person’s usual residence or theirworkplace or some other location. Similarly, if we measure some attribute such asthe elevation above sea level and/or the precipitation at a set of points, we also needto know the locations of these points, otherwise the elevation and precipitation measurements are useless (see Corbett and Carter [1996] and Custer, Farnes, Wilson,and Snyder [1996] for two examples of what can be accomplished by combininglocational information with elevations and precipitation measurements).Once spatial data have been captured, they need to be stored and transmitted. Thiscan create challenges as some spatial data sets can be extremely large. A census ofpopulation in the USA would contain, for example, records on almost 300 millionpeople with the locational data on each person typically being his or her residence(hence the well-known problem of census data being a snapshot of where peopleare at midnight rather than during the day). In some countries, a decennial censushas been replaced with a more continuous monitoring of the population in the formof a register which can be updated more regularly. Satellite imagery of the Earth’sSpatialdatacollectionGI ScienceSpatialdatastorageDatavisualizationDataanalysisSpecificApplicationAreasLIDARTraditionalmapsAirphotographyDatabaseissuese.g. raster/vectorVirtual reality3D surfacegenerationInteractivemapping-linkedviews-queriesExploratorystatisticsMedicalUrban/economicEnvironmentalGeosciencesTransportationForestry/biogeographyRetailingCadastresMilitarySocialConfirmatorystatisticsSpatialmodellingGraphicalanalysis ofmultivariatedataVisualanalysisSecondarysourcese.g. census ofpopulationSurveys– social andphysicalSatellitesurveysFig. 0.1Geographic Information Science (GISc): An OverviewTHO_A02  19/03/2007  11:08  Page 2 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGI SCIENCE: AN INTRODUCTION3surface can generate terabytes of data and the move towards global data sets can leadto even larger data sets. The data storage and transmission demands of spatiallyencoded digital video have already been referred to in endnote 2 and pose challengesto current systems. Consequently, spatial data sets can be extremely large and ﬁndingways to store, process, and transmit such large data sets efﬁciently is a major challengein GI Science.The next two levels of operations in the schematic in Figure 0.1 refer to the process of transforming data into information. We are currently living in a data-rich world that is getting richer by the day. In many operations, large volumes ofspatial data are being collected and a major challenge in GI Science is to turn thesedata into useful information. Consider, for example, the following sources of spatialdata (which are but a small sample from the complete set of sources):•Censuses of population which typically occur every ﬁve or 10 years and whichtypically record information on each individual in each household and on thehousehold itself;•Customer databases held by retail-related companies which hold informationon individuals submitted in various application forms or warranty cards;•Trafﬁc ﬂow monitoring along streets or at intersections;•LiDAR – low pass ﬂy-overs by plane generating large volumes of detailed dataon terrain features or urban areas;•Digital Elevation Models (DEMs) captured via satellites or the US space shuttlewhich can be at a global scale;•Health records either on the location of patients with particular diseases, usedto study possible geographic inﬂuences on etiology or to assess the level of demandfor various services in particular hospitals;•Satellite remotely-sensed images or aerial photographs used to track land usechange over time or to study the spatial impacts of various natural disasters orfor various military uses such as tracking missiles or identifying targets;•Satellite GPS used increasingly for general data capture of vehicles and individuals.This makes possible vehicle tracking, in-car navigation systems, precision agri-culture, animal tracking, monitoring of individuals, and general data captureon the location of objects via GPS receivers. It is now possible to contemplate,as the UK is doing, tracking the movement of all vehicles and charging for per mileage road use instead of a ﬂat road tax. Similarly, it is now possible via GPS to monitor a child’s movements via a GPS watch linked to a centralmonitoring system that parents can access remotely via the World Wide Web(see http://www.wherifywireless.com for additional details). The linking of GPSto mobile phones will allow the tracking of friends so that one can query thelocation of a registered friend at any moment. The use of mobile phones to locateindividuals by triangulation from mobile relay stations is already standard policepractice in the case of missing persons. Some of these uses of course immediatelyraise important ethical and legal questions which need to be resolved. Just howmuch spatial information on ourselves are we prepared to have captured and stored?Most organizations simply",
    "chunk_order_index": 7,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4cda934ee60aea7b335519fd205fd4aa": {
    "tokens": 1200,
    "content": "less.com for additional details). The linking of GPSto mobile phones will allow the tracking of friends so that one can query thelocation of a registered friend at any moment. The use of mobile phones to locateindividuals by triangulation from mobile relay stations is already standard policepractice in the case of missing persons. Some of these uses of course immediatelyraise important ethical and legal questions which need to be resolved. Just howmuch spatial information on ourselves are we prepared to have captured and stored?Most organizations simply do not have the resources (measured in terms of per-sonnel, knowledge, and/or software) to be able to make full use of all the data THO_A02  19/03/2007  11:08  Page 3 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f4A. STEWART FOTHERINGHAM AND JOHN P. WILSONthey routinely gather. There is a growing need for techniques that allow users tomake sense out of their spatial data sets. This mirrors the general transformationof society from one dominated by the industrial revolution with its origins in theeighteenth and nineteenth centuries, to one dominated by the information revolu-tion with its origins in the computer age of the late twentieth century. Two mainsets of techniques exist to turn data into information: visualization and statistical/mathematical modeling.There is a vast array of techniques that have been developed for visualizing spatial data and it remains a very intense and fruitful area of research (see Dykes, MacEachren, and Kraak [2005] for one such treatment). Spatial data lendthemselves to visualization because the data are geocoded and can therefore be represented easily on maps and map-like objects. Simply mapping spatial data canshed so much more light on what is being studied than if the data are presentedin tabular form.3However, maps can also deceive (see Monmonier [1991] for apopular treatment of this topic) and there are many GI Science issues that need to be considered if spatial data are to be displayed to provide reasonably accurateinformation content. The development of algorithms for continuous cartograms,software to create pseudo-3D virtual reality environments, and hardware that allowsdigital video to be linked to a GPS is providing us with the means towards muchmore sophisticated visualization of spatial data than traditional 2D maps and thereare great advances in this area yet to come. Because spatial data contain attributeand locational information, the data can be shown together as on a simple map of the distribution of an attribute or they can be displayed separately in differentwindows. The use of multiple windows for displaying spatial data is now com-monplace and it can sometimes provide useful information to display a map in onewindow and a non-spatial display of the data (such as a histogram or scatterplotfor example) in another window and to provide a link between the two (see GeoDA™[Anselin, Syabri, and Kho 2006] and STARS [Rey and Janikas 2006] for examplesof such systems). In this way, only data highlighted on the non-spatial display needto be mapped to show the spatial distribution of extreme values, for example.Alternatively, all the data can be displayed on a map and only the data points selectedon the map need to be highlighted in the non-spatial display. Finally, many spatialdata sets are multivariate and it is a major challenge to try to represent such com-plex data in one display.The other set of methods to turn spatial data into information are those involvingstatistical analysis and mathematical modeling. Statistical analysis was traditionallydominated by what is known as “conﬁrmatory” analysis in which a major objectivewas to examine hypotheses about relationships that were already formed. The typical approach to conﬁrmatory analysis would be to develop a hypothesis abouta relationship from experience or the existing literature and to use statistical tech-niques to examine whether the data support this hypothesis or not. Conﬁrmatorystatistical analysis generally depends on assessing the probability or likelihood thata relationship or pattern could have arisen by chance. If this probability or likelihoodis very low, then other causes may be sought. The assessment of the role of chancenecessitates the calculation of the uncertainty of the results found in a set of data(if we had a different data set, would the results perhaps be substantially differentor pretty much the same?). In classical statistical methods, this calculation typicallyTHO_A02  19/03/2007  11:08  Page 4 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGI SCIENCE: AN INTRODUCTION5assumes that the data values are independent of each other. A major problem arisesin the use of this assumption in spatial data analysis because spatial data are typic-ally not independent of each other. Consequently, specialized statistical techniqueshave been developed speciﬁcally for use with spatial data (see Bailey and Gattrell[1995] for an informative and accessible summary of some of these techniques) anda great deal more research is needed in this area.More recently, and probably related to the recent explosion of data availability,“exploratory” statistical techniques have increased in popularity. With these, theemphasis is more on developing hypotheses from",
    "chunk_order_index": 8,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e2fd32ee65fce129976f4525c28e86f8": {
    "tokens": 1200,
    "content": "spatial data are typic-ally not independent of each other. Consequently, specialized statistical techniqueshave been developed speciﬁcally for use with spatial data (see Bailey and Gattrell[1995] for an informative and accessible summary of some of these techniques) anda great deal more research is needed in this area.More recently, and probably related to the recent explosion of data availability,“exploratory” statistical techniques have increased in popularity. With these, theemphasis is more on developing hypotheses from the data rather than on testinghypotheses. That is, the data are manipulated in various ways, often resulting in a visualization of the data, so that possible relationships between variables may be revealed or exceptions to general trends can be displayed to highlight an areaor areas where relationships appear to be substantially different from those in theremainder of the study region. A whole set of localized statistical techniques hasbeen developed to examine such issues (for example, Fotheringham, Brunsdon, andCharlton 2000).Finally, spatial modeling involves specifying relationships in a mathematicalmodel that can be used for prediction or to answer various “what if” questions.Classical spatial models include those for modeling the movements of people, goods,or information over space and the runoff of rainwater over a landscape. There is afuzzy boundary between what might be termed a mathematical model and what mightbe termed a statistical model. Quite often, models are hybrids where a formulationmight be developed mathematically but the model is calibrated statistically. Wheremodels are calibrated statistically from spatial data, one important issue is that itis seldom clear that all, or even most, relationships are stationary over space, usu-ally an assumption made in the application of various modeling techniques. Forinstance, the application of traditional regression modeling to spatial data assumesthat the relationships depicted by the regression model are stationary over space.Hence, the output from a regression model is a single parameter estimate for eachrelationship in the model. However, it is quite possible that some or all of the rela-tionships in the model vary substantially over space. That is, the same stimulus may not provoke the same response in all parts of the study region for various con-textual, administrative or political reasons – people in different areas, for example,might well behave differently. Consequently, specialized statistical techniques suchas Geographically Weighted Regression (GWR) have been developed recently to allowfor spatially varying relationships to be modeled and displayed (Fotheringham,Brunsdon, and Charlton 2002).The ﬁnal layer of Figure 0.1 represents some of the application areas of geo-computation which gives an indication of why it is such an important and rapidlygrowing area of study. Spatial data can be found in most areas of study and includemany different types of data, such as:•Geodetic – coordinate reference systems for locating objects in space;•Elevation – recording heights of objects above mean sea level;•Bathymetric – recording the depth of water bodies;•Orthoimagery – georeferenced images of the earth’s surface;•Hydrography – data on streams, rivers and other water bodies;THO_A02  19/03/2007  11:08  Page 5 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f6A. STEWART FOTHERINGHAM AND JOHN P. WILSON•Transportation networks – roads, railways, and canals;•Communication networks – the transmission of ideas and data across space;•Cadastral – precise positioning of property boundaries;•Utilities – the locations of pipes, wires and access points;•Boundaries – electoral, administrative, school and health districts;•Medical – the location of incidents of disease and patients with respect to thelocation of services;•Crime – the location of police incidents;•Environmental – habitats, pollution, and the impacts of natural disasters;•Urban – the location of areas of high priority for social and economic intervention;•Planning – the spatial impacts of locational decisions;•Retailing – the location of consumers with respect to the location of services;•Biogeography – the location of one species with respect to the location of oneor more others.We now turn to a brief discussion of the topics covered in this book. Given theenormous breadth of GI Science, it is clear that not everything can be included inthis volume. However, in order to be as comprehensive as possible, we have triedto solicit contributions which have a fairly general application as opposed to beingstrictly about the use of GI Science in one particular ﬁeld.What Follows Next!The remainder of this book is organized under six headings. We start each sectionwith a brief description of the chapters that follow and the chapters, themselves,offer stand-alone treatments that can be read in any order the reader chooses. Eachchapter includes links to other chapters and key references in case the reader wantsto follow up speciﬁc themes in more detail.The ﬁrst group of six chapters looks at some of the recent trends and issues con-cerned with geographic data acquisition and distribution. Separate chapters  describehow the production and distribution of geographic data has changed since the mid-1970s, the principal sources of social data for GIS, remote sensing sources anddata, the possibilities of using spatial metaphors to represent data that may not beinherently spatial for knowledge discovery in massive, complex, multi-disciplinarydatabases, the myriad sources of uncertainty in GIS, and the assessment of spatialdata quality.The second section of the book explores some of the important and enduringdatabase issues and trends",
    "chunk_order_index": 9,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-29825b7947b23e732ab03a8c5a59bf68": {
    "tokens": 1200,
    "content": ". Separate chapters  describehow the production and distribution of geographic data has changed since the mid-1970s, the principal sources of social data for GIS, remote sensing sources anddata, the possibilities of using spatial metaphors to represent data that may not beinherently spatial for knowledge discovery in massive, complex, multi-disciplinarydatabases, the myriad sources of uncertainty in GIS, and the assessment of spatialdata quality.The second section of the book explores some of the important and enduringdatabase issues and trends. Separate chapters describe relational, object-oriented and object-relational database management systems, the generation of regular griddigital elevation models from a variety of data sources, the importance of time andsome of the conceptual advances that are needed to add time to GIS databases,and new opportunities for the extraction and integration of geospatial and relatedonline data sources.The third section of the book consists of seven chapters that examine some of therecent accomplishments and outstanding challenges concerned with the visualizationof spatial data. Separate chapters describe the role of cartography and interactiveTHO_A02  19/03/2007  11:08  Page 6 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGI SCIENCE: AN INTRODUCTION7multimedia map production, the role of generalization and scale in a digital world,the opportunities to display and analyze a variety of geographical phenomena assurfaces, fuzzy classiﬁcation and mapping in GIS, predictive rule-based mapping,multivariate visualization, and the ways in which digital representations of two-dimemsional space can be enriched and augmented through interactivity with usersin the third dimension and beyond.The fourth section of the book contains three chapters looking at the increasinglyimportant task of knowledge elicitation. These chapters examine the role of inferenceand the difﬁculties of applying these ideas to spatial processes along with the pro-cess of geographic knowledge discovery (GKD) and one of its central components,geographic data mining, and the prospects for building the geospatial semantic web.The next group of four chapters examines spatial analysis. The links betweenquantitative analysis and GIS, spatial cluster analysis, terrain analysis, and dynamicGIS are discussed here.The six chapters of Part VI examine a series of broader issues that inﬂuence the development, conduct, and impacts of geographic information technologies.Separate chapters examine institutional GIS and GI partnering, public participationGIS, GIS and participatory decision-making, several participatory mapping projectsfrom Central America to illustrate the dynamic interplay between conceptions ofpeople and place and the methods used to survey them, the relationship betweenGIS, personal privacy, and the law across a variety of jurisdictions, and the majordevelopments and opportunities for educating oneself in GIS.Finally, Part VII examines future trends and challenges. Separate chapters examinethe role of the World Wide Web in moving GIS out from their organization- andproject-based roles to meet people’s personal needs for geographic information, theemergence of location-based services (LBS) as an important new application of GIS,and two views of the challenges and issues that are likely to guide GI Science researchfor the next decade or more.Closing CommentsThis handbook seeks to identify and describe some of the ways in which the rapidlyincreasing volumes of geographic information might be turned into useful informa-tion. The brief introductions to topics offered in the previous section give some cluesas to what we think is important here – the rapid growth in the number and varietyof geographic data sets, ﬁnding new ways to store, process, and transmit these data sets, new forms of visualization and statistical/mathematical modeling, etc. To the extent that this book has helped to clarify the current state of knowledgeand indicate proﬁtable avenues for future research, it will have helped to educate andinform the next generation of geographic information scientists and practitioners.This generation will need to be more nimble than its predecessors given the rapidrate of technological change (innovation) and the tremendous growth of geographicinformation science, geographic information systems, and geographic informationservices that is anticipated in the years ahead. With this in mind, we hope the readerwill tackle the remainder of the book with an opportunistic and forward-lookingview of the world around them.THO_A02  19/03/2007  11:08  Page 7 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f8A. STEWART FOTHERINGHAM AND JOHN P. WILSONENDNOTES1In some circumstances, Geomatics also is used synonymously with GI Science as in Geo-matics for Informed Decisions (GEOIDE), the Canadian Network Centre of Excellenceheadquartered at Laval University (www.geoide.ulaval.ca). However, in other circumstances,such as in the naming of academic departments in the UK, the term Geomatics has beenused to “re-brand” Departments of Surveying where its scope and purpose are much morerestricted.2While we are used to seeing orthophotographs, photographs with associated ﬁles givinginformation on the location of each pixel so that operations can be carried out on thespatial relationships within the photograph, spatially encoded digital video allows the userto perform spatial queries and spatial analysis on video images. As one can imagine, thevolumes of such data that need to be stored and transmitted create special challenges.3See Ian Mc",
    "chunk_order_index": 10,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-da25edac663fe4187666c88cedc623ea": {
    "tokens": 1200,
    "content": "of Surveying where its scope and purpose are much morerestricted.2While we are used to seeing orthophotographs, photographs with associated ﬁles givinginformation on the location of each pixel so that operations can be carried out on thespatial relationships within the photograph, spatially encoded digital video allows the userto perform spatial queries and spatial analysis on video images. As one can imagine, thevolumes of such data that need to be stored and transmitted create special challenges.3See Ian McHarg’s 1969 book entitled “Design with Nature” for an inﬂuential book thatdocumented how maps could be overlaid and used to evaluate the social and environ-mental costs of land use change. This book has been reprinted many times and still servesas an important text in many landscape architecture courses and programs.REFERENCESAnselin, L., Syabri, I., and Kho, Y. 2006. GeoDa: An Introduction to Spatial Data Analysis.Geographical Analysis38: 5–22.Bailey, T. C. and Gattrell, A. C. 1995. Interactive Spatial Data Analysis.New York: JohnWiley and Sons.Burrough, P. A. 1986. Principles of Geographical Information Systems for Land ResourcesAssessment.New York: Oxford University Press.Chrisman, N. R. 1999. What does “GIS” mean? Transactions in GIS3: 175–86.Corbett, J. D. and Carter, S. E. 1996. Using GIS to enhance agricultural planning: The example of inter-seasonal rainfall variability in Zimbabwe. Transactions in GIS1:207–18.Cowen, D. J. 1988. GIS versus CAD versus DBMS: What are the differences? Photo-grammetric Engineering and Remote Sensing54: 1551–4.Custer, S. G., Farnes, P., Wilson, J. P., and Snyder, R. D. 1996. A comparison of hand- andspline-drawn precipitation maps for mountainous Montana. Water Resources Bulletin32:393–405.Dykes, J. A., MacEachren, A. M., and Kraak, M. J. (eds). 2005. Exploring Geovisualization.Amsterdam: Elsevier.Foresman, T. W. (ed.). 1998. History of Geographic Information Systems: Perspectives fromthe Pioneers.Englewood Cliffs, NJ: Prentice Hall.Fotheringham, A. S., Brunsdon, C., and Charlton, M. E. 2000. Quantitative Geography:Perspectives on Spatial Data Analysis. Thousand Oaks, CA: Sage Publishers.Fotheringham, A. S., Brunsdon, C., and Charlton, M. E. 2002. Geographically WeightedRegression: The Analysis of Spatially Varying Relationships.Chichester: John Wiley andSons.McHarg, I. L. [1969] 1994. Design with Nature (25th anniversary edn). New York: JohnWiley and Sons.Monmonier, M. 1991. How to Lie with Maps.Chicago: Chicago University Press.Rey, S. J. and Janikas, M. V. 2006. STARS: Space-time analysis of regional systems.Geographical Analysis38: 67–86.THO_A02  19/03/2007  11:08  Page 8 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPart IData IssuesThis ﬁrst group of chapters looks at some of the recent trends and issues concernedwith geographic data acquisition and distribution. The ﬁrst of these chapters, byDavid J. Cowen, describes how the production and distribution of geographic datahas changed in the past three decades. This chapter walks the reader through the over-lapping worlds of the National Spatial Data Infrastructure, Federal Geographic DataCommittee (FGDC), framework data, metadata, standards, FGDC clearinghouses,Geospatial One-Stop, and the National Map, and thereby offers a summary of recentdevelopments in the United States where publicly funded geographic data sets havebeen distributed at little or no cost to potential users for many years.The second chapter in this group, by David J. Martin, reviews the principal sourcesof social data for Geographic Information Systems (GIS). The examples demonstratehow conventional administrative, survey, and census-based data sources are becom-ing increasingly integrated as national statistical organizations look towards datacollection strategies that combine elements of each. This integration will probablyproduce higher spatial and temporal resolution and cross-scale data sets in futureyears that will, in turn, require entirely new geocomputational tools for effectivevisualization and/or analysis.The third of the chapters, by Brian G. Lees, describes the remote sensing sourcesand data that are commonly used as inputs to GIS. The opportunities for extract-ing and updating spatial and attribute information in geographic databases fromremotely sensed data are examined in some detail, and special attention is paid to the role of error within remote sensing and how insights about the behavior ofspatial data in GIS and spatial statistics are feeding back into remote sensing anddriving innovation in these rapidly evolving ﬁelds.In the fourth chapter André Skupin and Sara I. Fabrikant explore the possibilitiesof using spatial metaphors to represent data that may not be inherently spatial forknowledge discovery in massive, complex, multi-disciplinary databases. This areaof research is termed “spatialization” and the chapter discusses what kinds",
    "chunk_order_index": 11,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-978614a9cb729e31ba30e942a98bd17d": {
    "tokens": 1200,
    "content": "the role of error within remote sensing and how insights about the behavior ofspatial data in GIS and spatial statistics are feeding back into remote sensing anddriving innovation in these rapidly evolving ﬁelds.In the fourth chapter André Skupin and Sara I. Fabrikant explore the possibilitiesof using spatial metaphors to represent data that may not be inherently spatial forknowledge discovery in massive, complex, multi-disciplinary databases. This areaof research is termed “spatialization” and the chapter discusses what kinds of datacan be used for spatialization and how spatialization can be achieved. The authorsconclude their chapter by noting that spatialization is a new and exciting area inTHO_C01  20/03/2007  14:47  Page 9 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f10DATA ISSUESwhich GI Science is challenged to address important cognitive and computationalissues when dealing with both geographic and non-geographic data.Ashley Morris starts out the ﬁfth chapter by noting that uncertainty permeatesevery aspect of spatial data (including the assimilation and storage of geospatialfeatures, operations on those features, and the representation of the results of theseoperations) and goes on to explain why fuzzy object-oriented databases provide a viable and attractive option for modeling uncertainty in spatial databases. Thesedatabases provide membership functions that aid in the storage and representationof objects with uncertain boundaries and the focus on features means that they areable to store and represent both vector- and raster-based objects. These featurescoupled with the use of multiple alpha-cuts provide extensible systems that can sup-port objects with either crisp or ill-deﬁned boundaries at any desired level of detail.The chapter concludes by noting that the storage, manipulation, and representationof objects with uncertain boundaries is likely to become more important as usersbecome more sophisticated.The ﬁnal chapter in this group of six, by James D. Brown and Gerald B. M.Heuvelink, focuses on geographic data, it complements the previous chapter anddeals with the assessment of spatial data quality. This information is essential ifwe are to manage social and environmental systems effectively and more generally,for encouraging responsible use of spatial data where knowledge is limited and priorities are varied. This chapter offers an overview of data quality and measuresof data quality, the sources of uncertainty in spatial data, and some probabilisticmethods for quantifying the uncertainties in spatial attributes. The conclusion notesseveral challenges that must be overcome if we are to estimate and use informationon spatial data quality more effectively in the future.THO_C01  20/03/2007  14:47  Page 10 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 1The Availability of Geographic Data:The Current Technical and Institutional EnvironmentDavid J. CowenThe need for digital geographic data dates from the earliest computer-based applica-tions in mapping, statistical analysis, and Geographic Information Systems (GIS) inthe 1960s. Simply stated, without data there are no GIS applications. The evolu-tion of today’s robust GIS market can be directly linked to the availability of highquality data. The fact that the current US$5 billion market for geospatial data andservices is expected to expand six fold in the next couple of years suggests that theproduction and distribution of GIS data to an eager user community has dramatic-ally changed (Gewin 2004). This chapter presents an overview of the technical andinstitutional environment in which GIS data are made available.The issues relating to the availability of geographic data have changed signiﬁc-antly over the past three decades. For GIS pioneers the question of data availability was a major concern. This usually meant that users had to wait for large mappingorganizations to make the transition from the production of paper maps to the generation of digital representations of features on those maps. Of particular note arethe efforts of the US Geological Survey to convert their topographic maps into digitalline graphs which created the ﬁrst nationwide geographic data base (Anderson, Marx,and Keffer 1985, USGS 1989). As these subsequently evolved into the Census TIGERline ﬁles (Broome and Godwin 2003) and derivative products, the GIS user com-munity in the USA was provided with several nationwide data sources that were freelydistributed. The use of these publicly funded data sources was fostered by a liberalfederal data dissemination policy that encouraged federal data creators to “throwthe data over the fence” (NRC 1990) and let an eager GIS community determine thebest way to incorporate them into their applications. These federal data sourceshave been supplemented by a robust commercial sector. For example, GeographicData Technology (http://www.geographic.com/home/index.cfm), a pioneer in com-mercial GIS data production, recently sold its geographic data assets for more thanUS$100 million. The combination of public and private data providers has fosteredthe rapid expansion of the GIS and location-based services market. The fundamentalquestions regarding the availability of geographic data today often focus on dis-covery, choices, and the legal and ﬁnancial environment in which the data exist.THO_C01  20/03/2007  14:47  Page 11 Downloaded from https://onlinelibrary.wiley",
    "chunk_order_index": 12,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-04c3274c50220de8094a296c54235ce3": {
    "tokens": 1200,
    "content": "sold its geographic data assets for more thanUS$100 million. The combination of public and private data providers has fosteredthe rapid expansion of the GIS and location-based services market. The fundamentalquestions regarding the availability of geographic data today often focus on dis-covery, choices, and the legal and ﬁnancial environment in which the data exist.THO_C01  20/03/2007  14:47  Page 11 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f12DAVID J. COWENIn 2006, a discussion of the availability of geographic data could simply reviewa series of web sites that provide access to spatial data. In fact, a novice user is quitelikely to be overwhelmed by following a Google search for GIS data (June 3, 2006)that yields about 64,700,000 links. Among these links one will ﬁnd an increasingnumber of GIS data portals that are maintained by libraries such as the one at StanfordUniversity (http://www-sul.stanford.edu/depts/gis/web.html). A little probing into these sites will reveal the confusing and overlapping worlds of the National SpatialData Infrastructure, Geospatial One-Stop, the Federal Geographic Data Committee,the National Map, the National Atlas, the Geography Network, the Map Store, theMap Machine, the Demographic Data Viewer, the Open Geospatial Consortiumand many other data related sites. Ideally, the Electronic Government initiative to create Geospatial One-Stop (http://www.geo-one-stop.gov/) should satisfy the needfor a common search engine for existing GIS data. At the same time hundreds ofcommercial sites are using address matching capabilities and geographic data visual-izations that are accessed by millions of users every day. Unfortunately, a serious userwho wants to acquire rather than simply view data soon discovers that the avail-ability of geographic data is couched in a complex milieu of ﬁnancial, institutional,legal, technical, and even security issues.General Market ModelAcquiring geographic data involves a successful market transaction that links theproducers and consumers. Lopez (1996) provides a useful conceptualization of thegeographic data marketplace that exists to handle these transactions (Figure 1.1).On the supply side there is a robust commercial sector that is supplemented by apublic spatial data infrastructure. These ﬁrms operate in an environment that ismuch different from the one that existed in the early stages of GIS. Instead of build-ing geographic data by converting existing maps they now rely on high resolutiondata sources to identify features. Generally, the providers of geographic data includecommercial companies that acquire geographic data by direct surveying, recordingmeasurements from airborne- and satellite-based platforms, interpreting and ana-lyzing the raw data through the use of GIS, photogrammetric or image processingtechniques.While these suppliers may provide data directly to users they are often assistedby value-added intermediaries. The value-added intermediaries are analogous to theretail sector. These companies take raw or native data generated by the suppliers andenhance it or provide time and space utility to it. That means that an end user mayobtain the data in a more convenient or technically acceptable manner. For example,commercial street centerline vendors may improve accuracy and add additionalattributes to data and provide the data on a DVD for a vehicle navigation system.Many federal agencies have established web-based marketplaces where users canacquire data in a variety of formats and prices.A successful marketplace is one in which transactions provide revenue to theproviders and satisfaction to the consumer. It is useful to conceptualize the followingsteps in such transactions:THO_C01  20/03/2007  14:47  Page 12 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA131Awareness of the need for the data2Discovery of the source of the data3Understanding of the characteristics and quality of the data4Agreement on the price5Determination of a means of payment6Agreement on the restrictions on use7Acquisition of the data8Importing of the data into an applicationThere are obstacles associated with each step in this process. Many users are unawareof the type of data that they may need for a project. For example, the real estatedeveloper may not know that the local county maintains a complete GIS-based multi-purpose cadastre that will provide him or her with valuation, taxation, and zoninginformation. In order to be effective, suppliers need to advertise the existence ofdata holdings. Government organizations do not usually have much experience inFig. 1.1Geographic data marketplacehttp://books.nap.edu/books/0309092671/html/42.htmlEducation:K-12, University teaching,Technical Training, R&DPublic Interest Groups:Civic, EnvironmentalCitizensResources:Forestry, Mining, Oil andGas, AgriculturePublic InterestGroups: Civic,EnvironmentalGovernmentAgenciesValue-Added IntermediariesGeographic Data UsersPublic Spatial Data InfrastructureCommercial Data SuppliersLocal GovtsFederal GovtsCommercialUniversitiesand ResearchUtilities:Water, Sewage, Electric,Telecom, CableGovernment:Federal, State, Local,TribalInformation Industry:Real Estate, Insurance,Marketing, RetailingUtilitiesState GovtsSurveyingPhotogrammetryAirborne & SatelliteGISTHO_C01",
    "chunk_order_index": 13,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-382c40317c8595c4ef7bfbf139a5fecf": {
    "tokens": 1200,
    "content": "stry, Mining, Oil andGas, AgriculturePublic InterestGroups: Civic,EnvironmentalGovernmentAgenciesValue-Added IntermediariesGeographic Data UsersPublic Spatial Data InfrastructureCommercial Data SuppliersLocal GovtsFederal GovtsCommercialUniversitiesand ResearchUtilities:Water, Sewage, Electric,Telecom, CableGovernment:Federal, State, Local,TribalInformation Industry:Real Estate, Insurance,Marketing, RetailingUtilitiesState GovtsSurveyingPhotogrammetryAirborne & SatelliteGISTHO_C01  20/03/2007  14:47  Page 13 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f14DAVID J. COWENmarketing, therefore there is often a disconnect between potential producers andconsumers. Fortunately, an increasing number of organizations are creating metadatathat advertises the contents of their data holdings and Internet-based search enginesare discovering and serving these “electronic card catalogs” to the public. Manydata providers also allow users to preview the data by viewing and querying it througha web-based mapping system. The standardized spatial metadata is a great boonto users who can quickly determine whether the data satisﬁes their intended needs.Users often ﬁnd that free and easily accessed data are not of the appropriate scale orresolution or do not include the necessary attributes or reﬂect the current situationon the ground. The rapid expansion of the GIS data market is based on the real-ization the relatively small scale databases (1:100,000 or 1:24,000) created by Federalagencies are not appropriate for large scale applications in an urban setting. Whilethe data available from commercial or non-federal public agencies are much morelikely to meet user needs they are provided within a set of complex legal and ﬁnancialcovenants. These ﬁnancial and legal issues often stop the transaction. The methodsand media used to physically transfer data from a producer to a consumer haveevolved along with the general information technology. Today, these methods includeeverything from simple download via an FTP site to ordering an external hard driveloaded with gigabytes of digital imagery (USGS, EROS Data Center 2005).Institutional and Legal EnvironmentA sign that the GIS marketplace has matured signiﬁcantly is the recent publicationof a NRC report on licensing geographic data and services. The report provides auseful deﬁnition of geographic data: “location-based data or facts that result fromobservation or measurement, or are acquired by standard mechanical, electronic,optical or other sensors” (NRC 2004, p. 24). Surveyor’s coordinates, parcel corners,and unprocessed data captured by a sensor platform all fall into the category ofraw data. In a legal context courts have decided that such native data are facts andcannot be copyrighted. These unprocessed records may be subject to public dis-closure under most Freedom of Information Acts (FOIA). While native geographicdata have value to GIS professionals the value-added or preprocessed data is muchmore of a consumer good. For example, fully attributed georeferenced records ina multipurpose cadastre are extremely valuable products that can be marketed. Thesederived products can be thought of as “information” rather than “data” and may beprotected by a copyright. The NRC (2004, p. 107) panel provides a clear statementon copyright: “Although geographic data equivalent to facts will not be protectedby copyright, compilation of geographic data such as databases and data sets, aswell as maps and other geographic works that incorporate creative expression mayhave copyright protection.” According to the panel there are two dominant busi-ness models that govern the ownership of geographic data (NRC 2004, p. 63). Inone case, all rights are sold to the purchaser but the vendor retains the right to usethe work. In the other case, the rights are retained by the vendor, but customers areallowed to use the data under a license. In either case it is important to understandthe characteristics of digital geographic data. As with digital music it is intangibleand can be obtained and used concurrently by many consumers.THO_C01  20/03/2007  14:47  Page 14 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA15Since the government is such an important player throughout the “geographic valuechain” the concept of public domain is important. Again the NRC (2004, p. 26)deﬁnition is useful: “Public domain information – information that is not protectedby patent, copyright, or any other legal right and is accessible to the public withoutcontractual restrictions on redistribution or use.” It must be noted that there is amajor difference between the way that the federal government and other levels ofthe public sector operate in the USA in this regard. The federal policy is based on thepremise that data derive their value from use and it wishes to actively foster a robustmarket of secondary and tertiary users. Therefore, the federal model can be sum-marized as: “although exceptions exist, the general framework provided by the U.S. laws supports the current federal information data policy, which may be sum-marized as a strong Freedom of Information Act, no government copyright, feeslimited to",
    "chunk_order_index": 14,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6ff06f1d7ef65348a703197edd4134c9": {
    "tokens": 1200,
    "content": "levels ofthe public sector operate in the USA in this regard. The federal policy is based on thepremise that data derive their value from use and it wishes to actively foster a robustmarket of secondary and tertiary users. Therefore, the federal model can be sum-marized as: “although exceptions exist, the general framework provided by the U.S. laws supports the current federal information data policy, which may be sum-marized as a strong Freedom of Information Act, no government copyright, feeslimited to recouping the cost of dissemination and no restrictions on reuse” (NRC2004, p. 81). This policy is most clearly articulated in OMB Circular A-130 whichstates that federal agencies will:1.Avoid establishing, or permitting others to establish on their behalf, exclusive,restricted, or other distribution arrangements that interfere with the availabilityof information dissemination products on a timely and equitable basis.2.Avoid establishing restrictions or regulations, including the charging of fees or royalties, on the reuse, resale, or redissemination of Federal information dis-semination products by the public.3.Set user charges for information dissemination products at a level sufﬁcient to recoverthe cost of dissemination but no higher. They must exclude from calculation of thecharges costs associated with original collection and processing of the information(U.S. Ofﬁce of Management and Budget 2004).The US federal policy is in stark contrast to much of the rest of the world. Forexample, in the UK the Ordnance Survey protects its mapping products (and data)by the 1988 Crown Copyright, Designs and Patents Act: “The Ordnance Surveyoperates under a carefully controlled Licensed Use Schedule and pricing policy that prohibits any use of Ordnance Survey Data which is not expressly addressed in this Licensed Use Schedule under the deﬁnition of ‘Standard Licensed use’ orwhich is not otherwise expressly permitted by Ordnance Survey is prohibited” (HerMajesty’s Stationary Ofﬁce 1988). Within the USA, the issues regarding ownershipand restrictions on use of geographic data at the state and local government levelsare extremely fragmented. Faced with limited budgets they have developed a varietyof institutional frameworks to facilitate acquisition and sharing of data. These include:(1) ad hoc collaboration; (2) organized collaboration; (3) umbrella organizations;(4) contract work; and (5) agency assessments (NRC 2004, p. 84).The divergent philosophies of local governments have resulted in a wide rangeof policies governing the distribution of their data assets. For example, RichlandCounty, South Carolina operates under an ordinance (072-00HR) that states that“geographic information systems (GIS) data elements are distributed to customersin exchange for a data licensing and/or maintenance fee. Upon receipt of GIS data, customers must enter into a nontransferable data license agreement with theCounty” (Richland County, South Carolina 2004). At the other extreme, DelawareTHO_C01  20/03/2007  14:47  Page 15 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f16DAVID J. COWENCounty, Ohio provides a simple web interface for free downloads without any formof identiﬁcation or registration.Unfortunately, local government licensing programs often inhibit the develop-ment of the type of federal and local government partnerships that are needed tosupport programs such as the Census Bureau’s TIGER modernization program andthe USGS National Map. Consequently, federal taxpayers often have to foot thebill to create a poorer quality version of street centerline ﬁles than the ones thatalready exist in many local governments (Cowen and Craig 2004).The role of government in the creation and distribution of geographic data is per-vasive (Figure 1.2). The NRC (2004) panel provided a useful diagram of the logicaldownstream and upstream ﬂows of geographic data to and from government as itmoves from a data source to secondary and tertiary users. Whereas federal mappingorganizations once maintained major in-house mapping capabilities they now relyheavily on contractual arrangements for the outsourcing of the acquisition of nativedata from the private sector.Data SourceContractStructureGovernmentalUseRedistributionSchemesSecondaryUsersTertiary UseSchemesSatelliteFederal(cid:127) FOIA(cid:127) Pass Through LicenseState and Local(cid:127) Open Records–FOIA(cid:127) Pass Through License(cid:127) Potential Copyright & LicenseTypicallyFully LicensedNegotiatedLimited LicenseSpeculativeProvidersTypicallyFully LicensedNegotiatedLimited LicenseGovernmentalTypicallyUnrestrictedTransterLimited LicensedAirborneTypicallyOutright PurchaseInfrequentLimited LicensedCartographicProvidersCitizensResearch/LibraryPublic InterestGroupsGovernmentalCommercial/PublisherTypicallyOutright PurchaseInfrequentLimited LicensedView or No AccessRestrictedRedistributionUnlimited AccessView or No AccessUnlimited AccessRestrictedRedistributionView or No AccessLicense Fees,Royalties or OtherConsiderationUnlimited AccessView orNo AccessLicense FeesSingle LicenseUnlimited AccessView or No AccessRestrictedRedistributionSingle LicenseUnlimited AccessLegendFully Licensed RestrictedAd Hoc PassThroughProfessionalServicesOutrightTransferPublicationSubscriptionValue AddedResearchPublicationPass ThroughDisplayPublicationPass ThroughTertiary UsersLimited License RestrictionsUnrestricted TransferFig. 1.2Data ﬂow to and from governmenthttp://print.nap.edu/pdf/0309092671/pdf_image/60.pdfTHO_C01  20/03/2007  14:47  Page 16 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online",
    "chunk_order_index": 15,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-587e5e077d612d12702a584baa560044": {
    "tokens": 1200,
    "content": "OutrightTransferPublicationSubscriptionValue AddedResearchPublicationPass ThroughDisplayPublicationPass ThroughTertiary UsersLimited License RestrictionsUnrestricted TransferFig. 1.2Data ﬂow to and from governmenthttp://print.nap.edu/pdf/0309092671/pdf_image/60.pdfTHO_C01  20/03/2007  14:47  Page 16 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA17In this context, a natural tension exists between the ﬁrms that produce the dataand the public agencies that are the customers. The commercial producer would liketo control the use and distribution of data, while under OMB A-130 guidelines thefederal government must attempt to obtain outright licenses on data. This arrange-ment enables agencies to modify the data and place it into the public domain. Fromthe commercial supplier’s perspective this type of one-off arrangement limits thenumber of potential customers and thereby increases the unit cost to the agency.Even though it may purchase the data from a commercial provider the public agencybecomes the rightful custodian of the data. As such, it is beneﬁcial to be the solesource for the data. As its custodian the agency can ensure that it is properly main-tained and provides proper quality control programs. For example, there needs tobe only one ofﬁcial set of Census Bureau TIGER line ﬁles for Census processingand reapportionment.The federal government also encourages reuse of the data and cannot be com-pensated for more than the marginal cost of distribution. The Internet, inexpensivemass storage, and high speed bandwidth has dramatically changed the data dis-tribution process. Today, instead of responding to speciﬁc requests many agenciesplace their data holdings on an FTP site and enable users to select and downloadthe data.StandardsWhether we are talking about light bulbs or video tape, a user must be able to acquirea product with the assurance that it is going to work properly. The history of thelast two decades of GIS is closely tied to the evolution of spatial data standards.Some of the earliest efforts focused on the need to establish standards that wouldenable data to be transferred between proprietary software systems. In fact, between1980 and 1992 the federal government under the direction of USGS worked withthe user community to develop the Spatial Data Transfer Standard (SDTS). This com-prehensive effort could be viewed as the ﬁrst serious effort to make geospatial data“more available.”The SDTS provides a neutral vehicle for the exchange of spatial data betweendifferent computing platforms. It provides a detailed description of the logical spe-ciﬁcations, conceptual model, and spatial object types. The standard recognizes anddeﬁnes the variety of formats that are involved with spatial data transfer (Figure 1.3).It also includes components of a data quality report and the layout of all neededinformation for spatial data transfer (Figure 1.4). It contains a catalog of spatialfeatures and associated attributes for common spatial feature terms to ensure greatercompatibility in data transfer.From a policy viewpoint the current version of the SDTS standard (ANSI NCIT320-1998) is mandatory for federal agencies and an increasing number of organiza-tions distribute their data in this format. The SDTS website maintained by the USGS(http://mcmcweb.er.usgs.gov/sdts/) lists the current status of SDTS implementationand private sector involvement. Furthermore, there is a library of C language func-tions available for DOS or Unix operating systems which read and write the formatused by SDTS. It should be noted, however, that SDTS is an exchange format thatmust be converted into an operational format supported by the GIS software.THO_C01  20/03/2007  14:47  Page 17 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f18DAVID J. COWENProprietary GIS DataStructuresGeometry and TopologyLogical Data Organization/ClassificationMetadataGraphic Symbology/RepresentationGraphic-AttributeRelationship1011122625151617249Fig. 1.3Fundamental issues in spatial data transferhttp://mcmcweb.er.usgs.gov/sdts/training.htmlSDTS Base SpecificationModelMappingDocumentsProfilesBaseDigitalOrtho QuarterQuadranglesTopologicalVector ProfileRaster Profile? OthersDecodingSoftwareEncodingSoftwareOther RasterFormatsDigital LineGraphOther VectorFormatsTIGERDigitalElevation ModelFig. 1.4The Spatial Data Transfer Standardhttp://mcmcweb.er.usgs.gov/sdts/training.htmlTHO_C01  20/03/2007  14:47  Page 18 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA19Open Geospatial ConsortiumIn some ways the SDTS effort evolved into the formal establishment of the moreencompassing Open Geospatial Consortium (OGC) that includes 312",
    "chunk_order_index": 16,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6a2997743dc56b7d9c555bec305d5990": {
    "tokens": 1200,
    "content": "Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA19Open Geospatial ConsortiumIn some ways the SDTS effort evolved into the formal establishment of the moreencompassing Open Geospatial Consortium (OGC) that includes 312 memberorganizations. The OGC has the mission: “to create open and extensible softwareapplication programming interfaces for GI Systems and other mainstream tech-nologies.” Through its efforts a high level of interoperability now exists betweendata providers and users. These open system speciﬁcation efforts are particularlyimportant within a web-based environment where users wish to develop applica-tions that incorporate a variety of data that may be held in widely dispersed sites.Such applications may be simple real-time, location-based services or complex decision support systems used by mangers in times of emergency. The OGC haspushed the commercial side of the GIS business to accept open standards that havegreatly improved interoperability.The Federal Geographic Data Committee (FGDC) and National Spatial Data Infrastructure (NSDI)While the OGC has focused on technical issues required to make data interchangeablebetween systems other efforts have addressed the institutional obstacles relating toGIS data. Any user soon discovers that there is a wealth of data available and thatmultiple representations of the same themes often exist. For example, almost everycommunity has at least four versions of street centerlines (Census TIGER, USGSdigital line graphs, and two commercial vendors.) These multiple representationsvary in accuracy, currency, attributes, price, and scale. Unfortunately, until recentlythe uninformed user had little assistance in identifying the ﬁtness for use of a par-ticular geospatial data set. Since the problem of duplicative and overlapping datacreation efforts was particularly acute within the federal government there has beena concerted effort to improve the way federal agencies operate. Most of these effortscan be encapsulated under the concept of the National Spatial Data Infrastructure(NSDI) which has been closely related to the creation of the National Research CouncilMapping Science Committee in 1989. The committee was established to provide:“independent advice to society and to government at all levels on scientiﬁc, technical,and policy matters relating to spatial data.” The NRC Mapping Sciences Committeedeﬁned the NSDI very broadly in a 1993 report as “the materials, technology, andpeople necessary to acquire, process, store, and distribute such information to meeta wide variety of needs. The committee described the components of the NSDI to beusers, policies and procedures, institutional support, people, geographic informationand the materials and technology” (NRC 1993).The NSDI became part of the ofﬁcial federal lexicon in 1994 when President Clinton signed Executive Order 12906 “Coordinating Geographic Data Acquisitionand Access: The National Spatial Data Infrastructure.” That executive order furtherdeﬁned the NSDI as follows: “NSDI means the technology, policies, standards, and human resources necessary to acquire, process, store, distribute, and improveutilization of geospatial data (Ofﬁce of the Federal Register 1994).THO_C01  20/03/2007  14:47  Page 19 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f20DAVID J. COWENA critical component of the federal role has been a serious effort to minimize thebarriers that inhibit access to federal data and to reduce redundant data collectionefforts. One of the most signiﬁcant steps in the process occurred in 1990 when theOfﬁce of Management and Budget issued Circular A-16 that provided “directionfor federal agencies that produce, maintain or use spatial data either directly orindirectly in the fulﬁllment of their mission.” OMB also used A-16 to establish theFederal Geographic Data Committee (FGDC). In effect, the FGDC was establishedto oversee the development of the NSDI.One of the ﬁrst tasks of the FGDC was to establish categories of geospatial dataand to develop communities of interest for different thematic types of geospatial data.Its efforts resulted in the following subcommittees that represent the taxonomy ofgeospatial data: (1) base cartographic; (2) cadastral; (3) cultural and demographic;(4) geodetic; (5) geologic; (6) ground transportation; (7) international boundaries;(8) soils; (9) vegetation; (10) spatial water; (11) wetlands; (12) marine and coastalspatial data; and (13) spatial climate. These subcommittees have been overseeingthe development of standards that facilitate the exchange of data and provide thecommunity of GIS data users with a clear deﬁnition of terms and speciﬁcations.Table 1.1 lists the current standards that have been ﬁnalized by the FGDC, andTable 1.1Final Stage – FGDC Endorsed Standards (January 24, 2004)http://www.fgdc.gov/standards/status/textstatus.htmlContent Standard for Digital Geospatial Metadata (version 2.0), FGDC-STD-001-1998Content Standard for Digital Geospatial Metadata, Part 1: Biological Data Proﬁle, FGDC-STD-001.1-1999Metadata Proﬁle for Shoreline Data, FGDC-",
    "chunk_order_index": 17,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-bd8d2b1740d45a815851e32b21d1a443": {
    "tokens": 1200,
    "content": "1.1Final Stage – FGDC Endorsed Standards (January 24, 2004)http://www.fgdc.gov/standards/status/textstatus.htmlContent Standard for Digital Geospatial Metadata (version 2.0), FGDC-STD-001-1998Content Standard for Digital Geospatial Metadata, Part 1: Biological Data Proﬁle, FGDC-STD-001.1-1999Metadata Proﬁle for Shoreline Data, FGDC-STD-001.2-2001Spatial Data Transfer Standard (SDTS), FGDC-STD-002Spatial Data Transfer Standard (SDTS), Part 5: Raster Proﬁle and Extensions, FGDC-STD-002.5Spatial Data Transfer Standard (SDTS), Part 6: Point Proﬁle, FGDC-STD-002.6SDTS Part 7: Computer-Aided Design and Drafting (CADD) Proﬁle, FGDC-STD-002.7-2000Cadastral Data Content Standard, FGDC-STD-003Classiﬁcation of Wetlands and Deepwater Habitats of the United States, FGDC-STD-004Vegetation Classiﬁcation Standard, FGDC-STD-005Soil Geographic Data Standard, FGDC-STD-006Geospatial Positioning Accuracy Standard, Part 1, Reporting Methodology, FGDC-STD-007.1-1998Geospatial Positioning Accuracy Standard, Part 2, Geodetic Control Networks, FGDC-STD-007.2-1998Geospatial Positioning Accuracy Standard, Part 3, National Standard for Spatial DataAccuracy, FGDC-STD-007.3-1998Geospatial Positioning Accuracy Standard, Part 4: Architecture, Engineering Constructionand Facilities Management, FGDC-STD-007.4-2002Content Standard for Digital Orthoimagery, FGDC-STD-008-1999Content Standard for Remote Sensing Swath Data, FGDC-STD-009-1999Utilities Data Content Standard, FGDC-STD-010-2000US National Grid, FGDC-STD-011-2001Content Standard for Digital Geospatial Metadata: Extensions for Remote SensingMetadata, FGDC-STD-012-2002THO_C01  20/03/2007  14:47  Page 20 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA21the extent of these standards efforts points to the complexity of the issues surroundinggeospatial data.Framework dataThe FGDC also recognized the need for a common geographic base to create andmaintain additional thematic layers. The FGDC foundation or backbone consists ofthe following layers: (1) geodetic control; (2) orthoimagery; (3) elevation; (4) trans-portation; (5) hydrography; (6) governmental units; and (7) cadastral information.Ideally, framework data provides a common base at a sufﬁciently high level of resolution and accuracy that any thematic layer based on the framework should bepermanently maintained with a high degree of conﬁdence. It should be noted thatthere is considerable debate about how to establish and fund partnerships to developthe framework layers. As noted previously, the issues surrounding federal and localgovernment cooperation can be very perplexing.MetadataArguably, the most successful program of the FGDC has been the promulgation of The Content Standard for Digital Geospatial Metadata. The need for a meta-data standard was included in the 1994 executive order and became a cornerstoneof federal policy over the past decade. To the geospatial data community metadatais analogous to a library’s card catalog. The beneﬁts of metadata are listed by FGDC(2005) as1.Organize and maintain an organization’s internal investment in spatial data.2.Provide information about an organization’s data holdings to data catalogues, clearinghouses, and brokerages.3.Provide information to process and interpret data received through a transfer froman external source.The detailed speciﬁcation for creation of metadata is spelled out in great technicaldetail in several FGDC standards (Figure 1.5). The major elements of metadata are: (1) identiﬁcation information; (2) data quality information; (3) spatial data organization information; (4) spatial reference information; (5) entity and attri-bute information; (6) distribution information; (7) multi-use sections; and (8)extensibility.Metadata provides a user with the necessary information to make an informeddecision about whether an available data set is appropriate for use in an applica-tion. Producers and consumers of geographic data have greatly beneﬁted from this“truth in advertising” approach and software tools to create and maintain metadataas XML ﬁles are now commonplace.FGDC security concernsAccess to spatial data is also impacted by maters of national security. In fact, afterthe events of September 11, 2001 many of the sources of spatial data that had beenfreely distributed were quickly retracted:THO_C01  20/03/2007  14:47  Page 21 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed",
    "chunk_order_index": 18,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-21bc323d90b43615758d4f8dcd70521e": {
    "tokens": 1200,
    "content": "data that had beenfreely distributed were quickly retracted:THO_C01  20/03/2007  14:47  Page 21 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f22DAVID J. COWENAfter September 11, individual federal organizations withdrew some of their geospatialinformation that had been previously available to the public via agency websites andprinted documents. These initial decisions were made under conditions of time pres-sures and without much top-level guidance. However, even under the best circumstances,several factors complicate the decisionmaker’s task of determining which informationsources have signiﬁcant homeland security implications and, if so, whether some typeof restrictions on public access are necessary (Baker, Lachman, Frelinger, et al. 2004).When the GIS data resources were analyzed, the Rand group found that only sixpercent of the 629 federal data sets were judged to be potentially useful to attackersand was both useful and unique. These and other actions prompted the FGDC toestablish The Homeland Security Working Group. Security, foreign policy, law enforcement, and privacy issues represent major challenges to policy makers con-sidering geographic data access issues. There are difﬁcult decisions relating to theproper balance between potentially harmful or intrusive uses and legitimate uses(see Chapter 29 by Cho, this volume, for a more detailed discussion of GIS, personalprivacy, and legal issues). Therefore, the FGDC Homeland Security Working Group1.7.IdentificationInformationDistributionInformationData QualityInformationmandatoryifapplicableLEGENDSpatial DataOrganizationInformationSpatialReferenceInformationEntity andAttributeInformationMetadataReferenceInformation3-D BoxIndicatesDataEntryFieldmandatoryoptional2.6.5.4.3.MetadataFig. 1.5Content standard for digital geospatial metadatahttp://biology.usgs.gov/fgdc.metadata/version2/THO_C01  20/03/2007  14:47  Page 22 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA23(2004) developed a set of guidelines for providing appropriate access to geospatial datain response to security concerns (Figure 1.6). This ﬂowchart suggests that “blanketrestrictions and classiﬁcation on national security or law enforcement grounds areinadvisable except in unambiguous cases.”1. Did your organization originate these data?Section I: Is it your decisionto apply safeguardsto these data?3. Document your use of the decision procedure.(Have the sensitivity concerns been addressed by the changes to data?)4. Are these data useful for selecting specific target(s), and/or for planning and executing an attack on a potential target?6. Do the security costs outweigh the societal benefits of active dissemination of these data?8. Would the public still be served, and the security risk be mitigated, by changing these data?5. Is the information unique to these data?YesYesYesYes11. Do you have the authority to restrict these data?No12. Will the appropriate decision maker give permission to restrict these data?Decision orprocessValid endpoint for useof the guidelinesNoNoYes9. Do you have the authority to change these data?YesNoNo10. Change these data.14.Safeguardingis notauthorized.Section II: Do thesedata need to besafeguarded?Section III: What safeguardsare authorized and justified?13. Decidethe extent ofrestrictions.7.Safeguardingis notjustified.2. Followinstructionsof originatingorganization.NoNoNoYesYesFig. 1.6FGDC decision tree for providing appropriate access to geospatial data in response tosecurity concernshttp://www.fgdc.gov/fgdc/homeland/revised_access_guidelines.pdfTHO_C01  20/03/2007  14:47  Page 23 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f24DAVID J. COWENUnder the Critical Infrastructure Information Act of 2002 the Department ofHomeland Security has developed its own program to assemble important data fromutility companies and local governments. This Protected Critical InfrastructureInformation (PCII) Program solicits potentially sensitive information from privateand other sources and if the information qualiﬁes for protection it restricts the distribution. The PCII Program, creates a new framework which enables membersof the private sector to, for the ﬁrst time, voluntarily submit sensitive informationregarding the nation’s critical infrastructure.FGDC clearinghousesOrganizations around the world have established their own methods for distribut-ing geospatial data. In fact, a web search for “GIS clearinghouse” performed bythe author on June 3, 2006 generated a list of more that 1,500,000 links. Most of these sites do not conform to a standard set of guidelines and are not linkedinto a comprehensive network. In contrast to these ad hocsites, the FGDC has fostered the creation of ofﬁ",
    "chunk_order_index": 19,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0440654347f770896a3f800d7909dd3d": {
    "tokens": 1200,
    "content": ".FGDC clearinghousesOrganizations around the world have established their own methods for distribut-ing geospatial data. In fact, a web search for “GIS clearinghouse” performed bythe author on June 3, 2006 generated a list of more that 1,500,000 links. Most of these sites do not conform to a standard set of guidelines and are not linkedinto a comprehensive network. In contrast to these ad hocsites, the FGDC has fostered the creation of ofﬁcial Geospatial Data Clearinghouses that follow a setof rigorous standards. The success of these ofﬁcial clearinghouses is directly linkedto the widespread acceptance of the FGDC metadata standards and their adoptionby public agencies (Figure 1.7). The key to the success of these clearinghouses is the ability to discover and acquire geospatial data by harvesting metadata.Fortunately, the library community developed an ANSI/ISO protocol for network-based search and retrieval of such metadata. At the current time this standard isFGDCMETADATAPREPARATION(mp)LINK TOCLEARING-HOUSEINTERFACEIsiteZ39.50SoftwareGETMETATOOLSGETISITEWeb SiteHTMLSGMLTEXTREGISTERYOURSERVERCONFIGURESERVE(zserver)TESTSERVERADMINISTRIVIATESTINDEXINDEX(lindex)FGDCSTYLEMETADATAFig. 1.7FGDC steps to create a clearinghousehttp://www.fgdc.gov/clearinghouse/tutorials/imagetour.htmlTHO_C01  20/03/2007  14:47  Page 24 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA25the Z39.50 protocol. By adopting this standard it was possible for the FGDC toestablish geospatial data clearinghouses that could be assembled under a looselystructured federation (Figure 1.7). It should be noted that while organizations mustprovide metadata that accurately describes the data this does not ensure that theactual data is current or accurate.Throughout the world there are more than 250 clearinghouse nodes whichadvertise that they have geographic data that they are willing to share. These nodescan be assessed through six FGDC clearinghouse gateways as follows: (1) AlaskaGeographic Data Committee; (2) EROS Data Center; (3) FGDC; (4) NOAA CoastalServices Center; (5) Natural Resources Conservation Service (NRCS); and (6) ESRI.Each of the gateways provides a link to determine the status of the network ofclearinghouses. They also utilize a standard NSDI search wizard to “smart select”servers and data. The ﬁrst step in this search process involves the selection of atopic of interest from a list of themes (Table 2.2).Geospatial One-Stop (http://www.geo-one-stop.gov/)As noted above, in an ideal world there would be a one stop shop for geographic data.This is exactly the goal of Geospatial One-Stop (GOS) which is one of the President’sElectronic Government (E-GOV) Initiatives in the USA. In the broadest sense GOShas been established as a web-based government gateway to the geographic dataTable 1.2NSDI Geospatial Data Clearinghouse TopicsAdministrative and Political BoundariesAgriculture and FarmingAtmospheric and Climatic DataBase Maps, Scanned Maps, and ChartsBiologic and Ecologic InformationBusiness and Economic InformationCadastral and Legal Land DescriptionsEarth Surface Characteristics and Land CoverElevation and Derived ProductsEnvironmental Monitoring and ModelingFacilities, Buildings, and StructuresGeodetic Networks and Control PointsGeologic and Geophysical InformationHuman Health and DiseaseImagery and Aerial PhotographsInland Water Resources and CharacteristicsOcean and Estuarine Resources and CharacteristicsSociety, Cultural, and Demographic InformationTourism and RecreationTransportation Networks and ModelsUtility Distribution NetworksTHO_C01  20/03/2007  14:47  Page 25 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f26DAVID J. COWENmarketplace. GOS is a voluntary system that has been established to encourage organizations to publish geographic content such as maps, data and geographic activities, or events.GOS provides direct links to a wide range of public sector clearinghouses (Figure 1.8). There are links to every state level clearinghouse, and private com-panies may also advertise their sites. An important function of GOS is to serve as a site for information on future investments in geospatial information. Posting details on this site about future data capture investments is designed to provideopportunities for collaboration such as intergovernmental partnerships.While GOS represents a major step forward in providing a uniform starting point for locating geographic data it does not guarantee a consistent result and may not be the best way to locate desired data. For example, someone looking forwetlands data will be rewarded with a robust site for accessing the National WetlandsInventory maintained by the US Fish and Wildlife Service (Figure 1.9). Other searchesthrough the GOS portal will not result in such positive outcomes. For example, byfollowing a link to Cultural, Society and Demographic data and the subcategoryLaw Enforcement one gets directed to the general FBI web site with no obviouslinks to any",
    "chunk_order_index": 20,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0253499b5e990679c45afc69f4a2e3bd": {
    "tokens": 1200,
    "content": "be the best way to locate desired data. For example, someone looking forwetlands data will be rewarded with a robust site for accessing the National WetlandsInventory maintained by the US Fish and Wildlife Service (Figure 1.9). Other searchesthrough the GOS portal will not result in such positive outcomes. For example, byfollowing a link to Cultural, Society and Demographic data and the subcategoryLaw Enforcement one gets directed to the general FBI web site with no obviouslinks to any GIS data or mapping sites.Fig. 1.8Geospatial One-Stophttp://www.geo-one-stop.gov/THO_C01  20/03/2007  14:47  Page 26 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA27The National Map (http://www.nationalmap.usgs.gov)The USGS initiative to create a National Map is intended to complement the FGDCand Geospatial One-Stop (Figure 1.10). In fact, these three entities are organizedwithin the National Geospatial Programs Ofﬁce (NGPO) under the leadership ofan Associate Director for Geospatial Information (ADGI) and Chief InformationOfﬁcer.The vision for the National Map is to create nationally consistent layers of highresolution digital orthoimagery, elevation and bathymetry, hydrography, trans-portation, structures, boundaries of government features, geographic names, andland cover. More importantly, the USGS envisions that all of these data themeswill form seamless resources that are complete, consistent, integrated, and current.Technically, The National Map is a distributed series of web servers that cooper-ate “to coordinate and negotiate access to their data, develop protocols for dataintegration, develop data maintenance processes, and deﬁne data requirements.” For example, North Carolina has established a state-level program (NC One Map;see http://www.nconemap.com/ for additional details) that serves as an umbrellafor state, county, and local government partnerships. Therefore, as one interactivelyFig. 1.9US Fish and Wildlife Service Wetlands Mapper http://www.fws.gov/data/IMADS/index.htmTHO_C01  20/03/2007  14:47  Page 27 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f28DAVID J. COWENpans and zooms across North Carolina, the user is informed about several stateand local governments that have agreed to share their data.The National Map provides extensive web-based mapping and data discoverytools. One can view the data (quilt patches) that have been contributed by localpartners. In some cases this includes high resolution orthophotography, buildingfootprints, and even parcel boundaries. An important aspect of The National MapViewer is that it supports download of some vector features and raster images.The National Map also provides a link to the Seamless Data Distribution System(SDDS; Figure 1.11) that is maintained by the EROS Data Center to provide anonline map interface to view the data sets listed in Table 1.3 that are available fordownload or media delivery.Fig. 1.10The National Maphttp://nationalmap.usgs.gov/THO_C01  20/03/2007  14:47  Page 28 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA29Table 1.3USGS Seamless Data Distribution SystemNational Elevation Data set (NED) 1 Arc Second (~30 m resolution)National Elevation Data set (NED) 1/3 Arc Second (~10 m resolution)National Elevation Data set (NED) 1/9 Arc Second (~3 m resolution)National Landcover Characterization Data set (NLCD)Shuttle Radar Topography Mission (SRTM) 1 Arc Second (~30 m resolution) USElevation Data setShuttle Radar Topography Mission (SRTM) 3 Arc Second (~90 m resolution) GlobalElevation Data setHigh Resolution Orthoimagery1 meter Orthoimagery (limited areas)Moderate Resolution Imaging Spectroradiometer (MODIS) Direct Broadcast USNormalized Difference Vegetation Index (NDVI) 7-day CompositesBureau of Transportation Statistics (BTS) Roads Vector DataFig. 1.11The National Map Seamless Data Distribution System Viewerhttp://seamless.usgs.gov/website/seamless/viewer.phpTHO_C01  20/03/2007  14:47  Page 29 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use",
    "chunk_order_index": 21,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ba7064385a602f5e2b17848f4af34ef9": {
    "tokens": 1200,
    "content": "Viewerhttp://seamless.usgs.gov/website/seamless/viewer.phpTHO_C01  20/03/2007  14:47  Page 29 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f30DAVID J. COWENThere is a wide range of options for acquiring data from the SDDS. These optionsrange from free downloads of small amounts of data to the purchase of a 250 GBhard drive loaded with data for US$950 (Table 1.4).The National AtlasIn 1997 the USGS provided some of the ﬁrst web-based mapping functions with theNational Atlas (Figure 1.12). For maps and data at a scale of about 1:2,000,000Table 1.4USGS Earth Explorer Data SourcesSatellite ImageryAdvanced Very High Resolution RadiometerDeclassiﬁed Satellite Imagery – 1 (1996)Declassiﬁed Satellite Imagery – 2 (2002)EO-1 Advanced Land ImagerEO-1 HyperionETM+(Landsat 7, June 1999–May 2003)ETM+SLC-off (Landsat 7, July 2003–present)Landsat Orthorectiﬁed TM MosaicsMSS (Landsat 1–5, July 1972–October 1992)SPOT (Search Only)TM (Landsat 4–5, July 1982–present)Aerial PhotographyDigital Orthophoto QuadranglesDigital Orthophoto Quadrangles – CountyNational Aerial Photography Program (1987–present)National High Altitude Photography (1980–9)Space Acquired PhotographySurvey PhotographyUSGS High Resolution PhotographyDigital Line GraphsDigital Line Graph – 1:100,000 scaleDigital Line Graph – Large ScaleElevationDigital Elevation Model – 15 MinuteDigital Elevation Model – 30 MinuteDigital Elevation Model – 7.5 MinuteNational Elevation Data set (Predeﬁned Areas)Maps (Related Links)Digital Raster GraphicsNational Atlas of the United StatesTHO_C01  20/03/2007  14:47  Page 30 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA31the National Atlas provides an extremely useful way to discover, view, and evendownload data. The National Atlas is a useful national and regional atlas that hasevolved into a source for acquiring spatial data.ESRIIt would be remiss to discuss the current status of geographic data availability with-out including Environmental Systems Research Institute, Inc. (ESRI), an importantworldwide commercial supplier of GIS software and services. ESRI serves as one ofthe six NSDI Gateways to Ofﬁcial NSDI Data Clearinghouses. It also operates theGeography Network (http://www.geographynetwork.com/) that is a NSDI clearing-house node. In a dynamic web environment ESRI provides several ways to accessthe Geography Network (Figure 1.13). They provide the following categories ofdata access: (1) downloadable data; (2) dynamic data and maps; (3) ofﬂine data;and (4) clearinghouses. ESRI and other companies are providing a new form ofweb services to users. These services do not require the user to acquire specializedapplication software.Fig. 1.12The National Atlashttp://www.nationalatlas.gov/THO_C01  20/03/2007  14:47  Page 31 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f32DAVID J. COWENOther InitiativesAn additional aspect of geographic data availability involves a group of organizationsthat advocates various positions regarding the creation and distribution of geographicdata. The data producer side is represented by the Management Association forPrivate Photogrammetric Surveyors (MAPPS). MAPPS is an association of ﬁrms inthe surveying, spatial data, and geographic information systems ﬁelds. The objectiveFig. 1.13The Geography Networkhttp://www.geographynetwork.com/THO_C01  20/03/2007  14:47  Page 32 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA33of MAPPS is to “promote the business interests of the profession. Whether it is ﬁght-ing unfair competition by government, universities or non-proﬁt entities, or promotingqualiﬁcations-based selection, MAPPS enhances the ability of its member ﬁrms",
    "chunk_order_index": 22,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4336c4706edae94c431561ba84c70c49": {
    "tokens": 1200,
    "content": "https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE AVAILABILITY OF GEOGRAPHIC DATA33of MAPPS is to “promote the business interests of the profession. Whether it is ﬁght-ing unfair competition by government, universities or non-proﬁt entities, or promotingqualiﬁcations-based selection, MAPPS enhances the ability of its member ﬁrms toparticipate in our great free enterprise system: the business of MAPPS is the businessof maps” (see http://www.mapps.org/ for additional details).An interesting organization on the consumer side of the business is the Open DataConsortium (ODC) which advocates the following principles:1Public information is a necessary component of the democratic process and opengovernment;2The value of geospatial data is realized through its usage;3Widespread distribution and use of public geodata beneﬁts the data steward’sentire jurisdiction;4Public agencies increasingly store data electronically, and such digital data con-stitutes the public record;5In their roles as data custodians, public agencies have a responsibility to makedata available both for citizen access, and to reduce duplication of effort amongpublic agencies;6Public agencies need funding to develop, maintain, and distribute their data.The fact that organizations such as MAPPS and ODC exist suggests that the issuessurrounding the availability of geographic data are quite contentious and will con-tinue to be in the future.CONCLUSIONSOver the past three decades an extremely robust industry has emerged that relieson a steady supply of geographic data that serve a growing number of public andprivate organizations that require accurate, current, and reliable information about theconditions of features on the Earth’s surface. The expanding demand for geographicdata will be fueled by location-based services that are ported to an ever increasing setof spatially aware devices (see Chapter 32 by Brimicombe, this volume, for additionaldetails). The utilization of these data resources has the potential to improve the levelof decision making and planning throughout society. They should enable companiesin the private sector to be more efﬁcient and responsive. The proper use of the data in the public sector will make government more accountable and more equitablein the way it protects the health and safety of its citizens. While we have witnessedexciting technical developments in the way we gather, use, and distribute geographicdata we face many obstacles that often inhibit and frustrate the user community.There are several efforts such as Geospatial One-Stop and The National Map thatare addressing the problems with locating, acquiring, and using geographic data.REFERENCESAnderson, K., Marx, R., and Keffer, G. 1985. A prospective case for a national land datasystem: Ten years later. In Proceedings of the Fifty-ﬁrst ASP– ACSM Annual Meeting,Washington, DC, USA.THO_C01  20/03/2007  14:47  Page 33 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f34DAVID J. COWENBaker, J., Lachman, B., Frelinger D., O’Connell, K., Hou, A., Tseng, M., Orletsky, D., andYost, C. 2004. Mapping the Risks: Assessing the Homeland Security Implications of PubliclyAvailable Geospatial Information. Santa Monica, CA: Rand National Defense ResearchInstitute (available at http://www.rand.org/pubs/monographs/2004/RAND_MG142.pdf).Broome, F. R. and Godwin, L. S. 2003. Partnering for the people: Improving the U.S. CensusBureau’s MAF/TIGER Database. Photogrammetric Engineering and Remote Sensing 69:1119–16.Cowen, D. J. and Craig, W. 2004. A retrospective look at the need for a multipurpose cadastre. Surveying and Land Information Science63: 205–14.FGDC. 2005. Metadata. WWW Document, http://www.fgdc.gov/metadata/metadata.htmlFGDC Homeland Security Working Group. 2004. FGDC guidelines for providing appro-priate access to geospatial data in response to security concerns. WWW document,http://www.fgdc.gov/fgdc/homeland/revised_access_guidelines.pdf.Gewin, V. 2004. Mapping opportunities. Nature427: 376–7 (available at http://www.aag.org/nature.pdf).Her Majesty’s Stationary Ofﬁce. 1988. Copyright, Designs and Patents Act 1988. WWWdocument, http://www.hmso.gov.uk/acts/acts1988/Ukpga_19880048_en_1.htm.Lopez, X. R. 1996. Stimulating GIS innovation through the dissemination of geographic information.Journal of the Urban and Regional Information Systems Association8(3):24–36.NRC (National Research Council). 1990. Spatial Data Needs: The Future of the NationalMapping Program.Washington, DC: National Academy Press.NRC. 1993. Toward a Coordinated Spatial Data Infrastructure for the Nation. Washington,DC: National Academy Press (available at http://books.nap.edu/openbook/0309048990/html/index.html).NRC. 2003. Weaving a National Map: Review of the U.S. Geological Survey Concept",
    "chunk_order_index": 23,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ebdb2722a623f6ff05f0dc23cc1a4dbc": {
    "tokens": 1200,
    "content": "36.NRC (National Research Council). 1990. Spatial Data Needs: The Future of the NationalMapping Program.Washington, DC: National Academy Press.NRC. 1993. Toward a Coordinated Spatial Data Infrastructure for the Nation. Washington,DC: National Academy Press (available at http://books.nap.edu/openbook/0309048990/html/index.html).NRC. 2003. Weaving a National Map: Review of the U.S. Geological Survey Concept of theNational Map. Washington, DC: National Academy Press (available at http://www.nap.edu/books/0309087473/html).NRC. 2004. Licensing Geographic Data and Services.Washington, DC: National AcademyPress.Ofﬁce of the Federal Register 1994. Executive Order 12906. Federal Register59(71):17671–4.Richland County, South Carolina 2005. Richland County Geographic Information Systems(RC GEO). WWW document, http://www.richlandmaps.com/.USGS. 1989. Digital Line Graphs from 1:100,000-scale Maps: Data Users Guide 2: Reston,VA: US Geological Survey.USGS EROS Data Center. 2005. Seamless Data Distribution System. WWW document,http://seamless.usgs.gov/.US Ofﬁce of Management and Budget. 2004. Circular A-130. WWW document, http://www.whitehouse.gov/omb/circulars/a130/a130.html.THO_C01  20/03/2007  14:47  Page 34 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 2Social DataDavid J. MartinIn this chapter we shall be concerned with data that relate to human populationsand their activities. We shall explore the sources and spatial characteristics of socialdata with a view to their implications for Geographic Information Systems (GIS)analysis, but will not examine analytical techniques in detail as these will be coveredin later chapters. There is continuing growth in the availability and sophisticationof social data sources globally, although change in the key phenomena of interestis more subtle: issues such as social exclusion and accessibility remain as import-ant in the early 2000s as they were to nineteenth-century commentators, althoughtheir manifestation is continually evolving (Dorling, Mitchell, Shaw, Orford, andDavey-Smith 2000, Thurstain-Goodwin 2003). Methods for geographic referenc-ing and the value of linking data from different sources continue to have enormousimportance in social GIS applications at a time when there is evidence of a retreatfrom conventional population censuses towards alternative mechanisms of socialdata gathering. Data collection environments, ethical considerations, and data pro-tection measures are growing in signiﬁcance, with new challenges emerging overdetailed personal data and the principles governing their use.The key sources for social data are administrative records, censuses, and surveys.A further dimension to social data is added by remote sensing, although the latterdoes not form a major emphasis in this chapter. Increasing resolution in geographicreferencing is leading to more detailed attention on the ontologies of relevance tosocial data, speciﬁcally to more careful deﬁnition of households and residents and to continued interest in concepts of “neighborhood” (Kearns and Parkinson 2001).In part, this change of focus is due to the wealth of potential data. Household deﬁnitionissues are more important when we can realistically access geographically referencedindividual records than when the only available social data are aggregated acrossmany hundreds of dwelling units. GIS has also become important to the actual collec-tion and management of social data in addition to the traditional role, whereby GIScontributed to their visualization and analysis. The 2000/1 round of censuses hasbeen signiﬁcantly inﬂuenced by the use of GIS technology in national statistical organ-izations, and plans for future social data collection are being strongly inﬂuencedby geographic referencing strategies and data management considerations.THO_C02  19/03/2007  11:09  Page 35 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f36DAVID J. MARTINIn the remainder of this chapter we shall visit each of these issues in more detail,beginning with the fundamental objects of interest in social GIS. We shall then moveon to consider the principal social data sources, before dealing more speciﬁcallywith representational considerations for the use of social data in GIS. These repres-entational issues are also addressed in Martin (1999). Our discussion is intendedto be international in application and examples have been drawn from a variety ofcountries, although this is necessarily an illustrative rather than exhaustive review.Social Data EntitiesThe smallest social unit in GIS applications has usually been conceived as the indi-vidual person. Further, some deﬁnition of household or family unit is also elementalfor many purposes, as is a deﬁnition of the dwelling unit. Dwelling units are frequentlythe smallest entity to which a geographic reference can be attached. Individuals andhouseholds are generally indirectly georeferenced, for example by linkage to a dwellingunit address or code. Events such as hospital admissions or unemployment episodesfall below the",
    "chunk_order_index": 24,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d42a1621e52e50fb479c0451e60ae8a8": {
    "tokens": 1200,
    "content": "smallest social unit in GIS applications has usually been conceived as the indi-vidual person. Further, some deﬁnition of household or family unit is also elementalfor many purposes, as is a deﬁnition of the dwelling unit. Dwelling units are frequentlythe smallest entity to which a geographic reference can be attached. Individuals andhouseholds are generally indirectly georeferenced, for example by linkage to a dwellingunit address or code. Events such as hospital admissions or unemployment episodesfall below the level of the individual person, and may be georeferenced either bylinkage to a speciﬁc person or via some other known location: only recently hassufﬁcient precision been available for such events to be treated individually in someGIS applications. Above the person and household scales a series of imposed geo-graphic units may be of interest either for practical or analytical purposes and thesecould all be interpreted to a greater or lesser degree as measures of something called“neighborhood”. A neighborhood in these terms may represent a very small aggre-gation of the elemental units – perhaps to a street block face or unit postcode – rang-ing up to a distinct settlement or identiﬁable administrative or social subdivisionwithin a city.The increasing resolution of available geographic referencing systems has broughtdeﬁnitional issues much more to the fore, and this is particularly relevant with thegrowing use of administrative sources for social GIS data. The 2001 UK censuses,for example, have been signiﬁcantly challenged by the changing nature of house-holds and dwellings. Conventional census deﬁnitions are increasingly unable to accom-modate complex arrangements in which professionals dwell at a city apartment duringthe week and a family home outside the city at the weekend, or with children whospend different parts of the week with different parents, each of whom may be resident in households with other children from different partnerships. By contrast,similar basic dilemmas are observable in the 2001 South African census in whicha single rural residential compound may contain several dwellings, each occupiedby different branches of the same family yet considered by the inhabitants to be asingle “household.” In the face of such complex social realities, simple conventionalclassiﬁcations of households are inadequate.For many years, social data have only been made available to most GIS users asaggregate counts for areas – typically census areas – and there has been relativelylittle concern with the detailed deﬁnition of elemental units such as persons andhouseholds from a geographic referencing perspective. Of more concern have beenthe ways in which the ﬁxed reporting units could be related to the higher orderentities such as neighborhoods and suburbs. The lowest available levels of geographicTHO_C02  19/03/2007  11:09  Page 36 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSOCIAL DATA37referencing vary widely between countries, but the general trend is towards increasingspatial resolution. Areally aggregated social data are particularly prone to ecologicalfallacy and modiﬁable areal unit problems that are very relevant to the social GIS user(Openshaw 1984, Fotheringham and Wong 1991). This long-recognized group ofissues presents obstacles to statistical inference from areally aggregated data, whichare sensitive both to the scale and speciﬁc aggregation designs applied, and in which individual-level associations may be obscured or even reversed by aggregation.These problems arise primarily from the fact that the areal units over which social data are aggregated are usually deﬁned in terms which are only weakly relatedto socio-economic characteristics. Thus a street block face or political division have meaningful interpretations for the purposes of organizing mail delivery or local elections, but there is no necessary reason why their boundaries should be coin-cident with the social transitions that might be recognized by residents. The extentto which meaningful social neighborhoods are indeed recognizable is subject to intense debate. Galster (2001) presents a review of neighborhood deﬁnitions not-ing several separate traditions in the academic literature according to whether the concern is with purely ecological perspectives or with more socially-orienteddeﬁnitions. All of these suffer from weaknesses which make them problematic fromGIS and policy perspectives, and almost all conceptualizations of neighborhoodacknowledge that the phenomenon is recognizable at several spatial scales (Kearnsand Parkinson 2001).A further layer of complexity is added when the temporal dimension is to betaken into account. This operates at two scales: the long-term over which changeoccurs in the economic and social characteristics of neighborhoods, and real-timein which people travel through the settlement structure. Neighborhood-level changeis often obscured by changes in reporting geographies, whereby administrative pro-cesses dictate redrawing of boundaries, making impossible direct comparison of thesame small area between two consecutive censuses. Traditional data sources havegenerally captured night-time populations via residential locations. Increasingly, weare also interested in population ﬂows and in daytime locations or even 24-hourpopulation dynamics. For the purposes of cellular telephony, location-based services,emergency planning, and sophisticated retail modeling it is not sufﬁcient to under-stand only the distribution of the population when they are mostly asleep at homeat 2 a.m., but also necessary to be able to capture commuting and leisure ﬂowswhich reveal the locations of ofﬁce workers at lunchtime and sports fans traveling toa major weekend event. At present, our understanding of such 24-hour geographiesis still formative, but already detailed data are being captured which will help tomodel such phenomena.One of the greatest challenges to socio-economic GIS is ﬁnding appropriate",
    "chunk_order_index": 25,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ebb18235061fd2e8ee7fc48388249aca": {
    "tokens": 1200,
    "content": "under-stand only the distribution of the population when they are mostly asleep at homeat 2 a.m., but also necessary to be able to capture commuting and leisure ﬂowswhich reveal the locations of ofﬁce workers at lunchtime and sports fans traveling toa major weekend event. At present, our understanding of such 24-hour geographiesis still formative, but already detailed data are being captured which will help tomodel such phenomena.One of the greatest challenges to socio-economic GIS is ﬁnding appropriate dataand representational models to match such imprecise concepts as household andneighborhood. It is important that this is not seen as a search only for an “optimal”data structure or zoning solution, but that we develop GIS models which more realistically capture the perceptual spatial knowledge on which most individual decision-making is based. In the following section we shall consider the avail-able sources of social data, recognizing that none of these capture the full range of diversity and complexity encountered in social reality, and that value judgmentsare required at every stage of GIS representation and modeling.THO_C02  19/03/2007  11:09  Page 37 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f38DAVID J. MARTINSocial Data SourcesWe may usefully begin our consideration of social data sources by considering thethree dimensions of spatial aggregation, attribute detail, and ease of access. Withinthis three-dimensional space we will place our three major sources of social data,namely administrative records, censuses, and surveys, as illustrated in Figure 2.1.Ease of access is not just the result of arbitrary procedural arrangements, but a keyconsideration in social data. This relates to local interpretation both of data pro-tection measures and ethical issues associated with personal data – topics whichare addressed more fully in Chapter 29 of this volume by Cho. Administrative data sources display the lowest geographic aggregation, but verylow accessibility and only moderate attribute detail. Census data are more readilyaccessible, and offer more attribute detail in many respects, but cover a broaderrange of aggregation scales, often to quite coarse geographies. Survey data also rangein aggregation scale, frequently available only for very large geographic units, but provide high levels of attribute detail and greater ease of access than most administrative sources. Survey and census data are usually subject to some mini-mum population threshold requiring aggregation before publication. The three principal sources of social GIS data thus occupy this space, differing in detail be-tween speciﬁc data sources and national contexts, but generally adhering to the characteristics outlined here. Webber and Longley (2003) note that while govern-ment has tended to place reliance on censuses and information abstracted from admin-istrative sources in its modeling of population need, commercial organizations are often forced to rely on the ﬁndings of syndicated market research surveys and to use geodemographic classiﬁcations as the bridge between survey results anddenominator populations, indicating the importance of the accessibility axis in determining actual data use. It will become apparent that as national statistical organizations respond to contemporary data collection challenges, the traditionalboundaries between censuses, surveys and administrative sources are becoming increas-ingly blurred.AttributedetailEase ofaccessLevel of aggregationCensusesSurveysAdminrecords LowLowLowHighHighHighFig. 2.1Comparison of principal social data sources by attribute detail, level of aggregation andease of accessTHO_C02  19/03/2007  11:09  Page 38 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSOCIAL DATA39Administrative recordsAdministrative records refer to data which are collected as a result of routine organizational activities. In some countries, particularly in Scandinavia, there areexplicit population registers which aim to capture all members of the population.In the Netherlands, the integration of administrative data sources has replaced conventional census taking, with the census data now being derived from matchedadministrative records (van der Laan 2001). In many other national settings whereexplicit population registers do not exist there are nevertheless multiple populationlistings associated with government functions such as electoral registration, healthcare delivery, and personal taxation. These lists generally contain information notonly on the registered population, but provide limited attribute information includ-ing basic personal or property characteristics and some information on service usage.Frequently such registers do not actually contain any speciﬁc denominator and recordsrelate to service delivery events. For example, UK Hospital Episode Statistics (HES)record instances of patients in hospital. Thus a single patient, or even a single illness,may be represented by several distinct entries in the HES system. Vital events registra-tion systems also fall into this category, recording instances of births and deathsbut not any record of the base population. In each of these cases it is usually somelevel of the residential postal address which is used to georeference the event beingrecorded. Administrative sources may thus provide us with either denominator orevent data. The quality of address or property listings again varies widely betweennations, with the nature of property taxation having a major impact on the existenceand quality of cadastral maps and records. Such lists may also be maintained byutility companies or postal services, and by commercial organizations in the formof customer records, frequently providing large sample sizes and very rich attributeinformation. Some",
    "chunk_order_index": 26,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e4ba8f26bfa5a144a0b9274e808d83c6": {
    "tokens": 1200,
    "content": "address which is used to georeference the event beingrecorded. Administrative sources may thus provide us with either denominator orevent data. The quality of address or property listings again varies widely betweennations, with the nature of property taxation having a major impact on the existenceand quality of cadastral maps and records. Such lists may also be maintained byutility companies or postal services, and by commercial organizations in the formof customer records, frequently providing large sample sizes and very rich attributeinformation. Some real-time administrative data with high geographic resolutionare being captured, for example by cellular telephone operators although to dateaccess to such information has been highly restricted.Coverage issues are paramount when considering the potential of administrativedata sources for social GIS applications: very few listings short of a full popula-tion register or comprehensive cadastre actually capture the entire population orall dwelling units. Lists maintained for almost any non-statistical purpose are liable tosystematic omissions and biases: electoral registers capture only those entitled to vote,thus omitting children, non-native residents and all those who choose not to regis-ter; postal service address lists capture only those addresses which receive post, thusomitting industrial and other premises which may still be locations of employ-ment or other activities. The National Health Service Register, probably the UK’sbest approximation to a population register, is based on patient registration witha primary care doctor and in most areas represents an over-count of the populationasthere are no automatic mechanisms for removing patients who move away froman area but fail to inform their doctor (Haynes, Lovett, Bentham, Brainard, andGale 1995). Understanding the utility of such administrative data sources requiresa very careful consideration of the basic social data entities noted above in orderto determine whether the deﬁnitions and assumptions implicit in the data sourcematch those required for the GIS application. These considerations are additionalto speciﬁc issues of geographic referencing, which are addressed below.THO_C02  19/03/2007  11:09  Page 39 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f40DAVID J. MARTINAdministrative records that contain information about individual members of thepopulation are also subject to various levels of data protection that may preventtheiruse outside the organization by which they were originally created. In generalterms, data protection legislation seeks to preserve the anonymity of individuals andmay further require that personal data are used only for purposes made known tothe individuals at the time of data collection. A particular example of the challengesfor GIS use arising from this situation relates to the use of medical information forstatistical analysis and health care planning. The handling of such data is gener-ally governed by nationally-speciﬁc guidelines such as the UK’s Caldicott principles(Table 2.1),which grew out of a review of the ways in which patient informationis used. These principles recognize that while there is a need to protect the con-ﬁdentiality of individual patients, such information also underpins analyses that are essential to the effective organization of a health care system. Such guidelinestypically place restrictions on the data owner and may involve the appointment ofTable 2.1Summary of UK Caldicott principles for use of patient-identiﬁable data(adapted from http://www.learnonline.nhs.uk/info_gov/Caldicott.asp)Principle123456SummaryJustify purpose for useIndividually identiﬁable datashould be used only whereabsolutely necessaryIndividually identiﬁable datashould be kept to a minimumAccess to individuallyidentiﬁable informationshould be on a strict need-to-know basisEveryone with access topatient-identiﬁableinformation should be awareof their responsibilitiesUnderstand and comply withthe lawExplanationEvery proposed data use should be clearlydeﬁned and scrutinized, and continuing usereviewed, by an appropriate data guardian.Individually identiﬁable information itemsshould only be included where they areessential for the speciﬁc work purpose. The need for such data should be consideredat each stage of the work.Where use of individually identiﬁableinformation is considered to be essential theneed for each individual data item should beconsidered and justiﬁed so that the minimumof identiﬁable information is made available.Only those individuals who need access toindividually identiﬁable information shouldhave access to it, only have access to theitems that they require.All those handling individually identiﬁableinformation should be made fully aware of their responsibilities and obligations torespect conﬁdentiality.All use of individually identiﬁableinformation must be lawful. Someone ineach organization should be responsible forensuring that the organization complies withlegal requirements.THO_C02  19/03/2007  11:09  Page 40 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSOCIAL DATA41a review panel or data guardian to examine applications for data use. Administrativeinformation collected by commercial organizations is generally additionally protectedfor reasons of competitive advantage and may thus be unobtainable outside thecollecting organization or may be traded at a market price. Increasingly, adminis-trative records provide new sources for aggregate statistics, such as the UK’s newNeighbourhood",
    "chunk_order_index": 27,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f7b1ddbcf820535e41a1c8914ae2c13e": {
    "tokens": 1200,
    "content": "-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSOCIAL DATA41a review panel or data guardian to examine applications for data use. Administrativeinformation collected by commercial organizations is generally additionally protectedfor reasons of competitive advantage and may thus be unobtainable outside thecollecting organization or may be traded at a market price. Increasingly, adminis-trative records provide new sources for aggregate statistics, such as the UK’s newNeighbourhood Statistics system which is based on the aggregation of records ingovernment administrative systems so as to provide small area data series that wouldnot be available from other sources. Integration with census data is provided by theuse of a common geographic framework (Ofﬁce for National Statistics 2003).CensusesA frequently cited characteristic of censuses is that they provide the most spatiallydetailed geographic social data with the highest coverage of the population. It istherefore unsurprising that census data form a major component of most social GISimplementations. Censuses attempt to collect a broad range of social data on theentire population of a country, although this is becoming harder to achieve due to increasing non-compliance with census-taking. Census data are typically avail-able for a hierarchy of geographic units ranging from neighborhood to nationalscales, and in many countries digital boundary data are available to support GISanalysis of census results. A comprehensive review of the UK Census data systemleading up to the 2001 census is provided by Rees, Martin, and Williamson (2002).Census data are usually subject to speciﬁc conﬁdentiality legislation which requiresdata protection measures be applied – such as data suppression for areas that fallbelow some population threshold size, and randomization or rounding of counts forsmall areas. Data for small areas are also subject to randomization and roundingso as to protect the identity of individuals with distinctive characteristics. A com-parison of the attribute coverage of four national censuses from the 2000/1 round isgiven in Table 2.2. In each of these countries the internal structure of householdsis captured through a grid of questions about relationships between household members, although these differ in detail. More important differences reﬂect differ-ing social needs, such as the interest in orphaning and childhood survival in SouthAfrica, and the political acceptability of questions, such as the UK’s lack of an incomequestion, the topic being believed to be too sensitive to broach and that to do sowill risk endangering responses to other questions. Most of these census questionstell us little about consumption habits and lifestyle, for which we must rely on admin-istrative and particularly survey data sources.Censuses are also notable for the range of output data products that they canprovide. These include not only the most obvious areally aggregated data and associated geographic boundary frameworks that are widely used for thematic map-ping and GIS, but also microdata samples (Public Use Microdata Samples inCanada and the USA; Household Sample Files in Australia; Samples of AnonymisedRecords [SARs] in the UK) and longitudinal data sets such as the Ofﬁce for NationalStatistics Longitudinal Study in England and Wales. The latter two data types pro-vide extremely rich attribute detail but at the cost of high levels of geographic aggregation to the extent that these data sets rarely appear in GIS applications concerned with small area analysis: in Figure 2.1 they represent that part of theTHO_C02  19/03/2007  11:09  Page 41 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f42DAVID J. MARTINTable 2.2International comparison of 2000/1 census topic coverageEngland and USA 2000 short (S)/Australia South Africa Wales 2001long (L) form20012001Accommodation typeH1, H2L34, L35H-23Accommodation sizeH3L37, L3846H-24Water/toilet/washing facilitiesH4L39H-26, H-27Lowest ﬂoor levelH5Heating (availability, fuel)H6L42H-28Kitchen facilitiesL40Motor vehiclesH7L4345Telephone (availability)L41H-29Household goods (PC, radio, TV, H-29refrigerator)Computer/Internet use20, 21Mode of refuse disposalH-30Accommodation tenure business H8, H9S2, L33, L4447, 49H-25use, landlordHousehold costs, rentL45-L50, L52, L5348Property valueL51Relationships within householdGridGridGridGridSex2S5, L33P-02Age/date of birth3S6, L4, L184P-03Marital status4L76P-05Visitors/absent residentsTables 1, 27, 44P-11Country/place of birth (of parents)7L1211 (13,14)P-09Ethnic group/race8S7, S8, L5, L617, 18P-06Religion10 optional19 optionalP-08Language at home/ English abilityL1115, 16P-07CitizenshipL1310P-10When arrived in countryL1412General state of health11Caring for others12L19Long term illness/disability13L16, L17P-13Address one year ago148Address ﬁve years agoL159P-12Whether parents aliveP-14, P-15",
    "chunk_order_index": 28,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b5cac966f2c6bb726100edba5b54624c": {
    "tokens": 1200,
    "content": "5, L617, 18P-06Religion10 optional19 optionalP-08Language at home/ English abilityL1115, 16P-07CitizenshipL1310P-10When arrived in countryL1412General state of health11Caring for others12L19Long term illness/disability13L16, L17P-13Address one year ago148Address ﬁve years agoL159P-12Whether parents aliveP-14, P-15When moved to present addressL36P-12Live births/surviving childrenP-20Whether in education5L822, 23P-16Recent deaths in householdH-31Term-time address6Qualiﬁcations/completed education16, 17L925–30P-17Military serviceL20Current economic activity/ 18–23L21, L25, L26, L3032, 42, 43P-18employment history/availability for workEmployment status/job title/25, 27–9L28, L2933–5P-19work doneIncomeL31, L3231P-22Employer, business26, 33L22, L2736–9P-19Mode of travel to work34L23, L2441P-21Hours worked3540P-19Values in cells are question numbers on census formsTHO_C02  19/03/2007  11:09  Page 42 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSOCIAL DATA43census domain that is closest to large-scale survey data. Census interaction datadescribe ﬂows of individuals between home and work addresses or between presentand past addresses, offering a snapshot of residential migration and are sometimespublished at sufﬁciently detailed geographic resolution to be a practical data setfor use in GIS. However the two-dimensional nature of these interaction data presentnumerous additional data handling challenges (Stillwell and Duke-Williams 2003)not well handled by conventional GIS.In the face of growing enumeration and coverage challenges at the start of the2000s, several countries are moving away from traditional censuses as the primarysource of ofﬁcial population data collection and looking towards increased use ofadministrative records and large surveys, with an associated explicit move towardmodeled rather than fully enumerated social data, a theme reviewed more fully inMartin (2006).SurveysLarge-scale social surveys supplement the information collected by censuses and administrative sources. Surveys give the opportunity to gather much more attributedetail, perhaps relating to a speciﬁc area of socio-economic activity, such as theUK’s Labour Force Survey (LFS), or to ﬁll gaps in other ofﬁcial statistical systems,for example in order to capture information on international travelers, such as the UK’s International Passenger Survey (IPS). In the commercial world, marketresearch surveys aim to capture household consumption and lifestyle character-istics and may often achieve large sample sizes, albeit with acknowledged biases interms of the types of respondents from which information can be obtained. From theGIS perspective, these data sets share some of the main disadvantages of the censusmicro data sets, in that their relatively small sample sizes and sparse geographiccoverage lead to data aggregation over large geographic regions. Consequently thesedata sources are rarely able to directly provide geographically detailed inputs toGIS applications.The principal data-collection strategies of some major countries for the early yearsof the 2000s may now be best described as surveys rather than censuses: France ismoving to a rolling census model, whereby each small area is surveyed once everyﬁve years (Durr and Dumais 2000) and the USA has adopted a continuous popula-tion survey known as the American Community Survey (Alexander 2000) to replacethe information previously gathered by the “long form” census data (Table 2.2)on a rolling basis and to be used alongside a census short form in 2010.Remotely sensed dataMesev (2003a) makes it clear that sensing cities remotely is a difﬁcult endeavor. Manyof the socio-economic variations in which the social GIS users are likely to be mostinterested are not directly observable – whether from the ground or sky. Nevertheless,there is a distinct role for remote sensing in providing additional information to thatcaptured by our three ground-based groups of data sources, particularly in rela-tion to urban land use and the estimation of population data for regions in whichconventional measurement is impractical. The attribute information which can beTHO_C02  19/03/2007  11:09  Page 43 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f44DAVID J. MARTINcaptured by this means are generally limited to those aspects which are reﬂected bysettlement extent, land use, and energy usage (see Chapter 3 by Lees in this volumefor additional details on the role of remote sensing in delineating these features).Nevertheless these may be valuable clues to updating ground information in areasnot covered by ground data collection, particularly where rapid development is taking place. Interested readers will ﬁnd a contemporary review of techniques inMesev (2003b), including methodologies for the complementary use of census andremot",
    "chunk_order_index": 29,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b54990172f4ce2656688bcc421e7fef1": {
    "tokens": 1200,
    "content": "which are reﬂected bysettlement extent, land use, and energy usage (see Chapter 3 by Lees in this volumefor additional details on the role of remote sensing in delineating these features).Nevertheless these may be valuable clues to updating ground information in areasnot covered by ground data collection, particularly where rapid development is taking place. Interested readers will ﬁnd a contemporary review of techniques inMesev (2003b), including methodologies for the complementary use of census andremotely sensed data.Social Data Representation in GISRepresentation here refers to technical, as opposed to ethical, considerations follow-ing on from our discussion of social data sources. Methods relevant for the analysisof social data in GIS will be found in many chapters of this book, but all are affectedby the initial data acquisition and representational model. The way in which we chooseto represent social data in GIS is of particular importance because we are so oftendealing with secondary data sets and our representational decisions are thereforeoverlaid onto a series of decisions already made by the data collecting organizations.An important ﬁrst step is to recognize that social data in GIS share many generalcharacteristics with all secondary social data sets, particularly in terms of the uncer-tainties associated with pre-publication collapsing of classiﬁcations, imputation ofmissing values, random modiﬁcation, and rounding. It is wise to treat all such dataas estimates rather than counts and to pay particular attention to uncertainties that may display spatial bias. Census under-enumeration, for example, is generallyrelated to speciﬁc population sub-groups: both the original error and subsequentcorrection methods will therefore contain distinct spatial patterning, invisible in the headline published counts.It is conventional to consider spatial objects as point, line, area, and surface types.All four representational models are applicable to social data although in conven-tional applications point and area types predominate. Data collected from individualsand households are generally conceptualized as point phenomena, although con-ﬁdentiality considerations may necessitate areal aggregation prior to data publication.Information on transportation ﬂows such as roads or services within a public trans-portation system are generally conceptualized as lines and captured as such. Littleinformation is generally available about the socio-economic characteristics of routesand ﬂows, although online public transportation timetables are beginning to provideroute attributes that are suitable for spatial analysis and accessibility modeling (seeMartin et al. (2002) and Okabe, Okunuki, and Shiode (2006) for additional details).Surprisingly few social phenomena are genuinely areal in nature: most area-baseddata are the result of aggregation. However, land ownership, political representation,and policy zoning are all examples of genuinely areal social phenomena for whichexact boundaries may be identiﬁed.Except in the very rare situations where the individual reveals his/her own spatialcoordinates directly, for example by use of location-based services or a cellular tele-phone, we are forced to make decisions about how best to establish an appropriategeographical object to which to relate data about them. If we have administrativeTHO_C02  19/03/2007  11:09  Page 44 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSOCIAL DATA45or survey information about an individual person, we must determine whether itrelates most appropriately to their home or work address or to their presence atsome other location. We must then attempt to match the description of this loca-tion to an object for which we have a known or measurable geographical location.Administrative and survey data sources most frequently provide either a full or partial postal address, perhaps making use of a national postal code system suchas the UK’s postcode (Raper, Rhind, and Shepherd 1992) or US zipcode: these codesprovide relatively rapid geographic referencing at the neighborhood level as theyare straightforward to match against national directories of codes and locations.However, the apparently simple task of textual address matching is error-prone andgives rise to many ambiguities. In many national contexts, there are no deﬁnitiveaddress lists against which to compare recorded addresses and approximate matchesmay have to be made against street segments or even quite large neighborhoods: themaintenance of up-to-date address listings is impossible without extensive inter-agencycollaboration. Both the UK and USA are engaged in projects to enhance existingaddress listings. In the USA, this involves the modernization of the Master AddressFile/TIGER lists used for the 2000 census (Vitrano, Pennington, and Treat 2004).Meanwhile the UK is struggling to achieve a national solution, most recently throughthe National Spatial Address Infrastructure (NSAI) initiative (Ofﬁce of the DeputyPrime Minister 2005). These major infrastructural data sets are difﬁcult to completedue to differences in the objects of interest of the various organizations and con-tinual change in actual addresses. While social data may be directly associated withpoint locations by any of these methods, the techniques of point pattern analysismay be most applicable, although it is important always to consider the spatial dis-tribution of the relevant denominator populations.The 2001 census in England and Wales made use of GIS not just for enumerationdistrict design, but also for the creation of an entirely separate output geography,designed for the speciﬁc needs of census data publication (Openshaw and Rao 1995,Martin 1998 2000). This output geography took particular advantage of the smallsize of the UK’s unit postcodes, allowing output areas to be assembled by directaggregation",
    "chunk_order_index": 30,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-976fdad7e0f36ceb3fd93fb0d1f93f03": {
    "tokens": 1200,
    "content": "consider the spatial dis-tribution of the relevant denominator populations.The 2001 census in England and Wales made use of GIS not just for enumerationdistrict design, but also for the creation of an entirely separate output geography,designed for the speciﬁc needs of census data publication (Openshaw and Rao 1995,Martin 1998 2000). This output geography took particular advantage of the smallsize of the UK’s unit postcodes, allowing output areas to be assembled by directaggregation of postcodes. Many national statistical organizations could in theoryaggregate from address-referenced census and administrative data to produce out-put data for any desired geographical units but the associated problems of disclosurecontrol and data access are complex. Duke-Williams and Rees (1998) describe thedifferencing problem whereby a GIS user may intersect ofﬁcial counts for two veryslightly different areas thereby obtaining counts for an intersection polygon that fallsbelow acceptable conﬁdentiality thresholds. In England and Wales the response hasbeen to plan all new data publication for exact aggregations of the 2001 censusoutput areas. Whatever the mechanisms for geography deﬁnition and aggregation,areally aggregated data remain the primary form of social data for use in GIS, althoughthere are many circumstances in which complete area boundaries are unavailable andsuch data can only be georeferenced via centroids or other summary point locationsassociated with area identiﬁers.In cases in which social data are required for areal units other than those for whichthey have been published, some form of areal interpolation is required. This is anotherenduring GIS challenge (Flowerdew and Green 1992). Crude area-based interpola-tion in which population-related counts are transferred between zones in proportionTHO_C02  19/03/2007  11:09  Page 45 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f46DAVID J. MARTINto the areas of intersecting polygons is unsatisfactory except where population isuniformly distributed within polygons and the use of lookup tables or ancillary dis-tributional data is required. Goodchild, Anselin, and Deichmann (1993) note thatthis task of areal interpolation is actually one of estimating the characteristics ofan underlying continuously varying surface and indeed many social phenomena whichare expressed as densities per unit area or rates relative to denominator populationsmay helpfully be treated as surfaces (see Chapter 13 by Tate, Fisher and Martin inthis volume for additional information about surfaces). However, no such phenomenaare directly measurable in surface form, and surfaces are more usefully consideredas a representational or analytical device which overcomes many of the difﬁcultiesassociated with conventional area-based methods (Martin 1996, Lloyd, Haklay,Thurstain-Goodwin, and Tobon 2003). Further representational options are intro-duced when our interest is with areal units which may be modeled but not directlymeasured, such as the effective catchment area of a retail outlet or health center:such spatial objects may be constructed in many ways and are again a candidate forsurface rather than area-based modeling.CONCLUSIONS: IMPLICATIONS FOR SPATIAL ANALYSISIn this chapter we have brieﬂy reviewed the principal contemporary sources of social data for GIS. The central message of the chapter is that there are multipleapproaches to the acquisition and representation of almost all social phenomena,but none of these are neutral in their impacts on subsequent GIS use. The dataavailable in any national setting are a complex product of social priorities, organiza-tional culture, and historical precedent. Good practice with social GIS data involvesa clear ontology of the phenomena being modeled, a full understanding of dataacquisition and georeferencing, and careful attention to the choice of representationalmodels. Much analysis of social data in GIS tends to be focused on the manipulationof attributes without reference to geography, but, as all social GIS representationsare to some extent spatial models, the spatial aspects cannot be ignored: they arerarely random!Conventional administrative, survey, and census-based data sources are becomingincreasingly integrated as national statistical organizations look to data collectionstrategies which combine elements of each. Geographic referencing is continuallyimproving but high precision is often offset by data protection measures that resultin spatially inappropriate aggregation. Exciting new challenges will be posed by movestowards higher spatial and temporal resolution and cross-scale data integration thatrequire entirely new geocomputational tools such as those advocated by Gaheganin Chapter 16 of this volume.ACKNOWLEDGEMENTSThe author is supported by Economic and Social Research Council Award RES-507-34-5001 as Coordinator of the ESRC/JISC 2001 UK Census of PopulationProgramme.THO_C02  19/03/2007  11:09  Page 46 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSOCIAL DATA47REFERENCESAlexander, C. H. 2000. The American Community Survey and the 2010 US Census. Paper presented at INSEE-Eurostat Seminar on Censuses after 2001(available athttp://www.insee.fr/en/nom_def_met/colloques/insee_eurostat/pdf/alexander.pdf).Dorling,",
    "chunk_order_index": 31,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-363ae10f623ef2c23d0497d0fd638d86": {
    "tokens": 1200,
    "content": "-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSOCIAL DATA47REFERENCESAlexander, C. H. 2000. The American Community Survey and the 2010 US Census. Paper presented at INSEE-Eurostat Seminar on Censuses after 2001(available athttp://www.insee.fr/en/nom_def_met/colloques/insee_eurostat/pdf/alexander.pdf).Dorling, D., Mitchell, R., Shaw, M., Orford, S., and Davey-Smith, G. 2000. The ghost ofChristmas past: Health effects of poverty in London in 1896 and 1991. British MedicalJournal 321: 1547–5.Duke-Williams, O. and Rees, P. 1998. Can census ofﬁces publish statistics for more than onesmall area geography? An analysis of the differencing problem in statistical disclosure.International Journal of Geographical Information Science12: 579–605.Durr, J.-M. and Dumais, J. 2002. Redesign of the French census of population. SurveyMethodology28: 43–9.Flowerdew, R. and Green, M. 1992. Developments in areal interpolation methods and GIS.Annals of Regional Science 26: 67–77.Fotheringham, A. S. and Wong, D. W.-S. 1991. The modiﬁable areal unit problem in multi-variate statistical analysis. Environment and Planning A23: 1025–44.Galster, G. 2001. On the nature of neighbourhood. Urban Studies38: 2111–24.Goodchild, M. F., Anselin, L., and Deichmann, U. 1993. A framework for the areal inter-polation of socioeconomic data. Environment and Planning A25: 383–97.Haynes, R. M., Lovett, A. A., Bentham, G., Brainard, J. S., and Gale, S. H. 1995. Com-parison of ward population estimates from FHSA patient registers with the 1991 census.Environment and Planning A27: 1849–58.Kearns, A. and Parkinson, M. 2001. The signiﬁcance of neighbourhood. Urban Studies38:2103–10.Lloyd, D., Haklay, M., Thurstain-Goodwin, M., and Tobon, C. 2003. Visualising spatialstructure in urban data. In P. A. Longley and M. Batty (eds) Advanced Spatial Analysis:The CASA Book of GIS.Redlands, CA: ESRI Press, pp. 266–88.Martin, D. J. 1996. An assessment of surface and zonal models of population. InternationalJournal of Geographical Information Systems 10: 973–89.Martin, D. J. 1998. Optimizing census geography: The separation of collection and outputgeographies. International Journal of Geographical Information Science 12: 673–85.Martin, D. J. 1999. Spatial representation: The social scientist’s perspective. In P. Longley,M. F. Goodchild, D. J. Maguire, and D. W. Rhind (eds) Geographical Information Systems:Principles, Techniques, Applications and Management(2nd edn). Chichester: John Wileyand Sons, pp. 71–80.Martin, D. J. 2000. Towards the geographies of the 2001 UK Census of Population.Transactions of the Institute of British GeographersNS 25: 321–32.Martin, D. J. 2006. Last of the censuses? The future of small area population data.Transactions of the Institute of British Geographers NS 31: 6–18.Martin, D. J., Wrigley, H., Barnett, S., and Roderick, P. 2002. Increasing the sophisticationof access measurement in a rural healthcare study. Health and Place 8: 3–13.Mesev, V. 2003a. Remotely sensed cities: An introduction. In V. Mesev (ed.) Remotely SensedCities.London: Routledge, pp. 1–19.Mesev, V. (ed.). 2003b. Remotely Sensed Cities.London: Routledge.Ofﬁce for National Statistics. 2003. Proposals for an Integrated Population StatisticsSystem. London, Ofﬁce for National Statistics Discussion Paper (available at http://www.statistics.gov.uk/downloads/theme_population/ipss.pdf).Ofﬁce of the Deputy Prime Minister. 2005. Towards the National Spatial AddressInfrastructure: Outline Prospectus. WWW document, http://www.odpm.gov.uk/pub/578/TowardstheNationalSpatialAddressInfrastructurePDF235Kb_id1144578.pdf).THO_C02  19/03/2007  11:09  Page 47 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f48DAVID J. MARTINOkabe, A., Okunuki, K.-I., and Shiode, S. 2006. The SANET toolbox: New methods fornetwork spatial analysis. Transactions in GIS10: 535–50.Opens",
    "chunk_order_index": 32,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d81f3a156974f818d85ac296ec554291": {
    "tokens": 1200,
    "content": "/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f48DAVID J. MARTINOkabe, A., Okunuki, K.-I., and Shiode, S. 2006. The SANET toolbox: New methods fornetwork spatial analysis. Transactions in GIS10: 535–50.Openshaw, S. 1984. The Modiﬁable Areal Unit Problem.Norwich, GeoBooks Concepts andTechniques in Modern Geography No. 38.Openshaw, S. and Rao, L. 1995. Algorithms for reengineering 1991 census geography.Environment and Planning A27: 425–46.Raper, J. F., Rhind, D. W., and Shepherd, J. W. 1992. Postcodes: The New Geography.Harlow: Longman.Rees, P., Martin, D., and Williamson, P. (eds). The Census Data System.Chichester: JohnWiley and Sons.Stillwell, J. and Duke-Williams, O. 2003. A new web-based interface to British census ofpopulation origin: Destination statistics. Environment and Planning A35: 113–32.Thurstain-Goodwin, M. 2003. Data surfaces for a new policy geography. In P. A. Longleyand M. Batty (eds) Advanced Spatial Analysis: The CASA Book of GIS.Redlands, CA:ESRI Press, pp. 145–70.van der Lann, P. 2001. The 2001 census in the Netherlands: Integration of registers andsurveys. Paper presented at INSEE-Eurostat Seminar on Censuses after 2001(availableat http://www.insee.fr/en/nom_def_met/colloques/insee_eurostat/pdf/laan.pdf).Vitrano, F. A., Pennington, A., and Treat, J. B. 2004. Census 2000 testing, experimenta-tion, and evaluation program topic report 8: Address list development in Census 2000.Washington, DC: US Census Bureau.Webber, R. and Longley, P. A. 2003. Geodemographic analysis of similarity and proximity:Their roles in the understanding of the geography of need. In P. A. Longley and M. Batty(eds) Advanced Spatial Analysis: The CASA Book of GIS.Redlands, CA: ESRI Press, pp. 233–66.THO_C02  19/03/2007  11:09  Page 48 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 3Remote SensingBrian G. LeesRemotely sensed data is an important source of information for many spatial decision support systems. As the information age has progressed and, almost con-currently, problems of over-population, food security, pollution, global warming,and national security have become ever more urgent, decision makers at all levelsof government and industry are increasingly required to make decisions over shortertime cycles. These time cycles are now so short as to preclude extensive surveys toprovide a solid information base on which to base considered planning. It wouldbe hard to envisage, in this century, project funding being allocated to the 25- to50-year-long national soil surveys of the last century. Rather, it is becoming com-mon practice to use available archived data updated, where possible, with recentremotely sensed data or other reconnaissance tools. Remote sensing has become anindispensable tool for keeping geographic databases current and ready for rapidapplication.Remote sensing, as a ﬁeld, covers everything from digital scanning and optochemicalphotography from satellites and aircraft, laser and radar proﬁling, to echo soundingfrom ships. It can be classiﬁed as active or passive remote sensing depending onwhether the system is sensing the reﬂections of its own transmissions or not. Passivesystems sense reﬂections and re-radiations of the Sun’s energy, both in the visibleand middle infra-red wavelengths, and emitted radiation in the middle and thermalinfra-red wavelengths. Active systems sense reﬂected radiation in the microwave,laser light, and sound bandwidths.There is a considerable literature on how the Earth surface interacts with elec-tromagnetic radiation in the microwave range. Some is reﬂected, some is absorbed,and some is transmitted. Colwell’s (1983) huge two volume Manual of RemoteSensing, now out of print but widely available in libraries, gives an excellent over-view of the detailed characteristics of this interaction. Later volumes in the seriescover specialties such as radar remote sensing (Henderson and Lewis 1998), earthscience applications (Rencz and Ryerson 1999), and natural resource management(Ustin 2004), keeping the series current and making it a ﬁrst point of call for thoseseeking detailed information.THO_C03  20/03/2007  14:50  Page 49 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f50BRIAN G. LE",
    "chunk_order_index": 33,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-61d40796217a5dfdbc822245cd095370": {
    "tokens": 1200,
    "content": "HO_C03  20/03/2007  14:50  Page 49 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f50BRIAN G. LEESSPOT HRV 1, 2, 3, 4Pan 10 × 10Mss 20 × 20SPOT 5 HRG (2001;not shown)Pan 2.5 × 2.5; 5 × 5Mss 10 × 10SWIR 20 × 20107(10 years)Temporal Resolution (minutes)1061051041000(1 year)100(1 hour)100.1110Nominal Resolution (metres)10010001041SPIN-2KVR-1000 2 × 2TK-350 10 × 10AerialPhotography0.25 × 0.25m1 × 1mIRS-P5 (1999)Pan 2.5 × 2.5GOESVIS 1 × 1kmTIR 8 × 8kmNWS WSR-88DDoppler Radar1 × 1km4 × 4kmMETEOSATVISIR 2.5 × 2.5kmTIR 5 × 5kmAVHRRLAC 1.1 × 1.1kmGAC 4 × 4kmMODIS (1999)EOS AM-1Land 0.25 × 0.25kmLand 0.50 × 0.50kmOcean 1 × 1kmAtmo 1 × 1kmTIR 1 × 1kmRADARSATC-band11-9, 925 × 2848-30 × 2832-25 × 2850 × 5022-19 × 2863-28 × 28100 × 100BILSAT-1Pan 12 × 12Mss 26 × 26ORBIMAGEOrbview 3 (1999)Pan 1 × 1Mss 4 × 4Orbview 4 (2000)Pan 1 × 1Mss 4 × 4Hyperspectral 8 × 8mASTER (1999)EOS AM-1VNIR 15 × 15mSWIR 30 × 30mTIR 90 × 90mSPOT 4Vegetation1 × 1kmORBIMAGEOrbview 2Sea WiFS1.13 × 1.13kmEOSAT/Space ImagingIKONOS (1999)Pan 1 × 1Mss 4 × 4Quickbird (2000)0.82 × 0.823.28 × 3.28JERS-1MSS 18 × 24L-band 18 × 18FRS-1, 2C-band 30 × 30CBERS-2CCD VIS 19 × 19IR 80 × 80WFI GROON 260 × 260nIR 260 × 260IR-MSS IR 80 × 80TIR 160 × 160IRS-P6LISS-3 23 × 23AWiFS 56 × 56LISS-4 6 × 6LANDSAT 4, 5MSS 79 × 79mTM 30 × 30mLANDSAT 7 ETM+ (1999)Pan 15 × 15mMSS 30 × 30mTIR 60 × 60mFig. 3.1There is a wide range of remote sensing instruments available. The diagram shows sometypical platforms and instrument packages with a range of spatial resolutions (the wider boxes) and revisit schedulesThis diagram is modiﬁed after Longley et al. (2001) which itself is a modiﬁcation of a diagram inJensen and Cowen (1999). The ﬁgure is in no sense comprehensive; an up-to-date reference list ofremote sensing satellites and their instrument packages can be found at http://www.tbs-satellite.com/tse/online/mis_teledetection_res.htmlTHO_C03  20/03/2007  14:50  Page 50 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fREMOTE SENSING51There is a now a wide choice of systems with a range of spatial and spectral resolutions (Figure 3.1). Within this chapter we will concentrate on only those remotesensing sources and data which are commonly used as inputs to GeographicInformation Systems (GIS), or have the potential to be so.Remotely Sensed Imagery and GISUntil the end of the Cold War and the declassiﬁcation of military standard satelliteremote sensing systems, most spatial information used in GIS was derived from cartographic and survey products. Most of these, in turn, were derived from aerialphotography. It is only since 2001 that the satellite imagery available for civil pur-poses has been of a ﬁne enough resolution to be of more direct use in GIS.Remote sensing typically produces two kinds of information. It has the poten-tial to record high-quality, relatively accurate, spatial information and",
    "chunk_order_index": 34,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a1ee68305dbbcd1884c024708e442dc8": {
    "tokens": 1200,
    "content": "cation of military standard satelliteremote sensing systems, most spatial information used in GIS was derived from cartographic and survey products. Most of these, in turn, were derived from aerialphotography. It is only since 2001 that the satellite imagery available for civil pur-poses has been of a ﬁne enough resolution to be of more direct use in GIS.Remote sensing typically produces two kinds of information. It has the poten-tial to record high-quality, relatively accurate, spatial information and poorer quality attribute information. This potential is limited by the spatial and spectralresolution of the particular instrument. Newcomers to remote sensing are often con-fused by the considerable “overselling” of the quality of attribute information beingproduced.Many remote sensing platforms carry instruments with different character-istics matching an instrument with a high spatial and low spectral resolution withan instrument that has a moderate spatial and high spectral resolution. Specializedinstruments that have both high spatial and high spectral resolutions tend to beused over limited areas only and are often carried on aircraft or very low orbitspacecraft.Remotely sensed image data and cartographic data are two related, but differ-ent, forms of diagram in which there is a spatial treatment of spatial data. Bothhave a planar metric combined with planar topology. A photograph, however, is“realistic” while a map is symbolic (Lemon and Pratt 1997). The relationship ofboth the image and graphical diagrammatic representations to the original data isa homomorphism. Homomorphism is a many-to-one mapping in effect represent-ing a pattern in the domain of the mapping for a simpler pattern in its range.Homomorphisms are important in establishing whether one system is a model ofanother and which properties of the original system the model retains. For eachsystem one can construct a lattice of homomorphic simpliﬁcations. The inverse ofhomomorphism is not a mapping (Krippendorff 1986).The translation between the “realistic” homomorphism of imagery (land cover)and the symbolic homomorphism of mapping (land use) is difﬁcult to automate andeven the most advanced systems still currently require the supervision and inter-vention of expert analysts. This is an area of active research. Brown and Duh (2004)discuss a model for translating from land use to land cover. This seems to be a pos-sible achievement in the future, but a fully automated model for the more necessarytranslation from land cover to land use is hard to imagine. Partially automated systems for this are discussed below.The following sections discuss the methods for extracting symbolic spatial datafrom imagery which are currently available.THO_C03  20/03/2007  14:50  Page 51 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f52BRIAN G. LEESExtracting Spatial Information from Remotely Sensed DataRemoving distortionA considerable amount of processing is needed to derive high-quality spatial in-formation from remotely sensed data. Geometric distortion must be removed andthe data needs to be registered to some coordinate system. In addition, the relevantspatial information needs to be separated from the irrelevant information. Theseare not trivial tasks.All remote sensing is subject to geometric distortion. Optochemical systems, even under perfect conditions, produce data where the scale increases away fromthe ground point closest to the camera. In addition, platform acceleration or deceleration, pitch, roll, and yaw all cause geometric distortion. These effects arenot restricted to aircraft. Remote sensing satellites and ships both travel across the surface of dynamic ﬂuids. In the former case, it is the upper atmosphere, andin the latter case, the sea. Like aircraft, they accelerate, decelerate, climb, descend,pitch, roll, and yaw. To avoid these problems, aircraft involved in remote sensingare given strict limits for each of these movements and imagery outside these limitsis usually not accepted. It is not possible to do this for satellite remote sensing orship-borne sonar scanning and, to harness the spatial information contained in these data, the errors and distortions which result from these displacements mustbe corrected. Geometric correction of images can be performed at several levels ofcomplexity and accuracy.Normally, these corrections are dealt with by the data distribution agency. Themore corrections performed by the data provider, of course, the higher will be the cost of the imagery. Data providers also carry out some radiometric correctionsas a matter of course. These corrections usually involve the removal of distortions dueto sensor–solar geometry interactions, such as cross track brightening, solar glint,and hot spots. Increasingly, image data can be purchased “ready to go” with thegeometric corrections already done, the data registered to some coordinate system,and the image digital numbers converted to physical units for modeling, inversion,or multi-date work.For those who wish process their own raw remote sensing data, there is a widerange of processing systems available, a developed literature, and a whole remotesensing discipline.Updating spatial information in geographic databasesThere are some important issues when using remotely sensed data to update geo-graphic databases. One of the fundamental geographic databases is the cadastre.This is a vector data set which records land title, prior interest in land, and otherlegal requirements regarding land ownership. It is usually derived from a primary,text-based, spatial database. If there is disagreement between the two then, in manylegislatures, the text-based spatial database is given precedence. Digital databasesderived from the cadastre tend to be comparatively inaccurate spatially, althoughthey tend to be complete. Updating",
    "chunk_order_index": 35,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-deb91a6b29b3df62681e2db9946e0f77": {
    "tokens": 1200,
    "content": "-graphic databases. One of the fundamental geographic databases is the cadastre.This is a vector data set which records land title, prior interest in land, and otherlegal requirements regarding land ownership. It is usually derived from a primary,text-based, spatial database. If there is disagreement between the two then, in manylegislatures, the text-based spatial database is given precedence. Digital databasesderived from the cadastre tend to be comparatively inaccurate spatially, althoughthey tend to be complete. Updating the digital cadastral database using remotelyTHO_C03  20/03/2007  14:50  Page 52 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fREMOTE SENSING53sensed data can keep it complete, but the updates cannot easily be transmitted backto the text-based spatial database because of their low spatial accuracy.Geographic databases are usually based around the entity data model and com-prise points, lines, and areas. Until the advent of high spatial resolution space imagery,the process of updating geographic databases involved the laborious comparisonof the digital database with current orthophotos. With increased availability of highspatial resolution digital data this process can be partly automated. The process ofupdating the spatial information in a geographic database is comprised of threesteps (Walter and Fritsch 2000).First, changes between the original database and the more up-to-date imageryneed to be identiﬁed. Second, attributes need to be corrected. In an urban area thesemight be street names or ownership details, extracted from other databases. In non-urban areas, attributes are usually related to land use or land cover. These can bederived from remotely sensed data using techniques discussed later in this chapter.Finally, the changes need to be stored in the geographic database and checked forquality.The ﬁrst stage is the most labor intensive and is still one in which expert super-vision is necessary. At this stage, these two data sets have different data models andstructures leading to a fundamental mismatch which must be overcome. This is becausethey are different homomorphs of spatial reality. The crudest approach is to classifythe imagery and convert it from a ﬁeld data model to an entity data model. However,statistical clustering and classiﬁcation tools do not produce the cultural entities contained in geographic databases, rather they produce spectral entities. Some formof linking of spectral entities to produce cultural entities is necessary. In the past,this was one of the most time-consuming parts of processing remotely sensed dataas it needed to be accomplished manually assessing the color, shape, relative size,texture, pattern, and context of the image. Multi-resolution segmentation allows ahierarchical network of the image objects to be constructed which, under super-vision, greatly increases the speed at which this can be accomplished. Coupled withobject relationship modeling, it becomes a powerful tool. It is worthwhile brieﬂydescribing how this works.Conventional clustering or classiﬁcation algorithms tend to rely only on the topo-logical relationships between pixels in spectral space. Multi-resolution segmentationand object relationship modeling use both the topological relationship between pixels in spectral space and their topological relationship in geographic space. Pixelsthat are adjacent in geographic space and also proximate in spectral space are com-bined into image objects. Image objects which are adjacent in geographic space andproximate in spectral space can be further combined to give a hierarchical net ofimage objects with the user deciding at which level the hierarchy best represents acultural landscape. Some software implementations allow image objects which areadjacent in geographic space and remote in spectral space to be combined on thebasis of rules. For example, “sunlit roof” and “shadowed roof” are both elementsof the cultural object “roof” and can be adjacent in geographic space but remotein spectral space.Multi-scale or multi-resolution segmentation and object relationship modeling isbecoming a mature methodology (Baatz and Schape 2000, Blaschke, Lang, Lorup,Strobl, and Zeil 2000, Hofmann and Reinhardt 2000, Manakos, Schneider, andTHO_C03  20/03/2007  14:50  Page 53 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f54BRIAN G. LEESAmmer 2000, Blaschke and Hay 2001, Burnett and Blaschke 2003). Software whichenables the user to formulate concepts and knowledge about how spectral entitiescan be linked to give cultural entities and enable automated, rule-based linking isnow available (for example, eCognition, www.deﬁniens-imaging.com).Despite the signiﬁcant improvements in processing methodology, it is importantto recognize that difference between an older geographic database and a more recentimage does not, in itself, imply change. An automated, computer-based process whichachieves a result as good as a human operator in interpreting and identifying cul-tural entities is not yet a reality (Hofmann and Reinhardt 2000) and a differencebetween their results is expected. Nevertheless, these tools greatly accelerate the trans-formation of image data.This approach produces areas and area boundaries. However, it is not an effectivemethod of extracting the other",
    "chunk_order_index": 36,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6082efae0fc8bfa91554d2249042807c": {
    "tokens": 1200,
    "content": "database and a more recentimage does not, in itself, imply change. An automated, computer-based process whichachieves a result as good as a human operator in interpreting and identifying cul-tural entities is not yet a reality (Hofmann and Reinhardt 2000) and a differencebetween their results is expected. Nevertheless, these tools greatly accelerate the trans-formation of image data.This approach produces areas and area boundaries. However, it is not an effectivemethod of extracting the other components of an entity data structure, points and lines.Extracting points and linesThe extraction of points and lines from remotely sensed data requires a different pro-cessing approach to the extraction of area features. There are a number of strategieswhich are being used, with varying degrees of success, to extract line features fromremotely sensed data. The particular strategy used, and the results obtained, dependvery much upon the type of imagery being processed.One strategy looks at the digital numbers of a particular type of pixellated linefeature. These would usually cluster about some mean value. While a spectral signature is usually not enough to enable the identiﬁcation of the particular linefeature completely, it can be used to reﬁne exclusion criteria. Looking at the spectralcharacteristics of a neighborhood of pixels is another strategy that is sometimesused. Following these initial transformations, areas with similar length and widthdimensions can be excluded if one is looking for line features. The problem hereis that broken sections of continuous line may be ﬁltered out. Filters that searchfor patterns which are weakly linked can also be used to extract line features.To do better than this, the complexity of the approach increases rapidly. Hinzand Baumgartner (2003) describe an automatic extraction of urban road networks.Their system compiles knowledge about radiometric, geometric, and topological characteristics of roads in the form of a hierarchical semantic net. Pixels in the initial image which form a bright blob, or compact bright region, are interpretedas compact concrete or asphalt regions which, in the real world, may represent asimple junction. Pixels in the image which form an elongated bright region are inter-preted as elongated ﬂat concrete or asphalt regions which, in the real world, mayrepresent a section of road pavement, and so on. This road model is extended usingknowledge about context.The context model uses relationships which may exist locally to reinforce theextraction of road features. For example, in denser urban areas, the road tends toparallel the front face of buildings. In higher resolution imagery, the presence ofvehicles on roads or trees overshadowing roads, can occlude large parts of the roadmaking it difﬁcult to extract focal features. By identifying vehicles and trees, andtree shadows, as things which commonly occlude roads then the context model canlink the line feature through the occlusion.THO_C03  20/03/2007  14:50  Page 54 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fREMOTE SENSING55Once the road segments have been extracted, the network can be constructed geo-metrically using connection hypotheses. Put simply, most roads join up. AlthoughHinz and Baumgartner (2003) have demonstrated automatic extraction of urbanroad networks from remotely sensed imagery, their results emphasize that low errorrates are only possible due to the expertise of the system developers in setting the parameters correctly. This sort of system is still at the stage of fundamentalresearch and the reality is that extraction of point and line features from remotelysensed imagery still requires considerable human intervention. Choi and Usery (2004)describe a similar approach.Extracting Attribute InformationThe most common use of remotely sensed data in GIS, has been the generation of attribute information on land cover. There are thousands of papers discussing theprocessing of remotely sensed data to produce land cover information. We are nowat the stage where the promise of remote sensing, at least in this area, is becom-ing a reality. Users can make the choice to process data themselves or downloadpre-processed products.For an example of available pre-processed products, the University of MarylandGlobal Land Cover Facility lists a range of ﬁne, moderate and course resolutionproducts as does the NASA MODIS Land Discipline website. The latter offers:Radiation budget variables•Surface reﬂectance products•LST and emissivity•Snow and ice cover•BRDF and albedoEcosystem variables•Vegetation indices•LAI and FPAR•Vegetation production, NPP•Evapotranspiration and surface resistanceLand cover characteristics•Fire and thermal anomalies•Land cover•Vegetative cover conversion•Vegetation continuous ﬁeldsThere is extensive documentation to support each of these standard products. The land cover data set is supported by an algorithm theoretical basis document(Strahler, Muchoney, Borak, et al. 1999). This outlines the background and his-torical perspective to the algorithm development, the algorithm structure, and themathematical description of the algorithm. It also covers testing and validation ofthe algorithm and discusses sources of error and uncertainty. For those wishing to incorporate standard products into their geographic databases, these highly processed products are invaluable. However, it is almost certain that one of theTHO_C03  20/03/2007  14:50  Page 55 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and",
    "chunk_order_index": 37,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6c655c6ce6056fda8712f413e7e860b7": {
    "tokens": 1200,
    "content": "those wishing to incorporate standard products into their geographic databases, these highly processed products are invaluable. However, it is almost certain that one of theTHO_C03  20/03/2007  14:50  Page 55 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f56BRIAN G. LEESattribute data layers required is not available off-the-shelf and some processing willbe required!For those whose experience with remotely sensed data is limited, it is worth review-ing some important aspects of processing remotely sensed data to produce attributeinformation.AccuracyIn much of the older remote sensing literature there is an unfortunate overstating ofthe accuracy of products. Without citing culprits, it was not unusual to ﬁnd claimsof better than 90 percent accuracy for land cover classiﬁcations. This, of course, is the result of a failure to track errors properly along with a misunderstanding ofthe statistical basis for classiﬁcation and the impact on accuracy of mismatched datastructures. Some early papers on this topic are still important.Given the simplest case, in which we have two land cover types such as land andsea, a signiﬁcant proportion of our pixels will be boundary pixels. These pixelscannot be accurately classiﬁed as either land or sea and are truly a mixture. Theproportion of pixels which are truly mixels depends upon the shape of the landcover units and the size of the pixels (the spatial resolution of the sensor). Thisproportion is often very much higher than one might expect. In a mapping exercisefor a coastal bay where the ratio of the average land cover unit area to the pixelarea was 1 to 16, Jupp, Adomeit, Austin, Furlonger, and Mayo (1982) found that54.9 percent of the total cells were boundary pixels (mixels).Allocating mixels to one or other of the land cover classes results in errors ofomission and commission; A or B type errors (Crapper 1980). Markham andTownshend (1981) and Townshend and Justice (1981) have shown that, over alimited range, classiﬁcation accuracies can improve as the resolution becomes coarser.They also observed that, for a given scene, there may be an optimum resolutionabove and below which classiﬁcation accuracies will decline. This optimum resolu-tion will depend upon the within-theme spectral variation. Thinking about this errorgeneration in GIS terms, one can see that is the natural result of representing entitiesusing a grid data structure.The problem is sometimes compounded when the land cover is better representedas a ﬁeld, rather than as entities. This usually occurs when the land cover is deter-mined by environmental, or edaphic, processes rather than cultural activities, yetthe same sort of classiﬁcation process is used. The classiﬁcation of a constantly varying (in space) land cover into land cover types generates quite serious errorsof omission and commission (Lees 1996b, Mather 1999). In this case, the errorresults from the use of an inappropriate ecological model which maps directly ontoour cartographic model.Improving the quality of attribute informationA strong theme of research in the ﬁeld of remote sensing has been to improve the quality of the attribute information available from remotely-sensed image data.Since the mid-1990s techniques have been developed to enhance the attribute information available by combining the remotely-sensed image data with “ancillary”THO_C03  20/03/2007  14:50  Page 56 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fREMOTE SENSING57environmental and terrain data. Because the data distribution information requiredfor the diverse data sets is not always available, and the time involved in set-up, para-metric classiﬁers have become less favored than the non-parametric alternatives inthis sort of synthesis (Benediktsson, Swain, and Ersoy 1990). It is common to ﬁndpapers which suggest that parametric classiﬁers are unsuitable for classifying thissort of mixed data but Benediktsson, Swain, and Ersoy (1990) demonstrate how itcan be accomplished. They also demonstrate that this approach is extremely time-consuming compared to the non-parametric alternatives.Numerous studies of classiﬁcation using decision trees (Lees and Ritman 1991),neural networks of various kinds (Benediktsson, Swain, and Ersoy 1990; Fitzgeraldand Lees 1995, 1996), genetic algorithms and even cellular automata have beenpublished to examine these alternatives (Lees 1996a). However, the most commonform of delivery, and use, of vegetation information to spatial decision support sys-tems remains the mapped thematic, choropleth, form. Lees (1996b) argued that thepre-processing of data to suit this data structure perpetuates the use of an inappro-priate data model. Even following digital image analysis, results are conventionallypresented using one of the least useful data types, categorical, in a form which mimics the entity data structure, although the data structure is usually still pixels.In many natural environments",
    "chunk_order_index": 38,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-1fc14bc229069a238c03ac9ffe207bc1": {
    "tokens": 1200,
    "content": ", of vegetation information to spatial decision support sys-tems remains the mapped thematic, choropleth, form. Lees (1996b) argued that thepre-processing of data to suit this data structure perpetuates the use of an inappro-priate data model. Even following digital image analysis, results are conventionallypresented using one of the least useful data types, categorical, in a form which mimics the entity data structure, although the data structure is usually still pixels.In many natural environments, a continuum of change is being represented as aseries of overlapping gaussians. This leads inevitably to the generation of errors ofomission and commission.Lees (1996b) proposed a new method of representing vegetation data which avoided the errors of omission and commission that are generated using conven-tional techniques. This required the distribution of each species to be recorded asa ﬁeld and stored separately in some form of a database. Unfortunately, a ﬁeld-worker wishing for information about a point would have to scroll through, in the case of the Kioloa data set, the distributions of 41 tree species, 94 shrubs, and108 understorey species. The increase in accuracy gained is seriously offset by theindigestible nature of the output. Lees and Allison (1999) discussed the practicalitiesof these approaches without offering a solution. It remains clear that there is a require-ment for a single representation of vegetation distribution using the ﬁeld data modelwhich gives a synthetic view of the forest while avoiding the errors generated byclassiﬁcation.With only few exceptions, most classiﬁcations of remotely sensed data are non-spatial analyses of spatial data. The data is analyzed and clustered using its topo-logical relationships in spectral space. The spatial content of the image data usuallyremains un-investigated. Those studies that have examined the explicitly spatial analysis of this sort of spatial data have looked at strategies such as spatial signaldetection, local spatial autocorrelation, and local regression.Where local spatial statistical measures have been used in environmental remotesensing studies, most have used the Moran or Geary statistics (for example, Pearson2002). Relatively few have used the Getis–Ord statistic, although Wulder and Boots(1998) have reviewed its use with remotely sensed data. More recently, Holden,Derksen, and LeDrew (2000) used this method to evaluate coral ecosystem healthby identifying spatial autocorrelation patterns in multi-temporal SPOT images.The Getis–Ord statistic (Getis and Ord 1992, Ord and Getis 1995), with its addedinformation about brightness values, has shown itself to be particularly useful inTHO_C03  20/03/2007  14:50  Page 57 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f58BRIAN G. LEESdealing with remotely sensed data. This simple local spatial statistic has achieved resultscomparable to some of the more complex classiﬁcations of remotely sensed datapublished in the past which have attempted to include spatial context (Fitzgeraldand Lees 1995) with far less effort.CONCLUSIONSThe use of expert systems to automate much of the supervised processing of remotelysensed data into GIS data has increased greatly in the literature. In part this hasbeen driven by the increased availability of high spatial resolution remotely sensedimagery and in part by increasing demand for such algorithms. Increasingly, insightsinto the behavior of spatial data from GIS activities are feeding back into remotesensing and driving innovation. Some of these innovations are an increased aware-ness of error, both spatial and attribute, within remote sensing and an increasedinterest in spatial statistics.REFERENCESBenediktsson, J. A., Swain, P. H., and Ersoy, O. K. 1990. Neural network approaches versusstatistical methods in classiﬁcation of multisource remote sensing data. IEEE Transactionson Geoscience and Remote Sensing 28: 540–51.Baatz, M. and Schape, A. 2000. Multiresolution segmentation: An optimization approach forhigh quality multi-scale image segmentation. In J. Strobl, T. Blaschke, and G. Griesebner(eds) Angewandte Geographische Informationsverarbeitung XII, Beiträge zum AGIT-Symposium. Karlsruhe: Herbert Wichmann Verlag, pp. 12–23.Blaschke, T., Lang, S., Lorup, E., Strobl, J., and Zeil, P. 2000. Object-oriented image pro-cessing in an integrated GIS/remote sensing environment and perspectives for environmentalapplications. In A. Cremers and K. Greve (eds) Environmental Information for Planning:Politics and the Public,vol. 2. Marburg: Metropolis Verlag: 555–70.Blaschke, T. and Hay, G. J. 2001. Object-oriented image analysis and scale-space: Theoryand methods for modeling and evaluating multiscale landscape structures. InternationalArchives of Photogrammetry and Remote Sensing34(4): 22–9.Brown, D. G. and Duh, J. D. 2004. Spatial simulation for translating from land use to landcover. International Journal for Geographical Information Science18: 35–60.Burnett, C. and Blaschke, T. 2003. A multi-scale segmentation/object relationship modellingmethodology for landscape analysis. Ecological Modelling168: 233–49.Choi, J. and",
    "chunk_order_index": 39,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-91c8b29120fe346478952ce467c1787e": {
    "tokens": 1200,
    "content": "Remote Sensing34(4): 22–9.Brown, D. G. and Duh, J. D. 2004. Spatial simulation for translating from land use to landcover. International Journal for Geographical Information Science18: 35–60.Burnett, C. and Blaschke, T. 2003. A multi-scale segmentation/object relationship modellingmethodology for landscape analysis. Ecological Modelling168: 233–49.Choi, J. and Usery, E. L. 2004. System integration of GIS and a rule-based expert systemfor urban mapping. Photogrammetric Engineering and Remote Sensing70: 217–24.Colwell, R. N. 1983. Manual of Remote Sensing, vols 1 and 2.Falls Church, VA: AmericanSociety of Photogrammetry and Remote Sensing.Crapper, P. F. 1980. Errors incurred in estimating an area of uniform land cover using Landsat.Photogrammetric Engineering and Remote Sensing46: 1295–1301.Fitzgerald, R. W. and Lees, B. G. 1995. Spatial context and scale relationships in raster datafor thematic mapping in natural systems. In T. C. Waugh and R. G. Healey (eds) Advancesin GIS Research.London: Taylor and Francis, pp. 462–75.Fitzgerald, R. W. and Lees, B. G. 1996. Temporal context in ﬂoristic classiﬁcation. Computersand Geosciences22: 981–94.THO_C03  20/03/2007  14:50  Page 58 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fREMOTE SENSING59Getis, A. and Ord, J. K. 1992. The analysis of spatial association by use of distance statistics.Geographical Analysis24: 188–205.Henderson, F. M. and Lewis, A. J. 1998. Manual of Remote Sensing: Volume 2, Principlesand Applications of Imaging Radar.New York: John Wiley and Sons.Hinz, S. and Baumgartner, A. 2003. Automatic extraction of urban road networks from multi-view aerial imagery. ISPRS Journal of Photogrammetry and Remote Sensing58: 83–98.Hofmann, P. and Reinhardt, W. 2000. The extraction of GIS features from high resolu-tion imagery using advanced methods based on additional contextual information: Firstexperiences. ISPRS Journal of Photogrammetry and Remote Sensing33: 51–8.Holden, H., Derksen, C., and LeDrew, E. 2000. Coral reef ecosystem change detection based on spatial autocorrelation of multispectral satellite data. WWW document, http://www.gisdevelopment.net/aars/acrs/2000/ts3/cost006pf.htm.Jensen, J. R. and Cowen, D. J. 1999. Remote sensing of urban/suburban infrastructure and socio-economic attributes. Photogrammetric Engineering and Remote Sensing65:611–22.Jupp, D. L., Adomeit, E. M., Austin, M. P., Furlonger, P., and Mayo, K. K. 1982. The separability of land cover classes on the south coast of N.S.W. In Proceedings of LANDSAT’79 Conference, Sydney, Australia.Krippendorff, K. 1986. A dictionary of cybernetics. Unpublished report.Lees, B. G. 1996a. Inductive modelling in the spatial domain. Computers and Geosciences22: 955–7.Lees, B. G. 1996b. Improving the spatial extension of point data by changing the data model.In M. F. Goodchild (ed.) Proceedings of the Third International Conference on IntegratingGIS and Environmental Modeling. Santa Fe, NM, USA. Santa Barbara, CA: University ofCalifornia, National Center for Geographic Information and Analysis: CD-ROM.Lees, B. G. and Allison, B. 1999. A comparison between the accuracy of traditional forestmapping and more advanced, database oriented techniques. In W. Shi, M. F. Goodchild,and Fisher, P. (eds) Proceedings of the International Symposium on Spatial Data Quality.Hong Kong: Hong Kong Polytechnic University, pp. 442–8.Lees, B. G. and Ritman, K. 1991. A decision tree and rule induction approach to the integration of remotely sensed and GIS data in the mapping of vegetation in disturbed orhilly environments. Environmental Management15: 823–31.Lemon, O. and Pratt, I. 1997. Spatial logic and the complexity of diagrammatic reasoning,Machine Graphics and Vision6: 89–108.Longley, P. A., Goodchild, M. F., Maguire, D. J., and Rhind, D. W. 2001. GeographicInformation Systems and Science. Chichester: John Wiley and Sons.Manakos, I., Schneider, T., and Ammer, U. 2000. A Comparison between the ISODATAand eCognition Classiﬁcation Methods on the Basis of Field Data.ISPRS, Vol. XXXIII,Supplement CD. Amsterdam: ISPRS.Mather, P. 1999. Land cover classiﬁcation revisited. In P. M. At",
    "chunk_order_index": 40,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-10ed169b0e9b9f068ff497c71de9f0e6": {
    "tokens": 1200,
    "content": ". 2001. GeographicInformation Systems and Science. Chichester: John Wiley and Sons.Manakos, I., Schneider, T., and Ammer, U. 2000. A Comparison between the ISODATAand eCognition Classiﬁcation Methods on the Basis of Field Data.ISPRS, Vol. XXXIII,Supplement CD. Amsterdam: ISPRS.Mather, P. 1999. Land cover classiﬁcation revisited. In P. M. Atkinson and N. J. Tate (eds)Advances in Remote Sensing and GIS Analysis. Chichester: John Wiley and Sons, pp. 7–16.Markham, B. L. and Townshend, J. R. G. 1981. Land classiﬁcation accuracy as a functionof sensor spatial resolution. In Proceedings of the Fifteenth International Symposium onRemote Sensing of the Environment. Ann Arbor, MI, USA, pp. 1075–90.Ord, J. K. and Getis, A. 1995. Local spatial autocorrelation statistics: distributional issuesand an application. Geographical Analysis27: 286–305.Pearson, D. M. 2002. The application of local measures of spatial autocorrelation for describ-ing pattern in north Australian landscapes. Journal of Environmental Management 64:85–95.THO_C03  20/03/2007  14:50  Page 59 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f60BRIAN G. LEESRencz, A. N. and Ryerson, R. A. 1999. Manual of Remote Sensing: Volume 3, Remote Sensingfor the Earth Sciences.New York: John Wiley and Sons.Strahler, A., Muchoney, D., Borak, J., Friedl, M., Gopal, S., Lamblin, E., and Moody, A.1999. MODIS Land Cover and Land Cover Change: Algorithm Theoretical Basis. WWWdocument, http://modis-land.gsfc.nasa.gov/.Townshend, J. R. G. and Justice, C. O. 1981. Information extraction from remotely senseddata: A user view. International Journal of Remote Sensing2: 313–29.Ustin, S. 2004. Manual of Remote Sensing: Volume 4, Remote Sensing for Natural ResourceManagement and Environmental Monitoring. New York: John Wiley and Sons.Walter, V. and Fritsch, D. 2000. Automated revision of GIS databases. In K.-J. Li, K. Makki,N. Pissinou, and S. Ravada (eds) Proceedings of the Eighth ACM Symposium on Advancesin Geographic Information Systems, Washington, DC, USA, pp. 129–34.Wulder, M. and Boots, B. 1998. Local spatial autocorrelation characteristics of remotelysensed imagery assessed with the Getis statistic. International Journal of Remote Sensing19: 2223–31.THO_C03  20/03/2007  14:50  Page 60 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 4SpatializationAndré Skupin and Sara I. FabrikantResearchers engaged in geographic information science are generally concerned withconceptualizing, analyzing, modeling, and depicting geographic phenomena and pro-cesses in relation to geographic space. GI scientists consider spatial concepts, suchas a phenomenon’s absolute location on the Earth’s surface, its distance to otherphenomena, the scale at which it operates and therefore should be represented andstudied, and the structure and shape of emerging spatial patterns. Geographic loca-tion is indeed a core concept and research focus of GI Science, and this is well reﬂectedthroughout the many chapters of this volume. In recent years, however, it has becomeapparent that the methods and approaches geographers have been using for hundredsof years to model and visualize geographic phenomena could be applied to the representation of any object, phenomenon, or process exhibiting spatial charac-teristics and spatial behavior in intangible or abstract worlds (Couclelis 1998). Thisapplies, for example, to the Internet, in which text, images, and even voice messagesexist in a framework called cyberspace. Other examples include medical records thathave body space as a frame of reference, or molecular data structures that build upthe human genome. These abstract information worlds are contained in massivedatabases, where billions of records need to be stored, managed, and analyzed. Coregeographic concepts such as location, distance, pattern, or scale have gained import-ance as vehicles to understand and analyze the hard-to-grasp and volatile contentof rapidly accumulating databases, from real-time stock market transactions to globaltelecommunication ﬂows. This chapter is devoted to the use of spatial metaphors torepresent data that may not be inherently spatial for knowledge discovery in massive,complex, and multi-dimensional databases. It discusses concepts and methods thatare collectively referred to as spatialization.What Is Spatialization?In very general terms, spatialization can refer to the use of spatial metaphors tomake sense of an abstract concept. Such spatial",
    "chunk_order_index": 41,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-014d3b68561a857fc5656829091d84b8": {
    "tokens": 1200,
    "content": "asp and volatile contentof rapidly accumulating databases, from real-time stock market transactions to globaltelecommunication ﬂows. This chapter is devoted to the use of spatial metaphors torepresent data that may not be inherently spatial for knowledge discovery in massive,complex, and multi-dimensional databases. It discusses concepts and methods thatare collectively referred to as spatialization.What Is Spatialization?In very general terms, spatialization can refer to the use of spatial metaphors tomake sense of an abstract concept. Such spatialization is frequently used in everydayTHO_C04  20/03/2007  14:52  Page 61 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f62ANDRÉ SKUPIN AND SARA I. FABRIKANTlanguage (Lakoff and Johnson 1980). For example, the phrase “Life is a Journey”facilitates the understanding of an abstract concept (“human existence”) by mappingfrom a non-spatial linguistic source domain (“life”) to a tangible target domain (“journey”) that one may have actually experienced in the real world. The desk-top metaphor used in human–computer interfaces is another example for a spatialmetaphor.The role of spatial metaphors, including geographic metaphors, is also central tothe more narrow deﬁnition of spatialization developed in the GI Science literaturesince the 19990s (Kuhn and Blumenthal 1996, Skupin and Buttenﬁeld 1997, Skupin,Fabrikant, and Couclelis 2002), which is the basis for this chapter. Spatializationis here deﬁned as the systematic transformation of high-dimensional data sets intolower-dimensional, spatial representations for facilitating data exploration and know-ledge construction (after Skupin, Fabrikant, and Couclelis 2002).The rising interest in spatialization is related to the increasing difﬁculty of organ-izing and using large, complex data repositories generated in all parts of society.Spatialization corresponds to a new, visual paradigm for constructing knowledgefrom such data. In the geographic domain, interest in spatialization stems largely fromthe growing availability of multi-dimensional attribute data originating from suchsources as multi-temporal population counts, hyperspectral imagery, and sensor net-works. New forms of data, still largely untapped by geographic analysis includevast collections of text, multimedia, and hypermedia documents, including billionsof Web pages. A number of examples are discussed in this chapter highlighting therole of spatialization in this context.The focus on spatial metaphors hints at a fundamental relationship between spatialization efforts and GI Science, with relevance beyond the geographic domain.Many spatio-temporal techniques developed and applied in GI Science are applicablein spatialization, and the ontological, especially cognitive, foundations underlyingthe conceptualization and representation of space can inform spatialization research.That is particularly true for a group of spatializations collectively referred to as“map-like” (Skupin 2002b), which are discussed and illustrated in some detail laterin this chapter.Spatializations are typically part of systems involving people exploring highly interactive data displays with sophisticated information technology. Most currentspatialization research is directed at deﬁning and reﬁning various parameters of such interactive systems. However, the result of a spatialization procedure couldalso be a static hardcopy map that engages the viewer(s) in a discussion of depictedrelationships, and triggers new insights (Skupin 2004). For example, one could visualize all the scientiﬁc papers written by GI scientists in 2006 in the form of amap printed on a large poster and use this to inspect the structure of the disciplineat that moment in time. This can then encourage and inform the discourse on thestate and future of the discipline much as a neighborhood map facilitates discussionon zoning ordinance changes during a city-planning forum.Who Is Working On Spatialization?The main challenge faced by anyone embarking on the creation of spatializationsis that insights and techniques from numerous, and often disparate, disciplines needTHO_C04  20/03/2007  14:52  Page 62 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIALIZATION63to be considered. Visualizationresearch is very interdisciplinary and conducted by a heterogeneous group of loosely connected academic ﬁelds. Scientiﬁc visualiza-tion (McCormick, Defanti, and Brown 1987) and information visualization (Card,Mackinlay, and Shneiderman 1999) are two strands of particular interest for thisdiscussion, both drawing heavily on computer science. The former is concerned withthe representation of phenomena with physically extended dimensions (for example,width, length, height), usually in three dimensions. Typical application examplesare found in such domains as geology (rock formations), climatology (hurricanes),and chemistry (molecular structures). Scientiﬁc visualization has obvious linkageswith geographic visualization(see Chapters 11 and 16 of this volume, by Cartwrightand Gahegan respectively, for two treatments of this topic) whenever the focus ison depicting phenomena and processes that are referenced to the Earth’s surface. Incontrast, information visualization is concerned with data that do not have inherentspatial dimensions. Examples include bibliometric data, video collections, monetary",
    "chunk_order_index": 42,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-390010260e7b15024575698898c454db": {
    "tokens": 1200,
    "content": "), climatology (hurricanes),and chemistry (molecular structures). Scientiﬁc visualization has obvious linkageswith geographic visualization(see Chapters 11 and 16 of this volume, by Cartwrightand Gahegan respectively, for two treatments of this topic) whenever the focus ison depicting phenomena and processes that are referenced to the Earth’s surface. Incontrast, information visualization is concerned with data that do not have inherentspatial dimensions. Examples include bibliometric data, video collections, monetarytransaction ﬂows, or the content and link structure of Web pages. Most informationvisualizations are in essence spatialization displays. Spatialization is thus best inter-preted in the context of information visualization, which is quickly maturing intoa distinct discipline, including dedicated conferences, scientiﬁc journals, textbooks,and academic degree programs.Within GI Science, interest in spatialization tends to grow out of the geographicvisualization community, which in turn mostly consists of classically trained carto-graphers. It is not surprising then that GIScientists involved in spatialization researchdraw inspiration from traditional cartographic principles and methods (Skupin 2000).On the other hand, ongoing developments in geographic visualization have also led tointeractive, dynamic approaches that go beyond the static, 2D map (see Chapter 17by Batty, in this volume, for some additional discussion and examples of this type)and within which spatialization tools can be integrated.Data mining and knowledge discoveryshare many of the computational techniquesemployed in spatialization (see Chapter 19 by Miller, this volume, for some addi-tional discussion of geographic data mining and knowledge discovery), for exampleartiﬁcial neural networks. Many preprocessing steps are similar, such as the trans-formation of source data into a multidimensional, quantitative form (Fabrikant 2001),even if these data sources are non-numeric.Ultimately, spatialization is driven by the need to overcome the limited capacityof the human cognitive system to make sense of a highly complex, multidimensionalworld. That is why psychologyand especially cognitive sciencehave become inﬂu-ential disciplines in this research area. In this context it should be pointed out thatwhile this chapter focuses on visual depictions, spatializations could include multi-modal representations involving other senses such as sound, touch, smell, etc. In fact,the term spatialization ﬁrst became known in the context of methods for producing3D sound and detecting 3D spatial relationships from sound.Computer scienceis still the dominant academic home to most spatialization efforts and has led the development of fundamental principles and novel tech-niques, especially in the human–computer interaction (HCI) ﬁeld (Card, Mackinlay,and Shneiderman 1999). Few areas of scientiﬁc work have devoted as much effort to spatialization as information and library science, particularly when it comes tothe analysis of text and hypermedia documents (Börner, Chen, and Boyack 2002,Chen 2003).THO_C04  20/03/2007  14:52  Page 63 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f64ANDRÉ SKUPIN AND SARA I. FABRIKANTWhat Kinds Of Data Can Be Used For Spatialization?Spatialization methodologies can be applied to many different types of data. Onepossible division of these would focus on the degree to which they are structured,leading to a distinction between structured, semi-structured, and unstructured data(Skupin and Fabrikant 2003). This is useful in terms of highlighting basic data trans-formation difﬁculties often encountered in spatialization. For example, unstructuredtext data may lack a clear indication of where one data item ends and another beginsand can have dimensions numbering in the hundreds or thousands, as contrastedwith multidimensional data typically used in geospatial analysis, where one rarelyencounters more than a few dozen dimensions. However, given the focus of thisvolume on GI Science, this chapter considers two broad data categories. First, wediscuss geographically referenced data, which are of obvious relevance to GI sci-entists. Then, much attention is given to data that are not referenced to geographicspace or even related to geographic phenomena.Geospatially referenced dataWhy would one want to apply spatialization to geographically referenced dataifcartographic depictions have proven useful for over 5,000 years and continue tobe at the heart of current geovisualization research? Consider one very commonexample, the geographic visualization of demographic change. One almost alwaysﬁnds either juxtaposed maps of individual time slices or change condensed into com-posite variables (for example, relative percentage of growth). This may be sufﬁcientfor the visual detection of change as such, but does not easily support detection oftemporal patterns of change. While location is what vision experts and cognitivepsychologists call “pre-attentive” (MacEachren 1995, Ware 2000), this is basicallytaken out of play when geographically ﬁxed objects, such as counties, are visualizedin geographic space in this manner. Spatialization can eliminate that constraint bycreating a new, low-dimensional representation from high-dimensional attributes. Forexample, one could take multi-temporal, multi-dimensional, demographic data for counties, map each county as a point and, with deﬁned temporal intervals, linkthose points to form trajectories through attribute space (Skupin and Hagelman2005). Thus, change becomes visualized more explicitly (Figure 4.1). One can thenproceed to look for",
    "chunk_order_index": 43,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a9ec04648e886c8d32aba886e2cd6a41": {
    "tokens": 1200,
    "content": "geographic space in this manner. Spatialization can eliminate that constraint bycreating a new, low-dimensional representation from high-dimensional attributes. Forexample, one could take multi-temporal, multi-dimensional, demographic data for counties, map each county as a point and, with deﬁned temporal intervals, linkthose points to form trajectories through attribute space (Skupin and Hagelman2005). Thus, change becomes visualized more explicitly (Figure 4.1). One can thenproceed to look for visual manifestations of common verbal descriptions of demo-graphic change, such as “parallel” or “diverging” development (Figure 4.2). Tradi-tional cartographic visualization in geographic space may also fail to reveal patternsand relationships that do not conform to basic assumptions about geographic space,such as those expressed by Tobler’s First Law of Geography (Tobler 1970). Withspatialization one can take geographic location out (or control for it) while focusingon patterns formed in n-dimensional attribute space.In practice, spatializations derived from geographically referenced data will tend tobe used not in isolation but in conjunction with more traditional geographic depic-tions. Due to their predominantly two-dimensional form, geometric data structuresand formats used in GI Systems (GIS) are applicable to spatializations. They canbe displayed and interacted with in commercial off-the-shelf GIS. Most examplesTHO_C04  20/03/2007  14:52  Page 64 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIALIZATION65shown in this chapter were in fact created in ArcGIS (Environmental Systems ResearchInstitute, Redlands, California). Spatializations can also be juxtaposed to geographicmaps, linked via common feature identiﬁers, and explored in tandem.Many types of geographic data are suitable for spatialization. Population censusdata, for example, have traditionally been subjected to a number of multivariatestatistics and visualization techniques, sometimes combined to support exploratorydata analysis. Scatter plots and parallel coordinate plots (PCP) are established visualtools in the analytical arsenal. The spatialization methods discussed here do notreplace these, but add an alternative view of multivariate data. In this context, ithelps to consider how coordinate axes in visualizations are derived. In the case ofthe popular scatter plot method, each axis is unequivocally associated with an inputvariable. This is only feasible for a very limited number of variables, even whenscatter plots are arranged into matrix form (Figure 4.3). Principal coordinate plotslikewise exhibit clear association between axes and variables.Contrast this with map-like spatializations, in which the relationship between inputvariables and display coordinates is far less obvious. Some even refer to the result-ing axes as “meaningless” (Shneiderman, Feldman D, Rose A, and Grau 2000) andquestions like “What do the axes mean?” are frequently encountered. They are difﬁcultFig. 4.1Census-based visualization of trajectories of Texas counties based on data from 1980,1990, and 2000 US population censusFrom Skupin and Hagelman 2005WallerPanola198019902000HockleyYoakumFig. 4.2Cases of convergence and divergence in a spatialization of Texas county trajectories From Skupin and Hagelman 2005THO_C04  20/03/2007  14:52  Page 65 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f66ANDRÉ SKUPIN AND SARA I. FABRIKANTto answer, since in such techniques as multidimensional scaling or self-organizingmaps allinput variables become associated with all output axes. This allows a holistic view of relationships between observations (Figure 4.4). Figure 4.4 was derivedby training an artiﬁcial neural network, speciﬁcally a self-organizing or Kohonenmap (Kohonen 1995), with 32 input variables. Overall similarity of states becomesexpressed visually through 2D point visualization. In addition, some of the inputvariables are shown as component planes in the trained Kohonen map to allow aninvestigation of relationships between variables.WVWYWIRIIDSDORVTMAFLPATNWAOKNCVANJDCHINMCAAZNVFLNYNJILIDUTUTAKRIORWAWYMANCDCSCTNVTOHSDWIMSVAWVTXSCNYMDLATXNMMSAKUTVTWVNEWIWYSDMTRIWAPACTFLNJTNVASCNYLAMSHINMCATXAZNVNYFLCOILNJCTRIWYWAVAMDNHVTSDWIKSWVMEOHSCTNNCGADCCAGADCNCTXCOCOUTUTUTNMOKMDVTWAWANEMENDMDWIWIWYWYSDMTMOMOMNMNNHNHHIHIMAKSORORPANJINLALASCSCNVVAMSMSCACAGAVAGANCNCTXTXTXTXDCDCFLMIILDEAZAKNMNMNMNMOKOKOHTNTNMDMECACANYSDRIIAWVPAFLAZAZFLFLNVNVCOCONYNYUTWYOK",
    "chunk_order_index": 44,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-58b6eb8328bc6341a2c7e2b25b9b8c3c": {
    "tokens": 1200,
    "content": "CNCTXCOCOUTUTUTNMOKMDVTWAWANEMENDMDWIWIWYWYSDMTMOMOMNMNNHNHHIHIMAKSORORPANJINLALASCSCNVVAMSMSCACAGAVAGANCNCTXTXTXTXDCDCFLMIILDEAZAKNMNMNMNMOKOKOHTNTNMDMECACANYSDRIIAWVPAFLAZAZFLFLNVNVCOCONYNYUTWYOKORNDSDWVMTNEPAARMOOHVTKYILILNJNJDCVAVARIRIMAWIHIWIWYDETNMNNCWAWAUTAKGAMDNHNHMDNDWVSDTNVTAge 5–17WhiteHispanicAge 22–29Age 30–39Age 65+Fig. 4.3Scatter plots derived from demographic data for US statesUTTXCANVAKCONJHIILCTMANYRIMDDCLAMSGANCVASCTNKYALARDENHMEVTWVFLMOOHPAINIANEKSWIMNMIWAOROKSDNDMTIDNMAZWYWhiteHispanicAge 5–17Age 22–29Age 30–39Age 65+Fig. 4.4Spatializations derived from 32 demographic variables using the self-organizing mapmethod. Higher values in six (out of 32) component planes expressed as lighter shadingTHO_C04  20/03/2007  14:52  Page 66 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIALIZATION67Data without geographic coordinate referenceSome of the most exciting and evocative developments in the visualization ﬁeld in recent years have been efforts to apply spatial metaphors to non-geographic data or, more speciﬁcally, data that are not explicitly linked to physical space. Due to signiﬁcant differences in how such data are stored, processed, and ultimately visualized, this section discusses a number of data types separately.There are two broad categories of source data. One involves sources that alreadycontain explicitlinks between data items, which in their entirety can be con-ceptualized as a graph structure. The goal of spatialization for this category is toconveysuch structures in an efﬁcient manner in the display space. Hierarchical treestructures are especially common. A prime example is the directory structure of com-puter operating systems, like Windows or UNIX. Tree structures are also encountered in less expected places. For example, the Yahoo search engine organizes Web pages ina hierarchical tree of topics. The stock market can also be conceptualized as a tree,with market sectors and sub-sectors forming branch nodes and individual stocksas leaf nodes. Apart from such tree structures, data items could also be linked morefreely to form a general network structure. The hypermedia structure of the WorldWide Web is a good example, with Web pages as nodes and hot links between them.Scientiﬁc publications can also be conceptualized as forming a network structure,with individual publications as nodes and citations as explicit links between, gener-ally pointing to the past. The exception might be preprints as they do not exist yetin their deﬁning form. To illustrate this, we collected a few citation links from theInternational Journal of Geographical Information Science(IJGIS), starting with a2003 paper by Stephan Winter and Silvia Nittel entitled “Formal information model-ling for standardisation in the spatial domain.” The result is an origin–destinationtable of “who is citing whom” (Table 4.1). Later in this chapter, a visualizationcomputed from this citation link structure is shown.The second major group of non-georeferenced source data treats items as auto-nomous units that have no explicit connections among each other. Spatialization ofsuch data relies on uncovering implicitrelationships based on quantiﬁable notionsof distance or similarity. This requires ﬁrst a chunking or segmentation of individualdata items into smaller units, followed by a computation of high-dimensional rela-tionships. For example, the spatialization of text documents may involve breakingup each document into individual words. The following computations are then basedon ﬁnding implicit connections between documents based on shared terms (Skupinand Buttenﬁeld 1996). Similarly, images could be spatialized on the basis of imagesegmentation (Zhu, Ramsey, and Chen 2000). Other examples for spatializationsinvolving disjoint items have included human subject test data derived from usertracking and elicitation experiments (Mark, Skupin, and Smith 2001).How Does Spatialization Work?The types of data to which spatialization can be applied are so heterogeneous thatthere really is no single method. As was stressed earlier, spatialization tends to drawon many different disciplines and integrating these inﬂuences can be challenging. ForTHO_C04  20/03/2007  14:52  Page 67 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTable 4.1Origin–destination table for a citation network formed by papers within the International Journal of Geographical Information ScienceLinkFrom AuthorFrom TitleTo AuthorTo Title1Su et al. (199",
    "chunk_order_index": 45,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-3171132ba9d00c23caf219c67d1bf760": {
    "tokens": 1200,
    "content": "by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTable 4.1Origin–destination table for a citation network formed by papers within the International Journal of Geographical Information ScienceLinkFrom AuthorFrom TitleTo AuthorTo Title1Su et al. (1997)Algebraic models for the aggregation...Abler (1987)The National Science Foundation...2Su et al. (1997)Algebraic models for the aggregation...Rhind (1988)A GIS research agenda3Su et al. (1997)Algebraic models for the aggregation...Brassel and Weibel (1988)A review and conceptual framework...4Sester (2000)Knowledge acquisition for the...Su et al. (1997)Algebraic models for the aggregation...5Lin (1998)Many sorted algebraic data models...Su et al. (1997)Algebraic models for the aggregation...6Lin (1998)Many sorted algebraic data models...Kosters et al. (1997)GIS-application development with...7Winter and Nittel (2003)Formal information modeling...Lin (1998)Many sorted algebraic data models...8Lin (1998)Many sorted algebraic data models...Takeyama and Couclelis Map dynamics: integrating cellular...(1997)9Clarke and Gaydos Loose-coupling a cellular automaton...Takeyama and Couclelis Map dynamics: integrating cellular...(1998)(1997)10Shi and Pang (2000)Development of Voronoi-based...Okabe et al. (1994)Nearest neighborhood operations...11Shi and Pang (2000)Development of Voronoi-based...Takeyama and Couclelis Map dynamics: integrating cellular...(1997)12De Vasconcelos et al.A working prototype of a dynamic...Takeyama and Couclelis Map dynamics: integrating cellular...(2002)(1997)13Cova and GoodchildExtending geographical representation...Takeyama and CouclelisMap dynamics: integrating cellular...(2002)(1997)14Wu (2002)Calibration of stochastic cellular...Takeyama and CouclelisMap dynamics: integrating cellular...(1997)15Wu and Webster (2000)Simulating artiﬁcial cities in a GIS...Takeyama and CouclelisMap dynamics: integrating cellular...(1997)16Wu and Webster (2000)Simulating artiﬁcial cities in a GIS...Batty and Xie (1994)Modelling inside GIS: Part I. model...17Wu and Webster (2000)Simulating artiﬁcial cities in a GIS...Peuquet and Duan (1995)An event-based spatial temporal...18Wu and Webster (2000)Simulating artiﬁcial cities in a GIS...Burrough and Frank (1995)Concepts and paradigms in spatial...19Wu and Webster (2000)Simulating artiﬁcial cities in a GIS...Clarke and Gaydos (1998)Loose-coupling a cellular automaton...THO_C04  20/03/2007  14:52  Page 68 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFig. 4.5Portion of a spatialization of conference abstracts. Five levels of a hierarchical clusteringsolution are shown simultaneouslyFrom Skupin 2004SPATIALIZATION69an example, consider the task of creating a map-like visualization of the thousandsof abstracts that are presented at the annual meeting of the Association of AmericanGeographers (AAG). This is an example of a knowledge domain visualizationandwould be useful in the exploration of major disciplinary structures and relationshipsin the geographic knowledge domain (Figure 4.5). Figure 4.6 shows the broad out-lineof a possible methodology for creating such a visualization. In the process, italso serves to illustrate the range of involved disciplines and inﬂuences, which include •Information science and library science for creation of a term-document matrix,similar to most text retrieval systems and Web search engines (Widdows 2004);•Computer science for the artiﬁcial neural network method used here (Kohonen1995);•GIS for storage and transformation of spatialized geometry and associatedattributes;•Cartography for scale dependence, symbolization and other design decisions.PreprocessingAt the core of most spatialization procedures are techniques for dimensionality reduc-tion and spatial layout. These tend to be highly computational, with very speciﬁcrequirements for how data need to be structured and stored. Preprocessing of sourcedata aims to provide this. In the case of well-structured, numerical data stored instandard database formats, preprocessing is fairly straightforward. For example, for single-year census data it will often involve only a few processing steps that caneasily be accomplished using spreadsheet software, such as computation of z-scores,log transformations, or scaling of observations to ﬁt into a 0–1 range.The data to which spatialization is to be applied are, however, often not in aform that is amenable to immediate computation. In that case, much effort mayTHO_C04  20/03/2007  14:52  Page 69 Downloaded from https://onlinelibrary.wiley.com/",
    "chunk_order_index": 46,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-dcaaaa3cdfcc964057fb91abf88457a4": {
    "tokens": 1200,
    "content": "asily be accomplished using spreadsheet software, such as computation of z-scores,log transformations, or scaling of observations to ﬁt into a 0–1 range.The data to which spatialization is to be applied are, however, often not in aform that is amenable to immediate computation. In that case, much effort mayTHO_C04  20/03/2007  14:52  Page 69 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f70ANDRÉ SKUPIN AND SARA I. FABRIKANThave to be devoted to reorganizing source data into a more suitable form. This canalready be surprisingly difﬁcult when dealing with multi-temporal, georeferenceddata. Both geographic features and their attributes may be subject to change. Forexample, census block boundaries may be redrawn, ethnic categories redeﬁned, andso forth. However, the resulting difﬁculties pale in comparison to source data inwhich there are no set deﬁnitions of what constitutes a feature, how features areseparated from each other, or what the attributes should be that become associatedwith a feature.What one is faced with here is a distinction between structured and unstructureddata. The former is what one almost always encounters in GIS. Unstructured datapresent wholly different challenges. Consider the case of thousands of conferencepapers that one might have available in text form in a single ﬁle (Figure 4.7). Thereis no unequivocal separation between different documents nor clear distinction between content-bearing elements (title, abstract, keywords) and context elements(authors, afﬁliations, email addresses). One could look for certain elements (likeend-of-line characters) useful for parsing, but such a procedure will be uniquelytailored to this particular data set, may suffer from inconsistencies in the data, andwill require extensive modiﬁcation to be used for differently organized data.Semi-structured data are an attempt to address many of these problems by organ-izing data in accordance with a predeﬁned schema. The extensible markup languageFig. 4.6Procedure for deriving a spatialization from AAG conference abstracts From Skupin 2004ConferenceAbstracts inPDF filePreprocessing(Reformatting,Parsing, etc.)Stop WordRemovalLowFrequencyTerm RemovalCompute 2-DNeuronGeometryCompute 2-DNeuron ClusterGeometryCompute 2-DCoordinates forConferenceAbstractsVisualizationin GISPosterDocumentTerm-DocumentMatrixFilter OutDocumentsw/ Low or HighTerm CountSelf-OrganizingMap (SOM)TrainingComputeClusterLabelsTrainedSOMClustering ofSOM NeuronVectorsTHO_C04  20/03/2007  14:52  Page 70 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIALIZATION71(XML) is the most prominent solution to this. Figure 4.8 shows an example, inwhich a schema speciﬁcally designed for conference abstracts is applied to previouslyunstructured data. Such data offer many advantages. This XML ﬁle is suitable forhuman reading and computer parsing alike. From a software engineering point ofview, this type of hierarchical, unequivocal structure is also very supportive of object-oriented programming and databases.Spatialization depends on having data in a form that supports computation ofitem-to-item relationships in n-dimensional space. For structure-based methods, suchas those based on citation links (see Table 4.1) or hypertext links, relationships arealready explicitly contained and only have to be extracted to construct network graphs.For content-based analysis, the initial segmentation – for example the segmentationFig. 4.7Conference abstract as unstructured textFig. 4.8Conference abstract in semi-structured form as part of an XML ﬁleTHO_C04  20/03/2007  14:52  Page 71 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f72ANDRÉ SKUPIN AND SARA I. FABRIKANTof a photograph or the identiﬁcation of individual words within a text document –is followed by signiﬁcant transformations (see top row in Figure 4.6). For example,text data may undergo stop word removal and stemming (Porter 1980, Salton 1989),as illustrated here:input: The paper includes a brief discussion of alternatives to the Ralco Dam that couldsatisfy energy demand in southern Chile without violating indigenous rights to land andresourcesonput: paper includ brief discuss altern ralco dam satisﬁ energi demand southern chile violat indigen right land resourcFrom this, a high-dimensional vector can then be created for each document, withdimensions corresponding to speciﬁc word stems and values expressing the weightof a term within a document (Skupin and Buttenﬁeld 1996, Salton 1989, Skupin2002a).Dimensionality reduction and spatial layoutThe core of any spatialization",
    "chunk_order_index": 47,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ee6928d7ca0b59707de1cff60b0c2fd5": {
    "tokens": 1200,
    "content": "onput: paper includ brief discuss altern ralco dam satisﬁ energi demand southern chile violat indigen right land resourcFrom this, a high-dimensional vector can then be created for each document, withdimensions corresponding to speciﬁc word stems and values expressing the weightof a term within a document (Skupin and Buttenﬁeld 1996, Salton 1989, Skupin2002a).Dimensionality reduction and spatial layoutThe core of any spatialization methodology is the transformation of input data into alow-dimensional, representational space. In the case of data given as distinct featureswith a certain number of attributes one can rightfully refer to the correspondingtechniques as dimensionality reduction. Spatial layouttechniques are typically usedwhen dealing with explicitly linked features, as in the case of citation networks.Two popular dimensionality reduction techniques are multidimensional scaling(MDS) and the self-organizing map(SOM) method. MDSﬁrst requires the com-putation of a dissimilarity matrix from input features, based on a carefully chosendissimilarity measure. Then, the method attempts to preserve high-dimensional dis-similarities as distances in a low-dimensional geometric conﬁguration of features(Kruskal and Wish 1978). The popular Themescapes application (Wise, Thomas,Pennock, et al. 1995) is based on a variant of MDS (Wise 1999). Within GI Science,spatialization efforts have utilized MDS to create 2D point geometries for sub-disciplines of geography (Goodchild and Janelle 1988), newspaper articles (Skupinand Buttenﬁeld 1996, 1997), and online catalog entries (Fabrikant and Buttenﬁeld2001).The SOM method is an artiﬁcial neural network technique (Kohonen 1995). It starts out with a low-dimensional (typically 2D) grid of n-dimensional neuronvectors. N-dimensional input data are repeatedly presented to these neurons. Thebest matching neuron to each observation is found and small adjustments are madeto the vector of that neuron as well as to the vectors of neighboring neurons. Overtime, this leads to a compressed/expanded representation in response to a sparse/dense distribution of input features. Consequently, major topological relationshipsin n-dimensional feature space become preserved in the two-dimensional neurongrid. One can then map n-dimensional observations onto it (left half of Figure 4.4),visualize individual neuron vector components (right half of Figure 4.4), or computeneuron clusters (Figure 4.5). SOMs have, for example, been used to spatialize Usenetdiscussion groups, Web pages (Chen, Schuffels, and Orwig 1996), image content(Zhu, Ramsey, and Chen 2000), conference abstracts (Skupin 2002a, 2004), and evenTHO_C04  20/03/2007  14:52  Page 72 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIALIZATION73a collection of several million patent abstracts (Kohonen, Kaski, Lagus, et al. 1999).Spring modelsare another popular category of dimensionality reduction techniques(Kamada and Kawai 1989, Skupin and Fabrikant 2003).Pathﬁnder network scaling(PFN) is a technique used for network visualization,with a preservation of the most salient links between input features. It is frequentlyapplied to citation networks (Chen and Paul 2001). To illustrate this, we computeda PFN solution from the IJGIScitation data shown earlier. The result is a networkstructure consisting of links and nodes. When combined with a geometric layoutof nodes derived from a spring model, the citation network can be visualized inGIS (Figure 4.9). Circle sizes represent the degree of centrality a paper has in thisnetwork, a measure commonly used in social network analysis (Wasserman andFaust 1999). Note how the centrality of the Takeyama/Couclelis paper derives fromit being frequently cited (see Table 4.1), while the Wu/Webster paper establishes acentral role because it cites a large number of IJGISpapers.Among spatial layout techniques, the treemapmethod has become especially pop-ular in recent years. It takes a hierarchical tree structure as input and lays portions ofit out in a given two-dimensional display space (Johnson and Shneiderman 1991). Inthe process, node attributes can also be visually encoded (Figure 4.10). For example,when visualizing the directory structure of a hard drive, ﬁle size could be encoded asthe area size of rectangles. Another important category are graph layoutalgorithms,which attempt to untangle networks of nodes and links in such a manner that cross-ing lines are avoided as much as possible and network topology is preserved.Rhind (1988)Brassel & Weibel (1988)Abler (1987)Sester (2000)Winter and Nittel (2003)Su et al. (1997)Kosters et al. (1997)Okabe et al. (1994)Lin (1998)Clarke & Gaydos (1998)Batty & Xie (1994)Peuquet & Duan (1995)Shi & Pang (2000)Wu (2002)connectednesssmallmediumstrongcitationCova & Goodchild (2002)De Vas",
    "chunk_order_index": 48,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-09f9ebff1024e6a0ce8d7374a916a0a5": {
    "tokens": 1200,
    "content": "(2000)Winter and Nittel (2003)Su et al. (1997)Kosters et al. (1997)Okabe et al. (1994)Lin (1998)Clarke & Gaydos (1998)Batty & Xie (1994)Peuquet & Duan (1995)Shi & Pang (2000)Wu (2002)connectednesssmallmediumstrongcitationCova & Goodchild (2002)De Vasconcelos et al. (2002)Wu and Webster (2000)Burrough & Frank (1995)Takeyama & Couclelis (1997)Fig. 4.9Spring model layout and pathﬁnder network scaling applied to a small citation networkformed by papers in the International Journal of Geographical Information ScienceTHO_C04  20/03/2007  14:52  Page 73 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f74ANDRÉ SKUPIN AND SARA I. FABRIKANTOnce dimensionality reduction or spatial layout methods have been applied, further transformations are necessary to execute the visual design of a spatializa-tion. Depending on the character of the base geometry, these transformations mayinclude the derivation of feature labels, clustering of features, landscape interpola-tion, and others (Skupin 2002b, Skupin and Fabrikant 2003). When dealing with 2Dgeometry, much of this can be accomplished in commercial off-the-shelf (COTS) GIS.Many aspects of these transformations remain to be investigated in future research,for instance how scale changes can be implemented as semantic zoom operations(Figure 4.11).18210202186420Fig. 4.10The tree map methodFrom Skupin and Fabrikant 2003Fig. 4.11Use of GIS in implementing scale-dependent spatialization of several thousand AAGconference abstracts. Labeling is based on two different k-means cluster solutionsFrom Skupin 2004THO_C04  20/03/2007  14:52  Page 74 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIALIZATION75Spatialization geometry can also be linked to attributes that were not part of theinput data set. For example, demographic change trajectories (Figures 4.1 and 4.2)could be linked – via symbolization or selection – to voting behavior or public policydecisions (Skupin and Hagelman 2005).Usability and Cognitive PerspectivesAn extensive set of display techniques has been developed for spatialization, and theimpressive array of visual forms documents the productivity of this young academicﬁeld (Chen 1999). However, few researchers have succeeded in providing empir-ical evidence to support claims that interactive visual representation tools indeedamplify people’s cognition (Ware 2000). Generally, non-expert viewers do not knowhow spatializations are created and are not told, through legends or traditional map marginalia, how to interpret such aspects of spatialized displays as distance,regionalization, and scale. Of the few existing experimental evaluations in informa-tion visualization, most evaluate speciﬁc depiction methods or types of software (Chenand Czerwinski 2000, Chen, Czerwinski, and Macredie 2000). While usability engineering approaches are good at testing users’ successes in extracting informationfrom a particular visualization, they do not directly assess the underlying theoreticassumptions encoded in the displays, the users’ understanding of the semantic map-ping between data and metaphor, and between metaphor and graphic variables, orthe interaction of graphic variables with perceptual cues.A fundamental principle in spatialization is the assumption that more similar entities represented in a display should be placed closer together because users will interpret closer entities as being more similar (Wise, Thomas, Pennock, et al. 1995, Card, Mackinlay, and Shneiderman 1999). Montello, Fabrikant, Ruocco, and Middleton (2003) have coined this principle the distance-similarity metaphor.For example, according to the distance-similarity metaphor, US states depicted inFigures 4.3 and 4.4 or conference abstracts shown in Figure 4.5 that are more similar to each other in content are placed closer to one another in the display, whilespatialized items that are less similar in content are placed farther apart. Inessence, this distance-similarity metaphor is the inverse of Tobler’s (1970, p. 236)ﬁrst law of geography, because similarity typically determines distance in spatializa-tions. Thus we have referred to the “ﬁrst law of cognitive geography” (Montello,Fabrikant, Ruocco, and Middleton 2003) – people believe that closer features aremore similar than distant features. To the extent that this principle is true, it pro-vides theoretical justiﬁcation for the distance-similarity metaphor as a principle ofspatialization design.In a series of studies relating to point (Fabrikant 2001, Montello, Fabrikant, Ruocco,and Middleton 2003), network (Fabrikant,",
    "chunk_order_index": 49,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4255bbd5eb9ee1afd66187c982161856": {
    "tokens": 1200,
    "content": "(Montello,Fabrikant, Ruocco, and Middleton 2003) – people believe that closer features aremore similar than distant features. To the extent that this principle is true, it pro-vides theoretical justiﬁcation for the distance-similarity metaphor as a principle ofspatialization design.In a series of studies relating to point (Fabrikant 2001, Montello, Fabrikant, Ruocco,and Middleton 2003), network (Fabrikant, Montello, Ruocco, and Middleton 2004),region (Fabrikant, Montello, and Mark 2006), and surface display spatializations(Fabrikant 2003) Fabrikant and colleagues have investigated whether the fundamentalassumption that spatialization can be intuitively understood as if they represent real-world spaces (Wise, Thomas, Pennock, et al. 1995, Card, Mackinlay, andShneiderman 1999) is generally true. These studies provide the ﬁrst empirical evid-ence of the cognitive adequacy of the distance-similarity metaphor in spatialization.THO_C04  20/03/2007  14:52  Page 75 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f76ANDRÉ SKUPIN AND SARA I. FABRIKANTIn these studies, participants have rated the similarity between documents depicted aspoints in spatialized displays. Four types of spatialization displays have been examined:(1) point displays (e.g., Figures 4.3 and 4.4), (2) network displays linking the points(e.g. Figures 4.1, 4.2 and 4.9), (3) black-and-white regions containing the points (e.g.Figure 4.5), and (4) colored regions containing the points (Figure 4.10). In the pointdisplays, participants based judgments of the relative similarity of two pairs of docu-ment points primarily on direct (straight-line or “as the crow ﬂies”) metric distancesbetween points, but concentrations of points in the display led to the emergence ofvisual features in the display, such as lines or clusters, that considerably moderatedthe operation of the ﬁrst law of cognitive geography. In the network displays, par-ticipants based similarity judgments on metric distances along network links, eventhough they also had available direct distances across network links and topologicalseparations (numbers of nodes or links connecting points). In the region displays,participants based similarity judgments primarily on region membership so that com-parison documents within a region were judged as more similar than documentsin different regions, even if the latter were closer in direct distance. Coloring theregions produced thematically-based judgments of similarity that could strengthen orweaken regional membership effects, depending on whether region hues matchedor not. In addition, Fabrikant and Montello (2004) also gained explicit informationon how similarity judgments directly compare to default distance and direct distancejudgments. There are no differences between people’s estimates of distance underdefault (nonspeciﬁed) and direct (straight-line) distance instructions for point, net-work, and region spatializations. Default distance instructions are interpreted as requests for estimates of direct distance in spatializations. They have also foundthat well-known optical effects such as the vertical (Gregory 1987) and space-ﬁllinginterval illusion (Thorndyke 1981) affect distance judgments in spatializations andtherefore may affect the operation of the ﬁrst law of cognitive geography.Without empirical evidence from fundamental cognitive evaluations the identiﬁca-tion and establishment of solid theoretical foundations in spatialization will remainone of the major research challenges (Catarci 2000). A solid theoretical scaffold is not only necessary for grounding the information visualization ﬁeld on soundscience, but is also fundamental to deriving valid formalisms for cognitively ade-quate visualization designs, effective graphical user interface implementations, andtheir appropriate usability evaluation (Fabrikant and Skupin 2005).Where Is Spatialization Going?Spatialization addresses a need to make sense of the information contained in ever-growing digital data collections. There is considerable societal demand for thetypes of methods discussed in this paper. This includes such obvious applicationsas counter-terrorism work or the development of improved Web search engine interfaces. Telecommunications companies attempt to ﬁnd patterns in millions ofphone calls through spatialization. Private industry also hopes to use spatializationto detect emerging technological trends from research literature in order to gain a competitive advantage. Funding agencies would like to determine which researchgrant applications show the most promise. In recent years there have been a growingTHO_C04  20/03/2007  14:52  Page 76 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIALIZATION77number of events dedicated to the type of research within which spatialization isprominently featured, organized by the National Academy of Sciences (Shiffrin andBörner 2004), the National Institutes of Health, the National Security Agency, and other public and private entities.This chapter demonstrates that spatialization may be applicable to both geo-referenced and non-georeferenced phenomena, whenever n-dimensional data needto be investigated in",
    "chunk_order_index": 50,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-03767bde803044494f0356618f6da4a4": {
    "tokens": 1200,
    "content": "are governed by the applicable Creative Commons License\fSPATIALIZATION77number of events dedicated to the type of research within which spatialization isprominently featured, organized by the National Academy of Sciences (Shiffrin andBörner 2004), the National Institutes of Health, the National Security Agency, and other public and private entities.This chapter demonstrates that spatialization may be applicable to both geo-referenced and non-georeferenced phenomena, whenever n-dimensional data needto be investigated in a holistic, visually engaging form. The involvement of GI scientists in spatialization activities does not have to be a one-way street in termsof using spatialization within particular applications. GI Science is also beginningto help answer fundamental questions with regards to how spatializations are con-structed and used (Skupin, Fabrikant, and Couclelis 2002). Our understanding ofcognitive underpinnings, usability, and usefulness is still quite incomplete. The com-putational techniques used for spatialization also need further investigation, especiallywhen it comes to developing methods for integrated treatment of the tri-space formedby geographic, temporal, and attribute space. In summary, spatialization is an excit-ing area in which GI Science is challenged to address important issues of theoryand practice for many different data and applications.REFERENCESBörner, K., Chen, C., and Boyack, K. W. 2002. Visualizing knowledge domains. In B. Cronin(ed.) Annual Review of Information Science and Technology. Medford, NJ: InformationToday: 179–255.Card, S. K., Mackinlay, J. D., and Shneiderman, B. 1999. Readings in Information Visual-ization: Using Vision to Think.San Francisco, CA: Morgan Kaufmann.Catarci, T. 2000. What’s new in visual query systems? In Proceedings of the First Inter-national Conference on Geographic Information Science. Savannah, GA, USA. Santa Barbara,CA: National Center for Geographic Information and Analysis.Chen, C. 1999. Information Visualisation and Virtual Environments. London: Springer.Chen, C. 2003. Mapping Scientiﬁc Frontiers: The Quest for Knowledge Visualization.London: Springer.Chen, C. and Czerwinski, M. 2000. Empirical evaluation of information visualizations: Anintroduction. International Journal of Human-Computer Studies53: 631–5.Chen, C., Czerwinski, M., and Macredie, R. D. 2000. Individual differences in virtual envir-onments: Introduction and overview. Journal of the American Society of Information Science51: 499–507.Chen, C. and Paul, R. J. 2001. Visualizing a knowledge domain’s intellectual structure. IEEEComputer34(3): 65–71.Chen, H., Schuffels, C., and Orwig, R. 1996. Internet categorization and search: A self-organizing approach. Journal of Visual Communication and Image Representation7: 88–102.Couclelis, H. 1998. Worlds of information: The geographic metaphor in the visualiza-tion of complex information. Cartography and Geographic Information Systems25:209–20.Fabrikant, S. I. 2001. Evaluating the usability of the scale metaphor for querying semanticspaces. In R. D. Montello (ed.) Spatial Information Theory: Foundations of GeographicInformation Science.Berlin: Springer Lecture Notes in Computer Science No. 2205:156–72.THO_C04  20/03/2007  14:52  Page 77 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f78ANDRÉ SKUPIN AND SARA I. FABRIKANTFabrikant, S. I. 2003. Distanz als Raummetapher für die Informationsvisualierung (Distanceas a spatial metaphor for the visualization of information). Kartographische Nachrichten52: 276–82.Fabrikant, S. I. and Buttenﬁeld, B. P. 2001. Formalizing semantic spaces for informationaccess. Annals of the Association of American Geographers91: 263–80.Fabrikant, S. I. and Montello, D. R. 2004. Similarity and distance in information spatial-izations. In Proceedings of GIScience 2004, Adelphi, MD, USA. Santa Barbara, CANational Center for Geographic Information and Analysis, pp, 279–81.Fabrikant, S. I., Montello, D. R., and Mark, D. M. 2006. The distance-similarity metaphorin region-display spatializations. IEEE Computer Graphics & Applications26: in press.Fabrikant, S. I., Montello, D. R., Ruocco, M., and Middleton, R. S. 2004. The distance-similarity metaphor in network-display spatializations. Cartography and GeographicInformation Science31: 237–52.Fabrikant, S. I. and Skupin, A. 2005. Cognitively plausible information visualization. In Dykes, J., MacEachren, A. M., and Kraak, M.-J. (eds) Exploring Geovisualization.Amsterdam: Elsevier: 667–90.Goodchild, M. F. and Janelle, D. G. 1988. Specialization in the structure and organizationof geography.",
    "chunk_order_index": 51,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f23c81c65e7ee1c9d512c16e19541a12": {
    "tokens": 1200,
    "content": "–52.Fabrikant, S. I. and Skupin, A. 2005. Cognitively plausible information visualization. In Dykes, J., MacEachren, A. M., and Kraak, M.-J. (eds) Exploring Geovisualization.Amsterdam: Elsevier: 667–90.Goodchild, M. F. and Janelle, D. G. 1988. Specialization in the structure and organizationof geography. Annals of the Association of American Geographers78: 1–28.Gregory, R. L. (ed.). 1987. The Oxford Companion to the Mind.Oxford: Oxford UniversityPress.Johnson, B. and Shneiderman, B. 1991. Treemaps: A space-ﬁlling approach to the visual-ization of hierarchical information structures. In Proceedings of IEEE Visualization ’91,San Diego, CA, USA. Los Alamitos, CA: Institute of Electrical and Electronics Engineers,pp. 275–82.Kamada, T. and Kawai, S. 1989. An algorithm for drawing general undirected graphs.Information Processing Letters31: 7–15.Kohonen, T. 1995. Self-Organizing Maps.Berlin: Springer-Verlag.Kohonen, T., Kaski, S., Lagus, K., Salojärvi, J., Honkela, J., Paatero, V., and Saarela, A.1999. Self organization of a massive text document collection. In E. Oja and S. Kaski(eds) Kohonen Maps.Amsterdam: Elsevier, pp. 171–82.Kruskal, J. B. and Wish, M. 1978. Multidimensional Scaling.London: Sage University PaperSeries on Qualitative Applications in the Social Sciences No. 07-011.Kuhn, W. and Blumenthal, B. 1996. Spatialization: Spatial Metaphors for User Interfaces.Vienna, Austria: Technical University of Vienna.Lakoff, G. and Johnson, M. 1980. Metaphors We Live By.Chicago, I: University of ChicagoPress.MacEachren, A. M. 1995.How Maps Work.New York: Guilford Press.Mark, D. M., Skupin, A., and Smith, B. 2001. Features, objects, and other things: Onto-logical distinctions in the geographic domain. In D. R. Montello (ed.). Spatial InformationTheory: Foundations of Geographic Information Science.Berlin: Springer-Verlag LectureNotes in Computer Science No. 2205: 488–502.McCormick, B. H., Defanti, T. A., and Brown, M. D. 1987. Visualization in scientiﬁc com-puting. IEEE Computer Graphics and Applications7(10): 69–79.Montello, D. R., Fabrikant, S. I., Ruocco, M., and Middleton, R. 2003. Spatialization: Testing the ﬁrst law of cognitive geography on point-spatialization displays. In W. Kuhn,M. F. Worboys, and S. Timpf (eds) Spatial Information Theory: Foundations of Geo-graphic Information Science.Berlin: Springer-Verlag Lecture Notes in Computer ScienceNo. 2825: 335–51.Porter, M. F. 1980. An algorithm for sufﬁx stripping. Program-Automated Library andInformation Systems14: 130–7.Salton, G. 1989. Automated Text Processing: The Transformation, Analysis, and Retrievalof Information by Computer.Reading, MA: Addison-Wesley.THO_C04  20/03/2007  14:52  Page 78 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIALIZATION79Shiffrin, R. M. and Börner, K. 2004. Mapping knowledge domains. Proceedings of the NationalAcademy of Sciences101: 5183–5.Shneiderman, B., Feldman, D., Rose, A., and Grau, X. F. 2000. Visualizing digital librarysearch results with categorical and hierarchical axes. In Proceedings of the ACM Con-ference on Digital Libraries (DL2000),San Antonio, TX, USA. New York: Associationof Computing Machinery, pp. 57–65.Skupin, A. 2000. From metaphor to method: Cartographic perspectives on information visualization. In Proceedings of the IEEE Symposium on Information Visualization(InfoVis ’00),Salt Lake City, UT, USA. Los Alamitos, CA: Institute of Electrical andElectronics Engineers, pp. 91–7.Skupin, A. 2002a. A cartographic approach to visualizing conference abstracts. IEEEComputer Graphics and Applications, 22: 50–8.Skupin, A. 2002b. On geometry and transformation in map-like information visualization.In K. Börner and C. Chen (eds) Visual Interfaces to Digital Libraries.Berlin: Springer-Verlag Lecture Notes in Computer Science No. 2539: 161–70.Skupin, A. 2004. The world of geography: Visualizing a knowledge domain with cartographicmeans. Proceedings of the National Academy of Sciences101: 5274–8.Skupin, A. and Buttenﬁeld, B",
    "chunk_order_index": 52,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ad5f99dfcef413a5476e5db51ee915ed": {
    "tokens": 1200,
    "content": "On geometry and transformation in map-like information visualization.In K. Börner and C. Chen (eds) Visual Interfaces to Digital Libraries.Berlin: Springer-Verlag Lecture Notes in Computer Science No. 2539: 161–70.Skupin, A. 2004. The world of geography: Visualizing a knowledge domain with cartographicmeans. Proceedings of the National Academy of Sciences101: 5274–8.Skupin, A. and Buttenﬁeld, B. P. 1996. Spatial metaphors for visualizing very large data archives.In Proceedings of GIS/LIS ’96,Denver, CO, USA. Bethesda, MD: American Society forPhotogrammetry and Remote Sensing, pp. 607–17.Skupin, A. and Buttenﬁeld, B. P. 1997. Spatial metaphors for visualizing information spaces.In Proceedings of Auto Carto 13. Bethesda, MD: American Congress of Surveying andMapping/American Society for Photogrammetry and Remote Sensing, pp. 116–25.Skupin, A. and Fabrikant, S. I. 2003. Spatialization methods: A cartographic research agendafor non-geographic information visualization. Cartography and Geographic InformationScience30: 99–119.Skupin, A., Fabrikant, S. I., and Couclelis, H. 2002. Spatialization: Spatial metaphors andmethods for handling non-spatial data. WWW document, http://www.geog.ucsb.edu/~sara/html/research/ucgis/spatialization_ucsb.pdf.Skupin, A. and Hagelman, R. 2005. Visualizing demographic trajectories with self-organizingmaps. GeoInformatica9: 159–79.Thorndyke, P. W. 1981. Distance estimation from cognitive maps. Cognitive Psychology13:526–50.Tobler, W. 1970. A computer model simulating urban growth in the Detroit region. EconomicGeography46: 234–40.Ware, C. 2000. Information Visualization: Perception for Design.San Francisco, CA: MorganKaufman.Wasserman, S. and Faust, K. 1999. Social Network Analysis.Cambridge: Cambridge Uni-versity Press.Widdows, D. 2004. Geometry and Meaning. Stanford: CSLI Publications.Wise, J. A. 1999. The ecological approach to text visualization. Journal of the AmericanSociety for Information Science50: 1224–33.Wise, J. A., Thomas, A. J., Pennock, K., Lantrip, D., Pottier, M., Schur, A., and Crowet, V.1995. Visualizing the non-visual: Spatial analysis and interaction with information fromtext documents. In Proceedings of the IEEE Symposium on Information Visualization (InfoVis ’95),Atlanta, GA, USA, pp. 51–8.Zhu, B., Ramsey, M., and Chen, H. 2000. Creating a large-scale content-based airphotoimage digital library.IEEE Transactions on Image Processing9: 163–7.THO_C04  20/03/2007  14:52  Page 79 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 5Uncertainty in Spatial DatabasesAshley MorrisUncertainty permeates the fabric of spatial data at every level: in the assimilation andstorage of geospatial features (which may have uncertain or indeterminate boundaries),in the operations on these features, and in the representation of the results of theoperations.As a spatial database represents features modeled in the real, inﬁnitely complexworld, it is not able to be completely faithful to the real features being represented.Uncertainty is often used to describe the differences between what the database captures of the real world, and that which actually exists (Goodchild 1998).TermsThere is a special vocabulary attached to spatial databases. Some deﬁnitions areprovided below to ensure that the ambiguity in the verbiage is minimized.An erroris simply something that is incorrect. We must know a value to be incorrect for there to be error in our model. Occasionally, we may note that thereare missing values for attributes of our objects. We can treat these values as eitherbeing in error, or being uncertain. An observed error relates to a single value, whereasaccuracy relates to a set of values.Accuracymay be broken down into biasand precision. Bias is dependent uponthe underlying data model, and is most often predicted by the mean error betweena set of known (or actual) values and predicted (or stored) values. Precision is alsomodel-based, but it is often based upon the standard deviation of the error of a setof values. Accuracy can thus be deﬁned as the sum of the precision and the unbias(Foody and Atkinson 2002). Positional inaccuracy is typically caused by limitedability to measure locations on the surface of the earth (Goodchild 1998).Uncertaintysimply means that of which we are not certain; that which is notknown. Uncertainty can be divided into ambiguity and vagueness (Klir and Folger1988). Ambiguityis the type of uncertainty most often modeled internally by prob-ability. In probability, we are predicting the chances of an object being a memberof a boolean set. So if we were representing the country of Switzerland",
    "chunk_order_index": 53,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-93f9a9209316ed2f7f8be16af7e098b1": {
    "tokens": 1200,
    "content": "locations on the surface of the earth (Goodchild 1998).Uncertaintysimply means that of which we are not certain; that which is notknown. Uncertainty can be divided into ambiguity and vagueness (Klir and Folger1988). Ambiguityis the type of uncertainty most often modeled internally by prob-ability. In probability, we are predicting the chances of an object being a memberof a boolean set. So if we were representing the country of Switzerland as a singleTHO_C05  19/03/2007  11:21  Page 80 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fUNCERTAINTY IN SPATIAL DATABASES81object in our spatial database, and we had to choose among German, French, Italian,or Romansh as the value for the attribute language, we would most likely chooseGerman, as about 64 percent of the population speak German. However, if we wentto a higher level of detail and considered Switzerland as being made up of 23 indi-vidually modeled cantons, we could represent the predominant language of eachcanton, and thus end up with less ambiguity (http://www.switzerlandtourism.ch/).Most often, probability is used to express ambiguity when dealing with uncertaindata. Vaguenessrefers to data that does not strictly belong to a crisp set.Unfortunately, we also have ambiguity in the terms being used to denote some-thing of interest in a spatial database. The term featureis often used to describe a single entity, although it may refer to a collection of entities. Entity, on the otherhand, is often ambiguously used, because of the confusion with the term entity inthe entity/relationship method of conceptual database modeling. The same problemfollows the term object, as it is often confused with an object in an object-orientedspatial database. One particularly confusing point is that an object, in object-oriented database terminology, may actually be a collectionof several objects thatis treated as a single object.We will use the term featureto describe the representation of a single physicalthingwithin the spatial database, and entityto denote the physical thing existingin the real physical world.Crisp sets, also known as boolean sets or classical sets, consist of unordered collec-tions of unique objects. All members of the set have full (1.0) membership in the set.Objects that are not members of the set have no (0.0) membership in the set.In classical set theory, there are two fundamental laws: the law of the excludedmiddle and the law of contradiction. The law of the excluded middle states that everyproposition is either true or false, and the law of contradiction states that an elementx must either be a member of a set or not be a member of a set (Robinson 2003).Fuzzy sets introduce the concept of partial membership. In a fuzzy set, objects mayhave partialmembership. For example, a certain soil sample may have 0.49 member-ship in the set of Loamy Soil, it may have 0.33 membership in Sandy Soil, and it mayhave 0.18 membership in Rocky Soil. Note that this violates both the law of theexcluded middle, and the law of contradiction. This will have consequences on the operations that can be performed upon these sets, but it will allow operations tobe performed on elements that normally would not be considered as set members.Within a fuzzy set, we may have objects comprising the core(full membership of1.0 in the set in question) and we may have a boundary(the area beyond which theyhave no or negligible membership in the set). A classic example of the core andboundary problem is determining where a forest begins. Is it determined based ona hard threshold of trees per hectare? This may be the boundary set by manage-ment policy but it is likely not to be the natural deﬁnition. There are several waysto manage these uncertain boundaries (Fisher 1996, Cheng, Molenaar, and Lin 2001).If our spatial database can represent the outlying trees as being partial members ofthe forest, then the decision-maker will see these features as being partial memberson the display.In general, the idea of implementing fuzzy set theory as a way to model uncertaintyin spatial databases has a long history. In the 1970s, fuzzy set theory was proposedas a technique for geographic analysis (Gale 1972, Leung 1979). However, it isonly recently that this idea has taken hold in the modern Geographic InformationTHO_C05  19/03/2007  11:21  Page 81 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f82ASHLEY MORRISSystem (GIS) (see Chapter 14 by Robinson in this volume for a more detailed dis-cussion of this approach).What is Stored in Spatial DatabasesFirst, we need to understand what is being stored in a spatial database. It does notstore maps; rather it stores features, objects with an associated geometry. While a spatial database may store any object with a geometry, it typically stores geo-referenced or geospatial objects. These objects can have attributes answering thequestions: who, what, where",
    "chunk_order_index": 54,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6a5bd6dc5bf6ba11ba96fc68108f6519": {
    "tokens": 1200,
    "content": "(GIS) (see Chapter 14 by Robinson in this volume for a more detailed dis-cussion of this approach).What is Stored in Spatial DatabasesFirst, we need to understand what is being stored in a spatial database. It does notstore maps; rather it stores features, objects with an associated geometry. While a spatial database may store any object with a geometry, it typically stores geo-referenced or geospatial objects. These objects can have attributes answering thequestions: who, what, where, when, why, and how.The whorefers to the generator of the source material. It may have come fromremotely sensed data, bathymetric sidescan sonar, ﬁeld GPS surveying, or a down-loaded shapeﬁle. The whooften is important when measuring the quality of the data.If a source is not reliable, then we may want to consider the data has an additionaldegree of vagueness or imprecision.The whatis answered by the attributes of the object, the thematic data. Featuresin a spatial database may have many attributes for thematic data, they may havemultiple values for a single attribute of thematic data (like calling the largest mountainin Alaska both McKinleyand Denali), and they might possibly have no thematicattributes at all, other than their system generated primary key or object identiﬁer.Obviously, we may have ambiguity associated with the feature as a result of uncer-tainty in the thematic attributes.The whereis what differentiates spatial data from other kinds of data that maybe stored in a database. The spatial attributes not only tell the size and dimensionsof an object, but also where that object is positioned in space. This is the area where we will spend most of our effort: looking at the uncertainty that may occurwhen trying to determine, store, and represent wherean object may be. The spatialinformation stored in a spatial database describes the location and shape of thegeographic features in terms of points, lines, and areas.The whencomes from attempting to manage temporal data. Most databases donot, by default, attempt to manage temporal data. The relational database modelis designed to only store a snapshot of the world being modeled at a single pointin time. It can be extended to represent the evolution of the modeled world over time better, as can the object-oriented database model. It is slightly easier to model temporality in an object-oriented model, as we will describe in more detail later.Modeling whyis beyond the scope of most spatial databases, but may come intoplay if we are dealing with an advanced GIS that supports modeling and patterntype queries.How, as it relates to features, describes the scale of the data. When performingqueries using features of different scale, we may return imprecise results.Modeling and Storing FeaturesGIS users are demanding the ability to represent geographic objects with uncertainboundaries (e.g., Ehlschlaeger and Goodchild 1994, Campari 1996, Goodchild 1998,THO_C05  19/03/2007  11:21  Page 82 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fUNCERTAINTY IN SPATIAL DATABASES83Hunter 1998), thus, in modern GIS, there is a need to more precisely model andrepresent the underlying uncertain spatial data (Zhang and Goodchild 2002). Modelshave been proposed since 1990 that allow for enriching database models to manageuncertain spatial data (e.g. George, Buckles, and Petry 1992). A major motivationfor this is that there exist geographic objects with uncertain boundaries, and fuzzysets are a natural way to represent this uncertainty (Goodchild and Gopal 1990,Burrough 1996, Burrough and Couclelis 1996, Couclelis 1996, Petry, Cobb andMorris 1999). There are two primary ways to model this data: as individual objects,or as continuous ﬁelds. Ideally, we should aim towards a framework that can support both of these.Feature-based (atomic) models propose that the world can be modeled by representing the smallest single atomic feature, and then layers can be composedof collections of these features. On the other hand, ﬁeld-based (plenum) models donot have an intrinsic notion of atom, or boundaries. The crisp concept of featureis not applicable; rather each pixel may have a value for one or more attributes.Historically, raster-based GIS have been modeled on the ﬁeld concept, and vector-based GIS have used feature-based models.Rather than modeling geospatial features as continuous ﬁelds, with perhaps partial membership in every class being modeled, or modeling geospatial featuresas simple concrete objects, and avoiding the uncertainty altogether, the ideal spatialdatabase should be able to manage both. Nowhere does the problem of real-worldcomplexity cause greater problems than when trying to model the many possibleobservable abstractions of real-world data.Relational and object-oriented database management systems(DBMSs)A problem comes when we have to apply this real-world data model for storagein a DBMS. As we want to store features with uncertain boundaries it follows that a DBMS that supports fuzziness would be a more ideal solution. Buckles andPetry (1982), for example, show that we can easily extend the relational model to support fuzziness. So the problem lies not when we wish to store fuzzy items in a relational DBMS but when we wish to store spatial features in a relationalDBMS.Historically, most spatial databases have stored features in a relational format. Inthe",
    "chunk_order_index": 55,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-dfe19a9aca9d8f80884b6447899c73fc": {
    "tokens": 1200,
    "content": ". As we want to store features with uncertain boundaries it follows that a DBMS that supports fuzziness would be a more ideal solution. Buckles andPetry (1982), for example, show that we can easily extend the relational model to support fuzziness. So the problem lies not when we wish to store fuzzy items in a relational DBMS but when we wish to store spatial features in a relationalDBMS.Historically, most spatial databases have stored features in a relational format. Inthe relational database model, all data must be abstracted into two-dimensional tables.These tables consist of columns of attributes and rows (or tuples) of instances.There are several problems with the relational database model for storage of spatial entities. One chief problem is that these tables are deﬁned to be “sets of tuples”(Codd 1970). A mathematical setis deﬁned to be an unordered collection of objects.This is not a problem when dealing with zero-dimensional points in space. Whenworking with two-dimensional polygons or hulls, and even with one-dimensionallines, this does pose difﬁculties, as the ordering of the points comprising the boundaryof the object makes a deﬁnite difference in how the object may be represented (cf. Figures 5.1 and 5.2). So, to store spatial features in a relational DBMS we areviolating the basic deﬁnition of the relational model by insisting that the spatialattributes be stored in a particular order.THO_C05  19/03/2007  11:21  Page 83 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f84ASHLEY MORRISThere are ways to do this, as most GIS have relational databases as their storagemechanism. However, this is one of the reasons why several authors have suggestedthat the object-oriented data model might be the best available technique to modelspatial data (Goodchild and Gopal 1990, Mackay, Band and Robinson 1991, George,Buckles, Petry, et al. 1992, Cross and Firat 2000).Fuzzy spatial OODBMSMorris (2003) describes a framework that combines a geographic data model withan object-oriented data model that supports imprecision and uncertainty. In thisframework, we are able to incorporate all of the beneﬁts of the object-oriented para-digm into our geographic data framework. This framework is more appropriatefor spatial data (Robinson and Sani 1993) as it incorporates fuzziness into boththe storage and representation of the spatial features themselves (Burrough 1996,Couclelis 1996, Usery 1996, Morris and Petry 1998).One of the key elements of this framework is that coverages and/or layers canbe stored and represented as a setof spatial objects, or features (Morris, Foster,and Petry 1999). This set may be either crisp or fuzzy. By being able to representa coverage or geographic layer in the object-oriented model as a set we gain theuse of all of the normal set operations. Thus, we can use the notion of a set whenperforming spatial queries or operations. Spatial queries on spatial coverages, as per-formed by a GIS, are typically akin to set operations on those coverages, and behaveas queries on layers or collections (from an OO perspective). Fuzzy queries can alsobe supported with this framework.Another advantage of the object-oriented framework is that, internally to thedatabase, the points that comprise a feature may be stored in order. As mentionedbefore, the relational model does not allow for ordering, as points would be storedas a set, which by deﬁnition is unordered. In the OO world, we can store thesepoints using any of the collection types supported by the OODBMS (Cattell andBarry 2000). Since we have these collection types, it is trivial to store the points ina polygon in a particular order, and it is trivial for the rendering engine to connectthese points. So there is much less overhead (and conﬂict with the model) in theOODB model for spatial objects than in the relational database model.Fig. 5.1Case in which the points are stored inthe database and connected in order from thelast point back to the ﬁrst pointFig. 5.2Case in which the segments betweenthe points are connected in no particular order2154321543THO_C05  19/03/2007  11:21  Page 84 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fUNCERTAINTY IN SPATIAL DATABASES85The Open GIS Consortium (OGC; http://www.opengis.org), while not explicitlyspecifying an OODB format for spatial data, provides a connectivity layer within anobject-oriented framework. This will allow users to share existing data sets, regard-less of format. The framework of the OGC model is very abstract in its modeling.That is, it makes many demands upon the implementer to manage things such asmultiple and partial inheritance.Multiple inheritance may also introduce uncertainty into object behavior. Theremay be a conﬂict in methods when an object inherits from two or more classes.",
    "chunk_order_index": 56,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-30e0a6453529ce0449ff42ff0c7698e4": {
    "tokens": 1200,
    "content": "specifying an OODB format for spatial data, provides a connectivity layer within anobject-oriented framework. This will allow users to share existing data sets, regard-less of format. The framework of the OGC model is very abstract in its modeling.That is, it makes many demands upon the implementer to manage things such asmultiple and partial inheritance.Multiple inheritance may also introduce uncertainty into object behavior. Theremay be a conﬂict in methods when an object inherits from two or more classes. In the fuzzy world, there are a few different ways to manage this. Since an objecthas a degree of membership in a class, it is possible to simply let the class with the higher membership “win,” and the inheritance will be dependent upon the membership value of the direct parent class. In practice, GIS modelers usually takea very hands on approach to the implementation of a particular application, andthey will intervene and decide which parent class would be more dominant (Morris2003).The OGC framework allows for multiple representations of the same spatial object.First, a feature may be stored in the database as a single object, with several rep-resentations of its spatial characteristics. This would allow, for example, the querymechanism to pick the single most appropriate spatial representation of the onesstored for an object. For example, we may have three representations of a feature:one a raster representation at 1:10,000, one a vector representation at 1:24,000,and the third a raster representation at 1:5,000. If we were performing an overlayquery with a layer that consisted of vector objects at 1:15,000, our query mechan-ism would probably choose the 1:24,000 vector representation to use in the query.The GIS modeler could, of course, a prioridetermine which representation wouldbe the preferred one. The desired representation could also be derived based uponprevious user selection (Robinson 2000).When performing queries on an object-oriented spatial database, we can gener-alize all collections to the set (Morris, Foster, and Petry 1999). This gives us manyadvantages. First, since a spatial coverage is by deﬁnition a (fuzzy) set (Morris andPetry 1998), when a spatial operation is performed on a collection the order of pro-cessing of the elements in the collection is irrelevant, as spatial queries and spatialoperations are associative. While the order of processing individual elements of aset may have a drastic effect on performance, it will not affect the ﬁnal result. Anotheradvantage is that this generalization means we can use any set operation on anyspatial data collection, including coverages and layers.Classes, layers, and membershipThe framework described in Morris and Jankowski (2000) and Morris (2003) examines how object collections can be combined in a spatial database so that typ-ical GIS notions and queries are supported and maintained. In practice, the layersused by the GIS often, but not always, correspond to the classes in the underlyingobject database. This is because the layers are usually organized to represent a theme.Although layers often roughly correspond to classes in an OO model, they are byno means constrained to do so.THO_C05  19/03/2007  11:21  Page 85 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f86ASHLEY MORRISTo formulate the membership of an object oj in a class, we must consider the relevance and ranges of the attribute values of the object. With this in mind, the membership of object ojin class Cwith attributesAttr (C)is deﬁned as:µC(oj) =g[f(RLV(ai,C), INC(rngc(ai)/oj(ai)))]where RLV(ai,C) indicates the relevanceof the attribute aito the concept C, INC(rngc(ai)/oj(ai))denotes the degree of inclusionof the attribute values of ojin the formal range of aiin class C, frepresents the function of aggregation over the nattributes in the class, and greﬂects the nature of the semantic link existingbetween an object and a class (or between a subclass and its superclass). The valueof (RLV(ai,C) may be supplied by the user, or may be calculated by the system,for example, using the weighting method described in (Robinson 2000).Degree of membershipUsing our mountain example, here are some class deﬁnitions from our schema:CLASS: MountainPROPERTIES: elevationavg_snowfallavg_alpine_tempnamelocation (feature_attribute)scale (feature_attribute)END;CLASS: Skiable_mountainINHERIT: MountainPROPERTIES: trails ->(count(Trails)where mtn = mountain.name)lifts -> (count(Lifts)where mtn = mountain.nameand operational_ﬂag=TRUE)snowmaking_capacitylongest_run -> (max(Trails.length)where mtn = mountain.name)verticalEND;CLASS: TrailPROPERTIES: namelocation (feature_attribute)difﬁcultylengthEND;For the Skiable_mountainclass (abbreviated SM), let us assume the following typicalattribute ranges:THO_C05  19/03/2007  11:21  Page 86 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com",
    "chunk_order_index": 57,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-89fdc7ecaf1227a8e9af90ef070397b9": {
    "tokens": 1200,
    "content": "_attribute)difﬁcultylengthEND;For the Skiable_mountainclass (abbreviated SM), let us assume the following typicalattribute ranges:THO_C05  19/03/2007  11:21  Page 86 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fUNCERTAINTY IN SPATIAL DATABASES87Skiable_mountain attributes:rngsm(elevation) = {medium_short, average, medium_tall}rngsm(avg_snowfall)= {>4 meters}rngsm(avg_alpine_temp)= {slightly_above_freezing,freezing, slightly_below_freezing,below_freezing}rngsm(name)= {X}rngsm(location)= {Y}rngsm(trails)= {a_few, many, a_lot}rngsm(lifts)= {a_few, many, a_lot}rngsm(snowmaking_capacity)= {none, limited, moderate, extensive}rngsm(longest_run) = {fairly_short, average, fairly_long,long, very_long}rngsm(vertical) = {>500m}Note that name, location, and scale are not used in determining class membership.Calculating membershipNow we can compute the membership of an object in the Skiable_mountainclass.First, assume the following relevance rules for membership:RLV(elevation, SM)= 0.25RLV(avg_snowfall, SM)= 0.75RLV(avg_alpine_temp, SM)= 0.75RLV(lifts, SM)= 0.9RLV(trails, SM)= 0.85RLV(snowmaking_capacity, SM)= 0.95RLV(longest_run, SM)= 0.8RLV(vertical, SM)= 0.5Note that the relevance of lifts and snowmaking capacity are extremely high. If amountain has snow and has at least one ski lift, the chances are it meets the criteriafor a skiable mountain.Here is an example with Blackcomb mountain in Whistler, Canada:o(elevation)={2284m (average)}o(avg_snowfall)={9.14m}o(name)={Blackcomb}o(avg_alpine_temp)={-10C (below_freezing)o(location)={L}o(trails)={>100 (a_lot)}o(lifts)={17 (a_lot)}o(snowmaking_capacity)={215 hectares (extensive)}o(longest_run)={11km (very_long)}o(vertical)={1609m}Given these values, and using the maxfunction for g, we compute the followingmembership value for Blackcombin the class Skiable_mountain:THO_C05  19/03/2007  11:21  Page 87 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f88ASHLEY MORRISµC(oj) = g[f(RLV(ai,C), INC(rngc(ai)/oj(ai)))] =µSM(Blackcomb) =g[f(RLV(ai, Skiable_mountains), INC(rngc(ai)/Blackcomb(ai)))] =µSM(Blackcomb) =max(0.25 * elevation, 0.75 * avg_snowfall, 0.75 *avg_alpine_temp, 0.9 * lifts, 0.85 * trails, 0.95 *snowmaking_capacity, 0.8 * longest_run, 0.5 * vertical) =µSM(Blackcomb) =max(0.25*1.0, 0.75*1.0, 0.75*1.0, 0.9*1.0, 0.85*1.0, 0.95*1.0,0.8*1.0, 0.5*1.0)=µSM(Blackcomb) =max(0.25, 0.75, 0.75, 0.9, 0.85, 0.95, 0.8, 0.5) =0.95Thus one can see that Blackcomb has an extremely high degree of membership (0.95)in the class of skiable mountains, which one would expect.Modeling within Couclelis’s Taxonomy of Object Boundary UncertaintyAs a basic approach for managing uncertainty in spatial databases, we will lookat Helen Couclelis’s taxonomy of features with ill-deﬁned boundaries (Couclelis 1996), and for each dimensional attribute, we will provide ways for which it maybe modeled and stored in a spatial database.Dimension 1: the empirical nature of the entityThis attempts to distinguish what the nature of the entity is, and whether it lendsitself to being well or poorly bounded.Atomic or plenumHere, we are simply determining if we will store spatial entitiesas distinct atomic features, or as a plenum ﬁeld. If the objects are atomic, their spatialcontent can be stored as a spatial attribute of the object. If we are managing ﬁelds,then we have to parse the region into some form of grid, and each pixel must havea membership value [0.0,",
    "chunk_order_index": 58,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9951ca4bc53ba9a808e2d28fb89965e4": {
    "tokens": 1200,
    "content": "the entity is, and whether it lendsitself to being well or poorly bounded.Atomic or plenumHere, we are simply determining if we will store spatial entitiesas distinct atomic features, or as a plenum ﬁeld. If the objects are atomic, their spatialcontent can be stored as a spatial attribute of the object. If we are managing ﬁelds,then we have to parse the region into some form of grid, and each pixel must havea membership value [0.0, 1.0] in all types of features (classes in the OO sense) beingstored.Homogeneous or inhomogeneousThis is managed by providing fuzzy member-ship values for the class. If we are dealing solely with homogeneous features, thenwe simply have membership values of 1.0 or 0.0; inhomogeneous features have amembership value somewhere between these points.Discontinuous or continuousThe management here is somewhat dependent uponwhether the features are atomic or plenum. If plenum, then membership values are assigned at the pixel level, and the resulting presentation to the user should be evidence of continuity. If atomic, by providing for multiple alpha cuts in thespatial representation of an object, continuity can be stored and represented in aintuitive way.Connected or distributedThis can be managed via the object membership valuein the connectedclass or collection.THO_C05  19/03/2007  11:21  Page 88 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fUNCERTAINTY IN SPATIAL DATABASES89Solid or ﬂuidModeling ﬂuid objects is extremely difﬁcult. The best approaches todate are ones that deﬁne coreand boundaryfor the limits of the ﬂuid geometry,or an approach that deﬁnes multiple boundaries through temporal modeling.Two or three-dimensionalThree-dimensional objects may be modeled as easily astwo-dimensional objects using the fuzzy spatial object framework. When managingdifﬁcult cases (the canopy levels of trees), fuzzy boundaries may be used.Actual or non-actualMost object-oriented spatial databases support the conceptof versioning, where an object may have different numbers of attributes, relation-ships, and methods, as well as different values for the attributes, at different pointsin time. Versioning is a nice way to model non-actual objects.Permanent or variable; ﬁxed or movingAll of these object types may be modeledusing versioning.Conventional or self-deﬁningThe notion of membership can be used to modelthis as well.Dimension 2: The mode of observationObjects may appear to be well or ill bounded, despite their actual nature. Typically,our mode of observation is more important in determining whether the objects shouldbe modeled as well or poorly bounded.Scale, Resolution, and PerspectiveIdeally, we want to store features at the ﬁnestlevel of granularity possible. It will then be the responsibility of the representationtools to either display the ﬁnest detail, or the smallest features, so that collectionsappear to be atomic. In addition, it will be up to the representation tools to managethe viewshed and perspective.TimeIf modeled at all, this may be done by versioning, or another accepted wayto model temporality.ErrorAs mentioned previously, this must be generalized to uncertainty and modeledvia fuzziness.TheoryAlthough fuzzy spatial object databases may model atomic or plenum objects,they must still have some concept of boundary, even though the objects may haveno core, holes, or an endless boundary. Storing objects using a geostatistical approachwill require the representation tools to display the concept of implied or unimpliedboundary.Dimension 3: The user purposeOften, even though we may know whether or not a feature has a crisp or uncertainboundary, and even though our mode of observation may lend itself to well-deﬁnedor ill-deﬁned boundaries, it is immaterial to how we use the system.It is our opinion that the user purpose should be more clearly deﬁned by the GISmodeler, and thus it is up to the representation software to display features as well,bounded or not.THO_C05  19/03/2007  11:21  Page 89 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f90ASHLEY MORRISQueries on Spatial DatabasesRegardless of the mechanism used to store features in a spatial database, the queriesposed against that data may involve uncertainty to varying degrees (see Chapter 6of this volume by Brown and Heuvelink for a more detailed treatment of this topic).Let us consider the query “Display all skiable mountains within 10 km of an airport.” There are three terms or phrases in this query that may lead to uncertaintyor imprecision: skiable mountains, airport, and within 10 kilometers. First, the thematic layer, which contains skiable mountains, may consist solely of crisp data.However, if one is an Olympic athlete, then the deﬁnition of skiable will differ fromthe norm. Second, the concept of “airport” may be uncertain as well. One may belooking for a dirt strip, where a tiny two-passenger plane could land, as opposed toa multi-runway tarmac designed for commercial jetliners. A third way uncertaintymay exist within this query would be the fuzz",
    "chunk_order_index": 59,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7318a058d57207ddb3da040fcf65d82a": {
    "tokens": 1200,
    "content": ", which contains skiable mountains, may consist solely of crisp data.However, if one is an Olympic athlete, then the deﬁnition of skiable will differ fromthe norm. Second, the concept of “airport” may be uncertain as well. One may belooking for a dirt strip, where a tiny two-passenger plane could land, as opposed toa multi-runway tarmac designed for commercial jetliners. A third way uncertaintymay exist within this query would be the fuzziness in the semantics. In a crisplymodeled world, if one is 10.001 kilometers from an airport, then thatairport wouldnot satisfy the query. Even though one may ask for skiable mountains within 10 kmof an airport, one may wish to know all skiable mountains within walking distance,driving distance, or some other distance depending upon the circumstances. It wouldbe simple for the GIS to display circles around the airports with 10 km radii, but theperson posing the query may want to know the mountains within 10 km by road,which is a very different query indeed. What people say is not necessarily what theymean. Ideally, a query system should be robust enough to give the decision-makersmore information to help them in their process.A more classic example of a fuzzy querywould be to actually include one or morefuzzy terms. An example of this would be: “Display all skiable mountains nearanairport.” This query contains the term “near,” which could return a solution setwith a degree of membership of 1 for every mountain less than nine kilometers froman airport, and a degree of membership of 0 for every mountain more than 20 kmfrom an airport. Every mountain between nine and 20 km from an airport wouldhave a variable degree of membership.There are GIS products, namely IDRISI (Jiang and Eastman 2000) that supportfuzzy operations on data. Unfortunately, IDRISI does not consider how to storeobjects with ill-deﬁned boundaries. If we simply allow for fuzziness in the algorithmsbut not the underlying spatial database (Morris, Petry, and Cobb 1998, Morris,Foster, and Petry 1999), the representation may provide for alterations in visualiza-tion quanta, but it will still be represented as discrete data sets.Representing Query ResultsNow that we have stored the uncertain features in our database, how can we rep-resent this uncertainty to the user? Many ways have been proposed. Ehlschlaegerand Goodchild (1997) propose that we can represent positional uncertainty by eitherblurring features, or making them shake in an animation. Morris (2003) proposedprogressive shading, either using a continuous gradient or by using crisp boundariesof fuzzy alpha-cuts. There have been experiments with active interfaces (Morris andJankowski 2000) and even with sound (Goodchild 1998).THO_C05  19/03/2007  11:21  Page 90 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fUNCERTAINTY IN SPATIAL DATABASES91The problem with any method of representing uncertainty is that it is typicallycounter-intuitive to the user. The user expects the actual physical road to followthe map he or she is holding of the road. The user may even expect there to becrisp red lines denoting state boundaries and the desert to be beige, because thatis the color the map shows it to be.Whenever we want to introduce this uncertainty to the user, to let that user knowthat this boundary is not necessarily completely precise, then we need to do this insuch a way that the user understandsthat this is not necessarily a crisp measure-ment. The trials of Morris and Jankowski (2000) allowed the user to choose, oreven toggle modes from crisp, to uncertain with crisp alpha-cuts, to uncertain withcontinuous alpha-cuts. These results were much better received than the static pre-sentation, although this did require some education of the users.Obviously, while this will give added ﬂexibility to the user and modeler, it willalso allow the manipulation and distortion of data. For a few details on this, referto Mark Monmonier’s (1996) book entitled How to Lie with Maps.CONCLUSIONSIt is evident to the reader that we feel that the only proper way that uncertainty canbe modeled in spatial databases is through the use of fuzzy object-oriented databases.They can provide membership functions to aid in the storage and representationof objects with uncertain boundaries, and they inherit all of the advantages of theobject-oriented paradigm. By abstracting to the feature, we are able to store andrepresent both vector- and raster-based objects. By using multiple alpha-cuts, weare providing an extensible system that may support objects with either crisp orill-deﬁned boundaries at any level of desired detail.As users are becoming more sophisticated, the storage, manipulation, and rep-resentation of objects with uncertain boundaries is going to become increasinglyimportant, and the fuzzy spatial object framework is available to support it.REFERENCESBuckles, B. and Petry, F. 1982. A fuzzy representation of data for relational databases.International Journal of Fuzzy Sets and Systems7: 213–26.Burrough, P. A. 1996. Natural objects with indeterminate boundaries. In P. A. Burroughand A. Frank (eds)Geographic Objects with Indeterminate Boundaries.London: Taylor andFrancis: 3–28.B",
    "chunk_order_index": 60,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e8adb278edb0ea632b6f8f9298be1e54": {
    "tokens": 1200,
    "content": "is available to support it.REFERENCESBuckles, B. and Petry, F. 1982. A fuzzy representation of data for relational databases.International Journal of Fuzzy Sets and Systems7: 213–26.Burrough, P. A. 1996. Natural objects with indeterminate boundaries. In P. A. Burroughand A. Frank (eds)Geographic Objects with Indeterminate Boundaries.London: Taylor andFrancis: 3–28.Burrough, P. A. and Couclelis, H. 1996. Practical consequences of distinguishing crisp geographic objects. In P. A. Burrough and A. Frank (eds)Geographic Objects withIndeterminate Boundaries. London: Taylor and Francis, pp. 335–7.Campari, I. 1996. Uncertain boundaries in urban space. In P. Burrough, and A. Frank, (eds)Geographic Objects with Indeterminate Boundaries. London: Taylor and Francis,pp. 57–70.Cattell, R. G. G. and Barry, D. K. (eds). 2000. The Object Data Standard: ODMG 3.0. SanFrancisco, CA: Morgan Kaufman.Cheng, T., Molenaar, M., and Lin, H. 2001. Formalization and application of fuzzy objects.International Journal of Geographical Information Science15: 27–42.THO_C05  19/03/2007  11:21  Page 91 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f92ASHLEY MORRISCodd, E. F. 1970. A relational model of data for large shared data banks. Communicationsof the ACM13: 377–87.Couclelis, H. 1996. Towards an operational typology of geographic entities with ill-deﬁnedboundaries. In P. A. Burrough and A. Frank (eds).Geographic Objects with Indeter-minate Boundaries. London: Taylor and Francis: 45–56.Cross, V. and Firat, A. 2000. Fuzzy objects for geographical information systems. Fuzzy Setsand Systems113: 19–36.Ehlschlaeger, C. and Goodchild, M. 1994. Uncertainty in spatial data: Deﬁning, visualizing,and managing data errors. In Proceedings of GIS/LIS’94. Bethesda, MD: American Congressof Surveying and Mapping, pp. 246–53.Fisher, P. 1996. Boolean and fuzzy regions. In P. A. Burrough and A. Frank (eds)GeographicObjects with Indeterminate Boundaries. London: Taylor and Francis, pp. 87–94.Foody, G. M. and Atkinson, P. M. 2002. Uncertainty in remote sensing and GIS: Funda-mentals. In G. M. Foody and P. M. Atkinson (eds) Uncertainty in Remote Sensing andGIS. New York: John Wiley and Sons, pp. 1–18.Gale, S. 1972. Inexactness, fuzzy sets, and the foundations of behavioral geography.Geographical Analysis4: 337–49.George, R., Buckles, B., Petry, F., and Yazici, A. 1992. Uncertainty modeling in object-orientedgeographical information systems. In Min Tjoa, A. and Ramos, I. (eds) Database and ExpertSystems Applications: Proceedings of the Thirteenth International Conference in Valencia,Spain, 1992. Vienna: Springer-Verlag, pp. 294–299.Goodchild, M. F. 1998. Uncertainty: The achilles heel of GIS? Geo Info Systems8(11): 50–2.Goodchild, M. F. and Gopal, S. (eds). 1990. The Accuracy of Spatial Databases. Basingstoke:Taylor and Francis.Hunter, G. J. 1998. Managing uncertainty in GIS. WWW document, http://www.ncgia.ucsb.edu/giscc/units/u187/u187_f.html.Jiang, H. and Eastman, J. R. 2000. Application of fuzzy measures in multi-criteria evalu-ation in GIS. International Journal of Geographical Information Science 14: 173–84.Klir, G. J. and Folger, T. A. 1988 Fuzzy Sets, Uncertainty, and Information.EnglewoodCliffs, NJ: Prentice-Hall: 246–54.Leung, J. Y. 1979. Locational choice: A fuzzy set approach. Geography Bulletin15: 28–34.Mackay, D. S., Band, L. E., and Robinson, V. B. 1991. An object-oriented system for the organ-ization and representation of terrain knowledge for forested ecosystem. In ProceedingsofGIS/LIS’91. Bethesda, MD: American Congress of Surveying and Mapping, pp. 617–26.Monmonier, M. 1996. How to Lie with Maps(2nd edn). Chicago, University of Chicago Press.Morris, A., 2003. A framework for modeling uncertainty in spatial databases. Transactionsin GIS7: 83–101.Morris, A. and Jankowski, P. 2000. Combining fuzzy",
    "chunk_order_index": 61,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ecf8e318fd9c6599e381004aa575af3d": {
    "tokens": 1200,
    "content": "In ProceedingsofGIS/LIS’91. Bethesda, MD: American Congress of Surveying and Mapping, pp. 617–26.Monmonier, M. 1996. How to Lie with Maps(2nd edn). Chicago, University of Chicago Press.Morris, A., 2003. A framework for modeling uncertainty in spatial databases. Transactionsin GIS7: 83–101.Morris, A. and Jankowski, P. 2000. Combining fuzzy sets and databases in multiple criteria spatial decision making. In H. Larsen, J. Kacprzyk, S. Zadrozny, T. Andreasen,H. Christiansen (eds) Flexible Query Answering Systems: Recent Advances. Dordrecht:Kluwer, pp. 103–16.Morris, A. and Petry, F. E. 1998. Design of fuzzy querying in object-oriented spatial dataand geographic information systems. In Proceedings of Seventeenth International Con-ference of the North American Fuzzy Information Processing Society. Pistacaway, NJ: Instituteof Electrical and Electronic Engineers, pp. 165–9.Morris, A., Foster, J., and Petry, F. E. 1999. Providing support for multiple collection typesin a fuzzy object-oriented spatial data model. In Proceedings of the Eighteenth InternationalConference of the North American Fuzzy Information Processing Society. Pistacaway, NJ:Institute of Electrical and Electronic Engineers, pp. 824–8.Morris, A., Petry, F. E., and Cobb, M. 1998. Incorporating spatial data into the fuzzy object-oriented data model. In Proceedings of Seventh International Conference on InformationTHO_C05  19/03/2007  11:21  Page 92 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fUNCERTAINTY IN SPATIAL DATABASES93Processing and Management of Uncertainty in Knowledge Based Systems. Paris: EditionsEDK: 604–11.Petry, F., Cobb, M., and Morris, A. 1999. Fuzzy set approaches to model uncertainty inspatial data and geographic information systems. In, L. Zadeh and J. Kacprzyk (eds)Computing with Words in Information/Intelligent Systems2. Heidelberg: Physica-Verlag,pp. 345–67.Robinson, V. B. 2000. Individual and multi-personal fuzzy spatial relations acquired usinghuman–machine interaction. International Journal of Fuzzy Sets and Systems113:133–45.Robinson, V. B. 2003. A perspective on the fundamentals of fuzzy sets and their use in geo-graphic information systems. Transactions in GIS7: 3–30.Robinson, V. B. and Sani, A. P. 1993. Modeling geographic information resources for airport technical data management using the Information Resources Dictionary System (IRDS) standard. Computers, Environment, and Urban Systems17: 111–27.Usery, E. L. 1996. A conceptual framework and fuzzy set implementation for geographicfeatures. In P. A. Burrough and A. Frank (eds)Geographic Objects with IndeterminateBoundaries. London: Taylor and Francis, pp. 71–86.Zhang, J. and Goodchild, M. F. 2002. Uncertainty in Geographical Information. London:Taylor and Francis.THO_C05  19/03/2007  11:21  Page 93 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 6On the Identiﬁcation of Uncertaintiesin Spatial Data and TheirQuantiﬁcation with ProbabilityDistribution FunctionsJames D. Brown and Gerald B. M. HeuvelinkCentral to understanding and managing social and environmental systems is theneed to consider spatial patterns and processes. Spatial data are routinely used todescribe, predict, and explain a diverse range of geographical features, includingsoils, population density, water availability, the spread of disease, and ecologicaldiversity (Fotheringham, Charlton, and Brusden 2000). They are also used routinelyin Geographical Information Systems (GIS) to manage social and environmental features (Burrough and McDonnell 1998).Spatial data are rarely certain or “error free.” Rather, in abstracting and sim-plifying “real” patterns and processes, spatial data contain inherent errors that are insigniﬁcant at some spatial scales and for some applications but signiﬁcant forothers (see Chapter 5 by Morris in this volume). Often, decisions are based uponmultiple types and sources of data where approximation errors will combine andpropagate through spatial models, such as GIS operations (Heuvelink 1998). Thismay lead to poor decisions about the exploitation and management of social andenvironmental systems (Harremoës, Gee, MacGarvin, et al. 2002). Understandingthe limits and limitations of spatial data is, therefore, essential both for managingsocial and environmental systems effectively and for encouraging the responsibleuse of spatial data where knowledge is limited and priorities are varied (Hunterand Lowell 2002, Mowrer and Congalton 2002, Coucle",
    "chunk_order_index": 62,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0a9672ca42ddaed6e5a38e41584fc4d5": {
    "tokens": 1200,
    "content": "1998). Thismay lead to poor decisions about the exploitation and management of social andenvironmental systems (Harremoës, Gee, MacGarvin, et al. 2002). Understandingthe limits and limitations of spatial data is, therefore, essential both for managingsocial and environmental systems effectively and for encouraging the responsibleuse of spatial data where knowledge is limited and priorities are varied (Hunterand Lowell 2002, Mowrer and Congalton 2002, Couclelis 2003, Foody andAtkinson 2003).While it is generally accepted that spatial data are rarely (if ever) “error free,”these errors may be difﬁcult to quantify in practice. Indeed, the quantiﬁcation oferror (deﬁned here as a “departure from reality”) implies that the “true” nature of the environment or society is known. Yet absolute accuracy is neither achievablenor desirable in scientiﬁc research because resources are always limited and mustbe used efﬁciently. Rather, in the absence of such conﬁdence, we are uncertain aboutTHO_C06  20/03/2007  14:53  Page 94 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fON THE IDENTIFICATION OF UNCERTAINTIES IN SPATIAL DATA95the “true” character of the environment and about the errors in our representa-tions of it. However, it may be possible to constrain these errors with a stochasticmodel of reality (Ripley 1981), and to explore the impacts of uncertainty on decision-making through an uncertainty propagation analysis (Heuvelink 1998). The formercorresponds to an assessment of data quality where uncertainties are described (forexample, numerically), while the latter corresponds to an analysis of “ﬁtness for use”(Veregin 1999, De Bruin and Bregt 2001) where the impacts of uncertainty areexplored in the context of a speciﬁc application.This chapter focuses on the identiﬁcation of uncertainties in spatial data (that is, the assessment of spatial data quality), including the uncertainties associated with attribute and positional information. Particular emphasis is placed upon thequantiﬁcation of uncertainties in spatial attributes with probability distribution functions (pdfs). It does not describe the techniques for propagating uncertaintiesthrough GIS operations, for which reviews can be found elsewhere (for instance,Heuvelink 1999). The discussion is separated into four sections, namely: (1) an over-view of data quality and measures of data quality; (2) the sources of uncertainty inspatial data; (3) the development of uncertainty models for attribute and positionalinformation; and (4) a discussion of some major research challenges for improvingthe reliability andaccessibility of data quality models. In terms of the latter, it isargued that forward planning of data quality targets, including uncertainty analysesas well as conventional quality control (error reduction) procedures, will becomeincreasingly important in the future.Developing Measures of Spatial Data QualityUncertainties about spatial data may refer to a lack of conﬁdence about the qualityof a data set, or about its utility for a particular application (its “ﬁtness for use”).Uncertainty is an expression of conﬁdence about what we know, both as individualsand communities of scientists, and is, therefore, subjective (Brown 2004). Probabilitymodels are a common approach to describing uncertainties in spatial data. Differentpeople can reach different conclusions about how probable something is based ontheir own personal experiences and world-view, as well as the amount and qualityof information available to them (Cooke 1991, Heuvelink and Bierkens 1992, Fisher, Comber, and Wadsworth 2002). Indeed, it is widely accepted that stable or“objective” probabilities cannot be achieved when studying complex, variable, andpoorly sampled environmental systems, as evidenced by the widespread applicationof Bayes’ theorem to problems of scientiﬁc uncertainty in recent years (Beven andFreer 2001, Greenland 2001).While data quality is subjective, the standards used to assess and report uncer-tainty may be precisely deﬁned (USBB 1947, FGDC 1998, Burkholder 2002). Thesestandards may refer to the statistical accuracy and precision of data, their numericalprecision, lineage, logical consistency, currency, and “completeness,” among others(Chrisman 1991, Guptill and Morrison 1995). In contrast, the utility or ﬁtness foruse of data cannot be reported with ﬁxed standards, because ﬁtness for use is case-dependent. For example, an average error of ±1 m in a Digital Elevation Model(DEM) will be more important for predicting coastal ﬂooding in ﬂat terrain thanTHO_C06  20/03/2007  14:53  Page 95 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f96JAMES D. BROWN AND GERALD B. M. HEUVELINKfor planning an optimal route through mountainous terrain. In principle,",
    "chunk_order_index": 63,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4ed173ad5d7c077d4222d6a5808d1d51": {
    "tokens": 1200,
    "content": "onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f96JAMES D. BROWN AND GERALD B. M. HEUVELINKfor planning an optimal route through mountainous terrain. In principle, there-fore, the ﬁtness for use of a data set is conceptually different from its empiricalquality. In practice, however, the distinction between data quality and utility maybe blurred, both conceptually and operationally. First, if estimates of uncertaintyare sensitive to the experiences and judgments of people, the empirical quality ofa data set will be partly embedded in the speciﬁc applications that led to those experiences. Second, estimates of ﬁtness for use may be relevant for particular classes of application, such as “coastal ﬂood modeling,” if not individual applica-tions, such as ﬂooding on the east coast of England. Consequently, they might bestored in spatial databases alongside estimates of empirical quality. In this con-text, databases might be adapted to allow sampling of larger data sets in order toprovide some insight into the ﬁtness for use of data before they are applied in detail(De Bruin and Bregt 2001).If our deﬁnitions of geographic entities, such as “buildings,” “electoral wards,”and “rivers” are widely accepted (that is, “objective”), uncertainties in data may bereduced to expressions of empirical quality or some proxy for empirical quality, suchas trust in the source of information or the methods used to obtain it. In contrast,when our deﬁnitions of geographic entities are unclear, or our understandings ofreality are varied, assessments on the value of spatial data cannot refer to measuresof empirical quality alone. Rather, the failure to distinguish between empirical qual-ity and quality of concepts (for example, clarity of entities) will lead to conﬂictingobservations about what is “real,” where geographic variability is wrongly inter-preted as observational error (Richards, Brooks, Clifford, Harris, and Lane 1997).These conceptual uncertainties cannot be integrated fully with measures of empir-ical quality because our constructs of reality may be valued by their adequacy fora particular application rather than any inherent “truth” value. For example, polit-ical boundaries may be derived from concepts of “nation states” that only applyduring peacetime, and the distinction between a “mountain” and its surroundingsmay be useful in some situations but not in others.Finally, states of information on data quality should be reﬂected in the modes ofanalyzing and communicating uncertainty, as well as the magnitude of uncertaintyitself. For example, pdfsimply that all outcomes of an uncertain event are knownand that each of their associated probabilities is quantiﬁable. If probabilities cannotbe deﬁned numerically, an arbitrary pdf will imply a spurious notion of precisionabout data quality. When the parameters of a pdf cannot be estimated reliably, a spectrum of less precise measures is available for describing uncertainty (Ayyub2001). These include bounds (for example, binary classiﬁcations as certain/unknown)through rough sets or ternary classiﬁcation (possible/doubtful/unknown), multipleoutcomes ranked in order of likelihood, continuous classiﬁcations (that is, proportionalmembership of a “knowledge vector”), “histograms” where outcomes are coarselygraded in numerical frequency, or detailed qualitative information (for example,the pedigree matrices of Funtowicz and Ravetz 1990). Alternatively, scenarios maybe preferred if some or all possible outcomes of an uncertain event are known buttheir individual probabilities cannot be estimated reliably, either in numbers or innarrative (von Reibnitz 1988). The remainder of this chapter focuses on quantitativeestimates of probability, as pdfsare the most common measure of uncertainty inspatial data.THO_C06  20/03/2007  14:53  Page 96 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fON THE IDENTIFICATION OF UNCERTAINTIES IN SPATIAL DATA97What are the Key Sources of Uncertainty in Spatial Data?Sources of uncertainty in spatial dataSocial and environmental data are collected within discrete space-time boundariesand are sampled at discrete intervals of space and time within these boundaries. Theobjects of interest might include people, rivers, houses, mountains, lakes or forests,and their attributes might include “economic wealth,” “terrain,” “pH,” “votingintentions,” “ecological diversity,” or any other geographic entity derived from aclassiﬁcation of reality. The boundaries may be deﬁned by transitions in physicalproperties, such as mass, energy, and momentum, or in metaphysical properties (so-called ﬁat objects), such as political borders, or by a combination of the two.Within these boundaries, individual samples record the aggregate properties of oneor many social or physical variables. The samples are collected with instrumentsthat display ﬁnite sensitivities to the properties of interest and may not sample these properties directly, but rather infer them from known relationships with other,more easily measurable, properties. Following measurement, the patterns and pro-cesses inferred from a sample are implicitly historical. These inferences will ofteninvolve predictions about values at unmeasured points (",
    "chunk_order_index": 64,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f8be8e39bd5a756f964acd56b42fd1ed": {
    "tokens": 1200,
    "content": "combination of the two.Within these boundaries, individual samples record the aggregate properties of oneor many social or physical variables. The samples are collected with instrumentsthat display ﬁnite sensitivities to the properties of interest and may not sample these properties directly, but rather infer them from known relationships with other,more easily measurable, properties. Following measurement, the patterns and pro-cesses inferred from a sample are implicitly historical. These inferences will ofteninvolve predictions about values at unmeasured points (for example, that a measure-ment is valid beyond the instant it is captured), for which uncertainties are no longerbounded by an observation of the system but rely upon interpolation or extrapola-tion in space or time. Finally, multiple sources of error and uncertainty are introducedduring the registration and transformation of spatial data into digital products thatcan be used in GIS, including feature extraction and digitization, ﬁltering, vector-to-raster conversion and line simpliﬁcation.In practice, these sources of uncertainty are too numerous, and their interactionstoo complex, to consider in a formal uncertainty analysis (a source of ignorance),and many do not contribute to the quantiﬁable probability that a value is “correct.”Thus, expert judgments are always required to make an assessment of data qualityin general, as well as their suitability for making speciﬁc decisions (ﬁtness for use).Notwithstanding conceptual uncertainties, a discussion of the major sources of uncer-tainty in spatial data can usefully be separated into: (1) measurement, sampling, andinterpolation; (2) classiﬁcation (aggregation or dissaggregation of attribute values);and (3) scale and changes between scale (aggregation or dissaggregation in spaceor time).Measurement, sampling, and interpolationSpatial data are often derived from measurements in the ﬁeld, which introducesmeasurement uncertainty. Measurement uncertainty originates from a lack of con-ﬁdence about a local realizationof the measured variable. It may originate fromimperfect knowledge about the accuracy of an instrument, its ability to reconstructthe variable of interest (for example, river discharge from stage measurements), or the control volume for which it is representative (for instance, quantization oflight by a remote sensing instrument). While social and environmental parametersvary more or less continuously through space and time, measurements almost always occupy a limited number of space-time points. When exhaustive inputs areTHO_C06  20/03/2007  14:53  Page 97 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f98JAMES D. BROWN AND GERALD B. M. HEUVELINKrequired but only partial observations are available they must be interpolated, whichleads to interpolation uncertainty (Goovaerts 1997). Uncertainties in sampling andinterpolation originate from a lack of conﬁdence about a distributed realizationofthe measured variable. Interpolation uncertainty depends on the sample density, themagnitude and nature of spatial (and temporal) variation in the sampled attribute,and the interpolation algorithm employed. Measurement uncertainties can be estim-ated through comparisons with more accurate data, laboratory testing of measurementinstruments, or repeat measurement with the same instrument. While the formerprovides an indication of accuracy or “bias,” the latter two approaches only indicateprecision.In order to interpolate spatial data and to assess the uncertainties associated with spatial interpolation some assumptions must be made about the behavior ofthe measured variables at unmeasured locations. A common approach to samplingspatial “ﬁelds,” such as soil type or land use, involves separating the ﬁeld site intohomogeneous units, sampling these units and calculating a within-unit sample meanand variance (uncertainty). In practice, however, it may not be possible to separatea spatial domain into homogeneous units, but to assume instead that environmentalconditions vary continuously in space and time. Geostatistics can be used to inter-polate continuous data from partial measurements and to estimate the uncertaintiesassociated with spatial interpolation (Goovaerts 1997).ClassiﬁcationClassiﬁcation leads to uncertainty when our observations of reality cannot be assignedto discrete classes, either because the classes are poorly deﬁned, there are too fewclasses to capture all of the information available, or there is insufﬁcient informationto classify some values (Foody 2002, Stehman and Czaplewski 2003). If the un-certainties associated with classifying entities are to be explored effectively, the entities revealed through classiﬁcation must be clearly deﬁned and hence “real” ratherthan “effective” quantities (see below). However, they do not need to be distinct incharacter, or precisely deﬁned, because many aspects of reality are indistinct, depend-ing upon the space-time scales at which they are observed (Foody 1999). If reality isarbitrarily diffuse, precise deﬁnitions may be unhelpful, but deﬁnitions of geographicentities can also be insufﬁciently precise. Hence, the quality of a classiﬁcation isnot implicit in its precision but in its clarity of meaning, as well as its informationcontent(class “everything” has perfect accuracy) and empirical accuracy(all valuesassigned to the correct classes). In this context, too normative an emphasis on thestatistical agreement between remote sensing data and ﬁeld observations, or on the variance resulting from a geostatistical interpolation, may direct attention awayfrom the epistemic value of the classes themselves. Regardless of the precision withwhich entities are deﬁned, the scope for confusion about the meaning of geographicentities should be made clear otherwise estimates",
    "chunk_order_index": 65,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-c5bd2ecc11e76fd93b62559faa9f9c1c": {
    "tokens": 1200,
    "content": "well as its informationcontent(class “everything” has perfect accuracy) and empirical accuracy(all valuesassigned to the correct classes). In this context, too normative an emphasis on thestatistical agreement between remote sensing data and ﬁeld observations, or on the variance resulting from a geostatistical interpolation, may direct attention awayfrom the epistemic value of the classes themselves. Regardless of the precision withwhich entities are deﬁned, the scope for confusion about the meaning of geographicentities should be made clear otherwise estimates of uncertainty will be misleading.Scale and changes between scaleAn important consequence of the need for “closure” in geographic research (Lane2001) is that data and models provide inherently discrete representations of THO_C06  20/03/2007  14:53  Page 98 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fON THE IDENTIFICATION OF UNCERTAINTIES IN SPATIAL DATA99continuous patterns and processes. In particular, they rely upon the speciﬁcation ofdominant patterns and process controls and their discretization over limited areas andwith ﬁnite control volumes. The need to represent social or environmental systemsat one or a combination of scales may lead to uncertainty, because the dominantpatterns and processes are not known at all scales or cannot be incorporated practic-ally in models, and the control volumes used to represent them may be ﬁxed at otherscales (Hennings 2002).When spatial data are deﬁned with a different “support” from that required fora given application, these data must be aggregatedor disaggregatedto an appro-priate support (Heuvelink and Pebesma 1999, Bierkens, et al. 2000). Aggregation ordisaggregation of data is commonly referred to as the “change of support problem”(Journel and Huijbregts 1978), the “modiﬁable areal unit problem” (Cressie 1993)or the “scale problem” (Burt and Barber 1996). In aggregating spatial data it isassumed that the geometry of the control volume can be rescaled without deformingthe original data (that is, perfect tessellation) otherwise a “positional” or geometricuncertainty is introduced (Veregin 2000). If the input data are uncertain, these un-certainties will propagate through the rescaling model to the model output, that is, the rescaled quantity.In practice, space-time aggregation should lead to a reduction in uncertainty andto an increase in spatial autocorrelation, because much of the variability at ﬁnerscales is lost and, thus, disappears as a source of uncertainty and spatial divergence(Cressie 1993). Disaggregation of spatial data necessarily leads to uncertaintyabout the precise value of a given variable at a speciﬁc location, because its valueis only partially constrained by available information. Speciﬁcally, it is constrainedby the attribute value at an aggregated level (for example, the block support).Assessments of uncertainty in disaggregated data may be highly subjective, becausethe spatial variation of the attribute is rarely known at the disaggregated level. Incontrast to aggregation, space-time dissaggregation will lead to an increase in uncer-tainty and a reduction in spatial autocorrelation because the attribute variability isincreased at ﬁner scales.Quantifying Attribute and Positional UncertaintiesUncertainties about spatial data quality may refer to the space-time domain of a geographic entity, including its absolute and relative position and geometry (positional uncertainty), or to an attribute of that entity (attribute uncertainty). While assessments of uncertainty in spatial data have traditionally focused on attribute uncertainties (Journel and Huijbregts 1978, Goovaerts 1997; see the following section “Attributes and uncertainties”), studies of positional uncertaintyhave become increasingly common in recent years (and, following it, the sectionentitled “Positional uncertainties of geographic objects”). These include studies ofpositional uncertainties in vector data (Stanislawski, Dewitt, and Shrestha 1996,Kiiveri 1997, Leung and Yan 1998, Shi 1998) and combinations of positional andattribute uncertainties in raster data (Arbia, Grifﬁth, and Haining 1998). For geo-graphic “objects,” such as trees, uncertainties in attribute information (for example,tree species) may be separated from uncertainties in positional information (forTHO_C06  20/03/2007  14:53  Page 99 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f100JAMES D. BROWN AND GERALD B. M. HEUVELINKinstance, tree location). In contrast, for geographic ﬁelds, such as terrain elevationor land cover, attribute uncertainties interact with positional uncertainties wherepositional uncertainties may increase attribute uncertainties (Gabrosek and Cressie2002).Attribute uncertaintiesUncertainties about the precise value of an attribute at a particular point in spaceand time may be quantiﬁed with a marginal pdf(mpdf) for that attribute. For acontinuous numerical attribute Z, such as “tree height,” “rainfall,” or “annualincome,” the mpdfis described with the continuous function",
    "chunk_order_index": 66,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-12d3bea6b33072d8fe1c4a6a1a061db3": {
    "tokens": 1200,
    "content": "as terrain elevationor land cover, attribute uncertainties interact with positional uncertainties wherepositional uncertainties may increase attribute uncertainties (Gabrosek and Cressie2002).Attribute uncertaintiesUncertainties about the precise value of an attribute at a particular point in spaceand time may be quantiﬁed with a marginal pdf(mpdf) for that attribute. For acontinuous numerical attribute Z, such as “tree height,” “rainfall,” or “annualincome,” the mpdfis described with the continuous function:F(z)=Prob(Z ≤z)−∞<z <∞(6.1)For a discrete numerical attribute, such as population size, or a categorical attri-bute, such as land cover, the mpdfis described with a discrete function for thatattribute (C):P(c) =Prob(C =c)c ∈S(6.2)where Srepresents the set of all possible outcomes for C(e.g. S={urban, arable,forest, water,...} for land cover). For pragmatic or theoretical reasons, Fand Pmight be described with an idealized shape function and a parameter set whosevalues modify that shape for a particular data set. For continuous functions, the mpdfmay follow a “Gaussian,” “uniform,” “exponential,” “lognormal,” or“gamma” distribution, and for discrete functions it may follow a “uniform,”“binomial,” or “Poisson” distribution (among others). The shape function and para-meter set may be derived from expert judgment, or ﬁtted to a sample of differencesbetween more and less accurate data, or modeled from sample data (for example,Kriging). In other cases, Zor Ccannot be modeled with an idealized shape func-tion (for example, if the ﬁtting criteria are not met). Here the mpdfmay be describedwith an arbitrary “non-parametric” shape providing it satisﬁes the basic axioms ofprobability theory.Uncertainties about the precise value of two or more attributes occupying thesame space-time point may be quantiﬁed with a jointpdf(jpdf). For example, the number of road trafﬁc accidents at a motorway junction may depend on thevolume of trafﬁc passing through that junction. In this case, they must be describedwith a jpdfbecause one variable is “statistically dependent” on the other variable.While numerous shape functions are available for the mpdfs in Equations (6.1) and(6.2), few simple models are available for the statistically-dependent jpdf. For con-tinuous numerical variables, a common assumption is that the variables follow ajoint Gaussian distribution, which may be justiﬁed by the Central Limit Theorem.Furthermore, the multi-Gaussian distribution is mathematically simple and requiresonly a vector of means and a covariance matrix for complete speciﬁcation.Statistical dependence may also occur in space and time, both within and betweenvariables, for which a jpdfmust also be deﬁned. Spatial dependence is common inTHO_C06  20/03/2007  14:53  Page 100 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fON THE IDENTIFICATION OF UNCERTAINTIES IN SPATIAL DATA101“ﬁeld” attributes, such as elevation, rainfall, and land cover, but may also occurin the attributes of spatial “objects,” such as tree heights. In modeling the spatialdependence of geographic ﬁelds, a common assumption is that the attribute valuesfollow a joint Gaussian distribution and that the correlations or covariances betweenpairs of locations depend only on their separation distance (Journel and Huijbregts1978, Goovaerts 1997). Given these assumptions, Webster and Oliver (1992)found that the jpdffor geographic ﬁelds can be estimated with approximately 80–200 observations. These assumptions may be relaxed if additional observations or auxiliary data are available to improve the model.For a discrete numerical or categorical variable it is less straightforward to modelthe statistical dependencies between attribute values at different locations. For exam-ple, mnprobabilities must be speciﬁed for a categorical variable with m possibleoutcomes at n locations (for m =8 and n =6 this yields more than 250,000 prob-abilities). In practice, there are few idealized shape functions to model these probabilities and few generally applicable methods for reducing the complexity ofthe discrete jpdf.In assessing the accuracy of a discrete numerical or categorical variable, an erroror “confusion” matrix may be constructed from a sample of more accurate dataand assumed valid for a wider population. This approach originates from theclassiﬁcation of land cover with remote sensing imagery (Stehman and Czaplewski2003, Steele, Patterson, and Redmond 2003). The confusion matrix stores the errorsof omission and commission in a contingency table format (Story and Congalton1986), which allows speciﬁc accuracy statistics to be derived for a particular applica-tion. Since the confusion matrix is ideally derived from a probabilistic survey design,where each space point has an equal chance of being sampled, it can be used to determine the classiﬁcation uncertainty of individual points. However, spatialdependence between uncertainties is not included in the confusion matrix, yet spatial dependence may profoundly affect the propagation of uncertainties throughGIS operations (Heuvelink 1998).One approach to modeling statistical dependence in discrete numerical and categorical variables is indicator geostatistics (Goovaerts 1997, Finke, Wladis,Kros,",
    "chunk_order_index": 67,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7e89bfc6a474000e7fcda27f9b65326c": {
    "tokens": 1200,
    "content": ",where each space point has an equal chance of being sampled, it can be used to determine the classiﬁcation uncertainty of individual points. However, spatialdependence between uncertainties is not included in the confusion matrix, yet spatial dependence may profoundly affect the propagation of uncertainties throughGIS operations (Heuvelink 1998).One approach to modeling statistical dependence in discrete numerical and categorical variables is indicator geostatistics (Goovaerts 1997, Finke, Wladis,Kros, Pebesma, and Reinds 1999, Kyriakidis and Dungan 2001). For example, Finke,Wladis, Kros, Pebesma, and Reinds. (1999) used indicator variograms and cross-variograms to quantify uncertainty in categorical soil maps and land cover maps,and used indicator simulation to generate spatially correlated realizations of thesemaps for use in an uncertainty propagation analysis. However, indicator geostatisticsis inexact (Cressie 1993), and requires a large number of indicator (cross-)variogramsto be sampled and modeled, which may be impossible in practice. Other tech-niques for estimating the jpdfof geographic ﬁelds, such as land cover or bird counts,include conditional probability networks (Kiiveri and Cacetta 1998), BayesianMaximum Entropy (Christakos 2000) and Markov Random Fields (Norberg,Rosén, Baran, and Baran 2002). The attributes of spatial objects, such as tree heights, may be treated as “marked point processes” (Diggle 2003, Diggle, Ribeiro,and Christensen 2003, Schlather, Ribeiro, and Diggle 2004) where the spatial positions (points) as well as the attribute values (marks) are modeled as randomprocesses.THO_C06  20/03/2007  14:53  Page 101 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f102JAMES D. BROWN AND GERALD B. M. HEUVELINKPositional uncertainties of geographic objectsAttempts to deﬁne positional uncertainties in geographic objects have included partial and full applications of probability theory to vector data where lines or polygons are distorted with an autocorrelated “shock” (Kiiveri 1997), or positionaluncertainties are expressed in a conﬁdence region for the end nodes of a line segment(Dutton 1992, Shi 1998). The latter includes an “epsilon (ε) band” approach (Perkal1966) where the marginal pdfsfor each node are connected ex post, which resultsin a ﬁxed buffer of radius εaround each line segment, and a non-uniform “errorband” model where the end nodes are connected probabilistically through a jpdf(Dutton 1992, Shi 1998, Shi and Lui 2000). Models for positional uncertainty alsoinclude non-probabilistic approaches where rectangular buffers are used to createa “conﬁdence space” for lines and polygons (Goodchild and Hunter 1997).Uncertainties about the absolute position or geometry of spatial vectors, such as pointsand polygons, may lead to uncertainties about the topological relationships betweenvectors, such as the position of points within polygons (Winter 2000, Shortridge andGoodchild 2002). These uncertainties may be described analytically (Shortridge and Goodchild 2002), or quantiﬁed through an uncertainty propagation analysis.The joint Gaussian distribution is typically assumed in probability models of posi-tional uncertainty (Kiiveri 1997, Leung and Yan 1998, Shi 1994, 1998; Shi and Lui2000). Here, the uncertainties between locations may be statistically dependent inspace for which Shi (1998) and Shi and Lui (2000) introduce the “error-band” and“G-band” models respectively. These models were derived for straight-line segments,but may be extended to other vector shapes and to curved lines (Tong, Shi, andLui 2003). However, a more fundamental problem arises in the estimation of prob-ability models for curved lines where clear points for computing differences betweenmore and less accurate data do not exist (van Niel and McVicar 2002).More generally, quantitative probability models (Shi and Lui 2000) may be difﬁcultto estimate if information on positional uncertainty is limited to simple measuresof accuracy for whole line segments, rather than two or more points. Furthermore,the joint Gaussian assumption cannot easily be extended to complex featureswhere pre-processing and scale transformations affect some line segments more thanothers (Goodchild and Hunter 1997). In these cases, simple measures of positionaluncertainty, such as non-probabilistic buffers, might be preferred. These measuresmay be derived from comparisons between more and less accurate data (Goodchildand Hunter 1997, Tveite and Langaas 1999) or internal data geometry (Veregin2000). They may be extended to probabilistic measures once sufﬁcient data are available and the joint Gaussian assumption can be justiﬁed. However, they willultimately differ from point-based descriptions of positional uncertainty, such asthe “G-band” model of Shi and Lui (2000), because points and buffers are con-ceptually different (van Niel and McVicar 2002).Some Challenges for Estimating Spatial Data QualityUnderstanding the limitations of spatial data is essential both for managing socialand environmental systems effectively",
    "chunk_order_index": 68,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-5bf49ed3999f4ffb6480097c62e7433b": {
    "tokens": 1200,
    "content": "probabilistic measures once sufﬁcient data are available and the joint Gaussian assumption can be justiﬁed. However, they willultimately differ from point-based descriptions of positional uncertainty, such asthe “G-band” model of Shi and Lui (2000), because points and buffers are con-ceptually different (van Niel and McVicar 2002).Some Challenges for Estimating Spatial Data QualityUnderstanding the limitations of spatial data is essential both for managing socialand environmental systems effectively and for encouraging the responsible use ofTHO_C06  20/03/2007  14:53  Page 102 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fON THE IDENTIFICATION OF UNCERTAINTIES IN SPATIAL DATA103scientiﬁc research where knowledge is limited and priorities are varied. In this context,critical self-reﬂection about the uncertainties in spatial data must be encouraged along-side attempts to improve data by reducing error. In practice, however, there are manyongoing challenges for the successful application of uncertainty methodologies tospatial data (Brown 2004). This is evidenced by the rapid rate of progress in storingand retrieving “deterministic data” in GIS versus storing and retrieving informationabout data quality, and the uncertainties associated with spatial data.While not entirely, or even primarily, a technical challenge, some important technical challenges remain in assessing spatial data quality (Heuvelink 2002). Forexample, the identiﬁcation of statistical dependence between uncertain attributes,both in space and between multiple data sets, remains an important technical challenge for applying probability models to spatial data. First, the propagation of uncertainties through GIS operations, such as “spatial overlay,” “buffering” and“map algebra,” may be highly sensitive to spatial dependencies in the input data(Arbia, Grifﬁth, and Haining 1998, Heuvelink 1998). In addition, environmentalmodels typically rely upon multiple spatial inputs, including both “primary” data(for example, terrain elevation) and data derived from other inputs to the samemodel (for example, terrain slope), for which spatial dependencies become import-ant. Second, statistical dependencies are more difﬁcult to estimate than an averagemagnitude of uncertainty (such as a Root Mean Squared Error), and sensitivity test-ing with a range of possible dependence structures might be preferred in some cases.Third, measurement uncertainties may contain their own space-time dependencies,which are separate from, but complicated by, the real patterns of variation in themeasured variable. For example, errors in ﬂow measurements may increase withstream discharge, while current meters may be consistently misused or misinterpreted.However, measurement uncertainties can be obtained from some instruments, suchas GPS receivers (temporal correlation of the GPS precision), and remote sensingsatellites (Arbia, Grifﬁth, and Haining 1998) and can sometimes be estimated fromthe data themselves (for instance, through signal processing).In developing new techniques for assessing uncertainties in spatial data, futureresearch might focus on the identiﬁcation of quality metrics for groups of objectsrather than individual objects, and the interactions between uncertainties in multipleobjects and their attributes. It might also focus on the joint modeling of attributeand positional uncertainties, and on the provision of quality metrics that allow ﬁtnessfor use to be established without an uncertainty propagation analysis (Mowrer andCongalton 2000, Hunter and Lowell 2002). However, the development of new tech-niques for assessing and representing uncertainties in spatial data must coincide with the development of new concepts for applying groups of techniques to speciﬁcproblems where multiple data sets, degrees, and sources of uncertainty converge.Here, there is a need for “stochastic information systems” that allow different metricsof uncertainty to be stored in spatial databases and propagated through GIS whileeducatingusers about the nature and impacts of uncertainty in spatial data (Brownand Heuvelink 2006). Thus, standardization and automation should be carefullymanaged in developing uncertainty models. Indeed, in estimating pdfs, the balancebetween model complexity, identiﬁability, and reliability should be a guided decisionby those responsible for assessing uncertainty, and not a predetermined “error button”devoid of speciﬁcity or educational value.THO_C06  20/03/2007  14:53  Page 103 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f104JAMES D. BROWN AND GERALD B. M. HEUVELINKThus, there is a need to provide a ﬂexible, rather than a uniformly simple, infra-structure for retrieving information about spatial data quality from GIS users, andfor organizing this information within a database design. In this context, the com-plexity of an uncertainty model could be linked to the risks and resources associatedwith decision-making, as well as the state of information on uncertainty. Alongsidea ﬂexible framework for assessing and representing uncertainties about spatial data,there is a need for guidelines (and examples) to manage this ﬂexibility in speciﬁc casesso that users with limited statistical expertise can develop an appropriate uncertaintymodel for many applications (obviously, there are",
    "chunk_order_index": 69,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-db002ea263e2f1934d72dddf5f8c4133": {
    "tokens": 1200,
    "content": ". In this context, the com-plexity of an uncertainty model could be linked to the risks and resources associatedwith decision-making, as well as the state of information on uncertainty. Alongsidea ﬂexible framework for assessing and representing uncertainties about spatial data,there is a need for guidelines (and examples) to manage this ﬂexibility in speciﬁc casesso that users with limited statistical expertise can develop an appropriate uncertaintymodel for many applications (obviously, there are limits here). For quantitative descriptions of uncertainty, this might be achieved by grouping and demonstratingthe impacts of speciﬁc statistical decisions to users.There are, however, some more fundamental challenges for the development andsuccessful application of uncertainty models to spatial data. These include the socialdesire for simplicity in applying GIS (from which the “error button” philosophyoriginates), the time and money required to implement uncertainty methodologies,and the problems of ignorance and indeterminacy in geographic research where,respectively, we do not and cannot know about some aspects of spatial variability(Handmer, Norton, and Dovers 2001, Couclelis 2003). Indeed, too normative anemphasis on quantifying and reducing uncertainty neglects the wider conceptualproblems of “representing reality”with spatial data (for example, reality is space andtime varying), and discourages contingency planning and “openness” more generally.Thus, uncertainty analyses should assist in targeting the causes of uncertainty inGIS, but their success will ultimately rest on the desirefor openness and commun-ication about potential errors in spatial data for which some social, institutional, andlegal changes, as well as clear evidence on the utility of uncertainty analyses, shouldfurther support the widespread application of uncertainty tools in GIS.REFERENCESArbia, G., Grifﬁth, D., and Haining, R. 1998. Error propagation modelling in raster GIS:Overlay operations. International Journal of Geographical Information Science 12: 145–67.Ayyub, B. M. 2001. Elicitation of Expert Opinions for Uncertainty and Risks. Boca Raton,FL: CRC Press.Beven, K. J. and Freer, J. 2001. Equiﬁnality, data assimilation, and uncertainty estimationin mechanistic modelling of complex environmental systems. Journal of Hydrology249:11–29.Bierkens, M. F. P., Finke, P. A., and De Willigen, P. 2000. Upscaling and Downscaling Methodsfor Environmental Research. Dordrecht: Kluwer.Brown, J. D. 2004. Knowledge, uncertainty and physical geography: Towards the develop-ment of methodologies for questioning belief. Transactions of the Institute of BritishGeographers 29: 367–81.Brown, J. D. and Heuvelink, G. B. M. 2006. The Data Uncertainty Engine (DUE): A soft-ware tool for assessing and simulating uncertain environmental variables. Computers andGeosciences32: in press.Burkholder, E. F. 2002. The global spatial data model. In M. F. Goodchild, and A. J. Kimerling(eds) Discrete Global Grids. Santa Barbara, CA: National Center for Geographic Informa-tion and Analysis (available at http://www.ncgia.ucsb.edu/globalgrids-book/spatialdata/).THO_C06  20/03/2007  14:53  Page 104 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fON THE IDENTIFICATION OF UNCERTAINTIES IN SPATIAL DATA105Burrough, P. A. and McDonnell, R. 1998. Principles of Geographical Information Systems.Oxford: Oxford University Press.Burt, J. E. and Barber, G. M. 1996. Elementary Statistics for Geographers. New York: GuilfordPress.Chrisman, N. R. 1991. The error component of spatial data. In D. J. Maguire, M. F. Goodchild,and D. W. Rhind (eds) Geographical Information Systems: Principles and Applications.London: Longman, pp. 164–74.Christakos, G. 2000. Modern Spatiotemporal Geostatistics. Oxford: Oxford University Press.Cooke, R. M. 1991. Experts in Uncertainty: Opinion and Subjective Probability in Science.Oxford: Oxford University Press.Couclelis, H. 2003. The certainty of uncertainty: GIS and the limits of geographic knowledge.Transactions in GIS7: 165–75.Cressie, N. A. C. 1993. Statistics for Spatial Data. New York: JohnWiley and Sons.De Bruin, S. and Bregt, A. 2001. Assessing ﬁtness for use: The expected value of spatial datasets. International Journal of Geographical Information Science15: 457–71.Diggle, P. J. 2003. Statistical Analysis of Spatial Point Patterns. Oxford: Oxford UniversityPress.Diggle, P. J., Ribeiro Jr, P. J., and Christensen, O. F. 2003. An introduction to model basedgeostatistics. In J. Möller (ed.)Spatial Statistics and Computational Methods. Berlin: SpringerLecture Notes in Statistics No. 173: 43–86.Dutton, G. 1992. Handling positional",
    "chunk_order_index": 70,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-1d32b7a5ac3ff9a026ba727e0b03ca46": {
    "tokens": 1200,
    "content": "iggle, P. J. 2003. Statistical Analysis of Spatial Point Patterns. Oxford: Oxford UniversityPress.Diggle, P. J., Ribeiro Jr, P. J., and Christensen, O. F. 2003. An introduction to model basedgeostatistics. In J. Möller (ed.)Spatial Statistics and Computational Methods. Berlin: SpringerLecture Notes in Statistics No. 173: 43–86.Dutton, G. 1992. Handling positional uncertainty in spatial databases. In Proceedings of the Fifth International Symposium on Spatial Data Handling,Charleston, SC, USA.International Geographical Union Commission on GIS, pp. 460–9.FGDC. 1998. Geospatial Positioning Accuracy Standards:Part 3, National Standard for SpatialData Accuracy.Washington, DC: Federal Geographic Data Committee.Finke, P. A., Wladis, D., Kros, J., Pebesma, E. J., and Reinds, G. J. 1999. Quantiﬁcationand simulation of errors in categorical data for uncertainty analysis of soil acidiﬁcationmodelling. Geoderma93: 177–94.Fisher, P. F., Comber, A. J., and Wadsworth, R. A. 2002. The production of uncertainty inspatial information: The case of land cover mapping. In G. Hunter and K. Lowell (eds)Accuracy 2002: Proceedings of the Fifth International Symposium on Spatial AccuracyAssessment in Natural Resources and Environmental Sciences. July 10–12, Melbourne,Australia. Melbourne, Australia: University of Australia, pp. 60–73.Foody, G. M. 1999. The continuum of classiﬁcation fuzziness in thematic mapping.Photogrammetric Engineering and Remote Sensing65: 443–51.Foody. G. M. 2002. Status of land-cover classiﬁcation accuracy assessment. Remote Sensingof Environment80: 185–201.Foody, G. M. and Atkinson, P. M. (eds). 2003. Uncertainty in Remote Sensing and GIS.London: John Wiley and Sons.Fotheringham, A. S., Charlton, M. E., and Brunsdon, C. 2000. Quantitative Geography:Perspectives on Spatial Data Analysis. London: Sage Publications.Funtowicz, S. O. and Ravetz, J. R. 1990. Uncertainty and Quality in Science for Policy.Dordrecht: Kluwer.Gabrosek, J. and Cressie, N. 2002. The effects on attribute prediction of location uncer-tainty in spatial data. Geographical Analysis34: 262–85.Goodchild, M. F. and Hunter, G. J. 1997. A simple positional accuracy measure for linearfeatures. International Journal of Geographical Information Science11: 299–306.Goovaerts, P. 1997. Geostatistics for Natural Resources Evaluation.New York: OxfordUniversity Press.Goovaerts, P. 2001. Geostatistical modeling of uncertainty in soil science. Geoderma103:3–26.THO_C06  20/03/2007  14:53  Page 105 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f106JAMES D. BROWN AND GERALD B. M. HEUVELINKGreenland, S. 2001. Sensitivity analysis, Monte Carlo risk analysis, and Bayesian uncertaintyassessment. Risk Analysis21: 579–83.Guptill, S. C. and Morrison, J. L. 1995. Elements of Spatial Data Quality. Oxford: Elsevier.Handmer, J. W., Norton, T. W., and Dovers, S. R. (eds). 2001. Ecology, Uncertainty andPolicy.Harlow: Prentice Hall.Harremoës, P., Gee, D., MacGarvin, M., Stirling, A., Keys, J., Wynne, B., and Guedes, V. S.(eds). 2002. The Precautionary Principle in the 20th Century: Late Lessons from EarlyWarnings. London: Earthscan.Hennings, V. 2002. Accuracy of coarse-scale land quality maps as a function of the upscalingprocedure used for soil data. Geoderma107: 177–96.Heuvelink, G. B. M. 1998. Error Propagation in Environmental Modelling with GIS. London:Taylor and Francis.Heuvelink, G. B. M. 1999. Propagation of error in spatial modelling with GIS. In P. A. Longley,M. F. Goodchild, D. J. Maguire, and D. W. Rhind (eds) Geographical Information Systems:Principles, Techniques, Applications, and Management. New York: John Wiley and Sons:207–17.Heuvelink, G. B. M. 2002. Analysing uncertainty propagation in GIS: Why is it not thatsimple? In G. M. Foody and P. M. Atkinson (eds) Uncertainty in Remote Sensing andGIS. Chichester: John Wiley and Sons, pp. 155–65.Heuvelink, G. B. M. and Bierkens, M. F. P. 1992. Combining soil maps with interpolations",
    "chunk_order_index": 71,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0c02a020d246741ff232d60d55cbbf5f": {
    "tokens": 1200,
    "content": "velink, G. B. M. 2002. Analysing uncertainty propagation in GIS: Why is it not thatsimple? In G. M. Foody and P. M. Atkinson (eds) Uncertainty in Remote Sensing andGIS. Chichester: John Wiley and Sons, pp. 155–65.Heuvelink, G. B. M. and Bierkens, M. F. P. 1992. Combining soil maps with interpolationsfrom point observations to predict quantitative soil properties. Geoderma55: 1–15.Heuvelink, G. B. M. and Pebesma, E. J. 1999. Spatial aggregation and soil process modelling.Geoderma 89: 47–65.Hunter, G. and Lowell, K. (eds). 2002. Proceedings of the Fifth International Symposium onSpatial Accuracy Assessment in Natural Resources and Environmental Sciences (Accuracy2002). Melbourne, Australia: Department of Geomatics, University of Melbourne.Journel, A. G. and Huijbregts, C. J. 1978. Mining Geostatistics. London: Academic Press.Kiiveri, H. T. 1997. Assessing, representing and transmitting positional uncertainty in maps.International Journal of Geographical Information Science 11: 33–52.Kiiveri, H. T. and Cacetta, P. 1998. Image fusion with conditional probability networks formonitoring the salinization of farmland. Digital Signal Processing8: 225–30.Kyriakidis, P. C. and Dungan, J. L. 2001. A geostatistical approach for mapping thematicclassiﬁcation accuracy and evaluating the impact of inaccurate spatial data on ecologicalmodel predictions. Ecological and Environmental Statistics8: 311–30.Lane, S. N. 2001. Constructive comments on D Massey “Space-time, ‘science’ and the relation-ship between physical geography and human geography.” Transactions of the Institute ofBritish Geographers26: 243–56.Leung, Y. and Yan, J. 1998. A locational error model for spatial features. International Journalof Geographical Information Science 12: 607–20.Mowrer, H. T. and Congalton, R. G. (eds). 2000. Quantifying Spatial Uncertainty in NaturalResources: Theory and Applications for GIS and Remote Sensing. Chelsea, MI: Ann ArborPress.Norberg, T., Rosén, L., Baran, Á., and Baran, S. 2002. On modeling discrete geological struc-tures as Markov random ﬁelds. Mathematical Geology34: 63–77.Perkal, J. 1966. On the Length of Empirical Curves. Ann Arbor, MI: Michigan Inter-UniversityCommunity of Mathematical Geographers Discussion Paper No. 10.Richards, K. S., Brooks, S. M., Clifford, N. J., Harris, T. R. M., and Lane, S. N. 1997. Realgeomorphology in physical geography: Theory, observation and testing. In D. R. Stoddard(ed.) Process and Form in Geomorphology. London: Routledge, pp. 269–92.Ripley, B. D. 1981. Spatial Statistics. New York: John Wiley and Sons.THO_C06  20/03/2007  14:53  Page 106 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fON THE IDENTIFICATION OF UNCERTAINTIES IN SPATIAL DATA107Schlather, M., Ribeiro, P., and Diggle, P. 2004. Detecting dependence between marks andlocations of marked point processes. Journal of the Royal Statistical Society, Series B66:79–93.Shi, W. Z. 1994. Modelling Positional and Thematic Uncertainty in Integration of GIS andRemote Sensing. Enschede, Netherlands: ITC Publication No. 22.Shi, W. Z. 1998. A generic statistical approach for modelling error of geometric features inGIS. International Journal of Geographical Information Science 12: 131–43.Shi, W. Z. and Liu, W. 2000. A stochastic process-based model for the positional error ofline segments in GIS. International Journal of Geographical Information Science14: 51–66.Shi, W. Z., Fisher, P. F., and Goodchild, M. F. 2002. Epilogue: A prospective on spatialdata quality. In W. Shi, P. F. Fisher, and M. F. Goodchild (eds) Spatial Data Quality.London: Taylor and Francis, pp. 304–9.Shortridge, A. M. and Goodchild, M. F. 2002. Geometric probability and GIS: Some applications for the statistics of intersections. International Journal of GeographicalInformation Science16: 227–43.Stanislawski, L. V., Dewitt, B. A., and Shrestha, R. L. 1996. Estimating positional accuracyof data layers within a GIS through error propagation. Photogrammetric Engineering andRemote Sensing 62: 429–33.Steele, B. M., Patterson, D. A., and Redmond, R. A. 2003.",
    "chunk_order_index": 72,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a79ce278e052a624dd33140414520f63": {
    "tokens": 1200,
    "content": ". International Journal of GeographicalInformation Science16: 227–43.Stanislawski, L. V., Dewitt, B. A., and Shrestha, R. L. 1996. Estimating positional accuracyof data layers within a GIS through error propagation. Photogrammetric Engineering andRemote Sensing 62: 429–33.Steele, B. M., Patterson, D. A., and Redmond, R. A. 2003. Toward estimation of map accuracy without a probability test sample. Environmental and Ecological Statistics10:333–56.Stehman, S. V. and Czaplewski, R. L. 2003. Introduction to special issue on map accuracyEnvironmental and Ecological Statistics10: 301–8.Story, M. and Congalton, R. G. 1986. Accuracy assessment: a user’s perspective. Photo-grammetric Engineering and Remote Sensing52: 397–9.Tong, X., Shi, W., and Liu, D. 2003. An error model of circular curve features in GIS. InProceedings of the Eleventh ACM International Symposium on Advances in GeographicInformation Systems,New Orleans, LA, USA. New York, NY: Association of ComputingMachinery, pp. 141–6.Tveite, H. and Langaas, S. 1999. An accuracy assessment method for geographical line datasets based on buffering. International Journal of Geographical Information Science13:27–47.USBB. 1947. United States National Map Accuracy Standards.Washington, DC: US Bureauof the Budget.van Niel, T. G. and McVicar, T. R. 2002. Experimental evaluation of positional accuracyestimates from a linear network using point- and line-based testing methods. InternationalJournal of Geographical Information Science16: 455–73.Veregin, H. 1996. Error propagation through the buffer operation for probability surfaces.Photogrammetric Engineering and Remote Sensing 62: 419–28.Veregin, H. 1999. Data quality parameters. In P. A. Longley, M. F. Goodchild, D. J. Maguire,and D. W. Rhind (eds)Geographical Information Systems: Volume 1, Principles andTechnical Issues. New York: John Wiley and Sons, pp. 177–89.Veregin, H. 2000. Quantifying positional error induced by line simpliﬁcation. InternationalJournal of Geographical Information Science14: 113 30.von Reibnitz, U. 1988. Scenario Techniques. Hamburg: McGraw-Hill.Webster, R. and Oliver, M. A. 1992. Sampling adequately to estimate variograms of soilproperties. Journal of Soil Science43: 177–92.Winter, S. 2000. Uncertain topological relations between imprecise regions. International Journalof Geographical Information Science14: 411–30.THO_C06  20/03/2007  14:53  Page 107 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPart IIDatabase Trends and ChallengesThe second section of the book explores some of the important and enduring databaseissues and trends. In Chapter 7, The ﬁrst chapter in this set, Shashi Shekhar and RangaRaju Vatsavai describe the relational, object-oriented, and object-relational databasemanagement systems (DBMSs) from both the Geographic Information Systems (GIS)and spatial data management systems points of view. The principal characteristicsof GIS and spatial database management systems are brieﬂy described and the link-ages between these systems and the aforementioned DBMSs are explored. The keyconcepts of each of these DBMSs are illustrated using simple examples drawn fromthe standard World database.The second chapter in this group, Chapter 8 by Michael F. Hutchinson, exam-ines the generation of regular grid digital elevation models from a variety of datasources to support the elevation and landscape shape requirements of environmentalmodeling over a range of spatial scales. Such models have played an integral role inGI Science since its inception and have directly stimulated new methods for obtainingdigital environmental data, new spatial interpolation methods, and new methodsfor analyzing landscape dependent hydrological and ecological processes. The latter,which are usually performed by various forms of thin plate smoothing splines andgeostatistics, demonstrate some of the subtleties and growing importance of multi-variate statistical analysis in GI Science.In Chapter 9, the third chapter in this bundle on database trends and challenges,May Yuan describes the importance of time in geographic inquiry and understandingand some of the conceptual advances that are needed to add time to GIS databases.Separate sections focus on key developments in spatio-temporal ontologies, repres-entation, and data modeling, and support for spatio-temporal queries. The chapterconcludes by summarizing the current state of temporal GIS and the prospects fordeveloping temporal GIS that can support spatio-temporal information management,query, analysis, and modeling in the immediate future.The ﬁnal chapter of Part II, Chapter 10 by Craig A. Knoblock and Cyrus Shahabi,describes some of their recent work on the extraction and integration of geospatialand related data that go beyond conversion between different products and standardTHO_C07  20/03/2007  14:58  Page 109 Downloaded from https://onlinelibrary.w",
    "chunk_order_index": 73,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-1b8f2e3a01711a05b94663a1a44fb44a": {
    "tokens": 1200,
    "content": "can support spatio-temporal information management,query, analysis, and modeling in the immediate future.The ﬁnal chapter of Part II, Chapter 10 by Craig A. Knoblock and Cyrus Shahabi,describes some of their recent work on the extraction and integration of geospatialand related data that go beyond conversion between different products and standardTHO_C07  20/03/2007  14:58  Page 109 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f110DATABASE TRENDS AND CHALLENGESformats for the interoperability of these products. New techniques are introduced toturn online web sources into semi-structured data that can, among other things, beintegrated with other geospatial data; automatically and accurately integrate vectordata with high-resolution color imagery; integrate online property tax sources andconﬂated road vector data to identify and annotate buildings on imagery; automatic-ally integrate maps with unknown coordinates and satellite imagery; and efﬁcientlycombine online schedules and vector data to predict the locations of moving objects.These examples, while not exhaustive, are used by the authors to illustrate newopportunities for integrating various geospatial and online data sources.THO_C07  20/03/2007  14:58  Page 110 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 7Object-Oriented DatabaseManagement SystemsShashi Shekhar and Ranga Raju VatsavaiWe are in the midst of an information revolution. The raw material (data) poweringthis controlled upheaval is not found below the Earth’s surface where it has takenmillion of years to form but is being gathered constantly via sensors and other data-gathering devices. For example, NASA’s Earth Observing System (EOS) generatesone terabyte of data every day.Satellite images are one prominent example of spatial data. Extracting informationfrom a satellite image requires that the data be processed with respect to a spatialframe of reference, possibly the Earth’s surface. But satellites are not the only sourceof spatial data, and the Earth’s surface is not the only frame of reference. A siliconchip can be, and often is, a frame of reference. In medical imaging the human bodyacts as a spatial frame of reference. In fact even a supermarket transaction is anexample of spatial data if, for example, a zip code is included. Queries, or commands,posed on spatial data are called spatial queries. So, while the query “What are the names of all bookstores with more than ten thousand titles?” is an example of a non-spatial query, “What are the names of all bookstores within ten miles of the Minneapolis downtown?” is an example of a spatial query.A database is a permanent repository of data which is stored in one or more ﬁles and managed by a database management system (DBMS). Databases and thesoftware which manages them are the silent success story of the information age.They have slowly permeated all aspects of daily living, and modern society wouldcome to a halt without them. A DBMS can be characterized by its underlying datamodel and the query language used for describing and accessing the data. From adatabase point of view, a data model is a collection of mathematically well-deﬁnedconcepts for data abstraction. It provides tools for high-level description of data-base schemas at the conceptual level and hides low-level details of how the data isstored. Traditional DBMSs are generally based on one of the classical data models– hierarchical, network, or relational. However, the focus of attention since the late1980s has been on relational database management systems (RDBMS), which havegained widespread popularity. More recent data models include object-oriented andobject-relational models. The historical evolution of database technology is shownin Figure 7.1.THO_C07  20/03/2007  14:58  Page 111 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f112SHASHI SHEKHAR AND RANGA RAJU VATSAVAIAssociated with each data model is a database language, which provides two types constructs: one for deﬁning database schemas, and the second for queryingand modifying the data in the database. The Structured Query Language (SQL) isthe lingua francaof the database world, and it is tightly coupled with the relationaldatabase model. SQL is a descriptive query language, that is, a user describes whatdata he or she wants from the database without specifying how to retrieve it. Onthe other hand, the Object Query Language (OQL) is tightly coupled with the object-oriented model.Despite their spectacular success, the prevalent view is that a majority of theRDBMSs in existence today are either incapable of managing spatial data or arenot user-friendly when doing so. Now, why is that? The traditional role of a RDBMShas been that of a simple but effective warehouse of business and accounting data.Information about employees, suppliers, customers, and",
    "chunk_order_index": 74,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a1302e35b32865eb53ae04f0c12db64e": {
    "tokens": 1200,
    "content": "retrieve it. Onthe other hand, the Object Query Language (OQL) is tightly coupled with the object-oriented model.Despite their spectacular success, the prevalent view is that a majority of theRDBMSs in existence today are either incapable of managing spatial data or arenot user-friendly when doing so. Now, why is that? The traditional role of a RDBMShas been that of a simple but effective warehouse of business and accounting data.Information about employees, suppliers, customers, and products can be safely storedand efﬁciently retrieved through a RDBMS. The set of likely queries is limited, andthe database is organized to answer these queries efﬁciently. From the business world, the RDBMS made a painless migration into government agencies and academicadministrations.Data residing in these mammoth databases is simple, consisting of numbers, names,addresses, product descriptions, etc. These DBMSs are very efﬁcient for the tasks forwhich they were designed. For example, a query like “List the top ten customers, inHierarchical DBMSNetwork DBMSObject-RelationalORDBMSRelational DBMSObject-OrientedSystems (OODBMS)File SystemsFig. 7.1Evolution of databasesAfter Khoshaﬁan and Baker 1998THO_C07  20/03/2007  14:58  Page 112 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS113terms of sales, in the year 1998” will be very efﬁciently answered by a DBMS evenif the database has to scan through a very large customer database. Such commandsare conventionally called “queries” although they are not questions. The DBMSwill not scan through all the customer records; it will use an index, to narrow downthe search. By contrast, a relatively simple query such as “List all the customers whoreside within 50 miles of the company headquarters” will confound the database. Toprocess this query, the DBMS will have to transform the company headquarters andcustomer addresses into a suitable reference system, possibly latitude and longitude,in which distances can be computed and compared. Then the DBMS will have toscan through the entire customer list, compute the distance between the companyand the customer, and, if this distance is less than 50 miles, save the customer’s name.It will not be able to use an index to narrow down the search, because traditionalindices are incapable of ordering multi-dimensional coordinate data. A simple andlegitimate business query can thus send a DBMS into a hopeless tailspin. The RDBMS,which are designed for business data processing, are capable of managing only simpledata types such as numeric, character, and date. They are not suitable to managecomplex data types that arise in various emerging application domains such asGeographic Information Systems (GIS), Multimedia, Computer Aided Design (CAD)and Computer Aided Manufacturing (CAM). Therefore, there is an immediate needfor databases tailored to handle spatial data and spatial queries, and other complexapplications.The object-oriented paradigm appears to be a natural choice for highly com-plex application domains such as spatial databases, because it provides a direct correspondence between real-world entities and programming (system) objects. Theobject-oriented database management systems (OODBMS), which combine object-oriented programming concepts and database management principles, have maturedconsiderably since their appearance in the early 1980s. However, the adoptabilityof OODBMS has been limited to certain niche markets like e-commerce, engineering,medicine and some complex applications. Recently, hybrid systems, known as object-relational database management systems (ORDBMS), have become popular. TheORDBMS combines the good features of RDBMS (simple data types and SQL) withthe good features of OODBMS (complex data types and methods).This chapter provides an overview of current OODBMS and ORDBMS technologiesfrom a spatial database management point of view. The next section describes therelationship between GIS and Spatial Database Management Systems, and showsthe limitations of RDBMS in handling spatial data.GIS and Spatial Data Management Systems (SDBMS)GIS are the principal technology motivating interest in SDBMS; they provide a con-venient mechanism for the analysis and visualization of geographic data. Geographicdata are spatial data whose underlying frame of reference is the Earth’s surface. TheGIS provide a rich set of analysis functions which allows a user to affect powerfultransformations on geographic data. The rich array of techniques which geographershave added to GIS is the reason behind their phenomenal growth and multidisciplin-ary applications. Table 7.1 lists a small sample of common GIS operations.THO_C07  20/03/2007  14:58  Page 113 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f114SHASHI SHEKHAR AND RANGA RAJU VATSAVAIA GIS provides a rich set of operations over a few objects and layers, whereasan SDBMS provides simpler operations on sets of objects and sets of layers. Forexample, a GIS can list neighboring countries of a given country (for example, France)given the political boundaries of all countries. However it will be fairly tedious",
    "chunk_order_index": 75,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a6c2ddad979452b8c61b74416726dc11": {
    "tokens": 1200,
    "content": "on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f114SHASHI SHEKHAR AND RANGA RAJU VATSAVAIA GIS provides a rich set of operations over a few objects and layers, whereasan SDBMS provides simpler operations on sets of objects and sets of layers. Forexample, a GIS can list neighboring countries of a given country (for example, France)given the political boundaries of all countries. However it will be fairly tedious toanswer set queries like list the countries with the highest number of neighboringcountriesor list countries which are completely surrounded by another country.Set-based queries can be answered efﬁciently in an SDBMS.SDBMSs are also designed to handle very large amounts of spatial data storedon secondary devices (for example, magnetic disks, CD-ROMs, jukeboxes, etc.) usingspecialized indices and query-processing techniques. Finally, SDBMSs inherit the traditional DBMS functionality of providing a concurrency-control mechanism toallow multiple users to simultaneously access shared spatial data, while preservingthe consistency of that data. A GIS can be built as the front-end of an SDBMS.Before a GIS can carry out any analysis of spatial data, it accesses that data froma SDBMS. Thus an efﬁcient SDBMS can greatly increase the efﬁciency and pro-ductivity of a GIS.A typical spatial database consists of several images and vector layers like landparcels, transportation, ecological regions, soils, etc. Let us now consider how census block data can be stored in a DBMS. One naturalway of storing informationabout the census blocks (for example, their name, geographic area, population andboundaries) is to create the following table in the database:createtable censusblocks (namestring,areaﬂoat,populationnumber,boundarypolyline);In a (relational) database, all objects, entities, and concepts which have a distinctidentity are represented as relations or tables. A relation is deﬁned by a name anda list of distinguishing attributes which characterize the relation. All instances of therelation are stored as tuples in the table. In the preceding code fragment we havecreated a table(relation) named census_block, which has four attributes: name, area,population, and boundary. At table creation time, the types of attributes have toTable 7.1List of common GIS analysis operations (after Albrecht 1998)SearchThematic search, search by region, (re-)classiﬁcationLocation analysisBuffer, corridor, drainage networkTerrain analysisSlope/aspect, catchments, drainage networkFlow analysisConnectivity, shortest pathDistributionChange detection, proximity, nearest neighborSpatial analysis/StatisticsPattern, centrality, autocorrelation, indices of similarity,topology: hole descriptionMeasurementsDistance, perimeter, shape, adjacency, directionTHO_C07  20/03/2007  14:58  Page 114 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS115be speciﬁed, and here they are: string, ﬂoat, number, and polyline. A polyline is adata type to represent a sequence of straight lines.Figure 7.2 shows a hypothetical census block and how information about it canbe stored in a table. Unfortunately, such a table is not natural for a traditional rela-tional database because polyline is not a built-in data type. One way to circumventthis problem is to create a collection of tables with overlapping attributes, as shownin Figure 7.3. Another way is to use a stored procedure. For a novice user theseimplementations are quite complex. The key point is that the census block datacannot be naturally mapped onto a relational database. We need more constructsto handle spatial information in order to reduce the semantic gap between the user’sy-ax(0, 1)(1, 1)D(0, 0)(1, 0)B105A12C43x-axisName340Area1.58Population1839BoundaryPoly((5,8),(2,10),...(18,12),(5,8))Fig. 7.2Census blocks with boundary ID:1050NameCensus_blocks340Area1.58Population1839Boundary-ID1050Boundary-IDPolygon1050105010501050Edge-nameABCDedge-nameEdgeAEndpoint1A2B2B3C3C3D4D1endpointPoint1234x-coor0011y-coor1001Fig. 7.3Four tables required in a relational database with overlapping attributes to accommodatethe polyline data typeTHO_C07  20/03/2007  14:58  Page 115 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f116SHASHI SHEKHAR AND RANGA RAJU VATSAVAIview of spatial data and the database implementation. Such facilities are offeredby the object-oriented software paradigm.The object-oriented software paradigm is based on the principles of user-deﬁneddata types, along with inheritance and polymorphism. The popularity of languageslike C++, Java, and Visual Basic is an indicator that object-oriented",
    "chunk_order_index": 76,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9de18c5b8bba84882dc47fec1474bced": {
    "tokens": 1200,
    "content": "conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f116SHASHI SHEKHAR AND RANGA RAJU VATSAVAIview of spatial data and the database implementation. Such facilities are offeredby the object-oriented software paradigm.The object-oriented software paradigm is based on the principles of user-deﬁneddata types, along with inheritance and polymorphism. The popularity of languageslike C++, Java, and Visual Basic is an indicator that object-oriented concepts areﬁrmly established in the software industry. It would seem that our land parcel prob-lem is a natural application of object-oriented design: Declare a class polyline andanother class land parcel with attribute address, which is a string type, and anotherattribute boundarywhich is of the type polyline. We do not even need an attributeareabecause we can deﬁne a method areain the polyline class which will computethe area of any land parcel on demand. So will that solve the problem? Are object-oriented databases (OODBMS) the answer? Well, not quite.The debate between relational versus object-oriented within the database com-munity parallels the debate between vector versus raster in GIS. The introductionof abstract data types (ADTs) clearly adds ﬂexibility to a DBMS, but there are twoconstraints peculiar to databases that need to be resolved before ADTs can be fullyintegrated into DBMSs.•Market adoption of OODBMS products has been limited, despite the availabil-ity of such products for several years. This reduces the ﬁnancial resources andengineering efforts to performance-tune OODBMS products. As a result, manyGIS users will use systems other than OODBMS to manage their spatial datain the near future.•SQL is the lingua francaof the database world, and it is tightly coupled with therelational database model. SQL is a declarative language, that is, the user onlyspeciﬁes the desired result rather than the means of production. For example, inSQL the query “Find all land parcels adjacent to MY_HOUSE.” should be ableto be speciﬁed as follows:SELECTM.addressFROMland parcel L, MWHEREAdjacent(L,M) AND L.address = ‘MYHOUSE’It is the responsibility of the DBMS to implement the operations speciﬁed in the query. In particular, the function Adjacent(L,M)should be callable from withinSQL. The current standard, SQL-92, supports user-deﬁned functions, and SQL-3,the next revision, will support ADTs and a host of data structures such as lists,sets, arrays, and bags. Relational databases which incorporate ADTs and other prin-ciples of object-oriented design are called object-relational database managementsystems (ORDBMS).The current generation of ORDBMSs offers a modular approach to ADTs. AnADT can be built into or deleted from the system without affecting the remainderof the system. While this “plug-in” approach opens up the DBMS for enhancedfunctionality, there is very little built-in support for the optimization of operations.Our focus will be to specialize an ORDBMS to meet the requirements of spatial data.By doing so, we can extrapolate spatial domain knowledge to improve the overallefﬁciency of the system. We are now ready to give a deﬁnition of SDBMS for settingthe scope of this chapter:THO_C07  20/03/2007  14:58  Page 116 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS1171A spatial database management system is a software module that can work withan underlying database management system, for example, ORDBMS, OODBMS;2SDBMSs support multiple spatial data models, commensurate spatial abstractdata types (ADTs), and a query language from which these ADTs are callable;3SDBMSs support spatial indexing, efﬁcient algorithms for spatial operations,and domain-speciﬁc rules for query optimization.Figure 7.4 shows a representation of an architecture to build an SDBMS on top of an ORDBMS. This is a three-layer architecture. The top layer (from left to right) is the spatial application, such as GIS, MMIS (multimedia informationsystem), or CAD (computer-aided design). This application layer does not interactdirectly with the ORDBMS but goes through a middle layer which we have labeled “spatial database.” The middle layer is where most of the available spatial domainknowledge is encapsulated, and this layer is “plugged” into the ORDBMS. Thislayered approach explains why commercial ORDBMS products have names likeSpatial Data Blade (Illustra), Spatial Data Cartridge (Oracle), and Spatial Data Engine(ESRI).Let us now summarize the core features that are essential for any DBMS:1Persistence:The ability to handle both transient and persistent data. While transient data is lost after a program terminates, persistent data not only transcends program invocations but also survives system and media crashes.Further, the DBMS ensures that a smooth recovery takes place after a crash.In database management systems, the state of the persistent object undergoesfrequent changes, and it is sometimes desirable to have access to the previousdata states.2Transactions:Transactions map a database from one consistent state to another.This mapping is atomic (that is, it is executed completely or aborted). Typically,many transactions are executed concurrently, and the DBMS imposes an orderof execution",
    "chunk_order_index": 77,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e163375430c68204fc6656b26111861f": {
    "tokens": 1200,
    "content": "but also survives system and media crashes.Further, the DBMS ensures that a smooth recovery takes place after a crash.In database management systems, the state of the persistent object undergoesfrequent changes, and it is sometimes desirable to have access to the previousdata states.2Transactions:Transactions map a database from one consistent state to another.This mapping is atomic (that is, it is executed completely or aborted). Typically,many transactions are executed concurrently, and the DBMS imposes an orderof execution that can be performed as a series. Consistency in a database isaccomplished through the use of integrity constraints. All database states mustsatisfy these constraints to be deemed consistent. Furthermore, to maintain thesecurity of the database, the scope of the transactions is dependent on the user’saccess privileges.Spatial databases can be characterized by a set of spatial data types and the operations permitted on those data types.Spatial data typesA key issue in the encoding of spatial information is the choice of a basic set ofspatial data types required to model common shapes on maps. Many proposals have been made over the years. A consensus is slowly emerging in terms of theOGIS standard (OGIS 1999). Figure 7.5 shows the fundamental building blocks of two-dimensional spatial geometry and their interrelationships in Uniﬁed ModelingLanguage (UML) notation. We will give a brief description of the UML notationin later sections. Let us now look more closely at these building blocks of spatialgeometry.THO_C07  20/03/2007  14:58  Page 117 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSpatial ApplicationGISMMISCADObject-RelationalDatabaseServersInterface to DBMSCoreSpatial DatabaseSpace TaxonomyAbstract Data TypesInterface to Spatial ApplicationSpatial Data Typesand OperationsSpatial QueryLanguagesAlgorithms for spatialoperations with costmodelsSpatial indexaccess methods(with concurrencycontrol)Bulk LoadingConcurrency ControlRecovery/BackupCost FunctionsSelectivity EvaluationViewsDerived DataIndex StructuresData ModelInterpretationDiscretizationScale/ResolutionConsistencyNetworksData VolumeVisualizationPointLinePolygonSpatial JoinxFig. 7.4Three-layer architectureTHO_C07  20/03/2007  14:58  Page 118 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS119The most general shape is represented by “Geometry” described via a “SpatialRepresentation System” which is a coordinate system like latitude/longitude or someother consensus framework. The “Geometry” is subdivided into four categories,namely Point, Curve, Surface, and GeometryCollection. Pointdescribes zero-dimensionalobjects, for example, the city centers in a map of the world. Curvedescribes theshapes of one-dimensional objects, for example, rivers in the map of a world. The Curveobjects are often approximated by a LineString, which is representedby two or more points. The simplest LineStringis a straight line joining two ormore Points. The category Surfacedescribes the shape of two-dimensional objects,for example, countries on a map of the world. A Surfaceis often modeled by aPolygon. GeometryCollectionrepresents complex shapes such as a collection of oil wells, a group of islands, etc. GeometryCollectionin turn is of three types, namelyMulti-Point, Multi-Curve, and Multi-Surface. The GeometryCollectionspatial datatypes provide a “closure” property to OGIS spatial data types under geometric operations such as “geometric-union,” “geometric-difference,” or “geometric-intersection.” For example, if one takes a geometric-difference of the boundariesof Canada and Quebec, the result is a Multi-Surfaceeven if Canada and Quebecwere of Surfacespatial data type. This property is useful to support multi-step querying and data processing.Operations on spatial objectsLet us now brieﬂy look at the typology of embedding space and associated relation-ships, and some of the common operations deﬁned on spatial objects.GeometrySpatial Reference SystemSurfaceCurvePointGeometryCollectionLineStringPolygonMulti-SurfaceMulti-CurveMulti-PointLineLinear RingMulti PolygonMulti LineStringFig. 7.5An OGIS proposal for building blocks of spatial geometry in UML notationAfter OGIS 1999THO_C07  20/03/2007  14:58  Page 119 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f120SHASHI SHEKHAR AND RANGA RAJU VATSAVAISet-orientedThe simplest and most general of all embedding spaces is called set-oriented space.Common relationships allowable in this setting are the usual set-based relationshipsof union, intersection, containment, and membership. Hierarchical relationships like acounty contained in a state, or a state contained in a country are adequately modeledby set theory.TopologicalFor an intuitive feeling of what a topological space is, imagine two polygons whichtouch (meet) each other and are drawn on a",
    "chunk_order_index": 78,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0f52193a1a65781a9e4de21a5cb15e45": {
    "tokens": 1200,
    "content": "RANGA RAJU VATSAVAISet-orientedThe simplest and most general of all embedding spaces is called set-oriented space.Common relationships allowable in this setting are the usual set-based relationshipsof union, intersection, containment, and membership. Hierarchical relationships like acounty contained in a state, or a state contained in a country are adequately modeledby set theory.TopologicalFor an intuitive feeling of what a topological space is, imagine two polygons whichtouch (meet) each other and are drawn on a rubber sheet. Now if we deform therubber sheet by stretching or bending it, but not cutting or folding it, the adjacencyof the polygons remains intact. Meetis an example of a topological property andthe study of transformations (deformations) which preserve topological propertiesis called topology. Consider a political map of the world that shows boundaries ofcountries. The neighboring countries meet each other, whether the map is drawnon a sphere or on a ﬂat space. The area of a polygon is clearly not a topologicalproperty. In fact, the relative areas of different countries are often not preservedin many maps. Areas of countries near the equator are reduced relative to the areasof countries near the poles in many planar maps. From a spatial/geographic data-base point of view, topological relationships like meet, within, and overlapare mostlikely to be queried by a user of a spatial database management system. Is a givenland parcel adjacent to a hazardous waste site? Does the river ﬂoodplain overlapa proposed highway network? All of these are examples of topological relation-ships. More detailed information on topological spaces can be found in Egenhofer(1991).DirectionalDirectional relationships can be of three types – namely, absolute, object-relative, orviewer based. Absolute directional relationships are deﬁned in the context of a globalreference system, for example, North, South, East, West, North-East, etc. Object-relative directions are deﬁned using the orientation of a given object. Example relationships include left, right, front, behind, above, below, etc. Viewer relativedirections are deﬁned with respect to a specially designated reference object, calledthe viewer.Metric spaceMathematically speaking, a set Xis called a metric space if for any pair of points xand yof X, there is an associated real number d(x,y), called the distance (also calleda metric) from xto y, with the following properties:1d(x,y) ≥0 and d(x,x) =02d(x,y) =d(y,x)3d(x,y) ≤d(x,z) +d(z,y)for all x,y,zin X. Any function that satisﬁes these properties is called a metric on X.THO_C07  20/03/2007  14:58  Page 120 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS121In metric spaces the notion of distance is well deﬁned. A distance function canbe used to induce a topology on the space, and therefore every metric space is alsoa topological space. Metric spaces play a crucial role in network or graph settings.Optimal-distance and shortest travel-time queries are ideally handled in a metricspace setting.EuclideanLet Rbe the ﬁeld of real numbers. A vector space Vover Ris a nonempty set Vof objects vcalled vectors, together with two operations:1Addition: u+v∈Vfor all uv∈V2Product: αu∈Vfor all α∈R, v∈V.In addition to the existence of a special vector 0, there are other axioms that thetwo operations addition and product need to satisfy. For a complete discussion ofvector space, see Blythe and Robertson (1999).If there exists a (minimal) ﬁnite set of vectors {e1, e2, ..., en} such that any v∈Vcan be expressed as a linear combination of the eis, that is, there exists α1, ..., αn∈Rsuch that:v=α1e1+...+αnen(7.1)then the vector space is ﬁnite-dimensional. In a three-dimensional space the eiscorrespond to the familiar x, y, zcoordinate axis. If we add the notion of inner-product (angle) to vector space, we get a Euclidean space. In a Euclidean space setting, all spatial relationships including set, topological, metric, and directional(north/south) can be deﬁned.Dynamic spatial operationsMost of the operations that we have discussed so far have been static, in the sensethat the operands are not affected by the application of the operation. For example,calculating the length of a curve has no effect on the curve itself. Dynamicopera-tions alter the objects upon which the operations act. The three fundamental dynamicoperations are create, destroy, and update. All dynamic operations are variationsupon one of these themes (Worboys 1995). The mergefunction, commonly knownas “map-reclassiﬁcation” in many GIS, is an example of the create operation. Severalexamples of other dynamic spatial operations can be found in cartographic pro-jections and map editing features in a GIS.RDBMS and SQLThe relational model to represent data, introduced by Codd in 1970, has becomeone of the most popular logical data models. The power of this model is a con-sequence of the simplicity of its structure. We explain the terminology of the",
    "chunk_order_index": 79,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d343aa0d149878fc03e05e2110d0fa5a": {
    "tokens": 1200,
    "content": "knownas “map-reclassiﬁcation” in many GIS, is an example of the create operation. Severalexamples of other dynamic spatial operations can be found in cartographic pro-jections and map editing features in a GIS.RDBMS and SQLThe relational model to represent data, introduced by Codd in 1970, has becomeone of the most popular logical data models. The power of this model is a con-sequence of the simplicity of its structure. We explain the terminology of the relationalmodel in the context of a World databaseexample.THO_C07  20/03/2007  14:58  Page 121 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f122SHASHI SHEKHAR AND RANGA RAJU VATSAVAIWorld databaseSuppose we wanted to organize the data of each country in the world. Then we couldorganize the information about the countries in the form of a table, which we labelCountry, and list the array of available information in columns. For the Countrytable,the associated data consists of six things: the name of the country, the continentto which it belongs, its population and gross domestic product, its life expectancy,and the spatial geometry that holds each country’s international boundaries.The table is called a relation, and the columns, attributes. Each different instanceof the Countrywill be identiﬁed with a row in the table. A row is called a tuple, andthe order in which the rows and columns appear in the table is unimportant. Thusa relation is an unordered collection of tuples. Together the table and column names constitute the relation schema, and a collection of rows or tuples is calleda relational instance. The number of columns is called the degree of the relation.The Countryis a relation of degree six. Similarly, data about, for example, the different cities and major rivers ﬂowing through each country, can be organized as separate tables. Thus, the Worlddatabase consists of three relations or entities:Country, City, and River. The example tables are shown in Table 7.2 and the schemaof the database is shown below. Note that an underlined attribute is a primary key.For example, Name is the primary key in Country table.Country(Name:varchar(35), Cont:varchar(35), Pop:integer, GDP:integer, Life-Exp:integer, Shape:char(13))City(Name:varchar(35), Country:varchar(35), Pop:integer, Captial:char(1), Shape:char(9))River(Name:varchar(35), Origin:varchar(35), Length:integer, Shape:char(13))The Countryentity has six attributes. The Nameof the country and the continent(Cont) it belongs to are character strings of maximum length 35. The population(Pop) and gross domestic product (GDP) are integer types. The GDP is the total valueof goods and services produced in a country in one ﬁscal year. The Life-Expattri-bute represents the life expectancy in years (rounded to the nearest integer) for residents of a country. The Shapeattribute needs some explanation. The geometryof a country is represented in the Shapecolumn of Table 7.2. In relational data-bases, where the data types are limited, the Shapeattribute is a foreign key to ashape table. In an object-relational or object-oriented database, the Shapeattri-bute will be a polygon ADT. Since, for the moment, our aim is to introduce thebasics of the SQL, we will not query the Shapeattribute until the section below“Extending SQL for Spatial Data.”The Cityrelation has ﬁve attributes: Name, Country, Pop, Capital, and Shape.The Countryattribute is a foreign key into the Countrytable. Capitalis a ﬁxedcharacter type of length one; a city is a capital of a country or it is not. The Shapeattribute is a foreign key into a point shape table. As for the Countryrelation,we will not query the Shapecolumn.The four attributes of the Riverrelation are Name, Origin, Length, and Shape.The Originattribute is a foreign key into the Countryrelation and speciﬁes thecountry where the river originates. The Shapeattribute is a foreign key into a lineTHO_C07  20/03/2007  14:58  Page 122 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS123string shape table. The geometric information speciﬁed in the Shapeattribute is notsufﬁcient, however, to determine the country of origin of a river. The overloadingof Name across tables can be resolved by qualifying the attribute with tables usinga dot notation table.attribute: Country.Name, City.Name, and River.Name uniquelyidentiﬁes the Name attribute inside different tables. We also need information aboutthe direction of the river ﬂow.Basic SQL primerSQL is a commercial query language ﬁrst developed at IBM. Since then, it has becomethe standard query language for RDBMS. SQL is a declarative language; that is,Table 7.2The tables of the Worlddatabase(a) CountryCOUNTRYNameContPopGDPLife-ExpShape(millions",
    "chunk_order_index": 80,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4b36b73c1a879638e9a3bef952432d2a": {
    "tokens": 1200,
    "content": ", City.Name, and River.Name uniquelyidentiﬁes the Name attribute inside different tables. We also need information aboutthe direction of the river ﬂow.Basic SQL primerSQL is a commercial query language ﬁrst developed at IBM. Since then, it has becomethe standard query language for RDBMS. SQL is a declarative language; that is,Table 7.2The tables of the Worlddatabase(a) CountryCOUNTRYNameContPopGDPLife-ExpShape(millions)(billions)CanadaNAM30.1658.077.08Polygonid-1MexicoNAM107.5694.369.36Polygonid-2BrazilSAM183.31004.065.60Polygonid-3CubaNAM11.716.975.95Polygonid-4USANAM270.08003.075.75Polygonid-5ArgentinaSAM36.3348.270.75Polygonid-6(b) CityCITYNameCountryPop (millions)CapitalShapeHavanaCuba2.1YPointid-1Washington, DCUSA3.2YPointid-2MonterreyMexico2.0NPointid-3TorontoCanada3.4NPointid-4BrasiliaBrazil1.5YPointid-5RosarioArgentina1.1NPointid-6OttawaCanada0.8YPointid-7Mexico CityMexico14.1YPointid-8Buenos AiresArgentina10.75YPointid-9(c) RiverRIVERNameOriginLength (kilometers)ShapeRio ParanaBrazil2600LineStringid-1St LawrenceUSA1200LineStringid-2Rio GrandeUSA3000LineStringid-3MississippiUSA6000LineStringid-4THO_C07  20/03/2007  14:58  Page 123 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f124SHASHI SHEKHAR AND RANGA RAJU VATSAVAIthe user of the language has to specify the answer desired, but not the procedureto retrieve the answer.The SQL language has two separate components: the data deﬁnition language(DDL) and the data modiﬁcation language (DML). The DDL is used to create, delete,and modify the deﬁnition of the tables in the database. In the DML, queries areposed and rows inserted and deleted from tables speciﬁed in the DDL. We now pro-vide a brief introduction to SQL. Our aim is to provide enough understanding of the language so that readers can appreciate the spatial extensions that we willdiscuss in under the heading “Extending SQL for Spatial Data.” A more detailed andcomplete exposition of SQL can be found in any standard text on databases (Ullmanand Widom 1999, Elmasri and Navathe 2000).Data deﬁnition languageCreation of the relational schema and addition and deletion of tables are speciﬁedin the data deﬁnition language (DDL) component of SQL. For example, the Cityschema introduced earlier is deﬁned below in SQL. The Countryand Rivertablesare deﬁned in Table 7.3.CREATETABLE CITY {Name VARCHAR(35),Country VARCHAR(35),Pop INT,Capital CHAR(1)Shape CHAR(13)PRIMARY KEY Name }In the above example, the CREATE TABLE clause is used to deﬁne the relationalschema. The name of the table is CITY. The table has four columns, and the nameof each column and its corresponding data type must be speciﬁed. The Nameand Countryattributes must be ASCII character strings of less than 35 characters.Populationis of the type integer and Capitalis an attribute which is a single character Yor N. In SQL-92 the possible data types are ﬁxed and cannot be user-deﬁned. We do not give the complete set of data types, which can be found in anytext on standard databases. Finally, the Nameattribute is the primary key of therelation. Thus each row in the table must have a unique value for the Nameattribute.Table 7.3The Countryand Riverschema in SQL(a) Country schema(b) River schemaCREATETABLE Country {CREATETABLE River {Name VARCHAR(35),Name VARCHAR(35),Cont VARCHAR(35),Origin VARCHAR(35),Pop INT,Length INT,GDP INTShape CHAR(15)Shape CHAR(15)PRIMARY KEY Name }PRIMARY KEY Name } THO_C07  20/03/2007  14:58  Page 124 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS125Tables no longer in use can be removed from the database using the DROP TABLEcommand. Another important command in DDL is ALTER TABLEfor modifyingthe schema of the relation.Data manipulation languageAfter the table has been created as speciﬁed in DDL, it is ready to accept data. Thistask, which is often called “populating the table,” is done in the DML componentof SQL. For example, the following statement adds one row to the table River:INSERTINTO(Name, Origin, Length)RiverVALUES(‘Mississippi’, ‘USA’,",
    "chunk_order_index": 81,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-288189147ffee5876e0d8f3acae86e6f": {
    "tokens": 1200,
    "content": "TABLEcommand. Another important command in DDL is ALTER TABLEfor modifyingthe schema of the relation.Data manipulation languageAfter the table has been created as speciﬁed in DDL, it is ready to accept data. Thistask, which is often called “populating the table,” is done in the DML componentof SQL. For example, the following statement adds one row to the table River:INSERTINTO(Name, Origin, Length)RiverVALUES(‘Mississippi’, ‘USA’, 6000)If all the attributes of the relation are not speciﬁed, then default values are auto-matically substituted. The most often used default value is NULL. An attempt toadd another row in the Rivertable with Name = ‘Mississippi’will be rejectedby the DBMS because of the primary key constraint speciﬁed in the DDL.The basic form to remove rows from the table is as follows:DELETE FROM TABLE WHERE < CONDITIONS>For example, the following statement removes the row from the table Riverthatwe inserted above:DELETEFROMRiverWHEREName = ‘Mississippi’Basic form of an SQL queryOnce the database schema has been deﬁned in the DDL component and the tablespopulated, queries can be expressed in SQL to extract relevant data from the database.The basic syntax of an SQL query is extremely simple:SELECTTuplesFROMRelationsWHERETuple-constraintSQL has more clauses related to aggregation (for example, GROUP BY, HAVING),ordering results (for example, ORDER BY), etc. In addition, SQL allows the for-mulation of nested queries. We will illustrate these with a set of examples.Example queries in SQLWe now give examples of how to pose different types of queries in SQL. Our purposeis to give a ﬂavor of the versatility and power of SQL. All the tables queried arefrom the WORLD example introduced earlier under the heading “World database.”The results of these different queries can be found in Table 7.4.THO_C07  20/03/2007  14:58  Page 125 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f126SHASHI SHEKHAR AND RANGA RAJU VATSAVAITable 7.4Results of example queries(a) Query 1NameCountryPop (millions)CapitalShapeHavanaCuba2.1YPointWashington DCUSA3.2YPointBrasiliaBrazil1.5YPointOttawaCanada0.8YPointMexico CityMexico14.1YPointBuenos AiresArgentina10.75YPoint(i) Query 9Co.NameMexicoBrazilUSA(f) Query 6Average-Pop2.2(h) Query 8OriginMin-lengthUSA1200(g) Query 7ContContinent-PopNAM2343.5SAM676.1(e) Query 5Ci.NameCi.PopWashington, DC3.2(d) Query 4Ci.NameCo.PopBrassilia183.3Washington, DC270.0(c) Query 3: Life-expNameLife-expMexico69.36Brazil65.60(b) Query 2: ProjectNameCountryHavanaCubaWashington DCUSAMonterreyMexicoTorontoCanadaBrasiliaBrazilRosarioArgentinaOttawaCanadaMexico CityMexicoBuenos AiresArgentinaTHO_C07  20/03/2007  14:58  Page 126 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS1271Query: List all the cities and the country they belong to in the CITYtable.SELECTCi.Name,Ci.CountryFROMCity Ci2Query: List the names of the capital cities in the CITYtable.SELECT*FROMCityWHERECAPITAL=‘Y’3Query: List the names of countries in the Countryrelation where the life-expectancy is less than 70 years.SELECTCo.Name,Co.Life-ExpFROMCountry CoWHERECo.Life-Exp < 704Query: List the capital cities and populations of countries whose GDP exceedsone trillion dollars.SELECTCi.Name, Co.PopFROMCity Ci, Country CoWHERECi.Country = Co.Name ANDCo.GDP > 1000.0 ANDCi.Capital= ‘Y’Comments: This is the standard way of expressing the joinoperation. In thiscase the two tables Cityand Countryare matched on their common attri-butes Ci.Countryand Co.Name. Furthermore, two selection conditions arespeciﬁed separately in the Cityand Countrytable. Notice how the cascadingdot notation alleviated the potential confusion that might have arisen as a resultof the attribute names in the two relations.5Query: What is the name and population of the capital city in the country wherethe St Lawrence River originates?SELECTCi.Name, Ci.PopFROMCity Ci, Country Co, River RWHERER.Origin = Co.Name ANDR.Name = ‘St. Lawrence’ ANDCi.Capital= ‘Y’Comments:This query involves a join between three tables. The RiverandCountrytables are joined on the attributes Originand Name. The Countryand Citytables are joined on the attributes Nameand Country. There aretwo selection conditions on the Riverand Citytables respectively.THO_C07  20/03/2007  14:58  Page 127",
    "chunk_order_index": 82,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4015e12bdcf1479634704109c2f660c6": {
    "tokens": 1200,
    "content": ", River RWHERER.Origin = Co.Name ANDR.Name = ‘St. Lawrence’ ANDCi.Capital= ‘Y’Comments:This query involves a join between three tables. The RiverandCountrytables are joined on the attributes Originand Name. The Countryand Citytables are joined on the attributes Nameand Country. There aretwo selection conditions on the Riverand Citytables respectively.THO_C07  20/03/2007  14:58  Page 127 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f128SHASHI SHEKHAR AND RANGA RAJU VATSAVAI6Query: What is the average population of the non-capital cities listed in theCitytable?SELECTAVG(Ci.Pop)FROMCity CiWHERECi.Capital= ‘N’Comments: The AVG(Average) is an example of an aggregate operation. Otheraggregate operations are COUNT, MAX, MIN, and SUM. The aggregate operationsexpand the functionality of SQL because they allow computations to be performedon the retrieved data.7Query: For each continent, ﬁnd the average GDP.SELECTCo.Cont AVG(Co.GDP) AS Continent-GDPFROMCountry CoGROUP BYCo.ContComments: This query expression represents a major departure from the basicSQL query format. The reason is the presence of the GROUP BYclause. TheGROUP BYclause partitions the table on the basis of the attribute listed in the clause. In this example there are two possible values of Co.cont: NAMandSAM. Therefore, the Countrytable is partitioned into two groups. For eachgroup, the average GDPis calculated. The average value is then stored underthe attribute Continent-GDPas speciﬁed in the SELECTclause.8Query: For each country in which at least two rivers originate, ﬁnd the lengthof the smallest river.SELECTR.Origin, MIN(R.length) AS Min-lengthFROMRiver RGROUP BYR.OriginHAVINGCOUNT(*) > 1Comments: This is similar to the previous query. The difference is that the HAVINGclause allows selection conditions to be enforced on the different groupsformed in the GROUP BYclause. Thus only groups with more than one memberare considered.9Query: List the countries whose GDP is greater than Canada’s.SELECTCo.NameFROMCountry CoWHERECo.GDP      > ANY ( SELECTCo1.GDPFROMCountry Co1WHERECo1.Name = ‘Canada’)Comments: This is an example of a nested query. These are queries which haveother queries embedded in them. A nested query becomes mandatory when an intermediate table, which does not exist, is required before a query can beevaluated. The embedded query typically appears in the WHEREclause, thoughTHO_C07  20/03/2007  14:58  Page 128 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS129it can appear, albeit rarely, in the FROMand the SELECTclauses. The ANYisa set comparison operator. Consult a standard database text for a completeoverview of nested queries.SQL summaryStructured query language (SQL) is the most widely implemented database language.SQL has two components: the data deﬁnition language (DDL) and data manipula-tion language (DML). The schema of the database tables are speciﬁed and populatedin the DDL. The actual queries are posed in DML. We have given a brief overviewof SQL. More information can be found in any standard text on databases.Object-Oriented Database Management SystemsObject-oriented database technology results from the combination of object-orientedprogramming concepts with database management principles for supporting variousnon-traditional applications involving complex data types and operations. Let usnow brieﬂy review key features offered by most of the OODBMSs available on themarket today. These include types, classes, objects, methods, object identity, abstractdata types, complex objects, class hierarchies, overloading, and late binding.1Type System: A rich type system provides mechanisms to construct new typesusing the base types such as Booleans, integers, reals, and character strings. Manyobject-oriented programming languages allow constructing record structures andcollection types using a feature know as type constructor. A record structure ismade of ncomponents, where each component is a duplet consisting of a basetype and a ﬁeld name. A record structure is exactly the same as the “struct” typein the C and C++programming languages. A collection type is constructed usingcollection operators, such as arrays, lists, and sets. Thus although a collectiontype consists of more than one element, all elements are of the same type. Again,these two new types can be applied in the same fashion to construct even morecomplex types.2Classes:A class is a description of an object or group of objects with similarproperties and behavior. A class is made-up of a type, and one or more functionsor procedures known as methods.3Objects: An object is an instance of a class. The simplest objects are just basetypes, such as Booleans, integers, ﬂoats and strings, etc. An object can simplybe the value of that class or it can be a variable that holds values of",
    "chunk_order_index": 83,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7129300d560314b74f1d429d6c3f13ad": {
    "tokens": 1200,
    "content": "types.2Classes:A class is a description of an object or group of objects with similarproperties and behavior. A class is made-up of a type, and one or more functionsor procedures known as methods.3Objects: An object is an instance of a class. The simplest objects are just basetypes, such as Booleans, integers, ﬂoats and strings, etc. An object can simplybe the value of that class or it can be a variable that holds values of that class,known as immutable and mutable objects respectively. Formally, an object canbe thought of as a triple (I,C,V), where I is the object identity (OID), C is atype constructor, and V is the object state (that is, current value). An example is:o1=(i1, atom, “U.S.A.”).4Methods: A method implements a certain behavior or operation for a class. A method takes at least one argument that is an object of that class. Associatedwith each class is a special method, known as a constructor. Complex objectsare built from the simpler objects by applying constructors to them.THO_C07  20/03/2007  14:58  Page 129 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f130SHASHI SHEKHAR AND RANGA RAJU VATSAVAI5Object Identity: In the object-oriented (OO) paradigm, it is assumed that eachobject has a unique identity (OID), that is, the identity is independent of thestateof the object. It is also assumed that no two objects can have the sameOID, and that no object has two different OIDs. As a consequence, OODBMSsupport two important notions of object equivalence, known as object sharingand object updates.6Abstract Data Types: ADTs are user deﬁned arbitrary data types that are com-binations of atomic data types and the associated methods. ADTs provide dataencapsulation, that is, they restrict access to objects of a class through a welldeﬁned set of functions (methods).7Class Hierarchies: Generalization and specialization are two important object-oriented concepts that allow sharing or reuse of software. Through generalizationwe can organize the classes by their similarities and differences. Generalizationdeﬁnes the relationship between a superclass and its subclasses. A subclass inheritsall the properties (attributes) and the behavior (methods) of its superclass. Inaddition, the subclass may have its own properties (attributes and methods).While generalization takes a bottom-up approach, specialization takes a top-downapproach – that is, starting with the superclass and then splitting (specializing)into subclasses.Object-oriented query languagesIn the previous section, we have seen that SQL is the standard query language inthe RDBMS world. In this section, we present OQL, the object query language thatcombines the declarative programming feature of SQL with the object-oriented programming. Unlike SQL, OQL is intended to be used as an extension with someobject-oriented host language, such as C++or Java. Though it looks analogous tothe way SQL is embedded into a host language, the OQL and object-oriented hostlanguage combination provides seamless integration. Objects can be modiﬁed by thehost language and the OQL without explicitly transferring the values between the two languages, thereby providing an advantage over the embedded SQL. Nowlet us look at some of the query capabilities of OQL.OQL supports the basic SELECT-FROM-WHERE expressions of SQL. In addi-tion, OQL supports complex type constructors, such as Set(...), Bag(...), List(...),Array(...), and Struct(...), and path expressions. For simple queries, there would notbe any change between SQL and OQL query statements; however, the differencebetween them becomes obvious if we consider both class hierarchies and methods.In the next section we introduce some examples written in SQL-3 that incorporatesome object-oriented features into SQL.Object Relational Database Management SystemsDespite the advantages offered by object-oriented database management systems,the classical relational model (with various extensions) still dominates the markettoday. Nevertheless, the motivation that led to the development of OODBMS hasalso inﬂuenced the relational database community. Several database vendors, suchTHO_C07  20/03/2007  14:58  Page 130 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS131as Oracle and IBM (DB2), now offer hybrid systems known as object-relationaldatabase management systems (ORDBMS). Though relation is still a core conceptin ORDBMS, these newer systems now allow users to store collections of complexobjects that encapsulate both data and the behavior. The same is true in the SQLdomain, as seen in the recently standardized SQL-3, which brings object-orientedfeatures into the relational world. In this section we brieﬂy review the ORDBMStechnology through the OGC and SQL-3 extensions.Extending SQL for spatial dataAlthough it is a powerful query-processing language, SQL has its shortcomings. Themain one is that this language can handle only simple data types such as integers,dates, and strings. Spatial database applications must handle complex data types likepoints, lines",
    "chunk_order_index": 84,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-c57d4001d32cb25cc352ddaee52149ff": {
    "tokens": 1200,
    "content": "domain, as seen in the recently standardized SQL-3, which brings object-orientedfeatures into the relational world. In this section we brieﬂy review the ORDBMStechnology through the OGC and SQL-3 extensions.Extending SQL for spatial dataAlthough it is a powerful query-processing language, SQL has its shortcomings. Themain one is that this language can handle only simple data types such as integers,dates, and strings. Spatial database applications must handle complex data types likepoints, lines, and polygons. Database vendors have responded in two ways: Theyhave either used blobsto store spatial information, or they have created hybrid sys-tems in which spatial attributes are stored in operating-system ﬁles via a GIS. SQLcannot process data stored as blobs, and it is the responsibility of the applicationtechniques to handle data in blob form (Stonebraker and Moore 1997). This solutionis neither efﬁcient nor aesthetic because the data depends upon the host-languageapplication code. In a hybrid system, spatial attributes are stored in a separate operating-system ﬁle and thus are unable to take advantage of traditional databaseservices like query language, concurrency control, and indexing support.Object-oriented systems have had a major inﬂuence on expanding the capabilitiesof DBMS to support spatial (complex) objects. The program to extend a relationaldatabase with object-oriented features falls under the general framework of object-relational database management systems (ORDBMS). The key feature of ORDBMSis that they support a version of SQL, SQL-3/SQL-99, which supports the notionof user-deﬁned types (as in Java or C++). Our goal is to study SQL-3/SQL-99 enoughso that we can use it as a tool to manipulate and retrieve spatial data.The principal demand of spatial SQL is to provide a higher abstraction of spatialdata by incorporating concepts closer to our perception of space (Egenhofer 1994).This is accomplished by incorporating the object-oriented concept of user-deﬁnedabstract data types (ADT). An ADT is a user-deﬁned type and its associated func-tions. For example, if we have land parcels stored as polygons in a database, thena useful ADT may be a combination of the type polygonand some associated func-tion (method), say, adjacent. The adjacentfunction may be applied to landparcelsto determine if they share a common boundary. The term abstractis usedbecause the end-user need not know the implementation details of the associatedfunctions. All end-users need to know is the interface, that is, the available functionsand the data types for the input parameters and output results.The OGIS standard for extending SQLThe Open GIS Consortium (OGIS) was formed by major software vendors to for-mulate an industry-wide standard related to GIS interoperability. The OGIS spatialdata model can be embedded in a variety of programming languages, for example,C, Java, SQL, etc. We will focus on SQL embedding in this section.THO_C07  20/03/2007  14:58  Page 131 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f132SHASHI SHEKHAR AND RANGA RAJU VATSAVAIThe OGIS is based on a geometry data model shown in Figure 7.5. Recall that the data model consists of a base-class, GEOMETRY, which is non-instantiable (that is, objects cannot be deﬁned as instances of GEOMETRY), but speciﬁes a spatial reference system applicable to all its subclasses. The four major subclassesderived from the GEOMETRYsuperclass are Point, Curve, Surface, andGeometryCollection. Associated with each class is a set of operations whichacts on instances of the classes. A subset of important operations and their deﬁni-tions are listed in Table 7.5.Table 7.5A sample of operations listed in the OGIS standard for SQL (after OGIS 1999)Basic FunctionsSpatialReference()Returns the underlying coordinate system of the geometryEnvelope()Returns the minimum orthogonal boundingrectangle of the geometryExport()Returns the geometry in a different representationIsEmpty()Returns true if the geometry is a null setIsSimple()Returns true if the geometry is simple (no self-intersection)Boundary()Returns the boundary of the geometryTopological/Set EqualReturns true if the interior and boundary of the Operatorstwo geometries are spatially equalDisjointReturns true if the boundaries and interior do notintersectIntersectReturns true if the geometries are not disjointTouchReturns true if the boundaries of two surfacesintersect but the interiors do notCrossReturns true if the interior of the surface intersectswith a curveWithinReturns true if the interior of the given geometrydoes not intersect with the exterior of anothergeometryContainsTests if the given geometry contains another givengeometryOverlapReturns true if the interiors of two geometries havenon-empty intersectionSpatial AnalysisDistanceReturns the shortest distance between two geometriesBufferReturns a geometry that consists of all points whosedistance from the given geometry is less than orequal to the speciﬁed distanceConvexHullReturns the smallest convex geometric set enclosingthe geometryIntersectionReturns the geometric intersection of two geometriesUnionReturns the geometric union of two geometriesDifferenceReturns the portion of a geometry which does notintersect with another given geometrySymmDiffReturns the portions of two geometries which donot intersect with each otherTHO_C07  20/03/2007  14:58  Page 132 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas",
    "chunk_order_index": 85,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a2ed6b6814d9834ad69f59c393504f3d": {
    "tokens": 1200,
    "content": "Returns the smallest convex geometric set enclosingthe geometryIntersectionReturns the geometric intersection of two geometriesUnionReturns the geometric union of two geometriesDifferenceReturns the portion of a geometry which does notintersect with another given geometrySymmDiffReturns the portions of two geometries which donot intersect with each otherTHO_C07  20/03/2007  14:58  Page 132 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS133The operations speciﬁed in the OGIS standard fall into three categories:1Basic operations applicable to all geometry data types. For example,SpatialReferencereturns the underlying coordinate system where thegeometry of the object was deﬁned. Examples of common reference systems includethe well-known latitude and longitude system and the often-used UniversalTraversal Mercator (UTM) system.2Operations which test for topological relationships between spatial objects. Forexample, intersecttests whether the interior of two objects has a non-emptyset intersection.3General operations for spatial analysis. For example, distancereturns the shortest distance between two spatial objects.Limitations of the standardThe OGIS speciﬁcation is limited to the objectmodel of space. However, spatialinformation is sometimes most naturally mapped onto a ﬁeld-based model and theOGIS is currently developing consensus models for ﬁeld data types and operationsthat will probably be incorporated into a future OGIS standard.Even within the objectmodel, the OGIS operations are limited for simpleSELECT-PROJECT-JOINqueries. Support for spatial aggregate queries with theGROUP BYand HAVINGclauses does pose problems. Finally, the focus in the OGISstandard is exclusively on basic topological and metric spatial relationships. Supportfor a whole class of metric operations, namely, those based on the directionpre-dicate (for example, North, South, left, front) is missing.Example queries which emphasize spatial aspectsUsing the OGIS data types and operations, we formulate SQL queries in the Worlddatabase which highlight the spatial relationships between the three entities:Country, City, and River. We ﬁrst redeﬁne the relational schema, assuming thatthe OGIS data types and operations are available in SQL.1Query: Find the names of all countries which are neighbors of USAin the Countrytable.SELECTC1.Name AS “Neighbors of USA”FROMCountry C1, Country C2WHERETouch (C1.Shape, C2.Shape) = 1 ANDC2.Name = ‘USA’Comments: The Touchpredicate checks if any two geometric objects are adjacentto each other without overlapping. It is a useful operation to determine neigh-boring geometric objects. The Touchoperation is one of the eight topologicaland set predicates speciﬁed in the OGIS Standard. One of the nice propertiesof topological operations is that they are invariant under many geometric trans-formations. In particular, the choice of the coordinate system for the Worlddatabase will not affect the results of topological operations.THO_C07  20/03/2007  14:58  Page 133 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f134SHASHI SHEKHAR AND RANGA RAJU VATSAVAITopological operations apply to many different combinations of geometric types.Therefore, in an ideal situation these operations should be deﬁned in an “overloaded”fashion. Unfortunately, many object-relational DBMS do not support object-orientednotions of class inheritance and operation overloading. Thus, for all practical purposes,these operations must be deﬁned individually for each combination of applicablegeometric types (Table 7.6).1Query: For all the rivers listed in the Rivertable, ﬁnd the countries throughwhich they pass.SELECTR.Name C.NameFROMRiver R, Country CWHERECross(R.Shape, C.Shape) = 1Comments: The Crossis also a topological predicate. It is most often used tocheck for the intersection between LineStringand Polygonobjects, as inthis example, or a pair of LineStringobjects.2Query: Which city listed in the Citytable is closest to each river listed in theRivertable?SELECTC1.Name, R1.NameFROMCity C1, River R1WHEREDistance (C1.Shape, R1.Shape) <( SELECT Distance(C2.Shape, R2.Shape)FROM City C2, River R2WHERE C1.Name <> C2.NameAND R1.Name <> R2.Name)Table 7.6Basic data types(a)(b)CREATETABLECountry(CREATETABLERiver(Namevarchar(30),Namevarchar(30),Contvarchar(30),Originvarchar(30),PopInteger,LengthNumber,GDPNumber,ShapeLineString);ShapePolygon); (c) CREATETABLECity ( Namevarchar(30), Countryvarchar(30), Popinteger, ShapePoint ); THO_C07  20/03/2007  14:58  Page 134 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions",
    "chunk_order_index": 86,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-cd37166444d431aeba67a8312669efe7": {
    "tokens": 1200,
    "content": "); (c) CREATETABLECity ( Namevarchar(30), Countryvarchar(30), Popinteger, ShapePoint ); THO_C07  20/03/2007  14:58  Page 134 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS135Comments: The Distanceis a real-valued binary operation. It is being usedonce in the WHEREclause and again in the SELECTclause of the subquery. TheDistancefunction is deﬁned for any combination of geometric objects.3Query: The St Lawrence River can supply water to cities which are within 300 km.List the cities which can use water from the St Lawrence.SELECTCi.NameFROMCity Ci, River RWHEREOverlap (Ci.Shape, Buffer(R.Shape,300)) =1 ANDR.Name = ‘St. Lawrence’Comments: The Bufferof a geometric object is a geometric region centered atthe object whose size is determined by a parameter in the Bufferoperation.In the example the query dictates the size of the buffer region. The buffer operation is used in many GIS applications including ﬂoodplain managementand urban and rural zoning laws. A graphical depiction of the buffer operationis shown in Figure 7.6. In the ﬁgure, Cities A and B are likely to be affected ifthere is a ﬂood on the river, while City C will remain unaffected.4Query: List the name, population, and area of each country listed in theCountrytable.SELECTC.Name, C.Pop, Area(C.Shape) AS “Area”FROMCountry CComments: This query illustrates the use of the Areafunction. This function isonly applicable for Polygonand MultiPolygongeometry types. Calculatingthe Areaclearly depends upon the underlying coordinate system of the Worlddatabase. For example, if the shape of the Countrytuples is given in terms oflatitude and longitude, then an intermediate coordinate transformation must beperformed before the Areacan be calculated. The same care must be taken forDistanceand the Lengthfunction.Fig. 7.6The buffer of a river and points within and outside the resultant bufferCBATHO_C07  20/03/2007  14:58  Page 135 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f136SHASHI SHEKHAR AND RANGA RAJU VATSAVAI5Query:List the length of the rivers in each of the countries they pass through.SELECTR.Name, C.Name, Length(Intersection(R.Shape,C.Shape)) AS “Length”FROMRiver R, Country CWHERECross(R.Shape, C.Shape) =1Comments: The return value of the Intersectionbinary operation is a geo-metry type. The Intersectionoperation is different from the Intersectsfunction, which is a topological predicate to determine if two geometries inter-sect. The Intersectionof a LineStringand Polygoncan either be a Pointor LineStringtype. If a river does pass through a country, then the resultwill be a LineString. In that case, the Lengthfunction will return the lengthof the river in each country it passes through.6Query:List the GDP and the distance of a country’s capital city to the equatorfor all countries.SELECTCo.GDP, Distance(Point(0,Ci.y),Ci.Shape) AS“Distance”FROMCountry Co, City CiWHERECo.Name = Ci.Country AND Ci.Capital = ‘Y’Comments: Searching for implicit relationships between data sets stored in adatabase is outside the scope of standard database functionality. Current DBMSare geared toward online transaction processing (OLTP), while this query, asposed, is in the realm of online analytical processing (OLAP). At the moment thebest we can do is list each capital and its distance to the equator (Table 7.7).Point(0,Ci.y)is a point on the equator which has the same longitude asthat of the current capital instantiated in Ci.Name.7Query: List all countries, ordered by number of neighboring countries.SELECTCo.Name, Count(Co1.Name)FROMCountry Co, Country Co1WHERETouch(Co.Shape, Co1.Shape)GROUP BYCo.NameORDER BYCount(Co1.Name)Table 7.7Results of query 7Co.NameCo.GDPDist-toEq (km)Havana16.92562Washington DC80034324Brazilia10041756Ottawa6585005Mexico City694.32161Buenos Aires348.23854THO_C07  20/03/2007  14:58  Page 136 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS137Comment:In this query all the countries with at least one neighbor are sortedon the basis of number of neighbors.8Query: List the countries with only one neighboring country. A country is aneighbor of another country if their land masses share a boundary.SELECTCo.NameFROMCountry Co",
    "chunk_order_index": 87,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-88a533b05085fbe132fe03b358b07889": {
    "tokens": 1200,
    "content": "://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS137Comment:In this query all the countries with at least one neighbor are sortedon the basis of number of neighbors.8Query: List the countries with only one neighboring country. A country is aneighbor of another country if their land masses share a boundary.SELECTCo.NameFROMCountry Co, Country Co1WHERETouch(Co.Shape, Co1.Shape)GROUP BYCo.NameHAVINGCount(Co1.Name) = 1SELECTCo.NameFROMCountry CoWHERECo.Name IN(SELECT Co.NameFROM Country CoWHERE Touch(Co.Shape, Co1.Shape))GROUP BYCo.NameHAVINGCount(*) = 1Comments: Here we have a nested query in the FROMclause. The result of thequery within the FROMclause is a table consisting of pairs of countries whichare neighbors. The GROUP BYclause partitions the new table on the basis ofthe names of the countries. Finally, the HAVINGclause forces the selection tobe paired to those countries which have only one neighbor. The HAVINGclauseplays a role similar to the WHEREclause with the exception that it must includeaggregate functions like count, sum, max, and min.9Query: Which country has the maximum number of neighbors?CREATE VIEWNeighbor ASSELECTCo.Name, Count(Co1.Name) AS num neighborsFROMCountry Co, Country Co1WHERETouch(Co.Shape, Co1.Shape)GROUP BYCo.NameSELECTCo.Name, num neighborsFROMNeighborWHEREnum neighbor = (SELECT Max(num neighbors)FROMNeighborObject-relational SQLThe OGIS standard speciﬁes the data types and their associated operations whichare considered essential for spatial applications like GIS. For example, for the Pointdata type an important operation is Distance, which computes the distance betweentwo points. The lengthoperation is not a semantically correct operation on a Pointdata type. This is similar to the argument that the concatenationoperation makesmore sense for Characterdata type than for say, the Integertype.THO_C07  20/03/2007  14:58  Page 137 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f138SHASHI SHEKHAR AND RANGA RAJU VATSAVAIIn relational databases, the set of data types is ﬁxed. In object-relational and object-oriented databases this limitation has been relaxed and there is a built in supportfor user-deﬁned data types. While this feature is clearly an advantage, especiallywhen dealing with non-traditional database applications like GIS, the burden of con-structing syntactically and semantically correct data types is now on the databaseapplication developer. To share some of the burden, commercial database vendorshave introduced application-speciﬁc “packages” which provide a seamless interfaceto the database user. For example, Oracle markets a GIS speciﬁc package calledthe Spatial Data Cartridge.The recently standardized SQL-3 allows user-deﬁned data types within the overall framework of a relational database. Two features of the SQL-3 standardwhich may be beneﬁcial for deﬁning user-deﬁned spatial data types are describedbelow.A glance at SQL-3The SQL-3/SQL-99 proposes two major extensions to SQL-2/SQL-92, the currentaccepted SQL draft.1Abstract Data Type:An ADT can be deﬁned using a CREATE TYPEstatement.Like classesin object-oriented technology, an ADT consists of attributes andmember functions to access the values of the attributes. Member functions can potentially modify the value of the attributes in the data type and thus can also change the database state. An ADT can appear as a column type in a relational schema. To access the value that the ADT encapsulates, a member function speciﬁed in the CREATE TYPEmust be used. For example,the following script creates a type Pointwith the deﬁnition of one member function Distance:CREATE TYPEPoint (xNUMBER,yNUMBER,FUNCTIONDistance(:u Point,:v Point)RETURNS NUMBER );The colons before uand vsignify that these are local variables.2Row Type:A row type is a type for a relation. A row type speciﬁes the schemaof a relation. For example, the following statement creates a row type Point.CREATE ROW TYPEPoint (xNUMBER,yNUMBER );We can now create a table which instantiates the row type. For example:CREATE TABLE Pointtable of TYPE Point;THO_C07  20/03/2007  14:58  Page 138 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS139In our own work we emphasize the use of ADT instead of row type. This is becausethe ADT as a column type naturally harmonizes with the deﬁnition of an ORDBMSas an extended relational database.Object-relational schemaOracle 8 is an object-relational DBMS introduced by Oracle Corporation. Sim-ilar products are available from other database companies such as IBM. Oracle 8 implements a part of the SQL-3 Standard. In",
    "chunk_order_index": 88,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9e96569aa4e3a8fe1da6edafd0fb6f21": {
    "tokens": 1200,
    "content": "IENTED DATABASE MANAGEMENT SYSTEMS139In our own work we emphasize the use of ADT instead of row type. This is becausethe ADT as a column type naturally harmonizes with the deﬁnition of an ORDBMSas an extended relational database.Object-relational schemaOracle 8 is an object-relational DBMS introduced by Oracle Corporation. Sim-ilar products are available from other database companies such as IBM. Oracle 8 implements a part of the SQL-3 Standard. In this system, the ADT is called the“object type.”Below we describe how the three basic spatial data types – Point, LineString,and Polygon– are constructed in Oracle 8.CREATETYPE Point AS OBJECT (x NUMBER,y NUMBER,MEMBERFUNCTION Distance(:u Point,:v Point) RETURN NUMBER,PRAGMARESTRICT_REFERENCES (Distance, WNDS);The Pointtype has two attributes, xand y, and one member function, Distance.PRAGMAalludes to the fact that the Distancefunction will not modify the stateof the database: WNDS(Write No Database State). Of course in the OGISstandard many other operations related to the Point type are speciﬁed, but for simplicity we have shown only one. After its creation the Pointtype can be usedin a relation as an attribute type. For example, the schema of the relation Citycan be deﬁned as follows:CREATE TABLECity (Namevarchar(30),Popint,Capitalchar(1),ShapePoint);Once the relation schema has been deﬁned, the table can be populated in the usualway. For example, the following statement adds information related to Brasilia,the capital of Brazil, into the database:INSERT INTO CITY(‘Brasilia’, ‘Brazil’, 1.5, ‘Y’, Point(-55.4,-23.2));The construction of the LineStringdata type is slightly more involved thanthat of the Pointtype. We begin by creating an intermediate type, LineType:CREATE TYPE LineType AS VARRAY(500) OF Point;THO_C07  20/03/2007  14:58  Page 139 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f140SHASHI SHEKHAR AND RANGA RAJU VATSAVAIThus LineTypeis a variable array of Pointdata type with a maximum lengthof 500. Type-speciﬁc member functions cannot be deﬁned if the type is deﬁned asa Varray. Therefore, we create another type LineString:CREATE TYPELineString AS OBJECT (Num_of_Points INT,Geometry LineType,MEMBER FUNCTION Length(SELF IN) RETURN NUMBER,PRAGMA RESTRICT REFERENCES(Length, WNDS);The attribute Num_of_Pointsstores the size (in terms of points) of each instanceof the LineStringtype. We are now ready to deﬁne the schema of the Rivertable:CREATETABLERiver(Namevarchar(30),Originvarchar(30),Lengthnumber,ShapeLineString );While inserting data into the Rivertable, we have to keep track of the differentdata types involved.INSERT INTO RIVER (‘Mississippi’, ‘USA’, 6000, LineString(3, LineType(Point(1,1),Point(1,2),Point(2,3)))The Polygontype is similar to LineString. The sequence of type and table creationand data insertion is given in Table 7.8.Example queries1Query: List all the pairs of cities in the Citytable and the distances between them.SELECTC1.Name, C1.Distance(C2.Shape) AS “Distance”FROMCity C1, City C2WHEREC1.Name <> C2.NameComments: Notice the object-oriented notation for the Distancefunction inthe SELECTclause. Contrast it with the predicate notation used in section above,“Example queries which emphasize spatial aspects”: Distance(C1.Shape,C2.Shape). The predicate in the WHEREclause ensures that the Distancefunction is not applied between two copies of the same city.2Query: Validate the length of the rivers given in the Rivertable, using thegeometric information encoded in the Shapeattribute.SELECTR.Name, R.Length, R.Length() AS “Derived Length”FROMRiver RComments: This query is used for data validation. The length of the rivers is already available in the Lengthattribute of the Rivertable. Using theLength()function we can check the integrity of the data in the table.THO_C07  20/03/2007  14:58  Page 140 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS1413Query: List the names, populations, and areas of all countries adjacent to theUSA.SELECTC2.Name, C2.Pop, C2.Area() AS “Area”FROMCountry C1, Country C2WHERE* C1.Name = ‘USA’ ANDC1.Touch(C2.Shape) = 1Comments: The Area()function is a natural function for the PolygonADTto support. Along with Area(), the query also invokes the Touchtopologicalpredicate.CONCLUSIONSIn this chapter we have presented an overview of relational, object-oriented, andobject-relational database management systems",
    "chunk_order_index": 89,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0c1e8ae389d619d314a470bbeb93f812": {
    "tokens": 1200,
    "content": ".SELECTC2.Name, C2.Pop, C2.Area() AS “Area”FROMCountry C1, Country C2WHERE* C1.Name = ‘USA’ ANDC1.Touch(C2.Shape) = 1Comments: The Area()function is a natural function for the PolygonADTto support. Along with Area(), the query also invokes the Touchtopologicalpredicate.CONCLUSIONSIn this chapter we have presented an overview of relational, object-oriented, andobject-relational database management systems from a GIS and spatial data man-agement point of view. The relational data model, which has proven to be verysuccessful at solving most business data processing problems, has serious drawbacksTable 7.8The sequence of creation of the Countrytable(a)CREATE TYPE PolyType AS VARRAY (500) OF Point(b)CREATETYPE Polygon AS OBJECT (Num_of_Points INT,Geometry PolyType,MEMBER FUNCTION Area(SELF IN) RETURN NUMBER,PRAGMA RESTRICT_REFERENCES (Length, WNDS);(c)CREATETABLECountry(Namevarchar(30),Contvarchar(30),Popint,GDPnumber,Life-Expnumber,ShapePolygon);(d)INSERT INTOCountry(‘Mexico’, ‘NAM’, 107.5, 694.3, 1004.0,Polygon(23, Polytype(Point(1,1),...,Point(1,1)))THO_C07  20/03/2007  14:58  Page 141 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f142SHASHI SHEKHAR AND RANGA RAJU VATSAVAIwhen it comes to handling complex information systems. On the other hand, object-oriented database management systems, which are the result of combining goodfeatures of object-oriented programming concepts and database management prin-ciples, have been limited to certain niche markets. Recent object extensions of RDBMShave resulted in a more ﬂexible hybrid DBMS, known as ORDBMS, and seem tooffer the best of both worlds. We have provided key concepts of each of these DBMSthrough simple examples drawn from the standard World database.The treatment of this chapter was limited to the basic principles of the conceptsneeded to understand these DBMS. For additional information the interested readeris directed to the following references. Standard textbooks on DBMS (Ullman andWidom 1999, Elmasri and Navathe 2000) cover a broad spectrum of topics in thisﬁeld. Readers interested in spatial databases may refer to Rigaux, Scholl, and Voisard(2002) and Shekhar and Chawla (2003), which provide a detailed treatment of DBMSfrom a spatial data management point of view. Readers wanting additional insightson the intersection of computer science and GIS should consult Worboys (1995); thoseinterested in conceptual data models and their extensions with respect to spatialdatabase applications should consult Tryfona and Hadzilacos (1995), Hadzilacos andTryfona (1997), Shekhar, Vatsavai, Chawla, and Burk (1999), Brodeur, Bédard,and Proulx (2000), and Bédard, Larrivée, Proulx, and Nadeau (2004). For more onspatial query languages and spatial query processing, there is Orenstein (1986, 1990)and Egenhofer (1994); readers interested in multi-dimensional indexing should referto Gaede and Günther (1998). Finally, those interested in learning more about standards should consult OGIS (1999).REFERENCESAlbrecht, J. 1998. Universal analytical GIS operations: A task-oriented systematization ofdata-structure-independent GIS functionality. In M. Craglia and H. Onsrud (eds) GeographicInformation Research: Transatlantic Perspectives.London: Taylor and Francis: 557–91.Bédard, Y., Larrivée, S., Proulx, M.-J., and Nadeau, M. 2004. Modeling geospatial databaseswith plug-ins for visual languages: A pragmatic approach and the impacts of 16 years ofresearch and experimentations on perceptory. In S. Wang, D. Yang, K. Tanaka, F. Grandi,S. Zhou, E. E. Mangina, T. W. Ling, I.-Y. Song, J. Guan, and H. C. Mayr (eds) Con-ceptual Modeling for Advanced Application Domains: Proceedings of the InternationalConference on Conceptual Modeling (ER 2004), Shanghai, China.Berlin: Springer LectureNotes in Computer Science No. 3289: 17–30.Blythe, T. and Robertson, E. 1999. Basic Linear Algebra.Berlin: Springer-Verlag.Brodeur, J., Bédard, Y., and Proulx, M.-J. 2000. Modeling geospatial application data-bases using UML-based repositories aligned with international standards in geomatics. In Proceedings of the Eighth ACM Symposium on Advances in Geographic InformationSystems, Washington, DC, USA. New York, NY: Association of Computing Machinery,pp. 39–46.Egenhofer, M. J. 1991. Reasoning about binary topological relations. In O. Günther andH.-J. Schek (eds) Advances in Spatial Databases: Proceedings of the Second InternationalSymposium, SSD’91, Zürich, Switzerland.Berlin: Springer Lecture",
    "chunk_order_index": 90,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-bdd6539f4575b0a0392430e949d702e9": {
    "tokens": 1200,
    "content": ". In Proceedings of the Eighth ACM Symposium on Advances in Geographic InformationSystems, Washington, DC, USA. New York, NY: Association of Computing Machinery,pp. 39–46.Egenhofer, M. J. 1991. Reasoning about binary topological relations. In O. Günther andH.-J. Schek (eds) Advances in Spatial Databases: Proceedings of the Second InternationalSymposium, SSD’91, Zürich, Switzerland.Berlin: Springer Lecture Notes in Computer ScienceNo. 525: 143–60.Elmasri, R. and Navathe, S. 2000. Fundamentals of Database Systems.Boston, MA:Addison-Wesley.THO_C07  20/03/2007  14:58  Page 142 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fOBJECT-ORIENTED DATABASE MANAGEMENT SYSTEMS143Gaede, V. and Günther, O. 1998. Multidimensional access methods. ACM Computing Surveys30: 170–231.Hadzilacos, T. and Tryfona, N. 1997. An extended entity-relationship model for geographicapplications. SIGMOD Record26: 24–9.Khoshaﬁan, S. and Baker, A. 1998 Multimedia and Imaging Databases.San Francisco, CA:Morgan Kaufmann.OGIS. 1999. Open GIS Consortium: Open GIS Simple Features Speciﬁcation for SQL (Revision1.1).WWW document, http://www.opengis.org/techno/specs.htm.Orenstein, J. A. 1986. Spatial query processing in an object-oriented database system. InProceedings of the ACM SIGMOD International Conference on Management of Data,Washington, DC, USA. New York: Association of Computing Machinery, pp. 326–36.Orenstein, J. A. 1990. Comparison of spatial query processing techniques for native andparameter spaces.In Proceedings of the 1990 ACM SIGMOD International Conferenceon Management of Data: Atlantic City, NJ, USA. New York:Association of ComputingMachinery, pp. 343–52.Rigaux P., Scholl, M., and Voisard, A. 2002. Spatial Databases.San Francisco, CA: MorganKaufman.Shekhar, S. and Chawla, S. 2003. Spatial Databases: A Tour.Upper Saddle Creek, NJ: PrenticeHall.Shekhar, S., Vatsavai, R. R., Chawla, S., and Burk, T. E. 1999. Spatial pictogram enhancedconceptual data models and their transition to logical data models. In P. Agouris and A. Stefanidis (eds) Selected Papers from the International Workshop on Integrated SpatialDatabases, Digital Images and GIS. London: Springer Lecture Notes in Computer ScienceNo. 1737: 77–104.Stonebraker, M. and Moore, D. A. 1997. Object Relational DBMSs: The Next Great Wave.San Francisco, CA: Morgan Kaufmann.Tryfona, N. and Hadzilacos, T. 1995. Geographic applications development: Models andtools for the conceptual level. In Proceedings of the Third ACM Symposium on Advancesin Geographic Information Systems,Baltimore, MD, USA. New York: Association ofComputing Machinery, pp. 19–28.Ullman, J. and Widom, J. 1999. A First Course In Database Systems.Upper Saddle Creek,NJ: Prentice Hall.Worboys, M. F. 1995. GIS: A Computing Perspective.London: Taylor and Francis.THO_C07  20/03/2007  14:58  Page 143 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 8Adding the Z DimensionMichael F. HutchinsonThe land surface is the natural context for life on Earth. Above sea-level the landsurface plays a fundamental role in modulating land surface and atmospheric pro-cesses. Below sea-level it forms an important role in modulating ocean tides andcurrents. Life depends on these Earth surface processes over a wide range of spaceand time scales. Conversely, the land surface itself is molded by these processes,also over a wide range of time and space scales. It is thus not surprising that modelsof the land surface of the Earth have played an integral role in GI Science since itsinception. Analyses and representations of the land surface have directly stimulatednew methods for obtaining digital environmental data, new spatial interpolationmethods and new methods for analysing landscape dependent hydrological and ecological processes (Hutchinson and Gallant 1999). The Z dimension, the eleva-tion above or below sea-level of the land surface, is the primary descriptor of thisfundamental layer.Digital elevation models (DEMs) are used to represent the land surface in differ-ent ways, depending on the nature of the application. Visualization of landscapes,and of spatially distributed quantities and entities within landscapes, plays an import-ant role in conceptualization and in providing subjective understanding of surfaceprocesses. It can also play an important role in assessing data quality",
    "chunk_order_index": 91,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6d8d1a442b9ee48ab54d5194110f237e": {
    "tokens": 1200,
    "content": "). The Z dimension, the eleva-tion above or below sea-level of the land surface, is the primary descriptor of thisfundamental layer.Digital elevation models (DEMs) are used to represent the land surface in differ-ent ways, depending on the nature of the application. Visualization of landscapes,and of spatially distributed quantities and entities within landscapes, plays an import-ant role in conceptualization and in providing subjective understanding of surfaceprocesses. It can also play an important role in assessing data quality. These applica-tions are discussed extensively in “Optimization of DEM Resolution” below. Ofcentral importance for environmental modeling is the accuracy and spatial cover-age that can be achieved by incorporating appropriate dependencies on the landsurface. Mesoscale representations of surface climate, particularly temperature andprecipitation, have a strong direct dependence on elevation, the Z dimension itself,making such representations truly three-dimensional. Modeling applications at ﬁnerscales often depend on representations of the shape of the land surface rather thanelevation per se. These shape-based applications are largely the subject of terrainanalysis as discussed by Wilson and Gallant (2000; see also Chapter 23 by Deng,Wilson, and Gallant in this volume).This chapter is primarily concerned with the generation of regular grid digitalelevation models, from a variety of data sources, to support the elevation and THO_C08  20/03/2007  14:59  Page 144 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION145landscape shape requirements of environmental modeling over a range of spatialscales. Issues of data quality and spatial scale naturally arise in this context. Anessential shape-based attribute of DEMs for hydrological applications is drainageconnectivity. Coupling the process of automatic drainage enforcement to the inter-polation and ﬁltering of DEMs, as introduced by Hutchinson (1989), has improvedelevation accuracy and directly facilitated hydrological applications. DEM accuracycan also be improved by applying statistical ﬁltering methods that accurately reﬂectthe errors in elevation source data. The issues of drainage connectivity and elevationaccuracy are particularly relevant with the advent of ﬁne scale digital elevation datasources.The chapter also discusses the incorporation of dependencies of environmentalvariables on elevation and landscape shape. This is largely the domain of multivariatestatistical analysis, usually performed by various forms of thin plate smoothing splinesand geostatistics. These models normally apply data smoothing, in the same way ascan be applied to elevation data, to allow for ﬁne scale variability in the data andproduce spatial models with minimal error. The incorporation of dependencies onelevation and landscape shape has played a major role in developing accurate spatialrepresentations of environmental variables such as surface climate and in assessingspatially detailed impacts of projected climate change (Houser, Hutchinson, Viterbo,et al. 2004).Regular Grid Digital Elevation Models and Spatial ScaleDigital elevation models are commonly based on one of three data structures: triangulated irregular networks, contours, and regular grids. Triangulated irregularnetworks (TINs) have found most application in visualization where economy ofrepresentation is important. This can be achieved if the triangulations are based onwell-chosen surface speciﬁc points including peaks and points on ridges, streamlinesand breaks in slope (Weibel and Heller 1991, Lee 1991). Contour methods tend tobe computationally intensive and difﬁcult to apply to larger areas. They are less oftenused directly as elevation models, but have been used in hydrological applications(Moore, O’Loughlin, and Burch 1988) and in recent derivations of slope (Mizukoshiand Aniya 2002).On the other hand, regular grid DEMs offer simplicity of representation and oftopological relations between points, at the expense of somewhat larger storagerequirements than TINs. Regular grid DEMs are readily integrated with remotelysensed environmental data that are normally obtained in regular grid form. The gridspacing can also provide a useful index of scale. If stored with sufﬁcient verticalprecision, regular grid DEMs can represent terrain shape in areas of both high andlow relief. Thus regular grid DEMs have become the dominant vehicle for environ-mental applications that depend on elevation and shape of the land surface.The grid spacing, or spatial resolution, of a regular grid DEM, as well as pro-viding a practical index of scale also provides a measure of information content(Hutchinson 1996). The issue of spatial scale arises at various points in elevation-based environmental analysis and modeling. The scale of source topographic datashould guide the choice of grid spacing when generating DEMs from such data. TheTHO_C08  20/03/2007  14:59  Page 145 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTable 8.1Spatial scales of applications of digital elevation models (DEMs) and common sources of topographic data for generation of DEMsScaleFine ToposcaleCoarse ToposcaleMesoscaleMacroscaleDEM Resolution1–50 m50–200 m200 m–5 km5–500 kmCommon Topographic Data SourcesContour and streamline data from aerialphotography and existing top",
    "chunk_order_index": 92,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-80d672d030aec384f27322c850f9c669": {
    "tokens": 1200,
    "content": ") on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTable 8.1Spatial scales of applications of digital elevation models (DEMs) and common sources of topographic data for generation of DEMsScaleFine ToposcaleCoarse ToposcaleMesoscaleMacroscaleDEM Resolution1–50 m50–200 m200 m–5 km5–500 kmCommon Topographic Data SourcesContour and streamline data from aerialphotography and existing topographic maps atscales from 1:5,000 to 1:50,000.Surface speciﬁc point and streamline data obtainedby ground survey using GPS.Remotely sensed elevation data using airborne andspaceborne radar and laser.Contour and streamline data from aerialphotography and existing topographic maps atscales from 1:50,000 to 1:200,000.Surface speciﬁc point and streamline data digitizedfrom existing topographic maps at 1:100,000scale.Surface speciﬁc point and streamline data digitizedfrom existing topographic maps at scales from1:100,000 to 1:250,000.Surface speciﬁc point data digitized from existingtopographic maps at scales from 1:250,000 to1:1,000,000.National archives of ground surveyed topographicdata including trigonometric points and benchmarks.Hydrological and Ecological ApplicationsSpatially distributed hydrological modeling.Spatial analysis of soil properties.Topographic aspect corrections to remotelysensed data.Topographic aspect effects on solar radiation,evaporation, and vegetation patterns.Broader scale distributed parameterhydrological modeling.Sub-catchment analysis for lumped parameterhydrological modeling and assessment ofbiodiversity.Elevation dependent representations of surfacetemperature and precipitation.Topographic aspect effects on precipitation.Surface roughness effects on wind.Determination of continental drainage divisions.Major orographic barriers for generalcirculation models.THO_C08  20/03/2007  14:59  Page 146 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION147scales of DEMs should also match the natural scales of terrain dependent applications.The determination of appropriate DEM scales for hydrological modeling is an activeresearch issue (for example, Zhang and Montgomery 1994, Blöschl and Sivaplan1995, Feddes 1995, Sivaplan, Grayson, and Woods 2004). This is particularly rele-vant in recent years with the advent of high resolution data sources. Incorporationof terrain structure into considerations of spatial scale is also an emerging issue interrain analysis (Gallant and Dowling 2003).The range of spatial scales of hydro-ecological applications of DEMs, and thecorresponding common primary topographic data sources are indicated in Table 8.1,as adapted from Hutchinson and Gallant (2000). The general trend since the 1980shas been to move from broader continental and regional scales, closely allied to therepresentation of major drainage divisions (Jenson 1991, Hutchinson and Dowling1991), to mesoscale representations of surface climate (Hutchinson 1995b, Runningand Thornton 1996, Daly, Neilson, and Phillips 1994) and associated ﬂora andfauna (Nix 1986), to ﬁner toposcales suited to the modeling of surface hydrology,vegetation, and soil properties (Moore, Grayson, and Ladson 1991, Quinn, Beven,Chevallier, and Planchon 1991, Zhang and Montgomery 1994, Gessler, Moore,McKenzie, and Ryan 1995, Mackey 1996). This has been accompanied by improve-ments in methods for representing the ﬁne scale shape and structure of DEMs, supported by the steady increase in resolution of DEM data sources and the capacityof computing platforms. Fine scale processes are often the focus of hydrologicalapplications. However, it should be noted that coarser scale processes, particu-larly mesoscale climate, can have a signiﬁcant impact on the spatial distribution of elevation dependent environmental processes.Of the applications listed in Table 8.1, only representations of surface temperatureand rainfall have a direct dependence on elevation. All others depend on measures ofsurface shape and roughness, as exempliﬁed by the primary and secondary terrainattributes listed in Moore, Grayson, and Ladson (1991). This underlines the import-ance of DEMs providing accurate representations of surface shape and drainagestructure. This is particularly so in low relief areas where elevations must be recordedwith sub-meter precision to accurately reﬂect small elevation gradients.Though actual terrain can vary across a wide range of spatial scales, in practice,source topographic data are commonly acquired at a particular scale. This placespractical limits on the range of DEM resolutions that can be truly supported by aparticular source data set. The following section describes the data sources commonlysupporting generation of DEMs at each of the scales listed in Table 8.1.Sources of Topographic DataThree main classes of source topographic data may be recognized, for which differ-ent DEM generation techniques are applicable, as discussed below.Surface speciﬁc point elevation dataSurface speciﬁc point elevations, including high and low points, saddle points, andpoints on streams and ridges make up the skeleton of terrain (Clarke 1990). TheyTHO_C08  20/03/2007  14:59",
    "chunk_order_index": 93,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-5183e5c85cd131edcdb8a77413d55ead": {
    "tokens": 1200,
    "content": "listed in Table 8.1.Sources of Topographic DataThree main classes of source topographic data may be recognized, for which differ-ent DEM generation techniques are applicable, as discussed below.Surface speciﬁc point elevation dataSurface speciﬁc point elevations, including high and low points, saddle points, andpoints on streams and ridges make up the skeleton of terrain (Clarke 1990). TheyTHO_C08  20/03/2007  14:59  Page 147 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f148MICHAEL F. HUTCHINSONare an ideal data source for most interpolation techniques, including triangulationmethods and specially adapted gridding methods. These data may be obtained byground survey and by manually assisted photogrammetric stereo models (Makarovic1984). They can also be obtained from grid DEMs to construct TIN models (Heller1990, Lee 1991). The advent of the global positioning system (GPS) has enhancedthe availability of accurate ground surveyed data (Dixon 1991, Lange and Gilbert1998). Such data are mainly obtained for detailed survey of relatively small experi-mental catchments. They are less often used for larger areas.Contour and streamline dataContour and streamline data are still a common terrain data source for larger areas.They have found common application at the toposcale (see Table 8.1). Many ofthese data have been digitized from existing topographic maps that, until the adventof spaceborne survey methods, were the only source of elevation data for some parts of the world. The conversion of contour maps to digital form has been a majoractivity of mapping organizations world wide (Hobbs 1995). Contours can also begenerated automatically from photogrammetric stereo models (Lemmens 1988),although these methods are subject to error due to variations in surface cover. A sample contour and streamline data set, together with some additional point data,is shown in Figure 8.1. Contours implicitly encode a number of terrain features,including points on streamlines and ridges. The main disadvantage of contour datais that they signiﬁcantly under sample the areas between contour lines, especiallyin areas of low relief, such as the lower right hand portion of Figure 8.1. This has370380370370380353753853600385380375370365360360+354+381.3+356.8+386.8+356.80100MFig. 8.1Contour, point elevation, and streamline dataTHO_C08  20/03/2007  14:59  Page 148 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION149led most investigators to prefer contour speciﬁc algorithms over general purposealgorithms when interpolating contour data (Clarke, Grün, and Loon 1982, Mark1986, Hutchinson 1988, Weibel and Brändl 1995).Contour data differ from other elevation data sources in that they imply a degreeof smoothness of the underlying terrain. When contours are obtained by manu-ally assisted photogrammetric techniques, the operator can remove the effects ofobstructions such as vegetation cover and buildings. When coupled with a suitableinterpolation technique, contour data can be a superior data source in low reliefareas, where moderate elevation errors in remotely sensed data can effectively pre-clude accurate determination of surface shape and drainage structure (Garbrechtand Starks 1995).Streamlines are also widely available from topographic maps and provide importantstructural information about the landscape. However, few interpolation techniquesare able to make use of streamline data without associated elevation values. Themethod developed by Hutchinson (1989) can use such streamline data, providedthat the streamlines are digitized in the downslope direction. This imposes a signiﬁc-ant editing task, which can be achieved by using a GI System (GIS) with networkcapabilities.Remotely sensed elevation dataGridded DEMs may be calculated directly by stereoscopic interpretation of datacollected by airborne and satellite sensors. The traditional source of these data isaerial photography (Kelly, McConnell, and Mildenberger 1977). In the absence ofvegetation cover these data can deliver elevations to sub-meter accuracy (Ackermann1978, Lemmens 1988). Stereoscopic methods have been applied to SPOT imagery(Konecny, Lohmann, Engel, and Kruck 1987, Day and Muller 1988), and more recentlyto airborne and spaceborne synthetic aperture radar (SAR). Airborne and space-borne lasers can also provide elevation data in narrow swathes. A major impetusfor these developments has been the goal of generating high resolution DEMs with global coverage, recently achieved with the completion of the three-second (90 m) DEM for the globe obtained from the Shuttle Radar Topography Mission(USGS 2005).Remote sensing methods can provide broad spatial coverage, but have a num-ber of generic limitations. None of the sensors can reliably measure the ground elevations underneath dense vegetation cover. Even in the absence of ground cover,all methods measure elevations with signiﬁcant random errors that depend on theinherent",
    "chunk_order_index": 94,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-1cdd388096699ab8356c22d4725874d2": {
    "tokens": 1200,
    "content": "generating high resolution DEMs with global coverage, recently achieved with the completion of the three-second (90 m) DEM for the globe obtained from the Shuttle Radar Topography Mission(USGS 2005).Remote sensing methods can provide broad spatial coverage, but have a num-ber of generic limitations. None of the sensors can reliably measure the ground elevations underneath dense vegetation cover. Even in the absence of ground cover,all methods measure elevations with signiﬁcant random errors that depend on theinherent limitations of the observing instruments, as well as surface slope and rough-ness (Harding, Bufton, and Frawley 1994, Dixon 1995). The methods also requireaccurately located ground control points to minimize systematic error. These pointsare not always easy to locate, especially in remote regions. Best possible standardelevation errors with spaceborne systems currently range between 1 and 10 m, butelevation errors can be much larger, up to 100 m, under unfavorable conditions(Sasowsky, Peterson, and Evans 1992, Harding, Bufton, and Frawley 1994,Zebker, Werner, Rosen, and Hensley 1994, Lanari, Fornaro, Riccio 1997). Averagingof data obtained from multiple passes of the sensor can reduce these errors, but at greater cost.THO_C08  20/03/2007  14:59  Page 149 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f150MICHAEL F. HUTCHINSONAirborne laser scanning (ALS) data are an emerging source of ﬁne-scale, irregularlyspaced, elevation data with position and elevation errors around 10–20 cm andtypical data spacing around 1–2 m (Flood 2001, Maas 2002). Airborne laser canreliably detect the height of the ground surface below signiﬁcant tree cover. Thesedata offer the potential for a new generation of accurate ﬁne scale DEMs for a widerange of applications (Lane and Chandler 2003). But, as for coarser scale remotelysensed data, careful ﬁltering and interpolation of such data is required to maximizethe quality of the resulting DEMs and dependent representations of surface shapeand drainage structure.DEM interpolation methodsInterpolation is required to generate regular grid DEMs from irregularly spaced elevation data. These include surface speciﬁc points, contour data and high resolu-tion data obtained by detailed ground survey and by airborne and spaceborne laser.Streamline data can be incorporated into the interpolation process to improve thedrainage properties of the interpolated DEM. Since source topographic data setsare usually very large, high quality global interpolation methods, such as thin platesplines, in which every interpolated point depends explicitly on every data point,are computationally impractical. Such methods cannot be easily adapted to the stronganisotropy evidenced by real terrain surfaces. On the other hand, local interpola-tion methods – such as inverse distance weighting, local kriging, and unconstrainedtriangulation methods – achieve computational efﬁciency at the expense of somewhatarbitrary restrictions on the form of the ﬁtted surface. Three classes of interpolationmethods are in use. All achieve a degree of local adaptivityto anisotropic terrainstructure.TriangulationInterpolation based on triangulation is achieved by constructing a triangulation ofthe data points, which form the vertices of the triangles, and then ﬁtting local poly-nomial functions across each triangle. Linear interpolation is the simplest case, buta variety of higher order polynomial interpolants have been devised to ensure thatthe interpolated surface has continuous ﬁrst derivatives (Akima 1978, Sibson 1981,Watson and Philip 1984, Auerbach and Schaeben 1990, Sambridge, Braun, andMcQueen 1995). Considerable attention has been directed towards methods for con-structing the triangulation. The Delauney triangulation is the most popular methodand several efﬁcient algorithms have been devised (for example, Aurenhammer 1991,Tsai 1993).Triangulation methods have been seen as attractive because they can be adapted tovarious terrain structures, such as ridge lines and streams, using a minimal numberof data points (McCullagh 1988). However, these points are difﬁcult to obtain asprimary data. Triangulation methods are sensitive to the positions of the data pointsand the triangulation needs to be constrained to produce optimal results (Heller1990, Weibel and Heller 1991). Triangulation methods are known to have difﬁ-culties in interpolating contour data. These data tend to generate many ﬂat trianglesTHO_C08  20/03/2007  14:59  Page 150 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION151unless additional structural data points along streams and ridges can be provided(Clarke 1990, Zhu, Eastman, and Toledano 2001).Local surface patchesInterpolation by local surface patches is achieved by applying a global interpolationmethod to overlapping regions, usually rectangular in shape, and",
    "chunk_order_index": 95,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a30c7be471bdaf54bbe86112de3cfdfa": {
    "tokens": 1200,
    "content": "https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION151unless additional structural data points along streams and ridges can be provided(Clarke 1990, Zhu, Eastman, and Toledano 2001).Local surface patchesInterpolation by local surface patches is achieved by applying a global interpolationmethod to overlapping regions, usually rectangular in shape, and then smoothlyblending the overlapping surfaces. Franke (1982) and Mitasova and Mitas (1993)have used bivariate spline functions in this way. These methods overcome the com-putational problems posed by large data sets and permit a degree of local anisotropy.They can also perform data smoothing when the data have elevation errors. Thereare some difﬁculties in deﬁning patches when data are very irregularly spaced andanisotropy is limited to one direction across each surface patch. Nevertheless, Mitasovaand Mitas (1993) have obtained good performance on contour data. An advantagefor applications of this method is that topographic parameters such as slope andcurvature, as well as ﬂow lines and catchment areas, can be calculated directly from the ﬁtted surface patches, which have continuous ﬁrst and second derivatives(Mitasova, Hoﬁerka, Zlocha, and Iverson 1996). Local surface patches can also bereadily converted into regular grids.Locally adaptive griddingDirect gridding methods can provide a computationally efﬁcient means of applyinghigh quality interpolation methods to large elevation data sets. Iterative methodswhich ﬁt discretized splines in tension, as represented by a ﬁnite difference grid, havebeen described by Hutchinson (1989) and Smith and Wessel (1990). Both methodshave their origin in the minimum curvature method developed by Briggs (1974).Computational efﬁciency can be achieved by using a simple multi-grid strategy whichcan make computational time optimal, in the sense that it is proportional to thenumber of interpolated DEM points (Hutchinson 1989). The use of splines in tensionis indicated by the statistical nature of actual terrain surfaces (Frederiksen, Jacobi,and Kubik 1985, Goodchild and Mark 1987). It overcomes the tendency of minimumcurvature splines to generate spurious surface oscillations in complex areas.The ANUDEM direct gridding method of Hutchinson (1988, 1989, 2006) is usedwidely. It has been shown to be superior in terms of elevation accuracy to a varietyof local kriging methods (Bishop and McBratney 2002). It has several locally adaptivefeatures. It is best described by ﬁrst deﬁning an appropriate statistical modelfor the observed elevation data. Each elevation data value ziat location xi,yiis assumedto be given by:zi=f(xi,yi) +εi(i=1,..., n)(8.1)where fis an unknown suitably smooth bivariate function of horizontal locationrepresented as a ﬁnite difference grid, nis the number of data points and εiis azero mean error term with standard deviation wi. For accurately surveyed elevationdata the standard deviation is dominated by the natural discretization error of the ﬁnite difference representation of f. Assuming that each data point is locatedTHO_C08  20/03/2007  14:59  Page 151 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f152MICHAEL F. HUTCHINSONrandomly within its corresponding grid cell, the standard deviation of the discretizationerror is given by:wi=(8.2)where his the grid spacing and siis the slope of the grid cell associated with theith data point (Hutchinson 1996). The function fis then estimated by solving forthe regular grid ﬁnite difference approximation to the bivariate function fthat minimizes:(8.3)where J(f) is a measure of the roughness of the function fin terms of ﬁrst and second derivatives (Hutchinson 1989) and λis a positive number called the smooth-ing parameter. The smoothing parameter λis normally chosen so that the weightedresidual sum of squares in equation (8.3) is equal to n. This can be achieved withan approximate Newton-Rhapson method coupled with the iterative solution of f(Hutchinson 2000). The spatially varying weights in the residual sum of squares in equation (8.3) is a locally adaptivefeature that can only be achieved with aniterative interpolation method for which the slopes of the grid cells are availableas the iterative solution proceeds.Former limitations in the ability of general gridding methods to adapt to stronganisotropic structure in actual terrain surfaces, as noted by Ebner, Reinhardt, andHössler (1988), have been largely overcome by applying a series of locally adaptiveconstraints to the basic gridding procedure. Constraints which have direct relevancefor hydrological applications are those imposed by the drainage enforcement algorithmdevised by Hutchinson (1989). This algorithm removes spurious depressions in theﬁtted DEM, in recognition of the fact that sinks are usually quite rare in nature(Band 1986, Goodchild and Mark 1987). This can signiﬁcantly improve the drain-age quality and overall structure of the ﬁtted DEM. It can largely remove the needto modify the interpolated DEM to obtain drainage connectivity. Alternatively, thiscan be achieved",
    "chunk_order_index": 96,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-bdc44cf450fd7c8bc3475553e1b616ce": {
    "tokens": 1200,
    "content": "those imposed by the drainage enforcement algorithmdevised by Hutchinson (1989). This algorithm removes spurious depressions in theﬁtted DEM, in recognition of the fact that sinks are usually quite rare in nature(Band 1986, Goodchild and Mark 1987). This can signiﬁcantly improve the drain-age quality and overall structure of the ﬁtted DEM. It can largely remove the needto modify the interpolated DEM to obtain drainage connectivity. Alternatively, thiscan be achieved by artiﬁcially ﬁlling remaining depressions (Jenson and Domingue1988). A grid carving procedure for removing depressions from DEMs has beenrecently developed by Soille, Vogt, and Colombo. (2003). Its action is similar to thedrainage enforcement algorithm of Hutchinson (1989).The action of the drainage algorithm can be quite strong in data sparse areas, asillustrated in Figures 8.2 and 8.3 reproduced from Hutchinson (1989). The remain-ing sinks labeled S1, S2, S3, S4 in Figure 8.2, are removed by systematically iden-tifying the lowest saddle point in the drainage divide surrounding each remainingdepression. Thus the point D is the lowest saddle associated with the sink S1. Flowlines on each side of this saddle point are used to enforce approximate linear con-straints from S1 down to S2. Other sinks are cleared similarly. Sinks are clearedin order of increasing elevation. This yields a derived drainage network aligned with the actual streamline formation process. Thus, the sink S3 in Figure 8.2 wasnot initially cleared to the next lowest sink S4, but cleared to join the streamlineﬁrst inferred between S4 and S1. The drainage enforcement procedure can be made  [( (,))/] (),zfxywJfiiiiin  −+=∑12λ  hsi/12THO_C08  20/03/2007  14:59  Page 152 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION153computationally efﬁcient because both sink points and saddle points can be detectedlocallyon the grid DEM as the DEM is being interpolated.A related locally adaptivefeature is an algorithm which automatically calculatescurvilinear ridge and streamlines from points of locally maximum curvature on contour lines (Hutchinson 1988). This permits interpolation of the ﬁne structurein contours across the area between the contour lines in a more reliable fashion thanmethods which use linear or cubic interpolation along straight lines in a limited num-ber of directions (Clarke, Grün, and Loon 1982, Oswald and Raetzsch 1984, Legatesand Willmott 1986, Cole, MacInnes, and Miller 1990). A partly similar approach,combining triangulation and grid structures, has been described by Aumann, Ebner,and Tang (1992).The result of applying the ANUDEM program to the contour, streamline andpoint data in Figure 8.1 is shown Figure 8.4. The inferred stream and ridge linesare particularly curvilinear in the data sparse, low relief portion of the ﬁgure, andthere are no spurious depressions. The derived contours also closely match the datacontours. This locally adaptive method has largely overcome problems formerlyencountered by gridding methods in accurately representing drainage structure inlow relief areas (Douglas 1986, Carter 1988).This procedure also yields a generic classiﬁcation of the landscape into simple,connected, approximately planar, terrain elements, bounded by contour segments and255252260265EB255S4248265270259S3260.262255245S1250D250245237S2240.261252C.261255A.262.261.261255Fig. 8.2Minimum curvature gridding of point elevation data with spurious sinks or depressionsTHO_C08  20/03/2007  14:59  Page 153 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f154MICHAEL F. HUTCHINSONﬂow line segments. These are similar to the elements calculated by Moore, O’Loughlin,and Burch (1988), but their bounding ridge lines and streamlines are determinedin a more stable manner that incorporates uphill searches on ridges and downhillsearches in valleys (Hutchinson 1988). A recent development in this elevation grid-ding method is to include a locally adaptivesurface roughness penalty deﬁned byproﬁle curvature. This penalty attempts to match ﬂuvial landform processes in amore generic manner and initial results are encouraging (Hutchinson 2000).Filtering of remotely sensed elevation dataRemotely sensed data can be obtained as regular grid DEMs and as irregularly spacedlaser scanned data. Filtering of both forms of data is required to remove errors thatcan have both random and systematic components. Filtering of DEM data is usu-ally associated with a coarsening of the DEM resolution. Methods include simplenearest neighbor sub-sampling and standard ﬁltering techniques, including medianand moving average ﬁltering in",
    "chunk_order_index": 97,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0b21c96fc2294251c592f8eb61476c8c": {
    "tokens": 1200,
    "content": "(Hutchinson 2000).Filtering of remotely sensed elevation dataRemotely sensed data can be obtained as regular grid DEMs and as irregularly spacedlaser scanned data. Filtering of both forms of data is required to remove errors thatcan have both random and systematic components. Filtering of DEM data is usu-ally associated with a coarsening of the DEM resolution. Methods include simplenearest neighbor sub-sampling and standard ﬁltering techniques, including medianand moving average ﬁltering in the spatial domain, and lowpass ﬁltering in the frequency domain. Several authors have recognized the desirability of ﬁltering remotelysensed DEMs to improve the representation of surface shape.245S2237.261255250245DS1240245250.262.261.261260255.261260259S3.262260255265S4255250265252252Fig. 8.3Spurious sinks removed from the surface in Figure 8.2 by the drainage enforcementalgorithmTHO_C08  20/03/2007  14:59  Page 154 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION155Sasowsky, Peterson, and Evans (1992) and Bolstad and Stowe (1994) used thenearest neighbor method to sub-sample SPOT DEMs, with a spatial resolution of10 m, to DEMs with spatial resolutions ranging from 20 to 70 m. This generallyenhanced the representation of surface shape, although signiﬁcant errors remained.Giles and Franklin (1996) applied median and moving average ﬁltering methods to a 20 m resolution SPOT DEM. This similarly improved representation of slopeand solar incidence angles, although elevation errors were as large as 80 m and noeffective representation of proﬁle curvature could be obtained.Lanari, Fornaro, Riccio (1997) have applied a Kalman ﬁlter to spaceborne SARdata obtained on three different wavelengths. Standard elevation errors ranged betweenabout 5 and 80 m, depending on land surface conditions. There is clear potentialfor the application of smoothing methods that simultaneously maintain sensible mor-phological constraints, such as connected drainage structure, on the ﬁltered DEM.The locally adaptive ﬁnite difference gridding procedure described above is one suchmethod. It can be adapted to DEM data, and to irregularly spaced airborne laser data,by augmenting the error standard deviation described in equation (8.2) to includethe standard vertical measurement error in the remotely sensed data.Optimization of DEM ResolutionDetermination of the appropriate resolution of an interpolated or ﬁltered DEM isusually a compromise between achieving ﬁdelity to the true surface and respecting+++++Fig. 8.4Contours and inferred stream lines and ridge lines derived by the ANUDEM procedurefrom the topographic data shown in Figure 8.1.THO_C08  20/03/2007  14:59  Page 155 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f156MICHAEL F. HUTCHINSONpractical limits on the density and accuracy of the source data. Determination of theDEM resolution that matches the information content of the source data is desirablefor several reasons. It directly facilitates efﬁcient data inventory, since DEM storagerequirements are quite sensitive to resolution. It also permits interpretation of thehorizontal resolution of the DEM as an index of information content. This is animportant consideration when linking DEMs to other grid data sets and when ﬁlter-ing remotely sensed DEMs. Moreover, it can facilitate assessment of the scale depend-ence of terrain dependent applications, such as the determination of the spatial distributions of soil properties (Gessler, Moore, McKenzie, and Ryan 1995).A simple method for matching DEM resolution to source data information con-tent has been developed by Hutchinson (1996). The method is based on the locallyadaptive weighting of the residual sum of squares described in equations (8.1) and(8.2) above. The method monitors the root mean square slope of all DEM pointsassociated with elevation data as a function of DEM resolution (Figure 8.5). Theoptimum resolution is determined by reﬁning the DEM resolution until furtherreﬁnements produce no signiﬁcant increase in the root mean square DEM slope.The method is particularly appropriate when source data have been obtained in aspatially uniform manner, such as elevation contours from topographic maps at a ﬁxed scale, or from remotely sensed gridded elevation data.The root mean square slope criterion appears to be a reliable shape-based wayof matching DEM resolution, to within a factor two, to the information content ofthe source contour and streamline data. This criterion can be reﬁned, especially whensource data have positional errors, by examining plots of derived contours and proﬁlecurvature, as discussed by Hutchinson and Gallant (2000).Quality Assessment of DEMsThe quality of a derived DEM can vary greatly depending on the source data and the interpolation technique. The desired quality depends on the application for 8006.12512.52550100DEM Resolution (m)200400RMS Percent Slope2520151050++++++",
    "chunk_order_index": 98,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d40c39f0fb3b6f34fb64ea621a6990ce": {
    "tokens": 1200,
    "content": "can be reﬁned, especially whensource data have positional errors, by examining plots of derived contours and proﬁlecurvature, as discussed by Hutchinson and Gallant (2000).Quality Assessment of DEMsThe quality of a derived DEM can vary greatly depending on the source data and the interpolation technique. The desired quality depends on the application for 8006.12512.52550100DEM Resolution (m)200400RMS Percent Slope2520151050++++++Fig. 8.5Plot of root mean square slope of a DEM versus DEM resolutionTHO_C08  20/03/2007  14:59  Page 156 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION157which the DEM is to be used, but a DEM created for one application is often usedfor other purposes. Any DEM should therefore be created with care, using the bestavailable data sources and processing techniques. Efﬁcient detection of spurious features in DEMs can lead to improvements in DEM generation techniques as wellas detection of errors in source data. Early detection and correction of data errorscan avoid expensive reprocessing of DEM dependent applications.A ﬁrst measure of DEM accuracy is summary elevation difference, typically theroot mean square difference, of reference elevation data from the DEM. This canprovide a useful indication of DEM accuracy. However, since many applicationsof DEMs depend on representations of surface shape and drainage structure, measures of elevation error do not provide a complete assessment of DEM quality(Hutchinson 1989, Wise 2000). A number of graphical techniques for assessing dataquality have been developed. These are non-classical measures that offer means ofconﬁrmatory data analysis without the use of accurate reference data. Assessmentsof DEMs in terms of their representation of surface aspect have also been examinedby Wise (1998).Spurious sinks and drainage analysisSpurious sinks or local depressions in DEMs are frequently encountered and are asigniﬁcant source of problems in hydrological applications (Mackay and Band 1998).Sinks may be caused by incorrect or insufﬁcient data, or by an interpolation tech-nique that does not enforce surface drainage. They are easily detected by comparingelevations with surrounding neighbors. Hutchinson and Dowling (1991) noted thesensitivity of this method in detecting elevation errors as small as 20 m in sourcedata used to interpolate a continent-wide DEM with a horizontal resolution of 2.5 km. More subtle drainage artifacts in a DEM can be detected by performing a full drainage analysis to derive catchment boundaries and streamline networks,using the technique of Jenson and Domingue (1988).Views of shaded relief and other terrain attributesComputing shaded relief allows a rapid visual inspection of the DEM for local anomalies that show up as bright or dark spots. It can indicate both random andsystematic errors. It can identify problems with insufﬁcient vertical resolution, sincelow relief areas will show as highly visible steps between ﬂat areas. It can also detectedge-matching problems (Hunter and Goodchild 1995). Shaded relief is a graphicalway of checking the representation of slope and aspect in the DEM. Views of otherprimary terrain attributes, particularly proﬁle curvature, can provide a sensitive assess-ment of the accuracy of the DEM in representing terrain shape. Examination ofproﬁle curvature can prevent selection of a DEM resolution which is too ﬁne. Overﬁneresolution can lead to systematic errors in derived primary terrain attributes, as illus-trated by Hutchinson and Gallant (2000).Derived elevation contoursContours derived from a DEM provide a sensitive check on terrain structure sincetheir position, aspect, and curvature depend directly on the elevation, aspect, andTHO_C08  20/03/2007  14:59  Page 157 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f158MICHAEL F. HUTCHINSONplan curvature respectively of the DEM. Derived contours are a particularly usefuldiagnostic tool because of their sensitivity to elevation errors in source data. Subtleerrors in labeling source data contours digitized from topographic maps are com-mon, particularly for small contour isolations that may have no label on the printedmap. Examination of derived contours can prevent selection of a DEM resolutionwhich is too coarse to adequately represent terrain structure, as illustrated byHutchinson and Gallant (2000).Frequency histograms of primary terrain attributesOther deﬁciencies in the quality of a DEM can be detected by examining frequencyhistograms of elevation and aspect. DEMs derived from contour data usually showan increased frequency at the data contour elevations in an elevation histogram. Theseverity of this bias depends on the interpolation algorithm. Its impact is minimal forapplications that depend primarily on drainage analyses that are deﬁned primarilyby topographic aspect. Frequency histograms of aspect can be biased towards mul-tiples of 45 and 90 degrees by simpler interpolation algorithms that restrict searchingto a few speciﬁc directions between pairs of data points.Topographic Dependent Modeling of Environmental VariablesEnvironmental quantities are naturally distributed over space so accounting for thespatial distribution of environmental variables plays a key role in environmentalmodeling. Biophysical variables such as climate, soil and terrain",
    "chunk_order_index": 99,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-2f6728695d32f5ed31db4dc35a8c03a5": {
    "tokens": 1200,
    "content": "forapplications that depend primarily on drainage analyses that are deﬁned primarilyby topographic aspect. Frequency histograms of aspect can be biased towards mul-tiples of 45 and 90 degrees by simpler interpolation algorithms that restrict searchingto a few speciﬁc directions between pairs of data points.Topographic Dependent Modeling of Environmental VariablesEnvironmental quantities are naturally distributed over space so accounting for thespatial distribution of environmental variables plays a key role in environmentalmodeling. Biophysical variables such as climate, soil and terrain are the primaryspatially distributed determinants of plant growth. Dependent quantities such asnatural vegetation, agricultural productivity, soil erosion and human and animalpopulations all have spatial dimensions that can be addressed by making explicitlinks to these contributing spatial biophysical processes. The type of spatial analysisthat is discussed here is usually termed geostatistical. It is applied to data that havebeen sampled at points across the landscape. The broad aim of geostatistical analysisis to identify the nature of the spatial coherence of these data and use it to estimate(or interpolate) the complete spatial distribution from the sampled points.Geostatistics arose out of efforts by Krige in the 1950s to estimate the spatialdistributions of ore bodies. The theory was largely established by Matheron in the1960s (Chilès and Delﬁner 1999). A signiﬁcant body of related work on multivariatesmoothing spline methods also arose in the late 1970s, largely championed by Wahba(1990). The methods are formally equivalent, and have similar accuracy, but tendto differ in practice (Hutchinson and Gessler 1994). Schimek (2000) provides anextensive survey of spline-based approaches to multivariate modeling. A basic twodimensional spatial model underlying both geostatistics and smoothing splines is thatthere are nmeasured data values ziat spatial locations xi,yi,given byzi=f(xi,yi) +εi(i=1,..., n)(8.4)where fis a function to be estimated from the observations and εiis a zero meanerror term. In the case of smoothing splines fis assumed to be a smooth unknownTHO_C08  20/03/2007  14:59  Page 158 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION159function and in the case of geostatistics fis assumed to be a spatially autocorre-lated random ﬁeld.This spatial model has the same form as equation (8.1) given above for the locallyadaptive gridding model for elevation. However, in the case of surface climate datathe function can be solved analytically, since climate data sets normally have at mosta few thousand points and there is no need to apply locally adaptive constraints tothe interpolated function. The degree of data smoothing controls the complexityof the function f and has to be estimated from statistical analysis of the data. Thisis usually accomplished for smoothing splines by minimizing an estimate of the predictive error of the ﬁtted spline given by the generalized cross validation (GCV)(Wahba 1990). It is often done in geostatistics by variogram analysis (Cressie 1991).Alternatively, maximum likelihood methods can be applied to both splines and geostatistics. Extensions to the basic bivariate model described in equation (8.4) toincorporate dependences on topography are described below in terms of thin platesmoothing splines with their kriging equivalents.Partial spline modelThe simplest way to extend the spline model speciﬁed by equation (8.4) to incor-porate dependence on topography is to add a parametric linear dependence on elevation. Such a partial splinemodel can be appropriate for representing surfacetemperature since the environmental lapse rate of temperature is approximately linear. The model can be described asTi=f(xi,yi) +βhi+εi(i=1,..., n)(8.5)where Tiis the temperature at location xi,yiwith elevation hiabove sea-level, nisthe number of data points, βis a an unknown but ﬁxed elevation lapse rate and fis an unknown function of horizontal location (Hutchinson 2003). The error termεirepresents not only measurement error, but also deﬁciencies in the partial splinemodel due to ﬁne scale variation in surface temperature below the resolution ofthe data network. The function frepresents sea-level temperature and the scalar βrepresents the environmental lapse rate, usually around 6.5°C per km. The partialspline model permits simultaneous estimation of fand βwith the complexity ofthe function fdetermined by minimising the GCV. This corresponds to detrendedkrigingin geostatistics, also called regression kriging. In that case the trend βisusually set by initial linear regression on elevation and the residuals are then spatiallyinterpolated using ordinary kriging.Jarvis and Stuart (2001a, b) have found partial splines and detrended kriging toperform with similar accuracy in interpolating daily temperature data. A range oftopographic predictors have also been used in this manner to predict soil moisture(Famiglietti, Rudnicki, and Rodell 1998, Western, Grayson, Blöschl, Willgoose, andMcMahon 1999) and other soil properties (Odeh, McBratney, and Chittleborough1994, Bourennane, King, Cherry, and Bruand 1996). Additional",
    "chunk_order_index": 100,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-26387f6e8935281f8aefc9944270f6ef": {
    "tokens": 1200,
    "content": "similar accuracy in interpolating daily temperature data. A range oftopographic predictors have also been used in this manner to predict soil moisture(Famiglietti, Rudnicki, and Rodell 1998, Western, Grayson, Blöschl, Willgoose, andMcMahon 1999) and other soil properties (Odeh, McBratney, and Chittleborough1994, Bourennane, King, Cherry, and Bruand 1996). Additional linear predictors,based on topography and other factors, are easily added to partial spline and detrendedkriging models, as illustrated in a spatial analysis of precipitation by Kyriakidis,Kim, and Miller (2001). If there is no signiﬁcant spatial variation in the dependenceTHO_C08  20/03/2007  14:59  Page 159 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f160MICHAEL F. HUTCHINSONon topographic predictors the function fin equation (8.5) may be omitted and theanalysis reverts to simple linear regression on the topographic predictors. The spatialvariation in the ﬁtted model is then due only to the spatial variation in the topo-graphic predictors.Trivariate spline modelFor variables such as precipitation and soil moisture, with more complex topographicdependences, simple linear regression and partial spline models are not always adequate spatial models. Thus Agnew and Palutik (2000) and Kieffer Weisse andBois (2001) found elevation detrended kriging analyses of precipitation to performno better than simple linear regression on elevation. This is because topographicdependencies of precipitation are known to vary over larger areas. Similarly, Qiu,Fu, Wang, and Chen (2001) have noted that relationships between soil moistureand environmental variables can be very variable.There have been several attempts to introduce spatially varyingtopographic depend-ences into precipitation analyses. A relatively straightforward way is to divide theregion into subregions and perform separate linear regression analyses on elevationfor each subregion. Subregions may be deﬁned by partitioning the region into latitude and longitude rectangles (Michaud, Auvine, and Penalba 1995), or morecommonly by using a succession of local overlapping neighborhoods, each containinga minimum number of data points (Nalder and Wein 1998). The PRISM methodmakes a further subdivision based on broad classes of topographic aspect (Daly,Neilson, and Phillips 1994). These methods can be effective. Their main limitationsare non-robustness of the local regressions, due to the lack of sufﬁcient numbers ofstations at high altitude locations in some subregions, and minimal coherence betweenanalyses for adjoining subregions.These problems can be addressed by applying a multivariate analysis method that uses all the data to simultaneously incorporate a continuous spatially varyingdependence on both horizontal position and elevation. This can be implementedwith a trivariate smoothing spline model that can be writtenRi=f(xi,yi,hi) +εi(i=1,...,n)(8.6)where Riis the measured precipitation at location xi,yiwith elevation hi. A similartrivariate extension can be made to kriging analyses. Trivariate thin plate smoothingspline precipitation analyses have been shown by Hutchinson (1995a) to performsigniﬁcantly better than both bivariate analyses and elevation detrended bivariateanalyses.The accuracy of these analyses depended critically on exaggerating the scale ofelevation in relation to horizontal position by a factor of about 100. If horizontaland elevation coordinates were scaled equally then the trivariate smoothing splineanalysis performed no better than a bivariate analysis. This underlines the importanceof optimizing the vertical scaling in trivariate spline and kriging analyses. Trivariatespline smoothing has been shown to be superior to a local regression method forthe interpolation of both precipitation and temperature data, particularly in datasparse areas (Price, McKenney, Nalder, and Hutchinson 2000). Such analyses canTHO_C08  20/03/2007  14:59  Page 160 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION161also be improved by using elevation data from DEMs at an appropriate horizontalresolution. Several studies have found optimal horizontal resolutions of elevationdependence of precipitation between 4 and 10 km (Schermerhorn 1967, Chuan andLockwood 1974, Daly, Neilson, and Phillips 1994).Figure 8.6 shows a plot of annual mean precipitation overlaid on a digital eleva-tion model of northeastern Queensland in Australia. This model has been calculatedfrom a three-dimensional spline model ﬁtted to measured point precipitation data asa function of horizontal location and elevation. The resulting spatial precipitationpattern is quite complex, due in large measure to the complexity of the underlyingtopography. However, close inspection of the ﬁgure also reveals an underlying relat-ively simple, but spatially varying, dependence on elevation. The relative simplicityof this dependence enables its calibration from data sets of modest size.Limits to complexity of multivariate spatial modelsThere is a fundamental limit to the complexity of multivariate spatial models ﬁtted to",
    "chunk_order_index": 101,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ca6079e1612847464646c96d9f00c6ef": {
    "tokens": 1200,
    "content": "point precipitation data asa function of horizontal location and elevation. The resulting spatial precipitationpattern is quite complex, due in large measure to the complexity of the underlyingtopography. However, close inspection of the ﬁgure also reveals an underlying relat-ively simple, but spatially varying, dependence on elevation. The relative simplicityof this dependence enables its calibration from data sets of modest size.Limits to complexity of multivariate spatial modelsThere is a fundamental limit to the complexity of multivariate spatial models ﬁtted to data. The process indicated above of adding additional predictors, such as elevation and other topographic predictors, to a full multivariate spatial model cannot be continued without limit. Additional predictors rapidly enlarge the spacein which the model is ﬁtted. This is called the curse of dimensionality. In practiceit means that general multivariate functions with no constraints on structure otherthan surface smoothness cannot be ﬁtted to data sets of typical size if the dimensionof the function is more than about four or ﬁve.Fig. 8.6Spline model of annual mean precipitation over topographyTHO_C08  20/03/2007  14:59  Page 161 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f162MICHAEL F. HUTCHINSONThis has led to a variety of multivariate analysis methods that do impose con-straints on the nature of their dependences on additional predictors. These includeadditive tensor product spline models described by Wahba (1990) and additive regression splines (Sharples and Hutchinson 2004). The latter closely resemble local kriging with external drift. A large variety of cokriging methods have also beendeveloped (Chilès and Delﬁner 1999). These methods can be effective provided theconstraints on model structure are consistent with the processes being modeled. Thus Phillips, Dolph, and Marks (1992) found that cokriging of precipitation data with elevation peformed no better than ordinary kriging applied to elevationdetrended precipitation data. Similarly Odeh, McBratney, and Chittleborough(1994) found cokriging methods to perform less well than regression kriging in predicting soil properties in terms of landform attributes derived from a digital elevation model.CONCLUSIONSDigital elevation models play a central role in environmental modeling across a range of spatial scales (see Chapter 23 by Deng, Wilson, Gallant in this volume for additional discussion of numerous environmental modeling applications). Theregular grid mode of representation has become the dominant form for digital elevation models used in these applications. This form is directly compatible withremotely sensed geographic data sources and can simplify terrain-based analyses,including assessments of spatial scale. A distinguishing feature for many applica-tions, particularly those that operate at ﬁner scale, is a primary requirement forinformation about terrain shape and drainage structure, rather than elevation. Forthis reason, elevation contours and streamlines have remained popular sources ofprimary topographic data. They can be used to construct ﬁne scale digital eleva-tion models by gridding methods that are locally adaptive to surface shape anddrainage structure. Remotely sensed digital topographic data, particularly from airborne sensors, are an emerging source of ﬁne scale digital elevation data. Therandom errors associated with these data require appropriate ﬁltering, without degrading shape and drainage structure, to maximize the utility of these data inenvironmental applications, particularly in areas with low relief or with signiﬁcantsurface cover.Locally adaptive gridding procedures can be used to construct digital elevationmodels from digital elevation contours, point elevations and streamlines so that the elevation models preserve terrain shape and drainage structure. Grid resolution can be optimized to match the true information content of the source data and tomaximize the quality of primary terrain parameters derived from the interpolatedDEM. The process of producing a DEM from source data requires careful atten-tion to the accuracy of the source data and the quality of the interpolated DEM.Several shape-based measures of DEM quality, that are readily plotted, can greatlyassist in assessing DEM quality and in detecting data errors. These measures donot require the existence of separate reference elevation data. In particular, remain-ing sinks or depressions in a DEM are an excellent indicator of deﬁciencies in itsrepresentation of terrain shape and drainage structure.THO_C08  20/03/2007  14:59  Page 162 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION163Multivariate smoothing spline and kriging analysis methods of varying complexityhave been used to incorporate dependences on topographic predictors to enhance thespatial analysis and mapping of environmental variables. Climate variables dependenton elevation and soil moisture dependent on various shape-based terrain parametersare common applications. The methods include simple regression and partial splineand detrended kriging methods. These often perform as well or better than morecomplex methods such as various forms of cokriging. Full multivariate spline andkriging models offer the most ﬂexibility and have been successfully applied to thespatial interpolation of precipitation for which there is a spatially varying depend-ence on elevation. Both the relative vertical scale of elevation and its horizontalresolution need to be chosen carefully in such analyses to produce optimal results.Incorporating additional predictors may require im",
    "chunk_order_index": 102,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-87b8100eb02c87f660a40b4032999316": {
    "tokens": 1200,
    "content": "partial splineand detrended kriging methods. These often perform as well or better than morecomplex methods such as various forms of cokriging. Full multivariate spline andkriging models offer the most ﬂexibility and have been successfully applied to thespatial interpolation of precipitation for which there is a spatially varying depend-ence on elevation. Both the relative vertical scale of elevation and its horizontalresolution need to be chosen carefully in such analyses to produce optimal results.Incorporating additional predictors may require imposition of restrictions on modelstructure to avoid the instabilities that can arise with higher dimensional analy-ses. Such methods are still the subject of active investigation. They should be success-ful if the restrictions on model structure are consistent with the spatial processesbeing modeled.REFERENCESAckermann, F. 1978. Experimental investigation into the accuracy of contouring from DTM.Photogrammetric Engineering and Remote Sensing44: 1537–48.Agnew, M. D. and Palutikof, J. P. 2000. GIS-based construction of baseline climatologiesfor the Mediterranean using terrain variables. Climate Research14: 115–27.Akima, H. 1978. A method of bivariate interpolation and smooth surface ﬁtting for irregu-larly distributed data points. ACM Transactions on Mathematical Software4: 148–59.Auerbach, S. and Schaeben, H. 1990. Surface representation reproducing given digitized contour lines. Mathematical Geology22: 723–42.Aumann, G., Ebner, H., and Tang, L. 1992. Automatic derivation of skeleton lines fromdigitized contours. ISPRS Journal of Photogrammetry and Remote Sensing46: 259–68.Aurenhammer, F. 1991. Voronoi diagrams: A survey of fundamental geometric data struc-ture. ACM Computing Surveys23: 345–405.Band, L. E. 1986. Topographic partition of watersheds with digital elevation models. WaterResources Research22: 15–24Bishop, T. F. A. and McBratney, A. B. 2002. Creating ﬁeld extent digital elevation modelsfor precision agriculture. Precision Agriculture3: 37–46.Blöschl, G. and Sivaplan, M. 1995. Scale issues in hydrological modelling: A review.Hydrological Processes9: 313–30.Bolstad, P. V., and Stowe, T. 1994. An evaluation of DEM accuracy: Elevation, slope andaspect. Photogrammetric Engineering and Remote Sensing60: 1327–32.Bourennane, H., King, D., Cherry, P., and Bruand, A. 1996. Improving the kriging of a soilvariable using slope gradient as external drift. Journal of Soil Science47: 473–83.Briggs, I. C. 1974. Machine contouring using minimum curvature. Geophysics39: 39–48.Carter, J. R. 1988. Digital representations of topographic surfaces. PhotogrammetricEngineering and Remote Sensing54: 1577–80.Chilès, J. and Delﬁner, P. 1999. Geostatistics: Modelling Spatial Uncertainty. New York:John Wiley and Sons.Chuan, G. K. and Lockwood, J. G. 1974. An assessment of topographic controls on the distribution of rainfall in the central Pennines. Meteorological Magazine103: 275–87.THO_C08  20/03/2007  14:59  Page 163 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f164MICHAEL F. HUTCHINSONClarke, A. L., Grün, A., and Loon, J. C. 1982. The application of contour data for generatinghigh ﬁdelity grid digital elevation models. InProceedings of Auto Carto 5, Washington, DC,USA. Bethesda, MD: American Congress on Surveying and Mapping/American Society forPhotogrammetry and Remote Sensing, pp. 213–22.Clarke, K. C. 1990. Analytical and Computer Cartography. Englewood Cliffs, NJ: PrenticeHall.Cole, G., MacInnes, S., and Miller, J. 1990. Conversion of contoured topography to digitalterrain data. Computers and Geosciences16: 101–9.Cressie, N. A. C. 1991. Statistics for Spatial Data. New York: John Wiley and Sons.Daly, C., Neilson, R. P., and Phillips, D. L. 1994. A statistical-topography model for mappingclimatological precipitation over mountainous terrain. Journal of Applied Meteorology33:140–58.Day, T. and Muller, J.-P. 1988. Quality assessment of digital elevation models produced by automatic stereo matchers from SPOT image pairs. International Archives of Photo-grammetry and Remote Sensing27: 148–59.Dixon, T. H. 1991. An introduction to the global positioning system and some geologicalapplications. Reviews of Geophysics29: 249–76.Dixon, T. H. 1995. SAR Interferometry and Surface Change Detection.Miami, FL,University of Miami RSMAS Technical Report No. 95-003.Douglas",
    "chunk_order_index": 103,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d251d2d5e8ee2966b2507ad24b65cb3b": {
    "tokens": 1200,
    "content": "ers from SPOT image pairs. International Archives of Photo-grammetry and Remote Sensing27: 148–59.Dixon, T. H. 1991. An introduction to the global positioning system and some geologicalapplications. Reviews of Geophysics29: 249–76.Dixon, T. H. 1995. SAR Interferometry and Surface Change Detection.Miami, FL,University of Miami RSMAS Technical Report No. 95-003.Douglas, D. H. 1986. Experiments to locate ridges and channels to create a new type ofdigital elevation model. Cartographica23: 29–61.Ebner, H., Reinhardt, W., and Hössler, R. 1988. Generation, management and utilizationof high ﬁdelity digital terrain models. International Archives of Photogrammetry and RemoteSensing27: 556–65.Famiglietti, J. S., Rudnicki, J. W., and Rodell, M. 1998. Variability in surface moisture alonga hillslope transect: Rattlesnake Hill, TX. Journal of Hydrology210: 259–81.Feddes, R. A. 1995. Space and Time Scale Variability and Interdependencies in HydrologicalProcesses. Cambridge, Cambridge University Press.Flood, M. 2001. Laser altimetry: From science to commercial LiDAR mapping. Photo-grammetric Engineering and Remote Sensing67: 1209–18.Franke, R. 1982. Smooth interpolation of scattered data by local thin plate splines. Computersand Mathematics with Applications8: 273–81.Frederiksen, P., Jacobi, O., and Kubik, K. 1985. A review of current trends in terrain modelling.ITC Journal1985: 101–6.Gallant, J. C. and Dowling, T. I. 2003. A multiresolution index of valley bottom ﬂatnessfor mapping depositional areas. Water Resources Research39: 1347–60.Garbrecht, J. and Starks, P. 1995. Note on the use of USGS level 1 7.5-minute DEM coverages for landscape drainage analyses. Photogrammetric Engineering and Remote Sensing61: 519–22.Gessler, P. E., Moore, I. D., McKenzie, N. J., and Ryan, P. J. 1995. Soil-landscape modelling and spatial prediction of soil attributes. International Journal of GeographicInformation Systems9: 421–32.Giles, P. T. and Franklin, S. E. 1996. Comparison of derivative topographic surfaces of aDEM generated from stereographic SPOT images with ﬁeld measurements. PhotogrammetricEngineering and Remote Sensing62: 1165–71.Goodchild, M. F. and Mark, D. M. 1987. The fractal nature of geographic phenomena.Annals Association of American Geographers77: 265–78.Harding, D. J., Bufton, J. L., and Frawley, J. 1994. Satellite laser altimetry of terrestrial topo-graphy: Vertical accuracy as a function of surface slope, roughness and cloud cover. IEEE Transactions on Geoscience and Remote Sensing32: 329–39.Heller, M. 1990. Triangulation algorithms for adaptive terrain modelling. In Proceedings ofthe Fourth International Symposium on Spatial Data Handling, Columbus, OH: 163–74.THO_C08  20/03/2007  14:59  Page 164 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION165Hobbs, F. 1995. The rendering of relief images from digital contour data. Cartographic Journal32: 111–6.Houser, P., Hutchinson, M. F., Viterbo, P., Herve Douville, J., and Running, S. W. 2004.Terrestrial data assimilation. In P. Kabat, M. Claussen, P. A. Dirmeyer, J. H. C. Gash, L. Bravo de Guenni, M. Meybeck, R. S. Pielke, C. J. Vörösmarty, R. W. A. Hutjes, andS. Lütkemeier (eds) Vegetation, Water, Humans and the Climate: A New Perspective onan Interactive System. Berlin: Springer-Verlag, pp. 273–87.Hunter, G. J. and Goodchild, M. F. 1995. Dealing with error in spatial databases: A simplecase study. Photogrammetric Engineering and Remote Sensing61: 529–37.Hutchinson, M. F. 1988. Calculation of hydrologically sound digital elevation models. InProceedings of the Third International Symposium on Spatial Data Handling, Sydney,Australia. Columbus, OH: International Geographical Union, pp. 117–33.Hutchinson, M. F. 1989. A new procedure for gridding elevation and streamline data withautomatic removal of spurious pits. Journal of Hydrology106: 211–32.Hutchinson, M. F. 1995a. Interpolation of mean rainfall using thin plate smoothing splines.International Journal of Geographic Information Systems9: 385–403",
    "chunk_order_index": 104,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d3bb1b3cc5ac4c515db6f2d02a8d6962": {
    "tokens": 1200,
    "content": "Spatial Data Handling, Sydney,Australia. Columbus, OH: International Geographical Union, pp. 117–33.Hutchinson, M. F. 1989. A new procedure for gridding elevation and streamline data withautomatic removal of spurious pits. Journal of Hydrology106: 211–32.Hutchinson, M. F. 1995a. Interpolation of mean rainfall using thin plate smoothing splines.International Journal of Geographic Information Systems9: 385–403.Hutchinson, M. F. 1995b. Stochastic space–time weather models from ground-based data.Agricultral and Forest Meteorology73: 237–64.Hutchinson, M. F. 1996. A locally adaptive approach to the interpolation of digital elevationmodels. In Proceedings of the Third International Conference/Workshop on IntegratingGIS and Environmental Modeling, Santa Barbara, CA: National Center for GeographicInformation and Analysis: CD-ROM.Hutchinson, M. F. 1998. Interpolation of rainfall using thin plate smoothing splines: II, Analysisof topographic dependence. Journal of Geographic Information and Decision Making 2:168–85.Hutchinson, M. F. 2000. Optimising the degree of data smoothing for locally adaptive ﬁniteelement bivariate smoothing splines. ANZIAM Journal42: C774–96.Hutchinson, M. F. 2003. ANUSPLIN Version 4.3. WWW document, http://cres.anu.edu.au/outputs/anusplin.php.Hutchinson, M. F. 2006. ANUDEM Version 5.2. WWW document, http://cres.anu.edu.au/outputs/anudem.php.Hutchinson, M. F. and Dowling, T. I. 1991. A continental hydrological assessment of a new grid-based digital elevation model of Australia. Hydrological Processes5: 45–58.Hutchinson, M. F. and Gallant, J. C. 1999. Representation of terrain. In P. A. Longley, M. F. Goodchild, D. J. Maguire, and D. W. Rhind (eds) Geographical Information Systems:Principles, Techniques, Applications, and Management.New York: John Wiley and Sons,pp. 105–24.Hutchinson, M. F. and Gallant, J. C. 2000. Digital elevation models and representation of terrain shape. In J. P. Wilson and J. C. Gallant (eds) Terrain Analysis.New York: JohnWiley and Sons, pp. 29–50.Hutchinson, M. F. and Gessler, P. T. 1994. Splines: More than just a smooth interpolator.Geodema62: 45–67.Jarvis, C. H. and Stuart, N. 2001a. A comparison between strategies for interpolating maximum and minimum daily air temperatures: A, The selection of “guiding” topo-graphic and land cover variables. Journal of Applied Meteorology 40: 1060–74.Jarvis, C. H. and Stuart, N. 2001b. A comparison between strategies for interpolating maximum and minimum daily air temperatures: B, The interaction between number ofguiding variables and the type of interpolation method. Journal of Applied Meteorology40: 1075–84.Jenson, S. K. 1991. Applications of hydrologic information automatically extracted from digital elevation models. Hydrological Processes5: 31–44.THO_C08  20/03/2007  14:59  Page 165 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f166MICHAEL F. HUTCHINSONJenson, S. K. and Domingue, J. O. 1988. Extracting topographic structure from digital elevation data for geographic information system analysis. Photogrammetric Engineeringand Remote Sensing54: 1593–600.Kelly, R. E., McConnell, P. R. H., and Mildenberger, S. J. 1977. The Gestalt photomappingsystem. Photogrammetric Engineering and Remote Sensing43: 1407–17.Kieffer Weisse, A. and Bois, P. 2001. Topographic effects on statistical characteristics of heavy rainfall and mapping in the French Alps. Journal of Applied Meteorology40: 720–40.Konecny, G., Lohmann, P., Engel, H., and Kruck, E. 1987. Evaluation of SPOT imagery onanalytical instruments. Photogrammetric Engineering and Remote Sensing53: 1223–30.Kryiakidis, P. C., Kim, J., and Miller, N. L. 2001 Geostatistical mapping of precipitationfrom rain gauge data using atmospheric and terrain characteristics. Journal of AppliedMeteorology40: 1855–77.Lanari, R., Fornaro, G., Riccio, D., Migliaccio, M., Papathanassiou, K., Moreira, J.,Schwäbisch, M., Dutra, L., Puglisi, G., Franceschetti, G., and Coltelli, M. 1997. Generationof digital elevation models by using SIR-C/X-SAR multifrequency two-pass interferometry:The Etna case study. IEEE Transactions on Geoscience and Remote Sensing34",
    "chunk_order_index": 105,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0b0581688c2cb6de7e8a3cff9f054769": {
    "tokens": 1200,
    "content": "Fornaro, G., Riccio, D., Migliaccio, M., Papathanassiou, K., Moreira, J.,Schwäbisch, M., Dutra, L., Puglisi, G., Franceschetti, G., and Coltelli, M. 1997. Generationof digital elevation models by using SIR-C/X-SAR multifrequency two-pass interferometry:The Etna case study. IEEE Transactions on Geoscience and Remote Sensing34: 1097–114.Lane, S. N. and Chandler, J. H. 2003. The generation of high quality topographic data forhydrology and geomorphology: New data sources, new applications and new problems.Earth Surface Processes and Landforms28: 229–30.Lange, A. F. and Gilbert, C. 1998. Using GPS for GIS data capture. In P. A. Longley, M.F. Goodchild, D. J. Maguire, and D. W. Rhind (eds) Geographical Information Systems:Principles, Techniques, Applications and Management.ChichesterL: John Wiley and Sons,pp. 467–76.Lee, J. 1991. Comparison of existing methods for building triangular irregular network models of terrain from grid digital elevation models. International Journal of GeographicInformation Systems5: 267–85.Legates, D. R. and Willmott, C. J. 1986. Interpolation of point values from isoline maps.American Cartographer13: 308–23.Lemmens, M. J. P. M. 1988. A survey on stereo matching techniques. International Archivesof Photogrammetry and Remote Sensing27: V11–V23.Maas, H.-G. 2002. Methods for measuring height and planimetry discrepancies in airbornelaserscanner data. Photogrammetic Engineering and Remote Sensing68: 933–40.Mackay, D. S. and Band, L. E. 1998. Topographic partitioning of watersheds with lakesand other ﬂat areas on digital elevation models. Water Resources Research34: 897–901.Mackey, B. G. 1996. The role of GIS and environmental modelling in the conservation of biodiversity. In Proceedings of the Third International Conference/Workshop onIntegrating GIS and Environmental Modeling.Santa Barbara, CA: National Center forGeographic Information and Analysis: CD-ROM.Mark. D. M. 1986. Knowledge-based approaches for contour-to-grid interpolation ondesert pediments and similar surfaces of low relief. In Second International Symposiumon Spatial Data Handling, Seattle, WA, USA. Columbus, OH: International GeographicalUnion, pp. 225–34.Makarovic, B. 1984. Structures for geo-information and their application in selective sampling for digital terrain models. ITC Journal1984: 285–95.McCullagh, M. J. 1988. Terrain and surface modelling systems: theory and practice.Photogrammetric Record12: 747–79.Michaud, J. D., Auvine, B. A., and Penalba, O. C. 1995. Spatial and elevational variationsof summer rainfall in the southwestern United States. Journal of Applied Meteorology34:2689–703.THO_C08  20/03/2007  14:59  Page 166 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING THE Z DIMENSION167Mitasova, H. and Mitas, L. 1993. Interpolation by regularised spline with tension: I. Theoryand implementation. Mathematical Geology25: 641–55.Mitasova, H., Hoﬁerka, J., Zlocha, M., and Iverson, L. 1996. Modelling topographic potentialfor erosion and deposition using GIS. International Journal of Geographical InformationSystems10: 629–41.Mizukoshi, H. and Aniya, M. 2002. Use of contour-based DEMs for deriving and mappingtopographic attributes. Photogrammetric Engineering and Remote Sensing68: 83–93.Moore, I. D., O’Loughlin, E. M., and Burch, G. J. 1988. A contour-based topographic modelfor hydrological and ecological applications. Earth Surface Processes and Landforms13:305–20.Moore, I. D., Grayson, R. B., and Ladson, A. R. 1991. Digital terrain modelling: A reviewof hydrological, geomorphological and biological applications. Hydrological Processes5: 3–30.Nalder, I. A. and Wein, R. W. 1998. Spatial interpolation of climatic normals: Test of anew method in the Canadian boreal forest. Agricultural and Forest Meteorology92: 211–25.Nix, H. A. 1986. A biogeographic analysis of Australian elapid snakes. In R. Longmore (ed.) Atlas of Elapid Snakes of Australia. Canberra, Australian Flora and Fauna SeriesNo.7: 4–15.Odeh, I. O. A., McBratney, A. B., and Chittleborough, D. J. 1994. Spatial prediction of soilproperties from landform attributes derived from a digital elevation model. Geoderma63: 197–214",
    "chunk_order_index": 106,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-8a8f6417ced821faabf523f3232d2ef2": {
    "tokens": 1200,
    "content": "biogeographic analysis of Australian elapid snakes. In R. Longmore (ed.) Atlas of Elapid Snakes of Australia. Canberra, Australian Flora and Fauna SeriesNo.7: 4–15.Odeh, I. O. A., McBratney, A. B., and Chittleborough, D. J. 1994. Spatial prediction of soilproperties from landform attributes derived from a digital elevation model. Geoderma63: 197–214.Oswald, H. and Raetzsch, H. 1984. A system for generation and display of digital elevationmodels. Geo-Processing2: 197–218.Phillips, D. L., Dolph, J., and Marks, D. 1992. A comparison of geostatistical proceduresfor spatial analysis of precipitation in mountainous terrain. Agricultural and ForestMeteorology58: 119–41.Price, D. T., McKenney, D. W., Nalder, I. A., and Hutchinson, M. F. 2000. A comparisonof two statistical methods for spatial interpolation of Canadian monthly mean climate data.Agricultural and Forest Meteorology101: 81–94.Qiu, Y., Fu, B., Wang, J., and Chen, L. 2001. Spatial variability of soil moisture contentand its relation to environmental indices in a semi-arid gully catchment of the Loess Plateau,China. Journal of Arid Environments.49: 723–50.Quinn, P., Beven, K., Chevallier, P., and Planchon, O. 1991. The prediction of hillslope ﬂowpaths for distributed hydrological modelling using digital terrain models. HydrologicalProcesses5: 59–79.Running, S. W. and Thornton, P. E. 1996. Generating daily surfaces of temperature andprecipitation over complex topography. In M. F. Goodchild, L. T. Steyaert, B. O. Parks,C. Johnston, D. Maidment, M. Crane, and S. Glendinning (eds) GIS and EnvironmentalModeling: Progress and Research Issues. Fort Collins, CO: GIS World Books, pp. 93–8.Sambridge, M., Braun, J., and McQueen, H. 1995. Geophysical parameterization and inter-polation of irregular data using natural neighbours. Geophysical Journal International:122: 837–57.Sasowsky, K. C., Peterson, G. W., and Evans, B. M. 1992. Accuracy of SPOT digital eleva-tion model and derivatives: utility for Alaska’s North Slope. Photogrammetric Engineeringand Remote Sensing58: 815–24.Schermerhorn, V. P. 1967. Relations between topography and annual precipitation in westernOregon and Washington. Water Resources Research3: 707–11.Schimek, M. G. (ed.). 2000. Smoothing and Regression: Approaches, Computation andApplication.New York: John Wiley and Sons.Sharples, J. J. and Hutchinson, M. F. 2004. Multivariate spatial smoothing using additiveregression splines. ANZIAM Journal45: C676–92.THO_C08  20/03/2007  14:59  Page 167 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f168MICHAEL F. HUTCHINSONSibson, R. 1981. A brief description of natural neighbour interpolation. In V. Barnett (ed.)Interpreting Multivariate Data.Chichester: John Wiley and Sons, pp. 21–36.Sivaplan, M., Grayson, R., and Woods, R. 2004. Scale and scaling in hydrology. HydrologicalProcesses18: 1369–71.Smith, W. H. F. and Wessel, P. 1990. Gridding with continuous curvature. Geophysics55:293–305.Soille, P., Vogt, J., and Colombo, R. 2003. Carving and adaptive drainage enforcement ofgrid digital elevation models. Water Resources Research39: 1366–75.Tsai, V. 1993. Delauney triangulations in TIN creation: An overview and linear-time algorithm. International Journal of Geographical Information Systems7: 501–24.USGS, 2005. Shuttle Radar Topography Mission: Mapping the World in Three Dimensions.WWW document, http://srtm.usgs.gov.Wahba, G. 1990. Spline Models for Observational Data. Philadelphia: SIAM.Watson, D. F. and Philip, G. M. 1984. Triangle based interpolation. Mathematical Geology16: 779–95Weibel, R. and Brändl, M. 1995. Adaptive methods for the reﬁnement of digital terrain modelsfor geomorphometric applications. Zeitschrift für Geomorphologie, Supplementband 101:13–30.Weibel, R. and Heller, M. 1991. Digital terrain modelling. In D. J. Maguire, M. F. Goodchild,and D. W. Rhind (eds) Geographical Information Systems: Principles and Applications.Harlow: Longman: 269–97.Western, A. W., Grayson,",
    "chunk_order_index": 107,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e86be8e9dbf6b178ef79011e6822c909": {
    "tokens": 1200,
    "content": "nement of digital terrain modelsfor geomorphometric applications. Zeitschrift für Geomorphologie, Supplementband 101:13–30.Weibel, R. and Heller, M. 1991. Digital terrain modelling. In D. J. Maguire, M. F. Goodchild,and D. W. Rhind (eds) Geographical Information Systems: Principles and Applications.Harlow: Longman: 269–97.Western, A. W., Grayson, R. B., Blöschl, G., Willgoose, G. R., and McMahon, T. A. 1999.Observed spatial organization of soil moisture and its relation to terrain indices. WaterResources Research35: 797–810.Wilson, J. P. and Gallant, J. C. (eds). 2000. Terrain Analysis: Principles and Applications.New York: John Wiley and Sons.Wise, S. 1998. The effect of GIS interpolation errors on the use of digital elevation modelsin geomorphology. In S. N. Lowe, K. S. Richards, and J. H. Chandler (eds). LandformMonitoring, Modelling and Analysis.Chichester: John Wiley and Sons, pp. 139–64.Wise. S. 2000. Assessing the quality for hydrological applications of digital elevation modelsderived from contours. Hydrological Processes14: 1909–29.Zebker, H. A., Werner, C., Rosen, P. A., and Hensley, S. 1994. Accuracy of topographicmaps derived from ERS-1 interferometric radar. IEEE Transactions on Geoscience andRemote Sensing32: 823–36.Zhang, W. and Montgomery, D. R. 1994. Digital elevation model grid size, landscape representation, and hydrologic simulation. Water Resources Research30: 1019–28.Zhu, H., Eastman, R., and Toledano, J. 2001. Triangulated irregular network optimiza-tion from contour data using bridge and tunnel edge removal. International Journal ofGeographic Information Science15: 271–86.THO_C08  20/03/2007  14:59  Page 168 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 9Adding Time into GeographicInformation System DatabasesMay YuanDespite substantial advances, Geographic Information Systems (GIS) technology still lacks the ability to handle geospatial information of all kinds. One of the mostsigniﬁcant and long-standing issues is integration of spatial and temporal data andsupport for spatio-temporal analysis. Nevertheless, time is central to geographic inquiryand understanding, and the signiﬁcance of adding time to GIS databases cannot beover-stated. John Jakle argues that “it is doubtful...that geography can continueits search for spatial understanding by ignoring the integral dictates of time and spaceas a natural unity; thus have geographers come to focus on the processes of spatialorganization through time” (Jakle 1972). While the need to incorporate temporaldata is common to many information systems, the challenge is arguably much greaterin GIS because space and time in geography are interrelated. Consequently, spatio-temporal information about geography cannot be fully captured by simply addingan attribute ﬁeld “time” in a GIS database. Much research progress has been madein temporal GIS since the 1980s. However, a temporal GIS that is considered suf-ﬁciently robust to support spatio-temporal information management, query, analysis,and modeling has still to be developed.Challenges to the development of a full-ﬂedged temporal GIS arise deep withinthe conceptual, computational, and presentational foundations of GIS. Conceptually,we need an ontology to categorize and communicate spatio-temporal concepts; weneed GIS representations that can capture and frame these concepts; and, further-more, we need spatio-temporal data models to organize geographic data so thatspatio-temporal concepts can be computed and extracted from temporal GIS data-bases. Computationally, we need query languages to manipulate spatio-temporaldata and retrieve information about space, time, and geographic dynamics; we need spatio-temporal logic to reason about geographic dynamics and their relation-ships; and we need analytical and modeling frameworks to examine spatio-temporaldata and make predictions or retrospections in space and time. At the presentationlevel, we need means to visually communicate the multi-dimensional and dynamicnature of spatial change through time. The challenges demand a fundamental andcomprehensive examination of the underlying design of GIS and innovative waysto integrate spatial and temporal information.THO_C09  19/03/2007  11:19  Page 169 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f170MAY YUANThe focus of this chapter is on the conceptual foundations of adding time into GISdatabases. A sound conceptual foundation serves as the bedrock for computationaland presentational advances because modes of computation and presentation relyheavily upon what data are available in what form and structure. Ontology, repres-entation, and data models constitute the conceptual foundations for any informationsystem. The three conceptual components correspond to three stages of conceptual",
    "chunk_order_index": 108,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7029051320b295d0cd30f540d191ddaa": {
    "tokens": 1200,
    "content": "OA articles are governed by the applicable Creative Commons License\f170MAY YUANThe focus of this chapter is on the conceptual foundations of adding time into GISdatabases. A sound conceptual foundation serves as the bedrock for computationaland presentational advances because modes of computation and presentation relyheavily upon what data are available in what form and structure. Ontology, repres-entation, and data models constitute the conceptual foundations for any informationsystem. The three conceptual components correspond to three stages of conceptual-ization, identifying: (1) the elements that need to be considered (ontology); (2) theframeworks in which the identiﬁed elements will be best abstracted (representation);and (3) the structures with which the abstracted elements can be best organized(data models). In addition, spatio-temporal query is the means to retrieve data ofinterest for visualization and analysis. What we can do with an information systemdepends upon what we can access from the system. Hence, spatio-temporal queryis critical to the value of a temporal GIS. The following sections, therefore, focuson key developments in spatio-temporal ontologies, representation, data modeling,and spatio-temporal queries. The concluding section then summarizes the currentstate of temporal GIS and directions for future research.Ontologies of Space, Time, and Space-timeOntology, with its early ties to philosophy and linguistics, is “the metaphysical studyof the nature of Being and Existence” (Fellbaum 1998). From the perspective ofinformation science, it is the study of fundamental elements, concrete or abstract, inour world. Since a database is built upon identiﬁed views of the world, which canbe generic or application-speciﬁc, the ontology chosen dictates the kinds of informa-tion that will be stored in and made available from the database. A closely relatedterm to ontology is “semantics.” Generally speaking, semantic modeling stays closeto an identiﬁed database application while ontology goes beyond the immediateconcern of an application. Ontology describes elements of knowing and the basicmodes of description that distinguishes one element from the other (Peuquet 2002).Philosophically, there should be only one ontology since there is only one world.Nevertheless, studies show that ontology is tied to human cognition (Mark, Smith,and Tversky 1999), and people may hold distinct conceptualizations of the world, andformal ontologies that deal with interconnections of things (Smith 1998) play a keyrole in determining methodological and architectural design of information systems(Guarino 1998).In GIS, ﬁeld- and object-based conceptualizations of space assign reality into twodivergent sets of concrete and abstract kinds in geography (Couclelis 1992). Onto-logy of objects appears more intuitive to human cognition (Smith and Mark 1998,Mark, Smith, and Tversky 1999), while ontology of ﬁelds seems more compatible toscientiﬁc computation and mathematical modeling (Peuquet, Smith, and Brogaard1998). In addition, testing of human subjects suggests that natural features (for example, mountain, river, lake, ocean, hill, etc.) receive higher ontological recogni-tion than artiﬁcial features (for instance, town, city, etc.); furthermore, adjectives thatqualify something as geographic or mappable can inﬂuence responses to questionsof Being and Existence in geography (Mark, Skupina, and Smith 2001, Smith andMark 2001). The dichotomy the of ﬁeld- and object-views of the world is challengedTHO_C09  19/03/2007  11:19  Page 170 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING TIME INTO GIS DATABASES171by Yuan, Cova, and Goodchild who argue that many geographic phenomena exhibitboth ﬁeld- and object-like properties (Yuan 2001), and locations in a ﬁeld can beassociated with various objects (Cova and Goodchild 2002). Additional beings: f-objects and o-ﬁelds, are thus introduced.Likewise, elements of Being and Existence in time depend upon how time is con-ceptualized. Most GIS consider time as instantaneous and discrete beings since GISdata are valid at different instants (Frank 1997): this is the so-called SNAP viewof the world (Grenon and Smith 2004). Various time onotologies are possible becausetime can be bounded or unbounded, absolute or relative, discrete or continuous, ofdifferent types (for instance, linear, cyclic), of different dimensions (for example,points, intervals), and of different meanings (such as valid time and transition time)(Worboys 1990, 1994, Frank 1998, Raper 2000).Moreover, some temporal ontologies have been developed, not based on con-ceptualization of time per se, but based on how time is perceived and manifestsitself in reality. Time has long been related to cause and effect (Ullman 1974) andcan be considered as the abstraction of all relations of sequence (Feather 1959).Accordingly, Terenziani (1995) develops a causal ontology that accounts for tem-poral constraints between causes and effects. Another important mode of time isrepeatability, which is common to many natural phenomena (Frank 1998). Basedon return periods, repeatability can be intermittent or",
    "chunk_order_index": 109,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-181d1bf68d4401a78136057a96ac6e2d": {
    "tokens": 1200,
    "content": "self in reality. Time has long been related to cause and effect (Ullman 1974) andcan be considered as the abstraction of all relations of sequence (Feather 1959).Accordingly, Terenziani (1995) develops a causal ontology that accounts for tem-poral constraints between causes and effects. Another important mode of time isrepeatability, which is common to many natural phenomena (Frank 1998). Basedon return periods, repeatability can be intermittent or periodic. Terenziani (2002),furthermore, develops another ontology based on ﬁrst-order logic to deal with user-deﬁned periodicity and temporal constraints about repeated events.The degree of complexity increases exponentially with the development of an ontology of space and time. Compared to ontologies of non-temporal domains, Frank (2003) argues that an ontology of space and time should be more involvedin and has a stronger connection to the intended area of application. There are two alternative ways to handle space and time: SNAP considers successions of instantaneous snapshots of the world and SPAN, which is based on a uniﬁed viewof the spatio-temporal (Grenon and Smith 2004). SNAP entities are indexed at acertain point in time, which implies that these entities may have existed and willcontinue to exist for some time. Nevertheless, the SNAP ontology only recognizesexistence at a deﬁned instant, and consequently, SNAP entities have no temporalparts. Comparison of two instants results in changeof entity sets. Currently, a common approach to the treatment of spatio-temporal data in GIS is to follow the SNAP ontology. This is because GIS only recognizes a data object on the datalayer on which the object is indexed and considers objects on different data layersas different even if they represent the same geographic feature at different times.A SPAN entity, on the other hand, consists of temporal parts which constitute itshistory or lifeline. Because the SPAN ontology considers the continuum of an entityover space and time, additional concepts about spatio-temporal dynamics emerge,such as movement, vibration, sprawl, contraction, and deformation.While SNAP and SPAN offer a succinct ontological view of spatio-temporal Beings,they do not cope with the ontological complexity that arises from the relations amongreality, observation, application (purpose), societal constraint, and cognition. Toaccount for the ontological complexity, Frank (2003) proposes a ﬁve-tier ontologyto describe spatio-temporal things with uniform spatial properties, such as land parcels.The ﬁve tiers correspond to a transition from physical reality that exists externallyTHO_C09  19/03/2007  11:19  Page 171 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f172MAY YUANand objectively towards cognitive agents who extract knowledge from the perceivedas listed below (adopted from Table 2.1 in Frank 2003):1Ontological Tier 0: Physical Reality•The existence of a single physical reality•Determined properties for every point in time and space•Space and time as fundamental dimensions of this reality2Ontological Tier 1: Observable Reality•Properties are observable now at a point in space•Real observations are incomplete, imprecise, and approximate3Ontological Tier 2: Object World•Objects are deﬁned by uniform properties for regions in space and time•Objects continue in time4Ontological Tier 3: Social Reality•Social processes construct external names•Social rules create facts and relationships between them•Social facts are valid within the social context only5Ontological Tier 4: Cognitive Agents•Agents use their knowledge to derive other facts and make decisions•Knowledge is acquired gradually and lags behind reality•Reconstruction of previous states of the knowledgebase is required in legaland administrative processesThe ﬁve-tier ontology recognizes the existence of the physical reality independent ofobservers and human constructs derived from observations, generalization, socialmanipulation, and cognition. Such recognition allows philosophical integration ofpositivist views (Tier 0) to post-modern positions (Tier 3), discerning differences andpromoting understanding. Within each tier, modes of Being can be deﬁned by con-sidering existence in space and time, measurements of existence, traces of existence,and social settings of existence.Since each formal ontology of space and time circumscribes the conceptual boundof reality that will be considered in an information system, subscription to an onto-logy determines what should be represented and coded in a temporal GIS.Spatio-temporal Representation and Data ModelingGIS representation has followed the map metaphor that depicts geographic features asa set of static objects residing in a two-dimensional planar space. Hence, all geographicfeatures are represented as static, 2D, and geometrically ﬁxed objects. Comparable toSNAP entities, every object in 2D, static GIS is valid at a certain point in time, andobjects indexed at different times are independent from each other even if they repres-ent the same geographic entity in the world. While ﬁeld-based representation concernsonly properties at locations, rather than objects, the fact that properties are valid onlyat the time of measurement denotes the map-based and SNAP-nature of ﬁelds.Map-based representation also limits the ways that we can analyze data in a GIS.While map-based representation greatly facilitates spatial overlay to reveal spatialTHO_C09  19/03/2007  11:19  Page 172 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley",
    "chunk_order_index": 110,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-01b83d46754da2649b6335487c6a67cd": {
    "tokens": 1200,
    "content": "locations, rather than objects, the fact that properties are valid onlyat the time of measurement denotes the map-based and SNAP-nature of ﬁelds.Map-based representation also limits the ways that we can analyze data in a GIS.While map-based representation greatly facilitates spatial overlay to reveal spatialTHO_C09  19/03/2007  11:19  Page 172 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING TIME INTO GIS DATABASES173relationships among geographic variables, problems occur when we try to perform3D analysis or dynamic modeling. Three-dimensional visualization techniques can-not fully solve the problem because a true 3D application requires information thatcan only be derived from analyzing 3D topological relationships beyond simple visualizing 3D volumes of data. For example, a GIS must have capabilities to com-pute information about adjacency in vertical space to answer a 3D query for areaswhere sandstone lies on top of shalestone layers. Topological integrity forms the basicoperations to manipulate and analyze data in 2D, 3D, or 4D GIS (Hazelton 1998)and cannot be overlooked in spatio-temporal representation. In addition, geographicfeatures must be represented in ways that conform to proper analytic methods (Yuan,Mark, Peuquet, and Egenhofer 2004). For example, routing analysis requires a topo-logically sound transportation network with nodes representing cities or stops, whiledistributed modeling requires surface conditions to be represented in a grid to repres-ent properties at regular and pre-deﬁned locations (cells). These two representationshave become known as feature and location-based representations, respectively, corresponding to object- and ﬁeld-based ontologies. In addition, numerous regularand irregular tessellation models are used to represent the geographic space of ﬁelds(Frank and Mark 1991). Peuquet (1984) gives a penetrating analysis of conceptualframeworks used in GIS to represent geographic phenomena in a two-dimensionalspace. Abraham and Roddick (1996) offer a comprehensive review of spatio-temporaldatabases developed by computer scientists and GI scientists.However, geographic worlds are neither static nor planar. Incorporation of tem-poral components into a representation is not a trivial task because space and timehave distinctive differences in philosophical, computational, and cognitive concerns,from which grows the complexity of spatio-temporal representation (Peuquet 2002).Since the mid- to late-1980s, researchers in both GIS and database management havebeen examining ways to incorporate time into information systems (Figures 9.1 and 9.2). In relational databases, the time-stamping method appears to be the mostpopular treatment of time by attaching time to a table or relation (Gadia and Vaishnav1985), to a data object or tuple (Snodgrass and Ahn 1986), or to an attribute valueor a cell (Gadia and Yeung 1988). In these time-stamp approaches, time is con-sidered an intrinsic part of data and is attached by the information system auto-matically during data entry (Erwig, Guting, and Schneider 1999). An informationsystem may stamp its data with valid time (historical databases), transaction time(rollback databases), or both (bitemporal databases). Historical databases denotewhen the data is valid in the real world. On the other hand, transaction databasesallow retrospection of when data values were validated in the database so that datacan be rolled back for editing or revisions. While the time stamp approach seems toserve non-spatial database systems well, it quickly reaches its limits when situationsinvolve changes in space andtime. Nevertheless, the time-stamping approach is simple to conceptualize and implement and, therefore, remains popular for addingtime to GIS databases.In GIS, time-stamping techniques have been applied to layers in the snapshot model,to attributes in the space-time composite model (Langran and Chrisman 1988), or tospatial objects in the spatio-temporal objects model (Worboys 1994). Different fromthe temporal databases discussed earlier, time stamps are given by the user, not thesystem, to cope with the fact that new data objects may be created from the oldTHO_C09  19/03/2007  11:19  Page 173 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f174MAY YUANobjects over time (Erwig, Guting, and Schneider 1999). While the snapshot modelpresents the simplest way to incorporate time with space, it encounters problemsof data redundancy and possible data inconsistency, especially in dealing with largedata sets. The space-time composite model can eliminate these problems to a degree,but it has problems keeping spatial object identiﬁers persistent because updatingspace-time composites can cause fragmentation of existing spatial objects (Langranand Chrisman 1988). On the other hand, the spatio-temporal object model is ableto maintain spatial object identiﬁers, but it, as in all time-stamping approaches, hasdifﬁculty representing dynamic information, such as transition, motion, and processes.1993County Population Avg. IncomeNixonClevelandOklahoma17,00020,",
    "chunk_order_index": 111,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-464f766f57f65d646a7947ac3b49ef1f": {
    "tokens": 1200,
    "content": "object identiﬁers persistent because updatingspace-time composites can cause fragmentation of existing spatial objects (Langranand Chrisman 1988). On the other hand, the spatio-temporal object model is ableto maintain spatial object identiﬁers, but it, as in all time-stamping approaches, hasdifﬁculty representing dynamic information, such as transition, motion, and processes.1993County Population Avg. IncomeNixonClevelandOklahoma17,00020,0001994County Population Avg. IncomeNixonClevelandOklahoma20,00035,00019,80032,0001995County Population Avg. IncomeNixonClevelandOklahoma20,90035,00086,00021,00032,00028,000a. Time-stamped tables (Gadia and Vaishnav 1985).b. Time-stamped tuples (rows): an ungrouped relation (Snodgrass and Ahn 1985).c. Time-stamp values (cells): a group relation    (Gadia and Yeung 1988). [11, 60] represents    a period starting at T11 and ending at T60.StockIBMIBMIBMIBMPrice16191625To10-15-91  4:35pm10-30-91  4:57pm11-2-91  12:53pm11-5-91    2:02pmFrom10-7-9110:07am10-15-914:35pm10-30-914:57pm11-2-9112:53pm         Name[11,60] John[0,20] U [41,51]Tom[0,44] U [50, Now]Mary     Department[11,44] Toys[45, 60] Shoes[0, 20] Hardware[41, 51] Clothing[0,44] U [50, Now]Credit     Salary[11, 49] 15K[50, 54] 20K[55, 60] 25K[0, 20] 20K[41, 51] 30K[0,44] U [50,Now] 25KFig. 9.1Examples of representations of temporal information in a relational data model Adopted from Yuan 1999THO_C09  19/03/2007  11:19  Page 174 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING TIME INTO GIS DATABASES175Geographic information cannot be extracted from a system where the informationcannot be represented. Hence, data models developed using the time-stampingapproaches are incapable of supporting spatio-temporal queries about informa-tion on the dynamic characteristics of geographic processes, including movement,rate of movement, frequency, and interactions among processes. Geographic repres-entation “must deal with actual processes, not just the geometry of space-time”(Chrisman 1998).The most recent work on GIS representation has emphasized representation of dyn-amic processes. These models include Peuquet and Duan’s (1995) event-based spatio-temporal data model (ESTDM), Raper and Livingstone’s (1995) geomorphologica. Time-stamped layers (Armstrong 1988).b. Time-stamped attributes (columns): Space-Time Composites (Langran and Chrisman 1988).c. Time-stamped space-time objects: the spatiotemporal object model    (Worboys 1994).12345Poly id12345T1RuralRuralRuralRuralRuralT2RuralUrbanRuralRuralRuralT3RuralUrbanUrbanUrbanRuralT4RuralUrbanUrbanUrbanUrbanUT1T1t1t2t3T2T3S1S1S2S2S2T2T3t1t1t2t2t2t2t3t3t3UST-objects modelingregional changeDecomposition ofST-objects (U, T, and S)into 6 ST-atoms (U, T1,T2, T3, S1, and S2).UrbanAgricultureIndustryUTSTnT2T1Fig. 9.2Examples of representations of spatio-temporal information in a GIS environmentAdopted from Yuan 1999THO_C09  19/03/2007  11:19  Page 175 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f176MAY YUANspatial model (OOgeomorph), and Yuan’s (1994, 1999) three-domain model. ESTDMis conceptually simple and easily adaptable to other raster-based systems to representinformation about locational changes at pre-deﬁned cells alongthe passage of anevent. Central to ESTDM is a chain of vectors that changes at locations (cells) ona raster of a single theme (such as temperature). While the model has shown itsefﬁciency and capability to support spatial and temporal queries in raster systems,it will require a substantial redesign for use with vector-based data layers. On theother hand, OOgeomorph is a vector-based system",
    "chunk_order_index": 112,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7fbf35848b83e625a72cd5921f07fe76": {
    "tokens": 1200,
    "content": "to other raster-based systems to representinformation about locational changes at pre-deﬁned cells alongthe passage of anevent. Central to ESTDM is a chain of vectors that changes at locations (cells) ona raster of a single theme (such as temperature). While the model has shown itsefﬁciency and capability to support spatial and temporal queries in raster systems,it will require a substantial redesign for use with vector-based data layers. On theother hand, OOgeomorph is a vector-based system designed to handle point dataof time-stamped locations. The model starts with an object-oriented scheme of geomorphic features of interest. These geomorphic features emerge in the databasewhen an appropriate selection of attributes is made from time-stamped points. Forexample, data objects of coastlines will be created as all points with an elevationequal to zero are selected. The key idea of OOgeomorph is that instances of spatio-temporal data objects are dynamically derived through selection of attributes, andtherefore, object identity results from the interaction of space, time, and attribute.Questions remain as to OOgeomorph’s ability to handle spatial objects of higherdimensions and its applicability to systems other than geomorphology.The three-domain model attempts to capture a broad range of spatio-temporalityindependent of raster or vector data types and support for spatio-temporal queries(Yuan 1996). While developed as a separate venture, the three-domain model offersa general framework that accounts for histories at locations as in the space-timemodel, changes at locations along a passage of an event as in the ESTDM, anddynamic creation of object identities through attribute selections as in OOgeomorph.Fundamental to the three-domain model is the idea that geographic semantics (thegeographic meaning that a representation attempts to portray), temporal properties,and spatial characteristics are three elements of geographic things to be modeledin a spatio-temporal representation (Figure 9.3). The semantic domain can includespeciﬁc sets of ontological notations, semantic networks, or conceptual object-oriented models of geographic things, and their temporal and spatial properties arerepresented in the temporal and spatial domains respectively. Different ways of link-ing the three elements result in distinct spatio-temporal concepts being represented.For example, linking from spatial objects, through temporal objects, to semanticobjects, represents histories at locations; that is how locations change attributes over time, which is the basis of the space-time composite model. When linking from semantic objects through temporal objects to spatial objects, the representationdescribes how geographic things change locations or geometric properties over time;comparable to what is represented in the ESTDM. As compared to OOgeomorph,the semantic domain corresponds to the object-oriented scheme that deﬁnes geo-graphic entities of interest and their relationships. Selection of proper geographicattributes to form instances of geographic entities will be based on the deﬁnitionsof these geographic entities in the semantic domain. Once attributes are identiﬁed,linkages will be made to temporal and spatial data in the other two domains tocreate spatio-temporal instances.The three-domain model has shown its abilities to support a wide range of spatio-temporal queries; of particular interest are queries about spatio-temporal behaviorsand relationships (Yuan 1999). The model is also implemented in building a databaseto trace backward information about failure and repairs of electrical transformersTHO_C09  19/03/2007  11:19  Page 176 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING TIME INTO GIS DATABASES177in a large electric network (Wakim and Chedid 2000) and has shown its ability to model dynamic changes and scenarios. Ideas from the three-domain model are also adopted in the Multidimensional Location Referencing System (MDLRS) datamodel (Koncz and Adams 2002). By dealing with objects that represent semantics,temporal properties, and spatial properties separately and with links among themto represent dynamic geographic entities in space and time, the MDLRS data modeloffers the ability and ﬂexibility to integrate data from multiple sources and varioustransportation needs in multi-dimensional location referencing. Furthermore, the three-domain model is applied to represent dynamics of convective storms based onprecipitation data and to develop a prototype system with capabilities to supportqueries about the development, movement, merger, split, and lifelines of storms inthe database (Yuan 2001, Yuan and McIntosh 2003). In the storm application, objectsof events, processes, sequences, and states constitute the semantic domain and, as inOOgeomorph, instances of these semantic objects are created by deﬁned thresholdvalues of precipitation.By using events and processes to integrate space and time, geographic representa-tion can embrace much richer semantics that reﬂect dynamic characteristics of reality.However, representing events and processes is not a trivial task even at the con-ceptual level because the interwoven relationships among space, time, and phenomenacannot be fully integrated without a thorough consideration of the fundamentalsSemantic domainobjects representing categories, concepts, entities, events, and processes.Temporal domainobjects representing time instants, intervals, temporal geometry, and temporal topology.Spatial domainobjects representing locations, spatial extent, spatial geometry, and spatial topology.There are no direct links from semantic to spatial objects because the model assumes that a geographic entity or attribute is contingent on time. A null temporal object can be set to handle data records without temporal measures.Links from semantic and temporal objects to spatial objectsconstrain that an entity exists at determinable locations",
    "chunk_order_index": 113,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-04ea7e1593ce5768d2a6d09d6ab406da": {
    "tokens": 1200,
    "content": "concepts, entities, events, and processes.Temporal domainobjects representing time instants, intervals, temporal geometry, and temporal topology.Spatial domainobjects representing locations, spatial extent, spatial geometry, and spatial topology.There are no direct links from semantic to spatial objects because the model assumes that a geographic entity or attribute is contingent on time. A null temporal object can be set to handle data records without temporal measures.Links from semantic and temporal objects to spatial objectsconstrain that an entity exists at determinable locations ata given time.Links from spatial and temporal objects to semantic objectsconstrain that a location has determinable geographicsemantics at a given time.Fig. 9.3A conceptual framework for a three-domain modelAdopted from Yuan 1999THO_C09  19/03/2007  11:19  Page 177 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f178MAY YUANof geographic systems. Conceptually, it may appear simple to sort out geographicentities and their relationships. Complexity arises, however, from the inﬂuences ofscale in space and time on entity identiﬁcation. Consequently, the speciﬁcation ofand sustainability of entity relationships is sometimes challenging to track acrossspatial and temporal scales. Only since early 2000 has it been recognized that spaceand time should not always be seen as two orthogonal dimensions. Many researchersadvocate using an integrated approach to model geographic reality via events or pro-cesses (for example, Peuquet and Duan 1995, Raper and Livingstone 1995, Egenhoferand Golledge 1998, Yuan 2001). Ultimately, events and processes are central tothe understanding of geographic worlds. They constitute information of interest to many, and perhaps, the majority of applications and scientiﬁc inquiries.Spatio-temporal QueriesThe ability to retrieve data of interest from a massive data set is one of the mostfundamental functions in any information system. In fact, it can be argued that querysupport is the primary driver for developing a database. What data can be retrievedfrom a database and how efﬁciently the data can be retrieved depends very muchon the chosen ontologies, representation, and data models. For example, if a SNAPontology is adopted, the GIS will not have the knowledge of lifelines and thereforewill not be able to support access to data about lifelines. Likewise, if a space-timecomposite model is chosen, the GIS will not be able to support information queryabout movements. At the computational level, evaluation of a query is inﬂuencedby its query type and the algorithm designed to process this query type based onstorage structure and indexes (Teraoka, Maruyama, Nakamura, and Nishida 1996,Tsotras, Jensen, and Snodgrass 1998).Accordingly, many spatial or temporal query types identiﬁed by computer scientistsor geographers are based on indexing or processing needs. In spatial queries, we havequery types that center on certain geometry, spatial range, or selection methods.Speciﬁcally, spatial queries can be characterized as point query, range query, Booleanquery (Knuth 1973, Samet 1989), geometric query (Sourina and Boey 1998), select-by-location, select-by-attribute, spatial joins (Rigaux, Scholl, and Voisard 2002), andquery-by-sketch (Egenhofer 1997). Three additional spatial query types are recognizedbased on GIS computational needs: topological queries, set-theoretical queries, andmetric queries (Floriani, Marzano, and Puppo 1993). With historical and rollbackdatabases, temporal query types are categorized as snapshot, timeslice (Verma andVarman 1994), attribute-history, key-history (Verma and Vaishnav 1997), intervalintersection (Kanellakis, Ramaswamy, Vengroff, and Vitter 1993), time-range, andbitemporal queries (Kumar, Tsotras, and Faloutsos 1998). As mentioned previously,new ontological beings emerge, such as movement, split, and divergence, when bothspace and time are under consideration, and the complexity of their organization andrelationships grows exponentially (Yuan 2000). Consequently, a systematic way toidentify query types for spatio-temporal information is critical to the developmentof a temporal GIS with adequate support for spatio-temporal queries.Research on spatio-temporal queries is still in its infancy. An obvious reason is that there is no universal standard spatio-temporal data model, and therefore,THO_C09  19/03/2007  11:19  Page 178 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING TIME INTO GIS DATABASES179full-scale spatio-temporal information systems (that is, temporal GIS) have not yetbeen developed. Nevertheless, there are several studies that attempt to design searchalgorithms to support a few speciﬁc spatio-temporal query types (Tsotras, Jensen,and Snodgrass 1998). Based on the supply of query predicates, Tsotras, Jensen, andSnodgrass (199",
    "chunk_order_index": 114,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d6b49ee03d510424df647b098506531b": {
    "tokens": 1200,
    "content": "of use; OA articles are governed by the applicable Creative Commons License\fADDING TIME INTO GIS DATABASES179full-scale spatio-temporal information systems (that is, temporal GIS) have not yetbeen developed. Nevertheless, there are several studies that attempt to design searchalgorithms to support a few speciﬁc spatio-temporal query types (Tsotras, Jensen,and Snodgrass 1998). Based on the supply of query predicates, Tsotras, Jensen, andSnodgrass (1998) note that spatio-temporal queries can be categorized as selection-based on a single data set or other operations that require more than one data set:joins, unions, projections, aggregates, constraints, and differences.From around early in 2000, video search and data mining of mobile objects andsensor data have become key drivers in promoting research on spatio-temporal queries.To support searches for objects of interest in video databases, Kuo and Chen (1996)developed a content-based video query language utilizing the spatial and temporalrelations of content objects as predicates. Later, algorithms were designed to matchtrajectory patterns to answer queries about moving objects (trajectory queries) invideo databases (Li, Ozsu, and Szafron 1997). In addition to the trajectories of mov-ing objects, there is great interest in video queries that return semantic associationsamong objects under spatial and temporal constraints. A Video Data Base Manage-ment System (VSBMS) is developed with a Logical Hypervideo Data Model andquery language to support retrieval of video data with speciﬁcs to a wide range ofspatial and temporal constraints (relations) and semantic descriptions (Jiang andElmagarmid 1998). Most applications in tracking moving objects consider point-based objects. Querying moving objects that may involve geometric changes over timeis very challenging. Attempts have been made to develop extensions to the spatialdata model and query language to handle time-dependent geometries (Güting, Erwig,Jensen, et al. 2000).In addition to trajectories of moving objects, some spatio-temporal queries seekpatterns of change in databases, that is to say, spatio-temporal evolution. Djafri,Fernandes, Paton, and Grifﬁths (2002) referred to these as evolution queriesbecausethey aim to identify patterns of change throughout histories of the entities. Theyfurther classify evolution queries into sequence queries for a-spatial data, and devel-opments queriesfor spatial data. With data from the longitudinal study by the UKOfﬁce for National Statistics, Djafri, Fernandes, Paton, and Grifﬁths (2002) developalgorithms to handle evolution queries of individuals over consecutive snapshots.Of signiﬁcance to the work of Djafri, Fernandes, Paton, and Grifﬁths (2002) is theconsideration of interactions between point-based individuals (persons) and region-based individuals (enumeration units) to seek aligned histories of these objects.Recently, a functional approach is taken to support evolution queries on thematicmaps (d’Onofrio and Pourabbas 2003). While these studies collectively address awide range of spatio-temporal queries, most, if not all, spatio-temporal queries in theliterature deal with objects with uniform spatial properties. The assumption can be easily violated in geographic worlds because the properties of some entities may bespatially heterogeneous (Yuan 2001). Examples include storms, heat waves, oil spills,and pollution plumes, to name just a few. These objects have ﬁeld-like properties(for example, temperature, chemical concentration, etc.), and changes in their ﬁeld-like properties are central to the evolution of these objects.With an emphasis on exploring and understanding geographic dynamics as represented by spatio-temporal data, Yuan and McIntosh (2002) have proposed atypology of geographic queries based on the information sought and relevance ofTHO_C09  19/03/2007  11:19  Page 179 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f180MAY YUANspatio-temporal data mining. The typology includes one type of attribute query,three types of spatial query, three types of temporal query, and four types of spatio-temporal query as listed below:1Attribute Queriesseek properties information about speciﬁc geographic objectsor locations in a ﬁeld2Spatial Query typesseek geographic objects or locations based on criteria ofspeciﬁc points, ranges, or relations in space•Simple spatial queries•Spatial range queries•Spatial relationship queries3Temporal Query types seek geographic objects or locations based on criteriaof speciﬁc points in time, periods, or temporal relations•Simple temporal queries•Temporal range queries•Temporal relationship queries4Spatio-temporal Query typesseek geographic objects or locations based on criteria of speciﬁc properties, domains of space and time, spatio-temporal char-acteristics and spatio-temporal relations•Simple spatio-temporal queries•Spatio-temporal range queries•Spatio-temporal behavior queries•Spatio-temporal relationship queriesThe most challenging of all queries are those about spatio-temporal behaviorsand relationships for spatially heterogeneous (non-uniform) objects as discussed pre-viously. In most cases, geographic objects considered in these queries are complexgeographic phenomena, events, and processes (such as wildﬁres; see Yuan 1997 for further details about the information complexity of wildﬁre) that exhibit highdegrees of geographic dynamics with indeterminate boundaries. Nevertheless, themost challenging query types have the greatest potential",
    "chunk_order_index": 115,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-99f6c555d3ed5f26f596fde27c5bd81b": {
    "tokens": 1200,
    "content": "queriesThe most challenging of all queries are those about spatio-temporal behaviorsand relationships for spatially heterogeneous (non-uniform) objects as discussed pre-viously. In most cases, geographic objects considered in these queries are complexgeographic phenomena, events, and processes (such as wildﬁres; see Yuan 1997 for further details about the information complexity of wildﬁre) that exhibit highdegrees of geographic dynamics with indeterminate boundaries. Nevertheless, themost challenging query types have the greatest potential to offer new insights intowhat is embedded in a spatio-temporal database, and furthermore may help us probefor new scientiﬁc insight about these geographic worlds. For example, a spatio-temporal query may seek to retrieve events operating at a continental scale withbehaviors correlating to droughts in the Midwest of the United States. The resultsmay include some events that are not previously known to be correlates of droughtsin the Midwest. Consequently, data mining and knowledge discovery methods canbe applied to further validate the correlation in a large database, which may drivenew scientiﬁc inquiry about the physical causes of the correlation.CONCLUSIONSTime is a critical element to geographic study, and GIS technology cannot be fullydeveloped without abilities to handle both spatial and temporal data and to trans-form these data into spatio-temporal information. While the challenge is grand andmultitudinal, a sound conceptual foundation serves as the bedrock upon which afully ﬂedged temporal GIS can be built.THO_C09  19/03/2007  11:19  Page 180 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING TIME INTO GIS DATABASES181This chapter has discussed the developments and research needs for ontologies,representation and data modeling, and information queries that constitute the con-ceptual foundation of a temporal GIS. In summary, research on geographic ontologyhas resulted in many important advances in our understanding of what constitutesgeographies from empirical and cognitive perspectives, and in applications usingontology to improve interoperability of GIS data and feature identiﬁcation on images.As to representation and data modeling, the general trend directs us to approachesthat account for events and processes as integrals of space and time, in contrast totime-stamping approaches. As to spatio-temporal queries, most studies still con-sider only point-based objects in a 4D space in searching for trajectories of movingobjects. Few studies consider two-dimensional spatial objects, like regions, and changes in their geometries over time. New query languages and algorithms havebeen developed and have shown capabilities to retrieve information about historiesof individual spatio-temporal objects and intersections of their histories in spaceand time.Common to research on ontology, representation and data modeling, and queryis diversity. There are no universally accepted geographic ontologies, representa-tion and data models, or query languages in temporal GIS. The diversity, on theone hand, indicates that this research ﬁeld is thriving, but on the other hand, weneed concerted efforts to ensure sustained progress in temporal GIS. This chapteridentiﬁed several common threads (i.e. transitions) among the approaches, whichmay serve as the basis for future integration of the different schools of thoughts.In addition, suggestions have been made for future research in the considerationof complex geographic objects: their ontological implications, representation anddata modeling, and information query support.REFERENCESAbraham, T. and Roddick, J. F. 1996. Survey of Spatio-temporal Databases.Adelaide,University of South Australia, School of Computer and Information Science, AdvancedComputing Centre Technical Report No. CIS 96-011.Chrisman, N. R. 1998. Beyond the snapshot: Changing the approach to change, error, andprocess. In M. J. Egenhofer and R. G. Golledge (eds) Spatial and Temporal Reasoning inGeographic Information Systems. New York: Oxford University Press, pp. 85–93.Couclelis, H. 1992. People manipulate objects (but cultivate ﬁelds): Beyond the raster–vector debate in GIS. In A. U. Frank and U. Formentini (eds) Theories and Methods ofSpatio-temporal Reasoning in Geographic Space. Berlin: Springer-Verlag Lecture Notes inComputer Science No. 639: 65–77.Cova, T. J. and Goodchild, M. F. 2002. Extending geographical representation to includeﬁelds of spatial objects. International Journal of Geographical Information Science16:509–32.Djafri, N., Fernandes, A. A. A., Paton, N. W., and Grifﬁths, T. 2002. Spatio-temporal evolution: Querying patterns of change in databases. In Proceedings of the Tenth ACMInternational Conference on Advances in Geographic Information Systems, McLean, VA,USA. New York: Association of Computing Machinery, pp. 35–41.d’Onofrio, A. and Pourabbas, E. 2003. Modeling temporal thematic map contents. ACMSIGMOD Record32(2): 31–41.Egenhofer, M. J. 1997. Query processing in spatial-query-by-sketch. Journal of Visual Lan-guages and Computing8: 403–24.THO_C09  19/03/2007  11:19  Page 181 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library",
    "chunk_order_index": 116,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7f0e577373772db8fb9ca3e410cacd5c": {
    "tokens": 1200,
    "content": ". Modeling temporal thematic map contents. ACMSIGMOD Record32(2): 31–41.Egenhofer, M. J. 1997. Query processing in spatial-query-by-sketch. Journal of Visual Lan-guages and Computing8: 403–24.THO_C09  19/03/2007  11:19  Page 181 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f182MAY YUANEgenhofer, M. J. and Golledge, R. G. 1998. Spatial and Temporal Reasoning in GeographicInformation Systems, edited. New York: Oxford University Press.Erwig, M., Guting, R. H., and Schneider, M. 1999. Spatio-temporal data types: An approachto modeling and querying moving objects in databases. Geoinformatica3: 269–96.Feather, N. 1959. An Introduction to the Physics of Mass, Length, and Time.Chicago, IL:Aldine.Fellbaum, C. (ed.). 1998. WorldNet: An Electronic Lexical Database for Language, Speech,and Communication.Cambridge, MA: MIT Press.Floriani, L. D., Marzano, P., and Puppo, E. 1993. Spatial queries and data models. In A. U. Frank and I. Campari (eds) Spatial Information Theory: A Theoretical Basis forGIS.Berlin: Springer-Verlag Lecture Notes in Computer Science No. 716: 113–38.Frank, A. U. 1997. Spatial ontology: A geographical point of view. In O. Stock (ed.) Spatialand Temporal Reasoning. Dordrecht: Kluwer, pp. 135–53.Frank, A. U. 1998. Different types of “Times” in GIS. In M. J. Egenhofer and R. G. Golledge(eds) Spatial and Temporal Reasoning in Geographic Information Systems. New York:Oxford University Press, pp. 40–62.Frank, A. U. 2003. Ontology for spatio-temporal databases. In M. Koubarakis, T. K. Sellis,A. U. Frank, S. Grumbach, R. H. Güting, C. S. Jensen, N. Lorentzos, Y. Manolopoulos,E. Nardelli, B. Pernici, H.-J. Schek, M. Scholl, B. Theodoulidis, and N. Tryfona (eds) Spatio-temporal Databases: The Chorochronos Approach. Berlin: Springer Lecture Notesin Computer Science No. 2520: 9–77.Frank, A. U. and Mark, D. M. 1991. Language issues for GIS. In D. J. Maguire, M. F. Goodchild, and D. W. Rhind (eds) Geographical Information Systems: Principlesand Applications Vol. 1. Harlow: Longman, pp. 147–63.Gadia, S. K. and Vaishnav, J. H. 1985. A query language for a homogeneous temporal database.In Proceedings of the ACM Symposium on Principles of Database Systems: New York:Association of Computing Machinery, pp. 51–6.Gadia, S. K. and Yeung, C. S. 1988. A generalized model for a relational temporal data-base. In Proceedings of theACM SIGMOD International Conference on Management ofData: New York: Association of Computing Machinery, pp. 251–9.Grenon, P. and Smith, B. 2004. SNAP and SPAN: Towards dynamic spatial ontology. SpatialCognition and Computation 4: 69–103.Guarino, N. 1998. Formal ontology and information systems. In N. Guarino (ed.) FormalOntology in Information Systems.Amsterdam: IOS Press: 3–15.Güting, R. H., Böhlen, M. H., Erwig, M., Jensen, C. S., Lorentzos, N. A., Schneider, M.,and Vazirgiannis, M. 2000. A foundation for representing and querying moving objects.ACM Transactions on Database Systems25: 1–42.Hazelton, N. W. J. 1998. Some operational requirements for a multi-temporal 4D GIS. InM. J. Egenhofer and R. G. Golledge (eds)Spatial and Temporal Reasoning in GeographicInformation Systems.New York: Oxford University Press, pp. 63–73.Jakle, J. A. 1972. Time, space and the geographic past: A prospectus. American History Reviews77: 1084–103.Jiang, H. and Elmagarmid, A. K. 1998. Spatial and temporal content-based access to hyper-video databases. International Journal on Very Large Data Bases7: 226–38.Kanellakis, P. C., Ramaswamy, S., Vengroff, D. E., and Vitter, J. S. 1993. Indexing for datamodels with constraints and classes. In Proceedings of the Twelfth ACM Symposium on Principles of Database Systems, Washington, DC, USA. New York: Association ofComputing Machinery, pp. 233–43.Knuth, D. E. 1973.",
    "chunk_order_index": 117,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-277eb7f59154602a28526a83080cf5ec": {
    "tokens": 1200,
    "content": "7: 226–38.Kanellakis, P. C., Ramaswamy, S., Vengroff, D. E., and Vitter, J. S. 1993. Indexing for datamodels with constraints and classes. In Proceedings of the Twelfth ACM Symposium on Principles of Database Systems, Washington, DC, USA. New York: Association ofComputing Machinery, pp. 233–43.Knuth, D. E. 1973. The Art of Computer Programming: Volume1, Fundamental Algorithms.Reading, MA: Addison-Wesley.Koncz, N. and Adams, T. 2002. A data model for multi-dimensional transportation applica-tions. International Journal of Geographical Information Science16: 551–69.THO_C09  19/03/2007  11:19  Page 182 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fADDING TIME INTO GIS DATABASES183Kumar, A., Tsotras, V. J., and Faloutsos, C. 1998. Designing access methods for bitemporaldatabases. IEEE Transactions on Knowledge and Data Engineering10: 1–20.Kuo, T. C. T. and Chen, A. L. P. 1996. A content-based query language for video databases.In M. Sakanchi and W. Klas (eds) Proceedings of the Third IEEE International Conferenceon Multimedia Computing and Systems.Los Alamitos, CA, USA. IEEE Computer SocietyPress: 209–14.Langran, G. and Chrisman, N. R. 1988. A framework for temporal geographic information.Cartographica25: 1–14.Li, J. Z., Ozsu, M. T., and Szafron, D. 1997. Modeling of moving objects in a video database.In N. D. Georganas (ed.) Proceedings of the Fourth IEEE International Conference onMultimedia Computing and Systems.Los Alamitos, CA, USA. IEEE Computer Society Press:336–43.Mark, D. M., Skupina, A., and Smith, B. 2001. Features, objects, and other things: Onto-logical distinctions in the geographic domain. In D. Montello (ed.) Spatial InformationTheory.Berlin: Springer Lecture Notes in Computer Science No. 2205: 488–502.Mark, D. M., Smith, B., and Tversky, B. 1999. Ontology and geographic objects: An empirical study of cognitive categorization. In C. Freksa and D. M. Mark (ed.) SpatialInformation Theory: A Theoretical Basis for GIS.Berlin: Springer Lecture Notes inComputer Science No. 1661: 283–98.Peuquet, D., Smith, B., and Brogaard, B. O. 1998. The Ontology of Fields: Report of theSpecialist Meeting held under the auspices of the Varenius Project, Bar Harbor, Maine.Santa Barbara, CA: National Center for Geographic Information and Analysis.Peuquet, D. J. 1984. A conceptual framework and comparison of spatial data models.Cartographica21: 66–113.Peuquet, D. J. 2002. Representation of Space and Time. New York: Guilford.Peuquet, D. J. and Duan, N. 1995. An event-based spatio-temporal model (ESTDM) for temporal analysis of geographical data. International Journal of Geographical InformationSystems9: 7–24.Raper, J. 2000. Multidimensional Geographic Information Science.London: Taylor and Francis.Raper, J. and Livingstone, D. 1995. Development of a geomorphologic spatial model using object-oriented design. International Journal of Geographical Information Systems9: 359–84.Rigaux, P., Scholl, M., and Voisard, A. 2002. Spatial Databases with Application to GIS.San Francisco, CA: Morgan Kaufmann.Samet, H. 1989. The Design and Analysis of Spatial Data Structures. Reading, MA:Addison-Wesley.Smith, B. 1998. The basic tools of formal ontology. In N. Guarino (ed.) Formal Ontologyin Information Systems.Amsterdam: IOS Press, pp. 19–28.Smith, B. and Mark, D. M. 1998. Ontology and geographic kinds. In Proceedings of theEighth International Symposium on Spatial Data Handling (SDH’98), Vancouver, Canada,pp. 308–20.Smith, B. and Mark, D. M. 2001. Geographic categories: An ontological investigation.International Journal of Geographical Information Science15: 591–612.Snodgrass, R. and Ahn, I. 1986. Temporal databases. IEEE ComputerSeptember: 35–42.Sourina, L. and Boey, S. H. 1998. Geometric query types for data retrieval in relationaldatabases. Data and Knowledge Engineering27: 207–29.Teraoka, T., Maruyama, M., Nakamura, Y., and Nishida, S. 1996. The multidimensionalpersistent tree: A spatio-temporal data management structure suitable for spatial search.Systems and Computers in Japan27: 60–72.Terenziani, P. 1995. Towards a causal ontology coping",
    "chunk_order_index": 118,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-eb1300f6c8fc39ec08ff25c1a2b7c68a": {
    "tokens": 1200,
    "content": ". 1998. Geometric query types for data retrieval in relationaldatabases. Data and Knowledge Engineering27: 207–29.Teraoka, T., Maruyama, M., Nakamura, Y., and Nishida, S. 1996. The multidimensionalpersistent tree: A spatio-temporal data management structure suitable for spatial search.Systems and Computers in Japan27: 60–72.Terenziani, P. 1995. Towards a causal ontology coping with the temporal constraints betweencauses and effects. International Journal of Human-Computer Studies43: 847–63.THO_C09  19/03/2007  11:19  Page 183 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f184MAY YUANTerenziani, P. 2002. Toward a unifying ontology dealing with both user-deﬁned periodicityand temporal constraints about repeated events. Computational Intelligence18: 336–85.Tsotras, V., Jensen, C., and Snodgrass, R. 1998. An extensible notation for spatio-temporalindex queries. SIGMOD Record27: 47–53.Ullman, E. L. 1974. Space and/or time: Opportunity for substitution and prediction.Transactions of the Institute of British Geographers 62:125–39.Verma, R. M. and Vaishnav, J. H. 1997. An efﬁcient multiversion access structure. IEEETransactions on Knowledge and Data Engineering9: 391–409.Verma, R. M. and Varman, P. J. 1994. Efﬁcient archivalable time index: a dynamic indexingscheme for temporal data. In Proceedings of the International Conference on ComputerSystems and Education.Wakim, T. and Chedid, F. B. 2000. On the reconstruction of old versions from a spatio-temporal database. In Proceedings of the Twentieth ESRI International User Conference,San Diego, CA, USA. (Available at gis.esri.com/library/userconf/proc00/professional/papers/PAP458/p458.htm.)Worboys, M. F. 1990. Reasoning about GIS Using Temporal and Dynamic Logics.SantaBarbara, CA: National Center for Geographical Information and Analysis.Worboys, M. F. 1994. A uniﬁed model of spatial and temporal information.Computer Journal37: 26–34.Yuan, M. 1994. Wildﬁre conceptual modeling for building GIS space-time models. In Pro-ceedings of GIS/LIS ’94, Phoenix, AZ, USA, pp. 860–9.Yuan, M. 1996. Modeling semantical, temporal, and spatial information in geographic information systems. In M. Craglia and H. Couclelis (ed.) Geographic Information Research:Bridging the Atlantic. London: Taylor and Francis, pp. 334–7.Yuan, M. 1997. Knowledge acquisition for building wildﬁre representation in GeographicInformation Systems. International Journal of Geographic Information Science11: 723–45.Yuan, M. 1999. Use of a three-domain representation to enhance GIS support for complexspatio-temporal queries. Transactions in GIS3: 137–59.Yuan, M. 2000. Representation of dynamic geographic phenomena based on hierarchicaltheory. In Proceedings of the Ninth International Symposium on Spatial Data HandlingSpatial Data Handling SDH’00,Beijing, People’s Republic of China.Yuan, M. 2001. Representing complex geographic phenomena with both object- and ﬁeld-like properties. Cartography and Geographic Information Science28: 83–96.Yuan, M., Mark, D., Peuquet, D., and Egenhofer, M. 2004. Extensions to geographic representations. In R. McMaster and L. Usery (eds)Research Challenges in GeographicInformation Science.Boca Raton, FL: CRC Press, pp. 129–56.Yuan, M. and McIntosh, J. 2002. A typology of spatio-temporal information queries. In K. Shaw, R. Ladner, and M. Abdelguerﬁ (eds) Mining Spatio-temporal Information Systems.Berlin: Kluwer Academic Publishers, pp. 63–82.Yuan, M. and McIntosh, J. 2003. Weather intelligence: A GIS approach to enrich weather/climate databases. In Proceedings of the Eighty-third Annual Meeting of the AmericanMeteorological Society, Long Beach, CA. New York: Association of Computing Machinery.THO_C09  19/03/2007  11:19  Page 184 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 10Geospatial Data IntegrationCraig A. Knoblock and Cyrus ShahabiThe problem of integrating geospatial data is ubiquitous since there is so much geospatial data available and such a variety of geospatial formats. The commercialworld has numerous products that allow one to combine data that is represented inthe myriad of geospatial formats and perform the conversion between products in these various formats.",
    "chunk_order_index": 119,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-66b50efe60ab6d9e4b9d0bfce15c7037": {
    "tokens": 1200,
    "content": "-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 10Geospatial Data IntegrationCraig A. Knoblock and Cyrus ShahabiThe problem of integrating geospatial data is ubiquitous since there is so much geospatial data available and such a variety of geospatial formats. The commercialworld has numerous products that allow one to combine data that is represented inthe myriad of geospatial formats and perform the conversion between products in these various formats. In an effort to improve the sharing and interoperabilityof geospatial information, the Open GIS Consortium (see http://www.opengis.org foradditional details) has created the Geographic Markup Language (GML) to supportthe sharing of geographic information. GML provides an agreed-upon representa-tion for publishing and using the various types of spatial data (for example, maps,vectors, etc.). As the interest in and use of geospatial data continues to grow, theseefforts will be critical in exploiting the geospatial data that is available.However, even in a world where geospatial products can be readily convertedbetween different formats and geospatial information is published using agreed standards for interoperability, the problem is not fully solved. First, there may besources that are not represented in any geospatial data format. For example, thereare libraries of maps on the web that contain maps with only a textual descriptionof the map and no metadata about the location or scale of the map. Second, thereare many sources of online information that can be placed in a geospatial context,but the information is only available on a website as HTML pages, not in any standard geospatial format. Finally, even sources that may be available in one ofthe many standard formats may be difﬁcult to integrate in a meaningful way dueto differences in the resolution of the products, differences in the algorithms used toorthorectify the products, or just the lack of metadata on the products.In this chapter we describe recent work on the extraction and integration of geo-spatial and geospatial-related data that go beyond conversion between different products and standard formats for the interoperability of these products. First, wedescribe techniques for turning online web sources into more structured sources wherethe information in these sources can then be integrated with other geo-spatial data.Then we present techniques for accurately and automatically integrating vector data with high-resolution color imagery. Today this type of alignment is performedTHO_C10  19/03/2007  11:18  Page 185 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f186CRAIG A. KNOBLOCK AND CYRUS SHAHABImanually by identifying a set of control point pairs across different products andthen using rubber-sheeting techniques (Saalfeld 1993) to align the products, but thisapproach is very slow and labor intensive. Next, we describe techniques for exploit-ing online property tax sources and conﬂated road vector data to identify and annotate the buildings in an image. This goes beyond image processing, which maybe able to identify an object as a building, but cannot provide any of the identifyinginformation about the building. Then we present an approach that automaticallyintegrates maps with unknown coordinates with satellite imagery. This makes itpossible to exploit the data on a map to help label an image or vice versa. Finally,we present an approach to efﬁciently combine online schedules with vector data topredict the location of moving objects in the world, such as trains or buses.Extracting Data from Online SourcesBeyond the traditional types of geospatial data sources, including satellite imagery,maps, vector data, elevation data, and gazetteers, there are many other sources ofinformation available on the web that can be placed in a geospatial context. Thisincludes sources such as property tax sites, telephone books, train, and bus schedules.The amount of such information is large and continues to grow at a rapid rate. Thechallenge is how to make effective use of all of this information and how to placeit in a geospatial context. The ﬁrst step is to turn the online sources that were intendedfor browsing by people into sources that can be effectively integrated with the moretraditional types of geospatial sources.To address this challenge, researchers have developed machine learning techniquesfor rapidly converting online web sources into sources that can be queried as if theywere databases (Kushmerick 1997, Hsu and Dung 1998, Knoblock, Lerman, Minton,and Muslea 2003). These techniques greatly simplify the problem of turning webpages into structured data. The user provides examples of the information to beextracted and the system learns a wrapper that can dynamically extract data froman online source or convert an online source into a database. A wrapper is deﬁnedby a set of extraction rules that are speciﬁc to extracting the data from a particularwebsite. The extraction rules specify how to locate speciﬁc types of informationfrom a page and these rules must work over the potentially large number of pagesavailable on a given website. The machine learning techniques developed for thisproblem are designed to produce highly accurate extraction rules with a minimumnumber of training examples. The extraction rules for many websites can be learnedwith just a few examples.Figure 10.1 shows the property tax site for New York State. This site containsdetailed property information such as name, address, lot size, and date of purchase forall of the properties in the state. In order to exploit this information for geospatialdata integration we would ﬁrst need to build a wrapper that provides programmaticaccess to the data. This is accomplished",
    "chunk_order_index": 120,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0becb8c8f04a15f7ca5d194a038f2c5c": {
    "tokens": 1200,
    "content": "rules with a minimumnumber of training examples. The extraction rules for many websites can be learnedwith just a few examples.Figure 10.1 shows the property tax site for New York State. This site containsdetailed property information such as name, address, lot size, and date of purchase forall of the properties in the state. In order to exploit this information for geospatialdata integration we would ﬁrst need to build a wrapper that provides programmaticaccess to the data. This is accomplished by providing examples of the data to beextracted from several example pages on this site. The system then learns the setof extraction rules for the site and uses these rules to construct a wrapper tailoredto this website. This wrapper can take a request, such as to return the propertiesof everyone named “Smith” in “Syracuse,” and will return the information in astructured format, such as the XML document shown at the bottom of Figure 10.1.THO_C10  19/03/2007  11:18  Page 186 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFig. 10.1A wrapper converts the New York State Property Database into structured data that canthen be integrated with other sourcesGEOSPATIAL DATA INTEGRATION187THO_C10  19/03/2007  11:18  Page 187 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f188CRAIG A. KNOBLOCK AND CYRUS SHAHABIIntegrating Vector Data and ImageryWhen combining different geospatial data sources, such as vector data and satelliteimagery, a critical problem is that the products do not correctly align. This problemis caused by the fact that geospatial data obtained from various sources may usedifferent projections, may have different accuracy levels, and may have been cor-rected in different ways. The applications that integrate information from variousgeospatial data sources must be able to overcome these inconsistencies accuratelyand for large regions.Traditionally, this problem has been solved in the domain of image processing andGeographic Information Systems (GIS). The focus of image processing techniqueshas been on automatic identiﬁcation of objects in the image (Auclair-Fortier, Ziou,Armenakis, and Wang 2000; see also http://iris.usc.edu/Vision-Notes/bibliography/contents.html, topic 21, for a comprehensive bibliography of work on automaticextraction of road networks) in order to resolve vector-image inconsistencies. How-ever, these techniques require signiﬁcant CPU time to process an image in its entiretyand still may result in inaccurate results. The primary approach used in most GISis to require a user to manually identify a set of control point pairs and then to usea technique called conﬂation (Saalfeld 1993) to align two geospatial data sets. Theneed to manually identify control point pairs means that this approach does notscale up to large regions.To address this problem, we developed a technique to efﬁciently and automaticallyintegrate vector data with satellite or aerial imagery (Chen, Thakkar, Knoblock, andShahabi 2003, Chen, Shahabi, and Knoblock 2004b). Our approach is based ontwo important observations. First, there is a great deal of information that is knownabout a given location beyond the data that is to be integrated. For example,mostroad-network vector data sets also contain the road direction, road width and evenlocation of the road intersections. Second, rather than processing each source ofinformation in isolation, it is much more effective to apply what is known about thesesources to help in the integration of two sources. For example, the information aboutroad directions and road width can be used to help locate the corresponding inter-sections in the satellite imagery. In the remainder of this section we discuss someof the details of our technique to show how we utilized these two observations toeffectively incorporate the image processing techniques into the conﬂation processso that the resulting approach is both more effective and fully automatic (and hencescalable to large regions).To explain our approach, we ﬁrst need to explain the conﬂation process. Theconﬂation process divides into the following tasks: (1) ﬁnd a set of conjugate pointpairs, termed “control point pairs,” in both the vector and image data sets, (2) ﬁlterthe control point pairs, and (3) utilize algorithms, such as triangulation and rubber-sheeting, to align the remaining points and lines in the two data sets using the control point pairs. Traditionally, human input has been essential to ﬁnd controlpoint pairs and/or ﬁlter control points. Instead, we developed completely automatictechniques to ﬁnd control point pairs in both data sets and designed novel ﬁlter-ing techniques to remove inaccurate control points. We developed two different tech-niques to ﬁnd accurate control point pairs. Our ﬁrst technique generates controlTHO_C10  19/03/2007  11:18  Page 188 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/",
    "chunk_order_index": 121,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-233cf5fe594a4d1c29e60366fc2e4bde": {
    "tokens": 1200,
    "content": "completely automatictechniques to ﬁnd control point pairs in both data sets and designed novel ﬁlter-ing techniques to remove inaccurate control points. We developed two different tech-niques to ﬁnd accurate control point pairs. Our ﬁrst technique generates controlTHO_C10  19/03/2007  11:18  Page 188 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOSPATIAL DATA INTEGRATION189points using localized image processing. The second technique ﬁnds control points byquerying information from online web sources about known locations in the imagery.Because of lack of space, we only brieﬂy describe the ﬁrst technique, which reliesonly on the imagery and vector data for accurate integration.We ﬁrst ﬁnd feature points, such as the road intersection points from the vectordata set. For each intersection point, we perform image processing in a small areaaround the intersection point to ﬁnd the corresponding point in a satellite image.This is an example of the ﬁrst observation by exploiting what is known about thelocation, size, and orientation of the intersections and of the second observationby applying this information during the image processing task to focus the pro-cessing on the small area around the location of the intersection on the image (ratherthan processing the entire image). In addition to the approximate location of inter-sections, to locate intersections on the images, we also utilize the information inferredfrom vector data such as road directions, widths and shapes. In particular, we gen-erate a template inferred from all the vector information and then match it againstthe small area in the image to ﬁnd the corresponding intersection point on the imagery.This process is then repeated for every candidate intersection. Finally, during anautomatic ﬁltering step, we eliminate those intersection point pairs that do not agreewith the majority of pairs (that is, outliers). In contrast to techniques for simplyextracting road networks from imagery our technique does not need to locate allof the intersection points in order to accurately align the vector data with the imagery.The remaining steps are the same as those of the traditional conﬂation process.An example of the results of this technique is shown in Figure 10.2. The runningtime for this approach is dramatically lower than traditional image processing tech-niques due to the more focused image processing. Furthermore, the road directionand width information makes detecting edges in the image a much easier problem,thus reducing the running time further.a) Before Conflationb) Using road intersectionsfor image processingc) After ConflationFig. 10.2Automatic conﬂation of vector data with imageryTHO_C10  19/03/2007  11:18  Page 189 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f190CRAIG A. KNOBLOCK AND CYRUS SHAHABIIdentifying Structures in ImageryWe can exploit the various online sources of data to identify the structures (thatis, buildings) in a satellite image. The online property tax records are an especiallyrich source of data and, as described above, these can be turned into structuredsources that can be integrated with other data sources. In the previous section wedescribed how we can automatically identify the roads in a satellite image. In thissection we describe how we can combine this information with the property taxrecords to identify the buildings in an image.The traditional approach to locate a house is to use a geocoder, which maps streetaddresses into latitude and longitude coordinates. Current geocoders perform thismapping by using street vector data that is annotated with the address ranges andthen interpolating the address within the range. This approach provides inaccurateresults (for example, Ratcliffe 2001) since it assumes that the address ranges arefully populated (that is, there are 50 houses on each side of the street) and that alllots are of equal size, but this is rarely the case. Since the commercial geocodersare not accurate enough to precisely identify the houses in an image, instead wecombine the information that is known about the houses on a block to determinethe precise identity of each house.Figure 10.3 illustrates how the various sources of information can be fused toprecisely identify the houses in an image (Bakshi, Knoblock, and Thakkar 2004).We can combine the satellite imagery from a source such as terraserver.com, theEPALMAV610, Palm or645,Sierra645, Sierra or639,Sierra633, Sierra or629,Sierra604 or642604 or610642, Penn or636,Penn630,Penn or628,Penn636,Penn or630,Penn628,Penn or624,Penn624,Penn or618,Penn639, Sierra or633,Sierra629, Sierra or623,Sierra604610645, Sierra642,644,646Penn639, Sierra636,638,640Penn630,632,634Penn633, Sierra629, Sierra628, Penn624, Penn623, SierraLos Angeles County Assessor’sSite Property Tax RecordsGeocoded HousesConstraint SatisfactionInitial HypothesisResult After ConstraintSatisfactionData Extracted from Online SiteAddressLatitudeLongitude642 Penn St33.923413-118.409809640 Penn St33.923412-118",
    "chunk_order_index": 122,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-da7b9d6a93181e53ab9f5c788d98879a": {
    "tokens": 1200,
    "content": "Sierra or623,Sierra604610645, Sierra642,644,646Penn639, Sierra636,638,640Penn630,632,634Penn633, Sierra629, Sierra628, Penn624, Penn623, SierraLos Angeles County Assessor’sSite Property Tax RecordsGeocoded HousesConstraint SatisfactionInitial HypothesisResult After ConstraintSatisfactionData Extracted from Online SiteAddressLatitudeLongitude642 Penn St33.923413-118.409809640 Penn St33.923412-118.409809636 Penn St33.923412-118.409809604 Palm Ave33.923414-118.409809610 Palm Ave33.923414-118.409810645 Sierra St33.923413-118.409810639 Sierra St33.923412-118.409810Address# unitsArea(sq ft)Lot size642 Penn St31793135.72 * 53.33 604 Palm Ave188469 * 42610 Palm Ave175666 * 42645 Sierra St11337120 * 62639 Sierra St11408121*53.5Satellite ImageTerraserverStreet Vector DataCorrected Tiger Line FilesPalm AveMariposaAveSierra StPenn St(-118.40883, 33.92375)EPALMAVPENN STSIERRA STPENN STSIERRA STFig. 10.3Integrating and reasoning about the property tax data, satellite imagery, and road vectordata to identify the structures in an imageTHO_C10  19/03/2007  11:18  Page 190 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOSPATIAL DATA INTEGRATION191street vector data, which has been aligned with the imagery using the techniquesdescribed in the previous section, and the property tax records for the given region.The satellite imagery will show where the houses are located on a block. The streetvector data will provide the geographic coordinates of the block as well as the over-all dimensions of a block. Finally, the property tax site will provide the details oneach property including the street address and lot size.The critical piece of information that is missing from the property tax site is the exact location of the lots. We can tell how many houses are on a street, but thecorner lots create a problem since we do not know which street each of the cornerhouses is listed under. To solve this problem we treat this as a constraint satisfactionproblem (Russell and Norvig 1995), which will consider the possible orientationsof the corner lots and ﬁnd the layout that is closest to the actual dimension of theentire block. This is illustrated in the center of Figure 10.3, which shows the initialhypothesis where there is uncertainty about which houses are on the corners andthe result after running the constraint satisfaction. Once the exact layout of theblock has been determined, the lots can be accurately geocoded and the buildingsin the original image can be accurately identiﬁed.Integrating Maps and ImageryThere are a wide variety of maps available from various sources, such as the US Geological Survey, University of Texas Map Library, and various governmentagencies. These maps include street maps, property survey maps, maps of oil andnatural gas ﬁelds, and so on. However, for many of these maps, the geographiccoordinates and scale of the maps are unknown. Even if this information is known,accurately integrating maps and imagery from different data sources remains a challenging task. This is because spatial data obtained from various data sourcesmay have different projections and different accuracy levels. If the geographic projections of these data sets are known, then they can be converted to the same geographic projections. However, the geographic projection for a wide variety ofgeospatial data available on the Internet is not known. To address this problem, webuilt on our previous work on automatic vector to image conﬂation and developedefﬁcient techniques to the problem of automatically conﬂating maps with satelliteimagery (Chen, Knoblock, Shahabi, Thakkar, and Chiang 2004a).To tackle this integration task, we continue to rely on the two observations dis-cussed in the previous section: (1) utilizing all of the information known about agiven location; and (2) exploiting this information to integrate the products. Usingthe ﬁrst observation, we also consider the vector data of the roads in addition to themap and imagery that we want to integrate. With the second observation, we applythe vector data to help locate the intersection points on both the imagery and maps.The common vector data serves as the “glue” to integrate these two sources.The steps of our approach are illustrated in Figure 10.4. First, we utilize the tech-niques described above to align the road vector data with the imagery to identify the intersection points on the imagery. Then we apply techniques for identifying theintersections on maps (Sebok, Roemer, and Malindzak 1981, Musavi, Shirvaikar,Ramanathan, and Nekovei 1988), which we have extended to support maps withTHO_C10  19/03/2007  11:18  Page 191 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons",
    "chunk_order_index": 123,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f4568f21bf8e295cef7aef3f9551ad01": {
    "tokens": 1200,
    "content": "we have extended to support maps withTHO_C10  19/03/2007  11:18  Page 191 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f192CRAIG A. KNOBLOCK AND CYRUS SHAHABIdouble-lined roads and maps with lots of extraneous data such as on topographicmaps. Next, we apply a specialized point matching algorithm (Irani and Raghavan1999) to compute the alignment between the two sets of intersection points. Thismatching problem is challenging because of the potential of both missing and extraneous intersection points from the map intersection detection algorithms.Finally, we use the resulting set of control point pairs to automatically conﬂate themap and image.Experimental results on the city of El Segundo, California demonstrate that ourapproach leads to remarkably accurate alignments of maps and satellite imagery.The aligned map and satellite imagery supports inferences that could not have beenmade from the map or imagery alone. Figure 10.5 shows an example of our resultsfor the city of El Segundo.Map with UnknownCoordinatesDetect IntersectionPoints On the MapPoint PatternMatching& ConflationDetect Points On theSatellite Imagery/Vector DataVectorDataTIGERLineFig. 10.4Automatic conﬂation of maps with imageryFig. 10.5Results of conﬂating MapQuest map with imageryTHO_C10  19/03/2007  11:18  Page 192 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOSPATIAL DATA INTEGRATION193Integrating Online Schedules (Moving Objects) with VectorsThis ﬁnal example of geospatial data integration is rather different than the pre-vious cases in that it integrates spatial sources with temporal ones. In particular,we study the integration of vector data sets, for example, train tracks or road networks, with routing schedules such as train or bus schedules. In the databaseliterature, the querying of these speciﬁc types of spatio-temporal sources is some-times referred to as “moving object queries” or “spatio-temporal range queries”.In previous work (Shahabi, Kolahdouzan, and Sharifzadeh 2003), we investigatedthese queries. However, one of our previous studies (Shahabi, Kolahdouzan, Thakka,Ambite, and Knoblock 2001) stands out in that it is the only one we are aware ofthat focuses on the “integration” challenges in efﬁcient support of queries on spatio-temporal sources.In Shahabi Kolahdouzan, Thakkar, Ambite, and Knoblock (2001), we assumeda mediator-based web architecture, where some of the information sources con-tain spatial and temporal data. For example, a temporal source may be a wrappedwebsite providing train schedule information, while a spatial source is a databasecontaining railroad vector data. A spatio-temporal range query would then imposebounds on spatial and temporal attributes and ask for all tuples satisfying the con-straints. For example, given a point on the vector data and a time interval, we wouldlike to ﬁnd all the trains that would pass that point in the given time interval. Theuser interface of this application is shown in Figure 10.6, where the railroad vectordata is drawn on a map and the point on the vector data is shown with an “x.”The bottom part of Figure 10.6 lists all of the trains that will pass the point andthe estimated time they will reach that point.There are two main integration challenges with this application. First, as in theprevious cases, we need an accurate alignment of railroad tracks with maps and/or imagery. Here we can utilize the techniques described in previous sections by using the train stations as control point pairs. The other challenge is the efﬁcientintegration of spatial and temporal data to answer spatio-temporal queries.Evaluation of spatio-temporal range queries on distributed sources is time con-suming because of the complex computational geometry functions (for example,the shortest path function) that need to be executed on the large volume of vectordata as well as the temporal intersections that need to be applied among large sets oftime intervals. One solution to reduce the query processing time of spatio-temporalrange queries is to pre-compute the required information and materialize it usinga moving object data model such as the 3D Trajectory model (Vazirgiannis andWolfson 2001). This is a feasible approach if we assume that different schedule,railroad, and station information is all local and something over which we havefull control. However, with our assumed distributed environment, the sources ofinformation that we would like to access are autonomous and dynamic.Therefore, we investigated alternative distributed query plans to realize the integra-tion of spatial and temporal information (for example, for the railroad network andtrain schedules) from distributed, heterogeneous web sources. One approach to this problem is to ﬁrst look into the spatial source (containing railroads) and ﬁlterout only the railroad segments that overlap with the window query (spatial ﬁlter).THO_C10  19/03/2007  11:18  Page 193",
    "chunk_order_index": 124,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ee4840241e8162a6748044ea9bc41771": {
    "tokens": 1200,
    "content": ", we investigated alternative distributed query plans to realize the integra-tion of spatial and temporal information (for example, for the railroad network andtrain schedules) from distributed, heterogeneous web sources. One approach to this problem is to ﬁrst look into the spatial source (containing railroads) and ﬁlterout only the railroad segments that overlap with the window query (spatial ﬁlter).THO_C10  19/03/2007  11:18  Page 193 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f194CRAIG A. KNOBLOCK AND CYRUS SHAHABINext, for those qualifying segments, we check the temporal source (containing trainschedules) and ﬁnd the trains passing through the segments during the query time interval (temporal ﬁlter). Another approach is to do the same in the oppositeorder. We investigated both of these traditional ﬁlter+semi-join plans by applyingthe temporal ﬁlter ﬁrst and then performing the spatial semi-join or vice versa.However, we showed that there are two signiﬁcant drawbacks with both these plans.Fig. 10.6Integration of train schedules with vector data and mapsTHO_C10  19/03/2007  11:18  Page 194 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOSPATIAL DATA INTEGRATION195Instead, we introduced a novel spatio-temporal ﬁlter (termed deviation ﬁlter), whichcan exploit the spatial and temporal characteristics of the data simultaneously toimprove the selectivity.CONCLUSIONSIn this chapter we described a set of techniques for integrating geospatial data. These techniques are by no means comprehensive, but provide a set of examplesof how the wide range of geospatial data can be combined in novel ways. The techniques for extracting data from online sources make available a wide range ofdata from online sources that can now be integrated with geospatial data sources.The approach to automatically aligning road vector data with imagery makes itpossible to accurately identify roads in imagery and shows how we can combinedifferent sources of information (that is, what is known about the vector and whatcan be extracted from the imagery) to automate difﬁcult tasks. The integration of the constraint satisfaction techniques with the property tax data, imagery, andvector data provides an approach to identify the structures in imagery and showshow the combination of diverse types of data can provide new information. Theautomatic alignment of street maps with imagery provides an approach to exploit-ing maps that lack geospatial coordinates and is an example of how seemingly incompatible sources can be fused to provide new insights into the individual dataproducts. Finally, the combination of online schedules with railroad vectors pro-vides an approach to efﬁciently predicting the location of moving objects and provides another example of inferring new information from diverse sources of geo-spatial data. In sum, the techniques presented in this chapter are illustrative of the many possible ways of integrating the wide range of geospatial data that areavailable today.REFERENCESAuclair-Fortier, M. F., Ziou, D., Armenakis, C., and Wang, S. 2000.Survey of Work on RoadExtraction in Aerial and Satellite Images.Sherbrooke, Quebec: Université de Sherbrooke,Département de Mathématiques et d’Informatique Technical Report No. 247.Bakshi, R., Knoblock, C. A., and Thakkar, S. 2004. Exploiting online sources to accuratelygeocode addresses. In Proceedings of the Twelfth ACM International Symposium on Advancesin Geographic Information Systems (ACM-GIS ’04),Washington, DC, USA.Chen, C. C., Thakkar, S., Knoblock, C. A., and Shahabi, C. 2003. Automatically annotatingand interpreting spatial datasets. In T. Hadzilacos, Y. Manolopoulos, J. F. Roddick, andT. Theodoridis (eds) Advances in Spatial and Temporal Databases: Proceedings of the EighthInternational Symposium (SSTD 2003), Santorini Island, Greece.Berlin: Springer LectureNotes in Computer Science No. 2750: 469–488.Chen, C. C., Knoblock, C. A., Shahabi, C., Thakkar, S., and Chiang, Y. Y. 2004a. Auto-matically and accurately conﬂating orthoimagery and street maps. In Proceedings of the Twelfth ACM International Symposium on Advances in Geographic Information Systems (ACM-GIS ’04),Washington, DC, USA. New York: Association for ComputingMachinery.THO_C10  19/03/2007  11:18  Page 195 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f196CRAIG A. KNOBLOCK AND CYRUS SHAHABI",
    "chunk_order_index": 125,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-5b3fde8e27d02b25a11f40ad6408b09b": {
    "tokens": 1200,
    "content": "2007  11:18  Page 195 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f196CRAIG A. KNOBLOCK AND CYRUS SHAHABIChen, C. C., Shahabi, C., and Knoblock, C. A. 2004b. Utilizing road network data for automatic identiﬁcation of road intersections from high resolution color orthoimagery. In Proceedings of the Second Workshop on Spatio-Temporal Database Management(STDBM ’04), Toronto, Canada. New York: Association for Computing Machinery, pp. 17–24.Hsu, C. N. and Dung, M. T. 1998. Generating ﬁnite-state transducers for semi-structureddata extraction from the web. Information Systems23: 521–38.Irani, S. and Raghavan, P. 1999. Combinatorial and experimental results for randomizedpoint matching algorithms. Computational Geometry12: 17–31.Knoblock, C. A., Lerman, K., Minton, S., and Muslea, I. 2003. Accurately and reliably extract-ing data from the web: A machine learning approach. In L. A. Zadeh (ed.) IntelligentExploration of the Web.Berkeley, CA: Springer-Verlag: 275–87.Kushmerick, N. 1997. Wrapper induction for information extraction.Unpublished PhD Dis-sertation, Department of Computer Science and Engineering, University of Washington.Musavi, M. T., Shirvaikar, M. V., Ramanathan, E., and Nekovei, A. R. 1988. A vision-basedmethod to automate map processing. Pattern Recognition21: 319–26.Ratcliffe, J. H. 2001. On the accuracy of TIGER-type geocoded address data in relation tocadastral and census areal units. International Journal of Geographical Information Science15: 473–85.Russell, S. and Norvig, P. 1995. Artiﬁcial Intelligence: A Modern Approach.Englewood Cliffs,NJ: Prentice Hall.Saalfeld, A. 1993. Conﬂation: Automated Map Compilation.College Park, MD: Universityof Maryland, Center for Automation Research, Computer Vision Laboratory.Sebok, T. J., Roemer, L. E., and Malindzak, J. 1981. An algorithm for line intersectionidentiﬁcation. Pattern Recognition13: 159–66.Shahabi, C., Kolahdouzan, M. R., Thakkar, S., Ambite, J. L., and Knoblock, C. A. 2001.Efﬁciently querying moving objects with pre-deﬁned paths in a distributed environment.In Proceedings of the Ninth ACM International Symposium on Advances in GeographicInformation Systems (ACM-GIS), Atlanta, GA, USA. New York: Association for ComputingMachinery, pp. 34–40.Shahabi, C., Kolahdouzan, M. R., and Sharifzadeh, M. 2003. A road network embeddingtechnique for k-nearest neighbor search in moving object databases. Geoinformatica7:255–73.Vazirgiannis, M. and Wolfson, O. 2001. A spatiotemporal model and language for movingobjects on road networks. In Proceedings of the Seventh International Symposium on Spatialand Temporal Databases (SSTD), Redondo Beach, CA, USA. New York: Association forComputing Machinery, pp. 20–35.THO_C10  19/03/2007  11:18  Page 196 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPart IIIVisualizationThis third section of the book consists of seven chapters that explore some of therecent accomplishments and outstanding challenges concerned with the visualiza-tion of spatial data. The ﬁrst chapter, Chapter 11 by William E. Cartwright, startsout by describing the digital pre-web endeavors of designers and cartographers and the various applications of new media (for example, hypermedia, videodisks,CD-ROMs) that led to the establishment of theories and practical methods for inter-active multimedia map production. The role of traditional cartographic theory and practice and contributions of computer-assisted cartography and GeographicInformation Systems are highlighted along with the challenges that new media posefor those involved in the design and provision of contemporary mapping products.The conclusion describes some of the products available on the Web for both expertand novice map users.Chapter 12 by William A. Mackaness, the second chapter in this group, examinesthe role of generalization and scale in this digital age where the database is theknowledge store and the map is the metaphorical window by which geographicalinformation is dynamically explored. The key generalization concepts, methods, andalgorithms that have been proposed for creating and evaluating candidate solutionsfor graphical visualization and multiple representations are described. Mackaness(like Cartwright in the previous chapter) concludes by noting the importance of the art and science of cartography as well as the need for it to keep abreast of thechanging environments of",
    "chunk_order_index": 126,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b436a092e498ce9054817b3d1b96619d": {
    "tokens": 1200,
    "content": "and scale in this digital age where the database is theknowledge store and the map is the metaphorical window by which geographicalinformation is dynamically explored. The key generalization concepts, methods, andalgorithms that have been proposed for creating and evaluating candidate solutionsfor graphical visualization and multiple representations are described. Mackaness(like Cartwright in the previous chapter) concludes by noting the importance of the art and science of cartography as well as the need for it to keep abreast of thechanging environments of map use and analysis and broader developments in visual-ization methodologies if it is to remain relevant.In the next chapter, Chapter 13, Nicholas J. Tate, Peter F. Fisher, and David J.Martin looks at some of the opportunities and challenges that are encountered whendisplaying and analyzing a variety of geographical phenomena as surfaces. The chapter starts with a discussion of the advantages of surface representation and moves quickly to explore the various types of surface model used in GIS given thatsurface modeling is a necessary precursor to surface analysis and visualization. Theauthors then move on to examine some of the more popular and powerful visual-ization tools afforded by surfaces, and they conclude their chapter by summarizingthe unique place of surface representation and visualization in GIS.THO_C11  20/03/2007  16:36  Page 197 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f198VISUALIZATIONVincent B. Robinson describes the basic concepts underlying fuzzy set theory and their relationship to fuzzy classiﬁcation and mapping in GIS in Chapter 14.The ﬁrst part of the chapter summarizes the basic approaches to assigning a fuzzymembership value to a location and then visualizing that classiﬁcation. The two basicapproaches – fuzzy classiﬁcation with a priori knowledge and data-driven fuzzyclassiﬁcation – are described in considerable detail along with visualization strategiesand challenges. The latter sections of the chapter discuss the beneﬁts and costs offuzzy classiﬁcation-based mapping systems and software availability to support fuzzyclassiﬁcation – topics that provide a nice conduit to the next chapter by A-XingZhu on predictive rule-based mapping.Zhu focuses in Chapter 15 on predictive or rule-based mapping from a knowledge-based perspective that relies on the qualitative knowledge of human experts (thatis, performing fuzzy classiﬁcation with a priori knowledge). The implementationof rules in rule-based mapping under Boolean and fuzzy logic are compared andthe chapter concludes by noting some of the enduring challenges and research issuesthat will need to be solved to propel rule-based mapping to a new era in the yearsahead.In the next chapter in this group (Chapter 16), Mark Gahegan looks at the opportunities for multivariate visualization. The chapter starts with a brief dis-cussion of the need for multivariate analysis and the different approaches that havebeen utilized to analyze multivariate data. From there, Gahegan notes how the development of multivariate visualization can, and is, approached from a varietyof perspectives and he lists a selection of these approaches as a set of motivatingquestions. The major methods of visualization and a series of visualization examplesare then described in considerable detail. The chapter concludes with descriptionsof some of the ways in which multivariate visualization might support analysis, theprocess of multivariate visualization, the technological tools that contribute to oneor more geovisualization systems, and the problems that remain to be solved beforegeovisualization can fulﬁll its potential.In Chapter 17, the ﬁnal chapter in this group, Michael Batty examines the waysin which digital representations of two-dimemsional space can be enriched and augmented through interactivity with users in the third dimension and beyond. Thischapter starts out by identifying the salient features of virtual reality (VR) and theways in which GIS is being extended to embrace the third dimension, the questionof time, and the media used to communicate this science to users with very differ-ent professional backgrounds and skills. The focus of VR in GI Science is then elaborated by examining different visualizations of 3-dimensional space in termsof geographic surfaces and geometric structures, illustrating the different media inwhich VR environments are constructed and showing how VR is beginning to form as emergent interface to GIS and potentially to GI Science. Batty concludesby speculating that as the digital solution deepens and matures virtual environmentswill become recursive, with many different renditions of the same underlying digitalrepresentation being used in a variety of ways with the same user interface.THO_C11  20/03/2007  16:36  Page 198 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 11Mapping in a Digital AgeWilliam E. CartwrightCartographers have always striven to make their products more accessible, current,and usable. Access to products was greatly enhanced when printing was embracedas a means for making faithful reproductions of geographic information artifacts.Printing changed how information was “packaged” and delivered, including geo-graphic information. Early digital media trials led to the formulation of theoriesabout how best interactive multimedia mapping products might “work” and howconventional practices might be modiﬁed or, in some cases, not used at all. Now theWeb has also revolutionized how we address geographic information design andrealization and, with users in mind, how these",
    "chunk_order_index": 127,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-24a9e014029744100b3021146f6efec0": {
    "tokens": 1200,
    "content": "was embracedas a means for making faithful reproductions of geographic information artifacts.Printing changed how information was “packaged” and delivered, including geo-graphic information. Early digital media trials led to the formulation of theoriesabout how best interactive multimedia mapping products might “work” and howconventional practices might be modiﬁed or, in some cases, not used at all. Now theWeb has also revolutionized how we address geographic information design andrealization and, with users in mind, how these products are procured and utilized.What we do has changed and what we produce has also changed.When compared to other areas of cartography Web mapping is new, but, relat-ively quickly, a new genre of mapping product has evolved. This has caused cartographers to assess how they need to design, produce, and deliver these new,innovative products, resulting in a new “mindset” about what they do and howthey approach and conduct their activities. A new modus operandi (for mapping)has been established, one that facilitates the provision of new and exciting Web-delivered products.This chapter addresses mapping in a digital age from the perspective of usingNew Media for the provision of cartographic artifacts. In doing so it acknowledgesthe important contributions of computer-assisted cartography and GeographicInformation Systems (GIS), and how, in many instances, they have been “harnessed”to interactive multimedia to provide powerful analysis, production, and visualiza-tion tools. In order to appreciate the design and delivery task at hand when usingthe Web, it is appropriate to reﬂect upon what pre-empted Web mapping and someof the New Media foundations that were laid in the heady experimental days ofhypermedia, videodisc, and CD-ROM. Interactive multimedia mapping was new andexciting, and many innovative products were designed and trialed. This chapter beginsby describing the digital pre-Web endeavors of designer-cartographers and the various applications of New Media that led to the establishment of theories andpractical methods for interactive multimedia map production. It then provides THO_C11  20/03/2007  16:36  Page 199 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f200WILLIAM E. CARTWRIGHTand overview of the range of products available on the Web for both expert and novicemap users. Finally, the chapter addresses the challenges that New Media poses thoseinvolved in the design and provision of contemporary mapping products.The WebWith the arrival of the Web, and the use of Berners-Lee’s browser-driven informationdisplays, a different, graphical access method to information was made available. TheWeb is an information discovery system for browsing and searching the Internet’sworldwide “web” of digital information. There now exists almost instant access to geographic information, including maps. The extent and the use of the Internethave now matured to such a point that users see it as an everyday commodity orcommunications device. Education has embraced it for content delivery, face-to-facelecture support, and as a tool for students to keep in touch with academics andpeers, as well as to conduct day-to-day administrative and general queries. Industryuses it as a tool for facilitating more effective logistical approaches. Commerce usesit as a means for linking their services, and business views it as a conduit for marketing, selling, and delivering (digital) products.In The UCLA Internet Report: Surveying the Digital Future (Lebo 2003), theextent to which the Internet has been adopted can be seen. This report providesan annual survey of the impact of the Internet on the social, political and economicbehavior of users and non-users of the Internet. In general, the report noted that•Internet access remained generally stable from 2001 to 2002 and online hoursincreased, as did the use of the Internet at home;•Use of the Internet spans all age groups;•The Internet was seen as an important source of information (in 2002 over 60 percent of all users surveyed considered the Internet to be a very importantor extremely important source of information);•The Internet had increased the number of people that respondents communicatedwith;•Use of the Internet for making purchases online had declined, but the averagenumber of purchases made this way had increased; and•There were growing numbers of people using the Internet for business purposes,from e-mails to business-to-business and business-to-customer transactions.The Web can be “traveled” by following hypertext links from document to document that may reside in any of the many servers in different global locations.In 1993 the ﬁrst Internet workshop on Hypermedia and Hypertext standards washeld. At the end of 1994 there were almost 13 million users of the Internet. By late 1995 this number had risen to 23 million (plus an additional 12 million usingelectronic mail of various kinds) (Parker 1995). The Web grew one home page everyfour seconds and doubled every 40 days. It had 40 million plus users worldwideby early 1996. In terms of Web servers it grew from 130 in 1993 to an estimated660,000 in 1997 (Peterson 1997), by late 1998 servers numbered over 3.5 millionand in June 1999 there were just fewer than 6.2 million servers (Netcraft Web ServerTHO_C11  20/03/2007  16:36  Page 200 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley",
    "chunk_order_index": 128,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-aa3d6f63c3dc2039d0e60a3a59dbc5fe": {
    "tokens": 1200,
    "content": "130 in 1993 to an estimated660,000 in 1997 (Peterson 1997), by late 1998 servers numbered over 3.5 millionand in June 1999 there were just fewer than 6.2 million servers (Netcraft Web ServerTHO_C11  20/03/2007  16:36  Page 200 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE201Surveys 1998, 1999; see http://news.netcraft.com/ for additional details). In 2001this grew to over 110 million Internet hosts (see http://navigators.com/statall.gif foradditional details). In 2004 there were an estimated 945 million Internet users (ClickzStats 2004), 1.08 billion in 2005, and with a projected “population” of 1.8 billionin 2010 (Clickz Stats 2006).Pre-WebA number of trials for using different media were tried pre-Web. Cartographersstrived to “harness” New Media methods that could be employed to facilitate thestorage and presentation of geographic information in more effective and efﬁcientways. This included•Teletext/Videotext;•Two-way interactive television;•Hyperlinked television;•Hypermedia;•Videodisc;•CD-ROM; and•File transfer using the Internet.Teletext/videotextTelevision provides information via news services, documentaries, reports, live links,and ﬁlm archives. For the general public it has become one of the most usable informa-tion resources that supply on-demand information right in the home. Television wasseen as a way in which information could be readily disseminated through the useof teletext in its many forms, like Oracle and CEEFAX using the Prestel (Viewdata)system in the United Kingdom (a one-way system), Antiope in France in the mid-1970s, Telidon in Canada (1975) (a two-way version of the British Prestel system),Captain (1979–81) in Japan and Viatel in Australia. In the USA CBS experimentedwith a system called Extravision, but the system was never implemented.In Australia, where distance has always been an important information provisionissue, the use of teletext/videotext was trialed in the early days of Viatel as an adjunctto other education resources (Hosie 1985). British television ran very basic maps forthe provision of information like weather maps. A typical screen page from CEEFAXis shown in Figure 11.1.By far the most popular service of this type of information resource was Minitel,which replaced Antiope in France. France Telecom launched the system in February1984 and it consisted of a low-cost dedicated terminal in the home or ofﬁce or asan anonymous kiosk charging system. It provided a range of services through theuse of coarse text and graphics (compared to today’s standards) on color televisionscreens, and among its information pages it included the French telephone directory.Minitel proved to be most popular and it saw a rapid growth in consumer interest.At its peak it had 15 million clients in France. A typical information screen is shownin Figure 11.2. The popularity of the Web supplanted Minitel somewhat, and its trafﬁcTHO_C11  20/03/2007  16:36  Page 201 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f202WILLIAM E. CARTWRIGHTplateaued around 1994 (see http:/www.ust.hk/~webiway/content/France/history.htmlfor additional details). However, i-Minitel, France Telecom’s Web information service provides similar information.The potential of using videotext to provide geographic information and mapswas recognized by Taylor (1984), who saw that the Canadian Telidon system couldbe a useful conduit of map images. Maps have been provided using Minitel by multimedia provider SGCI Planfax. This company has offered maps via the Minitelsystem since 1992. Now it provides multimedia maps via the Web, for the FrenchYellow Pages.Fig. 11.1CEEFAX weather mapFrom Pemberton 2004Fig. 11.2Minitel “kiosk” From http://www.ust.hk/~webiway/content/France/history.htmlTHO_C11  20/03/2007  16:36  Page 202 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE203Two-way interactive televisionTwo-way interaction via television/PC/communications equipment is something thatis always being talked about for homes of the future, allowing users/viewers to trulyinteract with broadcast television packages, including mapping packages. Microsoftdeveloped their Tiger interactive television prototype server software in 1994, andlater live television",
    "chunk_order_index": 129,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-064b0bf0db265fb75ca068d2023341c8": {
    "tokens": 1200,
    "content": ".wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE203Two-way interactive televisionTwo-way interaction via television/PC/communications equipment is something thatis always being talked about for homes of the future, allowing users/viewers to trulyinteract with broadcast television packages, including mapping packages. Microsoftdeveloped their Tiger interactive television prototype server software in 1994, andlater live television through the Internet using technology like Intel’s Intercast, whichcombined the PC, television, and the Internet, and “streaming” techniques (a methodwhereby video is compressed as it is sent out over the Internet and then “played”by complementary software on the recipient’s computer). Intercast simultaneouslydelivered text, graphics, video, or data to a PC (equipped with Intercast technology)along with a television signal. Content was created with HyperText Mark-up Language(HTML) and the television signal appeared to the user as a web page. Transmissionof computer data would take place during the vertical blanking intervals of the tele-vision transmission image. The television needed to have a peripheral input device toreceive television signals (cable, broadcast, or satellite), a digitizer to convert analogsignals and a telephone-line modem to send data back through the Internet serviceprovider (Intercast: From Web TV to PC; Advanced Imaging 1996). Now this ismore readily realized with digital television.Hyperlinked televisionConsumers would probably argue that the only geographic information they getfrom television is weather maps and the occasional simple maps that accompanylifestyle programs and travel documentaries. However, pre-Web dominance of in-formation delivery thinking, the use of broadcast television that provided hyperlinksto other types of information was one possible scenario explored theoretically.Negroponte (1996) considered that one possible future scenario for allowing con-sumers to interact with information resources was hyperlinked television, whereby“touching” an athlete’s image on a television screen would produce relevant statistics,or touching an actor reveal that his tie is on sale this week. This would involve em-bedding extra information from a central database into broadcast television signals.Television could react according to the information delivery designer’s intention whenviewed under different circumstances. Negroponte (1996) saw Java contributing tothe idea of hyperlinked television.HypermediaMuch interest was centered on the production of electronic atlases during the late 1980s and early 1990s, mainly due to the availability of Apple’s HyperCardsoftware developed for the Macintosh computer and released in 1987 (Raveneau,Miller, Brousseau, and Dufour 1991). Typical of what was developed was Parson’sCovent Gardenarea prototype (Parsons 1994a, 1994b, 1995). This particular pro-ject presented users with a “through the window” view of the market via a 3Dview in perspective. Users could then navigate around the package using conven-tional cursor controls and mouse clicks on directional arrows indicating movementdirections.THO_C11  20/03/2007  16:36  Page 203 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f204WILLIAM E. CARTWRIGHTAnother hypermap product was HYPERSNIGE (Camara and Gomes 1991). Thiswas somewhat different, as it was developed to run on both the Apple Macintoshusing Hypercardand the PC with Matrix Layout. HYPERSNIGE was a hyper-media system, which included Portugal’s national, regional, and sub-regional mapsand information. Nodes in the system maps, text, and spreadsheets and links are usedfor navigation. Other control structures are numerical, linguistic (logical deductions),and pictorial (overlay). Maps were seen as links to spreadsheets ﬁlled with statisticaldata. They (the maps) could be drawn, imported, and exported. The package wasfurther developed to expand the themes and to incorporate multimedia using DigitalVideo-Interactive (DV-I).VideodiscThe ﬁrst real application was the Aspen Movie Map Project, devised and under-taken by the MIT Architecture Machine Group in 1978 (Negroponte 1995). Thistwo-videodisc system was developed to demonstrate the possibilities of providinginformation using multimedia resources and providing surrogate travel through thecity of Aspen, Colorado. This was the ﬁrst time that the term “multimedia” was usedand it is interesting to note that the ﬁrst multimedia product was in fact a mappingproject. A map and screen image from the system is illustrated in Figure 11.3.A later videodisc product was the Domesdayproject, produced in 1986 by theBBC (British Broadcasting Commission), Acorn Computers, and Philips to com-memorate the 900th anniversary of William the Conqueror’s tally book (Openshawand Mounsey 1986, 1987, Openshaw, Wymer, and Charlton 1986). Two videodiscswere produced for the project, one concentrating on national data and the otheron community information. The community videodisc included surrogate walks likethe Aspen Movie map. A typical screen is shown in Figure 11.4.(a)(b)Fig. 11.3Aspen Movie MapProjectFrom Allen 2003THO_C11  20/03/2007  16:36  Page 204 Downloaded from https://onlinelibrary.wiley.com/doi/ by University",
    "chunk_order_index": 130,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e971aad9cf531609209a02772847c34c": {
    "tokens": 1200,
    "content": "for the project, one concentrating on national data and the otheron community information. The community videodisc included surrogate walks likethe Aspen Movie map. A typical screen is shown in Figure 11.4.(a)(b)Fig. 11.3Aspen Movie MapProjectFrom Allen 2003THO_C11  20/03/2007  16:36  Page 204 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE205CD-ROMThe compact disc, more commonly referred to as the CD, was jointly developed bySony of Japan and Philips of The Netherlands in 1982. Initially, the potential of thelarge storage capacity of CD-ROMs for the distribution of geographic informationfostered interest in publishing digital maps using a new medium (Rystedt 1987,Siekierska and Palko 1986). A wide range of products, initially databases and photo-graphic collections, and later encyclopedia and atlases were made available on thisproduct. As they were made to conform to the ISO 9660 standard they were assured“play” success on all available machines, which ensured that they were widely acceptedand used.An interesting CD-ROM mapping package was The Territorial Evolution of Canadainteractive multimedia map-pack (developed from a prototype atlas as part of theNational Atlas of Canada from the Geographical Sciences Division, Survey andMapping Branch, Department of Energy and Resources (Siekierska and Palko 1986,Siekierska and Armenakis 1999). The product provided an innovative overview of Canada and it exploited the use of interactive multimedia in its truest sense. A “screen grab” from the product is shown in Figure 11.5. The use of discrete medialike CD-ROM or DVD is still a popular means of distributing cartographic products.InternetThe Internet was used before the Web to deliver mapping products and data sets. Usingthe File Transfer Protocol (FTP) ﬁles, usually compressed, were distributed in thismanner. File transfers were quick but the process was burdened with the overheadsof ﬁle compression and subsequent decompression and the need to have appropriatedisplay software on the “receiving” computer (Peterson 2001a). Collections of scannedpaper maps were constructed and delivered to consumers usually as graphic inter-change format (GIF) ﬁles. While an efﬁcient means of providing information, almostimmediately users still needed to undertake some ﬁle manipulations prior to theactual image being displayed. The Web enabled this problem to be eradicated.Fig. 11.4Surrogate walk from the Domesday Community discFrom http://www.binarydinosaurs.co.uk/Museum/Acorn/domesday.htmTHO_C11  20/03/2007  16:36  Page 205 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f206WILLIAM E. CARTWRIGHTWorld Wide WebThe ﬁrst browser was not all that dissimilar to today’s Internet Explorer or Netscapecounterpart, and a current-day user of the Web could easily adapt to this originalmanifestation. Some of the early Web mapping packages used text-heavy interfacesto list the available mapping inventory. The Virtual Atlas, by Ashdowne, Cartwright,and Nevile (1995, 1997) (Figure 11.6) is typical of this genre of geospatial productdeveloped in the “early” days of Web cartography. Once the HTML ﬁle was “clicked”the usual means of viewing geographic information was via a collection of scannedmaps. The CIA World Fact Book and the PCL (Perry Castaneda Library) Map Collec-tion (University of Texas at Austin) provided excellent collections of scanned maps alongwith other pertinent information. A most valuable global resource was made available.Progression of Web MappingAlong with Web development in the early 1990s map provision via this commun-ications media kept pace. Early implementations were scanned collections of imagesand maps, and the Corbis collection of images illustrated the wealth of informationthat could be delivered via the Web. The CIA World Fact Book, for example, madeavailable maps of almost any part of the world. And, while the shortcomings ofscanned maps must be acknowledged, this site made available, as it still continuesto, a plethora of geospatial artifacts and general geographic information. The mapdownloaded from this site in 1998, Figure 11.7, is typical of the type of early pro-duct availability, in this case from the Perry-Castañeda Library. Figure 11.8 showsa similar product from the CIA World Fact Book site. Many simple map access siteswere developed and, while powerful media access tools were provided, the relianceof just scanned maps somewhat limited their effectiveness.Also, quite early, in Web mapping terms, another new genre of “published” mapwas made available, like products from MapQuest. MapQuesthas probably producedthe most impressive product for ﬁnding streets and business locations, especially in theFig. 11.5Territorial evolution of CanadaFrom Siekierska and Armenakis 1999THO_C11  20/03/2007  16:36  Page",
    "chunk_order_index": 131,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-35cca001a87ad260be54c27a047fdbd3": {
    "tokens": 1200,
    "content": "of just scanned maps somewhat limited their effectiveness.Also, quite early, in Web mapping terms, another new genre of “published” mapwas made available, like products from MapQuest. MapQuesthas probably producedthe most impressive product for ﬁnding streets and business locations, especially in theFig. 11.5Territorial evolution of CanadaFrom Siekierska and Armenakis 1999THO_C11  20/03/2007  16:36  Page 206 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE207Fig. 11.6Ashdowne’s Virtual Atlas– initial text interfaceFrom Ashdowne, Cartwright, and Nevile 1997THO_C11  20/03/2007  16:36  Page 207 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f208WILLIAM E. CARTWRIGHTUSA. Using these resource users can pick a country, zoom into part of it, and thendown to street level. If two addresses in the USA are known, then both maps androute instructions can be generated and viewed. Whilst a complete coverage of theUSA is available, a sparser street database is available for other countries. Never-theless, the MapQuestproduct is a perfect example of Web-delivered information.Figure 11.9 shows early (1997) MapQuestproducts.Problems with scanned maps may include image quality degradation, warpingfrom improper scanning, coarse scanning resolutions, and over-reduction that rendermany maps unreadable. However, users have accepted these products because oftwo factors: lower cost (or free) and time (almost immediate delivery of products)(Peterson 2001b).Fig. 11.7Perry-Castañeda Library, The University of Texas at Austin map of AustraliaTHO_C11  20/03/2007  16:36  Page 208 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE209The Web changed map publishing forever. More maps were made available for freeor at modest costs. In addition, collections of valuable maps, once only accessibleby a visit to a library or map collection, were now made available to researchersand general map users. Web publishing has become proliﬁc, and Peterson (2001a)noted that by the mid-1990s a single computer operated by Xerox PARC researchfacility processed over 90,000 Internet requests for maps every day.Range of Products and UsageIn general terms, mapping services available on the Web include: (1) map and imagecollections; (2) downloadable data stores; (3) information services with maps; (4) online map-generation services; (5) Web atlases; and (6) hybrid products (Cart-wright 2002). These products are brieﬂy described below.Fig. 11.8CIA World Fact Book map of AustraliaTHO_C11  20/03/2007  16:36  Page 209 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f210WILLIAM E. CARTWRIGHTMap and image collectionsThe extent of map libraries on the Web can be illustrated by the sheer numberlisted in the University of Minnesota’s Web page (University of Minnesota 2000). Itincludes details of sites (numerous) in the USA as well as global libraries that provideWeb access. A large site to access geospatial information is the Alexandria DigitalLibrary (Andresen, Carver, Dolin, et al. 1997, see http://www.alexandria.ucsb.edufor additional details). It focuses on the provision of spatially indexed informa-tion via the World Wide Web (WWW). It contains a collection of geographically referenced materials and services for accessing those collections. The project is beingfurther developed via the Alexandria Digital Earth Prototype (ADEPT), funded for 1999–2004 by the US National Science (Alexandria Digital Library Project 2000).This type of Web resource is extremely helpful where access to rare or uniquemaps would otherwise be difﬁcult or impossible. Oxford University’s Bodleian Library,a repository of numerous historical artifacts including many related to Oxford and Oxfordshire, makes available via the Web a number of rare map facsimiles.These high-resolution scanned images may be used by scholars in papers withoutthe need to formally request copyright clearance. A typical image is illustrated inFigure 11.10.Fig. 11.9MapQuest – Victoria, Australiahttp://www.mapquest.com/cgi-bin/ia_ﬁ",
    "chunk_order_index": 132,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-150208fc143feb3f504dac90c41c38f4": {
    "tokens": 1200,
    "content": "otherwise be difﬁcult or impossible. Oxford University’s Bodleian Library,a repository of numerous historical artifacts including many related to Oxford and Oxfordshire, makes available via the Web a number of rare map facsimiles.These high-resolution scanned images may be used by scholars in papers withoutthe need to formally request copyright clearance. A typical image is illustrated inFigure 11.10.Fig. 11.9MapQuest – Victoria, Australiahttp://www.mapquest.com/cgi-bin/ia_ﬁnd?screen=ia_ﬁnd&link=ia_ﬁnd&uid=a09a4uc0e09edcaccessed July 26, 1997THO_C11  20/03/2007  16:36  Page 210 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE211Downloadable data storesDigital geospatial information ﬁles can be accessed and downloaded online. Webrepositories have been established by both governmental and private mapping organizations to streamline how these products are marketed, sold and delivered.Typical sites include•US Geological Survey (http://mapping.usgs.gov/www/products/status.html);•National Mapping, Australia (formerly AUSLIG) (http://www.auslig.gov.au/index.html);•Land Victoria – through its LandChannel site; and•Map Machine (National Geographic Society).In mid-1998 the Victorian Government, Australia went online with its land-relatedinformation and is part of the Electronic Service Delivery program of the StateGovernment of Victoria. Information provided, focusing around the themes of workand home, is related to: (1) buying a property; (2) selling a property; (3) renting andleasing; (4) planning and building; and (5) the land around us. Figure 11.11 illustratesthe information provided on this site.These sites have been developed with the express purpose of making maps morereadily available to the general public and professional map users. Most important,they also allow the information to be made available with little cost to the provid-ing organization due to the “hands-free” nature of Web delivery.Fig. 11.10Bodleian Library: Plan for rebuilding...London – J Evelyn 1666From http://www.rsl.ox.ac.uk/nnj/mapcase2.htmTHO_C11  20/03/2007  16:36  Page 211 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f212WILLIAM E. CARTWRIGHTInformation services with mapsPublishing houses that have traditionally published their information as paper mapsand books now use the Web to provide extra information to support their paperpublications. The sites are numerous, and they are provided by travel informationpublishers. In Australia, Melbourne-based Paciﬁc Access Pty Ltd., a Telstra Company,publish their Whereisstreet atlas (http://www.whereis.com.au/). Users gain accessto a set of Universal Business Directory’s (UBD) scanned street maps by typing-ina street address for Melbourne, Sydney, Brisbane, Gold Coast, Sunshine Coast,Canberra, Perth, and Adelaide. A map is returned along with a UBD map reference.The user is able to navigate to adjoining maps by clicking hot spots on the edgesof the displayed maps. Parent company, Paciﬁc Access Pty Ltd of Melbourne alsopublish paper and Web versions of the Australian White Pages™ directory and YellowPages®directory web sites, and the Whereisgeographical search functionality is builtinto these sites. Fully interactive Whereisstreet atlas maps can be embedded withinAustralian corporate web sites. See Figure 11.12 for an illustration of their site.On-line map generation servicesIn Australia the ﬁrst publicly available online environmental information was theEnvironmental Resources Information Network (ERIN) online service (EOS) (a national facility to provide geographically related environmental information requiredfor planning and decision-making). EOS provides public access to tables, maps, images,Fig. 11.11LandChannel, Government of VictoriaTHO_C11  20/03/2007  16:36  Page 212 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE213and large databases. Users can undertake their own spatial modeling by passing SQLcommands direct to the database. Another product is the Australian Coastal Atlas(ACA) that was initially a component of the Commonwealth Coastal Policy and isnow a major component of the Coasts and Clean Seas Initiative. It is an electronicatlas or gateway drawing together the combined data holdings of the Commonwealthin the coastal zone. An Australian Coastal Atlas prototype provides an interactiveWWW–GIS interface that uses pre-prepared GIFs of the 250,000-scale AustralianNational Mapping map sheet with GIS information and allows the user to overlaythese GIFs (Blake 1998). Users access AUSLIG maps that form part of the “tiled”mapping resource and also make their own maps (see Figure 11",
    "chunk_order_index": 133,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9177b1865c24a8654f2d2fa073a28264": {
    "tokens": 1200,
    "content": ". It is an electronicatlas or gateway drawing together the combined data holdings of the Commonwealthin the coastal zone. An Australian Coastal Atlas prototype provides an interactiveWWW–GIS interface that uses pre-prepared GIFs of the 250,000-scale AustralianNational Mapping map sheet with GIS information and allows the user to overlaythese GIFs (Blake 1998). Users access AUSLIG maps that form part of the “tiled”mapping resource and also make their own maps (see Figure 11.13).Web atlases and street directoriesAtlas producers, now having to face the realities of the expense of paper publishingand associated distribution costs, increasingly use the Web as a means of providingatlases of countries and regions. Many different conﬁgurations have been assembled,from the very simple to the more complex. One of the early products to be placedonline was the Atlas du Quebecet ses Regions, produced at the University of Quebecat Montreal (see http://www.unites.uqam.ca/atlasquebec/frameSet/fs05.01.html foradditional details).Fig. 11.12WhereIs map informationFrom http://www.whereis.com.auTHO_C11  20/03/2007  16:36  Page 213 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f214WILLIAM E. CARTWRIGHTAnother Canadian product that illustrates the effectiveness of providing atlas products via the Web is the National Atlas of Canada Quick Maps. This product pro-vides a number of ready-made maps, as well as the provision for users to “construct”their own maps. The atlas was produced by Natural Resources Canada and it isan excellent example of how atlases can be delivered online. The introductory pageis illustrated in Figure 11.14.Hybrid productsCombined discrete/distributed products that publish on the Web, on CD-ROM andon paper are also being developed. These products include the US Geological Survey’s(USGS) national atlas of the United States, published on both CD-ROM and theWeb (Guptill 1997). Perhaps one of the most impressive publications of this typeFig. 11.13Australian Coastal AtlasFrom http://www.environment.gov.au/marine/coastal_atlas/atlaspage.htmle/quickmap.htmlTHO_C11  20/03/2007  16:36  Page 214 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE215is the 2001 Atlas of Switzerland (http://www.swisstopo.ch/en/digital/adsi.htm),published on CD-ROM, online via the Web, and as an elegantly bound paper atlas.The atlas has been developed at the Department of Cartography at the ETH inZurich, which has always developed and produced the atlas on behalf of the Swissgovernment. Figure 11.15 illustrates a “page” from the atlas.Travel informationA major Australian-based travel information resource online is Lonely PlanetDestinations. Lonely Planet is an Australian company. Currently there are over 200 Lonely Planet titles in print that provide information via walking guides, atlases, phrasebooks, and the “Journeys” series of travel literature. Their Web site(http://www.lonelyplanet.com.au/) provides Destinations – an online guide to traveldestinations, Optic Nerve – an online photographic collection, On the Road (extractsFig. 11.14National Atlas of Canada Quick MapsTHO_C11  20/03/2007  16:37  Page 215 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f216WILLIAM E. CARTWRIGHTfrom the Journeys book series), The Thorn Tree (an electronic travelers’ bulletinboard), Postcards (access to individual travelers’ thoughts on unique destinations),and Health information.Going WirelessThe ﬁrst cellular mobile telephone network was introduced in Japan in 1979. Sincethen the coverage and the use of mobile devices has grown tremendously. Currentlymobile telephones have reached almost saturation point in terms of everyday use.However, using these devices to access geospatial information has not yet been properly exploited. As the information delivery infrastructure is already in place, andbecause of the fact that the graphics displays on telephone devices are always beingimproved, they offer the potential for delivering usable geoinformation graphics andsupport information like sound, or a series of Short Messaging Service (SMS) textual“prompts” to assist navigation. A number of developments that are of interest togeoinformation provision have taken place, including Nokia’s Smart Messaging System(SMS; see http://www.forum.nokia.com/ for additional details) and the WirelessApplication Protocol (WAP). WAP is simply a protocol – a standardized way thata mobile phone talks to a server installed in the mobile phone network. WAP tele-phones can deliver images as well as alphanumerics, making it a useful advertisingtool (see http://www.mobileaccess.be/pages/products/wap",
    "chunk_order_index": 134,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-8579d357706573697fab6f30fcbd8945": {
    "tokens": 1200,
    "content": "interest togeoinformation provision have taken place, including Nokia’s Smart Messaging System(SMS; see http://www.forum.nokia.com/ for additional details) and the WirelessApplication Protocol (WAP). WAP is simply a protocol – a standardized way thata mobile phone talks to a server installed in the mobile phone network. WAP tele-phones can deliver images as well as alphanumerics, making it a useful advertisingtool (see http://www.mobileaccess.be/pages/products/wap.thm for additional details).Fig. 11.15Atlas of SwitzerlandTHO_C11  20/03/2007  16:37  Page 216 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE217Mapping applications have been developed to deliver mainly trafﬁc information services by the French company, Webraska (see a screen output from an early Euro-pean application in Figure 11.16).Wireless is now seen as part of the Internet, and not distinct. It is increasinglybeing used as a “gateway” to resources provided via the Internet. The provision of geospatial information via these devices has spawned a whole new Location Based Services (LBS) industry that provides information on-site (see Chapter 32 by Brimicombe, this volume, for additional information on this topic). The loca-tion services, sometimes referred to as L-commerce, have seen European operatorsstruggling to create LBS revenue models. Short Message Services (SMS) was seenas providing the most dependable revenues from location services over the next several years (Gisler 2001). “Assisted GPS location solutions have been looked-upon favorably by the ‘location services’ company Snaptrack and telco Sprint, whohave conducted a joint case study. The industry sees that the biggest potential money earner is mobile location entertainment, especially amongst teenagers”(Gisler 2001).A fairly recent example of enterprise using LBS is the Zingo cab service in London(www.zingotaxi.co.uk), which provides a direct connection between available taxisand subscribers. Users call Zingo from a pre-registered mobile telephone, then Zingo’s location technology – Cellular and Global Positioning System (GPS) forthe user, and GPS for the taxi – links the customer with the nearest available taxi(Zingo 2003). The system pinpoints the potential passenger’s location by lockingon to the location of the mobile phone. The system operates using the UK’s Vodafone,O2, Orange, Virgin, and Three cellular telephone systems. It works automaticallywith O2 and Vodafone. In April 2003 there were 400 cabs using this system, with“several thousand” planned (Rubens 2003).Obviously the accuracy of the delivery of these services based on location variesbetween urban areas and rural areas and from country to country, where the saturation of mobile telephone transmission towers might be different. Europeanand Japanese companies were the ﬁrst to market solutions based on these impre-cise location technologies, using the cell ID (see http://www.jlocationservices.com/for additional details). Accuracy requirements are context and application-speciﬁcFig. 11.16WAP-enabled cellular telephone delivering map information from WebraskaTHO_C11  20/03/2007  16:37  Page 217 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f218WILLIAM E. CARTWRIGHT– emergency services and navigation requiring the highest degree of accuracy andweather and general information the least (Gisler 2001). The accuracy can be enhancedusing GPS, hence the interest in GPS-enabled mobile phones. It is predicted that95 percent of all handsets sold in the USA by 2005 will be location-enabled.Ubiquitous computing is also of much interest to computer technologists and alsocartographers. Ubiquitous computing has been named as the “third wave” in com-puting, or “the age of calm technology, when technology recedes into the backgroundof our lives” as described by the father of ubiquitous computing, the late Mark Weiser(Weiser 1996). We now see this type of computing in the form of handheld PCs,mobile phones, wireless sensors, radio tags, and Wi-Fi (Baard 2003). Designers ofubiquitous systems envision seeding private and public places with sensors and trans-mitters that are embedded into objects and hidden from view, providing for thedeployment of things like “Audio Tags,” which play an infrared sensor-triggeredmessage once a person is within a pre-determined proximity (Wired News 2003). TheInternational Cartographic Association recently formed a Commission on UbiquitousCartography to promote the study of this form of information provision.Advancing Mapping in a Digital AgeIt can be argued that maps were in fact the ﬁrst multimedia products – as they con-tain text, diagrams, graphics (as ordered symbols), and geographic facts. Paper mapscould be considered to be analog Virtual Reality (VR) tools. They have providedthe means by which armchair travelers could “go” to places from the comfort oftheir lounge or study. The rules that govern their design, production, and consumptionhave evolved over centuries, and the methods of producing maps via",
    "chunk_order_index": 135,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-813ccbb7e75e5122963a9b22e146b2e8": {
    "tokens": 1200,
    "content": "Digital AgeIt can be argued that maps were in fact the ﬁrst multimedia products – as they con-tain text, diagrams, graphics (as ordered symbols), and geographic facts. Paper mapscould be considered to be analog Virtual Reality (VR) tools. They have providedthe means by which armchair travelers could “go” to places from the comfort oftheir lounge or study. The rules that govern their design, production, and consumptionhave evolved over centuries, and the methods of producing maps via the printingpress have been established by 500 years of experiment and development. However,multimedia cartography on the Web is relatively new and its use as a geographicvisualization tool is still virtually unproven. There is little real information about“best use” with interactive multimedia cartographic tools. Applying old ways to newtools may be the “line of least resistance,” but it perhaps does not allow usto properly exploit New Media and new communications systems. In addition, asthere are no comprehensive skills packages for teaching how to use interactive multimedia effectively, there exists no “starting point” to decipher if the use of these products is any better than using a conventional paper map.Cartographers once knew their users: they knew what they wanted and how they intended to use the cartographic artifact produced. It could be argued of con-ventional paper maps that these products were not considered to be “mainstream”information documents but specialist artifacts to be used by expert users, or userswho were willing to “learn the rules” of map use. There now exists a new genreof users. Many may never have used maps before and they consider geographicinformation in the same way as any other commodity that they can obtain via theWeb. Now, with almost instant access to geographic data and graphic products via the Web, it is argued that the general public now considers Web-delivered mapsto be just part of what New Media delivers. Geographic information delivered throughthe use of New Media is seen as part of popular media, rather than scientiﬁc docu-ments. As the Web can be considered as an accepted part of popular media, usersTHO_C11  20/03/2007  16:37  Page 218 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE219could consider its employing it in similar ways to those in which they use television,video, movies, books, newspapers, journals, radio, and CD-ROM. The delivery ofcartographic artifacts via the Web to naive or inexpert users involves different stra-tegies to traditional map delivery and use. Use strategies need to be developed, tested,and implemented.CONCLUSIONSThe revolution in information provision prompted by the advent of the Internet, andmore particularly the World Wide Web, has changed forever how information prod-ucts are viewed. They are now wanted, no demanded, almost immediately by users.In newspaper terms this would be described as wanting information “before the inkhas dried,” but for digital information this is probably best described as wantinginformation “before the data collection sensor has cooled”! Advances in data collection and telecommunications ensure that collected data is quickly and faith-fully transmitted. Processing procedures and equipment, map “construction” and“rendering” software and geographical information delivery systems now providethe ability to deliver on-demand geo-information products in almost real time.Everything has changed, but the underlying theory and procedural knowledgeremain the same. We have powerful tools for the provision of information that hascurrency, accuracy, and immediacy, but how we apply them depends upon adequateknowledge of cartographic theory and practices. This “new” method of access to andrepresentation of geospatial information is different to formerly used methods and therefore, while New Media applications can be considered to be at a fairlyimmature stage of development (compared to paper maps), there is a need to identifythe positive elements of the media used and to isolate the negative ones, so as todevelop strategies to overcome any deﬁciencies. Web designers and graphic artistscan produce elegant information displays for the Web, but the integrity of their map-related products could be questioned. Without adequate grounding in the geospatialsciences, graphical presentations with impact and panache can be produced, butthey may be documents of misinformation. We need to ensure that what is deliveredvia the Web that relates to the provision of geographic information is produced to high standards, of both design and information content, and that users com-prehend the underlying structure of the data and the manipulations, or “cartographicgymnastics” that have been employed to ensure that the data is presented in thebest possible manner and are thoroughly understood by users.REFERENCESAdvanced Imaging. 1996. Intercast: From Web TV to PC. April, 52.Allen, R. 2003. Aspen Movie Map, 1978–80.WWW document, http://rebeccaallen.com/v1/work/work.php?isResearch=1&wNR=18&ord=alph&wLimit=1.Andresen, D., Carver, L., Dolin, R., Fischer, C., Frew, J., Goodchild, M., Ibarra, O., Kothuri,R., Larsgaard, M., Manjunath, B., Nebert, D., Simpson, J., Smith, T., Yang, T., and Zheng,Q. 1997. The WWW Prototype of the Alexandria Digital Library. WWW document, http://alexandria.sde.ucsb.edu/public-documents/papers/japan-paper.htm.THO_C11  20/03/2007",
    "chunk_order_index": 136,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-066b8ec2d30456c3034b8b57dc960741": {
    "tokens": 1200,
    "content": "Frew, J., Goodchild, M., Ibarra, O., Kothuri,R., Larsgaard, M., Manjunath, B., Nebert, D., Simpson, J., Smith, T., Yang, T., and Zheng,Q. 1997. The WWW Prototype of the Alexandria Digital Library. WWW document, http://alexandria.sde.ucsb.edu/public-documents/papers/japan-paper.htm.THO_C11  20/03/2007  16:37  Page 219 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f220WILLIAM E. CARTWRIGHTAshdowne, S., Cartwright, W. E., and Nevile, L. 1995. Designing a virtual atlas on the WorldWide Web. In Proceedings of AUSWEB ’95, Ballina, Australia (available at http://ausweb.scu.edu.au/aw96/educn/ashdowne/).Ashdowne, S., Cartwright, W., and Nevile, L. 1997. A virtual atlas on the World Wide Web:Concept, development and implementation. In Proceedings of the Eighteenth InternationalCartographic Conference,Stockholm, Sweden, pp. 663–72.Baard, M. 2003. A connection in every spot. Wired News(October 16; available athttp://www.wired.com/news/print/0,1294,60831,00.html).Blake, S. 1998. Customising maps on the World Wide Web: The Australian Coastal Atlas,an interactive GIS approach. In Proceedings of theMapping Sciences ’98 Conference,Fremantle, Australia. Freemantle, Australia: Mapping Sciences Institute, Australia.Camara, A. and Gomes, A. L. 1991. HYPERSNIGE: A navigation system for geographicinformation. In Proceedings of the Second European Conference on Geographical Informa-tion Systems (EGIS ’91), Brussels, Belgium, pp. 175–9.Cartwright, W. E. 2002. From printing maps to satisfy demand to printing maps on demand.In B. Cope and D. Mason (eds) Markets for Electronic Book Products. Melbourne: CommonGround Publishing, pp. 81–96.Clickz Stats. 2004. Population Explosion! WWW document, http://www.clickz.com/stats/big_picture/geographics/article.php/5911_151151.Clickz Stats. 2006. Trends & Statistics: The Web’s Richest Source. WWW document,http://www.clickz.com/stats/web_worldwide/.Gisler, M. 2001. Rome mobile location services conference attracts industry leaders. WLIANewsletter(available at www.wliaonline.com/publications/romeconference.html).Guptill, S. C. 1997. Designing a new national atlas of the United States. In Proceedings of the Eighteenth International Cartographic Conference,Stockholm, Sweden. Stockholm:International Cartographic Association, pp. 613–9.Hosie, P. 1985. Promises, promises: Viatel and education. Australian Journal of EducationalTechnology1: 39–46.Lebo, H. 2003. The UCLA Internet Report: Surveying the Digital Future.Los Angeles, CA: UCLA Center for Communication Policy (available at http://ccp.ucla.edu/pdf/UCLA-Internet-Report-Year-Three.pdf).Negroponte, N. 1995. Being Digital.Rydalmere: Hodder and Stoughton.Negroponte, N. 1996. Object-oriented television. Wired3(7): 188.Netcraft. 1998. Netcraft Web Server Survey. WWW document, http://survey.netcraft.com/Reports/.Netcraft. 1999. Netcraft Web Server Survey. WWW document, http://survey.netcraft.com/Reports/.Openshaw, S. and Mounsey, H. 1986. Geographic information systems and the BBC’sDomesday interactive videodisk. In Proceedings of Auto Carto 1,London, United Kingdom.Bethesda, MD: American Congress of Surveying and Mapping/American Society forPhotogrammetry and Remote Sensing, pp. 539–46.Openshaw, S. and Mounsey, H. 1987. Geographic information systems and the BBC’sDomesday interactive videodisk. International Journal of Geographical Information Sys-tems 1: 173–9.Openshaw, S., Wymer, C., and Charlton, M. 1986. A geographical information and map-ping system for the BBC Domesday optical discs. Transactions of the Institute of BritishGeographers11: 296–304.Parker, H. D. 1995. What does the Internet’s future hold? GIS World8(11): 118.Parsons, E. 1994a. Virtual worlds technology: The ultimate GIS visualization tool. In Pro-ceedings of AGI ’94, Birmingham, United Kingdom. London: Association for GeographicInformation.THO_C11  20/03/2007  16:37  Page 220 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA",
    "chunk_order_index": 137,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b739cbc472f0823408a292a9bc4b72a3": {
    "tokens": 1200,
    "content": "I ’94, Birmingham, United Kingdom. London: Association for GeographicInformation.THO_C11  20/03/2007  16:37  Page 220 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMAPPING IN A DIGITAL AGE221Parsons, E. 1994b. Visualisation techniques for qualitative spatial information. In Proceed-ings of EGIS ’94,Paris, France. Utrecht: EGIS Foundation, pp. 407–15.Parsons, E. 1995. GIS visualization tools for qualitative spatial information. In P. Fisher (ed.)Innovations in GIS 2. London: Taylor and Francis, pp. 201–10.Pemberton, A. 2004. Teletext: The Early Years. WWW document, http://www.pembers.freeserve.co.uk/Teletext/Photographs.html.Peterson, M. P. 1997. Trends in Internet map use. In Proceedings of Eighteenth Interna-tional Cartographic Association Conference,Stockholm, Sweden. Stockholm: InternationalCartographic Association, pp. 1635–42.Peterson, M. P. 2001a. Cartography and the Internet: Implications for Modern Cartography.WWW document, http://maps.omaha.edu.NACIS/paper.htm.Peterson, M. P. 2001b. Cartography and the Internet: Introduction and Research Agenda.WWW document, http://maps.omaha.edu.NACIS/CP26/article1.htm.Raveneau, J.-L., Miller, M., Brousseau, Y., and Dufour, C. 1991. Micro-Atlases and the diffusion of geographic information: An experiment with Hypercard. In D. R. F. Taylor(ed.) Geographic Information Systems: The Microcomputer and Modern Cartography.Oxford: Pergamon, pp. 201–24.Rubens, P. 2003. How to hail a cab with a mobile phone. BBC News (available at http://newsvote.bbc.co.uk/mpapps/pagetools/print/news.bbc.co.uk/1/hi/uk/2946129.stm).Rystedt, B. 1987. Compact disks for distribution of maps and other geographic informa-tion. In Proceedings of the Thirteenth International Cartographic Association Conference,Morelia, Mexico. Stockholm: International Cartographic Association, pp. 479–84.Siekierska, E. M. and Armenakis, C. 1999. Territorial evolution of Canada – An interactivemultimedia cartographic presentation. In W. E. Cartwright, M. P. Peterson, and G. Gartner(eds) Multimedia Cartography. Heidelberg: Springer-Verlag, pp. 131–9.Siekierska, E. M. and Palko, S. 1986. Canada’s electronic atlas. In Proceedings ofAutoCarto 2, London. Falls Church, VA: American Congress of Surveying and Mapping-American Society of Photogrammetry and Remote Sensing, pp. 409–17.Taylor, D. R. F. 1984. The cartographic potential of Telidon. Cartographica19: 3–4, 1830.University of Minnesota. 2000. Map Libraries on the World Wide Web. WWW document,http://www-map.lib.umn.edu/map_libraries.html.Weiser, M. 1996. Ubiquitous Computing. WWW document, http://sandbox.xerox.com/hypertext/weiser/UbiHome.html.Wired News. 2003. Balancing Utility with Privacy. WWW document, http://www.wired.com/news/print/0,1294,60871,00.html.Zingo. 2003. Get the Upper Hand in the Battle for a Taxi. WWW document, www.zingotaxi.co.uk.THO_C11  20/03/2007  16:37  Page 221 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 12Generalization of Spatial DatabasesWilliam A. Mackaness“All geographical processes are imbued with scale” (Taylor 2004, p. 214), thus issuesof scale are an essential consideration in geographic problem solving. The scale ofobservation governs what phenomena can be viewed, what patterns are discernible,and what processes can be inferred. We are interested in viewing the precise detailof those phenomena, as well as the broad linkages across regional and global space.Choosing scales of analysis, comparing output at different scales, describing con-structions of scale (Leitner 2004) are all common practices in the geosciences. Wedo this because we wish to know the operational scales of geographic phenomena,how relationships between variables change as the scale of measurement increasesor decreases, and we want to know the degree to which information on spatialrelationships at one scale can be used to make inferences about relationships atother scales (Sheppard and McMaster 2004; see also Chapter 18 by Brunsdon inthis volume). What is always apparent when viewing geographic phenomena is theinterdependent nature of geographic processes. Any",
    "chunk_order_index": 138,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9e6f7c164887bdb35a02db35ccddcb53": {
    "tokens": 1200,
    "content": ". Wedo this because we wish to know the operational scales of geographic phenomena,how relationships between variables change as the scale of measurement increasesor decreases, and we want to know the degree to which information on spatialrelationships at one scale can be used to make inferences about relationships atother scales (Sheppard and McMaster 2004; see also Chapter 18 by Brunsdon inthis volume). What is always apparent when viewing geographic phenomena is theinterdependent nature of geographic processes. Any observation embodies a set ofphysical and social processes “whose drivers operate at a variety of interlocked andnested geographic scales” (Swyngedouw 2004, p. 129).Both the scale of observation and of representation reﬂect a process of abstraction,an instantaneous momentary “slice” through a complex set of spatio-temporal, inter-dependent processes. Traditionally it has been the cartographer’s responsibility toselect a scale, to symbolize the phenomena, and to give meaning through the additionof appropriate contextual information. In paper-based mapping, various considera-tions acted to constrain the choice of solution (the map literacy of the intendedaudience, map styles, the medium, and choice of cartographic tools). Historically,the paper map reﬂected the state of geographic knowledge and was the basis ofgeographic inquiry. Indeed it was argued that if the problem “cannot be studiedfundamentally by maps – usually by a comparison of several maps – then it is questionable whether or not it is within the ﬁeld of geography” (Hartshorne 1939,p. 249). Information technology has not devalued the power of the map, but it hasdriven a series of paradigm shifts in how we store, represent and interact with geo-graphic information. Early work in automated mapping focused on supporting theTHO_C12  20/03/2007  15:05  Page 222 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGENERALIZATION OF SPATIAL DATABASES223activities of the human cartographer who remained central to the map design pro-cess. Current research is focused more on ideas of autonomous design – systemscapable of selecting optimum solutions among a variety of candidate solutions delivered over the web, in a variety of thematic forms, in anticipation of users whohave little or no cartographic skill (see Chapter 11 by Cartwright, this volume).Historically the paper map reﬂected a state of knowledge. Now it is the databasethat is the knowledge store, with the map as the metaphorical window by whichgeographic information is dynamically explored. In these interactive environments,the art and science of cartography (Krygier 1995) must be extended to support theintegration of distributed data collected at varying levels of detail, while conformingto issues of data quality and interoperability.GeneralizationAt the ﬁne scale, when viewing phenomena at high levels of detail (LoD), we candetermine many of the attributes that deﬁne individual features (such as their shape,size, and orientation), while at the broad scale, we see a more characteristic view– more particularly the regional context in which these phenomena are situated (forexample, their gestaltic and topolgical qualities, and various associations amongother phenomena). For example, journey planning requires a broad-scale view inorder to gauge timeframes and alternative travel strategies, while a ﬁne-scale, detailedmap is required to reach the ﬁnal point of destination. It is not the case that one mapcontains less or more information, but that they contain different, albeit inter-relatedinformation. Thus maps are required at a range of scales, in a variety of thematicforms, for delivery across a range of media. The term “map generalization” is oftenused to describe the process by which more general forms of a map can be derivedfrom a detailed form. In the context of twenty-ﬁrst century technology, there is avision of a single, detailed database, constantly updated in order to reﬂect the mostcurrent version of a region of the world. For any given National Mapping Agency(such as the Ordnance Survey [OS] of Great Britain or the Institut GéographiqueNational [IGN] of France) that region is deﬁned by its respective national boundaries.In such a context, the process of map generalization entails selecting objects fromthat detailed database, and representing them in various simpliﬁed forms appropriateto the level of detail required, and according to some purpose (or theme). By wayof example, Figure 12.1 shows a series of maps at different scales, of Lanvollon inFrance. The goal remains the creation of automated map generalization techniquesthat would enable the derivation of such maps from a single, detailed database. Thisvision is driven by a variety of motivations: data redundancy (maintaining a single,detailed database rather than a set of separate, scale-speciﬁc databases; Oosterom1995); storage efﬁciency (recording the ﬁne detail of a feature in as few points aspossible); exploratory data analysis (MacEachren and Kraak 1997) (being able todynamically zoom in and explore the data, and to support hypermapping); integra-tion (combining data from disparate databases of varying levels of detail); and papermap production (for traditional series mapping).Given the strong association of map generalization with traditional cartographyit is worth stressing its broader relevance to spatial analysis and ideas inherent inTHO_C12  20/03/2007  15:05",
    "chunk_order_index": 139,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-70d78e14af49eb03f5f8794e7ab8f2af": {
    "tokens": 1200,
    "content": "analysis (MacEachren and Kraak 1997) (being able todynamically zoom in and explore the data, and to support hypermapping); integra-tion (combining data from disparate databases of varying levels of detail); and papermap production (for traditional series mapping).Given the strong association of map generalization with traditional cartographyit is worth stressing its broader relevance to spatial analysis and ideas inherent inTHO_C12  20/03/2007  15:05  Page 223 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f224WILLIAM A. MACKANESSvisualization methodologies. Though discussion will focus on the cartographic, weare in essence dealing with the generalization of spatial databases (Muller 1991, vanSmaalen 2003). In this context we can view the ﬁne-scale, detailed database as theﬁrst abstraction of space – often called the Primary Model or Digital LandscapeModel (DLM) (Grünreich 1985). As a prerequisite the DLM requires the deﬁnitionof a schema that will support the explicit storage, analysis, and characterization ofall the geographic phenomena we wish to record. A series of secondary models can be derived from this primary model via the process of “model generalization.”These abstractions are free from cartographic representational information and could be used to support spatial analysis at various levels of detail. Both primaryand secondary models can be used as a basis for creating cartographic products(Digital Cartographic Models) via the process of “cartographic generalization”. Figure 12.2 summarizes the relationships between these models and the general-ization processes.Model generalization may involve reduction of data volume, for example via the selection, classiﬁcation, or grouping of phenomena, or the simpliﬁcation of phenomena such as network structures. This may be required as a prerequisite tospatial analysis, the integration of different data sets, or for computational efﬁci-ency. It is certainly an integral step in the derivation of multi-scaled cartographicproducts. Though it has important ramiﬁcations for cartographic generalization,model generalization does not itself seek to resolve issues of graphic depiction, suchas clarity or emphasis in depiction.Often seen as the complement to model generalization, cartographic general-ization describes the process by which phenomena are rendered, dealing with the challenges of creating appropriate symbols and the placement of text within thelimited space of the medium (whether on paper or the small screen of a mobile device).The symbology used to represent a geographic feature must be of a size discernibleto the naked eye. At reduced scale, less space is available on the map to place thesymbols. At coarser scales, the symbols become increasingly larger than the featurethey represent. It therefore becomes necessary to omit symbology associated withcertain features, to group features, to characterize them in a simpler way, or tochoose alternate forms of symbology in response to this competition for space (Mark1990). Figure 12.3 nicely illustrates this idea, showing The Tower of London andFig. 12.11:25,000, 1:100,000, and 1:250,000Copyright of the IGNTHO_C12  20/03/2007  15:05  Page 224 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGENERALIZATION OF SPATIAL DATABASES225its surroundings at scales of 1:10,000, 1:25,000, and 1:50,000. At the ﬁnest levelof detail we can discern individual walls, courtyards, pavements, and trees, and thebuildings are individually named. We can make many inferences drawing on ourunderstanding and experiences of geographic space, such as the function of buildingsFig. 12.2Generalization as a sequence of modeling operationsAfter Grunreich 1985Primary ModelDigitalLandscapeModel (DLM)model generalisationcartographicgeneralisationCartographic ModelDigitalCartographicModel (DCMs)Secondary ModelsDLM′Fig. 12.3Model and cartographic generalization acting in unison to reveal different qualities aboutThe Tower of LondonCopyright Ordnance SurveyKey buildingCASTLECastlegeneralbuildingsScale1:12501:10,0001:25,0001:50,0001:250,000THO_C12  20/03/2007  15:05  Page 225 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f226WILLIAM A. MACKANESSand the components of the various fortiﬁcations. At a coarser scale we see less detail,in exchange for more of the context. For example, we discern its strategic importancealong the bank of the river Thames, and text is used in a different way to labelvarious features. At the coarse scale of",
    "chunk_order_index": 140,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-953a83e8110af09fa4c2057f8a5bf801": {
    "tokens": 1200,
    "content": "-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f226WILLIAM A. MACKANESSand the components of the various fortiﬁcations. At a coarser scale we see less detail,in exchange for more of the context. For example, we discern its strategic importancealong the bank of the river Thames, and text is used in a different way to labelvarious features. At the coarse scale of 1:50,000 we see how competition for spacehas presented further challenges for the cartographer. The thick red symbology usedto represent the roads has encroached upon surrounding features, which have had tobe slightly “displaced” or made smaller in order to avoid overlapping and causingconfusion among the represented features. We can also discern more of a thematicedge to this representation, with the Tower highlighted as a tourist attraction. Overallthen, we can discern the processes of model and cartographic generalization at workin the creation of such map designs.Conceptual Models of GeneralizationInitial research in automated cartography began in the 1960s (Coppock and Rhind1991) and sought to replace the manual scribing tools and techniques used by the human cartographer, with their automated equivalent. Paper-based maps weredigitized to create inherently cartographic, vector based databases – in essence themap became a set of points, lines, areas, and text to which feature codes were attachedin order to control the symbolization process. But research soon highlighted the limitsof this approach, and revealed the art and science of cartographer as a design taskinvolving complex decision making. There was a clear need for conceptual models(such as those presented by Brassel and Weibel 1988 and McMaster and Shea 1992)as a basis for understanding the process of generalization, and developing auto-mated solutions. McMaster and Shea (1992) presented a comprehensive model thatdecomposed the generalization process into three stages: deﬁnition of philosophicalobjectives (why generalize), cartometric evaluation (when to generalize), and a setof spatial and attribute transformations (how to generalize). A complementary viewthat reﬂects the potential of more complete solutions to automated generalizationis one in which a variety of candidate solutions are considered (synthesis), based oncartometric and topological analysis (analysis). This is followed by an evaluationphase that selects the most appropriate candidate based on both ﬁne-scale and holistic evaluation techniques (Figure 12.4).Multi-scale databasesAligned closely to the topic of map generalization is the idea of “multiple repres-entation,” in which various cartographic representations of a single object are storedfor viewing or analysis at various levels of abstraction (Goodchild and Yang 1992,Kidner and Jones 1994, Kilpelainen and Sajakoski 1995, Devogele, Trevisan, andRanal 1996). A speciﬁc advantage being that their forms can be pre-cast and imme-diately presented to the user (thus avoiding the time cost associated with creatingsolutions “on the ﬂy”). Though the DLM (Figure 12.2) remains unchanged, a seriesof multiple representations can be derived at any time, only needing to be recastwhen the central database is updated to reﬂect changes in the real world. Thereare complicating issues in the management of the database, in particular ensuringTHO_C12  20/03/2007  15:05  Page 226 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGENERALIZATION OF SPATIAL DATABASES227the seamless joining together of multiple representation after an update cycle. Ideasof multiple representation mirror the idea of a single, detailed database, from whichother databases are derived using map generalization techniques.Generalization Methods and AlgorithmsFor any given conceptual framework, it is necessary to precisely deﬁne the methodsby which we can analyze, synthesize, and evaluate solutions. Early research focusedon reverse engineering the design process, observing the human cartographer at work,and, via a process of stepwise reﬁnement, identifying the discrete methods used bythe cartographer. In some instances the cartographer would omit selected features,or whole classes of features. Some features were merged and enlarged and (if spaceallowed, and where symbology overlapped) features were marginally displaced inorder to distinguish more easily between features. These and other methods can bedivided into two types of transformation: spatial and attribute transformation. Theten spatial transformation methods are: amalgamate, aggregate, collapse, displace,eliminate, enhance, merge, reﬁne, simplify, and smooth. The two attribute trans-formation methods are classify and symbolize (Weibel and Dutton 1999).Van Smaalen (2003) argues that in essence map features fall into one of threemetaclasses (Molenaar 1998). Classes that contain “network like” objects, such asrailways, rivers, and roads; classes of relatively small, often rigid, “island” objects– typically buildings; and a third class of mostly “natural” area objects – often form-ing exhaustive tessellations of space, for example land parcels, lakes, forested regions,Fig. 12.4Generalization in the context of automated solutionsTHO_C12  20/03/2007  15:05  Page 227 Downloaded from https://onlinelibrary.wiley.com/doi",
    "chunk_order_index": 141,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-fb596ea93cd8f55db936effc49ff6434": {
    "tokens": 1200,
    "content": "; classes of relatively small, often rigid, “island” objects– typically buildings; and a third class of mostly “natural” area objects – often form-ing exhaustive tessellations of space, for example land parcels, lakes, forested regions,Fig. 12.4Generalization in the context of automated solutionsTHO_C12  20/03/2007  15:05  Page 227 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f228WILLIAM A. MACKANESSand farms. Each class has different behaviors, and can be characterized in differ-ent ways. One can therefore envisage a matrix of these metaclasses against the twelvegeneralization methods. Each cell in the matrix containing a number of algorithmsfor modeling transformations of that particular metaclass for varying levels of detail,and for a range of themes. A huge amount of research has been devoted to populat-ing such a matrix – developing methods that can be applied to various classes ofobjects. By way of illustration, Dutton (1999) and others have worked on methodsfor generalizing linear features (Buttenﬁeld 1985, Plazanet, Bigolin, and Ruas 1998);ﬁnite element analysis and other techniques have been used to model displacementamong features (Burghardt and Meier 1997, Hojholt 2000). Considerable effort has been devoted to methods for generalizing buildings (Regnauld 2001, Jiang and Claramunt 2004), while other research has focused on how space-exhaustivetessellations of space can be generalized – as, for example, is found in geologicalmapping (Bader and Weibel 1997, Downs and Mackaness 2002). Others haveresearched the problem of attenuating network structures (Richardson and Thomson1996, Mackaness and MacKechnie 1999) while others have proposed solutions tothe problem of text placement (Christensen, Marks, and Shieber 1995).These methods have been framed in a variety of strategic contexts. For exampleMolenaar (1998) stratiﬁes these methods under four headings that reﬂect a need tomodel both individual and structural characteristics of the map. Importantly he dis-cusses the idea of functional generalization – a generalization technique used to groupobjects in close proximity, and non-similar objects in order to create meaningful com-posites (van Smaalen 2003). Figure 12.1 presents a nice example of this whereby thevarious objects comprising the town of Lanvollon represented at 1:25,000 scale, havebeen grouped and replaced by a single point symbol at the 1:250,000 scale. Functionalgeneralization is particularly appropriate in the case of signiﬁcant scale change.AnalysisA strong recurrent theme in all the research into generalization algorithms has been the need for techniques that make explicit the metric and topological qualit-ies that exist within and between classes of features. Effective characterization of geographic space requires us to make explicit the trends and patterns among andbetween phenomena, to examine densities and neighborhoods, and to model con-nectivity and network properties, as well as the tessellation of space. Thus the ﬁelddraws heavily on spatial analysis techniques such as graph theory (Hartsﬁeld andRingel 1990), Voronoi techniques (Peng, Sijmons, and Brown 1995, Christophe and Ruas 2002) and skeletonization techniques (Costa 2000). The identiﬁcation ofpattern draws on regression techniques, and automated feature recognition techniques(Priestnal, Hatcher, Morton, Wallace, and Ley 2004). These “supporting” structures(Jones, et al. 1995, Jones and Ware 1998) are used to enrich the database and enablethe modeling of topological transitions (Molenaar 1998).Synthesis and evaluationResearch has also tried to model the process by which a combination of methods isused to synthesize various solutions. For example, a group of islands may be merged,THO_C12  20/03/2007  15:05  Page 228 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGENERALIZATION OF SPATIAL DATABASES229and enlarged in order to remain visible to the naked eye at smaller scale. The pro-cess of enlargement may require marginal displacement to distinguish between theislands. Different results emerge according to the sequence in which the methods areapplied, and the degree to which they are applied (Mackaness 1996). The evaluationof candidate solutions must be graded against a set of criteria, themselves deﬁned bythe map task. For example, a map intended for tourists may accommodate greatergeneralization of the characteristic form than a map intended for sea navigation.In Figure 12.6 the two generalized forms (hand drawn) are shown at the same scaleas the original (in order to compare), prior to being reduced in size to 30 percentof the original.Even in the very simple example of Figure 12.6, with a restricted set of considera-tions, it is easy to imagine a very large set of permutations. But it",
    "chunk_order_index": 142,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6a122ddbbb8818ba73e137f25ea2c515": {
    "tokens": 1200,
    "content": "a map intended for tourists may accommodate greatergeneralization of the characteristic form than a map intended for sea navigation.In Figure 12.6 the two generalized forms (hand drawn) are shown at the same scaleas the original (in order to compare), prior to being reduced in size to 30 percentof the original.Even in the very simple example of Figure 12.6, with a restricted set of considera-tions, it is easy to imagine a very large set of permutations. But it is possible to deﬁneevaluation criteria. For example, shape and area metrics can be used to measurealignments (Christophe and Ruas 2002) or the degree of distortion from the original(Whang and Muller 1998, Cheung and Shi 2004). Topological modeling in surfacesand networks can be used to model neighborhood changes among a group of objects.Density and distribution measures can be used to determine trends in the frequencyof occurrence or the degree of isolation of a feature. Distance metrics can be usedto assess the perceptibility of an object (is it too small to be represented at the intendedscale) and the degree of crowding among objects. Evaluation also includes assess-ment of non-spatial attributes. For example, is it a rare geological unit relative to thesurrounding region (Downs and Mackaness 2002), or a special point of interest inthe landscape? Techniques have also been developed to measure the content of amap, and to evaluate levels of content as a function of change in scale (Topfer andPillewizer 1966, Dutton 1999). Many of the cartometric techniques used to analyzethe properties of a map as part of the synthesis of candidate solutions can also beused in this process of evaluation. In effect, each and every one of these techniquesmakes explicit some property within or between classes of objects.But a map in its generalized form reﬂects a compromise among a competing set of characteristics. There is very little in the map that remains invariant overchanges in scale. Indeed generalization is all about changing the characteristics ofa map in order to reveal different patterns and relationships among the phenomenabeing mapped. Often the preservation of one characteristic can only be achieved bycompromising another. Thus, among a group of buildings do we give emphasis tothe “odd one out” because it is signiﬁcantly larger than the remainder, or preserveAnalysisMeasuring manyproperties (metric,topological and nonspatial) both within andamong classes offeatures.EvaluationSelection of optimalsolution according tointended map use andtask, reflecting analysisat both the fine andbroad scale.SynthesisCreation of a variety ofsolutions using acombination of model andcartographic generalizationtechniques. Candidatesolutions in response toanalysis phase, constrainedby rules governing design.Fig. 12.5The choice, sequence, and degree of application of various methods enable synthesis ofdifferent solutions, but which one is “correct”?THO_C12  20/03/2007  15:05  Page 229 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f230WILLIAM A. MACKANESSthe characteristic orientation shared among the group of buildings and the adjoin-ing road? We know that the topology among a set of objects changes if we remove,aggregate, or functionally combine objects. But how do we ensure that the new topo-logy is a “valid” one? And, where we wish to combine data from different sourcesand scales, how do we validate the quality of any given solution? There is no short-age of techniques for measuring the properties of an object, but the challenge ofdeﬁning tolerances and collectively prioritizing those characteristics (linked tointended use) remains a signiﬁcant impediment to development of systems that aremore autonomous in their operation.A Rule-Based ApproachMore challenging than the development of generalization methods, has been theformalization of the procedural knowledge required to trigger the use of such methods. At any instant in the design phase, there may exist a range of alternatecandidate solutions, whose creation and choice is based on rules of thumb (heuristics), to a goal state that is somewhat hazy and hard to deﬁne (Starr andZeleny 1977). Various attempts have therefore been made to use a rule-based approachto automated map generalization (Richardson and Muller 1991, Heisser, Vickus,and Schoppmeyer 1995, Keller 1995) in which sequences of conditions and actionsare matched in order to control the overall process. For example, a small remotebuilding in a rural context has a signiﬁcance much greater than its counterpart ina cityscape and is therefore treated differently. A solution might be to enlarge thesymbology in order that the building remains discernible to the naked eye, accord-ing to those conditions:IF a building.context =rural AND building.neighborhood =isolated ANDbuilding.size =small THEN building.generalization =enlarge.We can formalise both the <condition> and <action> part of such rules from observation of how features are symbolized on paper maps at various scales. Weobserve how particular solutions operate over a band of scales (akin to the idea ofan “operational scale”, Phillips 1997) and that beyond a certain threshold a changein the level of generalization is invoked. Figure 12.7a illustrates the various repres-entational forms of a cathedral and Figure 12.7b shows the scale bands over",
    "chunk_order_index": 143,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ca9087ad65ee1c45fbb4313e002f9c0f": {
    "tokens": 1200,
    "content": "the <condition> and <action> part of such rules from observation of how features are symbolized on paper maps at various scales. Weobserve how particular solutions operate over a band of scales (akin to the idea ofan “operational scale”, Phillips 1997) and that beyond a certain threshold a changein the level of generalization is invoked. Figure 12.7a illustrates the various repres-entational forms of a cathedral and Figure 12.7b shows the scale bands over whichthose representations might operate. These threshold points are determined by (1) a feature’s geometry and size; (2) its non spatial attributes; (3) its distribution andassociation with other features; (4) its immediate proximity to other features; and (5) the resolution of the device on which the information is being displayed orprinted (Glover and Mackaness 1999).A feature’s treatment also depends upon its importance in relation to the intendedtheme. For example castles and visitor attractions in a tourist map will be givengreater emphasis from those buildings deemed more general. Figure 12.7 is basedon observations made from paper maps over a range of scales, and shows how key(or special buildings) and general buildings are typically represented.THO_C12  20/03/2007  15:05  Page 230 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGENERALIZATION OF SPATIAL DATABASES231Again from observation we can identify the generalization methods that can be applied at the ﬁne scale to derive these various solutions – that their forms aresimpliﬁed, or grouped, or collapsed and replaced with an iconic form. For examplederivation of the castle representational form at 1:50,000 scale can be formed byplacing a minimum bounding rectangle (MBR) around the group of “castle” buildings(so deriving its convex hull), and substituting this form for the group of individualFig. 12.6(a) Transformations with decreasing map scale, and (b) corresponding scale bands for atopographic mapGlover and Mackaness 1999aabbcddc1:12501:10,0001:25,0001:50,000Fig. 12.7Examples drawn from paper maps of building generalization at various scalesTHO_C12  20/03/2007  15:05  Page 231 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f232WILLIAM A. MACKANESSbuildings. One can envisage a similar process applied to each metaclass, and for eachscale band transition point (similar to the one illustrated in Figure 12.6). In thismanner we can deﬁne a decision tree that incorporates the various generalizationmethods used, according to: the building type, its association with adjacent features,and the operational scales of the various representational forms. Figure 12.8 is thedecision tree for “key” buildings intended for use in urban environments.These and other decision trees were collectively implemented in a GeographicInformation System (GIS) that was able to derive different thematic maps from HHScale band 1Scale band 2Scale band 3Get source data setgeometryBuilding area< 150?YESNOELIMINATESIMPLIFYENLARGEYESNOradius search –single building?PROPORTIONALMBRget iconsymbolget buildingcenterCONVEXHULLScale band 4YESNOradius search –single building?get convex hullor convex hullsof subgroupsget convexhull center(s)get iconsymbolNOYESoverlapsroad?SIMPLIFYget iconsymbolget convexhull centerRE GROUPget iconsymbolGet center ofeach subgroupconvex hullsof subgroupsget buildingcenterget iconsymbolFig. 12.8Decision tree for key buildingsTHO_C12  20/03/2007  15:05  Page 232 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGENERALIZATION OF SPATIAL DATABASES233a single detailed source (Glover and Mackaness 1999). The results (Figure 12.9)were compared with their manual equivalent, as the basis for identifying future work.Such a system works quite well for relatively small changes in scale. The systemis limited by its inability to generate alternate solutions to a design problem andto automatically evaluate the correctness of the ﬁnal solution. The work also highlighted the need for cartometric tools capable of analyzing both “local” con-straints (imposed by surrounding objects) and “global” constraints (ensuring consistency across the region including preservation of trends). What was required was a system that would enable consideration of alternate designs that took intoaccount a shared view of these and other design constraints. One such approachthat has shown great promise in this regard has been in the use of multi-agent systems (MAS).Fig. 12.9Different products according to theme and scale derived from the same",
    "chunk_order_index": 144,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7fc28968475da974b4edc4cdeb55866d": {
    "tokens": 1200,
    "content": "of analyzing both “local” con-straints (imposed by surrounding objects) and “global” constraints (ensuring consistency across the region including preservation of trends). What was required was a system that would enable consideration of alternate designs that took intoaccount a shared view of these and other design constraints. One such approachthat has shown great promise in this regard has been in the use of multi-agent systems (MAS).Fig. 12.9Different products according to theme and scale derived from the same sourceTHO_C12  20/03/2007  15:05  Page 233 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f234WILLIAM A. MACKANESSMulti-Agent SystemsThe idea of “agents” came from the observation that complex processes can bemodeled as a set of simple but interconnected set of tasks. For example, the com-plex task of sustaining an ant colony is achieved by assigning ants (agents) to speciﬁc, deﬁned tasks that collectively ensure the survival of the colony. In this wayquite complex emergent behavior can arise from a set of connected but simple agenttasks (Weiss 1999). Thus one deﬁnition of an agent is “a self contained programcapable of controlling its own decision making and acting, based on its perceptionof its environment, in pursuit of one or more objectives” (Luck 1997, p. 309). Wheremore than one agent exists, we can deﬁne what are called multi-agent systems inwhich several computational entities, called agents, interact with one another (Huhnsand Singh 1998). In the context of map generalization, it has been possible to model various characteristics of features and to implement an agent-based approachwhereby agents are assigned to manage the generalization process across a geo-graphic region (with a local perspective on the problem), and to communicate withother agents at a more regional scale (a global perspective) in order to ensure con-sistency in solution, and to ensure preservation of general trends across the mapspace (Duchêne 2003). This was the methodology utilized in the AGENT project,a European Union funded project, comprised of a consortium of universities andcommercial enterprises (Lamy, Ruas, Demazeau, et al. 1999; Barrault, Regnauld,Duchène 2001). The system was capable of analyzing various properties within andbetween classes of objects, of synthesizing alternate candidate solutions and evaluat-ing the optimum choice against a set of design constraints. Where a solution wasnot forthcoming, a more radical or broad-scale solution was proposed and con-trol passed from the local perspective to a more global one. Thus there existed ahierarchical structure of mico, meso and macro agents, which, in effect, modeledboth a ﬁne-scale view of design, as well as the more general view of the problem.The project commenced in 1998, and its commercial form is currently manifest inthe CLARITY system from Laser Scan (http://www.laser-scan.co.uk), and continuesto form the basis of on going research among a consortium of national mappingagencies across Europe under the MAGNET program. Given its adoption by a num-ber of European NMAs it is arguably the best solution to date to the challenges ofautonomous map generalization, though a number of challenges remain. The ﬁrstis in the development of an interface that enables “tuning” of solutions that arisefrom complex emergent behavior and interactions. The second is in deﬁning thetype of information that is passed among the hierarchies of agents, and how thisinformation is utilized in the various stages of decision making.CONCLUSIONSGeneralization holds an important position in the development of a theoretical framework for handling geographic information “as it deals with the structure andtransformation of complex spatial notions at different levels of abstraction” (vanSmaalen 2003). As a modeling process, map generalization is about characterizingTHO_C12  20/03/2007  15:05  Page 234 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGENERALIZATION OF SPATIAL DATABASES235space in a way that precipitates out the broader contextual relationships that existamong geographic phenomena. It is about making sense of things (Krippendorf 1995)and is intrinsic to geographic ways of knowing.In essence, a database is a system of relationships – the process of generalizationis about abstracting and representing those patterns of relationships inherent amongphenomena viewed at different levels of detail (similar to the goals of scientiﬁc visualization). The enduring vision is of a single, detailed database from which suchmultiple views can be automatically derived according to a broad range of tasks.Over the years a variety of solutions have emerged in response to both a growingunderstanding of the complexities of automated map design and to the changingcontext of use arising from developments in information technology. Attempts atautomation have highlighted the complexity of this task. It is certainly the case that the design of a map (irrespective of medium) is a hugely challenging task, though the paradigm shift afforded by data modeling techniques has called intoquestion the appropriateness of trying to mimic the human cartographer as",
    "chunk_order_index": 145,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b110a77d95416c0d27d2cd31f7da7208": {
    "tokens": 1200,
    "content": "tasks.Over the years a variety of solutions have emerged in response to both a growingunderstanding of the complexities of automated map design and to the changingcontext of use arising from developments in information technology. Attempts atautomation have highlighted the complexity of this task. It is certainly the case that the design of a map (irrespective of medium) is a hugely challenging task, though the paradigm shift afforded by data modeling techniques has called intoquestion the appropriateness of trying to mimic the human cartographer as a basisto automation.Developments in the ﬁeld of generalization continue to advance three key areas:(1) development of algorithms for model generalizations with the focus on spatial datahandling and analysis; (2) methods for creating and evaluating candidate solutionsfor graphical visualization and multiple representation; and (3) development of humancomputer interaction models that enable integration of these methodologies in boththe presentation and exploration of geographic information. Research continues toreveal the subtleties of the art and science of cartography. For it to remain relevant,however, it must keep abreast of the changing environments of map use and analysis(including interoperability requirements), and the broader developments in visual-ization methodologies.REFERENCESBader, M. and Weibel, R. 1997. Detecting and resolving size and proximity conﬂicts in thegeneralization of polygon maps. In Proceedings of the Eighteenth International Carto-graphic Association Conference, Stockholm, Sweden. Sweden: International CartographicAssociation, pp. 1525–32.Barrault, M., Regnauld, N., Duchène C., Haire, K., Baeijs, C., Demazeau, Y., Hardy, P.,Mackaness, I., Ruas, A., and Weibel, R. 2001. Integrating multi agent, object orientedand algorithmic techniques for improved autmoated map generalisation. In Proceedingsof the Twentieth International Cartographic Conference, Beijing, China. Stockholm:International Cartographic Association, pp. 2110–16.Brassel, K. E. and Weibel, R. 1988. A review and conceptual framework of automated mapgeneralization. International Journal of Geographical Information Systems2: 229–44.Burghardt, D. and Meier, S. 1997. Cartographic displacement using the snakes concept. InW. Foerstner and L. Pluemer (eds) Semantic Modelling for the Acquisition of TopographicInformation from Images and Maps.Basel: Birkhaeuser Verlag, pp. 59–71.Buttenﬁeld, B. 1985. Treatment of the cartographic line. Cartographica22: 1–26.Cheung, C. K. and Shi, W. 2004. Estimation of the positional uncertainty in line simpliﬁca-tion in GIS. Cartographic Journal41: 37–45.Christensen, J., Marks, J., and Shieber, S. 1995. An empirical study of algorithms for pointfeature label placement. ACM Transactions on Graphics14: 203–32.THO_C12  20/03/2007  15:05  Page 235 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f236WILLIAM A. MACKANESSChristophe, S. and Ruas, A. 2002. Detecting building alignments for generalisation purposes.In D. Richardson and P. van Oosterom (eds) Advances in Spatial Data Handling.Berlin:Springer-Verlag, pp. 419–32.Coppock, J. T. and Rhind, D. W. 1991. The history of GIS. In D. J. Maguire, M. F. Goodchild,and D. W. Rhind (eds) Geographical Information Systems: Principles and Applications.Harlow: Longman, pp. 21–43.Costa, L. D. F. 2000. Robust skeletonization through exact Euclidean distance transformand its application to neuromorphometry. Journal of Real Time Imaging6: 415–31.Devogele, T., Trevisan, J., and Ranal, L. 1996. Building a multi-scale database with scale transition relationships. In Proceedings of the Seventh International Symposium on Spatial Data Handling, Delft, Netherlands. Delft: Delft University of Technology, pp. 337–52.Downs, T. C. and Mackaness, W. A. 2002. Automating the generalisation of geological maps:The need for an integrated approach. Cartographic Journal39: 137–52.Duchêne, C. 2003. Automated map generalisation using communicating agents. In Proceedingsof the Twenty-ﬁrst International Cartographic Conference, Durban, South Africa. Stockholm:International Cartographic Association, pp. 160–9.Dutton, G. 1999. Scale, sinuosity and point selection in digital line generalisation. Carto-graphy and Geographic Information Systems26: 33–54.Glover, L. and Mackaness, W. A. 1999. Dynamic generalisation from single detailed databaseto support web based interaction. In Proceedings of the Nineteenth International Carto-graphic Conference, Ottawa, Canada. Stockholm: International Cartographic Association,pp. 1175–83.Goodchild, M. F. and Yang, S. 1992. A hierarchical data structure for global geographicinformation systems. Computer Vision,",
    "chunk_order_index": 146,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-658df509aa18d4037ee1cdde9d3dcac6": {
    "tokens": 1200,
    "content": "26: 33–54.Glover, L. and Mackaness, W. A. 1999. Dynamic generalisation from single detailed databaseto support web based interaction. In Proceedings of the Nineteenth International Carto-graphic Conference, Ottawa, Canada. Stockholm: International Cartographic Association,pp. 1175–83.Goodchild, M. F. and Yang, S. 1992. A hierarchical data structure for global geographicinformation systems. Computer Vision, Graphics, and Image Processing54: 31–44.Grünreich, D. 1985. Computer-assisted Generalisation. Unpublished Paper, CERCO-Cartography Course, Institut für Angewandte Geodasie, Frankfurt am Main.Hartsﬁeld, N. and Ringel, G. 1990. Pearls in Graph Theory: A Comprehensive Introduction.Boston, MA: Academic Press.Hartshorne, R. 1939. The Nature of Geography: A Critical Survey of Current Thought inthe Light of the Past. Washington, DC: Association of American Geographers, p. 249.Heisser, M., Vickus, G., and Schoppmeyer, J. 1995. Rule-orientated deﬁnition of small area selection and combination steps of the generalization procedure. In J.-C. Muller, J. P. Lagrange, and R. Weibel (eds) GIS and Generalization: Methodology and Practice.London: Taylor & Francis, pp. 148–60.Hojholt, P. 2000. Solving space conﬂicts in map generalisation: Using a ﬁnite element method.Cartography and Geographic Information Science27: 65–73.Huhns, M. N. and Singh, M. P. 1998. Readings in Agents. San Francsico, CA: MorganKaufmann.Jiang, B. and Claramunt, C. 2004. A structural approach to the model generalisation of anurban street network. GeoInformatica8: 157–71.Jones, C. B., Bundy, G. L., and Ware, J. M. 1995. Map generalization with a triangulateddata structure. Cartography and Geographic Information Systems22: 317–331.Jones, C. B. and Ware, J. M. 1998. Proximity relations with triangulated spatial models.Computer Journal41: 71–83.Keller, S. F. 1995. Potentials and limitations of artiﬁcial intelligence techniques applied togeneralization. In J. C. Muller, J. P. Lagrange, and R. Weibel (eds) GIS and Generaliza-tion: Methodology and Practice.London: Taylor and Francis, pp. 135–47.Kidner, D. B. and Jones, C. B. 1994. A deductive object oriented GIS for handling multiplerepresentation. In Proceedings of the Sixth International Symposium on Spatial DataHandling, Edinburgh, Scotland. Delft: Delft University of Technology, pp. 882–900.THO_C12  20/03/2007  15:05  Page 236 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGENERALIZATION OF SPATIAL DATABASES237Kilpelainen, T. and Sarjakoski, T. 1995. Incremental generalisation for multiple representa-tions of geographical objects. In J. C. Muller, J. P. Lagrange, and R. Weibel (eds) GIS andGeneralisation: Methodology and Practice.London: Taylor and Francis, pp. 209–18.Krippendorff, K. 1995. On the essential contexts of artifacts or on the proposition that “designis making sense (of things).” In V. Margolin and R. Buchanan (eds) The Idea of Design.Cambridge, MA: MIT Press, pp. 156–84.Krygier, J. B. 1995. Cartography as an art and a science. Cartographic Journal32: 3–10.Lamy, S., Ruas, A., Demazeau, Y., Jackson, M., Mackaness, W. A., and Weibel, R. 1999.The application of agents in automated map generalisation. In Proceedings of theNineteenth International Cartographic Conference, Ottawa, Canada. Stockholm: Interna-tional Cartographic Association, pp. 1225–34.Leitner, H. 2004. The politics of scale and networks of spatial connectivity: Transnationalinterurban networks and the rescaling of political governance in Europe. In E. Sheppardand R. B. McMaster (eds) Scale and Geographic Inquiry: Nature Society and Method.Malden, MA: Blackwell, pp. 236–55.Luck, M. 1997. Foundations of multi-agent systems: Issues and directions. KnowledgeEngineering Review12: 307–18.MacEachren, A. M. and Kraak, M. J. 1997. Exploratory cartographic visualization: Advan-cing the agenda. Computers and Geosciences23: 335–43.Mackaness, W. A. 1996. Automated cartography and the human paradigm. In C. H. Woodand C. P. Keller (eds) Cartographic Design: Theoretical and Practical Perspectives.NewYork: John Wiley and",
    "chunk_order_index": 147,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-eb9178cfefa110bbdd313ff2d464a6d7": {
    "tokens": 1200,
    "content": "307–18.MacEachren, A. M. and Kraak, M. J. 1997. Exploratory cartographic visualization: Advan-cing the agenda. Computers and Geosciences23: 335–43.Mackaness, W. A. 1996. Automated cartography and the human paradigm. In C. H. Woodand C. P. Keller (eds) Cartographic Design: Theoretical and Practical Perspectives.NewYork: John Wiley and Sons, pp. 55–66.Mackaness, W. A. and Mackechnie, G. 1999. Automating the detection and simpliﬁcationof junctions in road networks. GeoInformatica3: 185–200.McMaster, R. B. and Shea, K. S. 1992. Generalization in Digital Cartography: ResourcePublication in Geography. Washington DC: Association of American Geographers.Mark, D. M. 1990. Competition for map space as a paradigm for automated map design.In Proceedings of GIS/LIS ’90, Anaheim, CA, USA. Bethesda, MD: American Society ofPhotogrammetry and Remote Sensing, pp. 97–106.Molenaar, M. 1998. An Introduction to the Theory of Spatial Object Modelling for GIS.London: Taylor and Francis.Muller, J. C. 1991. Generalisation of spatial databases. In D. J. Maguire, M. F. Goodchild,and D. W. Rhind (eds) Geographical Information Systems.London: Longman, pp. 457–75.Oosterom, P. V. 1995. The GAP-tree: An approach to “on-the-ﬂy” map generalization of an area partitioning. In J. C. Muller, J. P. Lagrange, and R. Weibel (eds) GIS andGeneralization: Methodology and Practice.London: Taylor and Francis, pp. 120–32.Peng, W., Sijmons, K., and Brown, A. 1995. Voronoi diagram and Delaunay triangulationsupporting automated generalization. In Proceedings of the Seventeenth InternationalCartographic Conference, Barcelona, Spain. Stockholm: International CartographicAssociation, pp. 301–10.Phillips, J. D. 1997. Humans as geological agents and the question of scale. American Journalof Science297: 98–115.Plazanet, C., Bigolin, N. M., and Ruas, A. 1998. Experiments with learning techniques forspatial model enrichment and line generalization. GeoInformatica2: 315–33.Priestnall, G., Hatcher, M. J., Morton, R. D., Wallace, S. J., and Ley, R. G. 2004. A framework for automated feature extraction and classiﬁcation of linear networks.Photogrammetric Engineering and Remote Sensing70: 73–82.Regnauld, N. 1996. Recognition of building cluster for generalization. In Proceedings of theSeventh International Symposium on Spatial Data Handling, Delft, Netherlands. Delft: DelftUniversity of Technology, pp. 185–98.THO_C12  20/03/2007  15:05  Page 237 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f238WILLIAM A. MACKANESSRegnauld, N. 2001. Contextual building typiﬁcation in automated map generalisation.Algorithmica30: 312–33.Richardson, D. E. and Muller, J.-C. 1991. Rule selection for small-scale map generalization.In B. P. Buttenﬁeld and R. B. McMaster (eds) Map Generalization: Making Rules forKnowledge Representation.Harlow: Longman, pp. 136–49.Richardson, D. and Thomson, R. C. 1996. Integrating thematic, geometric and topologicalinformation in the generalisation of road networks. Cartographica33: 75–84.Ruas, A. 1995. Multiple paradigms for automating map generalization: Geometry, topo-logy, hierarchical partitioning and local triangulation. In Proceedings of Auto Carto 12,Charlotte, NC, USA. Bethesda, MD: American Congress on Surveying and Mapping, pp. 69–78.Ruas, A. and Mackaness, W. A. 1997. Strategies for urban map generalization. In Proceed-ings of the Eighteenth ICA/ACI International Cartographic Conference,Stockholm,Sweden. Stockholm: International Cartographic Association, 1387–94.Sheppard, E. and McMaster, R. B. (eds) 2004. Scale and Geographic Inquiry: Nature Societyand Method.Oxford: Blackwell.Starr, M. K. and Zeleny, M. 1977. MCDM: State and future of the arts. In M. K. Starr and M. Zeleny (eds) Multiple Criteria Decision Making.New York: North-Holland, pp. 5–29.Swyngedouw, E. 2004. Scaled geographies: Nature, place, and the politics of scale. In E. Sheppard and R. B. McMaster (eds) Scale and Geographic Inquiry: Nature Society and Method.Ox",
    "chunk_order_index": 148,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9d389cedb5aad32c21cf30c0e515e673": {
    "tokens": 1200,
    "content": "1977. MCDM: State and future of the arts. In M. K. Starr and M. Zeleny (eds) Multiple Criteria Decision Making.New York: North-Holland, pp. 5–29.Swyngedouw, E. 2004. Scaled geographies: Nature, place, and the politics of scale. In E. Sheppard and R. B. McMaster (eds) Scale and Geographic Inquiry: Nature Society and Method.Oxford: Blackwell, pp. 129–53.Taylor, P. J. 2004. Is there a Europe of cities? World cities and the limitations of Geo-graphical Scale Analyses. In E. Sheppard and R. B. McMaster (eds) Scale and GeographicInquiry: Nature, Society, and Method.Oxford: Blackwell, pp. 213–35.Topfer, F. and Pillewizer, W. 1966. The principles of selection. Cartographic Journal3: 10–6.van Smaalen, J. W. N. 2003. Automated Aggregation of Geographic Objects: A New Approachto the Conceptual Generalisation of Geographic Databases. Delft: Netherlands GeodeticCommission, p. 1.Weibel, R. and Dutton, G. 1999. Generalising spatial data and dealing with multiple representations. In P. A. Longley, M. F. Goodchild, D. J. Maguire, and D. W. Rhind (eds)Geographical Information Systems.New York: John Wiley and Sons, pp. 125–56.Weiss, G. (ed.). 1999. Multiagent Systems: A Modern Approach to Distributed ArtiﬁcialIntelligence.Cambridge, MA: MIT Press.Whang, Z. and Muller, J. C. 1998. Line generalisation based on analysis of shape charac-teristics. Cartography and Geographic Information Systems25: 3–15.THO_C12  20/03/2007  15:05  Page 238 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 13Geographic Information Systems and SurfacesNicholas J. Tate, Peter F. Fisher, and David J. MartinMany different geographic phenomena are displayed and analyzed as surfaces. Some are among the most concrete that Geographic Information Systems (GIS) are designed to work with (bona ﬁde, in the sense of Smith 2001), while others are among the most abstract. The surfaces concerned are completely different in type,but they all have one thing in common: a surface representation is appropriate underany circumstances where the phenomena being modeled can be thought of as varying continuouslyacross space. Indeed, the vector polygon model is a specialcase of a surface in which the changes in value across space happen abruptly atpolygon boundaries. The most tangible surface is the land, the ground under ourfeet, measured as an elevation above a particular datum, commonly mean sea level,which is conceptualized as a horizontal surface. The more abstract surfaces conceivedby geographers include, for example, population density surfaces (the probabilitythat you will meet someone at a particular location), soil pH, and atmospheric airpressure.Conventional conceptualizations of geographic objects make a distinction betweenpoint, line, area, and surface types. The continuous nature of surfaces means that,strictly, they do not embody any topology, although our inability to create trulycontinuous data structures means that surfaces are represented by various appro-ximations that may include topological information. These include the use of tri-angulated irregular networks (TINs), digital elevation models (DEMs), and isolines/contours, each of which are considered in more detail below. We conventionally referto the variable of interest, represented as the height of the surface as the Z variable(and associated Z values), to distinguish it from the familiar X and Y variables oftwo-dimensional cartographic space.The purpose of this chapter is to outline the nature and procedures which areavailable for surface modeling and visualization. In the following section we con-sider some of the advantages of surface representation. The focus of the secondsection (Surface Modeling) is on exploration of the various types of surface modelused in GIS. Surface concepts provide us with particularly powerful tools for visual-ization which is the subject of the third section, Surface Visualization.THO_C13  19/03/2007  11:15  Page 239 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f240NICHOLAS J. TATE, PETER F. FISHER, AND DAVID J. MARTINSurface RepresentationViewing space in terms of continuously varying scalar ﬁelds where the Z value isa continuous function of location f(X,Y) is often identiﬁed as the ﬁeld perspective(for example, Goodchild 1992, 2003) and is one of the two most frequently usedmodels in GI Science. Fields traditionally comprise regularly/irregularly distributedpoints, tessellations of various regular/irregular areas, and isolines (Goodchild2003).Point phenomena represented as surfaces can be further divided into two categories: point and reference interval functions (Nordbeck and Rystedt",
    "chunk_order_index": 149,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f578a2863cdaa2bb50662af9d3eab8fb": {
    "tokens": 1200,
    "content": "of location f(X,Y) is often identiﬁed as the ﬁeld perspective(for example, Goodchild 1992, 2003) and is one of the two most frequently usedmodels in GI Science. Fields traditionally comprise regularly/irregularly distributedpoints, tessellations of various regular/irregular areas, and isolines (Goodchild2003).Point phenomena represented as surfaces can be further divided into two categories: point and reference interval functions (Nordbeck and Rystedt 1970). Pointfunctions are those such as elevation of the land surface above sea level which, givencertain assumptions, are measurable at single point locations. However, referenceinterval functions such as population density cannot be measured in this way andcan only be measured in relation to a reference area – for example persons perhectare. In the latter case the Z value at a single point location is not constant butvaries according to the size and shape of the reference area. The treatment of theirZ values in surface construction varies according to whether they can be directlyinterpreted as Z values, or quantities from which Z must be derived. The popula-tion density at a point in the City of London would be low if measured in relationto its immediate neighborhood which comprises primarily commercial premises, butwould rise as surrounding residential areas are included in the reference interval.As we continue to extend the reference interval beyond the build-up area, the densitywould fall again, and all of these values would be “correct” for that same location.The distinction between point and reference interval functions is more subtle thanmight ﬁrst appear, with phenomena such as atmospheric pressure being referenceinterval functions (expressed as force per unit area), although the reference area isconventionally very small and measured at individual locations.Cartographic convention has led to some phenomena being more commonly conceptualized as surfaces than others: in general terms, point functions are more readily imagined to be continuously varying surfaces and the convention of represent-ing them by mapping isolines (for example, elevation contours, pressure isobars)that connect locations with the same Z value is long established. The continuouslyvarying distribution of population density by contrast is more often represented inthe form of shaded area (choropleth) maps which convey an impression of extensiveregions of uniformity separated by sharp and geographically irregular changes atboundaries. This convention owes more to the data collection processes associatedwith these geographic regions than to any speciﬁc advantages that they offer foranalysis or visualization. Effectively, a choropleth map of population density is onein which the value at each point is calculated using a uniquely shaped and sizedreference interval. This is a manifestation of the modiﬁable areal unit problem(Openshaw 1984) which affects all area-based data where boundaries are imposedon a continuously varying phenomenon: both the scale of the units and details of boundary placement at a given scale affect the mapped values. Interpretation ofchoropleth maps of phenomena such as population density is made particularlydifﬁcult if the underlying distribution is non-uniform, as the largest population con-centrations are afforded only the smallest areas on the map while unpopulated regionsTHO_C13  19/03/2007  11:15  Page 240 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND SURFACES241dominate the visual image. These types of problem are much diminished if the phe-nomenon is modeled as a surface, as a continuous model has no spatial units andno boundaries. An elevation matrix approximation provides us with very small,regularly placed units which can overcome many of the problems of choroplethrepresentation. A more extensive comparison between surface and zonal models ofpopulation is presented in Martin (1996).Key considerations in the selection of a surface representation should be its ﬁtnessfor the analysis and visualization methodologies to be employed (as discussed in thefollowing two sections). Analysis of runoff from a land surface or identiﬁcation ofdiscrete settlements from a population density surface require representations whichcapture surface characteristics not directly calculable from isoline or choropleth map-ping and are more appropriately addressed through surface modeling. For example,Thurstain-Goodwin (2003) explores the advantages of socio-economic surface rep-resentations in a policy making context.Surface ModelingSurface modeling is a necessary preliminary to surface analysis or visualization.Mathematically we can conceive of a surface as a bivariate scalar ﬁeld Z =f(X,Y).If we can sample Z at a sufﬁcient intensity/number of discrete points in space, wecan deﬁne a discrete point model of a surface also known as a ‘height ﬁeld’. Similarly,if we obtain Z as a set of isolines we deﬁne a discrete line model of a surface. Inthe context of terrain modeling these would be identiﬁed as a Digital EvaluationModel (DEM) and a contour model respectively. In both cases the geometric con-tinuity between the points/lines is only implied(Schneider 2001a). In the contextof terrain modeling Schneider (2001b) and Hugentobler (2004) have argued thatsuch surface models are less useful than models where the continuity between pointsis explicitlymodeled and the surface reconstructed as a set of piecewise functionsin the form of a polygonal mesh. Using this distinction we will discuss the meth-ods of surface modeling below.Height Fields, DEMs, and contoursThe direct measurement of the Z variable at point locations is the most direct, often the most accurate, and the most costly method of surface construction since it",
    "chunk_order_index": 150,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-68419a3a500645586abf5a337fbecf1a": {
    "tokens": 1200,
    "content": "Hugentobler (2004) have argued thatsuch surface models are less useful than models where the continuity between pointsis explicitlymodeled and the surface reconstructed as a set of piecewise functionsin the form of a polygonal mesh. Using this distinction we will discuss the meth-ods of surface modeling below.Height Fields, DEMs, and contoursThe direct measurement of the Z variable at point locations is the most direct, often the most accurate, and the most costly method of surface construction since itrequires the most measured data. Surface modeling in this form requires measuredsamples of the Z variable at sufﬁcient spatial locations in order to be able to characterize the surface, which in turn necessarily involves choices to be made withrespect to spatial sampling, the scale and pattern of variation, and the actual processof physical measurement. There are a variety of spatial sampling frames that mightbe suitable for the construction of surfaces by direct measurement; however, by far the most common are those that employ a regular square grid form, althoughirregularly distributed points can also be collected. Regular grids offer a variety ofadvantages for the digital/computer representation of surfaces; for example, bothposition and neighbors are explicit (Mark and Smith 2004). Ideally, the choice offrame is determined by the pattern of spatial variation that exists in the Z variableTHO_C13  19/03/2007  11:15  Page 241 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f242NICHOLAS J. TATE, PETER F. FISHER, AND DAVID J. MARTINin reality, as well as the form and the resolution of surface model that is required.Real surfaces often manifest complex spatial patterns of scaling (dependent or fractal)and directionality (isotropic or anisotropic), and a suitable sampling pattern willneed to honor these properties. Various methods might be employed to vary thedensity of sampling: one example used in the photogrammetric construction of terrain models is a technique based on the progressive density increases in areas of complex spatial patterns (Petrie 1990a). Once an appropriate sample frame hasbeen established, measurement of the Z variable is then obtained for each samplelocation – a process that might require ﬁeldwork, or lab-based measurement, andwhich may prove cost-prohibitive. The grid-based frame for sampling soil fertilitycharacteristics at Broom’s Barn Experimental station is shown in Figure 13.1. A more irregular sample frame of Light Detection and Ranging (LiDAR) points usedto construct a DEM for a section of Ribble Catchment in NW England is shownin Figure 13.2.An inherent feature of most surface-type geographic phenomena is that we oftencannot comprehensively capture their form by a measured sample alone. Surfacemodeling is therefore nearly always based on some combination of measurementFig. 13.1Sample frame for soil fertility characteristics recorded at Broom’s Barn ExperimentalStation, SuffolkWebster and McBratney 1987, Webster and Oliver 2001N02.55Metres × 40THO_C13  19/03/2007  11:15  Page 242 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND SURFACES243and statistical modeling. In the case of point functions the former may be knownvalues of the surface at measured locations, but for reference interval functions these will be estimates based on speciﬁc reference areas, which may themselves beirregular in size and shape. With known values at measured locations but at aninsufﬁcient spatial density/intensity, the statistical model required is some form ofinterpolation, that is, the estimation of Z at unmeasured locations. A great varietyof generic point-based as well as surface-speciﬁc interpolation methods can beemployed, and there are numerous surveys and classiﬁcations of interpolationmethods relevant to surface construction (see Lam 1983, Oliver and Webster 1990;Petrie 1990a, Watson 1992, Hutchinson 1993, Myers 1994, Mardia, Kent, Goodall,and Little 1996, Mitas and Mitasova 1999).The construction of surfaces – particularly terrain surfaces – from contours/isolines has been a topic of interest for some time in the GIS community, wherepaper maps were often the only convenient source of surface information (Legatesand Willmott 1986, Yoeli 1986, Petrie 1990b; see also Hutchinson, Chapter 8 inthis volume for additional discussion of this topic). As noted by Hormann, Spinello,and Schroeder (2003) contours can be treated as sets of points and subjected tostandard interpolation methods, although Gold (1994) has observed that artifactsN0510MetresFig. 13.2Sample frame for LiDAR data collected from an area of the Ribble Catchment, NWEnglandThis map is derived from data Copyright Environment Agency Science Group – Technology (2004)THO_C13  19/03/2007  11:15  Page 243 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11",
    "chunk_order_index": 151,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-de9d910a6e40702b0fdfff90220d1c6a": {
    "tokens": 1200,
    "content": ") has observed that artifactsN0510MetresFig. 13.2Sample frame for LiDAR data collected from an area of the Ribble Catchment, NWEnglandThis map is derived from data Copyright Environment Agency Science Group – Technology (2004)THO_C13  19/03/2007  11:15  Page 243 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f244NICHOLAS J. TATE, PETER F. FISHER, AND DAVID J. MARTIN– such as zero slope of the surface at the position of each sample point – are oftenintroduced into surfaces derived from such methods. Various purpose-designed algo-rithms have therefore been developed to construct surfaces from contour maps, for example making use of partial differential equations (Hormann, Spinello, andSchroeder 2003), bidirectional Hermitian splines (Legates and Willmott 1986) and “area stealing” from Voronoi tilings (Gold 1994). TINs (further discussed belowunder the heading “Poygonal models”) can also be constructed from digitized contour points; however, these will often contain ﬂat triangles in certain cases ofpeaks and pits (Thibault and Gold 2000, Gold 2003). Attempts have been madeto augment the point elevation information in TIN construction by using graph-based methods developed from computer graphics approaches (Amenta, Bern, and Eppstein 1998). Here, graphs derived both from the Delaunay triangulation andVoronoi/Thiessen polygonization of a set of digitized contours, which in a connectedform are termed a crustand skeleton/medial axis respectively (using the jargon ofAmenta, Bern, and Eppstein 1998), can be used to inform the process of TIN-basedsurface construction (see Thibault and Gold 2000 and Dakowicz and Gold 2002for examples in a terrain modeling context).Polygonal modelsAs noted above, surfaces can be represented in terms of discrete models of pointsand lines such as a DEM and contour map. These models can be estimated to higherresolution point models using some form of interpolation. However, as noted above,continuity is only impliedbetween individual points. An alternative is to reconstructthe surface explicitlyin continuous form. Surface reconstruction from scattered andoften noisy point samples has been of considerable interest in computer graphics (forexample, Hoppe, DeRose, Duchamp, McDonald, and Stuetzle 1992, Amenta, Bern,and Eppstein 1998, Xie, Wang, Hua, Qin, and Kaufman 2003) where the aim isto represent and model a variety of solid 3D objects by using only partial informa-tion about the original surface (Hoppe, DeRose, Duchamp, et al. 1994). Althoughmuch of this work often addresses more mathematically complex 3D manifoldsurfaces than the simpler 2.5D surfaces encountered in GIS, many of the algorithmsdeveloped have found application in a GIS context (for example, Thibault and Gold2000, Gold 2003). Surface reconstruction methods are often classiﬁed into thosethat construct piecewise(or patchwise) polygonal surfacesbetween data points and those that employ approximation techniqueswhich ﬁt functions to the data(Hoppe, DeRose, Duchamp 1992, Xie, Wang, Hua, Qin, and Kaufman 2003).In a GIS context polygonal surfaces are less frequently encountered in a regularsquare grid form but more frequently encountered in a triangular/TIN form (Figure 13.3). De Floriani, Marzano, and Puppo (1996) have deﬁned this polygonalsurface representation1as a combination of geometric domain partition (for example,a set of triangles or squares) and the function deﬁned on the partition.Often the functions that are used to model each triangle (or square) are simplypiecewise linear(or bilinear) as in Figure 13.3. However, the use of nonlinear func-tions such as Coons patches, NURBS, Clough-Tocher and Bezier splines – long popular in Computer Aided Geometric Design (CAGD) for smooth modeling (forexample, Foley, Van Dam, Feiner, and Hughes 1990, Barnhill 1993, Hoppe, DeRose,Duchamp 1994, Farin 1997), and long cited in the GIS and terrain modeling THO_C13  19/03/2007  11:15  Page 244 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND SURFACES245literature (see Gold 1979, McCullagh 1990, Watson 1992, Mark and Smith 2004,and references therein) – are becoming more popular within a GIS context (Schneider2001b, Hugentobler 2002, Hugentobler 2004). Importantly, such non-linear func-tions allow the expression of varying degrees of continuity.Mathematically, continuity is deﬁned as geometric continuity Gn",
    "chunk_order_index": 152,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e26095896c508fb41f73106bca1d43b7": {
    "tokens": 1200,
    "content": "GIS AND SURFACES245literature (see Gold 1979, McCullagh 1990, Watson 1992, Mark and Smith 2004,and references therein) – are becoming more popular within a GIS context (Schneider2001b, Hugentobler 2002, Hugentobler 2004). Importantly, such non-linear func-tions allow the expression of varying degrees of continuity.Mathematically, continuity is deﬁned as geometric continuity Gn(or parametriccontinuity Cn), where nindicates the order of the derivative (Foley, Van Dam, Feiner,and Hughes 1990). In this context we can deﬁne G0where the surface functionitself varies continuously, G1and G2which indicate continuity in ﬁrst and secondderivatives, that is, surface slope and surface curvature respectively (Hugentobler2004). For example, a simple bilinear function that might be used to model eachsquare of a regular square grid allows the surface function to vary continuously withno gaps – it is therefore G0continuous – but the breaks of slope between each cellthat will occur will preclude G1and G2continuity. Different piecewise functionswill impart different degrees of continuity to the surface (Hugentobler 2004) anda different visual appearance (McCullagh 1990). Certain applications of surfaces –for example, the use of terrain surfaces for the modeling of ﬂows in geomorpho-logy (Mark and Smith 2004) as well as for modeling erosion and deposition (forexample, Mitasova, Hoﬁerka, Zlocha, and Iverson 1996) – require local continuity.However, many natural surfaces are non-differentiable (fractal) at certain scales,contradicting the usual assumption of differentiability made in much modeling workFig. 13.3A TIN generated from the points displayed in Figure 13.2This map is derived from data Copyright Environment Agency Science Group – Technology (2004)THO_C13  19/03/2007  11:15  Page 245 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f246NICHOLAS J. TATE, PETER F. FISHER, AND DAVID J. MARTIN(Mark and Smith 2004). In a GIS context the degree of continuity required, andthe scales that continuity applies to determine an accurate representation of a givensurface are not always straightforward to determine.Although a polygonal model in a regular square grid form is a logical progres-sion from the points collected in the form of a height ﬁeld/DEM, TINs are oftenpreferred primarily because they allow more efﬁcient representations of surfaces andare easily adapted (De Floriani, Marzano, and Puppo 1996) in proportion to thecomplexity of the surface (Mark and Smith 2004). A TIN (with hillshade) is visiblein Figure 13.4 alongside the original hillshaded DEM.Such efﬁciencies are also relevant in the visualization of surfaces where a smallerscale or lower level of detail (LOD) is required; for example, in rendering moredistant objects in a scene (Luebke 2001). Views and their associated TINs with a differing LOD are displayed in Figure 13.5 where Figure 13.5a indicates the visualization and TIN with a constant LOD and Figure 13.5b indicates the sameview/TIN with an adaptive LOD proportional to the viewpoint.(a)(b)(c)Fig. 13.4LiDAR derived raster hillshade (a), TIN (b), and TIN hillshade (c) for an area of theRibble Catchment, NW EnglandThis map is derived from data Copyright Environment Agency Science Group – Technology (2004)THO_C13  19/03/2007  11:15  Page 246 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND SURFACES247There has been considerable effort in computer graphics and GIS/terrain modelingto develop efﬁcient structures for multi-resolution TINs, and algorithms for TINsimpliﬁcation both direct from the original height ﬁeld/DEM (for example, Fowler andLittle 1979, Lee 1991, Little and Shi 2001) and from an existing TIN (for example,Puppo and Scopigno 1997, Garland 1999, Kidner, Ware, Sparkes, and Jones 2000,Luebke 2001, Danovaro, De Floriani, Magillo, Mesmoudi, and Puppo 2003).Reference interval functionsA different approach is required when we wish to model surfaces from referenceinterval functions, for example population counts for areas. Each count relates toan (initially irregular) reference area. In modeling this type of information in sur-face form we may either produce a density value at a reference point for each areaand interpolate between these points, or explicitly redistribute the count associatedwith each area into a ﬁne grid approximating the required surface. The latter intro-duces the possibility",
    "chunk_order_index": 153,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-2c0a1becb17439d067af8f044cb363af": {
    "tokens": 1200,
    "content": "2003).Reference interval functionsA different approach is required when we wish to model surfaces from referenceinterval functions, for example population counts for areas. Each count relates toan (initially irregular) reference area. In modeling this type of information in sur-face form we may either produce a density value at a reference point for each areaand interpolate between these points, or explicitly redistribute the count associatedwith each area into a ﬁne grid approximating the required surface. The latter intro-duces the possibility of having zero-value (unpopulated) regions within the outputsurface and is suitable with small areas and high resolution grid references. Bothapproaches require the presence of reference points for each area. For interpolationa simple geometric centroid may be sufﬁcient. The density value for each area isassigned to its centroid and an appropriate interpolation algorithm applied as forpoint reference functions.(a)(b)Fig. 13.5Perspective surface views and TINS with (b) and without (a) adaptive LOD proportionalto the viewpointFrom Garland 1999, used with permissionTHO_C13  19/03/2007  11:15  Page 247 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f248NICHOLAS J. TATE, PETER F. FISHER, AND DAVID J. MARTINFor the redistribution approach a weighted centroid will produce better results,and if this is not directly available in the input data it may be possible to createone by overlaying ancillary data onto the original areas in order to estimate suchcentroids. An example would be the overlay of remotely sensed land use data ontocensus areas in order to identify centroids of populated areas to which the popula-tion counts can be assigned. Redistribution algorithms of this type typically employa spatial kernel which is focused over each centroid in turn and a distance decaymodel for the redistribution of the count into the immediate neighborhood applied.The process is illustrated by Figure 13.6.In Figure 13.6a a population count is associated with the area centroid location. InFigure 13.6b a kernel function is centered on the centroid in order to estimate weightsassociated with each location on a ﬁne-resolution grid. If the size of this kernel isvaried according to, for example, the number of other centroids encountered, thisis a form of adaptive kernel estimation (Bailey and Gatrell 1995). In Figure 13.6c theweights associated with each cell are used to guide redistribution of the originalpopulation count onto the surface model. The form of the surface is strongly deter-mined by the choice of kernel function: larger kernels will result in smoother surfacerepresentations. Some cells will not fall within the kernel of any centroids and thusremain unpopulated, while others will receive counts from several centroids, allowingthe surface model to reconstruct aspects of the underlying settlement geography. Thisis the method employed by Martin (1996) and Martin, Tate, and Langford (2000)in population density surface construction from census area centroid locations.Surface VisualizationRenderingSurface representation provokes a number of possible visualization strategies. First amongthem is the classic contour map (Figure 13.7).Historically this has been the most important representation for two reasons: ﬁrst,it is depicted by a set of lines in Cartesian space and as such it is easy to construct(a)(b)(c)Fig. 13.6Kernel estimation of a reference-interval function: (a) original data collection area withpopulation count and centroid location; (b) local kernel superimposed at centroid location; and (c) population count redistributed onto grid according to kernel functionTHO_C13  19/03/2007  11:15  Page 248 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND SURFACES249and relatively inexpensive to reproduce; and second, it leaves much space in anymap empty and therefore available for other information, particularly in topographicmapping. If these other information (place names, data values, etc.), or reproductioncosts are still a concern then the contour map remains the most effective repres-entation. The contour map, however, leaves much to the skill of the map reader,and the understanding of contours is not necessarily as intuitive as those who canappreciate them may believe. Furthermore, contouring is about the least informativevisualization method.The use of a color ﬁll between contours is the next simplest method (Figure 13.8),and embeds an ordering in the colors used between contours.This has been less-favored due to the cost of production and reproduction, but,with computer technology and the gridded data in particular, it is actually easierthan most other methods for visualization of surface data in most GIS. The choiceof colors, however, needs to respect the properties of color space, and blend througha limited part of that space. A number of conventions for coloring surfaces exist,but can be confusing. The classic method is to use a monochrome representationvarying the lightness or intensity of the color. For example, when terrain is visu-alized, the highest ground should normally be shown in the palest color (white ingrey scale image; Figure 13.8), but when the subject is some other environmentalor social",
    "chunk_order_index": 154,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-aee79e2e26f1018e048823b43fdf44b8": {
    "tokens": 1200,
    "content": ", however, needs to respect the properties of color space, and blend througha limited part of that space. A number of conventions for coloring surfaces exist,but can be confusing. The classic method is to use a monochrome representationvarying the lightness or intensity of the color. For example, when terrain is visu-alized, the highest ground should normally be shown in the palest color (white ingrey scale image; Figure 13.8), but when the subject is some other environmentalor social parameter, it is more usual to show the largest values with the darkestcolor. Terrain can also be illustrated with a multi-hue color scheme as is done inatlases, with yellow or brown through green to blue and white being a typical colorscheme for increasing altitude.Fig. 13.7An isoline visualization or contour map of a part of the British Lake District centered onthe Helvellyn rangeThe map is derived from the Ordinance Survey 50 m DEM, Panorama product © Crowncopyright/database right 2006. An Ordnance Survey/EDINA supplied serviceTHO_C13  19/03/2007  11:15  Page 249 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f250NICHOLAS J. TATE, PETER F. FISHER, AND DAVID J. MARTINAlso now commonplace are 2.5D or pseudo-3D views (Figure 13.9), so-called todistinguish them from true 3D navigable views discussed in the section on navig-able views below. Again, the cost and skill required for constructing these viewswas a deterrent to their reproduction in the past, but in computer systems it is trivial to generate perspective views of the surface. There are two principal types,isometric, and perspective, where the former ignores the complexity of perspective.However, there is little difference, when viewed from a distance, typical in carto-graphic representation. The problem of these views is that hills in the foregroundwill conceal parts of the terrain rather than revealing it as is usually the intentionin mapping.Derivatives and drapesIt is relatively simple to derive ﬁrst and second order derivatives of any surface,including the gradient or slope of the surface, the aspect and curvature (plan andproﬁle). These too can be visualized. Curvature and slope are continuous variablesand can be illustrated with simple monochrome colorings, such as a grey-scale fromwhite to dark grey (Figure 13.10), but aspect is measured as an angular bearingand so should use a color scheme where 360°is colored the same as 0°.Color hue can be used to visualize aspect and is sometimes speciﬁed in Intensity–Hue–Saturation schemes by 0°–360°(Brown and Feringa 2003). Moellering andKimerling (1990) and Brewer and Marlow (1993) (see also the cover illustration ofMacEachren and Fraser-Taylor [1994]), have suggested combining hue to indicateaspect and lightness (or intensity) to indicate slope. The resulting representationsare very striking and informative.Fig. 13.8A ﬁlled contour visualization of the same area as is shown in Figure 13.7© Crown copyright/database right 2006. An Ordnance Survey/EDINA supplied serviceTHO_C13  19/03/2007  11:15  Page 250 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND SURFACES251Another striking effect for surface visualization is produced when hillshading isused as a grey-scale background (lightness), and hue and saturation are used toshow elevation. This scheme is used in many atlases and topographic mappings,although the hue-saturation scheme for elevation varies.Contouring and color ﬁlled contours are appropriate for viewing the gross properties of a surface, but the detail of that surface will only appear when thederivatives are visualized (Wood and Fisher 1993, Wood 1994). To see detail, the most effective methods for visualization are entirely based on the derivatives.Mapping slope will show areas of steepness occurring in bands in a DEM wherethere are no bands of steep slope in the ﬁeld (they are ghosts of the digitized con-tour lines from which some DEMs are created). Perhaps hillshading is the mosteffective (Figure 13.11) of all, showing many different artifacts of a DEM wherecontour and other mapping do not.(a)(b)Fig. 13.9A psuedo-3D view of the same general area as is shown in Figure 13.7, showing (a) aﬁlled contour drape and (b) a hillshaded drape© Crown copyright/database right 2006. An Ordnance Survey/EDINA supplied serviceTHO_C13  19/03/2007  11:15  Page 251 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on",
    "chunk_order_index": 155,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f0ca6dfb4a945c71f3a0d87a84e0464c": {
    "tokens": 1200,
    "content": "hillshaded drape© Crown copyright/database right 2006. An Ordnance Survey/EDINA supplied serviceTHO_C13  19/03/2007  11:15  Page 251 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f252NICHOLAS J. TATE, PETER F. FISHER, AND DAVID J. MARTINOver any surface it is also possible to drape some other theme. Many such drapes are used, common ones being an aerial photograph or satellite image of thearea, and surface derivatives. The information has to be georegistered to the samereference framework, but otherwise the process is quite straightforward in mostmodern GIS.Navigable viewsThe ultimate form of visualization of a surface is as a navigable “Virtual Reality”(VR) model. The difference between the 2.5D view and the VR model is simplythat the user has the ability to navigate around the VR model, they can immersethemselves in the 3D model, and they can traverse it (Brodlie, Dykes, Gillings, etal. 2002; Figure 13.12). VR models are all grounded in the same basic technologybut come in many different versions, from the simple “through-the-window” VRon the standard computer screen, to VR theaters, caves, and headsets which allgive increasing amounts of personal immersion in the environment (Brodlie and El-Khalili 2002; see also Chapter 17 by Batty, in this volume for additional dis-cussion of VR and GI Science).VR models bring with them the desire to create photo-realistic views, which lookas the actual landscape might look. If the user intends to hover over the landscape,then it can be sufﬁcient to drape an aerial photograph over the landscape to givea realistic-looking context (Miller, Dunham, and Chen 2002), but if the viewer isto be embedded in the landscape it is not. Ultimately the VR view is based on aFig. 13.10A slope map of the same area as is shown in Figure 13.7; white indicates steep slopesand black ﬂat© Crown copyright/database right 2006. An Ordnance Survey/EDINA supplied serviceTHO_C13  19/03/2007  11:15  Page 252 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND SURFACES253(a)(b)Fig. 13.11Hillshaded maps of the same area as is shown in Figure 13.7; (a) is illuminated from thenorthwest and (b) from the southeast© Crown copyright/database right 2006. An Ordnance Survey/EDINA supplied serviceTHO_C13  19/03/2007  11:15  Page 253 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f254NICHOLAS J. TATE, PETER F. FISHER, AND DAVID J. MARTINsampling or abstraction of the landscape (elevations, houses, trees, etc.) and so thechallenge of generating a photo-realistic view is considerable (Ervin and Hasbrouck2001). The principal problem with realistic rendering of scenes is that so much movesin the real world, and if it does not move in the VR model the model looks likewhat it is, an abstraction (Gillings 2002).CONCLUSIONSIn this chapter we have reviewed the unique characteristics of surface-type geographicphenomena. These are characterized by continuous variation in some variable ofinterest over geographic space and cover a wide range of application areas. Thechallenge of surface representation in GIS concerns selection of an appropriate trade-off between costly measurement and complex modeling. Nevertheless, a number ofstandard approaches are available which allow us to achieve close approximationsto true surface properties and these support a range of enormously powerful visual-ization and analysis functions.Fig. 13.12A navigable 3D view of the area around the University of Leicester. Buildings areextruded from the land surface as prisms using only the number of ﬂoors for height without accurateroof lines or photographic drapes for detail or the elevationsSome Ordnance Survey Landline data was used © Crown copyright/database right 2006. AnOrdnance Survey/EDINA supplied serviceTHO_C13  19/03/2007  11:15  Page 254 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND SURFACES255ACKNOWLEDGEMENTSThe data representations in",
    "chunk_order_index": 156,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-8efb959120042f1e5573b9df5b7d6950": {
    "tokens": 1200,
    "content": "2007  11:15  Page 254 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND SURFACES255ACKNOWLEDGEMENTSThe data representations in Figure 13.1 were kindly provided by Richard Websterand Rothamsted Research. The data used in Figures 2, 3, and 4 were provided courtesy of the Environment Agency Science Group. Figure 13.5 is courtesy of MichaelGarland. The assistance of Kate Moore in assembling the database for Figure 13.11is also acknowledged.ENDNOTE1This they term a “Digital Surface Model” which contrasts with the use of the term inGIS/Photogrammetry as an elevation model which includes vegetation/building in addi-tion to the bare earth (Weibel 1997).REFERENCESAmenta, N., Bern, M., and Eppstein, D. 1998. The crust and the β-skeleton: Combinatorialcurve reconstruction. Graphical Models and Image Processing60: 125–35.Bailey, T. C. and Gatrell, A. C. 1995. Interactive Spatial Data Analysis. Harlow: Longman.Barnhill, R. E. 1983. A survey of the representation and design of surfaces. IEEE ComputerGraphics and Applications3: 9–16.Brewer, C. A. and Marlow, K. A. 1993. Color representation of aspect and slope simultan-eously. In Proceedings of Auto Carto 11, Bethesda, MD, USA. Bethesda, MD: AmericanSociety for Photogrammetry and Remote Sensing, pp. 328–37.Brodlie, K., Dykes, J., Gillings, M., Haklay, M. E., Kitchin, R., and Kraak, M. J. 2002.Geography in VR: Context. In P. F. Fisher and D. J. Unwin (eds) Virtual Reality inGeography.London: Taylor and Francis, pp. 7–16.Brodlie, K. and El-Khalili. 2002. Web-based virtual environments. In P. F. Fisher and D. J. Unwin (eds) Virtual Reality in Geography.London: Taylor and Francis, pp. 35–46.Brown, A. and Feringa, W. 2003. Colour Basics for GIS Users. Englewood Cliffs, NJ: Prentice-Hall.Dakowicz, M. and Gold, C. M. 2002. Extracting meaningful slopes from terrain contours.In P. M. A. Sloot, C. J. K. Tan, J. J. Dongarra, and A. G. Hoekstra (eds) ComputationalScience. Berlin, Springer-Verlag: Lecture Notes in Computer Science No 2329: 144–53.Danovaro, E., De Floriani, L., Magillo, P., Mesmoudi, M. M. and Puppo, E. 2003.Morphology-driven simpliﬁcation and multi-resolution modeling of terrains. In Proceed-ings of the Eleventh International Symposium on Advances in Geographical InformationSystems (ACM-GIS 2003), New York, USA. New York: Association for ComputingMachinery, pp. 63–70.De, Floriani. L., Marzano, P., and Puppo, E. 1996. Multiresolution models for topographicsurface description. The Visual Computer12: 317–45.Ervin, S. M. and Hasbrouck, H. H. 2001. Landscape Modeling: Digital Technique forLandscape Visualization. NewYork: McGraw-Hill.Farin, G. 1997. Curves and Surfaces for Computer-Aided Geometric Design: A Practical Guide(4th edn). San Diego, CA: McGraw-Hill.Foley, J. D., Van Dam, A., Feiner, S., and Hughes, J. 1990. Computer Graphics: Principlesand Practice(2nd edn). Massachusetts: Addison-Wesley.THO_C13  19/03/2007  11:15  Page 255 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f256NICHOLAS J. TATE, PETER F. FISHER, AND DAVID J. MARTINFowler, R. J. and Little, J. J. 1979. Automatic extraction of irregular network digital terrainmodels. Computer Graphics13: 199–207.Garland, M. 1999. Multi-resolution modeling: Survey and future opportunities. In Proceed-ings of Eurographics ’99,Milan, Italy. Aire-la-Ville, Switzerland: European Associationfor Computer Graphics, pp. 111–31.Gillings, M. 2002. Virtual archaeologies and the hyper-real. In P. F. Fisher and D. J. Unwin(eds) Virtual Reality in Geography.London: Taylor and Francis, pp. 17–34.Gold, C. M. 1979. Triangulation based terrain modeling: Where are we now?In Proceeding",
    "chunk_order_index": 157,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-35aaa5c01bbb22805128967e726009a1": {
    "tokens": 1200,
    "content": "ilan, Italy. Aire-la-Ville, Switzerland: European Associationfor Computer Graphics, pp. 111–31.Gillings, M. 2002. Virtual archaeologies and the hyper-real. In P. F. Fisher and D. J. Unwin(eds) Virtual Reality in Geography.London: Taylor and Francis, pp. 17–34.Gold, C. M. 1979. Triangulation based terrain modeling: Where are we now?In Proceedingsof Auto Carto 4,Baltimore, MD, USA. Bethesda, MD: American Society for Photogrammetryand Remote Sensing, pp. 104–11.Gold, C. M. 1994. An object-based method for modeling geological surfaces containing linear data. In Proceedings of the Annual Meeting of the International Association forMathematical Geology, Mont Tremblant, Quebec. Kingston, Ontario: International Asso-ciation for Mathematical Geology, pp. 141–6.Gold, C. M. 2003. But is it GIS? Journal of Geospatial Engineering5: 11–26.Goodchild, M. F. 1992. Geographical data modeling. Computers and Geosciences18: 401–8.Goodchild, M. F. 2003. The nature and value of geographic information. In M. Duckham,M. F. Goodchild, and M. F. Worboys (eds) Foundations of Geographic Information Science.London: Taylor and Francis, pp. 19–32.Hoppe, H., DeRose, T., Duchamp, T., Halstead, M., Jin, H., McDonald, J., Schweitzer, J.,and Stuetzle, W. 1994. Piecewise smooth surface reconstruction. In D. Schweitzer, A. Glassner,and M. Keeler (eds)Proceedings of the Twenty-ﬁrst Annual Conference on ComputerGraphics and Interactive Techniques. New York: ACM Press, pp. 295–302.Hoppe, H., DeRose, T., Duchamp, T., McDonald, J., and Stuetzle, W. 1992. Surface recon-struction from unorganized points. In J. J. Thomas (ed.) Proceedings of the NineteenthAnnual Conference on Computer Graphics and Interactive Techniques.New York: ACMPress, pp. 71–8.Hormann, K., Spinello, S., and Schroeder, P. 2003. C1continuous terrain reconstruction from sparse contours. In Proceedings of the Eighth International Workshop on Vision,Modeling, and Visualization, Munich, Germany, pp. 289–97.Hugentobler, M. 2002. Interpolation of continuous surfaces for terrain modeling with coonspatches. In Proceedings of the Tenth GIS Research UK Annual Conference, Shefﬁeld, United Kingdom. Shefﬁeld, United Kingdom: GISRUK, pp. 13–15. (Available on-line viahttp://www.shef.ac.uk/gisruk/.)Hugentobler, M. 2004. Terrain Modeling with Triangle Based Free-Form Surfaces. Unpub-lished PhD Dissertation, University of Zurich.Hutchinson, M. F. 1993. On thin plate splines and kriging. In M. E. Tarter and M. D. Lock(eds) Computing and Science in Statistics 25.Berkeley, CA: Interface Foundation of NorthAmerica, pp. 55–62.Kidner, D. B., Ware, J. M., Sparkes, A. J., and Jones, C. B. 2000. Multiscale terrain andtopographic modeling with the implicit TIN. Transactions in GIS4: 379–408.Lam, N. S. N. 1983. Spatial interpolation methods: A review. American Cartographer10:129–49.Lee, J. 1991. A comparison of the existing methods for building TIN models of terrain.International Journal of Geographical Information Systems5: 267–85.Legates, D. R. and Willmott, C. J. 1986. Interpolation of point values from isoline maps.American Cartographer13: 308–23.Little, J. J. and Shi, P. 2001. Structural lines, TINs and DEMs. Algorithmica30: 243–63.Luebke, D. P. 2001. A developer’s survey of polygonal simpliﬁcation algorithms. IEEEComputer Graphics and Applications21: 24–35.THO_C13  19/03/2007  11:15  Page 256 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND SURFACES257McCullagh, M. J. 1990. Digital terrain modeling and visualization. In G. Pertrie and T. J. M. Kennie (eds) Terrain Modeling in Surveying and Civil Engineering.London: WhittlesPublishing/Thomas Telford, pp. 128–51.MacEachren, A. M. and Fraser-Taylor, D. 1994. Visualization in Modern Cartography. Oxford:Elsevier.Mardia, K. V., Kent, J. T., Goodall, C. R., and Little, J. A. 1996. Kriging and splines withderivative information. Biometrika81: 207–21",
    "chunk_order_index": 158,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7dbf07b93088b11a0153f85e225ad08c": {
    "tokens": 1200,
    "content": "Engineering.London: WhittlesPublishing/Thomas Telford, pp. 128–51.MacEachren, A. M. and Fraser-Taylor, D. 1994. Visualization in Modern Cartography. Oxford:Elsevier.Mardia, K. V., Kent, J. T., Goodall, C. R., and Little, J. A. 1996. Kriging and splines withderivative information. Biometrika81: 207–21.Mark, D. M. and Smith, B. 2004. A science of topography: From qualitative ontology todigital representations. In M. P. Bishop and J. Shroder (eds) Geographic Information Scienceand Mountain Geomorphology. Chichester: Springer-Praxis: 75–100.Martin, D. 1996. An assessment of surface and zonal models of population. InternationalJournal of Geographical Information Systems10: 973–89.Martin, D., Tate, N. J., and Langford, M. 2000. Reﬁning population surface models:Experiments with Northern Ireland census data. Transactions in GIS4: 343–60.Miller, D. R., Dunham, R. A., and Chen, W. 2002. The application of VR modeling in assess-ing potential visual impacts of rural development. In P. F. Fisher and D. J. Unwin (eds)Virtual Reality in Geography.London: Taylor and Francis, pp. 131–43.Mitas, L. and Mitasova, H. 1999. Spatial interpolation. In P. A. Longley, D. J. Maguire,M. F. Goodchild, and D. W. Rhind (eds) Geographical Information Systems: Principlesand Applications.New York: John Wiley and Sons, pp. 481–92.Mitasova, H., Hoﬁerka, J., Zlocha, M., and Iverson, J. 1996. Modeling topographic potentialfor erosion and deposition using a GIS.International Journal of Geographic InformationSystems10: 629–41.Moellering, H. and Kimerling, A. J. 1990. A new digital slope-aspect display process.Cartography and Geographic Information Systems17: 151–9.Myers, D. E. 1994. Spatial interpolation: An overview. Geoderma62: 17–28.Nordbeck, S. and Rystedt, B. 1970. Isarithmic maps and the continuity of reference inter-val functions. Geograﬁska Annaler 52B: 92–123.Oliver, M. A. and Webster, R. 1990. Kriging: A method of interpolation for geographicalinformation systems. International Journal of Geographic Information Systems4:  313–32.Oliver, M. A. and Webster, R. 1991. How geostatistics can help you. Soil Use and Manage-ment7: 206–17.Openshaw, S. 1984. The Modiﬁable Areal Unit Problem: Concepts and Techniques in ModernGeography. Norwich: Geo Books.Petrie, G. 1990a. Modeling, interpolation and contouring procedures. In G. Petrie and T. J. M. Kennie (eds) Terrain Modeling in Surveying and Civil Engineering.London: WittlesPublishing/Thomas Telford, pp. 112–27.Petrie, G. 1990b. Terrain data acquisition and modeling from existing maps. In G. Petrieand T. J. M. Kennie (eds) Terrain Modeling in Surveying and Civil Engineering.London:Wittles Publishing/Thomas Telford: 85–111.Puppo, E. and Scopigno, R. 1997. Simpliﬁcation, LOD and multi-resolution: Principles andapplications. In Proceedings of the Eighteenth Annual European Conference on ComputerGraphics (Eurographics ’97), Budapest, Hungary. Aire-la-Ville, Switzerland: EuropeanAssociation for Computer Graphics.Schneider, B. 2001a. On the uncertainty of local shape of lines and surfaces. Cartographyand Geographic Information Science28: 237–47.Schneider, B. 2001b. Phenomenon-based speciﬁcation of the digital representation of terrainsurfaces. Transactions in GIS5: 39–52.Smith, B. 2001. Fiat objects. Topoi20: 131–48.Thibault, D. and Gold, C. M. 2000. Terrain reconstruction from contours by skeleton con-struction. GeoInformatica4: 349–73.THO_C13  19/03/2007  11:15  Page 257 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f258NICHOLAS J. TATE, PETER F. FISHER, AND DAVID J. MARTINThurstain-Goodwin, M. 2003. Data surfaces for a new policy geography. In P. A. Longleyand M. Batty (eds) The CASA Book of GIS.Redlands, CA: ESRI Press, pp. 145–70.Watson, D. F. 1992. Contouring: A Guide to the Analysis and Display of Spatial Data.Oxford:Pergamon.Webster, R. and McBratney, A.",
    "chunk_order_index": 159,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-fbfa7c9e5b75423b116de9df8e3efea5": {
    "tokens": 1200,
    "content": "Thurstain-Goodwin, M. 2003. Data surfaces for a new policy geography. In P. A. Longleyand M. Batty (eds) The CASA Book of GIS.Redlands, CA: ESRI Press, pp. 145–70.Watson, D. F. 1992. Contouring: A Guide to the Analysis and Display of Spatial Data.Oxford:Pergamon.Webster, R. and McBratney, A. B. 1987. Mapping soil fertility at Broom’s Barn by simpleKriging. Journal of the Science of Food and Agriculture36: 97–115.Webster, R. and Oliver, M. A. 2001. Geostatistics for Environmental Scientists. Chichester:John Wiley and Sons.Weibel, R. 1997. Digital terrain modeling for environmental applications: A review of techniques and trends. In Progress Seminar on Developments and Applications of DigitalElevation Models in Environmental Modeling,Vienna, Austria.Wood, J. 1994. Visualizing contour interpolation accuracy in digital elevation models. InH. M. Hearnshaw and D. J. Unwin (eds) Visualization in Geographical Information Systems.Chichester: John Wiley and Sons, pp. 168–80.Wood, J. D. and Fisher, P. F. 1993. Assessing interpolation accuracy in elevation models.IEEE Computer Graphics and Applications13: 48–56.Xie, H., Wang, J., Hua, J., Qin, H., and Kaufman, A. 2003. Piecewise C1continuous surfacereconstruction of noisy point clouds via local implicit quadric regression. In Proceedingsof the IEEE Conference on Visualization, Seattle, WA: 91–8.Yoeli, P. 1986. Computer executed production of a regular grid of height points from digital contours. The American Cartographer13: 219–29.THO_C13  19/03/2007  11:15  Page 258 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 14Fuzzy Classiﬁcation and MappingVincent B. RobinsonThe mapping process is basically concerned with determining “what” is “where”and representing that “what is where” knowledge in a form that can be stored for later retrieval, display, and analysis. With the advent of computerized Geogra-phic Information Systems (GIS) and related technologies, the digital representationof information from the mapping exercise led to the development of spatial databasesthat permit the representation, manipulation, and display of geographical phenomenawith greater rigor, detail, and consistency than ever before. However, owing to the characteristics of the mapping methodology and/or the nature of phenomenonbeing mapped it is often difﬁcult to be absolutely certain of “what is where.” Formany phenomena that are distributed over space there are no crisp boundaries that can be identiﬁed to differentiate classiﬁed geographic zones (Cheng, Molenaar,and Lin 2002). For examples, the boundary between beach and foreshore, betweenwoodland and grassland, and between urban and rural areas may be gradual ratherthan deﬁned by a sharp boundary. Furthermore, when we use a remotely sensedimagery to extract objects of interest, there are pixels that may contain sub-pixelobjects, trans-pixel objects, boundary pixels and/or natural intergrades (Foody 1999).The mixture of spectral information at the sub-pixel scale can lead to uncertainclassiﬁcation and indeterminate boundaries. These problems of uncertainty have ledmany to use classiﬁcation techniques based on fuzzy set theory.As researchers and practitioners wrestled with how to represent, manipulate, and manage geographic data within the developing ﬁeld of GIS, issues of error anduncertainty began to be recognized (Robinson and Frank 1985), and the potentialof fuzzy set theory (Zadeh 1965) in GIS began to be addressed. McBratney andOdeh (1997), in their perspective piece on fuzzy sets in soil science, note that theinadequacy of traditional Boolean logic for the design of spatial databases for GIShas been identiﬁed since the 1980s (Robinson and Strahler 1984). In his essay onthe principles of logic for GIS, Robinove (1989) discusses the potential value of fuzzyset theory. Thus, the relevance of fuzzy sets to GIS was recognized early on by asmall group of researchers.This chapter ﬁrst presents some basic concepts of fuzzy set theory and how theyare related to fuzzy classiﬁcation and mapping for GIS. A more in-depth presentationTHO_C14  20/03/2007  15:07  Page 259 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f260VINCENT B. ROBINSONof many of the topics summarized in this chapter can be found in other works (forexample, Klir and Yuan 1995, Burrough and Frank 1996, McBratney and Odeh1997, Burrough and McDonnell 1998, Robinson 2003). The reader is encouragedto consult them as well as the",
    "chunk_order_index": 160,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-54319a6a2b563b3ddb2c905ee0ac6926": {
    "tokens": 1200,
    "content": "on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f260VINCENT B. ROBINSONof many of the topics summarized in this chapter can be found in other works (forexample, Klir and Yuan 1995, Burrough and Frank 1996, McBratney and Odeh1997, Burrough and McDonnell 1998, Robinson 2003). The reader is encouragedto consult them as well as the references cited.Fuzzy Classiﬁcation: The BasicsIn set theory the membership of an element in a particular set is deﬁned by a charac-teristic function. Nonfuzzy classiﬁcation uses characteristic functions that result ina location being classiﬁed as either a member of a set or not. For example, in GISapplications percent slope is often calculated for each location in a study area. Wemay use a characteristic function that says that all locations where the percent slopeis between 5 and 17 will be classiﬁed as gentle slope. Now consider the question ofat which value of percent slope speciﬁcally a location goes from being gentle to notgentle?” Our rule implies that locations with a percent slope of 17.01 are classed asnot gentlewhile locations with 16.98 are gentle. Perhaps a slope of 17.01 is simplynot as gently sloping as one of 16.98, hence locations with a slope of 17.01 might beconsidered both gentle and not gentle but to differing degrees. This is the fundamentalproposition upon which fuzzy set theory is based. In other words, the characteristicfunction indexes the degree to which a location is a member of a set with largervalues denoting higher degrees of set membership. Such a function is referred to as amembership function. The set deﬁned by such a membership function is a fuzzy set.Assigning Membership ValuesIt is common in the GIS literature to describe the approaches to assigning fuzzymembership values as following either the Semantic Import (SI) or Similarity Relation(SR) model (Robinson 1988, Burrough and McDonnell 1998). The SI model is basedon using a prioriknowledge to construct fuzzy membership functions with which indi-viduals can be assigned a membership grade. If the process of assigning membershipvalues depends on similarity relations then it ﬁts the SR model. The essential aspectof the SR model is that membership values of elements are a function of how similar/dissimilar an element is to some ideal. The essential difference between the SI andSR models is the degree to which an approach is dependent on similarity measuresto derive a function that assigns membership values to individual elements. So ratherthan organize the methods of fuzzy classiﬁcation along SI/SR lines, the approach inthis chapter is to ﬁrst consider use of models that rely heavily on a priori knowledgeto arrive at a classiﬁcation. Then the important technique of fuzzy clustering will beconsidered since it focuses on extracting fuzzy classiﬁcation ‘rules’ from the data itself.Fuzzy Classiﬁcation with a priori KnowledgeOne common approach to specifying a membership function is to use a plausiblestandard function (for example, triangular or sigmoidal) (Robinson 2003). This THO_C14  20/03/2007  15:07  Page 260 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFUZZY CLASSIFICATION AND MAPPING261presumes some degree of a priori knowledge. No matter which standard function isused there remains the necessity of having the function be applicable to the problemat hand. In other words, parameters must be speciﬁed so the membership functionmakes sense in the context of the problem. On the other hand, there have been caseswhere membership functions have been constructed that are unique to the problem(for example, Brown 1998; Wang and Hall 1996).Although solitary membership functions have been used to provide linguistic interpretations of quantitative data, a fuzzy model is usually composed of manymembership functions in combination. The techniques of combining the membershipfunctions are grouped into aggregation models and rule-based models.Aggregation modelsAggregation operations on fuzzy sets are operations that combine several fuzzy sets in a desirable manner to produce a single fuzzy set (Klir and Yuan 1995). Theseveral fuzzy sets that are being combined are deﬁned by membership functionsapplied to a number of different map layers. This process is referred to as fuzziﬁca-tion. For example, application of membership functions may result in map layersdeﬁning the fuzzy sets good_slope, close_to_road, and far_from_stream. Aggrega-tion operators would be used to then combine them into a single fuzzy set such asgood_location. The term Joint Membership Function (JMF) conveys the idea thatthe fuzzy membership at a map location is a joint function of several fuzzy sets(Burrough and McDonnell 1998) combined using some model of aggregation. Thereare many aggregation operators from which to choose. The most commonly usedoperators are the intersection (min) and union (max) operators ﬁrst proposed byZadeh (1965).One problem with the max/min operators is that they confer equal weight toeach map. Some studies have incorporated preferences by formulating a weightedaggregation model. Oberthur, Dobermann, and Aylward (2000) used a convex combination in their study to combine sets of soil properties into indices of soilquality. Jiang and Eastman (2000) used a modi",
    "chunk_order_index": 161,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f347477e36ce0ff5825ec4ee6c11ecc5": {
    "tokens": 1200,
    "content": "commonly usedoperators are the intersection (min) and union (max) operators ﬁrst proposed byZadeh (1965).One problem with the max/min operators is that they confer equal weight toeach map. Some studies have incorporated preferences by formulating a weightedaggregation model. Oberthur, Dobermann, and Aylward (2000) used a convex combination in their study to combine sets of soil properties into indices of soilquality. Jiang and Eastman (2000) used a modiﬁed ordered weighted averaging operator (OWA) and showed different aggregation approaches can yield strikinglydifferent results.Rule-based modelsFuzzy rule-based models are another class of a priori knowledge-based models seen in GIS applications and are covered in more detail by Zhu in Chapter 15 ofthis volume. Fuzzy rules deﬁne the connection between input and output fuzzy sets(that is, membership functions). The rules have the general structure of the form:IF(antecedent) THEN(consequent). The antecedent and consequent conditions are deﬁned by fuzzy sets. If the fuzzy system is used as a classiﬁer the consequentcan become a crisp value (or label). The speciﬁc form of the antecedent fuzzy sets canbe based on standard membership functions, as was done in a fuzzy rule-basedapproach to map comparison (Power, Simms, and White 2001). To evaluate the rulebase and arrive at an answer requires the application of an inference, or implica-tion, method. The use of rule-based fuzzy models in GIS include applications forTHO_C14  20/03/2007  15:07  Page 261 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f262VINCENT B. ROBINSONthe conﬂation of vector maps (Cobb, Chung, Foley, Petry, and Shaw 1998), realestate evaluation (Zeng and Zhou 2001), and land ﬁll location (Charnpratheep,Zhou, and Garner 1997).Specifying membership functionsRegardless of whether an aggregation or rule-based model is being used, the spe-ciﬁcation of the membership functions is fundamental to model formulation. It isthe speciﬁcation and tuning of membership functions that has been a source of muchcriticism leveled at the fuzzy logic approach in general (Yen 1999) and more speciﬁcallyin GIS (Goodchild 2000). Often the parameters of standard membership functionsare described as being chosen by experts ( for example, Stefanakis, Vazirgiannis, andSellis 1999, MacMillan, Pettapiece, Nolan, and Goddard 2000, DeGenst, Canters,and Gulink 2001). Rigorous speciﬁcation of membership functions from expertscan be a difﬁcult task (Zhu 1999). The challenging proposition of acquiring fuzzymemberships from domain experts has been addressed by automating the processto some extent in systems such as the spatial relations acquisition station (SRAS)(Robinson 2000), SOLIM (Zhu 1999; Zhu, Hudson, Burt, Lubich, and Simonson2001) and others (Foley, Petry, Cobb, and Shaw 1997). Each uses a different, yetformal approach to acquiring fuzzy membership functions from experts. Anotheremerging class of approaches seeks to supplement, or supplant, the input of humanexpertise with automated techniques for parameterizing fuzzy models (Huang,Gedeon, and Wong 1998, Mackay, Samanta, Ahl, et al. 2003).Data-Driven Fuzzy ClassiﬁcationSo what happens when we do not have sufﬁcient a priori knowledge to construct afuzzy model? One of the most commonly used class of methods is fuzzy clustering.Less often seen is the use of neural networks to extract fuzzy rule bases or as thebasis for fuzzy classiﬁcation directly (Carpenter, Gjaja, Gopan, and Woodstock 1997,Foody and Boyd 1999, Zheng and Kainz 1999).Neural networks and fuzzy classiﬁcationIn the mapping of land cover over large regions remote sensing techniques are usedand the application of traditional neural network methods are adjusted so that theoutput is a fuzzy membership of a pixel in a land cover class. Thus, it is used todirectly produce a fuzzy classiﬁcation (Foody and Boyd 1999). Other GIS applica-tions may use neural networks to extract a rule base from the data (Zheng andKainz 1999). In either case, the general architecture of the artiﬁcial neural networkis basically the same. These networks are composed of a set of simple processingunits, or nodes, that are interconnected by some predeﬁned architecture which canbe trained. The processing nodes are arranged in a layered architecture typicallycomposed of three layers. The ﬁrst layer is the input, or fuzziﬁcation, layer wherethere is one node per input variable. The implication layer is comprised of a numberof processing units. These are the processing nodes that do most of the “thinking”THO_C14  20/03/2007  15:07  Page 262 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley",
    "chunk_order_index": 162,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-fbca9228394768746e20e2180beaf481": {
    "tokens": 1200,
    "content": "layer is comprised of a numberof processing units. These are the processing nodes that do most of the “thinking”THO_C14  20/03/2007  15:07  Page 262 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFUZZY CLASSIFICATION AND MAPPING263of the neural network. The outcomes of processing at this layer ﬂow to the outputlayer. In general, there is one output node associated with each class. Although thesenetworks are typically used to arrive at a crisp classiﬁcation, they can be designedto provide a fuzzy classiﬁcation (Foody and Boyd 1999). Alternatively, the processof generating classiﬁcations can be exploited to extract a fuzzy rule base (Zhengand Kainz 1999).A related technique is the adaptive neuro-fuzzy inference system (ANFIS) (Jang1993). Using a given input/output data set the objective is to construct a fuzzy infer-ence system whose membership functions best suit the data set. Using either a back-propagation algorithm and/or a least-squares method, the membership parametersare tuned in a training exercise similar to regular neural networks. ANFIS has beenused for map revision (Teng and Fairbairn 2002) and land cover classiﬁcation.The neural network approach has advantages and disadvantages. The advantagesof neural networks include an ability to learn from past experience and they canhandle noise and incomplete data. Once trained, a neural network can respond toa new set of data instantly. However, some of the disadvantages remain signiﬁcanthurdles for application in GIS. They can take a long time to train, especially sincetraining is still largely a trial and error situation further complicated by the factthat incomplete training data can cause the network to give wrong results, as canthe incorrect network target outputs in a supervised learning algorithm. Perhaps themost important disadvantage is that it is difﬁcult to explain the reasoning that ledto the output product. It is perhaps for this reason that the neuro-fuzzy techniquesare not quite as commonly used as another class of data-driven fuzzy classiﬁcationmethod, namely fuzzy clustering.Fuzzy clusteringOriginally developed by Dunn (1973) and later generalized by Bezdek (1981) thefuzzy c-means (FCM) algorithm (also known as the fuzzy k-means algorithm) remainsone of the most popular techniques for allocating individuals to fuzzy sets (that is, assigning membership values). The basic FCM algorithm seeks to minimize anobjective function with respect to the membership functions and centroids of theclusters. As input, the FCM algorithm requires that number of clusters be speciﬁed.When the number of classes is not known a priori, the FCM algorithm is run usingdifferent numbers of clusters and the number of clusters is chosen based on an index, such as the fuzzy performance index (Roubens 1982), partition coefﬁcient,classiﬁcation entropy (Bezdek, Ehrlich, and Full 1984), or Xie-Beni validity index(Xie and Beni 1991), that provides the best results.FCM did not receive much attention for GIS applications until the publicationof the algorithm in Bezdek, Ehrlich, and Full (1984). Shortly after Bezdek, Ehrlich,and Full’s (1984) publication of FCM, Robinson and Thongs (1986) demonstratedhow it could be used to obtain a fuzzy classiﬁcation of land cover from Landsatdata. It was subsequently shown how the results of a fuzzy classiﬁcation of landcover could be represented in a geographical database using concepts from the fuzzydatabase ﬁeld (Robinson 1988). Since that early exploratory work, FCM has beenused in a variety of mapping problems. It has been used to develop classiﬁcationsof land cover in suburban areas (Fisher and Pathirana 1994, Zhang and Foody 1998).THO_C14  20/03/2007  15:07  Page 263 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f264VINCENT B. ROBINSONIn studies of vegetation FCM has been used to model vegetation using remote sensing data as input (Foody 1996). It has been combined with geostatistical tech-niques to model soil variability from hyperspectral remote sensing data as a meansof improving soils maps (Ahn, Baumgardner, and Biehl 1999). There has also beenan exploration of the utility of incorporating terrain and other data with vegetationor remote sensing data to improve on landscape characterizations (Burrough, vanGaans, and MacMillan 2000, 2001).Although FCM (FKM) ﬁgures prominently in their papers on new approachesfor physical geographers (Wilson and Burrough 1999, Scull, Franklin, Chadwick,and McArthur 2003), it is but one approach to fuzzy clustering, albeit the one mostcommonly found in GIS applications. There are now several methods for fuzzy clustering that might prove useful when applied to GIS-related problems. Forexample, Yao, Dash, Tan, and Liu (2000) have described an entropy-based fuzzy",
    "chunk_order_index": 163,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-147a474e474cd1c0090457443d1a3828": {
    "tokens": 1200,
    "content": "M) ﬁgures prominently in their papers on new approachesfor physical geographers (Wilson and Burrough 1999, Scull, Franklin, Chadwick,and McArthur 2003), it is but one approach to fuzzy clustering, albeit the one mostcommonly found in GIS applications. There are now several methods for fuzzy clustering that might prove useful when applied to GIS-related problems. Forexample, Yao, Dash, Tan, and Liu (2000) have described an entropy-based fuzzyclustering (EFC) algorithm that requires the speciﬁcation of fewer parameters. Oneof the limitations of FCM has been its reliance on the use of ratio/interval data.The development of a mixed-variable fuzzy c-means (MVFCM) algorithm seeks toaddress that shortcoming (Yang, Hwang, and Chen 2004). Like FCM, MVFCM iscapable of assigning membership values to each element.Spatial Interpolation and Fuzzy ClassiﬁcationWhen data are not present at every location in an area the technique of spatial inter-polation is often used to estimate what the attribute might be at a particular loca-tion based on the spatial distribution of attributes surrounding that particular locationgenerally using either a local or global approach. For example, the output fromFCM may provide fuzzy memberships for only some, not all, points (or cells) in aregion. In this case spatial interpolation techniques have been used to interpolatefuzzy membership functions for the remainder of the region (McBratney and deGruijter 1992; Brown 1998; Bragato 2004). Dragicevic and Marceau (2000) haveextended this idea of interpolation of membership values to the temporal dynamicsof spatial land use change.Walvoort and de Gruiijter (2001) consider the basis and additive log-ratio methodsin comparison with their compositional kriging approach to spatial interpolationof fuzzy membership values. Another approach to the use of kriging with fuzzydata has been to fuzzify the variogram with either the application of the extensionprinciple or with the use of fuzzy arithmetic (Bardossy, Bogardi, and Kelly 1989).In this fuzzy kriging formulation, the use of fuzzy data and a fuzzy variogram resultsin fuzzy numbers as estimates and fuzzy numbers as estimation variances for eachpoint.It has been suggested that a fuzzy membership function represents a form of inter-polation. Thus, in geographical applications the fuzzy membership function can beconsidered a spatial, temporal or spatio-temporal interpolator (Anile, Furno, Gallo,and Massolo 2003). In many of these approaches fuzzy set theory is an intrinsic partof the interpolation technique. For example, Gedeon, Wong, Wong, and Huang (2003)integrate fuzzy reasoning with techniques of local and Euclidean interpolation thatmakes for a computationally efﬁcient spatial interpolation technique resulting in aTHO_C14  20/03/2007  15:07  Page 264 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFUZZY CLASSIFICATION AND MAPPING265crisp number at a location. Thus, the goal is not to interpolate membership valuesbut to use fuzzy set theory to better interpolate attributes themselves as was doneusing cubic splines in Lodwick and Santos (2003).Building on their work using B-splines to construct fuzzy terrain models, Anile,Furno, Gallo, and Massolo (2003) report an algorithm for constructing inter-visibility maps from a fuzzy terrain model. They show how a fuzzy terrain modelthat can be coupled to a GIS is constructed using fuzzy numbers, intervals, and B-splines(Anile, Furno, Gallo, and Massolo 2000).Visualizing Fuzzy ClassiﬁcationsMaps depicting membership in a single class are easily visualized by grey, or pseudo-color, scales that are related to strength of membership. However, when there is morethan one class to which elements are mapped then each class is associated with aseparate map (Figure 14.1). The potentially large number of separate maps doesnot allow the user to visualize the membership maps as a whole. Visualization offuzziness and uncertainty is important as it allows users to explore it and investigateFig. 14.1A simple example of typical results from using the FCM algorithm to obtain fuzzyclassiﬁcation of land cover as a function of four bands from Landsat Thematic Mapper data. The crisp classiﬁcation map is based on allocating a cell to that class which has the highestmembership valueClass 1Class 2Class 2Class 3Class 11.000.500.00FuzzymembershipvalueClass 3Crisp ClassificationTHO_C14  20/03/2007  15:07  Page 265 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f266VINCENT B. ROBINSONthe effects of different decisions in the classiﬁcation (MacEachren and Kraak 1997).Typically, defuzziﬁcation of the fuzzy maps allocates a spatial element to a singleclass thus collapsing the number of maps from many to one (see crisp classiﬁcationin Figure",
    "chunk_order_index": 164,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0bc698fc7b38ab71f065e498dcec63c0": {
    "tokens": 1200,
    "content": "elibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f266VINCENT B. ROBINSONthe effects of different decisions in the classiﬁcation (MacEachren and Kraak 1997).Typically, defuzziﬁcation of the fuzzy maps allocates a spatial element to a singleclass thus collapsing the number of maps from many to one (see crisp classiﬁcationin Figure 14.1) where each spatial element is depicted as belonging to a single, crisp,class. The most common defuzziﬁcation method is to produce a color map whereeach spatial element is assigned to the class of which it has the highest membershipvalue. Clearly, this does not provide a means of visualizing the information containedin the underlying fuzzy classiﬁcation.Use of measures such as entropy, ignorance, and ignorance uncertainty (Zhu 1997)illustrate a strategy of visualizing the fuzzy information contained in multiple maps(as in Figure 14.1) by using a measure that collapsesmultiple maps into a singlemap. For example, the confusion index (CI), a ratio of the dominant and ﬁrst sub-dominant membership value for each spatial element, has been mapped to visualizewhich parts of a landscape are characterized by an abrupt, or gradual, spatial changein classes (Burrough, van Gaans, and Hootman 1997, 2001). The presentation of CIis often done in tandem with other visual information such as a map of the maximummembership values or class map (DeBruin and Stein 1998, Burrough, Wilson, vanGaans, and Hansen 2001, Bragato 2004).The problem of visualizing fuzzy classiﬁcations is generally subsumed within thelarger literature of visualizing uncertainty (fuzzy or otherwise). As such the prob-lems of visualizing uncertainty in general are applicable to fuzzy classiﬁcation. For instance, FCM would produce cmaps, one for each cluster. Thus, presentingthose maps simultaneously in a 2D space completely ﬁlls the 2D space, saturatingit and potentially providing more visual stimulus than a viewer can comprehend.Furthermore, it has been noted that to map onto the 2D space supplementary information relating to the uncertainty of that 2D view increases clutter and con-fuses viewers (MacEachren 1992, van der Wel, Van der Gaag, and Gorte 1998).A number of strategies have been suggested to address these problems.Visualizing with colorSince the early recognition that color could play an important role in visualizingfuzzy maps (Robinson 1988), the appropriate use of color has continued to beexplored (Hengl 2003). A color mixture with fuzzy-metric legend methodology has been proposed to more effectively portray the results of fuzzy classiﬁcation (Hengl, Walvoort, Brown, and Rossiter 2004). This method is related to earlier workon the pixel mixture(PM) technique developed for visualizing membership mapsby including all membership values in the representation. PM randomly assigns pixels to a sub-pixel grid with a probability proportional to the (normalized) mem-bership in the class. It is argued that this technique provides a visual impression of both the possible classes and their confusion (de Gruijter, Walvoort, and VanGaans 1997).Dynamic visualizationWith the development of computer graphics and related technology researchers beganto consider ways of taking advantage of the computational/graphical environmentTHO_C14  20/03/2007  15:07  Page 266 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFUZZY CLASSIFICATION AND MAPPING267in which GIS users now operate. Thus, one approach to exploiting the potential ofcomputer-controlled displays constructs dynamic displays which can toggle betweena primary view and a view containing more information about fuzziness, or uncer-tainty (Evans 1997, van der Wel, Van der Gaag, and Gorte 1998). Although paststudies have tended to focus on comparing a classiﬁed map with its associated memberships, this visualization technique has also been incorporated into a fuzzyGIS query system so that users could toggle between the continuous map of resultsand a discrete representation (Morris 2003).Animation has been used to portray uncertainty in GIS applications (Fisher 1993,Davis and Keller 1997, Bastin, Fisher, and Wood 2002). There are two major cat-egories of animation that have been reported: serial animation (Bastin, Fisher, andWood 2002) and the moving shutter method (Blenkinsop, Fisher, Bastin, and Wood2000). The pace at which the animation proceeds is one problem that has beennoted as well as choice of hue in color animations (Davis and Keller 1997).In random animation a population of possible land cover maps is produced basedon (normalized) fuzzy memberships derived for every pixel. When the images areshown in succession, color at any point will change so that the mixing of the landcovers and uncertainty is identiﬁable (Bastin, Fisher, and Wood 2002).An interesting adjunct to visualizing fuzzy classiﬁcations was suggested by Fisher(1994). He discussed the use of sound by relating tone and/or rhythm to the level ofuncertainty (fuzziness) associated with a particular location, or mapped",
    "chunk_order_index": 165,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-3ad18ae83b4f41a88155d9cf175904f2": {
    "tokens": 1200,
    "content": "derived for every pixel. When the images areshown in succession, color at any point will change so that the mixing of the landcovers and uncertainty is identiﬁable (Bastin, Fisher, and Wood 2002).An interesting adjunct to visualizing fuzzy classiﬁcations was suggested by Fisher(1994). He discussed the use of sound by relating tone and/or rhythm to the level ofuncertainty (fuzziness) associated with a particular location, or mapped unit. Althoughthe efﬁcacy of audio remains to be demonstrated, it is an intriguing elaboration of thevisualization problem to a multimedia environment.Typically these techniques do not allow for a user to interact with the classiﬁca-tion algorithm itself as part of the visualization process. This could potentially bea valuable tool, especially in the classiﬁcation of remotely sensed data. One pro-totypical method uses a feature space plot dynamically linked with an image displayand the classiﬁcation result to allow the user to adapt class clusters in the featurespace so as to change the parameters of a fuzzy classiﬁcation algorithm (Lucieerand Kraak 2004).Human subjects and visualization strategiesAlthough anecdotal evidence has been offered for the effectiveness of the togglestrategy (Morris 2003), human subject testing suggests it can be an effective strategy(Evans 1997). In one study that included expert and novice users of land coverclassiﬁcation information, it was found that both were highly successful at deter-mining classiﬁcation uncertainty among pixels when shown grey-scale images andhistograms (Blenkinsop, Fisher, Bastin, and Wood 2000). In addition, results suggestthat users can extract uncertainty information from random animations (Evans 1997,Blenkinsop, Fisher, Bastin, and Wood 2000).Issues of Cost and Fuzzy MappingResults of some applications of fuzzy methods in mapping and GIS indicate thatuse of these techniques can be cost-effective. Using the soil-land inference modelTHO_C14  20/03/2007  15:07  Page 267 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f268VINCENT B. ROBINSON(SoLIM) approach (Zhu 1997, Zhu, Hudson, Burt, Lubich, and Simonson 2001)it has been estimated that the accuracy of a map product is about 80 percent ascompared to 60 percent for traditional map products and is ﬁfteen times faster with the cost being about one-third of the conventional approach (Zhu 2004).MacMillan, Martin, Earle, and McNabb (2003) report dramatically lower mappingcosts when using a fuzzy-based methodology. Thus, it is clear that incorporatingfuzzy classiﬁcation in mapping methodologies holds promise of increasing accuracywhile reducing costs.Recent developments in mapping systems that integrate Global Positioning Systems(GPS), mobile computing, GIS, and one or more sensors to take physical measurements(Arvanitis, Ramachandran, Brackett, Abd-El Rasol, and Xu 2000) suggest that it isnow realistic to think in terms of spatial data collection agents that use fuzzy logicto adapt their spatial sampling strategy in real-time as they move along a transectnetwork. Simulation results of a prototypical system indicate that a fuzzy adaptivesampler may be able to reduce the cost of collecting ﬁeld data while simultaneouslyimproving overall data quality (Graniero and Robinson 2003).Even though many studies stress the utility of the additional information affordedby fuzzy classiﬁcation, it is also noted by many, often the same, researchers that a fuzzy classiﬁcation can be subject to serious limitations (Oberthur, Dobermann,and Aylward 2000, Jiang and Eastman 2000, Guneralp, Mendoza, Gertner, andAnderson 2003). Most often the problem arises from the large potential parameterspace that accompanies any fuzzy classiﬁcation methodology and the subjectivitythat may be inherent in the choice of parameters. Thus, it is advisable to take carein developing the model upon which a fuzzy classiﬁcation is based.CONCLUSIONSThis chapter has summarized the basic approaches to assigning a fuzzy membershipvalue to a location and then visualizing that classiﬁcation. Hopefully the extensiveset of references will allow the reader to pursue selected topics in more detail.There remain many areas for further development and reﬁnement of fuzzyclassiﬁcation in mapping. For example, using fuzzy classiﬁcation for assessing the accuracy of thematic maps is perhaps the ﬁrst stage in developing intelligentmap update, or change detection, systems. As applications of GIS become moreintelligent and/or embedded in other systems where automated decision making is important, fuzzy classiﬁcation (that is, fuzzy set theory) may provide a cost-effective set of tools to address these increasingly complex problems of mapping.Although much progress has been made in the last few decades, many challengesremain.ACKNOWLEDGEMENTSPartial support of a grant from the Natural Sciences and Engineering Research Council(NSERC) of Canada is gratefully acknowledged. The comments of Linda Robinsonand Phil Graniero improved the manuscript.THO_C14  20/03/2007  15:07  Page 268 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions",
    "chunk_order_index": 166,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-fc248749294bf0a0a11cd6bfb459f36a": {
    "tokens": 1200,
    "content": ".ACKNOWLEDGEMENTSPartial support of a grant from the Natural Sciences and Engineering Research Council(NSERC) of Canada is gratefully acknowledged. The comments of Linda Robinsonand Phil Graniero improved the manuscript.THO_C14  20/03/2007  15:07  Page 268 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFUZZY CLASSIFICATION AND MAPPING269REFERENCESAhn, C.-W., Baumgardner, M. F., and Biehl, L. L. 1999. Delineation of soil variability usinggeostatistics and fuzzy clustering analyses of hyperspectral data. Soil Science SocietyAmerica Journal63: 142–50.Anile, A. M., Falcidieno, B., Gallo, G., Spagnuolo, M., and Spinello, S. 2000. Modeling uncer-tain data with fuzzy B-splines. Fuzzy Sets and Systems113: 397–410.Anile, M. A., Furno, P., Gallo, G., and Massolo, A. 2003. A fuzzy approach to visibilitymaps creation over digital terrains. Fuzzy Sets and Systems135: 63–80.Arvanitis, L. G., Ramachandran, B., Brackett, D. P., Abd-El Rasol, H., and Xu, X. S. 2000.Multi-resource inventories incorporating GIS, GPS and database management systems: A conceptual model. Computers and Electronics in Agriculture28: 89–100.Bardossy, A., Bogardi, I., and Kelly, W. E. 1989. Geostatistics utilizing imprecise (fuzzy)information. Fuzzy Sets and Systems31: 311–28.Bastin, L., Fisher, P. F., and Wood, J. 2002. Visualizing uncertainty in multi-spectralremotely sensed imagery. Computers and Geosciences28: 337–50.Bezdek, J. C. 1981. Pattern Recognition with Fuzzy Objective Function Algorithms. NewYork: Plenum Press.Bezdek, J. C., Ehrlich, R., and Full, W. 1984. FCM: The fuzzy c-means clustering algorithm.Computers and Geosciences10: 191–203.Blenkinsop, S., Fisher, P. F., Bastin, L., and Wood, J. 2000. Evaluating the perception ofuncertainty in alternative visualisation strategies. Cartographica37: 1–14.Bragato, G. 2004. Fuzzy continuous classiﬁcation and spatial interpolation in conventionalsoil survey for soil mapping of the lower Piave plain. Geoderma118: 1–16.Brown, D. G. 1998. Classiﬁcation and boundary vagueness in mapping pre-settlement foresttypes. International Journal of Geographical Information Science12: 105–29.Burrough, P. A. and Frank, A. U. 1996. Geographic Objects with Indeterminate Boundaries.London: Taylor and Francis.Burrough, P. A. and McDonnell, R. A. 1998. Principles of Geographical Information Systems.New York: Oxford University Press.Burrough, P. A., van Gaans, P. F. M., and Hootsman, R. J. 1997. Continuous classiﬁcationin soil survey: Spatial correlation, confusion and boundaries. Geoderma77: 115–35.Burrough, P. A., van Gaans, P. F. M., and MacMillan, R. A. 2000. High resolution landformclassiﬁcation using fuzzy k-means. Fuzzy Sets and Systems113: 37–52.Burrough, P. A., Wilson, J. P., van Gaans, P. F. M., and Hansen, A. J. 2001. Fuzzy k-meansclassiﬁcation of topo-climatic data as an aid to forest mapping. Landscape Ecology16:523–46.Carpenter, G. A., Gjaja, M. N., Gopal, S., and Woodcock, C. E. 1997. ART neural networksfor remote sensing: Vegetation classiﬁcation from Landsat TM and terrain data. IEEETransactions on Geoscience and Remote Sensing35: 308–25.Charnpratheep, K., Zhou, Q., and Garner, B. 1997. Preliminary landﬁll site screening usingfuzzy geographical information systems. Waste Management and Research15: 197–215.Cheng, T., Molenaar, M., and Lin, H. 2002. Formalizing fuzzy objects from uncertainclassiﬁcation results. International Journal of Geographical Information Science15:27–42.Cobb, M. A., Chung, M. J., Foley, I. H., Petry, F. E., and Shaw, K. B. 1998. A rule-basedapproach for the conﬂation of attributed vector data. Geoinformatica2: 7–35.Davis, T. J. and Keller, C. P. 1997. Modelling and visualizing multiple spatial uncertainties.Computers and Geosciences23: 397–408.DeBruin, S. and Stein, A. 1998. Soil-landscape modelling using fuzzy c",
    "chunk_order_index": 167,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-127bf501a0e3e689d07894dbf01716a4": {
    "tokens": 1200,
    "content": "E., and Shaw, K. B. 1998. A rule-basedapproach for the conﬂation of attributed vector data. Geoinformatica2: 7–35.Davis, T. J. and Keller, C. P. 1997. Modelling and visualizing multiple spatial uncertainties.Computers and Geosciences23: 397–408.DeBruin, S. and Stein, A. 1998. Soil-landscape modelling using fuzzy c-means clustering ofattribute data derived from a digital elevation model (DEM). Geoderma83: 17–33.THO_C14  20/03/2007  15:07  Page 269 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f270VINCENT B. ROBINSONDeGenst, A., Canters, F., and Gulink, H. 2001. Uncertainty modeling in buffer operationsapplied to connectivity analysis. Transactions in GIS5: 305–26.de Gruijter, J. J., Walvoort, D. J. J., and Van Gaans, P. F. M. 1997. Continuous soil maps:A fuzzy set approach to bridge the gap between aggregation levels of process and distribu-tion models. Geoderma77: 169–95.Dragicevic, S. and Marceau, D. J. 2000. An application of fuzzy logic reasoning for GIStermporal modeling of dynamic processes. Fuzzy Sets and Systems113: 69–80.Dunn, J. C. 1973. A fuzzy relative of the ISODATA process and its use in detecting com-pact well-separated clusters. Journal of Cybernetics3: 32–57.Evans, B. J. 1997. Dynamic display of spatial data-reliability: Does it beneﬁt the map user?Computers and Geosciences23: 409–22.Fisher, P. F. 1993. Visualizing uncertainty in soil maps by animation. Cartographica30:20–7.Fisher, P. F. 1994. Animation and sound for the visualization of uncertain spatial information.In H. H. Hearnshaw and D. J. Unwin (eds) Visualization in Geographical InformationSystems. New York: John Wiley and Sons, pp. 181–5.Fisher, P. F. and Pathirana, S. 1994. The evaluation of fuzzy membership of land cover classesin the suburban zone. Remote Sensing of Environment34: 121–32.Foley, H., Petry, F., Cobb, M., and Shaw, K. 1997. Using semantic constraints for improvedconﬂation in spatial databases.In Proceedings of the Seventh International Fuzzy Sys-tems Association World Congress, Prague, Czech Republic. International Fuzzy SystemsAssociation, pp. 193–7.Foody, G. M. 1996. Fuzzy modelling of vegetation from remotely sensed imagery. EcologicalModelling85: 3–12.Foody, G. M. 1999. The continuum of classiﬁcation fuzziness in thematic mapping. Photo-grammetric Engineering and Remote Sensing65: 443–51.Foody, G. M. and Boyd, D. S. 1999. Fuzzy mapping of tropical land cover along an environ-mental gradient from remotely sensed data with an artiﬁcial neural network. Journal ofGeographical Systems1: 23–35.Gedeon, T. D., Wong, K. W., Wong, P., and Huang, Y. 2003. Spatial interpolation using fuzzyreasoning. Transactions in GIS7: 55–66.Goodchild, M. F. 2000. Introduction: Special issue on uncertainty in geographic informa-tion systems. Fuzzy Sets and Systems113: 3–5.Graniero, P. A. and Robinson, V. B. 2003. A real-time adaptive sampling method for ﬁeldmapping in patchy, heterogeneous environments. Transactions in GIS7: 31–54.Guneralp, B., Mendoza, G., Gertner, G., and Anderson, A. 2003. Spatial simulation and fuzzythreshold analyses for allocating restoration areas. Transactions in GIS7: 325–43.Hengl, T. 2003. Visualisation of uncertainty using the HSI colour model: Computations withcolours. In Proceedings of the Seventh International Conference on GeoComputation,Southampton, United Kingdom. Southampton: School of Geography, University ofSouthampton, pp. 8–17.Hengl, T., Walvoort, D. J. J., Brown, A., and Rossiter, D. G. 2004. A double continuousapproach to visualisation and analysis of categorical maps. International Journal ofGeographical Information Science18: 183–202.Huang, Y., Gedeon, T., and Wong, P. 1998. Spatial interpolation using fuzzy reasoning andgenetic algorithms. Journal of Geographic Information and Decision Analysis2: 223–33.Jang, J.-S. 1993. ANFIS: Adaptive-network-based fuzzy inference systems. IEEE Trans-actions on Systems, Man and Cybernetics23: 665–85.Jiang, H. and Eastman, J. R. 2000. Application of fuzzy measures in multi-criteria evaluationin GIS. International Journal of Geographical Information Science14:",
    "chunk_order_index": 168,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-3b404b01e2cfa805eff8c792ed9cec50": {
    "tokens": 1200,
    "content": "interpolation using fuzzy reasoning andgenetic algorithms. Journal of Geographic Information and Decision Analysis2: 223–33.Jang, J.-S. 1993. ANFIS: Adaptive-network-based fuzzy inference systems. IEEE Trans-actions on Systems, Man and Cybernetics23: 665–85.Jiang, H. and Eastman, J. R. 2000. Application of fuzzy measures in multi-criteria evaluationin GIS. International Journal of Geographical Information Science14: 173–84.THO_C14  20/03/2007  15:07  Page 270 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFUZZY CLASSIFICATION AND MAPPING271Klir, G. J. and Yuan, B. 1995. Fuzzy Sets and Fuzzy Logic: Theory and Applications. UpperSaddle River NJ: Prentice-Hall.Lodwick, W. A. and Santos, J. 2003. Constructing consistent fuzzy surfaces from fuzzy data.Fuzzy Sets and Systems135: 259–77.Lucieer, A. and Kraak, M. J. 2004. Interactive and visual fuzzy classiﬁcation of remotelysensed imagery for exploration of uncertainty. International Journal of GeographicalInformation Science18: 491–512.McBratney, A. B. and de Gruijter, J. J. 1992. A continuum approach to soil classiﬁcationby modiﬁed fuzzy k-means with extragrades. Journal of Soil Science43: 159–75.McBratney, A. B. and Odeh, I. O. A. 1997. Application of fuzzy sets in soil science: Fuzzylogic, fuzzy measurements and fuzzy decisions. Geoderma77: 85–113.MacEachren, A. M. 1992. Visualizing uncertain information. Cartographic Perspectives13:10–9.MacEachren, A. M. and Kraak, M. J. 1997. Exploratory cartographic visualization: Advancingthe agenda. Computers and Geosciences23: 335–44.Mackay, D. S., Samanta, S., Ahl, D. E., Ewers, B. E., Gower, S. T., and Burrows, S. N. 2003Automated parameterization of land surface process models using fuzzy logic. Transactionsin GIS7: 139–53.MacMillan, R. A., Pettapiece, W. W., Nolan, S. C., and Goddard, T. W. 2000. A genericprocedure for automatically segmenting landforms into landform elements using DEMs,heuristic rules, and fuzzy logic. Fuzzy Sets and Systems113: 81–109.MacMillan, R. A., Martin, T. C., Earle, T. J., and McNabb, D. H. 2003. Automated analysisand classiﬁcation of landforms using high-resolution digital elevation data: Applications andissues. Canadian Journal of Remote Sensing29: 592–606.Morris, A. 2003. A framework for modeling uncertainty in spatial databases. Transactionsin GIS7: 83–103.Oberthur, T., Dobermann, A., and Aylward, M. 2000. Using auxiliary information to adjustfuzzy membership functions for improved mapping of soil qualities. International Journalof Geographical Information Science14: 431–54.Power, C., Simms, A., and White, R. 2001. Hierarchical fuzzy pattern matching for the regionalcomparison of land use maps. International Journal of Geographical Information Science15: 77–100.Robinove, C. J. 1989. Principles of logic and the use of digital geographic information sys-tems. In W. J. Ripple (ed.) Fundamentals of GIS: A Compendium. Washington, DC: AmericanSociety for Photogrammetry and Remote Sensing: 61–79.Robinson, V. B. 1988. Some implications of fuzzy set theory applied to geographic databases.Computers, Environment, and Urban Systems12: 89–97.Robinson, V. B. 2000. Individual and multipersonal fuzzy spatial relations acquired usinghuman-machine interaction. Fuzzy Sets and Systems113: 133–45.Robinson, V. B. 2003. A perspective on the fundamentals of fuzzy sets and their use in geographic information systems. Transactions in GIS7: 3–30.Robinson, V. B. and Frank, A. U. 1985. About different kinds of uncertainty in collectionsof spatial data. In Proceedings of the Seventh International Symposium on AutomatedCartography (Auto Carto 7), Baltimore, MD, USA. Bethesda, MD: American Congresson Surveying and Mapping / American Society for Photogrammetry and Remote Sensing,pp. 440–50.Robinson, V. B. and Strahler, A. H. 1984. Issues in designing geographic information systemsunder conditions of inexactness.In Proceedings of the Tenth International Symposium onMachine Processing of Remotely Sensed Data, West Lafayette, IN, USA. New York: Instituteof Electrical and Electronics Engineers, pp. 179–88.THO_C14  20/03/2007  15:07  Page 271 Downloaded from https://onlinelibrary.wiley.com",
    "chunk_order_index": 169,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-98d99516d52d40fd0cb6114438b63e61": {
    "tokens": 1200,
    "content": "and Strahler, A. H. 1984. Issues in designing geographic information systemsunder conditions of inexactness.In Proceedings of the Tenth International Symposium onMachine Processing of Remotely Sensed Data, West Lafayette, IN, USA. New York: Instituteof Electrical and Electronics Engineers, pp. 179–88.THO_C14  20/03/2007  15:07  Page 271 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f272VINCENT B. ROBINSONRobinson, V. B. and Thongs, D. 1986. Fuzzy set theory applied to the mixed pixel problemof multispectral landcover databases. In B. K. Opitz (ed.) Geographic InformationSystems in Government.Hampton, VA: A. Deepak Publishing, pp. 871–85.Roubens, M. 1982. Fuzzy clustering algorithms and their cluster validity. European Journalof Operational Research10: 294–301.Scul, P., Franklin, J., Chadwick, O. A., and McArthur, D. 2003. Predictive soil mapping: A review. Progress in Physical Geography27: 171–97.Stefanakis, E., Vazirgiannis, M., and Sellis, T. 1999. Incorporating fuzzy set methodologiesin a DBMS repository for the application domain of GIS. International Journal ofGeographical Information Science13: 657–75.Teng, C. H. and Fairbairn, D. 2002. Comparing expert systems and neural fuzzy systemsfor object recognition in map data set revision. International Journal of Remote Sensing23: 555–67.van der Wel, F., Van der Gaag, L. C., and Gorte, B. G. H. 1998. Visual exploration ofuncertainty in remote-sensing classiﬁcation. Computers and Geosciences24: 335–43.Walvoort, D. J. J. and de Gruijter, J. J. 2001. Compositional kriging: A spatial interpolationmethod for compositional data. Mathematical Geology33: 951–66.Wang, F. and Hall, G. B. 1996. Fuzzy representation of geographical boundaries in GIS.International Journal of Geographical Information Science10: 573–90.Wilson, J. P. and Burrough, P. A. 1999. Dynamic modeling, geostatistics, and fuzzy classiﬁca-tion: New sneakers for a new geography? Annals of the Association of American Geographers89: 736–46.Xie, X. L. and Beni, G. 1991. A validity measure for fuzzy clustering. IEEE Transactionson Pattern Analysis and Machine Intelligence13: 841–7.Yang, M.-S., Hwang, P.-Y., and Chen, D.-H. 2004. Fuzzy clustering algorithms for mixedfeature variables. Fuzzy Sets and Systems141: 301–17.Yao, J., Dash, M., Tan, S. T., and Liu, H. 2000. Entropy-based clustering and fuzzy model-ing. Fuzzy Sets and Systems113: 381–8.Yen, J. 1999. Fuzzy logic: A modern perspective. IEEE Transactions on Knowledge and DataEngineering11: 153–65.Zadeh, L. A. 1965. Fuzzy sets. Information and Control8: 338–53.Zeng, T. Q. and Zhou, Q. 2001. Optimal spatial decision making using GIS: A prototypeof a real estate geographical information system (REGIS). International Journal ofGeographical Information Science15: 307–21.Zhang, J. and Foody, G. M. 1998. A fuzzy classiﬁcation of sub-urban land cover from remotelysensed imagery. International Journal of Remote Sensing19: 2721–38.Zheng, D. and Kainz, W. 1999. Fuzzy rule extraction from GIS data with a neural fuzzysystem for decision making. In Proceedings of the Seventh ACM International Symposiumon Advances in Geographic Information Systems, Kansas City, MS: 79–84.Zhu, A.-X. 1997. Measuring uncertainty in class assignment for natural resource maps underfuzzy logic. Photogrammetric Engineering and Remote Sensing: 1195–202.Zhu, A. X. 1999. A personal construct-based knowledge acquisition process for natural resourcemapping. International Journal of Geographical Information Science13: 119–41.Zhu, A. X., Hudson, B., Burt, J., Lubich, K., and Simonson, D. 2001. Soil mapping usingGIS, expert knowledge, and fuzzy logic. Soil Science Society of America Journal65: 1463–72.THO_C14  20/03/2007  15:07  Page 272 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 15Rule-Based MappingA-Xing ZhuRule-based mapping is a predictive approach to mapping. By predictive it is meant",
    "chunk_order_index": 170,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f750290c8e21f96d143422341e7ab21e": {
    "tokens": 1200,
    "content": "272 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 15Rule-Based MappingA-Xing ZhuRule-based mapping is a predictive approach to mapping. By predictive it is meantthat the status of the geographic entity to be mapped at a given point is inferredfrom the conditions of other variables which are related to or inﬂuence the existenceand status of the entity. Examples of rule-based mapping include the prediction ofthe spatial distribution of potential customers for a retail store using census dataand the identiﬁcation of habitat areas for a speciﬁc wildlife using a set of physicallandscape conditions. The set of variables used in the prediction are collectivelyreferred to as predictive variables. Data on the spatial variation of these predictivevariables are often easier to obtain than the status or condition of the entity to be mapped. Predictive mapping is based on the concept that there is a relationshipbetween the phenomenon to be mapped and a set of predictive variables as expressedin the following equation:Sij=fij(Eij)(15.1)where Sijis the status or property value of a geographic entity at location (i,j), Eijis a set of predictive conditions (E1ij, E2ij,..., Evij,..., Eijm) at the location, and fijisa set of relationships (f1ij, f2ij,..., fvij,..., fijm) between the entity and the set of pre-dictive conditions for that location and is often expressed in the form of rules. Oftenwe assume that fijis stationary over a small area or over areas where geographicprocesses are similar across locations. Under this assumption, Equation (15.1) canbe simpliﬁed toSij=f(Eij)(15.2)Information on the spatial variation of Eis often derived using GeographicInformation System (GIS)/remote sensing techniques. The development of GI Scienceand technology has made the acquisition and compilation of predictive conditions(E) over large areas not only possible but also easier. Thus, rule-based mapping isnow very easy to implement in a GIS setting. In fact, many of the GIS applications,THO_C15  19/03/2007  11:13  Page 273 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f274A-XING ZHUparticularly those related to suitability analysis, are in the form of rule-based mapping(see Scott, Davis, Cusuti, et al. [1993] for rule-based mapping in Gap Analysis Program[GAP] analysis and Zhu, Hudson, Burt, Lubich, and Simonson [2001] in soil survey).The generation of rules is one of the most important parts of rule-based mapping.In a broad sense rule-based mapping can be classiﬁed into three major categoriesbased on the form and level of sophistication of the rules: physical process-based,knowledge-based, and statistical. The physical process-based approaches repres-ent rules as physical and mechanistic processes governed by a set of mechanisticequations and parameters. Process-based modeling (such as climate, ecosystem, andhydrological modeling) belongs to this category. For example, the Penman-Monteithcombination equation (Monteith 1965) is often used to model (predict) the tran-spiration of a forest canopy. This equation expresses the relationships between dailycanopy transpiration and a set of variables (parameters) describing the environ-mental conditions (such as vapor pressure and temperature) and tree physiology(such as stomatal conductance and leaf area index) (Ehleringer and Field 1993, Waringand Running 1998). Examples of urban and planning applications can be found inSimpson (2001). The deterministic nature of these equations requires us to have athorough understanding of these processes and the role that each parameter playsin the respective processes so that these processes can be reasonably quantiﬁed usingmathematical equations.The statistical approaches, to the contrary, assume little prior knowledge of therelationships between the phenomenon to be mapped (dependent variable) and the predictive (independent) variables. Rather, this type of approach often ﬁrst ex-tracts the relationships (rules) between dependent variable and predictive variablesfrom sample locations and then predicts (maps) the value of the dependent vari-able at unvisited sites using the extracted relationships (rules). Examples of theseapproaches include linear regression models (Hastie, Tibshirani, and Friedman 2001)and generalized linear models (Hastie and Pregibon 1992). Statistical clustering can also be considered as rule-based because it ﬁrst develops class signatures (a setof rules in the attribute domain) and then classiﬁes individual locations based onthe established class signatures (Lillesand, Kiefer, and Chipman 2004). Statisticalsimulation techniques (that is, cellular automata; Couclelis 1997, Batty 1998), agent-based modeling (O’Sullivan and Haklay 2000), and spatial analytical techniques(Goodchild and Haining 2004) can be considered in this group as well.Knowledge-based approaches to rule-based mapping sit between the above twoextremes in terms of the required level of understanding about geographic systems.Often, we understand geographic systems at some level that",
    "chunk_order_index": 171,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9f1d493fed5d59d94767455f5c4d2fd4": {
    "tokens": 1200,
    "content": "). Statisticalsimulation techniques (that is, cellular automata; Couclelis 1997, Batty 1998), agent-based modeling (O’Sullivan and Haklay 2000), and spatial analytical techniques(Goodchild and Haining 2004) can be considered in this group as well.Knowledge-based approaches to rule-based mapping sit between the above twoextremes in terms of the required level of understanding about geographic systems.Often, we understand geographic systems at some level that is not sufﬁcient forprescribing physical processes using a set of deterministic equations but that is more than enough to make the statistical approaches not worthwhile. In these circumstances, knowledge-based approaches to rule-based mapping are very usefulin exploiting this type of human expertise and in providing accurate mapping ofgeographic phenomena.This chapter focuses on rule-based mapping from a knowledge-based perspective,particularly in terms of making use of the qualitative knowledge of human experts.The other two types of mapping approaches (that is, the physical process-based andstatistical approaches) are not discussed further because they are extensively discussedin the existing literature.THO_C15  19/03/2007  11:13  Page 274 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fRULE-BASED MAPPING275Under a GIS framework and with a knowledge-based approach to rule-based map-ping, Equation (15.2) can be perceived to be that shown in Figure 15.1. The requiredenvironmental conditions can be characterized using GIS/RS techniques (Zhu, Band,Dutton, and Nimlos 1996, Wilson and Gallant 2000). The relationship between thefeature to be mapped and the related environmental conditions is approximated withdescriptive knowledge of human experts (Zhu 1999). The descriptive knowledgeand the characterized environmental conditions are then combined to predict thespatial distribution of the phenomenon through a set of inference techniques suchas spatial overlay and raster map algebra.The unique aspect of this knowledge-based approach is that the relationship is nowexpressed as descriptive knowledge in the form of rules, rather than mechanistic equa-tions or statistical relations. Figure 15.2 shows, as an example, the descriptive know-ledge used to map a soil series, Basco, over Pleasant Valley in Wisconsin, USA (thisexample will be used throughout this chapter to illustrate the implementation of rule-based mapping under GIS; readers can replace soil series with number of potentialcustomers or habitat of particular wildlife). The generation, encoding of descriptiveS   =    f  ( E )Descriptive knowledgeas rulesRelationship between the featureand environmental conditionsEnvironmental conditionsG.I.S./R.S.GIS, Artificial Intelligence-BasedGeocomputing TechniquesSpatial DistributionSuch as soil types,landslide susceptibilityf: (f1, f2, . . . fv, . . ., fm)m: number of environmental variablesInferenceFig. 15.2Example of descriptive knowledge expressed as a rule for rule-based mappingSoil Series at a location will be “Basco” if at that location Geology is “Jordan Sandstone” and Slope gradient is “<20%” and Elevation is “>950 ft” and Profile curvature is “linear to convex”Fig. 15.1Knowledge-based approach to rule-based mapping under GISTHO_C15  19/03/2007  11:13  Page 275 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f276A-XING ZHUknowledge, and inference using descriptive knowledge are the key issues in rule-basedmapping. The following sections will address each of these issues respectively.Obtaining RulesThere are three major sources from which rules can be derived: existing documents,human experts, and spatial data. The following subsections describe each of thesethree sources.Extracting rules from existing documentsExisting documents often contain information about relationships between phenom-ena or regulations about certain geographic activities. For examples, an insurancecompany may have documentation about how social and economic conditions of family are related to the likelihood of property insurance purchase. The ecology of an endangered species can provide us the rules needed to map the spatial distri-bution of its habitats. For another example, legal documents or governmental policystate that new developments cannot be within 20 m of streams. Rules can be easilydeﬁned using this type of information.Extracting rules from human expertsKnowledge acquisition from human experts has been a subject of study in the arti-ﬁcial intelligence community, a sub-discipline of computer science, for decades (forexample, Hart 1986, Boose and Gaines 1988, Fensel and Studer 1999, Liao 2005).There are often two parties involved in human knowledge acquisition: the domainexpert whose knowledge is to be elicited and the knowledge engineer who performsthe knowledge elicitation. There are two main strategies in acquiring knowledgefrom human experts: interviewing and observing. The interview techniques take aquestioning approach by asking the domain expert direct questions to elicit knowledge.Interview techniques are of two types: structured and unstructured. Structured inter-views organize the questions to be asked. These questions are interrelated and arepresented in a particular order during the interview process. During an unstructuredinterview questions being asked are not organized in any",
    "chunk_order_index": 172,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4c3bc46a72dc9cbb9134017811cae778": {
    "tokens": 1200,
    "content": "engineer who performsthe knowledge elicitation. There are two main strategies in acquiring knowledgefrom human experts: interviewing and observing. The interview techniques take aquestioning approach by asking the domain expert direct questions to elicit knowledge.Interview techniques are of two types: structured and unstructured. Structured inter-views organize the questions to be asked. These questions are interrelated and arepresented in a particular order during the interview process. During an unstructuredinterview questions being asked are not organized in any way. An unstructured inter-view is often used for initial information gathering while the structured interviewis much more suited for extracting the speciﬁc rules.The observing techniques elicit knowledge by studying the domain experts whilethey are in the problem solving process. There are two main groups: prototype analysis and ethnographic methods. The former requires experts to think aloud andreport what they do when solving a prototype problem but they do not need tojustify their actions. Prototype analysis techniques lead to a verbal protocol whichthe knowledge engineer can use to build a model of problem solving. The latterfocuses on the actions of a domain expert by observing the behaviors of the domainexpert in the workplace. This requires the knowledge engineer to be at the locationwhere the domain expert solves actual problems. The observing techniques are moresuited for knowledge related to operational or analytical procedures.THO_C15  19/03/2007  11:13  Page 276 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fRULE-BASED MAPPING277Knowledge on geographic relationships is often not well formulated. As a result, itis often very challenging to formally extract rules on spatial distribution of geographicphenomenon/features. Many of these knowledge acquisition techniques developedin the artiﬁcial intelligence community need to be revised when they are applied ingeography. In fact, there exist few knowledge extraction techniques speciﬁcallydesigned to elicit knowledge on relationships between geographic phenomena/features(Zhu 1999, Yamada, Elith, McCarthy, and Zerger 2003).Extracting rules from existing spatial dataDescriptive knowledge can also be derived from existing data (such as previouslyobtained ﬁeld observations and/or existing maps). The explosive growth in geo-spatial data since the late 1980s, as a result of the advent of remote sensing andother geospatial data collection technologies, has also made it viable to extract descriptive knowledge by linking ﬁeld observation data or existing maps with theseremotely sensed data and other geospatial data derived from GIS technology. Thisemerging ﬁeld is referred to as the geospatial data mining and knowledge discovery(Miller and Han 2001, Buttenﬁeld, Gahegan, Miller, and Yuan 2002). Qi and Zhu(2003) provided a detailed example on how to use geospatial data mining tech-niques to extract knowledge on soil-landscape relationships embedded in existingsoil maps. See Miller in Chapter 19 of this volume, for a more detailed treatmentof this topic.Encoding Rules in Rule-Based MappingRules as descriptive knowledge cannot be used directly in GIS-based mapping.Descriptive rules need to be encoded into a numeric form so that they can be applied in a computer environment. In other words, the question of how to usethese descriptive rules to approximate f in Figure 15.1 needs to be addressed. A rule typically consists of several components with each component describing therequired condition for a given predictive variable. For example, the rule shown inFigure 15.2 consists of four components: geology, slope gradient, proﬁle curvature,and plan curvature. The implementation of a descriptive rule needs to address thefollowing two issues: the encoding of each component into a function form (the fvin Figure 15.1) and the interaction of these components during inference (the “=” in Figure 15.1). The inference is a process of determining the values from func-tions (components of a rule) for a given location and then integrating these values toderive the ﬁnal value on the status of the mapped entity. The implementation of descrip-tive rules is discussed below under two logic frameworks (Boolean and fuzzy logic).Rule-based mapping under Boolean logicBoolean encoding of rule componentsUnder Boolean logic each component of a descriptive rule is encoded as a step func-tion. The function produces a value of 1 (or true) if the stated condition in theTHO_C15  19/03/2007  11:13  Page 277 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f278A-XING ZHUcomponent is met, 0 (false) otherwise. For a component describing a nominal/categorical variable, even for an ordinal variable, the step function is easy to deﬁne.For example, the step function for the component on geology in the rule shown inFigure 15.2 can be expressed asG(G) =1 if G =“Jordan Sandstone”(15.3a)G(G) =0 otherwise(15.3b)For interval and ratio variables, a numeric range or threshold needs to be estab-lished in order to deﬁne the step function. With some rules or components of a rule,the range or threshold is embedded in the descriptive term of the knowledge whileothers may just contain a linguistic term without",
    "chunk_order_index": 173,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7f9ea4464b8c6263d27dcf3e33806993": {
    "tokens": 1200,
    "content": "the rule shown inFigure 15.2 can be expressed asG(G) =1 if G =“Jordan Sandstone”(15.3a)G(G) =0 otherwise(15.3b)For interval and ratio variables, a numeric range or threshold needs to be estab-lished in order to deﬁne the step function. With some rules or components of a rule,the range or threshold is embedded in the descriptive term of the knowledge whileothers may just contain a linguistic term without any indication of what the rangeor threshold is. An example of the former is the slope gradient component and anexample of the latter is the proﬁle curvature component. For the former, the stepfunction can be expressed as:fslope(slope) =1 if slope < 20%(15.4a)fslope(slope) =0 otherwise(15.4b)For the components which contain only linguistic values (such as the proﬁle com-ponent in Figure 15.2) the numeric meaning (such as range or threshold) of theselinguistic values needs to be deﬁned before the step function can be formulated.The numeric meaning of the linguistic values can be deﬁned during the initial know-ledge acquisition process or through a secondary knowledge acquisition processspeciﬁcally designed for this purpose. An example of the former is the preparationinterview in the iterative knowledge acquisition process developed by (Zhu 1999).Liu (2004) developed a knowledge acquisition process speciﬁc for obtaining the numeric meaning of geographic linguistic values (terms) (such as “convex,” “linear,” and “concave”). During the process the domain expert was presented witha set of landscapes using a three dimensional visualization tool (3dMapper, seehttp://TerrainAnalytics.com/for additional details) and asked to delineate areas wherethe expert thinks the deﬁnition of the linguistic terms (such as “convex surface” or“linear surface” or “concave surface”) are well met. The delineated areas are thenanalyzed together with the data layer of the variable (such as proﬁle curvature) fordetermining the numeric meaning of the term in the domain of the variable. Oncenumeric meanings are obtained, the step function for each of these linguistic termscan be deﬁned in the same way as the components with known ranges or thresholds.Boolean integration of rule componentsUnder Boolean logic the values from the step functions are binary (0 or 1) and theintegration of these values are often illustrated via a truth table (see below). The integration of these values depends on the logic operator joining these com-ponents in formulating the rule. There are two basic logic operators that can beused to join the components depending on the nature of a rule: the logic AND andthe logic OR. Logic AND is used when all components of a rule need to be satisﬁedTHO_C15  19/03/2007  11:13  Page 278 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fRULE-BASED MAPPING279before the entire rule is met. Integration of components using logic AND is oftenaccomplished using the minimum operator. As its name indicates, the ﬁnal valueof the rule is the minimum of the values from the components. A truth table forintegrating the values from the components of the rule in Figure 15.2 is shown inTable 15.1. For simplicity, only the ﬁrst two components are used in this table.To produce a map of Basco the inference process will evaluate the conditions atevery pixel and determine the ﬁnal value using the integration process as illustratedhere across the landscape. Figure 15.3 shows the predicted distribution of Bascobased on the rule shown in Figure 15.2. One unique aspect of the prediction pro-duced under Boolean logic is that it is binary (1 or 0). In this case, it is either Bascoor not. There is no between.Logic OR is used when a rule is met when only some of its components are true.For example, in landslide susceptibility mapping several combinations of condi-tions can cause landslides to occur but each of these combinations impact landslideoccurrences independently (Zhu, Wang, Qiao, et al. 2004). When assessing land-slide susceptibility these combinations should be considered separately and landslidesusceptibility should be considered high when any of these combinations of condi-tions exists. Thus, the OR operator should be used to integrate these combinations.Integration under Logic OR is often accomplished using the maximum operator, thatis, the ﬁnal value is the maximum of the values from the components of the rule.Table 15.2 shows the truth table for integrating the components of the followingrule: “Landslides are most likely to occur when the Geology is ‘Shale’ or when theslope is steep (exceeding 50 percent)”.Common sense also tells us that Location 4 in Table 15.2 is most susceptiblebecause each condition can cause landslides independently. However, the OR imple-mentation of the rule does not reﬂect this situation. In addition to this problem, theBoolean encoding of components is often inappropriate or too rigid. For example,the step function used in encoding the impact of slope gradient on landslide sus-ceptibility does not consider the difference in impact between a location with slopeof 55 percent and a location with slope of 90 percent. Clearly the latter locationis more susceptible to landslide than the former.Table",
    "chunk_order_index": 174,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-c9f17e037d0fbc15d7230e9688a7f479": {
    "tokens": 1200,
    "content": "ides independently. However, the OR imple-mentation of the rule does not reﬂect this situation. In addition to this problem, theBoolean encoding of components is often inappropriate or too rigid. For example,the step function used in encoding the impact of slope gradient on landslide sus-ceptibility does not consider the difference in impact between a location with slopeof 55 percent and a location with slope of 90 percent. Clearly the latter locationis more susceptible to landslide than the former.Table 15.1The truth table for mapping Soil Series “Basco” by integrating the Geologycomponent with the Slope component using logic AND under Boolean logicLocationConditionsGeology ComponentSlope ComponentFinal(=“Jordan”)(Slope <20%)Value1Geology = Oneota,000Slope =25%2Geology =Jordan, 100Slope =25%3Geology = Oneota, 010Slope =18%4Geology = Jordan, 111Slope =18%THO_C15  19/03/2007  11:13  Page 279 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f280A-XING ZHUTable 15.2The truth table for mapping landslide susceptibility by integrating the Geologycomponent with the Slope component using logic OR under Boolean logicLocationConditionsGeology ComponentSlope ComponentFinal(=“Shale”)(Slope >50%)Value1Geology =Oneota, 000Slope =30%2Geology = Shale, 101Slope =30%3Geology =Oneota, 011Slope =60%4Geology =Shale, 111Slope =60%Fig. 15.3A distribution of Soil Series Basco in Pleasant Valley, Wisconsin, USA based on a Booleanintegration of the rule in Figure 15.2. White indicates areas of Basco soil (the thin lines are contours)and black areas are non-Basco soilsTHO_C15  19/03/2007  11:13  Page 280 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fRULE-BASED MAPPING281Rule-based mapping under fuzzy logicFuzzy encoding of rule componentsFuzzy logic allows the encoding of components to reﬂect the degree of suitability.In other words, under fuzzy logic the level at which a component is satisﬁed can beexpressed. The level is often referred to as membership value(grade) ranging from0 to 1, with 0 meaning no membership (not satisfying the component of a rule atall) and 1 meaning full membership (fully satisfying the component). The functionused to express (encode) the level of satisfaction is referred to as membership function(see Zimmermann [1985] for details on fuzzy logic; Zhu (1997a, 2005)for application of fuzzy logic in rule-based soil mapping). For rule-based mappingthe membership function for each component is deﬁned using what is referred toas the Semantic Import Model (SI) (see Burrough 1996, McBratney and Odeh 1997,Robinson 2003 for details), which means that the deﬁnition of a membership func-tion is based on the knowledge or experience of one or more domain specialists.Fuzzy membership functions for categorical/nominal variables are the same as thatunder Boolean logic. For ordinal variables membership functions can take a functionwith “multiple steps” with each ordinal value corresponding to one membershipgrade. The association of a membership grade to a given ordinal value depends onthe preference assigned to the speciﬁc ordinal value. The more preferred the value thehigher the membership grade.The deﬁnition of fuzzy membership functions for interval and ratio variable types typically requires three critical pieces of information: the form of the member-ship curve, the optimal value, and crossover point(s) (Figure 15.4). There are threebasic forms of membership curves which are often used in fuzzy mathematics (Figure 15.5): the bell-, Z-, and S-shaped. The bell-shaped curve describes that there10.5000.511.52MembershipCentral concept (optimal)Value of bLower crossover pointUpper crossover pointWidth (d)Width (d)Predictive VariableFig. 15.4The metrics of a fuzzy membership functionTHO_C15  19/03/2007  11:13  Page 281 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f282A-XING ZHUis an optimal attribute value or range over which membership is at unity (1.0) andas the attribute of the predictive variable deviates from this value or moves awayfrom this range the membership value decreases. For example, a slope componentstating “slope from 6 to 12 percent” can be captured using this membership function.The Z-shaped curve describes the scenario that there is a threshold value for thepredictive variable, smaller than which the membership is",
    "chunk_order_index": 175,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4b54c7019921c5d4942f2e3834b2d407": {
    "tokens": 1200,
    "content": "282A-XING ZHUis an optimal attribute value or range over which membership is at unity (1.0) andas the attribute of the predictive variable deviates from this value or moves awayfrom this range the membership value decreases. For example, a slope componentstating “slope from 6 to 12 percent” can be captured using this membership function.The Z-shaped curve describes the scenario that there is a threshold value for thepredictive variable, smaller than which the membership is at unity (1.0) and greaterthan which the membership decreases. “Slope less than 20 percent” in the rule shownin Figure 15.2 can be expressed using this function (the gentler the slope the moresuitable for Basco to develop given that other conditions permit). The S-shaped curvesdeﬁne the relationships opposite to that characterized by the Z-shaped curves. Asindicated through this discussion, the form of the membership curve can be deter-mined by the information provided in the component of a given rule.Crossover points are values of predictive variables at which the membership valueis 0.5 (Figure 15.4). For components with numeric limits speciﬁed, the crossoverpoint(s) can be set to these limits. For example, the crossover points of a member-ship function for a slope component stating “slope from 6 to 12 percent” can be setto 6 percent (for lower crossover point) and 12 percent (for the upper crossover point).For the one-sided curves (the S- and Z-shaped curves) the respective crossover pointscan be set to the “greater than” value and the “less than” value, respectively.The optimal value is the value (range) of the predictive variable at (over) which themembership value is at unity (1.0). For the bell-shaped membership function, the optimal value can be a single point or can be a range. For one-sided curves theoptimal value is a point from which the membership decreases (Z-shaped) from orBell Shaped1.0MembershipPredictive Variable(a)Z-ShapedS-Shaped01.0MembershipPredictive Variable(c)01.0MembershipPredictive Variable(b)0Fig. 15.5Three basic forms of membership functions: (a) bell-shaped; (b) Z-shaped; (c) S-shapedTHO_C15  19/03/2007  11:13  Page 282 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fRULE-BASED MAPPING283increases (S-shaped) to unity (1.0) as the attribute value increases. Determining theoptimal value (range) is more difﬁcult than determining the crossover pointsbecause the descriptive components in a rule may not contain this information. Thus,this information often has to be obtained through knowledge acquisition. For com-ponents with numeric limits speciﬁed the optimal values (range) can be obtainedfrom domain experts using the approach developed by Zhu (1999).For components with linguistic terms as values (such as curvature variables with“convex,” “linear,” “concave” terms) the determination of optimal and crossoverpoints is difﬁcult. Researchers have explored the use of geovisualization techniquesand frequency analysis techniques to deﬁne these values (see Robinson (2000) andLiu (2004) for additional details on these techniques).Once the form of the curve and the optimal and crossover points are deter-mined the membership function can be formulated quite easily. There are manymathematical functions that can be used in this respect (see Robinson (2003) foradditional details). Burrough (1989) use the following function to depict a sym-metrical bell-shaped membership function:(15.5)where xis the value of a predictive variable, bis the attribute value representing thecentral concept (optimal value), and dis the width of the bell-shaped curve betweenone of the cross-over points and b(Figure 15.4). The S-shaped curve can be createdby setting the membership value to 1 for x greater than bwhile the Z-shaped curvecan be created by setting the membership value to 1 for xless than b. Equation(15.5) can also be modiﬁed to model a membership function that has a range overwhich the membership value is at unity (Shi, Zhu, Burt, and Simonson 2004).Fuzzy integration of rule componentsAs we can see from the above-mentioned discussion on fuzzy encoding of rule components, for a given location (i,j) each membership function will produce a fuzzy membership value for its respective component. The integration of these fuzzymembership values produces a fuzzy membership value describing how much therule is satisﬁed at this location. The operator used to integrate the component valuesunder fuzzy logic is problem speciﬁc. There are a number of operators that can beused to accomplish the integration: the common ones are the logic AND and thelogic OR depending on the nature of joining these components in formulating the rule. There are a number of implementations for each of these two operators.The commonly used implementation of logic AND is what is termed the fuzzy minimum operator. The theoretical basis of the fuzzy minimum operator is the limiting-factor principle in ecology, which states that the formation or developmentof an ecological feature, such as vegetation or soil, is controlled or limited by theleast favorable factor in its environment. The integration under the fuzzy minimumoperator can be expressed as follows:(15.6)  SfEijvmvijv,, min[()] ==1",
    "chunk_order_index": 176,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-eac07ffc9077ad4d6adf0bfe04306b28": {
    "tokens": 1200,
    "content": "each of these two operators.The commonly used implementation of logic AND is what is termed the fuzzy minimum operator. The theoretical basis of the fuzzy minimum operator is the limiting-factor principle in ecology, which states that the formation or developmentof an ecological feature, such as vegetation or soil, is controlled or limited by theleast favorable factor in its environment. The integration under the fuzzy minimumoperator can be expressed as follows:(15.6)  SfEijvmvijv,, min[()] ==1  µfuzzyxxbd() =+−⎛⎝⎜⎞⎠⎟     112THO_C15  19/03/2007  11:13  Page 283 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f284A-XING ZHUwhere Si,jis the outcome of the rule at location (i,j) and mis the number of com-ponents in the rule. Table 15.3 shows the fuzzy equivalent of Table 15.1 given thata Z-shaped curve (Equation 15.7) based on Equation (15.5) is used to encode theslope component (with b= 15% and crossover point at 20%, d=20% −15%):for x>15%(15.7)µslope(x) =1otherwiseThe clear cut situation expressed in Table 15.1 no longer exists in Table 15.3.Location 2 now bears some similarity to soil series Basco. It is very possible that theslope condition at Location 2 is not steep enough to preclude the soil from bear-ing high similarity to Basco. At Location 4 the slope condition is in the transitionzone (15~20%) and we expect the soil to bear high similarity to Basco but may notﬁt the typical (central) concept of Basco exactly. This situation is reﬂected in itsmembership value being close to 1 but not 1. If Basco were the soil type which issuitable for a septic tank location, users would be able to gain a better appreci-ation of how suitable a particular location is for septic tanks with these small butimportant differentiations provided under fuzzy logic.The predicted distribution of Basco over the Pleasant Valley of Wisconsin basedon the fuzzy implementation of the rule in Figure 15.2 is shown in Figure 15.6.The difference between Figures 15.4 and 15.6 is that in the latter the predicted distribution of Basco is portrayed as memberships ranging from 1 (white area, for fully meeting the condition of the rule) to 0 (the black area, for not meetingthe condition of the rule at all). Basco is a soil that occurs on ridgetops and as onemoves away from ridges down the slope the typicality of Basco decreases which iscaptured by this fuzzy soil map.The commonly used implementation of logic OR is the fuzzy maximum operatorand can be expressed as:(15.8)  SfEijvmvijv,, max[()] ==1  µslopexx()      =+−⎛⎝⎜⎞⎠⎟111552Table 15.3The membership values for Soil Series “Basco” by integrating the Geologycomponent with the Slope component using the AND operator under fuzzy logicLocationConditionsGeology ComponentSlope ComponentFinal(=“Jordan”)(Slope <20%)Value1Geology = Oneota, 00.20Slope =25%2Geology = Jordan, 10.20.2Slope =25%3Geology = Oneota, 00.740Slope =18%4Geology = Jordan, 10.740.74Slope =18%THO_C15  19/03/2007  11:13  Page 284 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fRULE-BASED MAPPING285Given that Equation (15.9) is used to encode the slope component in the landslidesusceptibility example, after applying Equation (15.7) to the membership values from the components of the rule, we have the outcome from the rule as shown inTable 15.4.for x<70%(15.9)µslope(x) =1otherwiseBoolean versus fuzzyMuch of the difference between Boolean and fuzzy logic for rule-based mapping isrelated to how the rule components are encoded. When the minimum and maximumoperators are used for logic AND and logic OR, respectively, the integration ofvalues from components are the same for both Boolean and fuzzy logic. However,  µslopexx()      =+−⎛⎝⎜⎞⎠⎟1170202Fig. 15.6The predicted distribution of Soil Series Basco in Pleasant Valley, Wisconsin, USA basedon a fuzzy implementation of the rule in Figure 15.2. The lighter the grades the more typical ofBasco (thin lines are contours)THO_C15  19/03/2007  11:14  Page 285 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library",
    "chunk_order_index": 177,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4476dbc2e8e57582aa2ef2b11f3c1c03": {
    "tokens": 1200,
    "content": "1170202Fig. 15.6The predicted distribution of Soil Series Basco in Pleasant Valley, Wisconsin, USA basedon a fuzzy implementation of the rule in Figure 15.2. The lighter the grades the more typical ofBasco (thin lines are contours)THO_C15  19/03/2007  11:14  Page 285 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f286A-XING ZHUthe difference in the values from rule components under different logic frame-works drives the difference in ﬁnal results. Under Boolean logic the outcome froma rule is always either 1 (true) or 0 (false). However, the outcome from a rule implemented under fuzzy logic has a value between 0 and 1 (inclusive), althoughunder some circumstances the upper bound can be greater than 1. This ﬂexibilityof fuzzy logic in encoding and integrating the rule components greatly enhances ourability to capture and map the spatial gradation a of geographic entity (Zhu 1997a)(cf. Figures 15.3 and 15.6).The ﬂexibility under fuzzy logic also allows rule-based mapping to be more com-plete spatially and more informative than under Boolean logic. Figure 15.7 showsthe soil map of Pleasant Valley in Wisconsin based on Boolean logic using the rulesshown in Figure 15.8. The rigidity of the Boolean implementation means that theconditions at some of the locations in the area do not meet any of the rules speciﬁedfor the soil series in the area. As a result these areas are not mapped as any of thesoil types. Typically these missed locations are in the transitional areas between soiltypes. This means that under the Boolean implementation the soils in transitionalareas are completely missed out. On the contrary, fuzzy implementation retains the level of satisfaction of each rule and this level of satisfaction can be used tomap the areas where local conditions do not fully meet the conditions of the rules.Figure 15.9 shows the soil map of the same area using the same set of rules butunder fuzzy logic. The soil map in Figure 15.9 is produced by hardening the fuzzysoil membership maps produced for soil types using the respective rules. Hardeningis a process of assigning a pixel (location) to a soil type in which the location hasthe highest membership value (Zhu and Band 1994). The transitional areas are now mapped. More importantly, the hardening process also produces uncertaintyinformation associated with assigning a pixel to a soil class to which the soil at thepixel does not fully belong (Zhu 1997b). Figure 15.10 shows the uncertainty mapassociated with the soil map in Figure 15.9. The level of whitening in a color fora location indicates the level of uncertainty in assigning the local soil to the givenclass (represented by the color). It is clearly shown that the locations of whiteningin colors are in the transitional areas which are the missed areas in Figure 15.7.Table 15.4The membership values for landslide susceptibility by integrating the Geologycomponent with the Slope component using the maximum operator under fuzzy logicLocationConditionsGeology ComponentSlope ComponentFinal(=“Shale”)(Slope >50%)Value1Geology = Oneota, 00.20.2Slope =30%2Geology = Shale, 10.21Slope =30%3Geology = Oneota, 00.80.8Slope =60%4Geology = Shale, 10.81Slope =60%THO_C15  19/03/2007  11:14  Page 286 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fRULE-BASED MAPPING287BascoElkmoundCouncilOrionFig. 15.7Predicted distribution of soil series in Pleasant Valley, Wisconsin, USA based on aBoolean implementation of the rules in Figure 15.8. Light toned areas in the watershed are areas that do not meet the conditions of any of the rulesBasco:Bedrock: JordanGradient: <20%Elevation: >950 ftProfile: convex to linearCouncilBedrock: JordanGradient: 6–20%Elevation: 800–850 ftProfile: concaveElkmound:Bedrock: JordanGradient: >20%Elevation: 850–950 ftProfile: linear to slightly convexOrionBedrock: JordanGradient: <6%Elevation: <800 ftProfile: linear to slightly concaveFig. 15.8Descriptive rules for soils in Pleasant Valley, Wisconsin, USATHO_C15  19/03/2007  11:14  Page 287 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f288A-XING ZHUChallenges and Research IssuesRule-based mapping provides a very viable option to physical process-based andstatistical approaches for mapping variation of geographic phenomena/features, par-t",
    "chunk_order_index": 178,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-1fe0d5582b3248fadcc2f3b1f0b964fd": {
    "tokens": 1200,
    "content": "iley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f288A-XING ZHUChallenges and Research IssuesRule-based mapping provides a very viable option to physical process-based andstatistical approaches for mapping variation of geographic phenomena/features, par-ticularly when we know more than what is needed in statistical approaches butless than what is needed for physical process-based mapping. The development ofthe fuzzy logic concept, coupled with geographic information processing techniquesmakes rule-based mapping not only practical but also accurate in portraying spatialgradation of geographic entities.However, rule-based mapping still faces many challenges and many research issues.Examples of these challenges and research issues are: the extraction of rules, theweighting of rule components in inference, the deﬁnition of membership functions,and the use of fuzzy membership values. Much of the knowledge needed for rule-based mapping exists in the form of human expertise. Methods are needed to extractand document this knowledge. One important research issue is how to integrate know-ledge from different experts and sources (such as human expertise with knowledgethat exists in other forms).BascoElkmoundCouncilOrionFig. 15.9Predicted distribution of soil series in Pleasant Valley, Wisconsin, USA based on a fuzzyimplementation of the rules in Figure 15.8. No areas are missed outTHO_C15  19/03/2007  11:14  Page 288 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fRULE-BASED MAPPING289Most of the inference techniques treat rule components (variables in a rule) equally,not for simplicity of inference, but more importantly for the lack of knowledge on how these components (variables) interact. Assigning weights to variables is notdifﬁcult in the implementation of an inference engine or overlay process but whatweights should be assigned is a challenge. Is there knowledge from domain expertswhich can be used for determining the weights? Is spatial data mining an approachto this problem?Deﬁnition of fuzzy membership functions has come a long way (from generalfunctions to domain knowledge-based functions). There are still challenges aheadin this arena, particularly with variables which take linguistic terms as values. The following questions need to be answered before the meaningful deﬁnition ofmembership functions for these variables can be found: What does a given linguisticvalue mean in the numeric domain of data layers? How can we determine the numericmeaning of a given linguistic value? How does this meaning change from one personto another, from one landscape to another and from one application to another?Fuzzy logic has been well received by researchers in geography, particularly GIscientists (see Robinson, Chapter 14 of this volume, for a more detailed treatmentBascoElkmoundCouncilOrionFig. 15.10Uncertainty map associated with the soil map produced under the fuzzy implementationof the rules for the Pleasant Valley area. The purer the color the more certain for the area to belabeled as the soil represented by the colorTHO_C15  19/03/2007  11:14  Page 289 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f290A-XING ZHUof fuzzy classiﬁcation and mapping). However, the use of fuzzy membership valuesin decision making and other management practice has a long way to go. For example, people are used to seeing maps showing the distribution of soil classesand associated properties with these classes. How would a person associate therequired soil properties with a fuzzy membership map? What do fuzzy membershipmaps mean in decision making?Research in the areas mentioned above will almost certainly propel rule-based map-ping to a new era in the years to come. Information produced from rule-based mapping is then more likely to be meaningfully used in decision making and otherforms of geographic analysis.ACKNOWLEDGEMENTSThe author is grateful to the support from the “One-Hundred Talents” programof the Chinese Academy of Sciences. The assistance provided by Mr Rongxun Wangin preparing the maps used in this chapter is greatly appreciated.REFERENCESBatty, M. 1998. Urban evolution on the desktop: Simulation with the use of extended cellularautomata. Environment and Planning A30: 1943–67.Boose, J. H. and Gaines, B. R. (eds). 1988. Knowledge Acquisition Tools for Expert Systems.London: Academic Press.Burrough, P. A. 1989. Fuzzy mathematic methods for soil survey and land evaluation. Journalof Soil Science40: 447–92.Burrough, P. A. 1996. Natural objects with indeterminate boundaries. In P. A. Burrough andA. U. Frank (eds) Geographic Objects with Indeterminate Boundaries. London: Taylorand Francis: 3–28.Buttenﬁeld, B., Gahegan, M., Miller, H. J., and Yuan, M. 2002. Geospatial Data Miningand Knowledge Discovery. WWW document, http://www.ucgis.org/priorities",
    "chunk_order_index": 179,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e420866ae009d16f2cf41e8208910f35": {
    "tokens": 1200,
    "content": "urrough, P. A. 1996. Natural objects with indeterminate boundaries. In P. A. Burrough andA. U. Frank (eds) Geographic Objects with Indeterminate Boundaries. London: Taylorand Francis: 3–28.Buttenﬁeld, B., Gahegan, M., Miller, H. J., and Yuan, M. 2002. Geospatial Data Miningand Knowledge Discovery. WWW document, http://www.ucgis.org/priorities/research/research_white/2000%20Papers/emerging/gkd.pdf.Couclelis, H. 1997. From cellular automata to urban models: New principles for model development and implementation. Environment and Planning B24: 165–74.Ehleringer, J. R. and Field, C. B. (eds). 1993. Scaling Physiological Processes: Leaf to Globe.San Diego, CA: Academic Press.Fensel, D. A. and Studer, R. 1999. Knowledge Acquisition, Modeling and Management:Proceedings of the European Knowledge Acquisition Workshop (EKAW-99). New York:Springer Lecture Notes in Artiﬁcial Intelligence No. 1621.Goodchild, M. F. and Haining, R. P. 2004. GIS and spatial data analysis: Converging perspectives. Papers in Regional Sciences83: 363–85.Hart, A. 1986. Knowledge Acquisition for Expert Systems. New York: McGraw-Hill.Hastie, T. J. and Pregibon, D. 1992. Generalized linear models. In J. M. Chambers and T. J. Hastie (eds) Statistical Models in S. Paciﬁc Grove, CA: Wadsworth and Brooks, pp. 195–248.Hastie, T. J., Tibshirani, R. J., and Friedman, J. 2001. The Elements of Statistical Learning:Data Mining, Inference and Prediction.New York: Springer.Liao, S. H. 2005. Expert system methodologies and applications: A decade review from 1995to 2004. Expert Systems with Applications28: 93–103.THO_C15  19/03/2007  11:14  Page 290 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fRULE-BASED MAPPING291Lillesand, T. M., Kiefer, R. W., and Chipman, J. W. 2004. Remote Sensing and Image Inter-pretation(5th edn). New York: John Wiley and Sons.Liu, J. 2004. Mapping with words: A new approach to knowledge-based digital soil mapping.Unpublished MSc Thesis, Department of Geography, University of Wisconsin at Madison.McBratney, A. B. and Odeh, I. O. A. 1997. Application of fuzzy sets in soil science: Fuzzylogic, fuzzy measurements and fuzzy decisions. Geoderma77: 85–113.Miller, H. J. and Han, J. (eds). 2001. Geographic Data Mining and Knowledge Discovery.London: Taylor and Francis.Monteith, J. L. 1965. Evaporation and environment. In G. E. Fogg (ed.) The State andMovement of Water in Living Organisms. San Diego, CA: Academic Press: 205–34.O’Sullivan, D. and Haklay, M. 2000. Agent-based models and individualism: Is the worldagent-based? Environment and Planning A32: 1409–25.Qi, F. and Zhu, A. X. 2003. Knowledge discovery from soil maps using inductive learning.International Journal of Geographical Information Science17: 771–95.Robinson, V. B. 2000. Individual and multi-personal fuzzy spatial relations acquired usinghuman–machine interaction. Fuzzy Sets and Systems113: 133–45.Robinson, V. B. 2003. A perspective on the fundamentals of fuzzy sets and their use in geographic information systems. Transactions in GIS7: 3–30.Scott, M. J., Davis, F., Cusuti, B., Noss, R., Butterﬁeld, B., Groves, C., Anderson, H., Caicco,S., D’Erchia, F., Edwards, T. C., Ulliman, J., and Wright, R. G. 1993. GAP analysis: Ageographic approach to protection of biological diversity. Wildlife Monographs123: 1–41.Shi, X., Zhu, A. X., Burt, J., Qi, F., and Simonson, D. 2004. A case-based reasoning approachto fuzzy soil mapping. Soil Science Society of America Journal68: 88–94.Simpson, D. M. 2001. Virtual reality and urban simulation in planning: A literature reviewand topical bibliography. Journal of Planning Literature15: 359–72.Waring, R. H. and Running, S. W. 1998. Forest Ecosystem Analysis at Multiple Scales. SanDiego, CA: Academic Press.Wilson, J. P. and Gallant, J. C. (eds). 2000. Terrain Analysis: Principles and Applications.New York: John Wiley and Sons.Yamada, K., Elith, J., McCarthy, M., and Zerger,",
    "chunk_order_index": 180,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-73f272ff2d9a6293de17d4290fec854a": {
    "tokens": 1200,
    "content": "Journal of Planning Literature15: 359–72.Waring, R. H. and Running, S. W. 1998. Forest Ecosystem Analysis at Multiple Scales. SanDiego, CA: Academic Press.Wilson, J. P. and Gallant, J. C. (eds). 2000. Terrain Analysis: Principles and Applications.New York: John Wiley and Sons.Yamada, K., Elith, J., McCarthy, M., and Zerger, A. 2003. Eliciting and integrating expertknowledge for wildlife habitat modeling. Ecological Modeling165: 251–64.Zhu, A. X. 1997a. A similarity model for representing soil spatial information. Geoderma77: 217–42.Zhu, A. X. 1997b. Measuring uncertainty in class assignment for natural resource maps underfuzzy logic. Photogrammetric Engineering and Remote Sensing63: 1195–202.Zhu, A. X. 1999. A personal construct-based knowledge acquisition process for natural resourcemapping. International Journal of Geographical Information Science13: 119–41.Zhu, A. X. 2005. Fuzzy logic models. In S.Grunwald and M. E. Collins (eds) Environ-mental Soil-Landscape Modeling: Geographic Information Technologies and Pedometrics.Boca Rotan, FL: CRC Press, pp. 215–39.Zhu, A. X. and Band, L. E. 1994. A knowledge-based approach to data integration for soilmapping. Canadian Journal of Remote Sensing20: 408–18.Zhu, A. X., Band, L. E., Dutton, B., and Nimlos, T. J. 1996. Automated soil inference underfuzzy logic. Ecological Modelling90: 123–45.Zhu, A. X., Hudson, B., Burt, J., Lubich, K., and Simonson, D. 2001. Soil mapping using GIS,expert knowledge, and fuzzy logic. Soil Science Society of America Journal65: 1463–72.Zhu, A. X., Wang, R. X., Qiao, J. P., Chen, Y. B., Cai, Q. G., and Zhou, C. H. 2004. Mappinglandslide susceptibility in the Three Gorge Area, China, using GIS, expert systems and fuzzylogic. In Y. Chen, K. Takara, I. D. Cluckie, and F. H. De Smedt (eds) GIS and RemoteSensing in Hydrology, Water Resources and Environment. Wallingford, UK, InternationalAssociation of Hydrological Sciences Publication No. 289: 385–91.Zimmermann, H. J. 1985. Fuzzy Set Theory and Its Applications. Boston, MA: Kluwer-Nijhoff.THO_C15  19/03/2007  11:14  Page 291 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 16Multivariate GeovisualizationMark GaheganResearch into the physiological aspects of human perception points to three primarychannels by which visual information passes from the retina to the visual cortex;these essentially parallel channels carry encoded signals describing color, movement,and form (structure) within the scene (see Livingstone and Hubel 1988, for a moredetailed account). The signals they carry are integrated during the perception process,1and it is their joint interpretation, along with ocular disparity derived from stereovision and stored experiences and knowledge that enables us to make sense of thecomplexities of the visual stimulus presented to us with such consummate ease. Usingthese properties we “see” motion, perspective, speed, distance, pattern, surface prop-erties (shiny, dull), illumination characteristics (position and intensity of the lightsource), and many other visual qualities. It is therefore a regrettable fact that thefollowing description of the wonders of multivariate visualization is in a book, wherecolor, movement, and stereo vision are not supported and the available bandwidthfor visual communication of information is rather drastically restricted to the useof position and shape, with some possible further encoding of information usingshades of grey.2Thus, many of the important beneﬁts of visualization are lost, and it is a challenge to offer the reader any convincing proof of concept.I therefore humbly ask, gentle reader, that you try and imagine color, depth, andmovement in the rude images included in this chapter. Or if you prefer, visit theGeoVISTA website (http://www.geovista.psu.edu) where these visual properties areavailable in full measure.Why Do We Need So Many Variables?Before discussing the details of multivariate geovisualization – concurrent visual dis-play of many variables or dimensions – it is worth considering why the use of manyvariables is called for. There seem to be two sets of forces at work here, offeringa “push” and a “pull” factor. On the push side, two speciﬁc technologies presentus with ever more complex data sets. Firstly, measuring instruments from censusTHO_C16  20/03/2007  15:12  Page 292 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions",
    "chunk_order_index": 181,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-df73985fd65c8665523383384d8af671": {
    "tokens": 1200,
    "content": ". On the push side, two speciﬁc technologies presentus with ever more complex data sets. Firstly, measuring instruments from censusTHO_C16  20/03/2007  15:12  Page 292 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION293to satellite are becoming more complex and elaborate, gathering more and morevariables; secondly, as many longstanding problems of interoperability and data accessare solved it becomes possible to integrate once-separate data sets into highly multi-variate collections (Miller and Han 2001).On the pull side, trying to understand, as geographers are wont to do, the com-plexities of physical and human systems usually demands that we consider manyfactors simultaneously; systems tend to be unbounded or “open,” and interrelation-ships are complex, multi-faceted, and often accompanied with signiﬁcant spatial andtemporal variation. For example, understanding cancer incidence and prevalencewith respect to healthcare accessibility, demographics, and physical environmentmight reveal important trends that could form the basis of improved screening pro-grams and public education campaigns.Multivariate data visualization is one means by which humans can deal with thiskind of data complexity, and there are a number of well-established visual methodsfor displaying several variables concurrently (for example, McLeod and Provost 2001),as we will see later. However, continuing to add in more variables does not neces-sarily produce a more coherent picture; perceptual and cognitive limitations governthe effectiveness of these multivariate visualizations. What is not always clear isexactly howthese human limitations govern effectiveness. So, although there seemsby now little doubt that multivariate visualizations are a useful means to exploreand portray complex data, there are still many unanswered questions regarding per-ceptual limitations, appropriateness, and effectiveness. Multivariate visualization istherefore not a panacea for large or complex data sets, but just like statistics and datamining, it offers some techniques to address them, while introducing limitations andproblems of its own. Good analysis needs to integrate the best that each of theseapproaches has to offer.Different Ways to Analyze Multivariate DataTo elaborate, when faced with the task of understanding some complex system –a snapshot of which is captured in a multivariate data set – there are a variety oftools and methodologies that could be used. Multivariate statistics provides a vastarray of tried and tested analysis tools (for example, Mardia, Kent, and Bibby 1979);machine learning and data mining supply a newer set of tools that are sometimesmore ﬂexible and computationally efﬁcient, but are also less well tested and under-stood (Gahegan 2003; see also Chapter 19 by Miller in this volume). Table 16.1contrasts some of the basic tenets of these three different approaches.Any form of analysis is a collaboration between researchers and their tools andmethodologies; but this collaboration is most central to visualization, as it relies onhuman perceptual and cognitive systems to observe and interact with data, as wellas interpret the results. Visualization is also usually interactive, so analysis can beregarded as a form of communication (perhaps even a conversation; MacEachren,Gahegan, and Pike 2004) between geographer and data, and as such offers the poten-tial advantage of bypassing the formal language of mathematics or the theories ofmachine learning in order to communicate with the researcher. The language is visualas opposed to mathematical, statistical, or logical, and the conversation is often aidedTHO_C16  20/03/2007  15:12  Page 293 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f294MARK GAHEGANby interactive tools that support a dynamic exploration of the data by allowing theanalyst to keep refocusing their attention on different regions of the data set. Butbecause the human is such an integral part of the visualization process, the outcomesare more subjective in nature and hence the evaluation of ﬁndings becomes moreproblematic (Cleveland 1993). We each see and understand differently, so what workswell for one person may be unsuitable for another, based on factors as simple ascolor vision deﬁciencies and as complex as the difference in prior experiences ofanalysts (McGuinness 1994, Nyerges, Moore, Montejano, and Compton 1998).Ways to Approach Multivariate GeovisualizationThe development of multivariate visualizations can be, and is, approached from awide variety of perspectives, a selection of which appear below as a list of motivat-ing questions.1Graphic Design: How can I make displays that people want to look at – thatare intriguing and appealing, that capture the eye? (Arheim 1974, Karssen 1980,Tufte 1990, Landa 2004).2Perception and Cognition: How can I use the different visual variables at mydisposal, such as color, transparency, movement, size, in ways that are knownto be effective? (Bertin 1967, 1981, Koch and Ullman 1985, Treisman 1986,",
    "chunk_order_index": 182,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a1afd76c5c7485f0298221f6e0bfd62b": {
    "tokens": 1200,
    "content": "intriguing and appealing, that capture the eye? (Arheim 1974, Karssen 1980,Tufte 1990, Landa 2004).2Perception and Cognition: How can I use the different visual variables at mydisposal, such as color, transparency, movement, size, in ways that are knownto be effective? (Bertin 1967, 1981, Koch and Ullman 1985, Treisman 1986,Livingstone and Hubel 1988; Grinstein and Levkowitz 1995).3Statistics: How can I capture the variance of all the salient data attributes sothat the underlying trends and patterns can be better understood? (Asimov 1985,Cleveland and McGill 1988, Haslett, Bradley, Craig, Unwin, and Wills 1991,Cook, Majure, Symanzik, and Cressie 1996).4Computer Science: How can I improve the computational representation andmanipulation of graphical data? (Noll 1967, Sammon 1969, Glassner 1989,Spitaleri 1993, Ribarsky, Katz, and Holland 1999).5User-centered design: Who are the users, and what are they familiar with? (Hixand Hartson 1993, Shneiderman 1998, Vredenburg, Isensee, and Righi 2002,Kosara, Healey, Interrante, Laidlaw, and Ware 2003).Table 16.1A brief summary of the differences between statistical, machine learning, andvisual processes to analysis, a more detailed version appears in Buttenﬁeld, Flewelling,Gahegan, Miller, and Yuan (2005)MethodStatistical analysisMachine learningVisualizationData analyzed usingParametric function ﬁtting,inferential methodsInductive learning methods, datamining methodsGraphical methods, mappingdata to visual variablesTesting, rigorSigniﬁcance testing, power,goodness of ﬁtValidation experiments that testgenerality and repeatabilityUser studies, focus groups,protocol analysisTHO_C16  20/03/2007  15:12  Page 294 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION2956Cartography: How can I extend the familiar map to include additional useful andrelevant information? (Monmonier 1989, 1990 MacDougall 1992, MacEachren1994; Dykes 1996).All of these approaches have merits of their own and all of the ﬁelds representedabove have made signiﬁcant contributions to the emerging ﬁeld of information visualization. Historically, perhaps the most commonly used approaches to geovisual-ization are 6 and 2, with a little of 2, 3, and 5. By contrast, within advertising theemphasis instead is on 1 and 5.It is not surprising, then, that, as the ﬁeld of geovisualization develops, approachesand techniques are drawn from an increasingly wide variety of sources. Obviously,cartography remains a major inﬂuence, and provides not only a range of symboliza-tion and thematic techniques such as perceptually valid color schemes (Brewer 1997,Green and Horbach 1998) and cartograms (Dorling 1994) but also important earlytheoretical and conceptual contributions such as those of Taylor (1991), DiBiase(1990) and MacEachren (1995), and a rich history and commitment to testing andevaluation by experiments with users (Wood 1990, McGuinness 1994, Slocum, Blok,Jiang, et al. 2001, Andrienko, Adrienko, Voss, et al. 2002). The work of Bertin(1967, 1981, 1983) in describing low-level graphical primitives (retinal or visualvariables) and making recommendations as to how they should be used effectivelyhas become central to geovisualization, as it has to cartography. Efforts to extendour list of useful visual variables as they relate to dynamic, interactive displays areincreasingly relevant (for example, Mackinlay 1986, MacEachren 1994).At the present time, in the early twenty-ﬁrst century, most experimental systemsbuilt for multivariate geovisualization rely on a series of different data displays,including maps and other graphical techniques that are kept in step with each otherby a technique called “linking and brushing”; selecting items in one display causesthe same items to be selected in another display. This technique seems to have ﬁrstarisen within the statistical community (Cleveland and McGill 1988) and was laterapplied to interactive mapping by Monmonier (1989, 1990), where it has becomevery popular as a means to explore how patterns in geographic space are reﬂectedin attribute space, and vice versa. Linking and brushing, thematic classiﬁcation, anddata exploration form the basis of many environments for visualization (Egbert and Slocum 1992, Dykes 1996, Gahegan 1998, Andrienko and Andrienko 1999, Northand Shneiderman 1999, Gahegan, Takatsuka, Wheeler, and Hardisty 2002).Types of Visualization",
    "chunk_order_index": 183,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e8501d7bfa3d373b6ee03314e168fe5c": {
    "tokens": 1200,
    "content": "geographic space are reﬂectedin attribute space, and vice versa. Linking and brushing, thematic classiﬁcation, anddata exploration form the basis of many environments for visualization (Egbert and Slocum 1992, Dykes 1996, Gahegan 1998, Andrienko and Andrienko 1999, Northand Shneiderman 1999, Gahegan, Takatsuka, Wheeler, and Hardisty 2002).Types of Visualization Methods“Seeing” into high dimensional spaces typically involves reducing or re-portrayingthe space into forms that humans can better understand, and that can be physicallydisplayed in a smaller number of dimensions, or in a more compact form, on whatis usually a small display device such as a typical computer monitor. Many differentapproaches have been taken to increase visual effectiveness and to add in furtherdimensions, producing a wide variety of techniques as a result (Robertson 1997).Of course, it is usually the case for geographic inquiry that the spatial dimensions,and often the temporal dimensions, within the data are of great signiﬁcance andbecause of this they are often privileged in that they form the basis (for example,THO_C16  20/03/2007  15:12  Page 295 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f296MARK GAHEGANthe axes) around which other data dimensions are structured. No surprise, then,that geovisualization is typically biased toward map-based displays.More recently, information visualization – having become an established ﬁeld of research in its own right – has supplied a large number of newer techniques:graph-based methods such as the parallel coordinate plot (Inselberg 1985, 1997) andbagplot (Rousseeuw, Ruts, and Tukey 1999), hierarchical methods such as cone-trees(for example, Robertson, Mackinlay, and Card 1991), symbol-based methods suchas iconographs (Pickett and Grinstein 1988), techniques for making “informationlandscapes,” for analyzing multi-thematic information sources such as newspapersand scientiﬁc literature archives (for example, Miller, Wong, Brewster, and Foote 1999,Fabrikant 2000), and methods for visualizing concept graphs and ontologies (Muttonand Golbeck 2003, Pike and Gahegan 2003). Figure 16.5 shows an example of aparallel coordinate plot, Figure 16.9 a generalization hierarchy, Figure 16.4 an iconicvisualization, Figure 16.8 a demographic “information landscape,” and Figure 16.10a concept graph. A useful summary of some of the more established informationvisualization methods is given by McLeod and Provost (2001).Various attempts have been made to categorize these different methods accord-ing to the kinds of graphics they employ (Hinnenberg, Keim, and Wawryniuk 1999)or to the kinds of inference that they support (Gahegan, Wachowicz, Harrower,and Rhyne 2001). However, any distinctions between different methods are fastbecoming moot as they borrow freely from each other, fusing together differentgraphical and statistical approaches.Different methods for visualizing multivariate data include•Multiple linked views: graphs shown in separate (usually linked) displays (multiples or matrices), as in Figures 16.6 and 16.7;•Symbol construction or graphical mark (glyph) composition: data are mappedto different aspects of a chosen symbol or glyph, such as color, transparency,and shape resulting in a symbol that encodes two or more data variables, asshown in Figures 16.1, 16.2, and 16.4;•Data projection and/or reduction: data are transformed via some function intoa smaller number of variables (for example, projection pursuit, Cook, Buja,Cabrera, and Hurley 1995) sometimes followed by re-projection to a surface(for instance, using a Self Organizing Map as shown in Figure 16.8 and thevisual data mining display in Figure 16.11);•Animation: since the eye is so sensitive to changes in a display, movement orother forms of change can be very effective for getting trends in the data noticed,or, if badly used, can be very distracting (Figures 16.2 and 16.4 animate whenviewed on the web);•Hierarchies and node-edge graphs: these kinds of displays show taxonomies,concept graphs, and ontologies, that encode relationships such as “is a kind of,” and “is a part of” between entities or concepts. Figures 16.9 and 16.10are examples;•Using additional sensory modes (haptics, sound, etc.).Choosing a suitable visual representation for data depends heavily on the type ofdata under consideration, on the number of variables (p) and the number of recordsTHO_C16  20/03/2007  15:12  Page 296 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION297or objects (",
    "chunk_order_index": 184,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-c2ca6e856f951f20806f7dc37014d2b1": {
    "tokens": 1200,
    "content": "03/2007  15:12  Page 296 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION297or objects (n) but also on the nature of the task to be undertaken, such as explora-tion or communication, as discussed in the next section.Geovisualization ExamplesThe following set of geovisualizations exemplify many of the ideas described in thischapter, and are all available as color images or animations on the accompanyingwebsite, where the reader is advised to examine them if possible (animated displaysrequire a Flash Plugin available freely from http://www.macromedia.com/software/ﬂashplayer/). Note that as the number of variables increases, the visualizations becomemore abstract with less of the details in the original data being preserved. For exploring a highly multivariate data set, one might begin with these more abstracttechniques, using them to identify lower dimensional sub-spaces that show patternsof interest, then investigating these further using the simpler techniques.As a starting point, the ﬁrst image is a simple thematic (choropleth) map, show-ing just a single attribute value, human population in the year 2000 by county forthe contiguous 48 states of the USA (Figure 16.1). As is common in choroplethmapping, the population values are grouped into classes (six in this case) to providediscrete color values since this generally makes the map easier to interpret.Fig. 16.1Thematic map of population by county for the conterminous 48 states of the USATHO_C16  20/03/2007  15:12  Page 297 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f298MARK GAHEGANThe map in Figure 16.2 shows two variables concurrently. Proportional circlesare centered on the major cities, with the size of each circle encoding populationand the shade describing the proportion of foreign-born people who live there. Change over time is also shown in the accompanying applet, as a sequence of mapsrepresenting 10-year values from 1890–1990.Encoding data (such as population) with a visual variable (such as circle size) is neverstraightforward. A good deal of our visual interpretation is relative, depending inlarge part on the immediate context within the display. As an example, Figure 16.3Population Growth and Immigrant Populations in Major US Cities1890–199018901900191019201930194019501960197019801990Population in Thnusands50003000Percent of PopulationForeign BoraSources: The US Nutivity at the Population for the 50 Lugest Urban Phces 1870 to 1990 hop: www.32–4216–315–152–4No Data20001000500100Fig. 16.2Visualization of changes in population growth and immigrant population usingproportional circlesFig. 16.3Which inner circle seems bigger? A visual illusion concerning the size of circles (see text for details)THO_C16  20/03/2007  15:12  Page 298 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION299below shows a well-known visual illusion in which we see two inner circles of exactlythe same size as being of different sizes because of the surroundingcontext. Manyother such examples illustrate similar problems when interpreting orientation, motion,length, color, straightness, in fact just about all possible visual variables. The website:http://www.michaelbach.de/ot/ has several fascinating examples.The more complicated animated map reproduced in Figure 16.4 shows detailsof an oil reservoir in terms of each drilled well. Many variables are encoded: thecolor of the background encodes interpolated depth to reservoir; hypothesized oilregions are shown as a semi-transparent shaded (green) overlay, the bar positionsshow bore hole location, their tilt angle encodes the percentage sand encounteredat that location, the length of the bar shows the thickness of the oil layer; the squaredots show the added presence of water. When using the animated version on thewebsite, the bars change as the oil reservoirs become depleted over time.Figure 16.5 shows a parallel coordinate plot (PCP), a technique proposed byInselberg (1985) to visualize multiple data dimensions concurrently. The axes aredrawn parallel to each other and appear as vertical lines. The data set shown describesvarious demographic properties for the 48 conterminous US states, hence there are 48 polylines or “strings” shown. If the values for each state are marked off on the axes, then joined with a line, the result is a web of strings that can show trendsand clustering in the data. The arrows point to the trace for California (shown lightDepth toGA Sand% sand79–91 %70–78 %62–69",
    "chunk_order_index": 185,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-120134dedb5547fbe18a30595f5bddfa": {
    "tokens": 1200,
    "content": "vertical lines. The data set shown describesvarious demographic properties for the 48 conterminous US states, hence there are 48 polylines or “strings” shown. If the values for each state are marked off on the axes, then joined with a line, the result is a web of strings that can show trendsand clustering in the data. The arrows point to the trace for California (shown lightDepth toGA Sand% sand79–91 %70–78 %62–69 %53–61 %45–52 %High: 3500feetLow: 5300quantilefaultoilwaterNet PayOil Regions100+7550250Thicknessof theoil layerYears of production0153045Block 3303 × 3 MilesfeetFig. 16.4Characterization of oil reservoirs through time showing multiple data values via acombination of symbols or glyphsTHO_C16  20/03/2007  15:12  Page 299 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f300MARK GAHEGANgreen on the website) which stands out as being rather anomalous compared to the general trend.Looking between each pair of axes provides some insight into the correlationstructure; where strings do not cross each other much there is a positive correla-tion between adjacent variables (for example, “population 1990” and number of“households”), where they cross more often than not, the correlation is likely to benegative (for example, % “male” and “female”, % “white” and “black”). Color canbe added to the display to impose categories onto the strings. Variants of the PCPare often used to examine temporal trends in data, in which case the axes usuallyrepresent the same attribute measured at different times and arranged in sequence.Positive and negative trends through time are then shown by the slope of the strings.The display reproduced in Figure 16.6 provides multiple bivariate views onto adata set describing cancer incidence and prevalence, demographics, and healthcareaccessibility in the Appalachian region (West Virginia, Kentucky, most of Pennsyl-vania). Five variables are explored here, with each variable being assigned to botha row and column, hence ﬁve rows and ﬁve columns. The cells in the matrix showbivariate views onto the data, that is, the conjunction of one row and one columnvariable. The upper right cells show a scatterplot for each pair of variables, andthe lower left cells show the corresponding map. See MacEachren, Dai, Hardisty, Guo, and Lengerich (2003) for more details. The diagonal cell elements show thedata distribution (histogram) for each individual variable – on the website you canalso see that each scatterplot and map is colored using a bivariate color scheme to show the relationship between a pair of specially-chosen variables imposed on thegraphics in each cell of the matrix.The visualization in Figure 16.7 shows the results of using a decision tree classiﬁeron a six-dimensional land cover data set using the variables: height, ﬂow accumula-tion (surface), shape (surface morphometry), slope-degrees, TM-band-2 and TM-band-4 (both from the Landsat sensor). Although the diagram appears complex atﬁrst, it conveys a lot of useful information if carefully studied.The scatterplot matrix display (as in the previous ﬁgure) graphs each variable againstevery other variable, that is to say, the set of all possible bivariate scatterplots for Fig. 16.5A parallel coordinate plot (PCP) showing demographic and related information for the 48conterminous US states. The arrows point to the “string” representing CaliforniaTHO_C16  20/03/2007  15:12  Page 300 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION301the six-dimensional data set. Since it makes no sense to plot a variable against it-self, the diagonal cells in the matrix instead show a binned frequency histogramfor each individual variable, and so indicate the general shape of the distribution. Forall other cells, each cloud of points gives an indication of the degree of associationbetween any pair of variables, and sometimes can also show clusters and outliers,depending on the distribution. If the user wishes, the points can be color coded(according to some other data values such as the land cover class each point indicates,for example). The horizontal and vertical lines represent the output from a decisiontree classiﬁer using Quinlan’s (1993) C4.5 algorithm. So the horizontal lines acrossthe top row of the matrix show the number and position of decision rules thatwere constructed using the height attribute to classify the data into different landcover types. In this case three decision rules were used. Vertical lines work the same,so the lines in the rightmost column show decision rules using Landsat TM band 4.The lines can be color coded too, so that we can see which rules help to constructwhich classes. Many lines in a row or column indicate a variable that is very usefulin constructing the classiﬁcation scheme (formally reduces entropy) or that the variable has a",
    "chunk_order_index": 186,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-414ea0d2852d49bbb9829a5d64f7bf00": {
    "tokens": 1200,
    "content": "height attribute to classify the data into different landcover types. In this case three decision rules were used. Vertical lines work the same,so the lines in the rightmost column show decision rules using Landsat TM band 4.The lines can be color coded too, so that we can see which rules help to constructwhich classes. Many lines in a row or column indicate a variable that is very usefulin constructing the classiﬁcation scheme (formally reduces entropy) or that the variable has a complex relationship to the categories sought, no lines indicate avariable that is redundant and adds no qualifying power to the analysis. Of course,such a display becomes even more powerful when linked to maps, images, and othermultivariate displays such as the parallel coordinate plot.The visualization of the conterminous 48 states of the USA shown in Figure 16.8was constructed by clustering states based on their similarities or differences com-puted over 25 census variables describing population proﬁles in terms of raw count,Fig. 16.6Multiple scatterplots and bivariate maps of demographics and cancer-related dataorganized in a matrixTHO_C16  20/03/2007  15:12  Page 301 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f302MARK GAHEGANethnicity, proportions male and female, age, and the cost of renting accommodation.Hence, it encodes a large number of variables so that their dominant trends arepreserved although the original values are lost. Clustering was performed using theKohonen self-organizing map or SOM (Kohonen 1997), and in fact the visualiza-tion is a representation of the internal state of the SOM after training; the whitedots represent neurons, the labels show the relative location of each state and the background surface is a measure of difference between states that can be inter-preted just like a topographical surface; the actual distance between concepts beingcalculated as the path over the terrain between them, rather than as a straight line.Hence, New Mexico is similar to Nevada, Illinois is similar to Ohio and Pennsylvania,but California (represented by the huge spike bottom left) is very dissimilar to itsnearest neighbors, New York, Virginia, and Texas. For contrast, the same data setwas shown earlier in the parallel coordinate plot in Figure 16.8.The example reproduced in Figure 16.9 shows the use of geovisualization to explore historical data. The map above shows the city of London as it was duringFig. 16.7Scatterplot matrix showing land cover data and decision tree rules used in classifying the dataTHO_C16  20/03/2007  15:12  Page 302 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION303the seventeenth century, with streets containing signiﬁcant merchant premises over-laid. Color is used to show the density of merchants. The hierarchical visualizationtool (based on the Taxa tool; Graham, Watson, and Kennedy 2002) gives severalalternative perspectives onto the same information, organized by market sectors to which merchants can belong. The selected merchant, Wetherell Janaway, is usedto highlight relevant branches in the connected hierarchies of: commodities, retail,wholesale, tradesmen, and warehouses; for example retail-precious metals-goldsmith-Wetherall Janawayand production-precious metal-jewelers-Wetherell Janaway.The concept map in Figure 16.10 depicts a series of concepts and relationshipsthat together describe 10 signiﬁcant events that have helped to shape the currentphysical landscape of central Pennsylvania. The events themselves are shown as pale diamond-shaped nodes and speciﬁc consequences and examples are shown as rectangles. Linking all of these together are a series of directed and undirected edges that describe the relationships between these concepts; for example, growthof industry was facilitated by railroad building, forest use and management gave riseto ﬁre suppression and deforestation, and affected forest pathogens. A live version ofthis application (ConceptVista) dynamically reconﬁgures the graph according to theuser’s current interest (the concept “in focus”). This concept map also has ancillarymaterials, such as text and photographs, linked into it for use as an interactive Fig. 16.8A surface produced by clustering US states based on their demographic properties.California stands out as very anomalousTHO_C16  20/03/2007  15:12  Page 303 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f304MARK GAHEGAN1–45–1213–2526–5051–7576–150151–233NZWBDensity of MerchantsFig. 16.9The city of London during the seventeenth century, showing the density of merchantsalong various street segments (top) and a breakdown of the various hierarchies of goods and",
    "chunk_order_index": 187,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-dd45de205846d6c7917c352503954cb2": {
    "tokens": 1200,
    "content": ".com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f304MARK GAHEGAN1–45–1213–2526–5051–7576–150151–233NZWBDensity of MerchantsFig. 16.9The city of London during the seventeenth century, showing the density of merchantsalong various street segments (top) and a breakdown of the various hierarchies of goods and servicesthat the data set contains (bottom)THO_C16  20/03/2007  15:12  Page 304 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION305learning application. Tools to visualize and explore concept maps and ontologiesare likely to become increasingly important in the future as a means to representand exchange understanding between collaborating researchers.The visualization reproduced in Figure 16.11 shows a matrix of around 100 censusand disease variables and is used to gain a synoptic overview of possible signiﬁcantrelationships between pairs of variables. Two measures of similarity are used, linearcorrelation (upper right triangle, the lighter squares show higher correlation) andentropy (lower left triangle, the lighter colors show lower entropy). The diagonalline is kept black since this would represent each variable compared to itself. Lighterareas in the display are candidates for further investigation if the relationships shownare not already known; tools such as scatterplots, parallel coordinate plots, andmaps might be used with the identiﬁed smaller subsets of data.The Nature of Analysis: A Variety of TasksMultivariate visualization can help support a number of different activities; the various stages in the process of science provide a number of roles that visualiza-tion can play, including (but not limited to)•Exploring data, formulating hypotheses•Learning patterns, synthesis, making generalizations•Performing analysis – supporting analytical activities•Validating results – comparison, veriﬁcation, error assessment•Communicating ﬁndingsFig. 16.10A concept map depicting events that have shaped the landscape of central PennsylvaniaTHO_C16  20/03/2007  15:12  Page 305 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f306MARK GAHEGANEach of these activities is likely to require a different approach to visualization, andpossibly unique tools. For example, formulating a new hypothesis might involvetrying to ﬁnd a hitherto unknown or unexplained pattern in the data, whereas validat-ing results might involve comparing several modeled outcomes to known referencedata. For ﬁnding a pattern, techniques that help the user explore the data from manydifferent perspectives are likely to be effective, such as scatterplot animation methodsor automated clustering, whereas comparison of results against known data needs amethod that emphasizes the similarities and differences between two sets of values.Understanding the nature of the question being asked is vital to the success ofvisualization. Visualization techniques are often chosen pragmatically because theyare easily available or they can support the types and formats of the data underinvestigation. Three things are needed to improve this situation: (1) wider avail-ability of different techniques; (2) better inter-operation between techniques andother software to be used; and (3) more research on which techniques work bestfor which tasks (Fabrikant and Skupin 2005, Plaisant 2005, Gahegan 2005).Fig. 16.11A visualization of 100 census variables showing correlation and entropyTHO_C16  20/03/2007  15:12  Page 306 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION307Creating Multivariate VisualizationsThe process of creating a multivariate visualization involves a number of stages viawhich data are mapped to visual variables, which can then be rendered in a dis-play. The process starts with the data, which will be of a speciﬁc type (for example,point, line, region, non-spatial attribute), be discrete or continuous, and measuredaccording to a speciﬁc statistical scale. These factors must then be matched ﬁrst to appropriate visualization geometry or symbols, (the sign vehicle) then to speciﬁcvisual variables that those vehicles support. After these choices have been made,the range of values in the data must be transformed to a range of values supportedby the visual variable; for example, a set of population values for census regionscontaining between 1,000 and 10,000 people might be matched to the color of acircle, from purple through to green in ﬁve discrete steps. The relationship betweenvisual variable and data can be complex; several data variables may be combinedto produce one or a few visual variables as in the surface shown in Figure 16.8.Conversely, a single data value might be encoded by more than one",
    "chunk_order_index": 188,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-288c730e78d61b0e727a564a3ab61e6d": {
    "tokens": 1200,
    "content": "the visual variable; for example, a set of population values for census regionscontaining between 1,000 and 10,000 people might be matched to the color of acircle, from purple through to green in ﬁve discrete steps. The relationship betweenvisual variable and data can be complex; several data variables may be combinedto produce one or a few visual variables as in the surface shown in Figure 16.8.Conversely, a single data value might be encoded by more than one visual variableto give it added prominence in the display; a common example is to color a sur-face according to the “height” value thus using height twice – so called redundantencoding. This speciﬁc encoding is also used in Figure 16.8.The entire process is repeated for each spatial object or attribute to be visual-ized. This abstraction process is much the same as for traditional cartography(MacEachren 1995, Dent 1998), but with additional data types and visual variables,and sometimes many sophisticated computational methods by which to transformthe data into visual variables. Table 16.2 summarizes this process, after Muehrke,Muehrke, and Kimerling (2001) and Fabrikant and Skupin (2005). For simplicity,only static visual variables are considered in the table, though dynamic variablesused for animation, and variables for sound and haptics could also be added.In the table, two examples are given of the arrangements used to support visual-ization methods: available choices for the production of a scatterplot are shownshaded grey, and those used for a choropleth map have a heavier border; hence, ascatterplot visualizes attribute (non-spatial) data, that can be discrete or continuous,measured on an interval or ratio scale, transformed with a linear function, renderedwith a point symbol that supports visual variables for x, y, and zposition, color viahue, saturation, and value and size, and is useful for detecting structures and char-acterizing distributions. By contrast, a choropleth map uses attribute and area data,that is continuous and (usually) differentiable, measured on an ordinal, interval, orratio scale, transformed using a classiﬁcation method (equal interval in this case),displayed using polygons that support visual variables for xand yposition andcolor, and used to examine a spatial pattern.Supporting Multivariate VisualizationSince a number of different disciplines have independently developed the means tovisualize multivariate information, it is not surprising that a number of quite dif-ferent and usually incompatible visualization systems are now available. Choosingthe right system depends on how you want to visualize the data and what you hopeTHO_C16  20/03/2007  15:12  Page 307 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTable 16.2The abstraction process used to construct visualizations from data, showing two speciﬁc examples of a scatterplot (grey shading) and achoropleth map (heavy border line)Data typeAttributePointLineAreaSurfaceVolumeActivityStructure detectionCharacterization (learn pattern A)Differentiation (A from B)Examine spatial patternExamine temporal patternFind similarValidate resultsSign vehiclePoint (circle)LinePolygonSurfaceVolumeSphereArrowTransformation functionlinearlogarithmicEqual intervalsclassiﬁcationSelf organizing mapk-means clusteringStatistical ScaleNominalOrdinalIntervalRatioSmoothnessDiscreteContinuous/differentiableContinuous non-differentiableVisual VariableX positionY positionZ positionHueSaturationValueTransparencySizeOrientationLengthTHO_C16  20/03/2007  15:12  Page 308 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION309to achieve by so doing. Is animation important, or visual representation of 3D geo-metry, or perceptually sound use of color? In practice, the kinds of techniques andfunctionality available depends very much on the visualization system being used;at the time of writing commercial Geographic Information Systems (GIS) providesophisticated map rendering, with appropriate color schemes, proportional symbols,and dynamic reclassiﬁcation, often backed up by a scatterplot with dynamic link-ing and brushing between the two. For many kinds of multivariate visualization, thesecapabilities may sufﬁce, but compared to many of the specialized visualization systemsavailable, both commercial and academic, they are somewhat limited. The factorsthat typically separate GIS visualization capabilities from information visualizationsystems are:•Dynamics – temporal animation is either very limited or absent in most currentGIS;•Support for true 3D geometry – most GIS can render one or more surfaces, butnot a solid three-dimensional shape;•Control of light and viewpoint (the user’s position) in the 3D space of the scene– though increasingly GIS and remote sensing systems do offer some kind of“sun angle shading” algorithm to mimic the illumination from a single light source(usually the sun) at a given position above the geographical plane;•Control of textures and properties of surfaces, for instance, surfaces can be madeto appear more or less reﬂective to give objects in the scene a more realisticappearance;•A rich set of data visualization",
    "chunk_order_index": 189,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-3cd7d5d9fe2c7fee189bc56a5038cb7d": {
    "tokens": 1200,
    "content": "(the user’s position) in the 3D space of the scene– though increasingly GIS and remote sensing systems do offer some kind of“sun angle shading” algorithm to mimic the illumination from a single light source(usually the sun) at a given position above the geographical plane;•Control of textures and properties of surfaces, for instance, surfaces can be madeto appear more or less reﬂective to give objects in the scene a more realisticappearance;•A rich set of data visualization methods perhaps including some of those describedabove under the heading “Ways to Approach Multivariate Geovisualization” andas shown in the example ﬁgures.•The ability to “spatialize” data; that is to treat any data attribute as if it deﬁneda geographic coordinate (GIS typically have to be “tricked” into spatializing non-spatial data).Compared to the comprehensive lists of visual variables proposed by Bertin (1981)and extended by MacEachren (1994) and others, GIS can often support only a limitedsubset. Furthermore, in GIS there is usually an enforced connection between datatype and sign vehicle (refer back to Table 16.2); a point must be rendered as a point,or point symbol, a polygon as a region and so forth. By contrast, most informationvisualization systems make no assumptions about how different data types will besigniﬁed, even if the mappings make no intuitive sense. For example, two data valuesaand bcould be “spatialized” as a point x, y(as in a scatterplot) or a geographicpoint x, ycould be rendered as the size and transparency of a circle.Returning for a moment to the fundamental visual pathways described in theintroduction, (shape, color, movement), GIS provide good facilities for describingcolor, reasonable control over shape and position – but only for explicitly spatialdata, and little or no capability to support movement or dynamics, so there is roomfor further development, assuming we can determine how to make good use of theseextra capabilities. To this end, many cartographers and information visualizationspecialists have experimented with a plethora of additional variables, from anima-tion to sound to haptics (tactile feedback) and even taste and smell in order to addTHO_C16  20/03/2007  15:12  Page 309 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f310MARK GAHEGANto the number of concurrent variables that can be studied, or the effectiveness ofhow they are perceived by the user.Video graphics production environments such as Flash deserve a special mentionas they are playing an increasingly important part in the study and production ofdynamic maps, because of the ease by which temporal behavior can be scripted for the individual map components. Figures 16.2 and 16.4 are derived from Flashanimated maps. Capacity to handle spatial data remains primitive, but improvementsin the programming interface allow the intrepid user to make their own provision,with easy access to the temporal variables being the incentive.You Usually Do Not Need To See It AllMost of the visualization examples shown above portray a small number of variablesthat can be visualized quite effectively using existing methods and computing techno-logy. But as the dimensionality grows it becomes difﬁcult to show all variables clearlywithout exceeding the perceptual and cognitive abilities of the user (Maeder 1997),or the performance of the computer; some mechanism must be used to either dropsome variables, reduce the detail shown, provide a summary view or add windowingcapabilities (zoom and pan) onto the display. For example,the simplistic approachof assuming that all variables should be shown, and pair-wise related one to anotheras shown in Figure 16.6 will not scale to the highly multivariate data sets that areincreasingly becoming available; to illustrate the point, the AVIRIS 224 band satellitedata would require a scatterplot matrix to have 224*223/2 =24,976 cells!As argued by Scott (1992), if a highly multivariate space is treated as a hyper-cube, with each data variable having its own dimensions then the vast majority ofthe contained space is likely to be empty, containing no data values, and much of the remainder may contain no patterns of interest. It therefore makes sense toutilize methods that help users to locate interesting areas of lower dimensionality(sub-spaces), as shown in Figure 16.11, or to project data to a lower dimensionalform that is more compact, as in Figure 16.8.Current Geovisualization Research NeedsMuch progress has been made, but many problems remain to be solved before geo-visualization can fulﬁll all of its potential (Gahegan 1999, Foley 2000). Some speciﬁcproblems follow:1Perceptual and cognitive limitations There are certain to be some perceptualand cognitive limits as to how much information a human observer can takein. However, these limits depend very much on the experience of the observer,the types of data, the techniques in use, the tasks to be performed, and even thecapabilities of the display environment. A good deal of research has been directedtowards studying the effects of the above aspects in isolation, but little is under-stood concerning how these limits apply togetherin determining how much datais too much.THO_C16  20/03/2007  15:12  Page 310 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries,",
    "chunk_order_index": 190,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-cc6831a9950faa92aebe788038149eec": {
    "tokens": 1200,
    "content": "use, the tasks to be performed, and even thecapabilities of the display environment. A good deal of research has been directedtowards studying the effects of the above aspects in isolation, but little is under-stood concerning how these limits apply togetherin determining how much datais too much.THO_C16  20/03/2007  15:12  Page 310 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION3112Lack of an overarching theory It is very difﬁcult to combine the results of inde-pendent research to ascertain any global truths about the perceptual and cognitiveaspects of visualization. This is not to say that no useful theories or frameworksexist – they do, and several examples are given above. However, as with quantumphysics, all of these guidelines do not add up to a uniﬁed theory that holds truein all situations. So, rather like great art, there are exceptions that ﬂaunt theoryyet appear to work well. Hence there is great need for further research.3Subjectivity of resultsWhen any new understanding is generated as a result ofusing visualization it is of an informal nature and can be difﬁcult to representand communicate in an objective way. Contrast this with statistical inferencewhere quantiﬁable results are produced, often with a known signiﬁcance andreliability that can be communicated to others in a commonly understood, uni-versal language. However, this may be a strength as well as a weakness becausethe ﬁndings are not restricted to what can be said with statistical methods, butinstead by what can be observed and understood by the user.The International Cartographic Association (ICA) Commission on Geovisualizationdivides its research initiatives into four thematic areas: representation, knowledgediscovery, interfaces and cognition-usability (http://www.ica.org). Details of pro-gress and barriers are provided by MacEachren and Kraak (2001) and Dykes,MacEachren, and Kraak (2005).The FutureThe future will no doubt see many new multivariate visualization techniques proposed,and hopefully accompanied by improvements in tool availability and integration.The following list of developments also seems probable at the time of writing.1Increased use of immersive visualization environments such as caves and datawalls (Isakovic, Dudziak, and Köchy 2002) that can provide a good deal moredisplay real-estate and hence can visualize greater amounts of data. These envir-onments are usually large enough to accommodate groups of researchers whocan then collaborate in the shared visual spaces;2Personal augmented reality (glasses, retinal projection), coupled with access towireless geographic databases will allow visualization to move out of the laborat-ory and into the real world (Hedley, Billinghurst, Postner, May, and Kato 2004);3Further integration of visualization tools within the process of data mining, toimprove knowledge discovery (for example, Keim and Kriegel 1996, Ribarsky,Katz, and Holland 1999, Guo, Peuquet, and Gahegan 2003).4Bigger screens and better computers may appear to provide access to more data,but the pressing need to consider other limiting factors, such as perception, cognition, and the lack of formal models must be considered concurrently.5Better integration with other analysis approaches, such as machine learning, statistics, spatial analysis and GIS. There is already a trend to include visual-ization tools in GIS, and map rendering capabilities in visualization, statisticsand mathematical software environments.THO_C16  20/03/2007  15:12  Page 311 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f312MARK GAHEGAN6Development of standards to encode how geovisualization and map displaysappear, so that appearance can be saved and shared more effectively. The OpenGIS Consortium has already made signiﬁcant progress in this regard with theirStyled Layer Description (SLD) standard (OpenGIS 2002).7Increasing development and use of on-demand geovisualization tools that arehighly adaptable to the current needs of users, rather than relying on visual-izations that are custom-made, highly specialized and expensive to produce (Kraak 1998).ACKNOWLEDGEMENTSThe visualization examples shown are all the work of undergraduates, graduates,researchers, and faculty within the GeoVISTA Center at Penn State (http://www.geovista.psu.edu). The research leading to their production was funded in part by grants from the National Science Foundation, National Cancer Institute,and Centers for Disease Control; support from these organizations is gratefullyacknowledged.ENDNOTES1Exactly how this happens is known as the “binding problem.” For an informal descrip-tion of binding and a most intriguing optical illusion see the online article Tricks theBrain Plays, (http://www.npr.org/features/feature.php?wfId=1902700), from the radio show“All Things Considered”, May 19 2004, National Public Radio (NPR), USA.2It is possible to use animation in a book by placing a series of images at the outside corners of pages, one to each page",
    "chunk_order_index": 191,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-72530ea6339f6e6196f82980880d7c81": {
    "tokens": 1200,
    "content": "the “binding problem.” For an informal descrip-tion of binding and a most intriguing optical illusion see the online article Tricks theBrain Plays, (http://www.npr.org/features/feature.php?wfId=1902700), from the radio show“All Things Considered”, May 19 2004, National Public Radio (NPR), USA.2It is possible to use animation in a book by placing a series of images at the outside corners of pages, one to each page. If images progressively differ from each other in subtle ways, then ﬂipping through the pages can convey the notion of a “movie.” SeePilkey (1999) for another form of manual animation using books.REFERENCESAndrienko, G. L. and Andrienko, N. V. 1999. Interactive maps for visual data exploration.International Journal of Geographic Information Science13: 355–74.Andrienko, N., Andrienko, G., Voss, H., Bernardo, F., Hipolito, J., and Kretchmer, U. 2002.Testing the usability of interactive maps in common GIS. Cartography and GeographicInformation Science29: 325–42.Arnheim, R. 1974. Art and Visual Perception. Berkeley, CA: University of California Press.Asimov, D. 1985. The grand tour: A tool for viewing multidimensional data SIAM. Journalof Science and Statistical Computing6: 28–143.Bertin, J. 1967. Semiologie Graphique. Paris: Mouton.Bertin, J. 1981. Graphics and Graphic Information Processing. Berlin: Walter de Gruyter.Bertin, J. 1983. A new look at cartography. In D. R. F. Taylor (ed.) Progress in Contem-porary Cartography: Graphic Communication and Design in Contemporary Cartography.New York: John Wiley and Sons, pp. 69–86.Brewer, C. A. 1997. Evaluation of a model for predicting simultaneous contrast on colormaps. Professional Geographer49: 280–94.THO_C16  20/03/2007  15:12  Page 312 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION313Buttenﬁeld, B., Flewelling, D., Gahegan, M., Miller, H., and Yuan, M. 2004. Geospatialdata mining and knowledge discovery. In R. B. McMaster and E. L. Usery (eds) A ResearchAgenda for Geographic Information Science.Boca Rotan, FL: CRC Press, pp. 365–88.Cleveland, W. S. 1993. Visualizing Data. Summit, NJ: Hobart Press.Cleveland, W. S. and McGill, M. E. 1988. Dynamic Graphics for Statistics. Belmont, CA:Wadsworth & Brookes/Cole.Cook, D., Buja, A., Cabrera, J., and Hurley, C. 1995. Grand tour and projection pursuit.Computational and Graphical Statistics4: 155–72.Cook, D., Majure, J. J., Symanzik, J., and Cressie, N. 1996. Dynamic graphics in a GIS:Exploring and analyzing multivariate spatial data using linked software. ComputationalStatistics11: 467–80.Dent, B. D. 1998. Cartography: Thematic Map Design(5th edn). New York: McGraw Hill.DiBiase, D. 1990. Visualization in the earth and mineral sciences. Bulletin of the College ofEarth and Mineral Sciences, Penn State University59: 13–8.Dorling, D. 1994. Cartograms for Visualizing Human Geography. In D. J. Unwin and H. M. Hearnshaw (eds) Visualization in Geographical Information Systems.London: JohnWiley and Sons: 85–10.Dykes, J. A. 1996. Dynamic maps for spatial science: A Uniﬁed approach to cartographicvisualization. In D. Parker (ed.) Geographical Information Systems 3. London: Taylor andFrancis, pp. 171–81.Dykes, J. A., MacEachren, A. M., and Kraak, M. J. (eds). 2005. Exploring Geovisualization.Amsterdam: Elsevier.Egbert, S. L. and Slocum, T. A. 1992. ExploreMap: An exploration system for choroplethmaps. Annals of the Association of American Geographers82: 275–88.Fabrikant, S. I. 2000. Spatialization browsing in large data archives. Transactions in GIS4: 65–78.Fabrikant, S. I. and Skupin, A. 2005. Cognitively plausible information visualization. In J. A. Dykes, A. M. MacEachren, and M. J. Kraak (eds) Exploring Geovisualization.Amsterdam: Elsevier, pp. 667–90.Foley, J. 2000. Getting There: The Ten Top Problems Left. WWW document, http://www.computer.org/cga/articles/topten.htm.Gahegan, M. N. 1998. Scatterplots and",
    "chunk_order_index": 192,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-cbb3495d63e71ed7de91597f0d5ec320": {
    "tokens": 1200,
    "content": "Cognitively plausible information visualization. In J. A. Dykes, A. M. MacEachren, and M. J. Kraak (eds) Exploring Geovisualization.Amsterdam: Elsevier, pp. 667–90.Foley, J. 2000. Getting There: The Ten Top Problems Left. WWW document, http://www.computer.org/cga/articles/topten.htm.Gahegan, M. N. 1998. Scatterplots and scenes: Visualisation techniques for exploratory spatial analysis. Computers, Environment and Urban Systems21: 43–56.Gahegan, M. N. 1999. Four barriers to the development of effective exploratory visualiza-tion tools for the geosciences. International Journal of Geographical Information Science13: 289–310.Gahegan, M. N. 2003. Is inductive machine learning just another wild goose (or might it lay the golden egg?). International Journal of Geographical Information Science17: 69–92.Gahegan, M. N. 2005. Beyond tools: Visual support for the entire process of GIScience. In Dykes, J. A., MacEachren, A. M., and Kraak, M. J. (eds) Exploring Geovisualization.Amsterdam: Elsevier, pp. 83–99.Gahegan, M., Wachowicz, M., Harrower, M., and Rhyne, T. 2001. The integration of geographic visualization with knowledge discovery in databases and geocomputation.Cartography and Geographic Information Science28: 29–44.Gahegan, M., Takatsuka, M., Wheeler, M., and Hardisty, F. 2002. GeoVISTA Studio: Ageocomputational workbench. Computers, Environment and Urban Systems26: 267–92.Glassner, A. S. 1989. An Introduction to Ray Tracing. San Fransisco, CA: MorganKaufmann.Graham, M., Watson, M. F., and Kennedy, J. B. 2002. Novel visualisation techniques forworking with multiple, overlapping classiﬁcation hierarchies Taxon51: 351–8.THO_C16  20/03/2007  15:12  Page 313 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f314MARK GAHEGANGreen, D. R. and Horbach, S. 1998. Colour: Difﬁcult to both choose and use in practice.Cartographic Journal35: 169–80.Grinstein, G. and Levkowitz, H. 1995. Perceptual Issues in Visualisation. Berlin: Springer-Verlag.Guo, D., Peuquet, D., and Gahegan, M. 2003. ICEAGE: Interactive clustering and explora-tion of large and high-dimensional geodata. GeoInformatica7: 229–53.Haslett, J., Bradley, R., Craig, P., Unwin, A., and Wills, G. 1991. Dynamic graphics forexploring spatial data with application to locating global and local anomalies. AmericanStatistician45: 234–42.Hedley, N. R., Billinghurst, M., Postner, L., May, R., and Kato, H. 2004. Explorations inthe use of augmented reality for geographic visualization. Presence: Teleoperators and VirtualEnvironments11: 119–33.Hinneburg, A., Keim, D., and Wawryniuk, M. 1999. HD-Eye: Visual mining of high dimen-sional data. IEEE Computer Graphics and Applications19(5): 22–31.Hix, D. and Hartson, H. R. 1993. Developing User Interfaces: Ensuring Usability throughProduct and Process. New York: John Wiley and Sons.Inselberg, A. 1985. The plane with parallel coordinates. The Visual Computer1: 69–97.Inselberg, A. 1997. Multidimensional detective. In Proceedings of IEEE Conference onVisualization (Visualization ’97), Los Alamitos, CA, USA. Los Alamitos, CA: Institute ofElectrical and Electronics Engineers.Isakovic, K., Dudziak, T., and Köchy, K. 2002. X-Rooms: A PC-based immersive visualiza-tion environment. InProceedings of the Web3D Symposium, Tempe, AZ, USA. New York:Association of Computing Machinery.Karssen, A. J. 1980. The artistic elements in map design. Cartographic Journal17: 124–7.Keim, D. and Kriegel, H.-P. 1996. Visualization techniques for mining large databases: Acomparison. IEEE Transactions on Knowledge and Data Engineering8: 923–8.Koch, C. and Ullman, S. 1985. Shifts in selective visual attention: Towards the underlyingvisual circuitry. Human Neurobiology4: 219–27.Kohonen, T. 1997. Self-Organizing Maps. Berlin: Springer-Verlag.Kosara, R., Healey, C. G., Interrante, V., Laidlaw, D. H. V., and Ware, C. 2003. User Studies:Why, how, and when? IEEE Computer Graphics and Applications23(4): 20",
    "chunk_order_index": 193,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d8ff86694f331e76b5299915b46dfb51": {
    "tokens": 1200,
    "content": "in selective visual attention: Towards the underlyingvisual circuitry. Human Neurobiology4: 219–27.Kohonen, T. 1997. Self-Organizing Maps. Berlin: Springer-Verlag.Kosara, R., Healey, C. G., Interrante, V., Laidlaw, D. H. V., and Ware, C. 2003. User Studies:Why, how, and when? IEEE Computer Graphics and Applications23(4): 20–5.Kraak, M. J. 1998. The cartographic visualization process: From presentation to exploration.Cartographic Journal35: 11–5.Landa, R. 2004. Advertising by Design: Creating Visual Communications with Graphic Impact.New York: John Wiley and Sons.Livingstone, M. and Hubel, D. 1988. Segregation of form, colour, movement and depth:Anatomy, physiology and perception. Science240: 740–9.MacDougall, E. B. 1992. Exploratory analysis, dynamic statistical visualisation and geographicinformation systems. Cartography and Geographical Information Systems19: 237–46.MacEachren, A. M. 1994. Time as a cartographic variable. In H. M. Hearnshaw and D. J. Unwin (eds) Visualisation in Geographical Information Systems.Chichester: JohnWiley and Sons: 115–30.MacEachren, A. M. 1995. How Maps Work.New York: Guilford Press.MacEachren, A. M. and Kraak, M. J. 2001. Research challenges in geovisualization. Carto-graphy and Geographic Information Science 28: 3–12.MacEachren, A. M., Dai, X., Hardisty, F., Guo, D., and Lengerich, G. 2003. Exploring high-d spaces with multiform matricies and small multiples. In Proceedings of the InternationalSymposium on Information Visualization, Seattle, WA, USA. Los Alamitos, CA: Instituteof Electrical and Electronics Engineers.MacEachren, A. M., Gahegan, M., and Pike, W. 2004. Geovisualization for constructing and sharing concepts. Proceedings of the National Academy of Science101, Supplement1: 5279–86.THO_C16  20/03/2007  15:12  Page 314 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fMULTIVARIATE GEOVISUALIZATION315Mackinlay, J. D. 1986. Automating the design of graphical presentations of relational informa-tion. ACM Transactions in Graphics5: 110–41.Maeder, A. 1997. Human understanding limits in visualisation. In T. Caelli, P. Lam, andH. Bunke (eds) Spatial Computing: Issues in Vision, Multimedia and Visualisation Tech-nologies.Singapore: World Scientiﬁc, pp. 229–37.Mardia, K. V., Kent, T., and Bibby, J. M. 1979. Multivariate Analysis. London: AcademicPress.McGuinness, C. 1994. Expert/Novice Use of Visualization Tools. In A. M. MacEachren andD. R. F. Taylor (eds) Visualization in Modern Cartography.New York: Elsevier, pp. 185–99.McLeod, A. I. and Provost, S. B. 2001. Multivariate data visualization. In A. H. El-Shaarawiand W. W. Piegorsch (eds) Encyclopedia of Environmetrics.Somerset, NJ: John Wiley andSons, pp. 1333–44.Miller, N. E., Wong, P. C., Brewster, M., and Foote, H. 1999. Topic Islands™: A wavelet-based text visualization system. In Proceedings of the IEEE Symposium on InformationVisualization (Infoviz 2000), Salt Lake City, UT.Miller, H. and Han, J. (eds). 2001. Knowledge Discovery with Geographic Information.London: Taylor and Francis.Monmonier, M. 1989. Geographic brushing: Enhancing exploratory analysis of the scatter-plot matrix. Geographical Analysis21: 81–4.Monmonier, M. S. 1990. Strategies for the interactive exploration of geographic correlation.In Proceedings of the Fourth International Symposium on Spatial Data Handling, Zurich,Switzerland.Muehrcke, P., Muehrcke, J., and Kimerling, A. 2001. Map Use: Reading, Analysis and Inter-pretation(4th edn). Madison, WI: JP Publications.Mutton, P. and Golbeck, J. 2003. Visualization of semantic metadata and ontologies. InSeventh International Conference on Information Visualization (IV03), London, UnitedKingdom: 300–5.Noll, A. M. 1967. A computer technique for displaying n-dimensional hyperobjects.Communications of the Association for Computing Machinery10: 469–73.North, C. and Shneiderman, B. 1999. Snap-together Visualization: Coordinating MultipleViews to Explore Information.College Park, MD: University of Maryland, Computer ScienceDepartment Technical Report No. CS-TR-4020.Nyerges, T.",
    "chunk_order_index": 194,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7a657858c1d3610fcbf9ac4e45141cc4": {
    "tokens": 1200,
    "content": "UnitedKingdom: 300–5.Noll, A. M. 1967. A computer technique for displaying n-dimensional hyperobjects.Communications of the Association for Computing Machinery10: 469–73.North, C. and Shneiderman, B. 1999. Snap-together Visualization: Coordinating MultipleViews to Explore Information.College Park, MD: University of Maryland, Computer ScienceDepartment Technical Report No. CS-TR-4020.Nyerges, T. L., Moore, T. J., Montejano, R., and Compton, M. 1998. Interaction codingsystems for studying the use of groupware. Journal of Human–Computer Interaction13:127–65.Open GIS Consortium. 2002. Styled Layer Descriptor Implementation Speciﬁcation. WWWdocument, http://www.opengis.org/docs/02-070.pdf.Pickett, R. M. and Grinstein, G. G. 1988. Iconographic displays for visualizing multidimen-sional data. InProceedings of the IEEE Conference on Systems, Man and Cybernetics,Piscataway, NJ, USA.Pike, W. and Gahegan, M. 2003. Constructing semantically scalable cognitive spaces. In W. Kuhn, M. Worboys, and S. Timpf (eds) Spatial Information Theory: Foundations ofGeographic Information Science. Berlin: Springer-Verlag Lecture Notes in Computer ScienceNo. 2825: 332–48.Pilkey, D. 1999. Captain Underpants and the Attack of the Talking Toilets. New York:Scholastic Books.Plaisant, C. 2005. Information visualization and the challenge of universal access. In J. Dykes,A. M. MacEachren, and M. J. Kraak (eds) Exploring Geovisualization.Amsterdam: Elsevier,pp. 53–82.Quinlan, R. 1993. C4.5: Programs for Machine Learning.San Mateo, CA: Morgan Kaufmann.Ribarsky, W., Katz, J., and Holland, A. 1999. Discovery visualization using fast clustering.IEEE Computer Graphics and Applications19(5): 32–9.THO_C16  20/03/2007  15:12  Page 315 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f316MARK GAHEGANRobertson, G., Mackinlay, J., and Card, S. 1991. Cone trees: Animated 3D visualizationsof hierarchical information. InProceedings of Human Factors in Computing Systems(CHI’91), New York.Robertson, P. K. 1997. Visualizing spatial data: The problem of paradigms. InternationalJournal of Pattern recognition and Artiﬁcial Intelligence11: 263–73.Rousseeuw, P. J., Ruts, P. J., and Tukey, J. W. 1999. The bagplot: A bivariate boxplot.American Statistician53: 382–7.Sammon, J. W. 1969. A nonlinear mapping for data structure analysis. IEEE Transactionson Computers, Series C18: 401–9.Scott, D. W. 1992. Multivariate Density Estimation: Theory, Practice and Visualization. NewYork: John Wiley and Sons.Shneiderman, B. 1998. Designing the User Interface: Strategies for Effective Human–Computer Interaction. Reading: MA, Addison-Wesley.Slocum, T. A., Blok, C., Jiang, B., Koussoulakou, A., Montello, D., Fuhrmann, S., and Hedley, N. R. 2001. Cognitive and usability issues in geovisualization. Cartography and Geographic Information Science28: 61–75.Spitaleri, R. 1993. Reference models for computational visual simulations. In P. Palamidese(ed.) Scientiﬁc Visualization: Advanced Software Techniques.Chichester: Ellis-Horwood,pp. 3–14.Taylor, D. R. F. 1991. Geographic information systems: The microcomputer and moderncartography. In D. R. F. Taylor (ed.) Geographic Information Systems: The Microcomputerand Modern Cartography.Oxford: Pergamon, pp. 1–20.Treisman, A. 1986. Features and objects in early vision. Scientiﬁc American: 114B–25.Tufte, E. R. 1990. Envisioning Information. Cheshire, CT: Graphics Press.Vredenburg, K., Isensee, S., and Righi, C. 2002. User-Centred Design. Upper Saddle River,NJ: Prentice-Hall.Wood, M. 1990. Map perception studies. In C. R. Perkins and R. B. Parry (eds) InformationSources in Cartography.London: Bowker-Saur: 441–52.THO_C16  20/03/2007  15:12  Page 316 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by",
    "chunk_order_index": 195,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-eb6fac49c33a970a48f0272d61c10330": {
    "tokens": 1200,
    "content": "ondon: Bowker-Saur: 441–52.THO_C16  20/03/2007  15:12  Page 316 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 17Virtual Reality in GeographicInformation SystemsMichael BattyVirtual reality (VR) emerged as part of the extension of computing into graphicswhich began to accelerate with the advent of the microprocessor and its widespreaduse in personnel computers, workstations, and supercomputers. Sometime in themid-1980s, Jaron Lanier coined the term to describe the kinds of virtual environ-ments popping up everywhere in which users had begun to hook themselves intocomputers in such as way that what they saw, heard, and touched was a productof the machine’s simulation (Rheingold 1991). The visual was the most importantof these sensory experiences, and, approaching 2010, the typical portrait of VR isstill the 3D world in which the user is immersed and able to navigate amongst movable objects. But as computers have fused with networks, the concept of VRhas blurred, and no longer does the term imply total immersion in the machine’ssimulation. A more general deﬁnition from the computer and internet encyclopediaWebopediais “an artiﬁcial environment created with computer hardware and software and presented to the user in such a way that it appears and feels like areal environment” (see http://www.webopedia.com/TERM/V/virtualreality.html foradditional details). Today the term is used to describe many experiences in environ-ments which exist on everything from the desktop to the net.We need to be a little more speciﬁc about how we are beginning to use the term in GI Science for the complete panoply of environments, media, and electronicperipherals used to generate as many sensory experiences as possible (fully-ﬂedgedVR) have not yet been widely exploited in our ﬁeld. In fact GI Science is largelygraphical, rooted in the 2D space, the map, extending into 3D, and even into thetemporal dimension, but with little use of more esoteric virtual environment hard-ware and media. The main distinction we must make at the outset is one of abstrac-tion: VR technologies can be and are being exploited in two directions, ﬁrst withrespect to how we interact with analytical conceptions of space, with surfaces andtheir properties in terms of their statistics, and, second, with respect to much morerealistic conceptions of space in terms of landscapes where the quest for simulatedrealism is to the fore. In a sense, this is the difference between geographic and geo-metrical analysis, the difference between navigating in mathematical space and itsTHO_C17  20/03/2007  15:13  Page 317 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f318MICHAEL BATTYvarious transforms in contrast to interacting with the Euclidean space of the three-dimensional world in which we live. Of course, GI Science spans the route betweenboth conceptions of space, but the development of VR along this continuum marksout rather difference styles and methods that we need to consider.In essence, VR here is limited to that constellation of users and technologies thatenable interactions within a visual environment. Indeed, a good working deﬁnitionof VR is “visualization +interaction +motion” where motion implies that user movesand consciously manipulates the environment in some way. Interaction is more thanpassive in that users continuously respond to cues within the environment whichis conﬁgured for some particular task ranging from entertainment to scientiﬁc research.In this sense, interactivity is the watchword of VR, and it is not surprising that thisdomain has been dominated by the development of computer-aided environmentsoriented to design and problem-solving. In this sense, spatial, particularly ﬁne-scaledesign, such as computer-aided architecture design, has ﬁgured prominently in thedevelopment of VR.The environments we will present here begin with two-dimensional space which canbe treated geographically and/or geometrically. Before we begin to deﬁne the shapeand content of these environments, it is worth charting the range of possibilities andin this, we will deﬁne two continua – from real to virtual space and from real tovirtual users. Real space is the environment in which we live, while virtual space, isits digital equivalent. In fact this continuum does not speciﬁcally pick up the level ofabstraction in which real space is transformed to digital and it tends to exclude thoseﬁctional virtual realities that have no equivalent in the real world. Nevertheless, wewill assume that virtual space covers all types of digital abstractions based on varyingdegrees of ﬁction. Real users are ourselves while their virtual equivalents can be bothvirtual renditions of ourselves – so called avatars of which we show examples below:agents that mirror the requirements of real users, or robots that are under our control.We picture these continua in Table 17.1 where the grey tones indicate that the twokinds of environment involve virtual space which is populated by real users andtheir virtual equivalents. In GI Science, these virtualities exist at different levels ofabstraction from relatively realistic rend",
    "chunk_order_index": 196,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9e8708f856c3da329161995f6b193ba8": {
    "tokens": 1200,
    "content": "ﬁction. Real users are ourselves while their virtual equivalents can be bothvirtual renditions of ourselves – so called avatars of which we show examples below:agents that mirror the requirements of real users, or robots that are under our control.We picture these continua in Table 17.1 where the grey tones indicate that the twokinds of environment involve virtual space which is populated by real users andtheir virtual equivalents. In GI Science, these virtualities exist at different levels ofabstraction from relatively realistic renditions of landscape and urban scenes to moreabstract geographic models of how those same spaces function and operate.Table 17.1Virtual environments deﬁned in terms space and usersReal usersReal and virtual usersVirtual usersReal spaceEnvironments in whichWe Live...Populated by Robots,e.g., Hazardous,Remote EnvironmentsReal and virtual space…………Augmented Realities…………Virtual spaceDigital Environments in which Real UsersInteract...Real Users As Avatars,or Real Users ActingThrough AgentsTHO_C17  20/03/2007  15:13  Page 318 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fVIRTUAL REALITY IN GIS319When VR systems were ﬁrst developed in the 1980s, the virtual worlds were theexclusive domain of single users but two developments have exploded this into multi-user worlds. First, there are specialist hardware/software environments in which morethan a single individual can engage immersively such as VR theaters, CAVES,1andso on. Second, the convergence of computers with networks has opened a veritablePandora’s Box of possibilities for many users to interact with each other throughshared environments in remote locations. We will note these different media below,but this array of possible interactive environments also leads to the idea that multiplevirtual worlds can be arranged recursively where real users can take on a varietyof virtual personas in building interactions with on another across many levels.Virtual realities are always constructed with some purpose in mind, and thus the way users interact with the environment, and with each other, is essential to the way such realities are engaged. In GI Science, navigation through the virtualspace is crucial – but navigation is simply a means to an end that involves sometask which enables the properties of elements and objects that comprise the virtualreality to be extracted. Virtual environments are usually constructed either for design or for understanding in circumstances in which analysis is an important component of their construction. For example, ﬂying though the virtual equivalentof a real landscape might be geared to exploring the properties of landscape notonly in immediate visual terms but in terms of statistical relationships and patterns.Such environments may mix many kinds of space – from geographic to geometricbut also various transforms of these spaces into non-traditional structures nolonger represented as 2D or 3D map-like spaces. Frequently, such worlds are com-posed of many windows with only a limited number of these representing the 2Dand 3D map-like spaces. Frequently such worlds are composed of many windowswith only a limited number of these representing the 2D map or 3D extrusion fromthe map. Graphs, ﬂow charts, and related iconography may be equally importantas maps in such worlds where many of the graphic and statistical tools presentedelsewhere in this book, can be exploited.In the remainder of this chapter, we will examine three related aspects of VR for GIS. First, we will look at typical environments that use the third dimensionastheir essential organizing concept for visual interaction. Second, we will look atdifferent media – hardware and software for VR, noting the cornucopia of environ-ments form the desktop to the headset and from the theater to the net. Third, wewill look at the way VR can be fashioned as an interface to GIS and show howthe concept is changing as graphics and other sensory media are fast becoming routine in human–computer interaction. These three facets of VR lead to new possibilities for using digital simulations in diverse ways for design. We will con-clude with some suggestions as to how such virtual realities can be grounded inmore “concrete” realities, thus giving back to analysis some of the tangibility thatthe digital domain removes.Environments for VR: The Third Dimension and BeyondThe 3D geometric environment – rooms, buildings, cities, natural landscapes, andso on – represent the quintessential examples of VR. Many deﬁnitions of the termTHO_C17  20/03/2007  15:13  Page 319 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f320MICHAEL BATTYreﬂect the fact that the third dimension is all important in enabling users to trulyimmerse themselves in the digital environment. Most of the action to date, how-ever, in urban environments has come from computer-aided architectural design.Computer-aided design (CAD) software has been increasingly used to manufacturesuch environments although since the mid-1990s, as multimedia techniques haveexploded, such environments have been built using much more ad hoctechniqueswhich mix many types and ﬂavors of software. In terms of GI Science, GIS haveslowly moved to embrace the third dimension with most propriety packages nowoffering quite elaborate surface generating techniques based on spatial interpolation.Since the late 1990",
    "chunk_order_index": 197,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f794fc2fef3ce93ac32e3e1020409eab": {
    "tokens": 1200,
    "content": "architectural design.Computer-aided design (CAD) software has been increasingly used to manufacturesuch environments although since the mid-1990s, as multimedia techniques haveexploded, such environments have been built using much more ad hoctechniqueswhich mix many types and ﬂavors of software. In terms of GI Science, GIS haveslowly moved to embrace the third dimension with most propriety packages nowoffering quite elaborate surface generating techniques based on spatial interpolation.Since the late 1990s, 3D extrusion from the map to the cityscape or landscape hasbecome possible, thus providing geometric frameworks in which spatial data can bequeried and displayed in 3D, just as such techniques have become the workhorseof routine 2D GIS applications. In fact, there are extremely rapid developments in 3D GIS at present, as we will note in a later section. There is now little doubtthat the functionality that such systems offer in building such environments is con-siderably richer than the rather vacuous CAD methods that emphasize renderingrather than geometric database construction to which spatial attributes can be associated (Batty, Dodge, Doyle, and Smith 1998).In a sense, the 3D graphic environments that can now be produced easily using GIS do not constitute virtual reality. They may be the basis for constructingvirtual realities but such realities in the narrow sense depend upon how the user is immersed in the environment and this depends on the hardware and softwareused to make such environments work. In a broad sense of course, ﬂying througha 3D model on the desktop might be considered part of VR (and increasingly is so as the deﬁnition continues to broaden) but it is worth keeping such graphicsseparate from the media of communication and interaction. In the past, there havebeen quite severe limits on what 3D GIS can handle, although these are fast beingresolved. In particular, while moving through the model, detailed rendering has either not been possible or has been only primitive whether on-the-ﬂy or using pre-determined ﬂight paths. In current generations of software, all these limits are beingrelaxed while the size of the environment that can be handled is being massivelyincreased through better hardware and software. Embedding other kinds of multi-media into such environments such as panoramas has become possible (Shiffer 2001)and for the ﬁrst time, it looks at through 3D GIS is becoming the preferred mediumfor such model construction.Our own example of this is “Virtual London.” This is based on 20 km2of centralLondon where the 45,000 buildings within the Ordnance Survey’s MasterMapprod-uct are extruded to average building heights using LiDAR data from InfoTerra. The model sits on a digital terrain layer and currently data for the buildings reﬂect-ing land use, tenure, ﬂoorspace, rental levels, and so on are being ported into themodel as layers. The block model is built in ArcScenebut more detailed renditionsof certain buildings are produced photogrammetrically and then embedded in themodel as we show in Figures 17.1(a) and (b). In fact this is only on part of the virtual environment for much additional multimedia ranging from digital panoramasto fast zoomable and clickable maps are associated with the project. This informa-tion is not delivered to the user as a 3D GIS for this would require fast, memoryintensive hardware well beyond the resources of the casual user. Instead, variousTHO_C17  20/03/2007  15:13  Page 320 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFig. 17.1(a) The basic geometric model built in ArcSceneand (b) an example of a ﬁnely renderedbuilding imported into the scene(a)(b)THO_C17  20/03/2007  15:13  Page 321 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f322MICHAEL BATTY3D products are being manufactured from the base model. Moreover the softwareused is not restricted to GIS but embraces standard CAD and diverse rendering andphotogrammetric techniques. The preferred medium in which to deliver VirtualLondon to users is over the net, and thus net-based CAD, which is still rooted inVirtual Reality Modeling Language (VRML)-type languages, also plays a part.We shall return later to ways in which we can make this model “virtual” in thenarrow sense but we must now consider more abstract renditions of 2D virtual spacewhich are more strongly linked to GI Science than to GIS. Since the late 1980s,one of the main structures within GIS has been the notion of the layer. Landscapesare considered as layers of different activity and ways of generalizing, smoothing,interpolating both real and abstract properties of these landscapes have been evolved.In particular, interpolation of point patterns into gridded surfaces are now widelyavailable in GIS. Methods of doing this are still being researched intensively as spatial properties such as autocorrelation, local variance, and such like are importantin producing good generalizations. In a sense, the surfaces produced are geographicrather than geometric. The biggest",
    "chunk_order_index": 198,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a731dbf87deeb6a103e8371e390b1e15": {
    "tokens": 1200,
    "content": "the layer. Landscapesare considered as layers of different activity and ways of generalizing, smoothing,interpolating both real and abstract properties of these landscapes have been evolved.In particular, interpolation of point patterns into gridded surfaces are now widelyavailable in GIS. Methods of doing this are still being researched intensively as spatial properties such as autocorrelation, local variance, and such like are importantin producing good generalizations. In a sense, the surfaces produced are geographicrather than geometric. The biggest development in GI Science which has generatedVR-like systems is the idea that different windows on such surfaces can be producedwithin the viewing environment. The notion of taking different renditions of the mapor surface represented in both 2D and 3D and displaying its properties using moreabstract spaces – graphs, networks, ﬂow charts, and so on – displayed in windowslinked to the basic surface are now widely used as part of spatial statistical software.There are few proprietary systems which take these display mechanisms as far as thenarrower form of VR but there are examples in which such windowing has beenreported into artiﬁcial environment such as CAVES and VR theaters. The work of theGeoVistagroup at Penn State has pioneered developments in this area (for example,MacEachren 2001; see Chapter 16 by Gahegan in this volume for additional detailsas well), but it is important to stress that such developments are hard to classifyand generalize as applications in VR generally are eclectic.What is beginning to happen, however, is the mixing of geographic with geo-metric realities. In one sense, this might be seen as simply putting geographic andgeometric layers together to search for coincidences, correlations and patterns butthe fact that 3D GIS is now driving so much of this ﬁeld means that users of geo-metric environments can be treated to glimpses of their geographic equivalents andvice versa. We are a long way from truly embedding geographic attributes into thereal geometry of the 3D world and in one sense, our perspectives from each of thesedirections are not very well-developed conceptually (Batty 2000). But the ability to switch layers on and off in virtual environments give us the power to associateradically different conceptions and in one sense that is what VR is all about – evoking unusual and perceptive insights into real environments through the virtual.In Figure 17.2, we show an example of how a rather abstract surface of the intensityof retailing activity is overlaid and viewed translucently on the 3D geometry of central London with the higher buildings poking through this sea of retailing. Ourabilities to deal with these intersections and layering are far from perfect but weconsider this to be the way forward in VR for GI Science.Before we move to VR media, we should say a little about how to navigate insuch 3D environments. Navigation is always problematic as there is a steep learn-ing curve for most software. 3D GIS still tends to offer bird’s eye rather than detailedTHO_C17  20/03/2007  15:13  Page 322 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fVIRTUAL REALITY IN GIS323ground level viewing in contrast to CAD where ground level movement is easier.This is changing but in delivering most 3D environments, navigation needs to berestricted and thus predetermined ﬂight paths are the rule rather than the exception.Much depends of course on the complexity of the environment but as the geometrybecomes more intricate, navigation skills become more important. This is in con-trast to the wider user interface which relates to why the user is immersed in theenvironment in the ﬁrst place but this too can interact with our ability to navigate.Currently our knowledge of best practice in this area is primitive and this does represent a constraint on applications of such technologies. In Figure 17.3, we showa typical scene in the block model of Virtual London from predetermined ﬂy-throughalong the river.Media for Delivering VR: Headsets, CAVE, Theaters, NetsThe oldest VR simulations were based on immersing the user in the virtual envir-onment, usually a 3D scene, in such way that the user is part of the machine whichgenerates the “whole body experience”. The real world is excluded as the user ishooked to the machine and its software by a helmet or similar device which is con-ﬁgured so the user is part of the visual scene being simulated. Sometimes there areother sensory input and output, particular touch the simulated through data gloves,and hearing transmitted within the helmet. Part and parcel of the scene is the abilityFig. 17.2A geographic “sea” showing the intensity of retail activity layered onto the 3D geometryof central LondonTHO_C17  20/03/2007  15:13  Page 323 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f324MICHAEL BATTYto engage in two-way interaction, not passively but actively invoking changes in theelements comprising the scene. By the early 1990s, the idea that two or more userscould be connected together, adding interactions between themselves as well as withinthe environment in which they were moving,",
    "chunk_order_index": 199,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-8d7e3b86cc9456115c0dad263bb520f1": {
    "tokens": 1200,
    "content": "(https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f324MICHAEL BATTYto engage in two-way interaction, not passively but actively invoking changes in theelements comprising the scene. By the early 1990s, the idea that two or more userscould be connected together, adding interactions between themselves as well as withinthe environment in which they were moving, became a powerful driver to new kindof hardware-software. The notion of the VR theater in which a collective of userscould interact with each other online and ofﬂine (for such theaters are real physicalsettings) as well as within the simulated environment, became cutting edge. Theseextensions opened the virtual world to external interactions. At the same time, thenotion of something closer to full immersion – the CAVE – was developed. CAVESare based on approximately 10 m3cubes on whose faces different elements of thevirtual environment are projected in synchronized fashion so that users standing inthe CAVE are literally within a closed physical world made virtual. Normal con-versation is possible as users see each other within the virtual scene.Since then a variety of other VR devices have been produced, in particular desk-top-like tables in which the scene is projected, holographic-like and users wearingglasses or helmets are synchronized with one other and with the scene. Howeverwhat has blown VR completely out of its original niche has been the net. As com-puting has drifted onto the net and as the dominant paradigm has veered towardscollective interactive computing over nets of various kinds, VR has adapted to letmany users take part in the same kinds of “out-of-body experience” that traditionalimmersive handset technologies allow. In fact, the sense of total exclusion can neverFig. 17.3A typical ﬂy-through in virtual London, west along the River ThamesTHO_C17  20/03/2007  15:13  Page 324 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fVIRTUAL REALITY IN GIS325be completely simulated on the desktop but the fact than many remote users linkedthrough the net can by synchronized is shared environments has produced new reac-tions and insights into the virtual world. The best examples of these environmentsare multi-user worlds. These initially began as gaming environments, multi-usersdomains/dungeons (MUDs), based on adventure style games, but involving moreconsidered “chat” rooms and bulletin boards. Their visual equivalents, of which themost well-known is AlphaWorld, enable players or users to construct and colonize,appearing as avatars and being able to chat with those also present in the world(Dodge 2002). These are quintessential examples of virtual users in virtual space.In part, the objects in those worlds can also have a degree of intelligence in thatthey can be molded to enable different functions to be generated, particularly withrespect to design (Smith 2002).There have been some limited experiments with such worlds in GI Science butmainly for purposes of controlled design rather than entertainment. In fact in ourVirtual London model, one way in which we are making the model available tousers is to take its contents and manipulate it in such a world in which is set up asa virtual planning forum, virtual design studio, or virtual exhibition hall. To give asense of what is possible, Figure 17.4 shows how digital panoramas as well as the digital block model of central London developed using 3D GIS can be used topopulate such a virtual world. Figure 17.4(a) shows the virtual exhibition hall withFigure 17.4(b) showing how one can walk from this into a more realistic renditionof a well-known galleria on London’s South Bank. A little further along the bankis City Hall and in Figure 17.4(c), we show the avatar walking onto the balconyof the Hall which overlooks the ﬁnancial quarter of the City across the river.This is the kind of media that is fast developing in the network world but so far, the nature of the user interaction has been somewhat informal and it remainsto be seen as to how GI Science might make use of such interactivity. In con-trast but with equally rapid development at present, wireless VR is being to makean impact. Of course whatever can be achieved over wires can in principle be developed wirelessly and the whole range of media from headset to CAVE to theater can be treated in this manner. In Figure 17.5, we show an example of how3D GIS which forms once again a virtual image of central London can be projectedwirelessly onto elaborate headsets which contain their own screens and which arelinked wirelessly to other users. The user can see the virtual model and any otherusers who might be interacting with it as in Figure 17.5(a) while in Figure 17.5(b)we see the entire segment of the block model that each user sees projected intotheir headset.These last two examples show how VR is still stretching the ways in which wecan interact with 3D environment but so far, the technology continues to dominate.Scientiﬁc applications are beginning but a lot more needs to be done on the pro-cess of user interaction as well as tailoring these methods to speciﬁcs applications(Schroeder, Huxor, and Smith 2001). We have remarked before that 3D GIS is a technology in search of a problem in that we have very little theory of the thirdd",
    "chunk_order_index": 200,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b2f44c19c2c0b02fea1c23d56fcdf182": {
    "tokens": 1200,
    "content": "stretching the ways in which wecan interact with 3D environment but so far, the technology continues to dominate.Scientiﬁc applications are beginning but a lot more needs to be done on the pro-cess of user interaction as well as tailoring these methods to speciﬁcs applications(Schroeder, Huxor, and Smith 2001). We have remarked before that 3D GIS is a technology in search of a problem in that we have very little theory of the thirddimension on which we are able to build the requisite functionality which is theworkhorse of 2D GIS (Batty 2000). In fact, 3D GIS is leading the way but the limitshere are small in comparison with VR technologies where applications are still largelyfocuses on demonstrating what is possible.THO_C17  20/03/2007  15:13  Page 325 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f326MICHAEL BATTYFig. 17.4Porting the digital model and various panoramas into a virtual world: (a) the “ﬁctional”exhibition space which has doors and/or windows into/onto, (b) a digital panorama of a “real”galleria which in (c) leads the avatar to City Hall which overlooks the “real” virtual city(a)(b)(c)THO_C17  20/03/2007  15:13  Page 326 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFig. 17.5The Arthur interface – viewing the virtual city in a multi-user wireless headset fullyimmersive environment: (a) another user, (b) the projected model within the headset fromhttp://www.ﬁt.fraunhofer.de/projeckte/arthur/index_en.xml(a)(b)VIRTUAL REALITY IN GIS327THO_C17  20/03/2007  15:13  Page 327 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f328MICHAEL BATTYVR as an Interface to GISIn one sense, VR is simply an interface, albeit one of the richest available, to systems in which human users are intimately involved, and which enable diverseperspectives on the system in question to be accessed in parallel or simultaneously.There is a temptation to think of all science and entertainment as being enabledby VR but the number of possible applications where the power of VR is not con-testable is quite small. In GI Science, VR has not been widely applied and muchof its power is in potential as yet unrealized. A glance at a recent survey of VR inGeography (Fisher and Unwin 2002) shows that current applications tend to stressVR with respect to visualization which is intrinsically geographic, rather than VR inGI Science or GI Science within VR. So far, although there are some useful examplesof how data structures, geographic representation, and spatial analysis more gener-ally can be enriched using VR, by far the majority of applications are like thosewe have illustrate here – geographic landscapes of various kinds which enable usersto search and visualize patterns in the broadest sense.One of the best examples of VR as an interface dates back almost ten years toa geographic visualization of trafﬁc on the Internet, constructed in real time andvisualized using the various screens deﬁned by the walls of a CAVE. Lamm, Reed,and Scullin (1996) pioneered such a real time display as an interface to the space-timeseries of Internet trafﬁc routed through the MOSAIC server at the National Centerfor Supercomputer Applications. Within the CAVE, the focus was on real time dis-play of the pulsating nature of trafﬁc on the globe but other windows within the CAVEdisplayed the data in numerical form as we show in the interface in Figure 17.6. Thefocus of the effort was an analysis of load balancing but the potential of systemslike this for visualizing any kind of electronic transactions are still enormous.Since the mid-1990s, VR systems based on elaborate immersive hardware havebecome more usual generating much less hype than before. In fact as VR has spreadout of these environments and onto the net, many of interfaces to desktop- andnet-based software originally pioneered in headsets and theaters, are being adaptedto stand-alone software. An excellent example of this which is one of the newestadditions to ESRI’s ArcGISfamily of software, is ArcGlobewhich lets users mapany geographic ﬁle, suitably projected and tagged to the globe, thus enabling a clear analysis of scale to be imposed on any problem. ArcGlobeprovides a “revolutionary way to support multi-resolution global data visualization in 3D”(ESRI 2003) and integrates with a variety of ﬁles formats which are common inVR such as VRML, 3D Studio Max, and Open Flight. In",
    "chunk_order_index": 201,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e80bc734d3ccd7626a9ff8eceaba3b6f": {
    "tokens": 1200,
    "content": "GISfamily of software, is ArcGlobewhich lets users mapany geographic ﬁle, suitably projected and tagged to the globe, thus enabling a clear analysis of scale to be imposed on any problem. ArcGlobeprovides a “revolutionary way to support multi-resolution global data visualization in 3D”(ESRI 2003) and integrates with a variety of ﬁles formats which are common inVR such as VRML, 3D Studio Max, and Open Flight. In essence, the user can zoom,pan and analyze surfaces on the globe at any scale. Although the global cannot bespun in the kind of holographic environment available in a CAVE as in NSCA’sweb trafﬁc application, the user can spin the global on the desktop and thus viewdifferent parts of the world at different levels of resolution in 3D. We show a typ-ical application of this technology in Figure 17.7 where we have mapped the degreeof world urbanization onto three globes from three different perspectives and growthrates of population onto a fourth globe. All of these data are shown at the countrylevel but of course, visualization can be accomplished at any scale if the requisitedata is available.THO_C17  20/03/2007  15:13  Page 328 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fVIRTUAL REALITY IN GIS329This kind of interface, which by the time this book is published may well becommonplace within GIS, raises on of the most important issues involved in VR – the way time, navigation and scale interact. We will illustrate these issues withrespect to the way we can move around the globes shown in Figure 17.7 for manykinds of time are associated with these visualizations. Digital navigation is quasi-independent of scale and time but at least three varieties are implicit. As the usermoves around the globe, the time taken is that associated with a rocket ship butas the user zooms, speeds reduce. Once down at the 3D level of a city, navigationcan be slowed to walking page. This is a massive contrast in terms of the initialspeed and time implied by panning at the world level and it deﬁnes two ends of atime spectrum that is ﬁxed by scale. Moreover different layers of spatial data canbe dissolved on the globe. At the world level again, we can move from one timeperiod to another by dissolving layers associated with different times and this impliesFig. 17.6Geographic visualization of web trafﬁcTHO_C17  20/03/2007  15:13  Page 329 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f330MICHAEL BATTYa different time line where the speed of dissolution is related to the datum pointof the data layer in question. In this way, one might visualize the evolution of activities on the planet. The intersection of space and time in this way has barelybeen thought though in mainstream geography or GI Science with this being oneof the best examples of how VR is stretching our imagination about how structuresevolve in space and time.To complete the confusion that VR brings, readers are referred to visualizationsof city growth in 3D which are being developed for historical and heritage studies.One of the best examples is Bologna where the growth of the city from the eleventhcentury to the modern day can be visualized by pulling up different historical visual-izations conﬁgured from the location where the user is rooted in the city. The ideaof time travel as a user walks along a street, watching the city changing through itsactual temporal development, is implicit in these interfaces although to date, theyremain experimental (Bocchi, Calori, Fraticelli, Guidazzoli, and Mariani 2004).Another example under active development involves a history of the city of Londonfrom the twelfth century based on the merging of detailed historical archives andarchaeology with more contemporary data (see http://www.casa.ucl.ac.uk/people/Melina.html for additional details).Fig. 17.7Interfaces to GIS using 3D globes: (a), (b), and (c) three views of urbanization 2005, and(d) growth rates 1995–2005THO_C17  20/03/2007  15:13  Page 330 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fVIRTUAL REALITY IN GIS331Beyond VR: Back to Reality, of SortsOnce geographic information is represented in 3D, then there is the prospect that thismedia can be translated not only into VR but also back into more material renditions.There is little doubt that users are ambivalent about the digital world, knowingimplicitly that the material world from which the digital might be derived offersqualitatively different insights into their understanding and feeling. A good exampleof this involves the use of physical",
    "chunk_order_index": 202,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-cd77920a5831c513f5f47e13babc8c3c": {
    "tokens": 1200,
    "content": "VIRTUAL REALITY IN GIS331Beyond VR: Back to Reality, of SortsOnce geographic information is represented in 3D, then there is the prospect that thismedia can be translated not only into VR but also back into more material renditions.There is little doubt that users are ambivalent about the digital world, knowingimplicitly that the material world from which the digital might be derived offersqualitatively different insights into their understanding and feeling. A good exampleof this involves the use of physical models of the city to aid in our understanding ofdesign proposals. The City of London, for example, has a large conventional modelbuilt of traditional materials. They consider this invaluable to economic developmentand related visualizations, and developers are encouraged to add their proposals tothe model in the form of detailed renderings of buildings. All this could be replacedby a digital model of the kind illustrated above but the City’s Ofﬁcers are reluctant(Batty, Chapman, Evans, et al. 2001). However what is now in prospect is the trans-formation of our digital model into a form which is nearer the material but stilldigital. We can place the model in a virtual design studio and users as avatars can visitthe room and discuss design proposals virtually. In Figure 17.8, we extend the virtualworlds that we illustrated above to show how avatars might view the model in suchworld, as a simulation of the traditional model into which they are able to injecttheir design proposals, virtually. In some sense, this represents a recursion that has noend: a “simulacra” or “simulation of a simulation” as Baudrillard (1994) terms it.Imagine entering a digital 3D model, panning and zooming into a room which houseda virtual world in which the digital model was placed, the very digital model that wasentered in the ﬁrst instance. The recursion might continue indeﬁnitely, Escher-like,while at any point the user might jump through a window onto some other part ofthe world, to a world of analysis, to a theoretical world, whatever and wherever.It is entirely possible to move in another way. Once the model has been developed,it is possible to print it as hard copy. Photographs and maps are not routinely manufactured in a material form from their digital equivalents and it is only a matter of time before geographical space in all three dimensions can be so generated.In Figure 17.9, we show how one section of Virtual London can be printed usingCAD/CAM device. The model is tiny compared to its traditional form notwith-standing that it took two days to print but this shows the future. How long willit be before such models can be produced routinely, thus giving back to reality,their traditional equivalents? In the future, VR in GI Systems and GI Science maybe as much about moving from the virtual to the real as from the real to virtual.The future is both ways.ENDNOTE1“CAVE the name selected for the virtual reality theatre, is both a recursive acronym (CaveAutomatic Virtual Environment) and a reference to ‘The Simile of the Cave’ found inPlato’s Republic, in which the philosopher explores the ideas of perception, reality andillusion. Plato used the analogy of a person facing the back of a cave alive with shadowsthat are his/her only basis for ideas of what real objects are” (from http://www.sv.vt.edu/future/vt-cave/whatis/ accessed July 20, 2004).THO_C17  20/03/2007  15:13  Page 331 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f332MICHAEL BATTYACKNOWLEDGEMENTSThe author wishes to thank Elena Besussi, Steve Evans, Andy Hudson-Smith, andSinesio Alves Junior for their help with the various examples reproduced here.REFERENCESBatty, M., Dodge, M., Doyle, S., and Smith, A. 1998. Modeling virtual environments. InLongley, P. A., Brooks, S., McDonnell, R., and Macmillan, B. (eds) Geocomputation: A Primer.Chichester, John Willey and Sons: 139–61.Fig. 17.8Constructing the Simulacra: The digital model as a “material artifact” in a virtualexhibition spaceTHO_C17  20/03/2007  15:13  Page 332 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fVIRTUAL REALITY IN GIS333Batty, M. 2000. The new geography of the third dimension. Environment and Planning B27: 483–4.Batty, M., Chapman, D., Evans, S., Haklay, M., Kueppers, S., Shiode, N., Smithm, A., and Torrens, P. 2001. Visualizing the city: Communicating urban design to planners and decision-makers. In Brail, R. and Klosterman, R. (eds) Planning Support Systems:Integrating Geographic Information Systems, Models, and Visualization Tools.Redlands,CA, ESRI Press: 405–43.Baudrillard, J",
    "chunk_order_index": 203,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e4a299c3f68b6959a90adbcb4bf38ad5": {
    "tokens": 1200,
    "content": "Evans, S., Haklay, M., Kueppers, S., Shiode, N., Smithm, A., and Torrens, P. 2001. Visualizing the city: Communicating urban design to planners and decision-makers. In Brail, R. and Klosterman, R. (eds) Planning Support Systems:Integrating Geographic Information Systems, Models, and Visualization Tools.Redlands,CA, ESRI Press: 405–43.Baudrillard, J. 1994. Simulacra and Simulation. Ann Arbor, MI, University of Michigan Press.Bocchi, F., Calori, L., Fraticelli, L., Guidazzoli, A., and Mariani, M. 2004. The Four-DimensionalCity. WWW document, http://www.cineca.it/editions/ssc97/html/guidazzo.htm.Dodge, M. 2002. Explorations in Alpha World: The geography of 3D virtual worlds on theInternet. In Fisher, P. F. and Unwin, D. J. (eds) Virtual Reality in Geography.London,Taylor and Francis: 305–31.ESRI 2003. Introducing ArcGlobe: An ArcGIS 3D Analyst application.ArcNews Online(Summer 2003; available at http://www.esri.com/news/arcnews/summer03articles/introducing-arcglobe.html).Fisher, P. F. and Unwin, D. J. 2002. Virtual Reality in Geography. London, Taylor andFrancis.Lamm, S. E., Reed, D. A., and Scullin, W. H. 1996. Real-time geographic visualization of World Wide Web trafﬁc. In Proceedings of theFifth International World Wide WebConference, Paris, France (available at http://www5conf.inria.fr/ﬁch_html/papers/P49/Overview.html).MacEachren, A. M. 2001. Cartography and GIS: Extending collaborative tools to support vir-tualteams. Progress in Human Geography25: 431–44.Rheingold, H. 1991. Virtual Reality. NewYork, Touchstone Books.Schroeder, R., Huxor, A., and Smith, A. 2001. ActiveWorlds: Geography and social inter-action in Virtual Reality. Futures33: 569–87.Fig. 17.9Printing the virtual city using CAD/CAM technologyTHO_C17  20/03/2007  15:13  Page 333 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f334MICHAEL BATTYShiffer, M. J. 2001. Spatial multimedia for planning support. In Brail, K. and Klosterman, R.(eds) Planning Support Systems: Integrating Geographic Information Systems, Models, andVisualization Tools.Redlands, CA, ESRI Press: 361–85.Smith, A. 2002. 30 Days in ActiveWorlds: Community, design and terrorism in a virtualworld. In Shroeder, R. (ed.) The Social Life of Avatars: Presence and Interaction in SharedVirtual Environments.Berlin, Springer: 77–89.THO_C17  20/03/2007  15:13  Page 334 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPart IVKnowledge ElicitationThe fourth section of the book consists of three chapters looking at the increasinglyimportant task of knowledge elicitation. The ﬁrst chapter (Chapter 18 by ChrisBrunsdon) considers some fundamental ideas about inference and the difﬁculties of applying these ideas to spatial processes. The chapter starts with a brief over-view of the classical and Bayesian statistical inferential frameworks and moves from there to explore the particular nature of statistical inference when spatial processes are considered and the ways in which these two sets of inferential tasks are related. The chapter concludes with a brief discussion of computationalapproaches and broader issues – including other forms and types of inference andthe availability of software to implement the types of applications noted in this particular chapter.In the second chapter in this group (Chapter 19), Harvey J. Miller discusses the process of geographic knowledge discovery (GKD) and one of its central com-ponents, geographic data mining. The rapid growth in number and importance ofthese techniques derives from the large volumes of geographically referenced datathat are being collected, archived, and shared by researchers, public agencies andthe private sector, and the realization that traditional statistical techniques may not help with knowledge discovery in these instances. The chapter starts out witha review of the more general problem of knowledge discovery from databases andrelated data mining techniques. It moves on from there to a discussion of GKDand geographic data mining techniques, and concludes by noting some of the impor-tant research frontiers in GKD at the time of writing.In Chapter 20, the ﬁnal chapter in this set, Frederico Fonseca examines the pro-spects for building the geospatial semantic web. This enterprise seeks to translatethe description of all of the available data on the Web – existing geospatial data aswell as less structured",
    "chunk_order_index": 204,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ec2a46134040077b7b19e2fbe1edd223": {
    "tokens": 1200,
    "content": "related data mining techniques. It moves on from there to a discussion of GKDand geographic data mining techniques, and concludes by noting some of the impor-tant research frontiers in GKD at the time of writing.In Chapter 20, the ﬁnal chapter in this set, Frederico Fonseca examines the pro-spects for building the geospatial semantic web. This enterprise seeks to translatethe description of all of the available data on the Web – existing geospatial data aswell as less structured informal information sources that may or may not containgeographic information – into a formal language that computers can understandand process. The central roles played by trust and meaning in the semantic web and why the semantic web and geospatial semantic web in particular, must beTHO_C18  19/03/2007  11:12  Page 335 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f336KNOWLEDGE ELICITATIONviewed and understood as works in progress are explained. This chapter concludesby noting why we need to create ontologies and to match them to data on the Webin order to implement in computers something similar to the human use of spaceand time metaphors.THO_C18  19/03/2007  11:12  Page 336 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 18Inference and Spatial DataChris BrunsdonIt is often necessary to make informed statements about something that cannot beobserved or veriﬁed directly. It is equally useful to assess how reliable these state-ments are likely to be. A great deal of research is based on the collection of data,both qualitative and quantitative, in order to make such statements. For this reason,inference in science is a fundamental topic, and the development of theories of statistical inferenceshould be seen as a cornerstone of any ﬁeld of study claimingto be based on scientiﬁc method.However, despite this clear recognition of the importance of statistical inference,many commercial Geographic Information System (GIS) packages claiming to offer“spatial analysis” facilities offer no tools for statistical inference. One might askwhy this is. The answer is complex, but one thing to note is that it was the Chi-Squared test, and not statistical inference in general that was cited by the AmericanAssociation for the Advancement of Science (AAAS) as a key development. Chi-Squared tests are relatively simple computationally, and make a number of assump-tions about the simplicity of the underlying processes about which inferences areto be made. In particular, they assume that each observation is probabilisticallyindependent and is drawn from the same distribution. For spatial data this is unlikelyto be the case – observations may well not be independent. In addition, the dis-tributions of observations may well be conditional on their geographic location.This violates the “drawn from the same distribution” assumption. Thus, althoughtools of inference are just as important for geographic data as for any other kind of data, there are potential problems when “borrowing” standard statisticalmethods and applying them to spatial phenomena. Thus, the aim of this chapteris to consider some fundamental ideas about inference, and then to discuss someof the difﬁculties of applying these ideas to spatial processes – and hopefully offera few constructive suggestions. It is also important to note that although for some areas a degree of consensus has been reached, the subject of statistical inference is not without its controversies – see Fotheringham and Brunsdon (2004)for example – and in particular there are unresolved issues in inference applied togeographic data.THO_C18  19/03/2007  11:12  Page 337 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f338CHRIS BRUNSDONBasic Ideas of InferenceTo begin with, it is important to identify – and distinguish between – some keyconcepts of statistical inference. These are:•The inferential framework:This is essentially the model of how inferences are made.Examples of these are Bayesian inference(Bayes 1763) and classical infer-ence. Each model provides a set of general principles describing how some kindof decision related to a model (or set of models) can be arrived at, given a set ofobservations.•The process model:This is a model, with a number of unknown parameters,describing the process that generated the observations. This will take a mathemat-ical form, describing the probability distribution of the observations.•The inferential task:The task that the analyst wishes to perform having obtainedtheir observations. Typical tasks will be testing whether a hypothesis about agiven model is true, estimating the value of a parameter in a given model, ordeciding which model out of a set of candidates is the most appropriate.•The computational approach:Having chosen a process model, the inferentialframework should determine what mathematical procedure is necessary to carryout the inferential task. In many cases, the procedure is the",
    "chunk_order_index": 205,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-34b437bf945e1eb8ce1edddc9b11444f": {
    "tokens": 1200,
    "content": "of the observations.•The inferential task:The task that the analyst wishes to perform having obtainedtheir observations. Typical tasks will be testing whether a hypothesis about agiven model is true, estimating the value of a parameter in a given model, ordeciding which model out of a set of candidates is the most appropriate.•The computational approach:Having chosen a process model, the inferentialframework should determine what mathematical procedure is necessary to carryout the inferential task. In many cases, the procedure is the relatively simpleapplication of a simple formula (for example, a Chi-Squared test). However,sometimes it is not. In such cases alternative strategies are needed. Sometimesthey involve numerical solution of equations or optimizations. In other casesMonte-Carlo simulation-based approaches are used, where characteristics of statistical distributions are determined by simulating variables drawn from thosedistributions. The strategy used to carry out the task is what will be termed the“computational approach” here.Probably the most fundamental of these concepts is the inferential framework. Thisis also the most invariant across different kinds of statistical applications – even ifgeographers have special process models or computational approaches, most of thetime they are still appealing to the same fundamental principles when they drawinferences from their data. For example, one frequently sees geographers declareparameters in models to be “signiﬁcantly different from zero,” or quote conﬁdenceintervals. When they do so, they are making use of two key ideas from classicalinference that may be applied to geographic and non-geographic problems alike.The most geographically speciﬁc of the concepts is the process model. As statedearlier, many inferential tests are based on the assumption that observations are inde-pendent of one another – in many geographic processes (such as those inﬂuencinghouse prices) this is clearly not the case. In some cases, the geographic model is ageneralization of a simpler aspatial model – perhaps the situation where geographyplays no role is a special case where some parameter equals zero. In these situations,one highly intuitive inferential task is to determine this parameter doesequal zero.In other cases, the task is to estimate the parameters (and ﬁnd conﬁdence intervals)that appear in both spatial and aspatial cases of the models (for example regressioncoefﬁcients). In these cases, the spatial part of the model is essentially a nuisance,making the inferential task related to another aspect of the model more difﬁcult.THO_C18  19/03/2007  11:12  Page 338 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINFERENCE AND SPATIAL DATA339The previous examples are relatively simple from a geographic viewpoint, butmore sophisticated geographic inferential tasks can be undertaken. In particular,the tasks above are related to what Openshaw (1984) terms “whole-map statistics.”That is, they consider single parameters (or sets of parameters) that deﬁne the natureof spatial interaction at all locations, but supply no information about any speciﬁclocations. To the geographer, or GIS user, it is often more important to identify whichlocations are in some way different or anomalous. Arguably, this is a uniquely geographic inferential task. Although this inferential task can be approached withstandard inferential frameworks, some careful thought is required.Thus, to address the issue of statistical inference for geographic data one mustconsider the nature of statistical inference in general, the particular nature of statist-ical inference when spatial processes are considered, and the way in which thesetwoare related. This provides a broad framework for the chapter. First, a (very)brief overview of the key statistical inferential frameworks will be outlined. Next,spatial process models and related inferential tasks will be considered, together with a discussion of how the inferential approaches may be applied in this context.Finally, a set of suggested computational approaches will be considered.An Overview of Formal Inferential FrameworksThe two most commonly encountered inferential frameworks are Classical andBayesian. Suppose we assume a model Mwith some unobserved parameters θ, and some data x. Two kinds of tasks commonly encountered are the following:1Given Mand x, to infer whether some statement about θis likely to be true;2Given Mand x, to estimate the value of θ.Classical inferenceThe classical framework is most commonly used, and will be deﬁned ﬁrst. The classical framework generally addresses two kinds of inferential tasks. The ﬁrst taskis dealt with using the signiﬁcance test.Hypothesis testingThe statement about θmentioned above is termed the null hypothesis. Next a teststatistic is deﬁned. Of interest here is the distribution of the test statistic if the nullhypothesis is true. The signiﬁcance(or p-value) of the test statistic is the probabilityof obtaining a value at least as extreme as the observed value of the test statisticif the null hypothesis is true. When the signiﬁcance is very low, this suggests thatthe null hypothesis is unlikely to be true. To perform an α% signiﬁcance test onecalculates the value of the test statistic with a signiﬁcance of α/100 – this is calledthe critical value. Typical values of αare 0.05 and 0.01. If the observed value ismore extreme than the critical value, then the null hypothesis is rejected. Note thatadopting the above procedure has a probability of αof rejecting the null hypo-thesis when it is actually",
    "chunk_order_index": 206,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-069795bed650b8238926eb41a42e9800": {
    "tokens": 1200,
    "content": "be true. To perform an α% signiﬁcance test onecalculates the value of the test statistic with a signiﬁcance of α/100 – this is calledthe critical value. Typical values of αare 0.05 and 0.01. If the observed value ismore extreme than the critical value, then the null hypothesis is rejected. Note thatadopting the above procedure has a probability of αof rejecting the null hypo-thesis when it is actually true.THO_C18  19/03/2007  11:12  Page 339 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f340CHRIS BRUNSDONThis may seem rather abstract without an example. One commonly used tech-nique based on these principles is the two-sample t-test. Here θ=(µ1,µ2) where µ1and µ2are means of two normally distributed samples having the same variance.The null hypothesis here is that µ1=µ2. Here the test statistic is the well-known t-statistic(18.1)where x¯1and x¯2are the sample means from the two samples, n1and n2are therespective sample sizes, and s2is deﬁned by(18.2)where s12and s22are the respective sample variances for the two samples.The above outlines the procedure of a signiﬁcance test, one of the two inferentialtasks performed using classical inference. Of course, such inference is probabilistic– one cannot be certain if we reject the null hypothesis that it really is untrue. However, we do know what the probability of incorrectly rejecting the null hypo-thesis is. This kind of error is referred to as the type I error. Another form of errorresults when we incorrectly accept the null hypothesis – this is called a type II error.It is generally harder to compute the probability of committing a type II error –usually denoted as 1 −β. The relationship between αand βis given in Table 18.1.Estimating parametersThe other inferential task is that of estimating θ. As with hypothesis testing, wecannot be sure that our estimate is exact – indeed given the fact that it is derivedfrom a sample we can be almost certain that it is not. Thus, in classical inference thekey method provides upper and lower bounds – the so-called conﬁdence interval.Note that this assumes that θis a scalar quantity. The situation when they are notwill be discussed later. A conﬁdence interval is a pair of numbers aand bcom-puted from the sample data, such that the probability that the interval (a, b) contains θis 1 −α. This probability is computed on the assumption that the modelis known in advance, up to the speciﬁcation of θ. A very important distinguishing  snsnsnn211222212112     =−+−+− ( )  ( )    txxsnn     =−+⎛⎝⎜⎞⎠⎟1221211 Table 18.1Relationship between αand βProbabilityReject Null HypothesisYesNoNull Hypothesis True1 −ααNull Hypothesis False1 −ββTHO_C18  19/03/2007  11:12  Page 340 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINFERENCE AND SPATIAL DATA341characteristic of this approach is that the probability quoted for a conﬁdence interval is NOT the probability that θlies within the interval (a,b). θis not a random variable – under classical inference θis a ﬁxed but unobservable quantity. The variables aand bare the random variables, since they are computed from therandom sample of observations.In situations where θis not a scalar, one may specify conﬁdence regionsfromthe data. For example, in the two-dimensional case we could represent it as a pointin the plane. A conﬁdence region is some sub-region of the plane determined fromthe sample data that has a 1 −αprobability of containing the true θ.Other issues for classical inferenceEarlier (see “Hypothesis testing” above) it was assumed that the quantity αcouldbe easily calculated. In some situations this is not the case and a Monte-Carlo(Metroplois and Ulam 1949) approach may be more helpful. In this approach, alarge number of random numbers are drawn from the probability distribution ofthe test statistic that would apply under the null hypothesis, and the observed valueof the statistic is compared against this list (see Manly 1991 for some examples).It may be checked that the percentage rank of the observed test statistic when it ismerged with the list of randomly generated test statistics is itself a signiﬁcance level.Thus, provided we may generate random numbers from the distribution of the teststatistic, this provides an alternative approach to the classical signiﬁcance test – albeitone with a very different computational approach. This approach may also be usedto generate conﬁdence intervals.Another important observation is that the derivation of the test statistics hinges onthe model for the distribution of the observational data being known – however,it is",
    "chunk_order_index": 207,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-fa76d92a1f2a6264ecfef8976373ec57": {
    "tokens": 1200,
    "content": "list of randomly generated test statistics is itself a signiﬁcance level.Thus, provided we may generate random numbers from the distribution of the teststatistic, this provides an alternative approach to the classical signiﬁcance test – albeitone with a very different computational approach. This approach may also be usedto generate conﬁdence intervals.Another important observation is that the derivation of the test statistics hinges onthe model for the distribution of the observational data being known – however,it is possible to draw inference from data when such a model is unknown. This isknown as a non-parametricapproach (see, for example, Siegel 1957). The advant-age of this approach is that it allows tests to be made when one has no strong evidence of the distribution generating the data. A price paid for this is that thecomputational overhead is much higher – and typically non-parametric tests are not as powerful as the simpler parametric equivalents, provided the assumptionsunderlying the parametric tests hold.Simple classical inference in actionTo illustrate some of the above ideas a simple example is given. Here, the dataconsists of a number of sale prices of houses from two adjacent districts in the greater London area in 1991. The location of the districts in the context of greaterLondon as a whole is shown in Figure 18.1, as are the locations of the houses inthe sample. There are 220 houses in district 1 and 249 in district 2 (the district to the west).If we assume that house prices in both districts have independent normal dis-tributions with equal variances, we may test the hypothesis that the mean houseprice is the same in each district. Together, this null hypothesis along with the assumptions set out above lead to the use of the t-test as set out in equation (18.1).The values of the relevant quantities are set out in Table 18.2.THO_C18  19/03/2007  11:12  Page 341 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f342CHRIS BRUNSDONSince we are interested in detecting differences in the mean value of either sign,we use the absolute value (that is, 2.37). However, from tables, the critical valueof tfor (two-tailed) a=0.05 is 1.96 – suggesting we should reject the null hypo-thesis at the 5% level. Thus, with a 5% chance of making an incorrect statementif the null hypothesis is true, we reject the null hypothesis – and state that there isa difference in average house price between two zones.Bayesian inferenceThe Bayesian approach views θin a very different way. Whereas classical inferenceregarded θas a deterministic but unknown quantity, Bayesian inference regards itas a random variable. The idea is that the probability distribution of θrepresentsthe analyst’s knowledge about θ– so that, for example, a distribution with verylittle variance suggests a great deal of conﬁdence in knowing the value of θ. If weaccept that θis a random quantity, as is x, the observed data, we can consider thejoint probability density of the two items given model M, say f(x,θ|M). Standardprobability theory tells us thatTable 18.2Two sample t-testDistrict 1District 2n1220n2249x177.7x286.4s137.3s241.5s239.6v467t−2.3710 km1 kmFig. 18.1The location of study area (LHS) and the houses in the samples (RHS)THO_C18  19/03/2007  11:12  Page 342 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINFERENCE AND SPATIAL DATA343f(θ|x) =f(x|θ)f(θ)/f(x)(18.3)where f(x|.) and f(θ|.) denote marginal distributions of xand θrespectively. Assum-ing we have a given observed data set x, we may regard f(x)−1as a normalizingconstant and writef(x|θ) ∝f(x|θ)f(θ)(18.4)This is essentially Bayes’ theorem, and is the key to the inferential model here. Ifwe regard f(θ) as the analysts knowledge about θregardless of x, then multiplyingthis by the probability of observing xgiven theta (that is, f(x|θ)) gives an expres-sion proportional to f(θ|x). Note that in this framework, f(x|θ) is our process model,as set out in the initial section, “Basic Ideas of Inference.” We can interpret thislast expression as the analyst’s knowledge about θgiventhe observational data x.Thus, we have updated knowledge about θin the light of the observations x– thisis essentially the inferential step.In standard Bayesian terminology f(θ) is referred to as the prioror prior dis-tributionfor θand f(x|θ) is referred to as the posterioror posterior distributionfor θ. Thus, starting out with a prior belief in the value of θ",
    "chunk_order_index": 208,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b48c56a6e9d10b12054edadecaeddcc9": {
    "tokens": 1200,
    "content": "Ideas of Inference.” We can interpret thislast expression as the analyst’s knowledge about θgiventhe observational data x.Thus, we have updated knowledge about θin the light of the observations x– thisis essentially the inferential step.In standard Bayesian terminology f(θ) is referred to as the prioror prior dis-tributionfor θand f(x|θ) is referred to as the posterioror posterior distributionfor θ. Thus, starting out with a prior belief in the value of θ, the analyst obtainsobservational data xand modiﬁes his or her belief in the light of these data to obtainthe posterior distribution. The approach has a number of elegant properties – forexample, if individual data items are uncorrelated and if data is collected sequentially,one can use the posterior obtained from an earlier subset of the data as a prior tobe input to a later set of data. However, the approach does require a major changein world view. The requirement of a prior distribution for θfrom an analyst couldbe regarded as removing objectivity from the study. Where does the knowledge toderive this prior come from?One way of overcoming this is the use of non-informativepriors which rep-resent no knowledge of the value of θprior to analysis. For example, if θwere a parameter between 0 and 1, then f(θ) =1 −a uniform distribution – would be anon-informative prior since no value of θhas a greater prior probability densitythan any other. Sometimes this leads to problems – for example if θis a variabletaking any real value. In this case, f(θ) =constant is not a well deﬁned probabilitydensity function. However, this shortcoming is usually ignored provided the poster-ior probability thus created is valid (typically the posterior in this case could beregarded as a limiting value of an inﬁnite sequence of posteriors derived from well-deﬁned priors – for example, if a sequence of priors with variances increasingwithout bound were supplied). A prior such as this is termed an improperprior.Having arrived at a posterior distribution f(x|θ) we may begin to address thetwo key inferential questions:1Estimate the value of θθ: Since we have a posterior distribution for θwe canobtain point estimates of θusing estimates of location for the distribution –such as the mean or median. Alternatively, we can obtain interval estimates suchas the inter-quartile range derived from this distribution. Typically, one wouldcompute an interval [θ1,θ2] between which θhas a 0.95 probability of lying. Notethat this is subtly different from the conﬁdence interval of classical inference.THO_C18  19/03/2007  11:12  Page 343 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f344CHRIS BRUNSDONThe 95% in a conﬁdence interval refers to the probability that the randomlysampled data provides a number pair that contains the unobserved, but non-random θ. Here we treat θas a random variable distributed according to theposterior distribution obtained from equation (4). To emphasize that theseBayesian intervals differ from conﬁdence intervals, they are referred to as credibility intervals.2Infer whether some statement about θθis likely to be true: If our statement isof the form a<θ<bwhere either aor bare inﬁnite, then this may be answeredby computing areas under the posterior probability density function. However,questions of the form addressed by classical inference – such as “is θzero?”where typically one is concerned with pointvalues of θpresent more difﬁculties.With a posterior probability density, the probability attached to any point value is zero. One approach is to decide how far from zero θcould be for the difference to be unimportant and to term this e. If this is done, we maythen test the statement −e <θ<e using the above approach. Other approachesdo attempt to tackle the exact value test directly – see Lee (1997) for furtherdiscussion.Bayesian inference in actionIn this section, we revisit the house price example, this time applying a Bayesianinferential framework to the problem. As before, we assume that house prices areindependently normally distributed in each of the two districts. If we regard ourlist of house prices as x, then θ=(µ1,µ2) the respective means of the house pricedistribution for districts 1 and 2, and f(x|θ) is just the product of the house price probability densities for each observed price. Here we are interested in thequantity µ1−µ2. In this case we have a non-informative prior in µ1and µ2andalso in log σwhere σis the standard deviation of house prices in both districts.The choice of the prior for σmay seem strange, but essentially stems from the fact that this is a scale parameter, rather than one of location – see Lee (1997), for example. In this case, it can be shown that the posterior distribution for thequantity δ=µ1−µ2is that of the expression(18.5)where all variables are as deﬁned in equation (18.1) except for t, which is a randomvariable with a tdistribution with νdegrees of freedom (again νis as deﬁned earlier). The posterior distribution for δis shown in Figure 18.2.Here, the hypothesis under test differs from that of the classical",
    "chunk_order_index": 209,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b713144cccbf916d9fa10f2837159c46": {
    "tokens": 1200,
    "content": "this case, it can be shown that the posterior distribution for thequantity δ=µ1−µ2is that of the expression(18.5)where all variables are as deﬁned in equation (18.1) except for t, which is a randomvariable with a tdistribution with νdegrees of freedom (again νis as deﬁned earlier). The posterior distribution for δis shown in Figure 18.2.Here, the hypothesis under test differs from that of the classical test. Rather than a simple test of whether δ=0 – which makes little sense given the posteriorcurve above, we test whether |δ|<Gwhere Gis deﬁned as some quantity belowwhich a difference in means would be of little consequence. This is very differentfrom the standard classical approach. In that framework, if a test were sufﬁcientlypowerful, differences in mean house prices of pennies could be detected. However,in terms of housing markets such a difference is of no practical importance. Forthis example we choose Gto be £1,000 (UK). If this is the case, the probability  (  )    xxsnnt12121112−++⎛⎝⎜⎞⎠⎟THO_C18  19/03/2007  11:12  Page 344 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINFERENCE AND SPATIAL DATA345that |δ|<Gcorresponds to the shaded area in Figure 18.2. This is equal to 0.014 – alternatively one could state the probability that |δ|exceeds £1,000 is 1 −0.014 =0.986. Thus, from a Bayesian perspective, it seems very likely thatthere is a non-trivial difference between the mean house prices for the two districts.Another possibility is to compute the probability that district 2 has a higher meanthan district 1. This is just the posterior probability that δ>0, which, from thecurve is equal to 0.99 – again suggesting this is highly likely.Bayesian approaches – some closing commentsThe Bayesian approach is regarded by some as very elegant. Certainly the simplic-ity of the underpinning equation (18.4) and the natural way that hypotheses maybe assessed, and parameters estimated from the posterior distribution do have adirectness of appeal. However, there is a sting in the tail. Equation (18.4) gives the posterior distribution up to a constant– implying that the expression for the probability distribution can only be obtained by integrating its un-normalized form.Herein lies the problem: in many cases the integral is not analytically tractable. At the time of writing, this presents fewer problems than in the past as numer-ical quadrature techniques may be used to estimate the integrals. Alternatively, techniques based on Monte-Carlo simulation and the Metropolis algorithm allow random values of θto be generated according to the posterior distribution. In thiscase, hypotheses about θare investigated by generating large numbers of randomvalues and investigating their properties.Posterior Density0.100.080.060.040.020.00–20–10$(1000’s Pounds)010Fig. 18.2Posterior distribution forδ=µ1−µ2THO_C18  19/03/2007  11:12  Page 345 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f346CHRIS BRUNSDONWhat is Special about Spatial?In the above section, two of the most common approaches to formal statistical inference were discussed. However, this was done in a general sense – nothing statedin the previous section applied exclusively to geographic data. As hinted in the intro-duction, working with spatial data introduces a few speciﬁc problems.This raises a number of issues:1What are the consequences of ignoring spatial effects?2Does one need to modify the above ideas of inference when working with spatialdata?3If some spatial effects are present, can they be represented as geographic patternsor images?All of these issues lead to important questions – questions without unique answers.If there are no serious problems encountered when ignoring spatial effects then thereis little that spatial analysis can add to the canon of standard statistical methods.Perhaps unsurprisingly, it is argued here that there are serious consequences of ignor-ing such effects. There are many examples of the consequences of ignoring space– a striking analysis is that by Fotheringham, Brunsdon, and Charlton (1998), whichfollows the work of Rees (1995) in modeling the relationship between limiting long-term illness (LLTI) as deﬁned in the 1991 UK census of population and a numberof predictor variables. The study area consists of the four counties Tyne and Wear,Durham, Cleveland, and North Yorkshire, in the north-east of England. Of par-ticular interest here is the population density variable. An ordinary least squaresregression model was ﬁtted to the data, giving a coefﬁcient of −5.6. A t-test basedon principles of classical inference showed this to be signiﬁcantly different from zero.In general, this suggests that an increase in population density leads to a decrease inLLTI",
    "chunk_order_index": 210,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-52ebe7052dbd7a3975f5c3e44781df58": {
    "tokens": 1200,
    "content": "the four counties Tyne and Wear,Durham, Cleveland, and North Yorkshire, in the north-east of England. Of par-ticular interest here is the population density variable. An ordinary least squaresregression model was ﬁtted to the data, giving a coefﬁcient of −5.6. A t-test basedon principles of classical inference showed this to be signiﬁcantly different from zero.In general, this suggests that an increase in population density leads to a decrease inLLTI. This is perhaps counterintuitive. Normally one associates higher morbidityrates with urban areas, which have higher population densities. However, the study went on to consider geographically weighted regression (GWR) (Brunsdon,Fotheringham, and Charlton 1996) – a technique in which regression parametersvary over space. It was found that the regression parameter for population densitywas at its most negative in areas in the region around the coalﬁelds of east Durham.Here, it is likely that LLTI is linked to employment in the coalﬁelds, and that most people in such employment lived in settlements near to the coalﬁelds, where population density is low. However, those people living in urbanized areas in thatpart of the region are less likely to be employed in occupations associated with highLLTI. Thus, in that locality a negative relationship between population density and LLTI holds. However this is unusual in general, and in other parts of the studyarea (west Durham, North Yorkshire), there is a positive relationship. Here, lowpopulation density corresponds to a more typical rural environment, and in theseplaces a more conventional urban/rural trend occurs. The key point here is that theglobal model told only one story, while the spatially-oriented GWR identiﬁed twodifferent processes occurring in different parts of the study area. Ignoring geographycan lead to misinterpretation!THO_C18  19/03/2007  11:12  Page 346 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINFERENCE AND SPATIAL DATA347How can this difﬁculty be overcome? This leads on to the second issue listed above.To address this, we return once again to the four aspects of statistical inferencelisted in the ﬁrst section of the chapter: both Bayesian and classical inferential frame-workscan handle the key inferential tasksof hypothesis evaluation and parameterestimation for spatial processes. However, for spatial data the process modelmustallow for geographic effects. Finally, it is also the case that the computational approachmust also be altered on some occasions. These two key issues will be consideredin turn.Process models for spatial dataThe process models for spatial data can differ from more commonly used ones ina number of ways. The two most common ones are that they exhibit spatial non-stationarityand spatial autocorrelation. Spatial non-stationarity is essentially thecharacteristic of the LLTI example above. The unknown parameter θis not a con-stant, but in fact a function of spatial location. In this case, a technique like GWRmay be used to estimate θat a set of given localities. Using this approach, one canapply the classical inferential framework to obtain estimates of θ, and test hypo-theses such as “is θa global ﬁxed value?” A classical inferential framework forGWR is detailed in Fotheringham, Brunsdon, and Charlton (2002).The phenomenon of spatial autocorrelation occurs when each of the observed xvalues are not drawn from statistically independent probability distributions, butare in fact correlated. In the geographic context, the correlation is generally relatedto proximity – nearby xvalues are more correlated than values located far apart.Typical examples are the SAR (spatial autoregression) and CAR (conditional auto-regression) models. Unlike GWR, these regression models do not assume that theregression parameters vary over space – however they do assume that the dependentvariables are correlated. Typically here, each record of variables is associated witha spatial unit, such as a census tract, and the spatial dependence occurs betweenadjacent spatial units. As well as the regression coefﬁcients and the variance of theerror term, CAR and SAR models have an extra parameter controlling the degreeto which adjacent dependent variables are related. In the classical inference case,parameter estimation is typically based on maximum likelihood, with the parametervector θcontaining the extra parameter described above as well as the usual regres-sion parameters. There is much work on the classical inferential treatment of suchmodels, see, for example, Cressie (1991). LeSage (1997) offers a Bayesian perspective.The computational approachComputational issues for geographic data are generally complex. The whole ﬁeldof geocomputation has grown to address this. As well as problems of data storage,data retrieval, and data mining, there are many computational overheads attribut-able to inference in spatial data, for a number of reasons. In some cases, the issueis related to Monte-Carlo or randomization methods – this is particularly true ofthe Monte-Carlo Markov Chain approach to Bayesian analysis. In others, it is linkedto developing efﬁcient algorithms to access large geographic datasets – this can be an issue in localized methods such as GWR. In each case, it is true that speciﬁcTHO_C18  19/03/2007  11:12  Page 347 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06",
    "chunk_order_index": 211,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-16683c9710005d12a76661a88dc2b1bd": {
    "tokens": 1200,
    "content": "Markov Chain approach to Bayesian analysis. In others, it is linkedto developing efﬁcient algorithms to access large geographic datasets – this can be an issue in localized methods such as GWR. In each case, it is true that speciﬁcTHO_C18  19/03/2007  11:12  Page 347 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f348CHRIS BRUNSDONalgorithms may need to be created to handle the geographic situation. A very goodexample is found in Diggle, Tawn, and Moyeed (1998).The ﬁnal question in the earlier list also raises some interesting problems. Theformal (Bayesian or classical) approach to hypothesis testing is essentially foundedon the notion of testing a single hypothesis. However, many geographers wouldlike answers to more complex hypotheses. In the spatial context, one of the keyquestions is “Is there an unusually high or low value of some quantity in region R?”Typically this quantity might be the average price of a house, or an incidence rateof some disease. This phenomenon is often termed clustering (see Chapter 22 byJacquez in this volume for more discussion on this topic). In some situations R is known in advance – for instance it may represent the catchment area of a par-ticular school in the house price example. If it is known in advance the approachis relatively simple. One creates a proximity measure to reﬂect how close to Reachobservation is, or creates a “membership function” of Rfor each observation, andthen builds this into a model, using a parameter that may vary the inﬂuence of thisnew variable. Then one goes on to test the hypothesis that this parameter is zero(or whatever value of the parameter implies that proximity to Rhas no inﬂuenceon the quantity of interest).This approach ﬁts in well with conventional theory – there is one single hypo-thesis to test, and it may be tested as set out above. However, on many occasionswe have no prior knowledge of R, possibly even on whether Ris a single region ora number of disjoint areas. On such occasions, a typical approach would be to carryout a test such as that described above on every possible region and map the onesthat have a signiﬁcant result. This is essentially the approach of the GeographicalAnalysis Machine (GAM; Openshaw 1987) – here the Rs are circular regions ofseveral radii centered on grid points covering the study area. However, there is a difﬁculty with this approach. Suppose we carry out a signiﬁcance test on each of the Rs. There could be a large number of tests, possibly hundreds. Even if noclustering were present, the chance of obtaining a false positive is α, the signiﬁc-ance level of the test. If α=0.05 as is common practice, we would expect to ﬁndNasigniﬁcant results even when no clustering occurs, where Nis the number ofregions to be tested. For example, if N=200 and α=0.05, we would expect toﬁnd 10 signiﬁcant regions even when in reality no clustering occurs. Thus, in anunadjusted form, this procedure is very prone to false positive ﬁndings. Essentiallythis is a problem of multiple hypothesis testing. Because the test has a positive prob-ability of incorrectly rejecting the null hypothesis, carrying out enough tests willgive some positive results even if in reality there are no effects to detect. A typicalway of tackling the problem is to apply the Bonferroniadjustment to the signiﬁcancelevelsof the test. For example, this is done by Ord and Getis (1995) for assessinglocal autocorrelation statistics.The correction is derived by arguing that to test for clustering, we wish to testthat noneof the regions Rhave a signiﬁcant cluster centered on them. Thus, theprobability of a false positive overall is the probability that any one of the regionshas a false positive result. If it is assumed that each test is independent, then it canbe shown that this probability (which will be called α′) is given byα′=1 −(1 −α′)N(18.6)THO_C18  19/03/2007  11:12  Page 348 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINFERENCE AND SPATIAL DATA349Now, if we wish to develop an overall test for clustering, with say α′=0.05 thenequation (18.6) may be solved for α– giving a signiﬁcance level for the individualtests needed in order to achieve the overall level of signiﬁcance. For example, if N=200 and we require α′=0.05 then α=0.000256. This is a fairly typical result. To counter the risk of false positives, the individual tests must have verylow values of α.However, one thing of note about the above approach is that the assumptionthat the tests are independent is often incorrect for geographic studies. Typically,a large number of regions Rare used, and many overlap,",
    "chunk_order_index": 212,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-63381a7e62aa5fd18dd891f5c3e6951b": {
    "tokens": 1200,
    "content": "achieve the overall level of signiﬁcance. For example, if N=200 and we require α′=0.05 then α=0.000256. This is a fairly typical result. To counter the risk of false positives, the individual tests must have verylow values of α.However, one thing of note about the above approach is that the assumptionthat the tests are independent is often incorrect for geographic studies. Typically,a large number of regions Rare used, and many overlap, sharing part of the sample data used for the local tests – and clearly the results of these tests cannotbe independent. It is usually argued that the Bonferroni procedure provides con-servative tests – in the case where the tests are correlated the estimate of α′in equation (18.6) is an underestimate. In the attempt to avoid false positives, we insist on very strong evidence of clustering around each of the test regions. In thepresence of correlated testing, we will be insisting on stronger evidence than is actually necessary. As a result of this, there is some chance that genuine clusteringis overlooked. In a nutshell this is a typical dilemma when looking for clusters –ignoring multiple hypothesis testing leads to false positives, but overcompensationfor this could lead to false negatives.Other Types of InferenceAlthough classical and Bayesian methods are both covered in this chapter, theseare not the only possible approaches. For example, Burnhan and Anderson (1998)outline ways in which Akaike’s Information Criterion (AIC; Akaike 1973) may beused to compare models. This approach is quite different in terms of its inferentialtask – rather than testing whether a statement about a particular model is true –or assuming a speciﬁc model holds and then attempting to estimate a parameter ofthat model, this approach takes several models and attempts to identify which oneis “best” in the sense that it best approximates reality. The AIC is an attempt tomeasure the “nearness” of the model to reality – obviously the true model is notknown, but the observations have arisen from that model, and this is where the“clues” about the true model come from. This is very different from the otherapproaches because it regards all potential models as compromises – none isassumed to be perfect – and attempts to identify the best compromise. This areamay prove fruitful in the future – for example, Fotheringham, Brunsdon, and Charlton(2002) use a method based on this idea to calibrate GWR models. The idea of ﬁndinga “best approximation” also sits comfortably with the idea of approximating a largeﬁnite sample with a continuous distribution put forward in the previous section.Of course, exploratory data analysis can be thought of as yet another inferentialframework, albeit a less formal one. Although this can provide a very powerful frame-work for discovering patterns in data, it could be argued that this is an entire subject in its own right, and that there will be many examples elsewhere in thisbook, where the production of maps and associated graphics by various softwarepackages provide excellent examples exhibiting the power and utility of graphicaldata exploration.THO_C18  19/03/2007  11:12  Page 349 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f350CHRIS BRUNSDONSoftwareNo chapter about inference would be complete without some discussion of software.Having argued that making inferences about data is central to knowledge discoveryin spatial analysis, one has every right to expect that software for inferential pro-cedures will be readily available. However, as mentioned in the introduction, mostreadily available GIS packages do not contain code for many of the procedures out-lined here. Unfortunately, although several commercial statistics packages do containcode for carrying out general inferential procedures, such as the t-test example dis-cussed earlier in the chapter, they offer less support for more speciﬁc inferential tasksdeveloped for spatial data. Until recently, for a number of spatial inferential tasks one was forced to write one’s own code. However this situation is now improv-ing. A number of packages that are either dedicated to the analysis of spatial dataor sufﬁciently ﬂexible that they may be extended to provide spatial data analysisnow exist. Although by no means the only option, the statistical programming lan-guage R provides good spatial analysis options – all of the examples (most notablythe spatial one) in this chapter were based on calculations done in R. The packageis also “Open Source” so it provides an easy entry option for anyone wishing toexperiment more with inferential approaches for geographic data.ACKNOWLEDGEMENTSI am grateful to the Nationwide Building Society for providing the house price dataﬁrst introduced in the section entitled “Simple Classical Inference in Action.”REFERENCESAkaike, H. 1973. Information theory and an extension of the maximum likelihood principle.In B. Petrov and F. Csaki (eds) Proceedings of the Second International Symposium onInformation Theory.Budapest: Akademiai Kiado, pp. 267–78.Bayes, T. [1763] 1958. Studies in the history of probability and statistics: IX, Thomas Bayes’sessay towards solving a problem in the doctrine of chances. Biometrika45: 296–315. (Bayes’sessay in modernized notation.)Brunsdon, C., Fotheringham, A. S., and Charlton, M. 1996. Geographically weightedregression: A method for exploring spatial non-stationarity. Geographical Analysis",
    "chunk_order_index": 213,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-3785a9a3f6f3276ca548d43a4bc655ae": {
    "tokens": 1200,
    "content": ", T. [1763] 1958. Studies in the history of probability and statistics: IX, Thomas Bayes’sessay towards solving a problem in the doctrine of chances. Biometrika45: 296–315. (Bayes’sessay in modernized notation.)Brunsdon, C., Fotheringham, A. S., and Charlton, M. 1996. Geographically weightedregression: A method for exploring spatial non-stationarity. Geographical Analysis28: 281–9.Burnhan, K. P. and Anderson, D. R. 1998. Model Selection and Inference: A PracticalInformation-Theoretic Approach. New York: Springer.Cressie, N. A. C. 1991. Statistics for Spatial Data. New York: John Wiley and Sons.Diggle, P. J., Tawn, J. A., and Moyeed, R. A. 1998. Model-based geostatistics. Applied Statistics47: 299–350.Fotheringham, A. S. and Brunsdon, C. 2004. Some thought on inference in the analysis ofspatial data. International Journal of Geographical Information Science18: 447–57.Fotheringham, A. S., Brunsdon, C., and Charlton, M. 1998. Scale issues and geographicallyweighted regression. In N. Tate (ed.) Scale Issues and GIS.Chichester: John Wiley andSons: 123–40.THO_C18  19/03/2007  11:12  Page 350 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINFERENCE AND SPATIAL DATA351Fotheringham, A. S., Brunsdon, C., and Charlton, M. 2002. Geographically WeightedRegression: The Analysis of Spatially Varying Relationships. Chichester: John Wiley andSons.Lee, P. M. 1997. Bayesian Statistics: An Introduction. London: Arnold.LeSage, J. 1997. Bayesian estimation of spatial autoregressive models. International RegionalScience Review20: 113–29.Manly, B. 1991. Randomization and Monte Carlo Methods in Biology. London: Chapmanand Hall.Metropolis, N. and Ulam, S. 1949. The Monte-Carlo method. Journal of the American StatisticalAssociation44: 335–41.Openshaw, S. 1984. The Modiﬁable Areal Unit Problem. Norwich: Quantitative MethodsResearch Group, Royal Geographical Society and Institute of British Geographers, Con-cepts and Techniques in Modern Geography Publication No. 38.Openshaw, S. 1987. A mark 1 geographical analysis machine for the automated analysis ofpoint data sets. International Journal of Geographical Information Systems1: 335–58.Ord, J. K. and Getis, A. 1995. Local spatial autocorrelation statistics: Distributional issuesand an application. Geographical Analysis27: 286–306.Rees, P. 1995. Putting the census on the researcher’s desk. In S. Openshaw (ed.) CensusUsers’ Handbook.Cambridge: GeoInformation International: 27–82.Siegel, S. 1957. Nonparametric Methods for the Behavioral Sciences.New York: McGraw-Hill.THO_C18  19/03/2007  11:12  Page 351 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 19Geographic Data Mining andKnowledge DiscoveryHarvey J. MillerGeographic information science exists in an increasingly data- and computation-richenvironment. The coverage and volume of digital geographic data sets are exten-sive and growing. High spatial, temporal, and spectral resolution remote sensingsystems and other environmental monitoring devices gather vast amounts of geo-referenced digital imagery, video, and sound (see Chapter 3 by Lees in this volume formore details on this topic). Geographic data collection devices linked to location-awaretechnologies (LATs) such as the global positioning system allow ﬁeld researchers tocollect unprecedented amounts of data. Other LATs, such as cell phones, in-vehiclenavigation systems, and wireless Internet clients, can capture data on individual move-ment patterns. Information infrastructure initiatives such as the US National SpatialData Infrastructure are facilitating data sharing and interoperability. The growthof computing power is widely expected to continue the exponential rate implied byMoore’s Law for at least two or three more decades.Traditional spatial analytical methods were developed when data collection wasexpensive and computational power was weak. The increasing volume and diversenature of digital geographic data easily overwhelm techniques that are designed to tease information from small, scientiﬁcally sampled, and homogenous data sets.Traditional statistical methods, particularly spatial statistics, have high computationalburdens. They are also conﬁrmatory and require the researcher to have a priorihypotheses, meaning that they cannot discover unexpected or surprising information(Miller and Han 2001).This chapter discusses the process of geographic knowledge discovery(GKD) andone of its central components, namely, geographic data mining. GKD is based on abelief that there",
    "chunk_order_index": 214,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e5d4c552933e7a7328861d1660f9ec0a": {
    "tokens": 1200,
    "content": ", scientiﬁcally sampled, and homogenous data sets.Traditional statistical methods, particularly spatial statistics, have high computationalburdens. They are also conﬁrmatory and require the researcher to have a priorihypotheses, meaning that they cannot discover unexpected or surprising information(Miller and Han 2001).This chapter discusses the process of geographic knowledge discovery(GKD) andone of its central components, namely, geographic data mining. GKD is based on abelief that there is novel and useful geographic knowledge hidden in the unprecedentedamount and scope of digital georeferenced data being collected, archived, and sharedby researchers, public agencies, and the private sector. This knowledge cannot be revealed using traditional methods that require a priori hypotheses or cannot bescaled to handle massive data. Since GKD is an extension of a broader trend in com-puter science, we will ﬁrst review the more general problem of knowledge discoveryTHO_C19  20/03/2007  15:14  Page 352 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC DATA MINING AND KNOWLEDGE DISCOVERY353from databases (KDD) and related data mining techniques. We will then discusswhy GKD is a meaningful extension of KDD, as well as identify major geographicdata mining techniques. This chapter concludes with a discussion of research frontiersin GKD.It is important to make a distinction between geographic data, GKD, and geo-graphic data mining on the one hand, and the closely related but broader ﬁeld of spatial databases, knowledge discovery, and data mining on the other. “Spatial”concerns any phenomena for which the data objects can be embedded within someformal space that generates implicit relationships among the objects. Examples include genetics and astronomy (Shekhar and Chawla 2003). “Geographic” refersto the speciﬁc case in which the data objects are georeferenced and the embeddingspace relates (at least conceptually) to locations on or near the Earth’s surface.Although many spatial databases and related techniques can be applied to the speciﬁcproblem of GKD, these techniques can also be applied more widely.Knowledge Discovery from DatabasesThe knowledge discovery processData mining is only one step of the KDD process. Data mining involves the appli-cation of techniques for distilling data into informationor facts implied by the data.KDD is the higher level process of obtaining facts through data mining and dis-tilling this information into knowledgeor ideas and beliefs about the mini-worlddescribed by the data. This generally requires a human-level intelligence to guidethe process and interpret the results based on pre-existing knowledge (Miller andHan 2001). The data miner is the critical interface between the syntactic know-ledge or patterns generated by machines and the semantic knowledge required byhumans for reasoning about the real world (Gahegan, Wachowicz, Harrower, andRhyne 2001).The KDD process does not seek any arbitrary pattern from a database; rather,data mining seeks only those that are interesting. These patterns are valid(a gener-alizable pattern, not simply a data anomaly), novel(unexpected), useful (relevant),and understandable(can be interpreted and distilled into knowledge) (Fayyad,Piatetsky-Shapiro, and Smyth 1996). In addition to the scale of the data involved,the requirement for novelty distinguishes data mining from traditional statistics oriented towards hypothesis conﬁrmation rather than generation. From a KDD perspective, anything that can be hypothesized a priori is not novel and thereforenot interesting.The KDD process typically involves the following major steps grouped into largeractivity categories (Fayyad, Piatetsky-Shapiro, and Smyth 1996, Han and Kamber2001, Qi and Zhu 2003):1Background(i)Developing an understanding of the application domain; this is oftenreferred to as background knowledge;THO_C19  20/03/2007  15:14  Page 353 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f354HARVEY J. MILLER2Data pre-processing(i)Data selection, or determining a subset of the records or variables in thedatabase for focusing the search for interesting patterns;(ii)Data cleaning, including removal of noise and outliers;(iii)Data reduction, including transformations, projections and aggregationsto ﬁnd useful representations for the data;3Data mining(i)Choosing the data mining task, involving the selection of the generic typeof patternsought through data mining, this is the language for expressingfacts in the database; generic pattern types include classes, associations,rules, clusters, outliers and trends (discussed in more detail below);(ii)Choosing the data mining techniquefor discovering patterns of the generictype selected in the previous step; since data mining algorithms are oftenheuristics (due to scalability requirements), there are typically several techniques available for a given pattern type, with different techniques concentrating on different properties or possible relationships among thedata objects;(iii)Data mining:applying the data mining technique to search for interestingpatterns;4Knowledge construction(i)Interpreting the mined patterns,often through visualization;(ii)Consolidating the discovered knowledge, either",
    "chunk_order_index": 215,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b7ae811ea7283a2ebd7bf98369dd2582": {
    "tokens": 1200,
    "content": "quefor discovering patterns of the generictype selected in the previous step; since data mining algorithms are oftenheuristics (due to scalability requirements), there are typically several techniques available for a given pattern type, with different techniques concentrating on different properties or possible relationships among thedata objects;(iii)Data mining:applying the data mining technique to search for interestingpatterns;4Knowledge construction(i)Interpreting the mined patterns,often through visualization;(ii)Consolidating the discovered knowledge, either by incorporating the know-ledge into a computational system (such as a knowledge-based database)or through documenting and reporting the knowledge to interested parties.The KDD process is not necessarily sequential: it is likely that the analyst willre-sequence and even revisit steps based on the knowledge sought and the natureof the information uncovered within the process. The data pre-processing steps ofselection, cleaning, and reduction can be applied in different sequences and iter-atively. The three data mining steps are also highly ﬂexible and often iterative. The analyst can also jump back and forth between major tasks such as backgroundknowledge, pre-processing, mining, and knowledge construction.Although human-level intelligence is required to guide the complex KDD pro-cess, it is possible to support the process through computational representations of background knowledge and the interestingness measures. Concept hierarchies are simple but powerful representations of multilevel background knowledge. Eachnode represents a concept at some level of abstraction, and a tree arranges theselevels of abstraction from the highest level (at the root) to its lowest levels (at theleaves). Concept hierarchies support rolling up(generalization) and drilling down(specialization) of data for the mining process; this allows the user to explore andinterpret patterns at different semantic levels. Figure 19.1 illustrates a concept hierarchy for the geographic concept location within a particular knowledge domain(Han and Kamber 2001).A data mining technique can generate an overwhelmingly large number of patterns.Interestingness measuresattempt to quantify the concept of interesting to limit thecandidate patterns presented to the analyst. Types of interestingness measures includesimplicity (such as rule length), certainty(conﬁdence measures), utility(databaseTHO_C19  20/03/2007  15:14  Page 354 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC DATA MINING AND KNOWLEDGE DISCOVERY355support; the number of objects for which it is true) and novelty (redundancy withpatterns already stored in the database). Most measures require speciﬁed relevancythreshold values (Han and Kamber 2001).Data Warehousing and Related TechnologiesData warehouses are critical, enabling technologies underlying the data mining and knowledge discovery process. A data warehouse is a non-transactional (non-editable) database, comprising read-only historical copies of one or more of thetransactional databases used in an organization or enterprise. Data warehouses integrate and represent these data in a manner that supports very efﬁcient query-ing and processing. Consequently, the design principles for data warehouses aredifferent from transactional databases. Transactional databases should be normal-izedor converted into the simplest logical representation in order to avoid incon-sistencies associated with multiple users editing replicated data within the samedatabase. In contrast, data warehouses need to be as connected as possible to supportefﬁcient query processing; this implies redundant data. Data warehouse design schemesinclude the star design, the snowﬂake design, and fact constellations(Han and Kamber2001). Data warehouses are not necessarily centralized; they can be distributed, multi-tiered, and federated. For example, some systems can include data martsor smallerscale data warehouses speciﬁc to particular departments or divisions within a largerenterprise (Bédard, Merrett, and Han 2001).Data warehouses include tools for quick multi-dimensional and multi-level datasummaries. Online analytical processing (OLAP) tools allow users to manipulatesimple database summaries and explore the data associated with these views. Thiscan support data mining and other stages of the KDD process by allowing a synoptic sense of the database before applying more computationally intensive techniques. A common OLAP technique is the data cube; this reports all possiblecross-tabulations of database attributes in the format of an mdimensional hypercube,AlllocationsVancouverBritishColumbia.........VictoriaOttawaTorontoColumbusClevelandSalt LakeCityOntario......CanadaOhioUtahUSAFig. 19.1A concept hierarchy for locationBased on Han and Kamber 2001, Figure 2.7THO_C19  20/03/2007  15:14  Page 355 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f356HARVEY J. MILLERwhere mis the number of attributes (Gray, Chaudhuri, Bosworth 1997). Figure 19.2illustrates a simple data cube for trafﬁc data attributed according to the date (D),time of day (T), and trafﬁc counter station (S).Seeking interesting patterns through data miningMost data mining techniques are heuristics tailored to discover patterns of a generictype. Generic patterns include classes, associations, rules, clusters, and outliers (Hanand Kamber 2001",
    "chunk_order_index": 216,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-c37ae4fdb3fec873a8d799c3c2f96289": {
    "tokens": 1200,
    "content": "number of attributes (Gray, Chaudhuri, Bosworth 1997). Figure 19.2illustrates a simple data cube for trafﬁc data attributed according to the date (D),time of day (T), and trafﬁc counter station (S).Seeking interesting patterns through data miningMost data mining techniques are heuristics tailored to discover patterns of a generictype. Generic patterns include classes, associations, rules, clusters, and outliers (Hanand Kamber 2001). Since these techniques are heuristics, there is no single optimalalgorithm for discovering patterns of a given type; different techniques highlightdifferent aspects of the information space implied by the database at the expenseof other characteristics. The following discussion deﬁnes these patterns and someassociated techniques:1Classiﬁcation involves mapping data into speciﬁed classes or meaningful categorieswhose cardinality is much less than the number of data objects. The mappingcan be achieved through data characterization(classiﬁcation based on sharedcharacteristics) or data discrimination (methods that highlight differences amongrecords). Characterization techniques include attribute-oriented induction: thiscompresses data into increasingly general relations through aggregating attri-butes based on the generalization operators or concept hierarchies (Han andFu 1996). Discrimination techniques generate statistical and visual summariesintended to highlight differences among user-speciﬁed classes such as those basedon data cubes.2Association analysis involves the study ofdependency relationships betweenattributes in a database to determine their association rules. These are typic-ally expressed in the form X⇒Y(c,r) where X, Yare disjoint sets of databaseattributes, cis the conﬁdence or the conditional probability P(Y|X) and rissupportor the probability P(X∪Y). Algorithms for association analysis includebreadth-ﬁrst and depth-ﬁrst search heuristics based on concept hierarchies (Hipp,Güntzer, and Nakhaeizadeh 2000).3Classiﬁcation and predictioninvolves ﬁnding simple functions or models that candistinguish between data classes or concepts. Classiﬁcation and prediction are alsocommon in traditional statistics, but data mining demands highly scalable tech-niques that can be applied in an exploratory rather than a conﬁrmatory manner.TDSTSDSTDDSTFig. 19.2A data cube for trafﬁc data attributed by date, time of day, and stationShekhar, Lu, Zhang, and Liu 2002THO_C19  20/03/2007  15:14  Page 356 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC DATA MINING AND KNOWLEDGE DISCOVERY357Techniques include decision tree induction, ﬁtted linear or curvilinear relationships,Bayesian classiﬁcation, and artiﬁcial neural networks (Han and Kamber 2001).4Cluster analysis includes techniques for classifying data objects into similar groups.Unlike concept description techniques, clusters are not pre-speciﬁed but ratheremerge from the inherent similarity and dissimilarity among objects. Clusteringis a computationally intensive problem and it is only since the 1990s that efﬁcienttechniques for massive databases have emerged in the literature. Clustering tech-niques have different objectives that affect the resulting cluster morphology.Important data characteristics include the type of data (nominal, ordinal, numeric),data dimensionality (since some techniques perform better in low-dimensionalspaces), and error (since some techniques are sensitive to noise) (Han, Kamber,and Tung 2001).5Outlier analysis refers to the examination of data objects (outliers) that appearinconsistent with respect to the remainder of the database (Barnett and Lewis1994). While in many cases these can be anomalies or noise, they sometimesrepresent rare or unusual events to be investigated further. For example, outlieranalysis has been used in detecting credit fraud, determining voting irregularities,and in severe weather prediction (Shekhar, Lu, and Zhang 2003a). Most toolsfor data mining can also be used in outlier detection since they typically alsogenerate exceptions to the discovered patterns. However, using standard datamining techniques in outlier detection can be restrictive (since outliers are deﬁnedindirectly as observations that do not meet some speciﬁed pattern) and com-putationally inefﬁcient (since ﬁnding patterns can require more effort than ﬁndingoutliers). Direct methods for outlier detection include distribution-,depth-,anddistance-based approaches. Distribution-based approaches use standard statisticaldistributions, depth-based techniques map data objects into an m-dimensionalinformation space (where mis the number of attributes), and distance-basedapproaches calculate the proportion of database objects that are a speciﬁed dis-tance from a target object (Ng 2001).Visualization and knowledge discoveryVisualization is a powerful strategy for leveraging the visual orientation of sightedhuman beings. Sighted humans are extraordinarily good at recognizing visual patterns, trends, and anomalies; these skills are valuable at all stages of the know-ledge discovery. Visualization can be used in conjunction with OLAP to aid theuser’s synoptic sense of the database. Visualization can also be used to support datapreprocessing, the selection of data mining tasks and techniques, interpretation, and integration with existing knowledge (Keim and Kriegel 1994). Visualizationcreates an opportunity for machines and humans to cooperate in ways that exploitthe best abilities of both (fast but dumb calculation and record-keeping versus slow but smart",
    "chunk_order_index": 217,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-22fe2b9c6cf3af3ca071023c34569395": {
    "tokens": 1200,
    "content": "all stages of the know-ledge discovery. Visualization can be used in conjunction with OLAP to aid theuser’s synoptic sense of the database. Visualization can also be used to support datapreprocessing, the selection of data mining tasks and techniques, interpretation, and integration with existing knowledge (Keim and Kriegel 1994). Visualizationcreates an opportunity for machines and humans to cooperate in ways that exploitthe best abilities of both (fast but dumb calculation and record-keeping versus slow but smart recognition and interpretation, respectively) (Gahegan, Wachowicz,Harrower, and Rhyne 2001).Methods for visual data mining and exploratory analysis include map-based, chart-based, projection, pixel, iconographic, and network techniques. Map-basedtechniquesallow the user to interactively represent georeferenced data in cartographicform. Chart-based techniques plot data using graphs and charts such as scatterplotsTHO_C19  20/03/2007  15:14  Page 357 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f358HARVEY J. MILLERand pie charts. Projection techniquesuse statistical transformations to represent datain alternative (non-Euclidean) spaces. Pixel techniquesmap data values to indi-vidual pixels that are in some meaningful order or position on the screen (such astemporal ordering or similarity-based clusters). Iconographic techniquesuse com-plex symbols (such as stick ﬁgures) to give the viewer a sense of the whole whilehighlighting some differentiation in the data. Network methodsorganize visual representation based on speciﬁed logical structures such as trees (Gahegan 2000).Geographic Knowledge DiscoveryWhy geographic knowledge discovery?Geographic knowledge discovery(GKD) is the process of extracting informationand knowledge from massive georeferenced databases. The nature of geographicentities, relationships, and data means that standard KDD techniques are not sufﬁci-ent (Shekhar, Zhang, Huang, and Vatsavai 2003b). Speciﬁc reasons include the natureof geographic space, the complexity of spatial objects and relationships as well astheir transformations over time, the heterogeneous and sometimes ill-structured natureof georeferenced data, and the nature of geographic knowledge.Objects in aspatial databases are typically discrete with explicitly deﬁned rela-tionships codiﬁed into the database. In contrast, spatial objects by deﬁnition areembedded in a continuous space that serves as a measurement framework for allother attributes. This framework generates a wide spectrum of implicit distance,directional, and topological relationships, particularly if the objects are greater thanone dimension (such as lines, polygons, and volumes). Also, although most mappingtechniques and spatial analyses assume Euclidean space for this framework, thereare many physical and human geographic processes that exhibit non-Euclidean spatial properties (examples include migration, disease propagation, and travel timesin congested urban areas). Exploring alternative geo-spaces for representing geo-graphic data is a form of data pre-processing that could substantially enhance theGKD process. It is also possible to calculate relationships through attributed geo-graphic space that represents terrain, land cover, velocity ﬁelds, or other cost ﬁeldsthat condition movement (Miller and Wentz 2003).Geographic data often exhibits the properties of spatial dependency and hetero-geneity. Spatial dependency is the tendency of observations that are more proximalin geographic space to exhibit greater degrees of similarity or dissimilarity (depend-ing on the phenomena). Proximity can be deﬁned in highly general terms, includingdistance, direction, and/or topology. Spatial heterogeneity or the non-stationarityof the process with respect to location is often evident since many geographic processes are local. Spatial dependency and heterogeneity can be evidence of mis-speciﬁcation (such as missing variables) but can also reﬂect the inherent nature of the geographic process. Either way, these relationships are information-bearing (Miller and Wentz 2003, Shekhar, Zhang, Huang, and Vatsavai 2003b).Data objects in typical KDD applications can be reduced to points in some multi-dimensional space without information loss. In contrast, many geographic entitiescannot be reduced to point objects without signiﬁcant information loss. CharacteristicsTHO_C19  20/03/2007  15:14  Page 358 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC DATA MINING AND KNOWLEDGE DISCOVERY359such as the size and morphology of geographic entities can have non-trivial inﬂuenceson geographic processes. Geographic objects can also be measurement artifacts; aggregate spatial units such as census districts are often chosen for administrativereasons or convenience rather than reality. The sensitivity of model results to thespatial measurement units is a well-known quandary often referred to as the mod-iﬁable areal unit problem(MAUP) in spatial analysis (see Fotheringham and Wong1991 for additional details). The implications of arbitrary spatial zoning and aggre-gation should be explored within the GKD process to determine if a discoveredpattern is robust or simply an artifact of the spatial measurement units.Including time introduces additional complexity to the GKD process. A simplestrategy that treats time as",
    "chunk_order_index": 218,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9dd46761519579eab6033c80656a734e": {
    "tokens": 1200,
    "content": "to thespatial measurement units is a well-known quandary often referred to as the mod-iﬁable areal unit problem(MAUP) in spatial analysis (see Fotheringham and Wong1991 for additional details). The implications of arbitrary spatial zoning and aggre-gation should be explored within the GKD process to determine if a discoveredpattern is robust or simply an artifact of the spatial measurement units.Including time introduces additional complexity to the GKD process. A simplestrategy that treats time as an additional spatial dimension is not sufﬁcient. Timehas different semantics than space: time is directional, has unique scaling and granu-larity properties, and can be cyclical and even branching with parallel local timestreams (Roddick and Lees 2001). Spatial transformations are also complex: forexample, a formal model of possible transformations in spatial objects with respectto time includes the operators create,destroy,kill,reincarnate,evolve,spawn,iden-tity,aggregate,disaggregate,fusion,and ﬁssion(see Frank 2001 for additional details).Roddick and Lees (2001) argue that the potential complexity of spatio-temporalpatterns may require meta-miningtechniques that search for higher-level patternsamong the large number of patterns generated from spatio-temporal mining.Digital geographic databases are also expanding to include more heterogene-ous data types, including ill-structured data. Traditional logical data models for spatial data include vector (spatial objects in an embedding space) and raster (discreterepresentations of continuous spatial ﬁelds using a grid-cell tessellation). Real-timeenvironmental monitoring systems such as intelligent transportation systems andlocation-based services are generating georeferenced data in the form of dynamicﬂows and space-time trajectories. Georeferenced multimediaincludes audio, imagery,video, and text that can be related unambiguously to a location on the Earth’s sur-face based on the location of the data collection or its content (Câmara and Raper1999). Despite the ill-structured nature of these data, they contain a potential wealthof information about particular places and times, including secondary (interpreted)information.The complexity of spatial objects and relationships in georeferenced data, as wellas the computational intensity of many spatial algorithms, means that geographicbackground knowledge can play an important role in managing the GKD process.Geographic concept hierarchies are particularly useful for guiding knowledge dis-covery at different levels of spatial aggregation (and therefore levels of computationalcomplexity due to the spatial representations and data volumes). Figure 19.1 illustrateda simple geographic concept hierarchy. More sophisticated hierarchies are availablefrom formal theories such as central place theory as well as the qualitative knowledgein traditional regional geography (as discussed in more detail in the ﬁnal section).Spatial Data WarehousingSpatial data warehouses (SDWs) are data warehouses that include both spatial andaspatial data. SDWs often include georeferenced data, but other non-geographicdata (such as medical imagery) can also be archived using SDW techniques. ExamplesTHO_C19  20/03/2007  15:14  Page 359 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f360HARVEY J. MILLERof geographic SDWs include the US Census database, Sequoia 2000, and archivesfrom transportation operations centers (Shekhar and Chawla 2003).Functional differences between SDW and standard data warehouses include capabilities for visualization and spatial aggregation. Conventional OLAP methodssuch as the data cube generate summary cross-tabs in tables; spatial data requires cap-abilities for data summaries in cartographic form. Conventional OLAP tools also haveclear standards for aggregation and cross-tabulation, namely, the one-dimensionalattributes associated with each data object. Conversely, spatial aggregation is morecomplex, and standards for aggregation operators on geometric data types have notyet emerged (Shekhar and Chawla 2003). In addition to purely spatial aggrega-tions, SDW must also support non-spatial aggregations(such as those involvingadministrative or political units treated as nominal categories), spatial-to-non-spatialaggregations(where data are spatial at low aggregation levels but aspatial at somehigher level and beyond; an example is aggregating polygons representing states orprovinces that eventually become nominal categories such as regions or countries).These spatial and hybrid aggregation operators can require background knowledgein the form of concept hierarchies such as the one illustrated in Figure 19.1. Spatialaggregation and related measures can also be computationally-demanding; the SDWdesigner can choose whether to compute them on-the-ﬂy, to selectively pre-computesome measures, or use ﬁlter and reﬁne methods (Bédard, Merrett, and Han 2001).Shekhar, Lu, Tan, Chawla, and Vatsavai (2001) develop the map cube as a spatial analog of the data cube. A map cube includes standard summaries and cross-tabulations as well as spatial summaries at different levels of aggregation with pointers to the corresponding spatial objects. The map cube includes geographicvisualizations of these summaries and cross-tabulations: it generates an album of maps corresponding to all possible aspatial and spatial summaries of the databased on a speciﬁed spatial aggregation hierarchy. Figures 19.3  and 19.4 illustratemap cube visualizations based on the trafﬁc data cube in Figure 19.2. Figure 19.3StationDate(Day of Week)Time of dayFig. 19.",
    "chunk_order_index": 219,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-c85572fc07c502bce05563a7c133663a": {
    "tokens": 1200,
    "content": "the corresponding spatial objects. The map cube includes geographicvisualizations of these summaries and cross-tabulations: it generates an album of maps corresponding to all possible aspatial and spatial summaries of the databased on a speciﬁed spatial aggregation hierarchy. Figures 19.3  and 19.4 illustratemap cube visualizations based on the trafﬁc data cube in Figure 19.2. Figure 19.3StationDate(Day of Week)Time of dayFig. 19.3Trafﬁc map cube visualization by date, time of day, and stationShekhar, Lu, Zhang, and Liu 2002THO_C19  20/03/2007  15:14  Page 360 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC DATA MINING AND KNOWLEDGE DISCOVERY361illustrates a visualization of cross-tabulation by date, time of day, and station, andFigure 19.4 illustrates visualization by date, time of day, and geographic location.Spatial data miningPattern types such as classes, associations, rules, clusters, outliers, and trends all havespatial expressions since these patterns can be conditioned by the morphology aswell as spatial relationships among these objects. This section reviews major tech-niques and applications of spatial data mining.1Spatial classiﬁcation These techniques map spatial objects into meaningful categories that consider the distance, direction, or connectivity relationships and/or the morphology of these objects. Koperski, Han, and Stefanovic (1998)use spatial buffers to classify objects based on attribute similarity and distance-based proximity. Ester, Kriegel, and Sander (1997) generalize this approachthrough a spatial classiﬁcation learning algorithm that considers spatial rela-tionships deﬁned as path relationships among objects in a deﬁned neighborhoodof a target object. These paths are highly general and can be deﬁned using anyspatial relationship (see Ester, Kriegel, and Sander 2001 for a generalization ofthis approach to other data mining tasks).2Spatial association Spatialassociation rulesare association rules as deﬁned abovethat also contain spatial predicates in their precedent or antecedent. Koperski,Han, and Stefanovic (1998) pioneered this concept, providing detailed descrip-tions of their formal properties as well as a top-down tree search technique thatexploits background knowledge in the form of a geographic concept hierarchy.A speciﬁc type of association rule is a co-location pattern: these are subsets ofY(latitude)DateTime of dayX(longitude)Fig. 19.4Trafﬁc map cube visualization by date, time of day, and geographic locationTHO_C19  20/03/2007  15:14  Page 361 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f362HARVEY J. MILLERspatial objects that are frequently located together. Huang, Shekhar, and Xiong(2000) develop a multi-resolution ﬁltering algorithm for discovering co-locationpatterns in spatial data.3Spatial classiﬁcation and prediction Malebra, Esposito, Lanza, and Lisi (2001)use inductive learning algorithms to extract information from general purposetopographic maps such as the type produced by national surveying and carto-graphic organizations. A search heuristic builds logical predicates based on the spatial objects, background knowledge, deﬁned higher-level concepts and a performance criterion. Qi and Zhu (2003) apply a decision tree induction algorithm to extracting knowledge about complex soil-landscape processes. Their system combines background knowledge in the form of a soil survey mapwith other environmental data to extract the expert’s judgments underlying thesubjective map. Gopal, Liu, and Woodcock (2001) use a type of artiﬁcial neuralnetwork known as adaptive resonance theory networks to extract knowledgefrom remotely sensed imagery. They also illustrate the use of visualization tosupport interpretation and insights into neural network performance.4Spatial clustering Spatial clusteringalgorithms exploit spatial relationships amongdata objects in determining inherent groupings of the input data. Since ﬁndingthe optimal set of kclusters is intractable (where k is some integer much smallerthan the cardinality of the database), a large number of heuristic methods forclustering exist in the literature. Many of these can be adapted to or are speciallytailored for spatial data (Han, Kamber, and Tung 2001). Traditional partitioningmethods such as k-means and the expectation-maximization(EM) method cancapture simple distance relationships and are therefore available for massive spatial databases. Hierarchical methodsbuild clusters through top-down (by splitting) or bottom-up (through aggregation) methods. Density-based methodsdeﬁne clusters as regions of space with a relatively large number of spatial objects;unlike other methods, these can ﬁnd arbitrarily-shaped clusters. Grid-based methodsdivide space into a raster tessellation and clusters objects based on thisstructure. Model-based methodsﬁnd the best ﬁt of the data relative to speciﬁcfunctional forms. Constraints-based methodscan capture spatial restrictions on clusters or the relationships that deﬁne these clusters. An example is the clustering with obstructed distance algorithm that can account for geographicobstacles such as rivers, borders",
    "chunk_order_index": 220,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d077235736026ef4bb7816875d6b668b": {
    "tokens": 1200,
    "content": "relatively large number of spatial objects;unlike other methods, these can ﬁnd arbitrarily-shaped clusters. Grid-based methodsdivide space into a raster tessellation and clusters objects based on thisstructure. Model-based methodsﬁnd the best ﬁt of the data relative to speciﬁcfunctional forms. Constraints-based methodscan capture spatial restrictions on clusters or the relationships that deﬁne these clusters. An example is the clustering with obstructed distance algorithm that can account for geographicobstacles such as rivers, borders, and mountains.5Spatial outlier analysisShekhar, Lu, and Zhang (2003a) deﬁne a spatial outlieras a spatially-referenced object whose non-spatial attributes appear inconsist-ent with other objects within some spatial neighborhood. Note that, other thanis the case with aspatial outliers, this deﬁnition does not imply that the object issigniﬁcantly different than the overall database as a whole: it is possible for aspatial object to appear consistent with the other objects in the entire databasebut nevertheless appear unusual within a local neighborhood. They develop a uniﬁed modeling framework and identify efﬁcient computational structuresand strategies for detecting these types of spatial outliers based on a single (non-spatial) attribute. More generally, geographic objects can also exhibit unusualspatial properties such as size and shape. Ng (2001) uses distance-based measuresto detect unusual paths in two-dimensional space traced by individuals througha monitored environment. These measures allow the identiﬁcation of unusualTHO_C19  20/03/2007  15:14  Page 362 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC DATA MINING AND KNOWLEDGE DISCOVERY363trajectories based on entry/exit points, speed and geometry; these trajectoriesmay correspond to unwanted behaviors such as theft.Geographic visualization and knowledge discoveryGeographic visualization(GVis), or the integration of scientiﬁc visualization withtraditional cartography, is highly complementary to the GKD process and can beexploited at all stages, including data pre-processing, data mining, and knowledgeconstruction (see Gahegan, Wachowicz, Harrower, and Rhyne 2001 and Chapter 16by Gahegan in this volume for additional details). In addition to the data volumesinvolved, a unique challenge is the extraordinary richness of geographic data with respect to the number and types of attributes that can be associated with geo-graphic locations, particularly when diverse data sets are integrated based on place(Gahegan, Wachowicz, Harrower, and Rhyne 2001). The problem is how to pre-serve the richness of this information space when restricted to the low dimensionalinformation spaces that can be easily related to geographic space by the user (thesebeing two or three spatial dimensions, and possibly time through animation). Forexample, dense and complex symbols and colors within low dimensionality spacescan create visual interaction effects that are poorly understood and can confoundknowledge discovery and communication (Gahegan 1999).GKD Research FrontiersGKD is a dynamic ﬁeld that is only just beginning at the time of writing. GKD willcontinue to grow as the scope and volume of digital georeferenced data expands andGI scientists develop new techniques to exploit these data as well as the increasingpower of computational platforms. The following points identify some particularlyimportant research frontiers in GKD.1Representation and integration of background geographic knowledge There isa rich source of existing geographic models, theories, laws, and knowledge thatcan be codiﬁed to serve as background knowledge for the GKD process. Forexample, central place theory offers a hierarchy of market centers that can beapplied at scales from local to global. Other theories such as spatial interactiontheory suggest general principles regarding the role of spatial separation andcomplementary attributes of origins and destinations in conditioning the move-ment of materials or information, as well as related spatial processes. Qualitativeand subjective knowledge about regional geography at all geo-scales from localto global could also be represented as concept hierarchies or other semantic networks. Physical geography also contains sophisticated geographic concept hierarchies based on geomorphology, river networks, biotic regimes, and so on.A critical research frontier is extracting and representing this rich geographicbackground knowledge to guide GKD.2Knowledge discovery from georeferenced multimedia A multimedia database system stores and manages large collections of multimedia objects such as audio,image, video, and text, including metadata about where and when the media wasTHO_C19  20/03/2007  15:14  Page 363 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f364HARVEY J. MILLERcollected, or the locations and times described by the media. Multimedia datamining is challenging since these data are implicit and the media must be pro-cessed to extract even its most basic features and structures (Han and Kamber2001). Mining georeferenced multimedia encompasses these challenges plus thedifﬁculties associated with geographic data mining and knowledge discovery.3Parallel algorithms and distributed infrastructures for geographic data miningParallel processing and distributed computational platforms such as grid com-puting environments can be exploited in GKD. Spatial data mining techniquescan sometimes be decom",
    "chunk_order_index": 221,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-eb919ef8d3a48d575dfef1b703479aa4": {
    "tokens": 1200,
    "content": "media. Multimedia datamining is challenging since these data are implicit and the media must be pro-cessed to extract even its most basic features and structures (Han and Kamber2001). Mining georeferenced multimedia encompasses these challenges plus thedifﬁculties associated with geographic data mining and knowledge discovery.3Parallel algorithms and distributed infrastructures for geographic data miningParallel processing and distributed computational platforms such as grid com-puting environments can be exploited in GKD. Spatial data mining techniquescan sometimes be decomposed into parallel tasks. Even if task parallelism isimpossible, georeferenced data can often be divided into spatial subsets for parallel processing (see Healy, Dowers, Gittings, and Mineter 1998, Wang andArmstrong 2003). Developing and testing parallel and distributed algorithmsand architectures for GKD is an important research frontier.4Spatio-temporal knowledge discovery As mentioned earlier in this chapter, includ-ing time in GKD greatly increased its logical complexity. There is a critical needto develop formal representations, database designs, data mining techniques, andvisualization methods that can extract meaningful information from these data.A particularly challenging frontier is developing representation and methods for data on mobile objects. LATs and wireless network-based location-basedservices(LBS) are a potentially rich source of knowledge about human activitiesin space and time, as well as emergent spatio-temporal phenomena such as trafﬁcjams, urban dynamics, and migration patterns (Smyth 2001, Wolfson 2002).Physical phenomena such as weather, predator–prey dynamics, invasive species,disease propagation, and environmental change also have emergent spatio-temporal properties that are notoriously difﬁcult to analyze using traditionalmethods (Mesorobian, Muntz, Santos 1994, 1996).5New questions for geographic research A critical and broad research questionfor GI scientists and geographers is “What are the questions that we could notask before?” Geographic and other domain scientists should articulate funda-mental and daunting research questions and challenges to guide the developmentof new GKD techniques. There are also needs for benchmarking and proof-of-concepts to demonstrate that these techniques can discover interesting geographicknowledge.6Integrating discovered knowledge into spatial analysis and Geographic Informa-tion Systems (GIS)Most existing spatial analysis techniques and GIS databasesuse simple representations of geographic knowledge such as primitive distanceand topological relationships. Discovered geographic knowledge should be usedto develop knowledge-based GIS as well as intelligent spatial analytical techniques.There is also a need to develop user-friendly interfaces for these techniques andsoftware so they can be exploited by domain scientists.ACKNOWLEDGEMENTSFigure 19.4 was reproduced courtesy of Professor Shashi Shekhar and Mr. PushengZhang, Spatial Databases Group, University of Minnesota (http://www.cs.umn.edu/research/shashi-group/).THO_C19  20/03/2007  15:14  Page 364 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC DATA MINING AND KNOWLEDGE DISCOVERY365REFERENCESBarnett, V. and Lewis, T. 1994. Outliers in Statistical Data(3rd edn). Chichester: John Wileyand Sons.Bédard, Y., Merrett, T., and Han, J. 2001. Fundamentals of spatial data warehousing forgeographic knowledge discovery. In H. J. Miller and J. Han (eds) Geographic Data Miningand Knowledge Discovery.London: Taylor and Francis, pp. 53–73.Câmara, A. S. and Raper, J. (eds). 1999. Spatial Multimedia and Virtual Reality.London:Taylor and Francis.Ester, M., Kriegel, H.-P., and Sander, J. 1997. Spatial data mining: A database approach.In M. Scholl and A. Voisard (eds) Advances in Spatial Databases.Berlin: Springer LectureNotes in Computer Science No. 1262: 47–66.Ester, M., Kriegel, H.-P., and Sander, J. 2001. Algorithms and applications for spatial datamining. In H. J. Miller and J. Han (eds) Geographic Data Mining and Knowledge Discovery.London: Taylor and Francis, pp. 160–87.Fayyad, U. M., Piatetsky-Shapiro, G., and Smyth, P. 1996. From data mining to know-ledge discovery: An overview. In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Ulthurusamy (eds) Advances in Knowledge Discovery and Data Mining.Cambridge,MA: MIT Press, pp. 1–34.Fotheringham, A. S. and Wong, D. W. S. 1991. The modiﬁable areal unit problem in multi-variate statistical analysis. Environment and Planning A23: 1025–44.Frank, A. 2001. Socio-economic units: Their life and motion. In A. Frank, J. Raper, and J.-P. Cheylan (eds) Life and Motion of Socio-economic Units.London: Taylor and Francis,pp. 21–34.Gahegan, M. 1999. Four barriers to the development of effective exploratory visualisation toolsfor the geosciences. International Journal of Geographical Information Science13: 289–309.Gahegan, M. 200",
    "chunk_order_index": 222,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-69e90a931effcbf9c66987e57f742866": {
    "tokens": 1200,
    "content": "io-economic units: Their life and motion. In A. Frank, J. Raper, and J.-P. Cheylan (eds) Life and Motion of Socio-economic Units.London: Taylor and Francis,pp. 21–34.Gahegan, M. 1999. Four barriers to the development of effective exploratory visualisation toolsfor the geosciences. International Journal of Geographical Information Science13: 289–309.Gahegan, M. 2000. On the application of inductive machine learning tools to geographicalanalysis. Geographical Analysis32: 113–39.Gahegan, M., Wachowicz, M., Harrower, M., and Rhyne, T. M. 2001. The integration ofgeographic visualization with knowledge discovery in databases and geocomputation.Cartography and Geographic Information Systems28: 29–44.Gopal, S., Liu, W., and Woodcock, X. 2001. Visualization based on fuzzy ARTMAP neu-ral network for mining remotely sensed data. In H. J. Miller and J. Han (eds) GeographicData Mining and Knowledge Discovery.London: Taylor and Francis, pp. 315–36.Gray, J., Chaudhuri, S., Bosworth, A., Layman, A., Reichart, D., Venkatrao, M., Pellow,F., and Pirahesh, H. 1997. Data cube: A relational aggregation operator generalizing group-by, cross-tab and sub-totals. Data Mining and Knowledge Discovery1: 29–53.Han, J. and Fu, Y. 1996. Exploration of the power of attribute-oriented induction in datamining. In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Ulthurusamy (eds) Advancesin Knowledge Discovery and Data Mining.Cambridge, MA: MIT Press, pp. 399–421.Han, J. and Kamber, M. 2001. Data Mining: Concepts and Techniques. San Francisco, CA:Morgan Kaufman.Han, J., Kamber, M., and Tung, A. K. H. 2001. Spatial clustering methods in data mining:A survey. In H. J. Miller and J. Han (eds) Geographic Data Mining and KnowledgeDiscovery.London: Taylor and Francis, pp. 188–217.Healy, R., Dowers, S., Gittings, B., and Mineter, M. (eds). 1998. Parallel Processing Algorithmsfor GIS.London: Taylor and Francis.Hipp, J., Güntzer, U., and Nakhaeizadeh, G. 2000. Algorithms for association rule mining:A general survey and comparison. SIGKDD Explorations2: 58–64.Huang, Y., Shekhar, S., and Xiong, H. 2000. Discovering Co-location Patterns from Spatial Datasets: A General Approach. WWW document, http://www.cs.umn.edu/research/hashi-group/.THO_C19  20/03/2007  15:14  Page 365 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f366HARVEY J. MILLERKeim, D. A. and Kriegel, H.-P. 1994. Using visualization to support data mining of largeexisting databases. In J. P. Lee and G. G. Grinstein (eds) Database Issues for DataVisualization. Berlin: Springer Lecture Notes in Computer Science No. 871: 210–29.Koperski, K., Han, J., and Stefanovic, N. 1998. An efﬁcient two-step method for classiﬁca-tion of spatial data. InProceedings of the International Symposium on Spatial Data Handling(SDH ’98), Vancouver, Canada. Columbus, OH: International Geographical Union, pp. 45–54.Malerba, D., Esposito, F., Lanza, A., and Lisi, F. A. 2001. Machine learning for informa-tion extraction from topographic maps. In H. J. Miller and J. Han (eds) Geographic DataMining and Knowledge Discovery.London: Taylor and Francis, pp. 291–314.Mesrobian, E., Muntz, R., Santos, J. R., Shek, E., Mechoso, C. R., Farrara, J. D., and Stolorz,P. 1994. Extracting spatio-temporal patterns from geoscience data sets. In Proceedings oftheIEEE Workshop on Machine Vision,Seattle, WA, USA. Los Alamitos, CA: Instituteof Electrical and Electronic Engineers, pp. 92–103.Mesrobian, E., Muntz, R., Shek, E., Nittel, S., La Rouche, M., Kriguer, M., Mechoso, C.R., Farrara, J. D., Stolorz, P., and Nakamura, H. 1996. Mining geophysical data for know-ledge. IEEE Expert11: 34–44.Miller, H. J. and Han, J. 2001. Geographic data mining and knowledge discovery: An overview.In H. J. Miller and J. Han (eds) Geographic Data Mining and Knowledge Discovery.London:Taylor and Francis, pp. 3–32.Miller, H. J.",
    "chunk_order_index": 223,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-5008c38ababc5f0bdf020da13312f04a": {
    "tokens": 1200,
    "content": "J. D., Stolorz, P., and Nakamura, H. 1996. Mining geophysical data for know-ledge. IEEE Expert11: 34–44.Miller, H. J. and Han, J. 2001. Geographic data mining and knowledge discovery: An overview.In H. J. Miller and J. Han (eds) Geographic Data Mining and Knowledge Discovery.London:Taylor and Francis, pp. 3–32.Miller, H. J. and Wentz, E. A. 2003. Representation and spatial analysis in geographic information systems. Annals of the Association of American Geographers93: 574–94.Ng, R. 2001. Detecting outliers from large data sets. In H. J. Miller and J. Han (eds) GeographicData Mining and Knowledge Discovery.London: Taylor and Francis, pp. 218–35.Qi, F. and Zhu, A.-X. 2003. Knowledge discovery from soil maps using inductive learning.International Journal of Geographical Information Science17: 771–95.Roddick, J. F. and Lees, B. 2001. Paradigms for spatial and spatio-temporal data mining. In H. J. Miller and J. Han (eds) Geographic Data Mining and Knowledge Discovery.London:Taylor and Francis, pp. 33–49.Shekhar, S. and Chawla, S. 2003. Spatial Databases: A Tour. Upper Saddle River, NJ: Prentice-Hall.Shekhar, S., Lu, C. T., Tan, X., Chawla, S., and Vatsavai, R. R. 2001. Map cube: A visual-ization tool for spatial data warehouses. In H. J. Miller and J. Han (eds) Geographic DataMining and Knowledge Discovery.London: Taylor and Francis, pp. 74–109.Shekhar, S., Lu, C. T., Zhang, P., and Liu, R. 2002. Data mining for selective visualizationof large spatial data sets. InProceedings of Fourteenth IEEE International Conference onTools with Artiﬁcial Intelligence (ICTAI ’02),Washington DC, USA. Los Alamitos, CA:Institute of Electrical and Electronic Engineers, pp. 41–8.Shekhar, S., Lu, C. T., and Zhang, P. 2003a. A uniﬁed approach to detecting spatial outliers.GeoInformatica7: 139–66.Shekhar, S., Zhang, P., Huang, Y., and Vatsavai, R. R. 2003b. Trends in spatial data mining.In H. Kargupta, A. Joshi, K. Sivakumar, and Y. Yesha (eds) Data Mining: Next Generation:Challenges and Future Directions.Menlo Park, CA: AAAI/MIT Press, pp. 357–79.Smyth, C. S. 2001. Mining mobile trajectories. In H. J. Miller and J. Han (eds) GeographicData Mining and Knowledge Discovery.London: Taylor and Francis, pp. 337–61.Wang, S. and Armstrong, M. P. 2003. A quadtree approach to domain decomposition forspatial interpolation in grid computing environments. Parallel Computing29: 1481–504.Wolfson, O. 2002. Moving objects information management: The database challenge. InPro-ceedings of the Fifth Workshop on Next Generation Information Technologies and Systems,Caesarea, Israel. Los Alamitos, CA: Institute of Electrical and Electronic Engineers.THO_C19  20/03/2007  15:14  Page 366 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 20The Geospatial Semantic WebFrederico FonsecaThe Web’s continuous growth has facilitated the increased availability of informa-tion in general and of geospatial information in particular. At the same time it hasbecome clear that such a wealth of data sources is not useful if we are not able toefﬁciently index, retrieve, and integrate all this information. The situation regardinggeospatial data is even worse because of the new means for collecting spatial datasuch as the widespread use of Global Positioning System (GPS) technology and theavailability of new and more sophisticated satellites (see Chapters 3 and 28 by Leesand Dana respectively, in this volume, for more information on both of these options).The only way to deal efﬁciently with such an amount of information is to delegate tocomputers some of the tasks of indexing, organizing, and retrieving information. Inorder to do this it is necessary for computers to be able to understand the meta-data, the data that describes the data. Therefore the main challenge of the enterprisecalled the Semantic Web is to translate the description of all the available data onthe Web into a formal language that computers can understand and process.The idea of the Semantic Web can be compared to what you do when you arelooking for some hard-to-ﬁnd product. It might be, for instance, a vintage com-puter game. You cannot ﬁnd it in large chain stores. You have to go there and talkwith the sales people. They will give you a phone number or an address of a smallstore specializing in vintage games. Now you call the small store and are forwardedto another out-of-town store. You call the new store and the phone number",
    "chunk_order_index": 224,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b62b1be964ccd7d576b31ee9a7d8ba2d": {
    "tokens": 1200,
    "content": "can be compared to what you do when you arelooking for some hard-to-ﬁnd product. It might be, for instance, a vintage com-puter game. You cannot ﬁnd it in large chain stores. You have to go there and talkwith the sales people. They will give you a phone number or an address of a smallstore specializing in vintage games. Now you call the small store and are forwardedto another out-of-town store. You call the new store and the phone number is disconnected. You then go to the Web and do a search and ﬁnd the store’s newphone number. Now you are able to call and ﬁnally reach them. They do not havethe game you are looking for but they write down your name and number andpromise to call you back whenever they are able to get the game. Finally, they callyou two months later with the game. In the Semantic Web vision you can delegate allthe tasks that you have performed in this example to a software agent. You can thinkof an agent as a piece of software that you trust and to which you can delegatesome functions such as ﬁnding and buying you a vintage game cartridge. In orderto do this the agent has to know your preferences and constraints. It also has toknow the intended meanings of terms that you and the parts it will be negotiatingwith use. So at the heart of the Semantic Web we have two main issues: trust andTHO_C20  19/03/2007  11:11  Page 367 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f368FREDERICO FONSECAmeaning. Since the work is being accomplished by computers another crucial issueis that whatever way this meaning is expressed it has to be machine-readable.Since we do not have yet these resources available on the Web we can say thattoday’s agents that look for the best price for you to buy a book or the best dealfor you vacation use brute force. The semantics and the knowledge are hardwiredinto the software agent itself. If one of the travel websites changes their tags forprice or location, the software agent has to be reprogrammed. Someone has to gothrough the code and make the changes there or this website will not be taken intoaccount in the next search for an affordable dream vacation. Berners-Lee, Hendlers,and Lassila (2001) considers that “the challenge of the Semantic Web, therefore,is to provide a language that expresses both data and rules for reasoning about thedata and that allows rules from any existing knowledge-representation system tobe exported onto the Web.” The Semantic Web has to be viewed and understoodas a work in progress. From the World Wide Web Consortium (W3C 2001) Intro-duction we can read “The Semantic Web is a vision: the idea of having data onthe web deﬁned and linked in a way that it can be used by machines not just fordisplay purposes, but for automation, integration and reuse of data across variousapplications.”SemanticsBut what is semantics? The term “semantic” is related to signiﬁcation or meaning.What is the meaning of the database with data about deforestation in the Amazonthat I just found on the Web? What did the vendor of a game cartridge mean by priceon its web page? All the (human) negotiation in the search for meaning that we gavein our introductory example has to be performed by computers in the Semantic Webvision. In order to do this we need standard vocabularies, formal deﬁnitions, andformal languages. Uschold (2003) suggests a semantic continuum starting from sharedhuman consensus which has little formalism and ranging to the completely formallanguages to be used in computers. Human beings communicate and share meaningthrough the use of language. The process of communication implies the acceptanceof the meaning embedded in words used by one agent in the communication processby a second agent in the same process. When there are questions the agents engagein a discussion trying to clarify the precise meaning of certain terms. This processof interaction is considered to be the basis of being human and it is addressed inthe hermeneutical literature, especially by Heidegger (1962) and Gadamer (1975).One of the main challenges of the Semantic Web is how to close the gap betweenthe shared human consensus of our everyday lives (the one that the user bringswith him/her when he/she uses a search engine) and a language with formally speciﬁedsemantics, a language that computers can manipulate and use to make inferences.Main Components of the Semantic WebWe are interested in the information resources that are available on the Internet.For us to have access to these resources we have to name them with identiﬁers soTHO_C20  19/03/2007  11:11  Page 368 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE GEOSPATIAL SEMANTIC WEB369that: (1) we are able to locate them; and (2) they are uniquely identiﬁed. The uniquename of each resource on the Web is called the Uniform Resource Identiﬁer (URI).Once we have a name tag for each resource we need to be able to describe what",
    "chunk_order_index": 225,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-97d4ec23691a2414b2170da38cd6e598": {
    "tokens": 1200,
    "content": "iley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE GEOSPATIAL SEMANTIC WEB369that: (1) we are able to locate them; and (2) they are uniquely identiﬁed. The uniquename of each resource on the Web is called the Uniform Resource Identiﬁer (URI).Once we have a name tag for each resource we need to be able to describe whatis in each resource. The description should be understandable to different communitiesand to computers as well. The proposed solution for a language that can be usedto describe the contents of web pages is the Resource Description Framework (RDF).The RDF language was created by consensus among the members of the World-WideWeb Consortium (W3C). What RDF does is to provide syntax speciﬁcation and aschema speciﬁcation. Thus RDF allows the advertisement of the contents of webresources in a machine-readable (and understandable) form. Once web pages havetheir RDF-ready descriptions, multiple uses will arrive such as improved searches,more effective and secure web commerce, collaboration, and customizations. In RDFeach resource is seen as having properties. Each of these properties has a PropertyType and Value. Therefore, using RDF we can make assertions that any informationresource with a URI has properties which in their turn have values. RDF uses theeXtensible Markup Language (XML) that lets users create their own tags referringto the content of a document. Although RDF gives users a tool to express simplestatements about resources, it is still necessary to create descriptions of the vocabu-laries used in the statements. What is the meaning of the terms being described? AnRDF Schema, usually referred to as RDF-S, provides the resources to describe ahierarchy of classes and the attached properties of the entities. Therefore, RDF-Scan be used to describe taxonomies. More complex descriptions may be necessary inthe Semantic Web scenario and new languages that can be considered as extensionsof RDF-S are being created and will be discussed below.Now that we have a way to describe the content of Internet resources the nextquestion is how can we share meaning? For information sharing to be efﬁcient andto deliver the kind of data that the users are expecting it is necessary to have anagreement on the meaning of the data. In broader terms, it is necessary to reachan agreement about the meaning of the entities representing the content of the webinformation resources. These entities are parts of a mental model that representsconcepts of the real world. A concept such as body of water carries with it a deﬁnitionand the mental image that users have of it. But what kinds of agreement can bereached among users? The question of whether it is possible to reach such an agree-ment among all users regarding the basic entities of the world is a subject underdiscussion by researchers. We can see this issue under two different perspectives.In the ﬁrst, there is one Ontology and we can reach a consensus about it throughthe reﬁnement of the concepts step by step over time. The other perspective doesnot accept this single Ontology and says that it is necessary to live with possiblyincompatible views of reality and try to map concepts from one ontology into anotherwhenever possible. A solution that can reach out to both perspectives supports thenotion that small agreements can be made within small communities. Later, theseagreements can be expanded to reach larger communities. When this larger agreementoccurs, part of the original meaning is lost, or at least some level of detail is lost.For instance, inside a community of biology scholars, a speciﬁc body of water canbe a lake that serves as the habitat for a speciﬁc species and, therefore, it can havea special concept or name to refer to it. Nonetheless, it is still a body of water, andwhen a biologist is working at a more general level it is considered as a body of waterTHO_C20  19/03/2007  11:11  Page 369 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f370FREDERICO FONSECAand not as a lake. At this higher level it is more likely that this real-world entity– body of water – can ﬁnd a match with the same concept in another community.So the biologist and a member of another community can exchange informationabout bodies of water. The information will be more general than when the bodyof water is seen as the habitat of a speciﬁc ﬁsh species.Before information sharing happens among different communities it is necessaryﬁrst to have explicit formalizations of the mental concepts that users have about thereal world. Furthermore, these concepts need to be grouped by communities repres-enting the basic agreements that exist within each community. Once these mentalmodels are explicitly formalized, mechanisms must be created for generalizing aspeciﬁc type of lake into a body of water or for adding sufﬁcient speciﬁcation tothe concept of body of water so that it becomes a speciﬁc lake. People performsuch operations in their minds all the time. The requirement to formalize them comesfrom the need to have these operations available as computer implementations. The explicit formalization of the mental models of a certain community is called anontology. The basic description of the real things in the world, the description ofwhat would be the truth, is called Ontology (with an upper-case O). The result of making explicit the agreement within communities is what the Artiﬁcial Intel-ligence community calls ontology (",
    "chunk_order_index": 226,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-5f9ce0af5cf37439577d02dfc26adfe3": {
    "tokens": 1200,
    "content": "such operations in their minds all the time. The requirement to formalize them comesfrom the need to have these operations available as computer implementations. The explicit formalization of the mental models of a certain community is called anontology. The basic description of the real things in the world, the description ofwhat would be the truth, is called Ontology (with an upper-case O). The result of making explicit the agreement within communities is what the Artiﬁcial Intel-ligence community calls ontology (with a lower-case o). Therefore, there is onlyone Ontology, but many ontologies.For agents to be able to carry on a successful negotiation it is necessary that notonly the ontologies are formally expressed but also that they are in a computer-readable language. Therefore, the Semantic Web needs ontology languages (Fensel2002). The most recent recommendation from W3C is OWL, the Web OntologyLanguage. OWL is a semantic markup language for sharing ontologies on the Web;it is a vocabulary extension of RDF and is derived from the DAML+OIL. DAML, theDARPA Agent Markup Language, was created with the objective of surpassing the limitations of RDF, such as the lack of resources for specifying data types anda consistent expression for enumerations. OIL, the Ontology Inference Layer, was aproposal for a web-based representation and inference layer for ontologies. OILgives the user a precise semantics for describing term meanings and also, therefore,information resources on the Web. These are the fundamentals of the Semantic Web.But what are the implications for geospatial data on the Web? In the next section,the speciﬁcs of spatial information that make the challenges of indexing, retrieving,and using geographic information available on the Web so daunting are discussed.The Geospatial Semantic WebIn their vision paper about the Semantic Web, Berners-Lee, Hendlers, and Lassila(2001) used concepts of space and time:At the doctor’s ofﬁce, Lucy instructed her Semantic Web agent through her handheldWeb browser. The agent promptly retrieved information about Mom’s prescribed treat-ment from the doctor’s agent, looked up several lists of providers, and checked forthe ones in-plan for Mom’s insurance within a 20-mile radius of her home and witha rating of excellent or very good on trusted rating services.THO_C20  19/03/2007  11:11  Page 370 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE GEOSPATIAL SEMANTIC WEB371Egenhofer (2002) also emphasizes that the future of the Semantic Web includes not only the geographic component but the spatial component. In his perspective,Egenhofer addresses the combination of geospatial data with other kinds of data.Another perspective for the Web user is to look for exclusively geospatial data. Thissecond type of user is looking for images, maps, spatial databases, tables in general.In this case, the geospatial data was previously classiﬁed as such. But a third andwidely available geospatial information resource on the Web is the geographic descriptions present in personal web pages. Historically, humans in every civiliza-tion and all over the world have gathered information about their environment forutilitarian purposes. These can vary from directions of how to get to a favoriterestaurant to descriptions of landscapes and reports of bird watching activities. Peoplewrite about their spatial surroundings and post it on the Web. Therefore, one ofthe research questions for the Geospatial Semantic Web is to come up with methodsto recognize and distinguish the different geospatial information resources.For example, when you are looking for a place to rent or buy you want your(web) agent to collect:•Information from your online realtor according to your criteria for location, price,or other conveniences;•Information from a governmental environmental agency giving you data aboutpotential health hazards in the region;•Informal reports from people who live in the neighborhood;•Aerial photos from an Internet map service; and•Photos from the neighborhood taken by the people that live there.When your software agent gives you all the data then you can make an informeddecision. In the next sections we discuss the nature of the different geospatial webinformation resources from the point of view of their structure, the queries thatcan be applied to them, and their nature. The work underway in the Semantic Webis related to the current research effort in interoperability. We can see the SemanticWeb as another layer in the interoperability arena. All the results achieved in inter-operability research are going to be used in the Semantic Web. What was missingin the previous interoperability research efforts was a common semantic under-standing. A growing interest in the development of a common data model led to newlines of research in geographic information integration. One of the largest initiativesfollowing this line of research is the OpenGIS Consortium (McKee and Buehler 1996).This association of software developers, government agencies, and systems integratorsaims at deﬁning a set of requirements, standards, and speciﬁcations to support geo-graphic information interoperability. The OpenGIS data model deals primarily withrepresentations of geographic information.The OpenGIS Consortium has also created a language based on XML to storeand exchange geographic data. The Geography Markup Language (GML) (seehttp://www.opengis.org/docs/02-023r4.pdf for additional details), is able to encodeOpenGIS geographic features. New approaches are needed to step up to a higherlevel of abstraction where the more valuable information about the meaning of thedata can be handled. Neither a standard data format",
    "chunk_order_index": 227,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-be27581023e6f70fe77c99c64bedd714": {
    "tokens": 1200,
    "content": "data model deals primarily withrepresentations of geographic information.The OpenGIS Consortium has also created a language based on XML to storeand exchange geographic data. The Geography Markup Language (GML) (seehttp://www.opengis.org/docs/02-023r4.pdf for additional details), is able to encodeOpenGIS geographic features. New approaches are needed to step up to a higherlevel of abstraction where the more valuable information about the meaning of thedata can be handled. Neither a standard data format nor a common data modelallows for the transfer of the meaning of information. The more complex issue ofTHO_C20  19/03/2007  11:11  Page 371 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f372FREDERICO FONSECAwhat is represented instead of how it is represented needs to be addressed. For instance,the user looking for water in New Mexico can obtain this information from theﬁles of the Environmental Protection Agency or from data stored by the New MexicoParks and Recreation Department. The important thing here is if and how thesetwo agencies share the idea of what a body of water is. An active agent that usesthe concept of body of water can actively look for this information, retrieve it, andmake it available for the user. Addressing the issues of how to share meaning in acomputational environment is the main objective of the geospatial semantic web.The structure of geospatial information resourcesGeospatial information on the web is available in different forms ranging from highly structured resources such as databases and web services to loosely structuredresources such as personal web pages (Table 20.1). Highly structured informationresources are closer to what is necessary for the geospatial semantic web to comeinto being. These resources are organized according to some explicit structure beit either a data model or a taxonomy.What is necessary in terms of the geospatial semantic web for these informationresources to be available is for them to describe their contents in RDF and committo a known public ontology expressed in a semantic web language such as OWL.Since they are already in a structured format all that is necessary is that the onto-logies become widely available as well as translation mechanisms between their structure and a language such as RDF. Structured resources, such as a spatial dataportal, have passed through the ﬁrst step in organizing data. Usually portals havetaxonomies leading to data sources. These taxonomies need to be translated intoa semantic web compatible format. Services that negotiate between the portal andthe information resources are also necessary. Therefore, there is a need for one levelof translation here that will transform a structured information resource into a highlystructured one. Scientiﬁc papers on Geographic Information Science (GISc) are alsoa structured source of geo-information. Scientiﬁc papers usually have a commonontology with title, abstract, keywords, introduction, ﬁndings, and conclusion amongother things. Journals and other sources of papers can commit a general ontology ofpapers expressed in OWL and communicate their contents in RDF. Unstructureddocuments such as textual web pages are a rich resource but also the most difﬁcultone to be converted into a semantic web ready form. How can an agent tell thatthis is a “geospatial” web page? What is it that makes a web page spatial? TheTable 20.1Organization of different geospatial web resourcesOrganizationResourceExamplesHighly structuredWeb servicesFinding the closest restaurant to your hotelHighly structuredSpatial databasesUS Census Bureau boundary ﬁlesStructuredPortalsUS Geological Survey portal for geographic dataStructuredScientiﬁc papersCiteSeer with a GISc queryUnstructuredTextual web pagesBest restaurants in PittsburghTHO_C20  19/03/2007  11:11  Page 372 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE GEOSPATIAL SEMANTIC WEB373ability to ﬁnd these kinds of web pages and extract the correct resources and formatthem to be used by the semantic web is a challenging task. All these tasks of formal-ization of web content need support from geo-ontologies. Previous work in GIScwill help with the creation of ontologies of different geographic kinds to enable theadvent of the geospatial semantic web.QueriesThere are two important aspects to the queries created by users of the geospatialsemantic web: the form and the presentation of the results. Egenhofer (2002) suggestsa canonical form to pose geospatial queries:<geospatial request> ::=<geospatial constraint> [<logical connective> <geospatialrequest>]<geospatial constraint> ::=<geospatial term> <geospatial comparator> <geospatialterm><geospatial comparator> ::=! based on the geospatial-relation ontology used<geospatial term> ::=<geospatial class> | <geospatial label><geospatial class> ::=! based on a geospatial feature ontology<geospatial label> ::=! based on a geospatial gazetteerThe second aspect in a geospatial query is how to represent the results. Dependingon the nature of the query the result may be only an address such as an URI orreal spatial data. What kind of spatial data and how to represent it is a questionthat an ontology of spatial data can help to answer. Again ontologies",
    "chunk_order_index": 228,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6e1b6f64b0271856d893b840e5c353f6": {
    "tokens": 1200,
    "content": "> | <geospatial label><geospatial class> ::=! based on a geospatial feature ontology<geospatial label> ::=! based on a geospatial gazetteerThe second aspect in a geospatial query is how to represent the results. Dependingon the nature of the query the result may be only an address such as an URI orreal spatial data. What kind of spatial data and how to represent it is a questionthat an ontology of spatial data can help to answer. Again ontologies come into thepicture. The solution for most semantic web problems involves the user committingto an ontology. This means that a user relies on some previous compilation of someexplanation of facts that he/she thinks is truthful. In our query problem, the userwill accept as a representation of the answer the representation of geographic dataas stated in a speciﬁc ontology.Nature of geospatial information resourcesThe Geospatial Semantic Web is intended to handle information that is meaningfulboth for humans and computers. Therefore, the way potential users understand anduse information is very important. In particular, we see three basic dimensions forusers of geographic information in the Geospatial Semantic Web context:1Professional– highly structured geographic information stored in geographicdatabases which are indexed, stored, or described on the Web;2Naive– the retrieval of unstructured, subjacent, informal geographic informa-tion in web pages;3Scientiﬁc – geographic information science papers, models, and theories availableon the Web.ProfessionalIn order to improve the results of queries looking for information stored in geo-graphic databases it is necessary to support better deﬁnition for spatial conceptsand terms used across different disciplines and the development of multiple spatialTHO_C20  19/03/2007  11:11  Page 373 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f374FREDERICO FONSECAand terminological ontologies. Here we also have web services – the most commonexamples are called location-based services – that are able to locate restaurants, hotels,and other facilities depending on the user’s location through the use of spatial data-bases (see Chapter 32 by Brimicombe later in this volume, for more a detailed discussion of the linkages between location-based services and GIS databases). TheOpenGIS consortium has a standard for web services. This shows again the import-ance of the integration between OpenGIS and the W3C. The geospatial semanticweb will need to build a semantic layer over the standards that the OpenGIS isdeveloping or have already deployed.NaiveIn this case we are looking for geographic information in the text of web pages. It can be pages with descriptions of geographic features such as cities, geographicphenomena, or facilities. The user may be looking for complementary informationor the Web may even be the main source of data. A case in which we can mix thecontent of textual web pages with more structured data such as the geographic dis-tribution of machines on the Web is the ability to answer queries such as “I foundthis interesting web page, where is its geographic location?” or “Find other websitesthat contain information about places close to places mentioned in this website”or “List (or even graphically display) all the location information on the IBM website (ofﬁces, research centers, etc.)”. The user may also want to ﬁnd pages that describea special region of San Francisco and uses as a constraint that the web server inwhich the page is stored is located in San Francisco because he or she thinks thatlocals will give better naive information.ScientiﬁcHere the situation is similar to what Citeseer (Giles, Bollacker, and Lawrence 1998)does today for computer science. It provides a specialized search engine for scientiﬁcpapers in a speciﬁc domain. Besides being able to index GISc documents it is alsonecessary to create ontologies that express the different theories expressed in the papers.Challenges of the Geospatial Semantic WebThere are many the challenges we face to make these types of queries feasible. Mostof them are related to ontologies because ontologies are the main structure in thesemantic web to represent semantics.Creation and management of geo-ontologiesActivities involved in ontology management include designing, developing, storing,registering, discovering, visualizing, maintaining, and querying ontologies. One aspectthat makes ontology management particularly challenging is that ontology is based onagreements among domain experts that can be geographically distributed. Ultimately,the endurance of an ontology is based on users’ acceptance. GIS communities can sup-port an initiative in ontology management that can include developing or adaptingTHO_C20  19/03/2007  11:11  Page 374 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTHE GEOSPATIAL SEMANTIC WEB375effective methodologies and tools for ontology management, and applying them todevelop domain speciﬁc ontologies with broad community acceptance.Matching geographic concepts in web pages to geo-ontologiesIt is necessary to apply a geospatial characteristic to the interpretation of texts(hermeneutics). It is also necessary to research in innovative methods of buildingontologies from maps, images, and sketches available on the web.Ontology integrationIn order to provide better results for queries",
    "chunk_order_index": 229,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-5b405188ffa5060022ee39ca852cf323": {
    "tokens": 1200,
    "content": "OSPATIAL SEMANTIC WEB375effective methodologies and tools for ontology management, and applying them todevelop domain speciﬁc ontologies with broad community acceptance.Matching geographic concepts in web pages to geo-ontologiesIt is necessary to apply a geospatial characteristic to the interpretation of texts(hermeneutics). It is also necessary to research in innovative methods of buildingontologies from maps, images, and sketches available on the web.Ontology integrationIn order to provide better results for queries it is necessary to integrate differentontologies not only in the geographic dimension (scientiﬁc, professional, naive) butalso in the non-geographic domain. Future research needs to address the necessity ofdeveloping and testing the theory of the integration of multi-disciplinary ontologiesby: (1) performing an empirical study of how different communities categorize the relationship between the different geographic entities; (2) creating relevant geo-ontologies; and (3) designing, prototyping, and assessing computational models tospecify, represent, access, and share multiple ontologies of geographic information.TrustIt is necessary to implement mechanisms that enable users to assign different levelsof trustfulness to different information resources. The necessary level of conﬁdence inthe information is different if the user is looking for information about the restaurantsaround his/her hotel or if the user is downloading geospatial information to decideif he/she is going to open a million-dollar business at this location. Onsrud (1999)provides a ﬁne review of the potential liability problems for producers and con-sumers of spatial information. He later reminds us of even further implications becauseof the international aspect of the Web (Onsrud 2004). Different laws and perspectivescome into play in a global scenario such as the Internet (see Chapter 29 by Choin this volume for an in-depth discussion of the various ways in which GIS andpersonal privacy issues are dealt with in different legal jurisdictions).CONCLUSIONSThe Geospatial Semantic Web is about bringing more semantics to the web. It isa way to make computers work closer to the way people do. The Web is here tostay and more and more content will be available online. There is no use for thismassive amount of information if we cannot have at least reasonably easy accessto it. Furthermore, spatial information is present everywhere. Some people estimatethat 80 percent of government and business information is spatial in some way(Eichelberger 1993, McKee and Buechler 1996). This proportion should be validfor data on the Web as well and means that there is a vast amount of spatial dataon the Web with the potential to advance our understanding of the world around us.The semantic web vision includes the creation of descriptions of the data sources onTHO_C20  19/03/2007  11:11  Page 375 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f376FREDERICO FONSECAthe Web. These descriptions should be expressed both in machine-readable format andin natural language. We need to create ontologies (expressing our world views) and match them to data on the Web. This is the great geospatial semantic webchallenge. The second challenge is the building of what Egenhofer (2002) calls theSemantic Spatial Web. Then we will be able to have implemented in computerssomething similar to the human use of metaphors of space and time.REFERENCESBerners-Lee, T., Hendler, J., and Lassila, O. 2001. The Semantic Web: A new form of Webcontent that is meaningful to computers will unleash a revolution of new possibilities. ScientiﬁcAmerican284(5): 34–43.Egenhofer, M. J. 2002. Toward the Semantic Geospatial Web. In K. Makki and N. Pissinou(eds) The Tenth ACM International Symposium on Advances in Geographic InformationSystems.New York: ACM Press, pp. 1–4.Eichelberger, P. 1993. The importance of addresses: The locus of GIS. In Proceedings of theAnnual Conference of the Urban and Regional Information Systems Association (URISA’93), Atlanta, GA, USA. Park Ridge, IL: Urban and Regional Information SystemsAssociation, pp. 212–22.Fensel, D. 2002. Language standardization for the Semantic Web: The long way from OIL to OWL. In J. Plaice, P. G. Kropf, P. Schulthess, and J. Slonim (eds) DistributedCommunities on the Web: Proceedings of the Fourth International Workshop (DCW 2002).Berlin: Springer Lecture Notes in Computer Science No. 2468: 215–27.Gadamer, H.-G. 1975. Truth and Method.New York: Seabury Press.Giles, C. L., Bollacker, K. D., and Lawrence, S. 1998. CiteSeer: An automatic citation indexingsystem. In Proceedings of the Third ACM International Conference on Digital Libraries,Pittsburgh, PA, USA, pp. 89–98.Heidegger, M. 1962. Being and Time.New York: Harper.McKee, L. and Buehler, K. (eds). 1996. The Open GIS Guide: An Introduction toInteroperable Geoprocessing and the OpenGIS Speciﬁcation. Wayland, MA: Open GISConsortium, Inc.Onsrud, H. 1999.",
    "chunk_order_index": 230,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-49eeab3607e0a1b7170304720040dc9a": {
    "tokens": 1200,
    "content": "Conference on Digital Libraries,Pittsburgh, PA, USA, pp. 89–98.Heidegger, M. 1962. Being and Time.New York: Harper.McKee, L. and Buehler, K. (eds). 1996. The Open GIS Guide: An Introduction toInteroperable Geoprocessing and the OpenGIS Speciﬁcation. Wayland, MA: Open GISConsortium, Inc.Onsrud, H. 1999. Liability in the use of GIS and geographical data sets. In P. A. Longley,M. F. Goodchild, D. J. Maguire, and D. W. Rhind (eds) Geographical Information Systems:Management Issues and Applications.New York: John Wiley and Sons, pp. 643–52.Onsrud, H. 2004. Geographic information legal issues. In C. Medeiros (ed.) The Encyclopediaof Life Support Systems (EOLSS).Developed under the auspices of the UNESCO, EOLSSPublishers, Oxford, UK, [http://www.eolss.net].Uschold, M. 2003. Where are the semantics in the semantic web? AI Magazine24(3): 25–36.W3C. 2001. The Semantic Web Activity Statement. WWW document, http://www.w3.org/2001/sw/.THO_C20  19/03/2007  11:11  Page 376 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPart VSpatial AnalysisThe next group of four chapters examines selected topics in spatial analysis. Chapter 21 by Martin E. Charlton, the ﬁrst of these chapters, offers a straightforwardbut insightful account of the links between quantitative analysis and GeographicInformation Systems (GIS). The various strands indicate the ways in which GIS andstatistical packages complement one another and the circumstances in which GISanalysts might consider using the latter and when statisticians might make use ofGIS. From this vantage point, it provides an important backdrop to the three subsequent chapters dealing with speciﬁc techniques for analyzing spatial data.In the next chapter in this set (Chapter 22) by Geoffrey M. Jacquez examinesspatial cluster analysis. The ﬁrst part of this chapter provides a working deﬁnitionof a cluster, the role of cluster analysis in exploratory spatial data analysis, andthe ﬁve components that contribute to statistical pattern recognition. Global, local,and focused clustering methods, cluster morphology descriptors, approaches for quantifying cluster change and persistence, and the value of multiple testing are dis-cussed next. These details are used by Jacquez to demonstrate why the “one size ﬁtsall” approach to cluster analysis is likely to yield an incomplete picture of clustermorphology and why integrated approaches are likely to yield substantial beneﬁtsin documenting cluster change and persistence and for identifying disparities in twoor more geographically referenced variables. The chapter concludes with an over-view of software resources for conducting cluster analysis.Yongxin Deng, John P. Wilson, and John C. Gallant review several key character-istics of terrain analysis and the importance of fuzzy logic, equiﬁnality, shape-baseddata quality evaluations, and multi-scale terrain analysis in Chapter 23. The chapterbegins by describing the most common terrain attributes as scale- and algorithm-dependent descriptions of the terrain surface and related biophysical processes. Thecontributions of terrain analysis to soil erosion/deposition modeling, soil mapping/landform delineation, and TOPMODEL model applications are discussed next andthese examples are used to illustrate several enduring challenges in terrain analysis.The ﬁnal part of the chapter examines the effects of spatial scale and data qualityTHO_C21  19/03/2007  11:30  Page 377 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f378SPATIAL ANALYSISon computed terrain attributes and identiﬁes some of the key questions that willneed to be answered to advance terrain analysis applications in the years ahead.In the ﬁnal chapter in this set on spatial analysis (Chapter 24), Jochen Albrechtrecasts some recent work usually subsumed under the geocomputation banner byfocusing on the temporal dimension and uncovering the low-level structural prob-lems that make it so difﬁcult to merge the spatial and temporal aspects of GIS datamodels. The chapter starts out with a review of current approaches to dynamic GISthat covers several important innovations, such as the development of fully-ﬂedgeddynamic modeling languages, cellular automata, and agent-based modeling, beforemoving to brief descriptions of examples related to air trafﬁc control and regionalstorm prediction. The chapter concludes with the observation that further progressin building and implementing dynamic GIS will depend on the development andimplementation of a language of “change.”THO_C21  19/03/2007  11:30  Page 378 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License",
    "chunk_order_index": 231,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-3b3dae6b7d8173a56e525472223becbf": {
    "tokens": 1200,
    "content": "a language of “change.”THO_C21  19/03/2007  11:30  Page 378 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 21Quantative Methods and GeographicInformation SystemsMartin E. CharltonThis chapter is concerned with the relationship between quantitative methods andGeographic Information Systems (GIS). It does not explore the use of particularquantitative methods – some of the following chapters deal in greater detail withparticular techniques which may be applied to spatial data. Rather, it considers whenand how we might use GIS and appropriate quantitative techniques together to dealwith some larger problem. In practice this relationship is often based on movinginformation between applications programs on a computer. Anyone who has hadto do this will understand that this is a sometimes rocky path. It is worth, therefore,spending some time considering what is involved and when. Readers interested ina rather more detailed treatment of quantitative methods viewed from a geographicalperspective might usefully refer to Fotheringham, Brunsdon, and Charlton (2000)– this chapter draws on material from chapters 2 and 3 of that text.The reader of this book might well feel that by the time this chapter has beenreached he or she has an understanding of the nature and purpose of GIS. In practicean analyst is usually faced with a computer program – among the more popularones we would include Arc/Info, ArcMap, ArcView, and MapInfo: this list is byno means exhaustive. The analyst needs to understand the nature of data which is appropriate for storage and manipulation in a GIS, whether it be vector with a locational component and some associated attributes or raster in which the phenomenon of interest is spatially discretized in a regular fashion. It is helpful tohave some understanding of coordinate systems and map projections, and it is use-ful to know what sort of operations can be undertaken in the program that is beingused. In short it is also useful to be conversant with the manner in which data may be stored, interrogated, manipulated, mixed, and displayed in the particularprogram. A good understanding of the principles which underlie GIS will help greatlyin dealing with its practice.If the data of interest have a spatial component, what quantitative methods areappropriate for such data? A related question is: if the data have a spatial com-ponent do we have to use that component explicitly in its analysis? A glance at the59 or so titles in the Concepts and Techniques in Modern Geography series whichTHO_C21  19/03/2007  11:30  Page 379 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f380MARTIN E. CHARLTONwere published under the auspices of the Quantitative Methods Study Group ofthe Institute of British Geographers, mainly during the 1970s and 1980s, wouldsuggest that the spatial component was not particularly important. While intro-ductory pedagogic guides to cartograms (Dorling 1996), Voronoi polygons (Boots1986), spatial autocorrelation (Goodchild 1986), the modiﬁable areal unit prob-lem (Openshaw 1984), centrographic measures (Kellerman 1981), and directionalstatistics (Gaile and Burt 1980) suggested that we should take notice of some of theproperties of spatial data in our analyses, other author’s volumes on logit models,linear regression, factor analysis, and contingency table analysis implied that weneed not. However, while many of the techniques in the former group do not existwithin some of the mainstream statistical applications programs, all of the lattergroup do and are frequently and widely applied to data which relates to locationson the surface of the Earth.One of the notable developments since the 1980s has been a set of techniqueswhich are applicable to spatial data – the analyst might turn to Cressie (1993) forhelp on geostatistical methods, and a wide range of models for lattice and pointdata. None of the techniques that he describes can be found in mainstream statis-tical software such as SPSS. However, we ﬁnd in volumes such as Davis (2002)treatment of a wide range of techniques which might be thought of as aspatial (t-test, analysis of variance, correlation, linear regression, spectral analysis, clusteranalysis, factor analysis, correspondence analysis, and canonical correlation), as wellas the analysis of point, line and spherical data, shape analysis, contouring, trendsurfaces, and elementary geostatistics. Again the aspatial techniques are in SPSS andthe spatial ones are not.Where does GIS ﬁt into this picture? Assuming that the appropriate quantitativemethod has been chosen, and suitable software is available, the analyst has an interest in four areas:1Creating the data for the analysis;2The exploration of the data prior to the analysis;3The statistical analysis of the data; and4The interpretation of the results.Each of these stages may involve several sub-stages and several pieces of software.There may also be feedback loops where an examination of the results of the analysis may lead to the realization that an important item of data is missing, inwhich case a return to an earlier step may be required. In this sense",
    "chunk_order_index": 232,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6991b5353f6349519d1cb9d786d25f83": {
    "tokens": 1200,
    "content": "interest in four areas:1Creating the data for the analysis;2The exploration of the data prior to the analysis;3The statistical analysis of the data; and4The interpretation of the results.Each of these stages may involve several sub-stages and several pieces of software.There may also be feedback loops where an examination of the results of the analysis may lead to the realization that an important item of data is missing, inwhich case a return to an earlier step may be required. In this sense we may viewGIS as a tool which assists in the analysis.Despite the best efforts of GIS software developers, no single GIS applicationsprogram will provide all that an analyst is likely to need. Indeed GIS software whichincorporated all of the techniques in Cressie (1993) and Davis (2002) would beunwieldy in use. This does not stop manufacturers releasing add-ons for their soft-ware to carry out geostatistical operations, for example. Sensibly many softwaredevelopers provide a macro language to permit analysts to incorporate their owntechniques into software; good examples are the Arc Macro Language used in Arc/Infoand Avenue which was used with ArcView. A search of ESRI’s own website andelsewhere on the Internet will reveal a rich variety of software written in these macroTHO_C21  19/03/2007  11:30  Page 380 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fQUANTATIVE METHODS AND GEOGRAPHIC INFORMATION SYSTEMS381languages which extends the capabilities of the base product to deal with variousproblems which are of interest. It would be pointless to catalog such software here,as the body of user-produced software increases daily.It is not always necessary to resort to coding one’s own software. Let us considera simple example as a prelude to thinking about the issues involved. An analyst isinterested in the relationship between the price of housing and the characteristicsof that housing. There is a rich body of theory and practice in economics whichdeals with hedonic models which are appropriate for such an analysis. Hedonicmodels require individual data on each house. Areas in cities are sometimes char-acterized as being “cheap” or “expensive” in terms of housing cost, perhaps for theirproximity to an industrial neighborhood or a well kept park. Location may well beimportant. A real-estate or mortgage company may be able to provide anonymousdetails of housing data on an individual level, although they are unlikely to be ableto provide any spatial reference for it beyond a zip code or postcode. As well asthe housing data, the analyst may be able to obtain data about the social structureof the immediate neighborhood of each house. If proximity to some facility is thoughtto be important, then the analyst may need to measure the distance to that facility,or perhaps its direction. A mail company may be able to provide an index whichgives spatial references for the zipcodes or postcodes.Such a problem is not atypical. Long before any hedonic modeling can take place,the analyst has to combine these data sources to extract the appropriate data. Anydata exploration may well include mapping the data (are all the detached propertiesin the same location in the city?). While an initial analysis may involve nothing moreand a linear regression model ﬁtted using ordinary least squares, the interpretationof the results would be partial if the analyst did not consider the possibility of theexistence of spatial patterns in the results, so another map will be necessary. Whatissues are there in dealing with such a problem?An important initial question is that of how many houses are involved in the study.One might be tempted to use Excel to deal with some of the initial data integration.There is currently a limit of 65,536 rows in Excel, so if the data set is larger, thenan alternative has to be found. To add spatial information to the housing data, thezipcodes or postcodes will need to be merged with the index. What is the granularityof the spatial references in the index? In the UK postcodes have a variety of formatswhich may cause problems in matching the data sets. Indeed the analyst might usethe ﬁle matching facilities available in SPSS to link the coordinate information from the index to the housing records.Having gone to the extent of creating an SPSS data ﬁle, can this be transferredeasily to another package? Linking in the census data will probably require the GIS software. If the housing records are stored with point references, how are theyto be linked to the census data – the latter may have a point reference or centroid,or may be represented as an area. If the census data have point references thenassociation of the census and housing data might be the result of an operation toﬁnd the nearest census centroid to each house, and assign its attributes to the houserecord. If the census data are area data, then a geometric operation is required thatwill identify in which census area each house lies – once this is done, the censusarea attributes can be transferred to the house data. Other proximity or containmentcomputations are best left to the GIS software. At this point, some exploration ofTHO_C21  19/03/2007  11:30  Page 381 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative",
    "chunk_order_index": 233,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-8d88610338c569ac48c72af5a57d787b": {
    "tokens": 1200,
    "content": ". At this point, some exploration ofTHO_C21  19/03/2007  11:30  Page 381 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f382MARTIN E. CHARLTONthe spatial patterns in the data can take place – what are appropriate symbols, whatclassiﬁcation is to be used with the continuous data (are any patterns in the pricesa reﬂection of some spatial phenomenon or merely an artifact of the choices thesoftware has made for its symbols)?It is unlikely that the hedonic modeling would be carried out in the GIS soft-ware. A transfer to another package is required. In the case of ArcView the dBaseﬁles in which it stores attribute data can be relatively easily transferred to SPSS,although some attention may be required to the characteristics of each attribute,such that, say, the number of decimal places is preserved. Depending on which statistical software is being used – the choice is large – this transfer may be moreor less reliable.The nature of the modeling will be driven by the analyst’s expertise and experi-ence. Perhaps stepwise methods might be employed to remove variables which donot appear to inﬂuence the variation in the price. It would be wise to calculatesome residuals for each of the models that are used. Among the assumptions ofOLS regression are that the observations are independent of one another and thatthe residuals are random and heteroskedastic. A map of the residuals may help to determine whether they have these properties. Spatial pattern in the residualssuggests that something has been omitted from the model, or perhaps that OLSregression is not the most appropriate technique. Either way, the residuals will require transfer from the statistical software to the GIS program. This may be asimple as cutting and pasting from one desktop window to another, or it may require the creation and linking of tables. In the latter case, it helps if the data inthe statistical program and the GIS bear some corresponding identiﬁer (even if thisis just a sequence number).CouplingIt is worth noting here that the GIS software has been used in three of the foursteps outlined above and the statistical program in two. There is another issue whichis sometimes referred to as “coupling.” Outlined above is an example of “loosecoupling.” Two software programs have been used for tasks which appear appro-priate to their strengths, and the data has been transferred between them in one ormore ﬁles. This is at once ﬂexible yet error prone, and does demand some facilitywith at least two software programs. The converse is “tight coupling” in which theanalytical method is incorporated in the GIS, either by initial design, or by usingan extension or add-in (such as ESRI’s “Spatial Analyst” which permits simple geostatistical analysis). The advantage is that the problems of data transfer in theloose-coupled approach do not occur, but the analyst is now restricted to what-ever is programmed into the extension.A third approach is to consider adding simple functions to other statistical environments, such as R (Ihaka and Gentleman 1996). One such extension allowsR to read data from ArcView shapeﬁles and then use these for modeling. The analyst beneﬁts from the ease of data transfer, and the full and rich analytical functionality of R that is available. However, transfer to a GIS for mapping maybe less easy, although cut/paste operations are available. While GIS does provideTHO_C21  19/03/2007  11:30  Page 382 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fQUANTATIVE METHODS AND GEOGRAPHIC INFORMATION SYSTEMS383some facilities for interactive exploration of data, a highly interactive environmentof the sort provided by XLispStat (Tierney 1990), S-Plus (Venables and Ripley 2002),or R (Ihaka and Gentleman 1996) might provide greater ﬂexibility. It is perhapsworthwhile noting that if the automatic class-interval selection provided with manyGIS display software is relied on, a number of alternative classiﬁcations should beexplored to ensure that the pattern seen on the screen is not an artifact of theclassiﬁcation algorithm.Anselin and Bao (1997) have provided a SpaceStat extension for ArcView 3.x.SpaceStat itself is a program for undertaking various spatial analyses (Anselin 1988,1992). As a stand-alone program it has facilities for the input of spatial data anda variety of analyses including creation and manipulation of spatial weights, descript-ive spatial statistics and spatial regression. The ArcView extension allows the userto transfer locational and associated attribute data from a shapeﬁle to SpaceStat,and to transfer results of the analyses back into ArcView for display via a menuwhich is added to the ArcView menubar.Aldstat and Getis (2002) have programmed Visual Basic (VBA) macros for usewith ArcGIS to carry out a range of point pattern analyses. Visual Basic is embeddedwithin ArcGIS as a development tool to allow extensions to be coded to carry outanalyses not included within ArcGIS. VBA has the disadvantage that it",
    "chunk_order_index": 234,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9bec1a25d136ee5b7ff7fc8cf063a0c5": {
    "tokens": 1200,
    "content": "a shapeﬁle to SpaceStat,and to transfer results of the analyses back into ArcView for display via a menuwhich is added to the ArcView menubar.Aldstat and Getis (2002) have programmed Visual Basic (VBA) macros for usewith ArcGIS to carry out a range of point pattern analyses. Visual Basic is embeddedwithin ArcGIS as a development tool to allow extensions to be coded to carry outanalyses not included within ArcGIS. VBA has the disadvantage that it is an inter-preted rather than compiled language, so the applications will run somewhat slowerthan a standalone program. However, dynamic link libraries may be written for“core” spatial analysis tasks and VBA used to link them to ArcGIS in a rather moretightly coupled fashion.Unix users may use Xgobi (Cook, Majure, Symanzik, and Cressie 1996, Symanzik,Majure, and Cressie 1997) which links with ArcView to provide a range of toolsfor visually exploring multivariate data. Haining (1998) has been responsible forthe generation of a set of procedures for use with Arc/Info which considerably extend the capabilities of that software to include relative risk models for diseasedata and spatial regression models. MacEachren, Brewer, and Pickle (1998) detailan extension to ArcView to provide a set of additional tools for the exploration ofspatial data including linked brushing and outlier detection. ESRI’s replacement of ArcView 3.x with the integrated ArcGIS system where the scripting language isVisual Basic appears to have created a market for tools to convert existing Avenuescripts into Visual Basic (an Internet search reveals a number of organizations offer-ing such services, among them: Compass Informatics in Dublin, Ireland; CEDRACorporation in New York; and Data East LLC in Novosibirsk, Russia).Data Integration and ManagementIn many studies involving spatial data analysis, the role of GIS is that of provid-ing an integrating environment. There are a number of related issues that requirea little exploration so that the result of the data manipulation and integration isreliable. Goodchild (2000) attributes the observation that “GIS technology lets usproduce rubbish faster, more cheaply, and in greater volume than ever before” to David Rhind. It is probably worth bearing in mind these words each time youundertake a GIS operation on your spatial data. To give an example, a recent studyTHO_C21  19/03/2007  11:30  Page 383 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f384MARTIN E. CHARLTONin the UK used the number of motorway interchanges per head of population inan area as one measure of accessibility to that area. A point shapeﬁle was createdfor the motorway interchanges in the UK, this was then intersected with a polygonshapeﬁle of the areas of interest, and a count produced of the number of motorwayinterchanges in each area. Such an operation is a relatively common GIS task. Inassessing the results of the study a problem came to light which had potentiallyserious implications for the modeling that had taken place. In several areas, one ofthe boundaries ran along a section of motorway which happened to include an inter-change. What should be done about such interchanges – are they to be allocatedto one area and one only, or are they to be allocated to the two neighboring areas(or perhaps half an interchange assigned to each area)?The software used assumed that the point which represented the interchange couldbe assigned to one area only. Blakemore (1984) identiﬁed the status of a point withrespect to a polygon as being: (1) wholly inside; (2) probably inside; (3) on theboundary; (4) probably outside; or (5) wholly outside. In the situation of the inter-changes on the motorways, cases (2), (3), or (4) presented themselves. In cases (2) and(4), depending on where the point representing the interchange had been chosen,the interchange would be assigned to one polygon and not its neighbor on the otherside of the motorway. In case (3) the software made a choice that may have beenrandom or simply the result of the manner in which the point-in-polygon algorithmunderlying the assignment had been coded by its programmers. Prudent analystswould have at least mapped the assignments following the intersection operation,rather than making the discovery after a great deal of modeling effort.Underlying this are issues of accuracy and appropriateness. Doing the wrong thingwith GIS is no more beneﬁcial than doing the wrong thing without GIS, and GISwill not rescue bad initial decisions.LocationThe data used in GIS are given some form of spatial reference. However, not all thedata might have compatible spatial references. A commonly asked ﬁrst question iswhether the data being gathered together for the study have the same coordinatesystem, and whether they have the same level of resolution. Many of the algorithmsin GIS software assume that the data being manipulated is in some Cartesian coordin-ate system, where the coordinates of each location area are obtained with referenceto an origin and a pair of axes at right angles to each other (usually referred to asthe x- and y-axis). The coordinates are usually referred to as the “x-coordinate”and the “y-coordinate,” or “eastings” and “northings.” For instance, in Great Britain,the national mapping agency, the Ordnance Survey, has its own projection based",
    "chunk_order_index": 235,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-80fe564b98a9c00eeca96c34b1c63c04": {
    "tokens": 1200,
    "content": "data being manipulated is in some Cartesian coordin-ate system, where the coordinates of each location area are obtained with referenceto an origin and a pair of axes at right angles to each other (usually referred to asthe x- and y-axis). The coordinates are usually referred to as the “x-coordinate”and the “y-coordinate,” or “eastings” and “northings.” For instance, in Great Britain,the national mapping agency, the Ordnance Survey, has its own projection basedon a Transverse Mercator projection – published maps and digital data are pro-vided with coordinates measured in meters relative to the origin for the projectionwhich is to the south west of the Scilly Isles. Other data-providing agencies use thisprojection in supplying mappable data, notably the Ofﬁce of National Statistics whichpublishes data from Britain’s decennial censuses. The national mapping agencies ofmost countries have their own projections. The Universal Transverse Mercator pro-jection divides the globe into a set of segments running north–south which occupyTHO_C21  19/03/2007  11:30  Page 384 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fQUANTATIVE METHODS AND GEOGRAPHIC INFORMATION SYSTEMS385six degrees of arc at the equator. The availability of a consistent set of coordinatesremoves one set of problems.How do we deal with the case where data to be integrated is in a series of differ-ent projections? For example, data in UTM coordinates might be being linked with data taken from a hand-held Global Positioning System (GPS) receiver. Themeasurements of location used in the GPS are in latitude and longitude based ona model of the Earth or datum known as WGS84. It is likely that the GPS receiverwill have built into its ﬁrmware a series of commonly used projections such thatthe position display on the screen is in the coordinate system of the locally used pro-jection. The formulae used for these on-the-ﬂy conversions are generally approxim-ate, and the user is best advised to download the stored locations (waypoints) inlatitude and longitude and use the projection conversion facilities of the GIS programat hand to change from geographic to projected coordinates. This may require know-ledge of the projection name, datum, and spheroid, although for commonly usedprojections, this is provided in the software. Using an incorrect datum will usuallyresult in coordinates being shifted some distance from their “true” position. Anaccessible text which deals with some of the detail of projections and datum in GISis Iliffe (2000). The goal of creating the spatial database for manipulation is to haveall the layers with a consistent spatial reference.A second consideration is that of the spatial resolution of the coordinates. It mayappear to be obvious that the coordinates in each layer should have the same levelof resolution (for example that all should be in 1 m coordinates) but it is easy tooverlook this if the layers are from a variety of sources. For example, the OrdnanceSurvey grid reference to 1 m of a point somewhere in the Geography Depart-ment at Newcastle University is 424787, 565115. The 100 m resolution referencewould be 4247, 5651. Grid references from earlier versions of the Central PostcodeDirectory in the UK are to 100 m resolution. Many GIS programs have a facilitywhich allows the transformation from one Cartesian coordinate system to another.This allows data from digitizing tablets to be converted into the coordinate systembeing employed in the spatial database and apparently makes the problem of resolution one that is easily solved – the coordinate values need to be multiplied by100. Unfortunately this introduces a consistent south-west bias in the grid references.This may have repercussions in data integration – for example, points may be assignedto the wrong polygon in an intersection operation. One solution might be to jitterthelocations after the transformation by the addition of a random number betweenzero and 99 to each of the coordinates. While this may be reasonable for pointdata (what is “reasonable” depends on the application) it may cause problems inpreserving topological relationships in polygon data.Allied to the problem of the resolution of the coordinate data is a programmingproblem. In the days when computer storage was expensive, the choice of data pre-cision for the storage of layers was important. The Arc/Info system, for example,allows users to choose whether the locational components of a layer are stored insingle or double precision. What does this mean and what are the implications? A ﬂoating point number in a computer may be stored in a 32- or a 64-bit location,single or double precision respectively. Seven bits of each location are reserved for the abscissa, and one bit for the sign. That leaves 24 bits for the mantissa insingle precision and 56 bits in double precision. The advantage of single precisionTHO_C21  19/03/2007  11:30  Page 385 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f386MARTIN E. CHARLTONis that the locational data only requires half the storage that would be required ifthe coordinates were stored in double precision. The disadvantage is that typicallyseven digits of precision are available",
    "chunk_order_index": 236,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d2b1022e3622450418d340f55787cfd2": {
    "tokens": 1200,
    "content": "Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f386MARTIN E. CHARLTONis that the locational data only requires half the storage that would be required ifthe coordinates were stored in double precision. The disadvantage is that typicallyseven digits of precision are available in single precision compared with 14 for double precision. With coordinate values that are in the hundred thousands – whichincludes most of those at 1 km resolution in UK data – roundoff errors become a problem in GIS operations carried out in single precision. I did not worry toomuch about this until I was examining data from repeated differential GPS surveysof a river in northern England – estimates were needed of the movement of gravelin a particular reach of the river over a period of time. The coordinates were totwo places of decimals – effectively eight signiﬁcant ﬁgures. Quite different answers were obtained when the computations were carried out in double precision ratherthan single precision. With the relative cheapness of storage, this is less of a problem.The disadvantage of being cavalier with storage is the cost of transfer across a network – however, technological improvements in networks will bring these costsdown in future years.Spatial Data and Quantitative MethodsSpatial data does pose some interesting challenges to the analyst. Since the early1970s geographers and others working with spatial data have realized that somecare needs to be taken with its analysis. While recent examples in the geographicliterature (Bailey and Gatrell 1995, Fotheringham and Rogerson 1994, Fischer andGetis 1997, Longley and Batty 1996) suggest that geographers are beginning to concern themselves with the problem of analysis with spatial data, there have beendevelopments in other disciplines notably statistics and computer science (Cressie1993).There has been a diffusion of interest in GIS outside geography and this has led to some interesting developments. Openshaw’s Geographical Analysis Machine(Openshaw, Charlton, Wymer, and Craft 1987) was the result of inquiry on thepart of a group of pediatric oncologists, which engendered further work by others,notably Besag and Newell (1991) and Fotheringham and Zhan (1996), as well asa range of scan statistics for dealing with similar point-based problems, for exampleKulldorff’s spatial scan statistics (Kulldorff 1997).However, there are a number of problems posed by spatial data which shouldbe borne in mind. These include, but are not limited to: spatial autocorrelation,spatial outliers, edge effects, spatial dependency, and the modiﬁable areal unit prob-lem. While geographers in the 1960s were quite happy to punch up the FORTRANcodes from texts such as Cooley and Lohnes (1962) and run the programs on their data ignoring any geographical solecisms, the beneﬁt of hindsight brings circumspection.One of the underlying assumptions of classical inference is that the objects forming the basis of the analysis are independent of each other. However, WaldoTobler observed in 1970 that “everything is related to everything else, but nearthings are more related than distant things” (Tobler 1970); for a recent discussionon this see Phillips (2004) Smith (2004), Goodchild (2004), and Tobler (2004).Stephan (1934) made the observation 70 years ago thatTHO_C21  19/03/2007  11:30  Page 386 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fQUANTATIVE METHODS AND GEOGRAPHIC INFORMATION SYSTEMS387Data of geographic units are tied together, like bunches of grapes, not separate, likeballs in an urn. Of course, mere contiguity in time and space does not itself indicateindependence between units in a relevant variable or attribute, but in dealing with socialdata, we know that by the very virtue of their social character, persons, groups, andtheir characteristics are interrelated and not independent. Sampling error formulas may yet be developed which are applicable to these data, but until then, the older formulas must be used with great caution. Likewise, other statistical measures mustbe carefully scrutinized when applied to these data.Cressie (1993, pp. 14–15) presents an example of the inﬂuence of autocorrela-tion on the estimate of the conﬁdence interval for the population mean. If there is positive autocorrelation, and the usual formula is used, the conﬁdence intervalwill be too narrow. If the data are negatively autocorrelated and we ignore it, the conﬁdence interval will be too wide. This does have implications if we are comparing means for equality. If the data for two samples are positively spatiallyautocorrelated and we choose to ignore this, then we may decide that the samplemeans are not sufﬁciently different for us to be conﬁdent that there is an observabledifference in the population means. Thus, if autocorrelation is ignored, then werun the risk of making the wrong decision. The subject of autocorrelation and itsassociated problems has interested geographers since the early 1970s (for example,Cliff and Ord 1973, 1981",
    "chunk_order_index": 237,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-24e525369a97552ae51a3070b09a9a06": {
    "tokens": 1200,
    "content": "lyautocorrelated and we choose to ignore this, then we may decide that the samplemeans are not sufﬁciently different for us to be conﬁdent that there is an observabledifference in the population means. Thus, if autocorrelation is ignored, then werun the risk of making the wrong decision. The subject of autocorrelation and itsassociated problems has interested geographers since the early 1970s (for example,Cliff and Ord 1973, 1981; Grifﬁth 1987).AggregationAggregation of data from either individual observations to a set of zones, or fromone system of areas to another is a further source of potential problems. A commonoperation in GIS is to take some data which are the attributes of a point coverageand count or aggregate these in some fashion to a set of larger areal units. Theremight be a number of very good reasons for doing this. For example, the areal unitsbeing used might be those of some administrative areas which form the basis of thestudy, or the areal units might be those at which a large corpus of data produced bya third party is available. The GIS operations of intersection or union, followed by some summation and perhaps creation of ratios is typical. As an example, a studyof illness among a particular cohort of children might have the location of the children given as a point reference. If data about the “at-risk” population are onlyknown at an aggregated scale, one option is to aggregate the individual records for the children to the boundaries of the areas. In Openshaw, Charlton, Wymer,and Craft’s (1987) Geographical Analysis Machine GAM, the aggregation was tocircular regions, combining data from two layers – point references of the locationof the residences of children with acute lymphoblastic leukaemia and point refer-ences of the centroids of enumeration districts (small areas used in data collectionin the UK Census of Population).Gehlke and Biehl (1934) observed that if data for census tracts in Cleveland were aggregated to larger units, the correlation coefﬁcient between male juveniledelinquency and median rental income increased as the size of the areal units increased. They observed a similar phenomenon on the correlation between numbersTHO_C21  19/03/2007  11:30  Page 387 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f388MARTIN E. CHARLTONof farmers with the value of farm products taking data from 1,000 rural counties in1910. Robinson (1950) showed that correlations based on data aggregated to somespatial units were different from those which were based on data about the indi-viduals in those units. Thomas and Anderson (1965) came to the conclusion that theﬁndings of Gehlke and Biehl could not be substantiated. However, Openshaw and Taylor (1979) revisited the problem in bivariate analysis, and Fotheringham andothers have investigated the problem in multivariate analysis and spatial modeling(Fotheringham and Wong 1991, Fotheringham, Densham, and Curtis 1995). Theproblem has two components, one due to scale (results may be conditioned on unitsize) and the other due to zoning (different results can be obtained with differentregroupings of zones). If suitable individual level data are available then themethodology proposed by Holt, Steel Tranmer, and Wrigley (1996) and Tranmerand Steel (1998) shows some promise. King (1997) uses an approach based on localforms of regression to deal with the problem.This does have implications for the use of GIS in data manipulation, particularlyin the choice of the areal units used. One GIS operation, often referred to as cross-area aggregation, involves a set of procedures used to estimate data available forone set of areal units to another set of areal units. Typically, the areal units haveentirely different geographies, without the nesting which characterizes administrat-ive spatial hierarchies. In the UK, areas used for the delivery of local governmentservices (districts and unitary authorities) are different in number and size and arenot conterminous with those used for the organization of postal deliveries (postaldistricts). If data are available for a phenomenon at the postal district level (perhapsreadership of a particular newspaper) and data on some other phenomenon, suchas the social characteristics of the population, are available for administrative dis-tricts, then it is tempting to consider how the relationship between the two mightbe modeled. However, to convert the census counts from the administrative geo-graphy to the postal geography requires cross-area aggregation. This is effectivelyan interpolation procedure.There are several ways of achieving this. A union operation between the two setsof areal units will produce another set of areal units in which each new area hasthe attributes of its parent areas. Aggregation may take place using weighting byarea. If we have two sets of areas, the ﬁrst numbered 1, 2, 3,...and the secondidentiﬁed by letter, A, B, C,...then the result of the intersection might producethree new areas that together comprise area A, but are composed of 50 percent ofarea 1, 30 percent of area 2, and 20 percent of area 3. If the variable in questionis, say, p population, then the population of area A is the sum of 50 percent of thepopulation of area",
    "chunk_order_index": 238,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-3b26aeae8e39db679a6bf9cc9e62e797": {
    "tokens": 1200,
    "content": "1, 2, 3,...and the secondidentiﬁed by letter, A, B, C,...then the result of the intersection might producethree new areas that together comprise area A, but are composed of 50 percent ofarea 1, 30 percent of area 2, and 20 percent of area 3. If the variable in questionis, say, p population, then the population of area A is the sum of 50 percent of thepopulation of area 1, 30 percent of the population of area 2, and 20 percent ofthe population of area 3. Other attributes would then be created using a similarweighting. The underlying assumption is that the population is distributed uniformlyaround each area, which may or may not be the case. If some third variable is available whose distribution is known in both the source and target zones (say thelocations of dwellings), then weighting may take this into account.Greater levels of sophistication are available for cross-area aggregation using Poisson regression for count data (Flowerdew 1988) and the Dempster, Laird, andRubin (1977) EM algorithm (Flowerdew and Green 1991). Kehris (1989) has createda suitable GLIM macro together with code to interchange data with Arc/Info as anTHO_C21  19/03/2007  11:30  Page 388 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fQUANTATIVE METHODS AND GEOGRAPHIC INFORMATION SYSTEMS389implementation of this method. Tobler (1991) has suggested pycnophylactic inter-polation as another means of interpolating data from one set of areal units to another.Dummer, Dickinson, Charlton, and Parker (2000) use conditional probabilities inthe estimation of the population of young people by ethnic group for one regionin the UK based on aggregated data – one advantage of this method is that it pro-duces conﬁdence intervals on the resulting counts. Although the authors suggest itcould be applied to other regions in the UK, its data requirements might precludeits adoption in other parts of the world. However, in most cases, aggregation willbe based on whatever has been provided by the software manufacturer and thisusually means areal weighting or weighting by another variable.The Post-Analysis Role of GISGIS has also a role after any analysis in the exploration and interpretation of theresults. The extraction of the mean of a distribution or the median might lead tomapping those locations with values above or below the statistic – is there a spatialpattern, and is it regional or local? With techniques such as regression, among the outputs are a set of predicted values and the residuals (the difference between theobserved and predicted values). Here, GIS has a more obvious role. The analystshould certainly plot the spatial distribution of the residuals. Useful diagnostics arethe standardized or studentized residuals as these values have a mean of zero anda standard deviation of unity. This allows identiﬁcation of pattern in the residuals– the class intervals for the symbolism might be in units of 1 standard deviationeither side of the mean. It also allows the identiﬁcation of unusually high or lowvalues – the class intervals might be chosen to identify those in the tails of the dis-tribution of values (that is, ±1.96 and ±2.58 standard deviations from the mean).Again, the questions which suggest themselves include the identiﬁcation of patternsin the residuals. If a linear regression has been ﬁtted using the OLS procedure inSPSS, for example, and pattern is observed in the plot of the residuals, this wouldsuggest either that one or more variables have been omitted, or that OLS regres-sion is inappropriate and a method needs to be used that will deal with the spatialdependency in the data. Models to think about here include drift analysis (Casettiand Can 1999), the expansion method (Casetti 1972, 1992), or geographicallyweighted regression (Fotheringham, Brunsdon, and Charlton 2002).Other multivariate techniques also have mappable outputs. For example, one out-put from a discriminant analysis is the prediction that an observation will have mem-bership of a particular group. Mis-classiﬁcation occurs when the predicted groupmembership differs from the actual group membership. A plot of the misclassiﬁedand correctly classiﬁed locations may suggest some further steps in the analysis. Aswell as a predicted group membership, another output is the probability of member-ship of each group – plotting either the probability of membership of the observedor the predicted class again may suggest further steps to take in the analysis.Principal components analysis is a frequently used data reduction technique inwhich an attempt is made to create a set of new variables (“principal components”)a few of which will account for most of variation in the data set. One output is aset of values of the new variables (“component scores”) which again may be mappedTHO_C21  19/03/2007  11:30  Page 389 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f390MARTIN E. CHARLTONto give some insights into",
    "chunk_order_index": 239,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7f1ae780521432e0988af302ea27f493": {
    "tokens": 1200,
    "content": "/2007  11:30  Page 389 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f390MARTIN E. CHARLTONto give some insights into the problem being addressed – where are the outliers,for example, and why might those locations have such unusual values?Cluster analysis is a set of classiﬁcation techniques which attempt to partition aset of objects into some (generally) distinct groups. There are some techniques whichattempt to ﬁnd a hierarchy in the data (agglomerative techniques such as Ward’smethod, or divisive techniques such as monothetic and polythetic division) and somewhich are non-hierarchical, such as k-means or partitioning around medoids. If a cluster analysis is being undertaken on spatial data, then a plot of the locationsof the predicted members of each cluster may be a helpful tool in the interpreta-tion of the cluster results. K-means provides a measure of the distance from thelocation of an object in k-space to its cluster centroid; again, a plot of the valueswill show whether the objects which are “distant” from a cluster center exhibit anyspatial pattern. Other cluster methods, for example those based on density methods,also provide a value which can be mapped.Geographically weighted regression (GWR) (Fotheringham, Brunsdon, and Charlton2002) is an example of a technique where the outputs are intended for mapping.GWR attempts to deal with spatial dependency in the data set being modeled byincorporating this dependency into a weighting scheme in a kernel regression. Amongthe outputs are parameter estimates of the local model structure at the locations atwhich the data have been collected. A number of different weighting schemes arepossible, but they share the common feature that data locations near the point wherethe parameters are being estimated are given a greater weight in the estimation pro-cedure than locations further away. In one sense this embodies the view expressedby Tobler (1991, 2004). If a set of parameters is desired for some location u, thenthese are obtained with the estimatorββˆ(u) ==(XTW(u)X)−−1XTW(u)Y(21.1)where W(u) is the weight matrix for the location u. It should be noted that thelocation uneed not be one at which data have been collected. GWR can be thus usedto interpolate a surface of parameter estimates. As well as a parameter vector foreach u, there is a vector of location-speciﬁc standard errors. If the regression points(that is, those at which parameter estimates are being provided) coincide with thedata points, further diagnostics are obtained, including a set based around the hatmatrix (the matrix which converts the observed Ys into the predicted Ys). The diag-nostics include: measures of inﬂuence and leverage, and Cook’s D values. A localgoodness of ﬁt measure can also be computed (see an early suggestion in Fotheringhamand Rogerson 1994). In addition to providing a model with a Gaussian error term forﬁtting data from a continuous distribution, GWR models also exist for dichotomousresponse variables (logistic) and response variables which are positive non-zero integers (Poisson) (Fotheringham, Brunsdon, and Charlton 2002).The plethora of parameter estimates and associated diagnostics from GWR bringsin turn its own set of visualization problems. If the data relate to point objects, say,houses or people, then symbolism of varying sizes and colors can be used to showthe variation in the estimates. Should the range include zero, then the symbolismcan be a conjunction of size and color, with say, blue for negative values and red forpositive values. There may be cases in which the number of symbols to be displayedTHO_C21  19/03/2007  11:30  Page 390 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fQUANTATIVE METHODS AND GEOGRAPHIC INFORMATION SYSTEMS391on a map to the spatial variation in a parameter estimate is so great that it con-fuses any pattern. One solution is to convert the point output into a surface – thiscan be done by a further process of interpolation (using some form of distanceweighted smoothing, for example). A post-GWR interpolation stage does, however,introduce further choices by the analyst, such as a smoothing parameter, which may obscure rather than reveal any spatial variation if it is injudiciously chosen.An alternative approach is to make use of the ability of GWR to create parameterestimates at locations other than those at which the data were selected. If these latter locations are the mesh points of a regular grid, then these can be plotted as a smoothly varying surface. The disadvantage with the second approach is thatdiagnostics based on the hat matrix are not available.If the geographically weighted regression is based on data for areas, the area values can themselves be mapped. If the software developed by Fotheringham,Brunsdon, and Charlton (2002) is being used, the output has no ID variable to link it through a tabular-merge with an existing areal database, so an intersect operation is required to tag the records in the GWR",
    "chunk_order_index": 240,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a07c06e21660fdfbe81a516fe8720cb3": {
    "tokens": 1200,
    "content": "surface. The disadvantage with the second approach is thatdiagnostics based on the hat matrix are not available.If the geographically weighted regression is based on data for areas, the area values can themselves be mapped. If the software developed by Fotheringham,Brunsdon, and Charlton (2002) is being used, the output has no ID variable to link it through a tabular-merge with an existing areal database, so an intersect operation is required to tag the records in the GWR output with the IDs of theareas to which they belong. After that, choropleth mapping is one approach to displaying the results – again with different colors and intensities of color to modelthe spatial variation.One advantage of GIS with a macro language, such as ESRI’s Arc Macro Language,is that plotting a range from maps from a GWR run can be automated to the extentof creating a linked series of macros, with a single “driver” macro to generate andplot the necessary maps. Many of the maps in Fotheringham, Brunsdon, and Charlton(2002) were generated in this fashion. The advantage is that new results from achange of, say, bandwidth, can be mapped with the minimum of effort leaving maximum time for their interpretation. One perhaps ought to bear in mind Rhind’sstrictures mentioned earlier in this chapter when adopting such an approach.CONCLUSIONSThe upsurge of interest since the 1980s in the analysis of spatial data has been paralleled by the wide diffusion geographic information software and expertise. It is notable that this diffusion has taken place in many disciplines outside of geo-graphy. This has been accompanied by a welcome interest in the problems of spatial data analysis from the statistical community. None of these three strandsof activity shows any sign of abating.The link between quantitative analysis and GIS is bi-directional. Inevitably,many of those who have an interest in the quantitative analysis of spatial data willencounter GIS software in its role of providing an integrating environment and perhaps a tool to assist in the interpretation of the results. On the other hand, there will be those who are frequent users of GIS who encounter a problem thatrequires some statistical analysis. The former group need to be aware of thestrengths and weaknesses of GIS; whether they use a particular piece of softwareor employ somebody to operate that software is a separate question, but the neces-sity for appreciation remains. Those in the latter group should perhaps be awareof the problems and opportunities offered by the statistical analysis of spatial data.THO_C21  19/03/2007  11:30  Page 391 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f392MARTIN E. CHARLTONThat the software is easy to use does not absolve users from thinking about thesolutions and whether they are appropriate.REFERENCESAldstadt, J. and Getis, A. 2002. Point pattern analysis in an ArcGIS environment.InProceedings of the CSISS Specialist Meeting on New Tools for Spatial Data Analysis,SantaBarbara, CA, USA. Santa Barbara, CA: Center for Spatially Integrated Social Science.Anselin, L. 1988. Spatial Econometrics: Methods and Models. Dordrecht, Kluwer.Anselin, L. 1992. SpaceStat Tutorial: A Workbook for Using SpaceStat in the Analysis of Spatial Data.Santa Barbara, CA: National Center for Geographic Information and Analysis Technical Software Series S-92-1.Anselin, L. and Bao, S. 1997. Exploratory spatial data analysis linking SpaceStat and ArcView.In M. M. Fischer and A. Getis (eds) Recent Developments in Spatial Analysis. Berlin: Springer-Verlag, pp. 35–59.Bailey, T. C. and Gatrell, A. C. 1995. Interactive Spatial Data Analysis. Harlow: Longman.Besag, J. and Newell, D. 1991. The detection of clusters in rare diseases.Journal of the RoyalStatistical Society, Series A154: 143–55.Blakemore, M. J. 1984. Generalisation and error in spatial databases. Cartographica21:131–9.Boots, B. 1986. Voronoi (Thiessen) Polygons. Norwich: GeoBooks.Casetti, E. 1972. Generating models by the expansion method: Applications to geographicresearch. Geographical Analysis4: 81–91.Casetti, E. 1992. Bayesian regression and the expansion method. Geographical Analysis24:58–74.Casetti, E. and Can, A. 1999. The econometric estimation and testing of DARP models. Journalof Geographical Systems1: 91–106.Cliff, A. D. and Ord, J. K. 1973. Spatial Autocorrelation. London: Pion.Cliff, A. D. and Ord, J. K. 1981. Spatial Processes: Models and Applications. London: Pion.Cook, D., Majure, J. J., Symanzik, J., and Cressie, N. 1996. Dynamic graphics in a GIS:Exploring and analyzing multivariate spatial data using linked software. ComputationalStatistics11: 467–80.Cook, D., Symanzik, J., Majure, J. J., and Cressie, N. 1997. Dynamic graphics in a GIS:More examples using linked",
    "chunk_order_index": 241,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-20dbac5ca2b3c1ef9c40b1b4af589170": {
    "tokens": 1200,
    "content": "Applications. London: Pion.Cook, D., Majure, J. J., Symanzik, J., and Cressie, N. 1996. Dynamic graphics in a GIS:Exploring and analyzing multivariate spatial data using linked software. ComputationalStatistics11: 467–80.Cook, D., Symanzik, J., Majure, J. J., and Cressie, N. 1997. Dynamic graphics in a GIS:More examples using linked software. Computers and Geosciences23: 371–85.Cooley, W. W. and Lohnes, P. R. 1962. Multivariate Procedures for the Behavioural Sciences.New York: John Wiley and Sons.Cressie, N. A. C. 1993. Statistics for Spatial Data. New York: John Wiley and Sons.Davis, J. C. 2002. Statistics and Data Analysis in Geology. New York: John Wiley and Sons.Dempster, A., Laird, N., and Rubin, D. B. 1977. Maximum likelihood from incomplete datavia the EM algorithm (with discussion). Journal of the Royal Statistical Society B39: 1–38.Dorling, D. 1996. Area Cartograms: Their Use and Creation. Norwich: University of EastAnglia.Dummer, T. B. J., Dickinson, H. O., Charlton, M. E., and Parker, L. 2000. Estimating thepopulation of young people by ethnic group in the Northern Region of England1971–1991. Environment and Planning A32: 1935–58.Fischer, M. M. and Getis, A. (eds). 1997. Recent Developments in Spatial Analysis. Berlin:Springer-Verlag.Flowerdew, R. 1988. Statistical Methods for Areal Interpolation: Predicting Count Data froma Binary Variable. Lancaster: Universities of Lancaster and Newcastle, Northern RegionalResearch Laboratory Research Report 16.THO_C21  19/03/2007  11:30  Page 392 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fQUANTATIVE METHODS AND GEOGRAPHIC INFORMATION SYSTEMS393Flowerdew, R. and Green, M. 1991. Data integration: Statistical methods for transferringdata between zonal systems. In I. Masser and M. Blakemore (eds) Handling GeographicInformation. Harlow: Longman, pp. 38–54.Fotheringham, A. S., Brunsdon, C., and Charlton, M. E. 2000. Quantitative Geography.London: Sage.Fotheringham, A. S., Brunsdon, C., and Charlton, M. E. 2002. Geographical Weighted Regres-sion: The Analysis of Spatially Varying Relationships. Chichester: John Wiley and Sons.Fotheringham, A. S., Densham, P. J., and Curtis, A. 1995. The zone deﬁnition problem inlocation-allocation modelling. Geographical Analysis27: 60–77.Fotheringham, A. S. and Rogerson, P. A. (eds). 1994. Spatial Analysis and GIS. London:Taylor and Francis.Fotheringham, A. S. and Wong, D. 1991. The modiﬁable areal unit problem in multivariatestatistical analysis. Environment and Planning A23: 1025–44.Fotheringham, A. S. and Zhan, F. 1996. A comparison of three exploratory methods forcluster detection in spatial point patterns. Geographical Analysis28: 200–18.Gaile, G. L. and Burt, G. E. 1980. Directional Statistics. Norwich: GeoBooks.Gehlke, C. D. and Biehl, K. 1934. Certain effects of grouping on the size of the correlationcoefﬁcient in census tract material. Journal of the American Statistical Association,Supplement29: 169–70.Goodchild, M. F. 1986. Spatial Autocorrelation. Norwich: GeoBooks.Goodchild, M. F. 2000. Cartographic futures on a digital earth. Cartographic Perspectives36: 3–11.Goodchild, M. F. 2004. The validity and usefulness of laws in geographic information scienceand geography. Annals of the Association of American Geographers94: 300–3.Grifﬁth, D. A. 1987. Spatial Autocorrelation: A Primer.Washington, DC: Association ofAmerican Geographers.Haining, R. P. 1998. Spatial statistics and the analysis of health data. In A. C. Gatrell andM. Loytonen (eds) GIS and Health. London: Taylor and Francis, pp. 29–47.Holt, D., Steel, D. G., Tranmer, M., and Wrigley, N. 1996. Aggregation and ecological effectsin geographically based data. Geographical Analysis28: 244–61.Ihaka, R. and Gentleman, R. 1996. R: A language for data analysis and graphics. Journalof Computational and Graphical Statistics5: 299–314.Iliffe, J. C. 2000. Datums and Map Projections for Remote Sensing GIS and Surveying. BocaRaton, FL: CRC Press.Kehr",
    "chunk_order_index": 242,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-979c15092d49e9c32663061b2a83d81c": {
    "tokens": 1200,
    "content": "ley, N. 1996. Aggregation and ecological effectsin geographically based data. Geographical Analysis28: 244–61.Ihaka, R. and Gentleman, R. 1996. R: A language for data analysis and graphics. Journalof Computational and Graphical Statistics5: 299–314.Iliffe, J. C. 2000. Datums and Map Projections for Remote Sensing GIS and Surveying. BocaRaton, FL: CRC Press.Kehris, E. 1989. Interfacing Arc/Info and GLIM: A Progress Report.Lancaster: Universityof Lancaster,Northwest Regional Research Laboratory Research Report No. 5.Kellerman, A. 1981.Centrographic Measures in Geography. Norwich: GeoBooks.King, G. 1997. A Solution to the Ecological Inference Problem: Reconstructing IndividualBehaviour from Aggregate Data. Princeton, NJ: Princeton University Press.Kulldorf, M. 1997. A spatial scan statistic. Communications in Statistics: Theory andMethods26: 1481–96.Longley, P. A. and Batty, M. 1996. Spatial Analysis: Modelling in a GIS Environment.Cambridge: GeoInformation International.MacEachren, A. M., Brewer, C. A., and Pickle, L. 1998. Visualizing georeferenced data:Representing reliability of health statistics. Environment and Planning A30: 1547–61.Openshaw, S. 1984. The Modiﬁable Areal Unit Problem. Norwich: GeoBooks.Openshaw, S., Charlton, M. E., Wymer, C., and Craft, A. W. 1987. A mark 1 geographicalanalysis machine for the automated analysis of point data sets. International Journal ofGeographical Information Systems1: 359–77.Openshaw, S. and Taylor, P. J. 1979. A million or so correlation coefﬁcients: Three experi-ments on the modiﬁable areal unit problem. In N. Wrigley (ed.) Statistical Applicationsin the Spatial Sciences. London: Pion, pp. 127–44.THO_C21  19/03/2007  11:30  Page 393 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f394MARTIN E. CHARLTONPhillips, J. D. 2004. Doing justice to the law. Annals of the Association of AmericanGeographers 94: 290–3.Robinson, W. R. 1950. Ecological correlation and the behaviour of individuals. AmericanSociological Review15: 351–7.Smith, J. M. 2004. Unlawful relations and verbal inﬂation. Annals of the Association ofAmerican Geographers94: 294–99.Stephan, F. F. 1934. Sampling errors and interpretations of social data ordered in time and space. Journal of the American Statistical Association29: 165–6.Thomas, E. N. and Anderson, D. L. 1965. Additional comments on weighting values in correlation analysis of areal data. Annals of the Association of American Geographers55:492–505.Tierney, L. 1990. LISP-STAT: An Object-oriented Environment for Statistical Computingand Dynamic Graphics. New York: John Wiley and Sons.Tobler, W. R. 1970. A computer movie simulating urban growth in the Detroit region.Economic Geography46: 234–40.Tobler, W. R. 1991. Frame-independent spatial analysis. In M. F. Goodchild and S. Gopal(eds) Accuracy of Spatial Databases. London: Taylor and Francis, pp. 115–22.Tobler, W. R. 2004. On the ﬁrst law of geography: A reply. Annals of the Association ofAmerican Geographers94: 304–10.Tranmer, M. and Steel, D. G. 1998. Using census data to investigate the causes of the ecological fallacy. Environment and Planning A30: 817–31.Venables, W. N. and Ripley, B. D. 2002. Modern Applied Statistics with S (4th edn). NewYork: Springer.THO_C21  19/03/2007  11:30  Page 394 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 22Spatial Cluster AnalysisGeoffrey M. JacquezWe may at once admit that any inference from the particular to the general must beattended with some degree of uncertainty, but this is not the same as to admit that suchinference cannot be absolutely rigorous, for the nature and degree of the uncertaintymay itself be capable of rigorous expression. In the theory of probability, as developedin its application to games of chance, we have the classic example proving this pos-sibility. If the gambler’s apparatus are really true or unbiased, the probabilities of the different possible events, or combinations of events, can be inferred by a rigorousdeductive",
    "chunk_order_index": 243,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-021c38d6c1d99aa7cc51d194537efbe9": {
    "tokens": 1200,
    "content": "some degree of uncertainty, but this is not the same as to admit that suchinference cannot be absolutely rigorous, for the nature and degree of the uncertaintymay itself be capable of rigorous expression. In the theory of probability, as developedin its application to games of chance, we have the classic example proving this pos-sibility. If the gambler’s apparatus are really true or unbiased, the probabilities of the different possible events, or combinations of events, can be inferred by a rigorousdeductive argument, although the outcome of any particular game is recognized to be uncertain. The mere fact that inductive inferences are uncertain cannot, therefore, beaccepted as precluding perfectly rigorous and unequivocal inference. (Fisher 1935)Humility is indeed wise for the spatial analyst! (Bailey and Gatrell 1995)Spatial cluster analysis plays an important role in quantifying geographic vari-ation patterns. It is commonly used in disease surveillance, spatial epidemiology, population genetics, landscape ecology, crime analysis, and many other ﬁelds, butthe underlying principles are the same. This chapter provides an overview of a probabilistic approach that is the foundation of spatial cluster analysis. It ﬁrst pro-vides a working deﬁnition of a cluster, founded on the type of data to be analyzed.The role of cluster analysis in Exploratory Spatial Data Analysis (ESDA) is dis-cussed and provides an entrée into ﬁve components that underlie statistical patternrecognition. The clustering typology of global, local, and focused methods is thendeﬁned, followed by an overview of descriptors of cluster morphology. Approachesto quantifying cluster change and persistence are summarized, and issues of multipletesting are addressed. The chapter concludes with an overview of some softwareresources for undertaking cluster analyses.What is a Cluster?In order to deﬁne a spatial cluster we ﬁrst must consider the kinds of data that arebeing studied. The information to be clustered may be event-based, population-based,THO_C22  20/03/2007  15:15  Page 395 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f396GEOFFREY M. JACQUEZﬁeld-based, or feature-based. Event-based data include point locations (such as theplaces of residence and time of diagnosis of cases of disease in people, or the locationsof a species of tree in a forest) and counts (accidents at particular road intersections).Population-based data incorporate information on the population from which theevents arose, and include disease rates with case counts in the numerator and size ofthe at-risk population in the denominator. Field-based data are observations that arecontinuously distributed over space, and include concentrations and temperatures.Feature-based data include boundaries and polygons that may be derived from ﬁeld-based data, such as zones of rapid change in an attribute’s value.A spatial cluster might then be deﬁned as an excess of events (for event- andpopulation-based data, such as a cancer cluster) or of values (for ﬁeld-based data,such as a grouping of excessively high concentrations of cadmium in soils) in geo-graphic space. For feature-based data, a cluster might be a spatial aggregation ofboundaries. But in practice, the term “cluster” is too generic and does not conveyinformation on cluster morphology, such as descriptors of magnitude of the excessor deﬁcit, geographic size and shape of the cluster and the locations of spatial outliers, and descriptors of boundary shape, as described in more detail later inthis chapter. For now, it is useful to think of a “cluster” as a spatial pattern thatdiffers in important respects from the geographic variation expected in the absenceof the spatial processes that are being investigated. This is a key concept – that“clustering” is always measured relative to a null expectation.Why Search for Clusters?Cluster analysis plays important roles in the construction of spatial models and in ESDA. Model construction requires an understanding of the patterns of spatial variation as one often wants to incorporate relevant features of attribute variabilityinto the model. ESDA involves the identiﬁcation and description of spatial patterns(such as outliers, clusters, hotspots, cold spots, trends, and boundaries) and hastwo primary objectives:•Objective 1: Pattern recognition using visualization, spatial statistics and geo-statistics to identify the locations, magnitudes, and shapes of statistically signiﬁcantpattern descriptors;•Objective 2: Hypothesis generation to specify realistic and testable explanationsfor the geographic patterns found under Objective 1.Statistical Pattern RecognitionSpatial patterns are of interest because they are the trace of space-time processesthat are the focus of geographic studies. For example, in cancer research spatialpatterns contain the geographic trace of processes, covariates, and factors (such as exposures to environmental carcinogens; access to cancer screening facilities; behaviors mediating cancer risks, and so on) that determine how cancer risk variesacross and is expressed within human populations.THO_C22  20/03/2007  15:15  Page 396 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIAL CLUSTER ANALYSIS397There are several approaches to pattern recognition, including visualization tech-niques that rely on the human",
    "chunk_order_index": 244,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-fb10ae862ae3732c6f8d8aa35b9be7f9": {
    "tokens": 1200,
    "content": "Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIAL CLUSTER ANALYSIS397There are several approaches to pattern recognition, including visualization tech-niques that rely on the human visual cortex (for example, “eye-balling”), kernel-basedmethods that accentuate differences on a surface (for example, median smoothingtechniques such as headbanging – see Kaﬁdar 1996, Gelman, Price, and Lin 2000);artiﬁcial intelligence approaches (for instance, neural network and genetic algorithms– Pandya and Macey 1996), and methods of statistical pattern recognition that arethe foundation of ESDA (Bailey and Gattrell 1995; Moore and Carpenter 1999;Jacquez 1998, 2000; Rushton and Elmes 2000). Most commonly used spatial clusteranalysis methods are founded on statistical pattern recognition.Statistical pattern recognitionproceeds by calculating a statistic (for instance, spatial cluster statistic, autocorrelation statistic, boundary statistic, etc.) that quantiﬁesa relevant aspect of spatial pattern in event-, population-, ﬁeld- or feature-baseddata. For human disease this might be a health outcome (for example, case/controllocations, incidence, or mortality rate), putative cause (for example, exposure toagricultural pesticides), risk factor (smoking prevalence, for example) or access measure (for instance, availability of prostate screening). The numerical value ofthis statistic is then compared to the distribution of that statistic’s value under a null spatial model. This provides a probabilistic assessment of how unlikely anobserved spatial pattern is under the null hypothesis (Gustafson 1998). Waller andJacquez (1995) formalized this approach by identifying ﬁve components of a testfor spatial pattern:•The test statisticquantiﬁes a relevant aspect of spatial pattern (for example,Moran’s I, Geary’s c, LISA, a spatial clustering metric, etc.);•The alternative hypothesisdescribes the spatial pattern that the test is designedto detect. This may be a speciﬁc alternative, such as clustering near a focus, orit may be the omnibus “not the null hypothesis”;•The null hypothesisdescribes the spatial pattern expected when the alternativehypothesis is false (for instance, uniform cancer risk);•The null spatial modelis a mechanism for generating the reference distribu-tion; this may be based on distribution theory, or it may use randomization (forinstance, Monte Carlo) techniques – for example, many disease cluster tests employheterogeneous Poisson and Bernoulli models for specifying null hypotheses (seeLawson and Kulldorff 1999);•The reference distributionis the distribution of the test statistic when the nullhypothesis is true.Comparison of the test statistic to the reference distribution allows calculation ofthe probability of observing that value of the test statistic under the null hypothesisof no clustering. This ﬁve-component mechanism underpins most tests commonlyused in spatial cluster analysis.Null or Neutral Hypothesis?There still is some debate as to how the null hypo-thesis and null spatial model should be speciﬁed. Many implementations of spatialcluster tests employ the null hypothesis of Complete Spatial Randomness or CSR.In the real world, CSR is an appropriate model for pure noise processes such asthe static on a television screen when a channel with no signal is selected. But mostgeographic systems are highly complex and a null hypothesis of CSR is rarely, ifTHO_C22  20/03/2007  15:15  Page 397 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f398GEOFFREY M. JACQUEZever, appropriate. While CSR is useful in some situations, it is not a relevant nullhypothesis for highly complex and organized systems such as those encountered inthe physical, environmental, and health sciences including ﬁelds such as geography,spatial epidemiology, and exposure assessment (Liebisch, Jacquez, Goovaerts, andKaufmann 2002). CSR is not relevant because spatial randomness rarely, if ever,occurs – some spatial pattern is almost always present. Hence, rejecting CSR haslittle scientiﬁc value because it does not describe any plausible state of the system.The term “Neutral Model” captures the notion of a plausible system state that can be used as a reasonable null hypothesis (for example, “background variation”).A typology of neutral models that account for differences in underlying populationsizes and for regional and local variation in mean values is one mechanism for con-structing null hypotheses that are more plausible than CSR (Goovaerts and Jacquez2004, 2005). The problem then is to identify spatial patterns above and beyondthat incorporated into the neutral model. In this chapter we will continue to usethe terms “null model” and “null hypothesis,” with the proviso that they denoteappropriate levels of spatial pattern expected in the absence of the hypothesizedalternative spatial process.Types of TestsThere are dozens of cluster statistics (see Jacquez, Grimson, Waller, and Wartenberg1996, Jacquez, Waller, Grimson, and Wartenberg 1996; Lawson and Kulldorff 1999,among others, for reviews), and",
    "chunk_order_index": 245,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9109c873af924f23812c3d49b2cf0d76": {
    "tokens": 1200,
    "content": "we will continue to usethe terms “null model” and “null hypothesis,” with the proviso that they denoteappropriate levels of spatial pattern expected in the absence of the hypothesizedalternative spatial process.Types of TestsThere are dozens of cluster statistics (see Jacquez, Grimson, Waller, and Wartenberg1996, Jacquez, Waller, Grimson, and Wartenberg 1996; Lawson and Kulldorff 1999,among others, for reviews), and presentation of these statistics would ﬁll most ofthis book. Instead, we now present the characteristics of global, local, and focusedtests with a few commonly used statistics as examples.Globalcluster statistics are sensitive to spatial clustering, or departures from the null hypothesis, that occur anywhere in the study area. Many early tests forspatial pattern, such as Moran’s I(Moran 1950) were global in nature and providedone statistic, such as a global autocorrelation coefﬁcient, that summarized spatialpattern over the entire study area. While global statistics can identify whether spatial structure (for instance, clustering, autocorrelation, uniformity) exists, theydo not identify where the clusters are, nor do they quantify how spatial dependencyvaries from one place to another.Localstatistics such as Local Indicators of Spatial Autocorrelation (LISA) (Anselin1995, Ord and Getis 1995) quantify spatial autocorrelation and clustering withinthe small areas that together comprise the study area. Many local statistics haveglobal counterparts that often are calculated as functions of local statistics. For example, Moran’s global autocorrelation statistic is the scaled sum of the LISA statistics that are calculated as:(22.1)Here Llis the LISA statistic for area i, ziis the observation at location i, scaled to have a mean of 0 and unit standard deviation (a z-score), and the term in thesummation is the average within those areas immediately adjacent to the ith area.Local statistics thus can tell you the nature of spatial dependency (for example, not  Lzwzliijj =∑ THO_C22  20/03/2007  15:15  Page 398 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIAL CLUSTER ANALYSIS399signiﬁcantly different from the null expectation, cluster of high values, cluster oflow values, and high or low spatial outlier) in a given locality, while also providinga global test.Focusedstatistics quantify clustering around a speciﬁc location called a focus.These tests are particularly useful for exploring possible clusters of disease near potential sources of environmental pollutants. For example, Lawson (1989) andWaller, Turnbull, Clark, and Nasca (1992) proposed tests that score each area forthe difference between observed and expected disease counts, weighted by degreeof exposure to the focus:(22.2)Here there are Nareas, giis a function deﬁning the exposure to the focus, oiis the observed number of cases in area i, and eiis the expected number of cases inthat area. A commonly used exposure function is the inverse distance to the focus(1/d). The null hypothesis is no clustering relative to the focus, and the expecteddisease count thus is calculated as the Poisson expectation using the population atrisk in each area and the assumption that disease risk is uniform over the studyarea.Waller, Turnbull, Clark, and Nasca (1992) used this test to explore whether casesof leukemia clustered near 12 hazardous waste sites in upstate New York that wereinjecting trichloroethylene (TCE) into the groundwater. The Score test found someof the foci to be associated with high leukemia risk, and was signiﬁcant after adjust-ing for the 12 repeated tests.Tests for Cluster AssociationOnce clusters are identiﬁed they deﬁne feature sets that can be compared to theconﬁguration of other feature sets. This is an exercise in pattern matching, ratherthan statistical pattern recognition. So, for example, one can ask whether the edgesof disease clusters are near the edges of pollutant plumes. An ecologist might askwhether the spatial distribution of species abundance is associated with habitat patches, and so on. This kind of pattern matching task has been called the mapcomparison problem (Jacquez 1995), and has been addressed using methods of geographic boundary analysis (Jacquez, Maruca, and Fortin 2000). Two approacheswill be discussed. The ﬁrst quantiﬁes boundary overlap, the second quantiﬁes areaoverlap.Boundary overlapJacquez (1995) proposed four tests for the overlap of geographic boundaries. For ease of reference, we will term one set of boundaries boundary Gand the other Boundary H. For example, Hmight correspond to the edges of clusters in ahealth related variable and Gmight be the cluster edges for a pollutant plume. Thestatistics are based on the nearest neighbor distances between boundary elements  UgoeiiiiN  ( )=−=∑ 1THO_C22  20/03/2007  15:15  Page 399 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f400GEOFFREY M.",
    "chunk_order_index": 246,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7402858fbe812734f42d8620051fdb96": {
    "tokens": 1200,
    "content": "22  20/03/2007  15:15  Page 399 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f400GEOFFREY M. JACQUEZ(BEs), which are those geographic coordinates that deﬁne the cluster boundary. Theﬁrst statistic, OS, is the count of the number of BEs that are included in both setsof boundaries, and is a measure of exact boundary overlap. The second statistic,OG, is the mean minimum distance from the BEs in Gto the nearest BE in H. OHis the mean minimum distance from the BEs in Hto the nearest BE in G. OGHisthe mean distance from a BE in either boundary set to the nearest BE in the otherboundary set. These statistics are useful for evaluating whether the edges of geo-graphic features, such as zones of rapid change and clusters, are signiﬁcantly nearone another. These statistics thus evaluate spatial association and are a tool thatcan be used in conjunction with non-spatial tests for association such as correlationand regression.Boundary overlap examplesJacquez (1995) explored boundary overlap in respiratory illness and environmentalozone in southern Ontario. Exposure to high ozone can cause acute respiratory distress leading to pulmonary edema or even emphysema. Jacquez asked whetherzones of rapid change in environmental ozone induced concomitant zones of rapidchange in respiratory health. Ozone boundaries appeared by visualization to coincidewith boundaries in hospital respiratory admissions; however, the overlap statisticswere not signiﬁcant. Most likely other factors were involved that may have obscuredthe relationship between ozone and respiratory health, and these results demon-strate the need to statistically evaluate apparent associations in order to avoid the“Gee Whiz” effect (Jacquez 1998).Fortin, Drapeau, and Jacquez (1996) used boundary overlap to assess the relation-ships between edaphic factors (soil types and moisture) and vegetation boundaries.They found that vegetation boundaries based on species’ stem density and species’presence/absence overlapped boundaries in edaphic factors, but vegetation boundariesbased on species diversity and richness did not. This pattern suggests a hierarchy ofeffects, with edaphic factors predicting species presence but not plant communitystructure.To determine how much the variable examined inﬂuences boundary delinea-tion, Fortin (1997) evaluated overlap among vegetation boundaries calculated from different data sets. She found that density, percent coverage, and presence/absencefor trees, shrubs, and trees and shrubs together signiﬁcantly overlapped. While mostvariables concurred, the tree-only and the shrub-only data did not. This study demonstrated the use of boundary overlap analysis to distinguish variables that arespatially associated from those that are not.Hall and Maruca (2001) compared vegetation boundaries to those in songbirdabundance in a 45 ha swamp in Michigan. They found that bird abundance bound-aries were signiﬁcantly associated with vegetation boundaries, but not vice versa.Upon investigating the composition of the eight vegetation clusters, they found thatthe variable driving the vegetation clusters, and hence their boundaries, was thedensity of coniferous trees, a potentially important factor inﬂuencing the selectionof songbird nesting and foraging areas. The authors suggested boundary analysismay aid in the development of monitoring and recovery plans for threatened birdspecies that use mosaic landscapes.THO_C22  20/03/2007  15:15  Page 400 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIAL CLUSTER ANALYSIS401Cluster overlapMaruca and Jacquez (2002) developed tests for identifying the amount of overlapbetween two spatial patterns. These tests differ from boundary overlap tests in thatthey focus on overlap of the areas enclosed within cluster boundaries. Recognizingthe ubiquity of edge effects in natural systems and that spatial heterogeneity typic-ally occurs on several spatial scales, they developed a test for association between twospatial patterns (for example, sets of clusters calculated on two different variables)that is not biased by edge effects and is based on null spatial models that can incor-porate spatial heterogeneity found in real-world systems. These methods can be usedto determine whether landscape classiﬁcation maps have geographic partitions thatoverlap to a signiﬁcant extent, and to determine whether spatial clusters deﬁned ondifferent variables (for instance, health outcomes and putative exposures) are signiﬁc-antly close to one another, existence of which is consistent with (but does not prove)a causal relationship.Assume two sets of clusters, Iand J, each comprised of NIand NJclusters andobtained as a spatial cluster analysis of different variables in the same geographic space.For cluster iin set Iand cluster jin set J, relative cluster overlapis calculated as:(22.3)Here a(i∩j)is the area of intersection and a(i∪j)is the area of union for clusters iandj. This statistic is zero for non-overlapping clusters, and increasing values representbetter overlap, with a maximum value of 1 for perfectly overlapping clusters(where a(i∩j)=a(i∪j)). For each cluster iin Iwe can then ﬁnd the cluster in J",
    "chunk_order_index": 247,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ea23af58593e659db2fdb4ce3580d398": {
    "tokens": 1200,
    "content": "cluster jin set J, relative cluster overlapis calculated as:(22.3)Here a(i∩j)is the area of intersection and a(i∪j)is the area of union for clusters iandj. This statistic is zero for non-overlapping clusters, and increasing values representbetter overlap, with a maximum value of 1 for perfectly overlapping clusters(where a(i∩j)=a(i∪j)). For each cluster iin Iwe can then ﬁnd the cluster in Jthat ioverlaps best with, by ﬁnding the maximum value of aijover all clusters in J(calledthe maximum relative cluster overlap):Ai=max(ai•)(22.4)A cluster overlap statistic from the perspective of set Iis the average maximum relative cluster overlap(Equation 22.5). This also can be calculated for set J(Equation 22.6), and a simultaneous area overlap statistic is shown in Equation 22.7:(22.5)(22.6)(22.7)AAANNIJiiNjjNIJIJ =++==∑∑ max()  max()  ••11AANJjjNJJ =•=∑ max()1  AANIiiNII =•=∑ max()1  aaaijijij =∩∪ ()()THO_C22  20/03/2007  15:15  Page 401 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f402GEOFFREY M. JACQUEZThe statistic AIis a measure of how well the clusters in Ioverlap the clusters inJ, and AJis a measure of how well clusters in Joverlap with those in I. AIJis ageneral (or bi-directional) measure of overlap between the two sets of clusters. Thesestatistics are best suited to instances where the two sets of clusters contain roughlythe same number of clusters, and with clusters of about the same size. However, inthe real world we expect to ﬁnd cluster sets with very different numbers of clusters.Further, a given cluster set may contain clusters of drastically different sizes, as occurswhen spatial variation is heterogeneous. The constraint on cluster number and sizedistribution is relaxed by calculating the average maximum relative overlap(AI′) asa weighted average, where the weight is the area of the focus cluster (aifor clusteriin set I; ajfor cluster jin set J). In this scenario, the statistics would be calculatedas follows:(22.8)(22.9) (22.10)These tests have local versions, just as the global cluster tests discussed earlierhave corresponding local tests. The local version identiﬁes those locations on themap where statistically signiﬁcant cluster overlap and overlap avoidance are found.Implementation of this involves decomposing the summation for either the raw (equations 22.5–22.7) or weighted versions (from equations 22.8–22.10) into localcontributions for each cluster. Thus, for the global unweighted overlap statistic inEquation 22.5 the local version is:(22.11)Here the “index” cluster is cluster l, and AIlis the contribution of cluster ltothe global overlap statistic Al. Local counterparts can also be constructed for theother global statistics in equations (22.6–22.10). The value of each local overlapstatistic can indicate overlap, no association, or overlap avoidance. A probabilityfor overlap of cluster of the size of cluster lis calculated from the distribution ofAIlunder a Monte Carlo simulation that conditions on both the number and size  AANIllI = max()•′=++====∑∑∑∑AaAaAaaIJiiiNjjjNiiNjjNIJIJ   [max()]  [max()] ••1111′===∑∑AaAaJjjjNjjNJJ  [max()]•11  ′===∑∑AaAaIiiiNiiNII  [max()]•11THO_C22  20/03/2007  15:15  Page 402 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIAL CLUSTER ANALYSIS403distribution of the clusters, but assumes no association between the geographies ofthe clusters in sets Iand J.Method Selection AdvisorsSo far the reader has been introduced to global, local, and focused cluster statistics,as well as spatial association tests for boundary and area overlap. Researchers oftenask “which spatial cluster test should I use?” and online cluster analysis advisors,such as those found at http://www.terraseer.com/bsr/boundaryseer_advisor.html andhttp://www.terraseer.com/csr/clusterseer_advisor.html can aid in this regard.But looking for the “one” suitable cluster test is appropriate only when one hasprior knowledge of cluster shape. For example, if one knows cancer clusters arecircular then it would be appropriate to use a spatial scan statistic with a circularscanning window. However, this reasoning is also circular since one usually under-takes a cluster analysis in order to locate and describe the clusters – prior knowledgeof cluster shape therefore is lacking.Cluster Morphology",
    "chunk_order_index": 248,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e000731176cfde491ac8c5e875fee5bc": {
    "tokens": 1200,
    "content": "/csr/clusterseer_advisor.html can aid in this regard.But looking for the “one” suitable cluster test is appropriate only when one hasprior knowledge of cluster shape. For example, if one knows cancer clusters arecircular then it would be appropriate to use a spatial scan statistic with a circularscanning window. However, this reasoning is also circular since one usually under-takes a cluster analysis in order to locate and describe the clusters – prior knowledgeof cluster shape therefore is lacking.Cluster MorphologyThere is a growing awareness that clusters can take on a variety of different shapes,but cluster tests are usually sensitive to only one proﬁle (Sun 2002, Smith 2003,Jacquez 2004, Tango and Takahashi 2005). Different techniques are sensitive todifferent aspects of cluster morphology– some detect boundaries, some detect out-liers, some detect circular clusters, some detect elliptical clusters, and so on. Areasof high value can take many shapes, yet most cluster-detection techniques employgeographic “templates” such as circular scanning windows. These include the GAM(Openshaw, Charlton, Craft, and Birch 1988), the scan statistic (Kulldorff andNagarwalla 1995), Turnbull’s test (Turnbull, Iwano, Burnett, Howe, and Clark 1990),Besag and Newell’s (1991) test, the score test of Lawson and Waller (1996) that usesa circular risk function, ﬁrst-order adjacencies such as LISA statistics, and nearest-neighbors relationships such as used in Cuzick and Edward’s (1990) test. These testsare most sensitive to cluster shapes that correspond to the geographic templates theyemploy. But spatial variation and hence cluster morphology in geographic systemsis highly complex, and cannot be well described by a single geographic templateor clustering approach.This observation recently motivated the development of an integrative approachthat provides a more complete description of cluster morphology (Jacquez and Greiling2003a, b). This integrative framework employs a battery of ESDA techniques includ-ing geographic boundary analysis, spatial agglomerative clustering, local Moran tests, and scan statistics (Table 22.1). Jacquez and Greiling employed it to more fullydescribe multi-scalar and multivariate patterns in the incidence of breast, colorectal,and lung cancers on Long Island, New York. They used global, local, and focusedtests to explore the spatial scale of clustering, LISA statistics to identify spatial outliers, hot spots and cool spots, boundary analysis to ﬁnd zones of rapid change,boundary overlap to evaluate possible associations between lung cancer and airborneTHO_C22  20/03/2007  15:15  Page 403 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f404GEOFFREY M. JACQUEZcarcinogens, and spatial agglomerative clustering to identify multivariate clusters thatwere homogeneous in lung, breast, and colorectal cancer incidence (Figure 22.1). Thisintegrative approach yielded a detailed description of the morphology of statistic-ally signiﬁcant geographic variation patterns for breast, lung, and colorectal cancerincidence on Long Island.An alternative approach is to use techniques for which the geographic templateis ﬂexible and can assume any shape. The ﬁrst method, called the Upper Level Setscan statistic (Patil and Taillie 2004), involves estimation of cluster morphology (forexample, shape, extent, and conﬁguration) from the data itself. The second methodinvolves the “growth” of clusters by grouping adjacent areas that have similar (highor low) rates (see Urban 2004). While techniques for spatially agglomerative cluster-ing have been available for some time (Legendre 1987, for example), they often donot assign probabilities to the resulting clusters. A new approach called B-statisticswas recently proposed that simultaneously detects agglomerative clusters of arbitraryshape as well as edges (borders where two adjacent areas of signiﬁcantly differentrates abut), and provide cluster probabilities under realistic null hypotheses (Jacquez,Kaufmann, and Goovaerts 2006). Finally, kernel density estimation methods resultin spatially continuous maps of the probability of a disease outcome (Rushton 1997,Rushton, Peleg, Banerjee, Smith, and West 2004) and appear capable of circum-scribing clusters of variable shape, but the impact of kernel-based smoothing onthe type I and type II error has yet to be fully quantiﬁed.Cluster Change and PersistenceWith the advent of routine remote sensing and improved environmental monitor-ing and health surveillance it now is possible to analyze data that are spatially andtemporally referenced. In particular, there now are Space-Time Intelligence Systems(STIS) designed speciﬁcally to deal with georeferenced data through time. Analysisof how spatial patterns change through time is quite straightforward in such systems.Table 22.1Cluster Morphology DescriptorsDescriptorExampleAmount of excess or deﬁcitRelative Risk in a disease cluster, number of cases in theclusterExtentGeographic area, number of sub-areas in the clusterLengthLength of major and minor axes in an elliptical clusterBoundaryLengthLength of cluster boundaryCrenellationBoundary fractal dimensionFuzzinessAlpha core and surrounding zone of uncertaintyShapeRatio of boundary length / cluster areaBivariate spatial associationBoundary overlap analysis; Cluster overlap analysisMultivariate spatial structureClusters from multivariate spatially agglomerativeclustering; boundaries from multivariate boundary analysisTHO",
    "chunk_order_index": 249,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-61c42caefdc8712cc9bd3d84ff1137a0": {
    "tokens": 1200,
    "content": "a disease cluster, number of cases in theclusterExtentGeographic area, number of sub-areas in the clusterLengthLength of major and minor axes in an elliptical clusterBoundaryLengthLength of cluster boundaryCrenellationBoundary fractal dimensionFuzzinessAlpha core and surrounding zone of uncertaintyShapeRatio of boundary length / cluster areaBivariate spatial associationBoundary overlap analysis; Cluster overlap analysisMultivariate spatial structureClusters from multivariate spatially agglomerativeclustering; boundaries from multivariate boundary analysisTHO_C22  20/03/2007  15:15  Page 404 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSignificant female lung cancer clusters (high SMR)Significant female lung cancer Local Moran clusters (low SMR)Outlier in female lung cancer (low SMR)more than 100% above expected50–100% above expected15–49% above expectedwithin 15% of expected15–50% below expectedmore than 50% below expectedSignificant male lung cancer Local Moran clusters (high SMR)Significant male lung cancer Local Moran clusters (low SMR)Outliers in male lung cancer (low SMR)more than 100% above expected50–100% above expected15–49% above expectedwithin 15% of expected15–50% below expectedmore than 50% below expected1176511709117221177911752117301178211950113671136811412200204060 Miles1174311727117641195311955119501195111967117631178211694117381102411576Lung Cancer OPR boundariesSMR female lung cancer boundariesSMR for male lung cancer boundariesNATALung Cancer OPR7E–40_002NNMale Lung Cancer SMR valuesFemale Lung Cancer SMR valuesFig. 22.1Cluster morphology of cancer incidence on Long Island. Top: LISA clusters in male lungcancer incidence; Middle: LISA clusters in female lung cancer incidence; Bottom: Boundaries in male and female lung cancer incidence and air toxics from EPA’s National Air Toxics AssessmentprogramFrom Jacquez and Greiling 2003 a, bTHO_C22  20/03/2007  15:15  Page 405 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f406GEOFFREY M. JACQUEZ22.5 to 3020 to 22.517.5 to 2015 to 17.512.5 to 1510 to 12.57.5 to 105 to 7.52.5 to 50 to 2.516.460410.00.0−10.0−16.8426''1950–691970–941994–1950Fig. 22.2Cluster change and persistence. Changes in pancreatic cancer mortality along the lowerMississippi River for white males for all ages from 1950–69 to 1970–94. Top: Mortality 1950–69;Middle: Mortality 1970–94; Bottom: Difference in mortality rates for the two time periodsCancer data from CancerAtlas Viewer; http://www.terraseer.com/products/atlasviewer.htmlWe now consider two aspects of cluster change and persistence: temporal change inthe spatial distribution of clusters and clustering of attributes from two different timeperiods. In this discussion we use the LISA statistic, but the approach is generaland can apply to most cluster tests.•Temporal change in the spatial distribution of clustersAn obvious ﬁrst-step inthe exploration of cluster change and persistence is to cluster an attribute at timetand compare the spatial distribution of those clusters to those obtained forthat attribute at time t +1 (Figures 22.2 and 22.3). Boundary and area overlapTHO_C22  20/03/2007  15:15  Page 406 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIAL CLUSTER ANALYSIS407statistics such as those summarized earlier may be used to determine the amountof association between the clusters at the different time periods. The local over-lap statistics are used to distinguish those clusters that signiﬁcantly overlap fromthose that do not. This approach is useful for identifying where cluster existencechanges through time and where clusters are persistent.High-highHigh-lowLow-highLow-lowNot significant1950–691970–94bivariateFig. 22.3Cluster change and persistence continued. LISA clusters in pancreatic cancer for 1950–69(top) and 1970–94 (middle). High pancreatic cancer mortality is spreading north in counties alongthe Mississippi River. Bivariate LISA clusters identify counties high in pancreatic cancer in 1950–69that are surrounded by counties with high mortality in 1970–94. Analyses conducted in TerraSeer’sSTIS softwareTHO_C22  20/03/2007  15",
    "chunk_order_index": 250,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-80a658fa3a7351044db498f7644dfe84": {
    "tokens": 1200,
    "content": "change and persistence continued. LISA clusters in pancreatic cancer for 1950–69(top) and 1970–94 (middle). High pancreatic cancer mortality is spreading north in counties alongthe Mississippi River. Bivariate LISA clusters identify counties high in pancreatic cancer in 1950–69that are surrounded by counties with high mortality in 1970–94. Analyses conducted in TerraSeer’sSTIS softwareTHO_C22  20/03/2007  15:15  Page 407 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f408GEOFFREY M. JACQUEZ•Clustering of attributes at two different time periods Bivariate LISA statistics areuseful for identifying those areas with high values at time tthat are surroundedby areas with high values at time t +1. This tool is useful for gaining insightsinto cluster persistence and spread (Figure 22.3).•Clustering temporal differenceRather than working with maps of the attri-bute at times tand t +1, one can ﬁrst calculate difference maps that subtractthe value at time t +1 from the value at time t. These clusters (Figure 22.4)identify areas where the difference is high, and thus are useful for pinpointingthose localities where the attribute value is uncertain, unstable and/or changingdramatically.16.460410.00.0–10.0–16.8426High-highHigh-lowLow-highLow-lowNot significant1994–1950ChangeClustersFig. 22.4Cluster change and persistence continued. Difference maps (top) quantify the difference in mortality rates between 1950–69 and 1970–94. LISA clusters of the difference maps (bottom)identify those localities where the change in morality is high. Analyses conducted in TerraSeer’s STIS softwareTHO_C22  20/03/2007  15:15  Page 408 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIAL CLUSTER ANALYSIS409Disparity clustersWhen faced with different classes of an item (say males and females) the questionoften arises as to whether spatial clusters of disparity exist. This is an importantproblem in the health sciences, as substantial disparities in disease incidence andmortality are observed for different race, gender, and ethnic groups. Consider cancer.According to the National Cancer Institute’s (NCI) planning and budget proposalfor 2004The unequal burden of cancer in our society is more than a scientiﬁc and medical challenge. It is a moral and ethical dilemma for our Nation. Certain populations experience signiﬁcant disparities in cancer incidence, the care they receive, and the out-comes of their disease. These differences have been recognized, or at least suspected,for some time. They now are being documented with increasing frequency and clarity.(NCI 2003)The identiﬁcation of locations of high disparity in a health outcome – a disparitycluster – is an important step that allows one to target interventions and to addressinequities in access to health care and provision of screening services. How can healthdisparities be identiﬁed?The approach employed involves three steps similar to those employed for evaluat-ing cluster change and persistence. Comparison of cluster maps, bivariate clusteranalysis, and clustering of difference maps.Consider an example. Pancreatic cancer incidence and mortality have changedlittle over the last three decades. Mortality rates in this period have been relativelystable for black and white males, have decreased for white females, and increased forblack females. In each racial/ethnic group males have higher incidence and mortal-ity than women. Blacks have incidence and mortality rates nearly 50 percent higherthan whites. Rates for native Hawaiians are higher than for whites, while those forHispanic and Asian-American rates are lower (Miller, Kolonel, Bernstein, et al. 1996).Risk is highest in the older population, and pancreatic cancer is rare among those30–54 years old. Incidence for blacks 55–69 years of age is 60 percent higher than for whites of the same age, although this difference diminishes in ages 70 years and older. Age-based racial mortality patterns are similar to those observed in theincidence rates. Does the disparity in cancer mortality between white and black malescluster geographically?The difference in standardized rates can be used to create cancer mortality dis-parity maps (for example, for BM–WM), and clusters of high values on these maps(hot spots) then identify locations of elevated mortality for black males. In additionto univariate clustering of the difference, bivariate LISAs for detecting clusters andanomalies of disparities in cancer mortality can be constructed of the form:(22.12)Here Li,BMxWMis the bivariate LISA at location ifor the disparity in pancreaticcancer mortality between black and white males at the local spatial scale. zj,WMisthe standardized mortality rate for black males at that location and zj,WMis the local  LzwziBMxWMiBMijjWMj,,,  =∑THO_C22  20/03/2007  15:15  Page 409 Download",
    "chunk_order_index": 251,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ce5b5c9a3ed61d7e706fb6620723543c": {
    "tokens": 1200,
    "content": "form:(22.12)Here Li,BMxWMis the bivariate LISA at location ifor the disparity in pancreaticcancer mortality between black and white males at the local spatial scale. zj,WMisthe standardized mortality rate for black males at that location and zj,WMis the local  LzwziBMxWMiBMijjWMj,,,  =∑THO_C22  20/03/2007  15:15  Page 409 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f410GEOFFREY M. JACQUEZcomponent for white males at location jadjacent to i. The term is the average white male pancreatic cancer mortality for locations (for instance, counties)adjacent to i. The disparity statistic Li,BMxWMis positive when pancreatic cancer mortality at neighboring locations is similar for both races, and negative if there isa disparity. Signiﬁcance of the statistic is evaluated under conditional randomiza-tion, and the Moran scatter plot identiﬁes clusters and hotspots of racial disparityin pancreatic cancer mortality. P-values under randomization are then used to con-struct pancreas cancer mortality disparity maps (Figure 22.5).The two approaches (univariate on difference maps and bivariate on standardizedrates) inform two different aspects of the geography of disparity. The univariatedifference clusters detect signiﬁcant spatial clusters and outliers in the differencebetween standardized rates (for example, BM–WM). The bivariate LISA statisticidentiﬁes spatial clusters and outliers in the standardized rates for one race–gendercombination (for example, BM) relative to the average of the standardized ratesfor the second race–gender combination (for example, WM) in surrounding areas.Spatial cluster analysis has obvious utility for geographically pinpointing locationsof statistically signiﬁcant disparities in pancreatic cancer mortality.An alternative approach to evaluating statistical signiﬁcance of health disparities wasrecently proposed by Goovaerts (2005), who recognized that tests for differencesin means, such as that based on the students t-distribution, would be useful fordetecting health disparities provided differences in population sizes could beaccounted for. His disparity statistic is an adaptation of the classical test for inferenceof two population proportions (Devore 2000) to the comparison of rates measured  wzijjWMj,∑Fig. 22.5Disparity clustersTHO_C22  20/03/2007  15:15  Page 410 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIAL CLUSTER ANALYSIS411in two sub-populations, labeled as reference and target populations. For a given region,the disparity statistic is calculated as the standardized difference between the targetand reference rates, weighted by the population proportions, and has been demon-strated to detect regions with statistically signiﬁcant health disparities that accountfor the population sizes of the reference and target populations (see Goovaerts 2005).Multiple TestingESDA and the description of cluster morphology may involve iterations of visual-ization and statistical analyses to elucidate different aspects of spatial patterns andto successively reﬁne the alternative hypotheses explored in pattern recognition procedures. Hence a typical analysis, say of prostate cancer incidence, may beginwith the creation of maps using appropriately adjusted rates (for example, to stab-ilize the rates and to adjust for covariates such as age), and may then involve theuse of global, local, and focused tests to determine whether the rates are spatially autocorrelated (using global tests such as those of Moran 1950, Oden 1995, Tango1995 and others), to identify the locations of cold-spots, hot-spots, and outliers(using local tests such as Anselin 1995, Getis and Ord 1992, Turnbull, Iwano, Burnett,Howe, and Clark 1990, Besag and Newell 1991, among others), and to assess whethercases tend to cluster near the locations of putative environmental exposures (usingfocused tests such as Lawson and Waller 1996). To maintain statistical rigor theimpact of repeated statistical procedures must be accounted for (Jacquez, Waller,Grimson, and Wartenberg 1996b), and this may be accomplished within the struc-ture of the test itself (as in Kulldorff’s 1997 scan test) or by adjusting P-values orType I errors using the methods of Bonferroni (Sidak 1967, Simes 1986), Holms(Holland and Copenhaver 1987) or Hochberg (1988). Recently, Tango (2007) pro-posed using a “min-P” approach in which the test statistic itself is the minimump-value observed from a group of tests. Because of the exploratory nature of theanalyses there is some question as to whether a formal approach to inferential statistics (for example, comparing a P-value to the alpha level to determine whetherthe null hypothesis is rejected) is applicable. Most experts now advocate interpreta-tion of P-values within the context of other information, such as the biological plausibility of the cluster, the quality of the data, and the",
    "chunk_order_index": 252,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-286fed840cc92b42fb8f28a998ea81e0": {
    "tokens": 1200,
    "content": "the test statistic itself is the minimump-value observed from a group of tests. Because of the exploratory nature of theanalyses there is some question as to whether a formal approach to inferential statistics (for example, comparing a P-value to the alpha level to determine whetherthe null hypothesis is rejected) is applicable. Most experts now advocate interpreta-tion of P-values within the context of other information, such as the biological plausibility of the cluster, the quality of the data, and the costs associated with falsepositives and negatives (Waller and Jacquez 1995; Jacquez, Grimson, Waller, andWartenberg 1996, Jaquez, Waller, Grimson, and Wartenberg 1996). Some softwarepackages such as ClusterSeer (Jacquez, Maruca, Greiling, et al. 2001, Jacquez, Greiling,Durbeck 2002) account for multiple tests automatically and provide appropriatelyadjusted probability values.ToolsInformation Frames. There are literally dozens of spatial cluster tests, and cogentsummaries of the different tests are needed to support method selection and to remind one of the properties of a given test. In a recent study funded by the NCI,researchers at BioMedware, Inc. and the University of Michigan School of PublicTHO_C22  20/03/2007  15:15  Page 411 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f412GEOFFREY M. JACQUEZHealth developed one-page information frames that give a quick overview of theproperties of a test (Figure 22.6).Software. Cluster analysis software includes Satscan, which implements a scan-type statistic employing circular scanning windows. The commercial softwareClusterSeer (Jacquez, Greiling, Estberg, et al. 2001, Jacquez Greiling, Durbeck, etal. 2002) has dozens of statistical techniques that employ a variety of geographictemplates (for instance, circular scanning windows, nearest neighbor relationships,LISA tests, global tests, and focused tests). It comes with a cluster advisor and adjusts for multiple testing. BoundarySeer (Jacquez, Maruca, Greiling, et al. 2001)employs techniques to detect the edges of clusters, and these clusters can be of anyk-Nearest Neighbor testIndications/Recommendations for use: When space-time interaction is present nearby cases willoccur at about the same time, (space nearest neighbors tend to be time nearest neighbors), andthe test statistic will be large (more).Description: A k-nearest neighbor method used to detect space-time interaction.Test statistic: The number of pairs of cases that are k-nearestneighbors in both space and time.Null Hypothesis: Whether cases are nearest neighbors in space is independent of whether theyare nearest neighbors in time.Alternative Hypothesis: Nearest neighbors in space tend to be nearest neighbors in time.GeoMed Inputs: Space and time distances between pairs of cases.Example AnalysisReference:GeoMed Outputs: Results table includes: ° k, the number of nearest neighbors being considered ° Jk, the number of space-time k nearest neighbors ° significance of Jk ° ∆Jk, the number of space-time nearest neighbors added when k increased from k-1 ° significance of ∆Jk ° p-values for the probability, under H0, of observing a statistic as large or larger than that  observed and combined for the k tests in 3 ways:  ■ Bonferroni  ■ Simes  ■ Statistical Distance ° A linkage map  ■ case locations are mapped  ■ k-order linkages displayed as selected by user(cid:127) spatial/temporal(cid:127) global(cid:127) region-based(cid:127) Similar Tests: ° Mantel ° Knox ° Direction ° Grimson(cid:127) All available testsJk = Σ ΣsijktijkNi=1Nj=1Fig. 22.6Information frames provide cogent summaries of the properties of spatial cluster statisticsand are available through the cluster advisor found athttp://zappa.nku.edu/~longa/geomed/stathelp/advisor.htmlTHO_C22  20/03/2007  15:15  Page 412 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIAL CLUSTER ANALYSIS413shape. Both univariate and multivariate methods are included. The CancerAtlas viewer(http://www.terraseer.com/atlasviewer.html) comes with county, State Economic Area,and State level mortality data for 43 site-speciﬁc cancers, and employs LISA statistics.TerraSeer’s STIS (http://www.terraseer.com/products/stis.html) supports linked windows,statistical brushing, spatial and space-time cluster statistics, animation as well asspatio-temporal georeferencing.CONCLUSIONSThis chapter provided a quick overview of some of the issues and approaches in spatial cluster analysis. The reader should now have some appreciation of the rolespatial cluster analysis plays in ESDA, and of global, local, and focused techniques.It should now be apparent that the “one size ﬁts all” approach to cluster analysisyields an incomplete picture of cluster morphology. The integrated approach conveys",
    "chunk_order_index": 253,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a26309a550fcc1df42720004c093da3f": {
    "tokens": 1200,
    "content": "istical brushing, spatial and space-time cluster statistics, animation as well asspatio-temporal georeferencing.CONCLUSIONSThis chapter provided a quick overview of some of the issues and approaches in spatial cluster analysis. The reader should now have some appreciation of the rolespatial cluster analysis plays in ESDA, and of global, local, and focused techniques.It should now be apparent that the “one size ﬁts all” approach to cluster analysisyields an incomplete picture of cluster morphology. The integrated approach conveysa far more complete quantiﬁcation of cluster morphology descriptors and ultimatelyleads to a better understanding of spatial variation. Spatial cluster analysis can yieldsubstantial beneﬁts in documenting cluster change and persistence, and for identify-ing disparities in two spatially referenced variables. The ﬁeld is evolving rapidly, andas the volume of spatially and temporally referenced data increases cluster analysiswill play an increasing role in pattern recognition and data reduction.ACKNOWLEDGEMENTSSome of the ﬁndings reported in this publication were developed under grantsCA92669 from the National Cancer Institute and ES10749 from the National Instituteof Environmental and Health Sciences. The perspectives of this publication are solelythose of the author and do not necessarily represent the ofﬁcial views of the fundingorganizations.REFERENCESAnselin, L. 1995. Local indicators of spatial association: LISA. Geographical Analysis27:93–115.Bailey, T. C. and Gatrell, A. C. 1995. Interactive Spatial Data Analysis. Harlow: AddisonWesley Longman.Besag, J. and Newell, J. 1991. The detection of clusters in rare diseases. Journal of the RoyalStatistical Society Series A154: 143–55.Cuzick, J. and Edwards, R. 1990. Spatial clustering for inhomogeneous populations. Journalof the Royal Statistical Society Series B52: 73–104.Devore, J. L. 2000. Probability and Statistics for Engineering and the Sciences.Belmont,CA: Duxbury Press.Fisher, R. A. 1935. Design of Experiment. (First Edition). London: Oliver and Boyd.Fortin, M. J. 1997. Effects of data types on vegetation boundary delineation. Canadian Journalof Forest Research27: 1851–8.Fortin, M. J., Drapeau, P., and Jacquez, G. M. 1996. Statistics to assess spatial relationshipsbetween ecological boundaries. Oikos77: 51–60.THO_C22  20/03/2007  15:15  Page 413 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f414GEOFFREY M. JACQUEZGelman, A., Price, P. N., and Lin, C. 2000. A method for quantifying artefacts in mappingmethods illustrated by application to headbanging. Statistics in Medicine19: 2309–20.Getis, A. and Ord, J. K. 1992. The analysis of spatial assosciation by use of distance statistics.Geographical Analysis24: 189–206.Goovaerts, P. 2005. Analysis and detection of health disparities using geostatistics and a space-time information system: The case of prostate cancer mortality in the United States, 1970–1994. In Proceedings of GIS Planet 2005, Estoril, Portugal. Lisboa: InstitutoGeograﬁco Portugues.Goovaerts, P. and Jacquez, G. 2004. Accounting for regional background and population sizein the detection of spatial clusters and outliers using geostatistical ﬁltering and spatial neutral models: The case of lung cancer in Long Island, New York. International Journalof Health Geographics3:14.Goovaerts, P. and Jacquez, G. M. 2005. Detection of temporal changes in the spatial dis-tribution of cancer rates using LISA statistics and geostatistically simulated spatial neutralmodels. Journal of Geographical Systems7: 137–59.Gustafson, E. J. 1998. Quantifying landscape spatial pattern: What is the state of the art?Ecosystems1: 143–56.Hall, K. R. and Maruca, S. L. 2001. Mapping a forest mosaic: A comparison of vegetationand bird distributions using geographic boundary analysis. Plant Ecology156: 105–20.Hochberg, Y. 1988. A sharper Bonferroni procedure for multiple tests of signiﬁcance.Biometrica75: 800–2.Holland, B. S. and Copenhaver, M. D. 1987. An improved sequentially rejective Bonferronitest procedure. Biometrics43: 417–23.Jacquez, G. M. 1995. The map comparison problem: Tests for the overlap of geographicboundaries. Statistics in Medicine14: 2343–61.Jacquez, G. M. 1998. GIS as an enabling technology. In A. Gatrell and M. Loytonen (eds)GIS and Health.London: Taylor and Francis, pp. 17–28.Jacquez, G. M. 2000. Spatial epidemiology: Nascent science or a failure of GIS? Journal ofGeographical Systems2: 91–7.Jacquez, G. M. 2004. Current practices in the spatial",
    "chunk_order_index": 254,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9cd92056706256d90be214f37f2bd613": {
    "tokens": 1200,
    "content": "quez, G. M. 1998. GIS as an enabling technology. In A. Gatrell and M. Loytonen (eds)GIS and Health.London: Taylor and Francis, pp. 17–28.Jacquez, G. M. 2000. Spatial epidemiology: Nascent science or a failure of GIS? Journal ofGeographical Systems2: 91–7.Jacquez, G. M. 2004. Current practices in the spatial analysis of cancer: Flies in the ointment.International Journal of Health Geographics3:22.Jacquez, G. M. and Greiling, D. A. 2003a. Local clustering in breast, lung, and colorectalcancers in Long Island, New York. International Journal of Health Geographics 2: 3 (avail-able at http://www.ij-healthgeographics.com/content/2/1/3).Jacquez, G. M. and Greiling, D. A. 2003b. Geographic boundaries in breast, lung, and colorectal cancers in relation to exposure to air toxics in Long Island, New York.International Journal of Health Geographics 2: 4 (available at http://www.ij-healthgeographics.com/content/2/1/4).Jacquez, G. M., Greiling, D. A., Durbeck, H., Estberg, L., Do, E., Long, A., and Rommel, B.2002. ClusterSeer User Guide 2: Software for Identifying Disease Clusters. Ann Arbor,MI: TerraSeer Press.Jacquez, G. M., Greiling, D., Estberg, L., Do, E., Long, A., and Rommel, B. 2001.ClusterSeer User Guide: Software for Identifying Disease Clusters. Ann Arbor, MI:TerraSeer Press.Jacquez, G. M., Grimson, R., Waller, L., and Wartenberg, D. 1996. The analysis of diseaseclusters: Part 2, Introduction to techniques. Infection Control and Hospital Epidemiology17: 385–97.Jacquez, G. M., Kaufmann, A., and Goovaerts, P. 2006. Boundaries, ladders and clusters:A new paradigm in spatial analysis? Environmental and Ecological Statistics13: 31–48.Jacquez, G. M., Maruca, S. L., and Fortin, M. J. 2000. From ﬁelds to objects: A review ofgeographic boundary analysis. Journal of Geographical Systems2: 221–41.THO_C22  20/03/2007  15:15  Page 414 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSPATIAL CLUSTER ANALYSIS415Jacquez, G. M., Maruca, S. L., Greiling, D. A., Kaufmann, A., Muller, L., Rommel, B., Sengupta, S., Agarwal, P., and Hall, K. 2001. BoundarySeer User Guide: Software forGeographic Boundary Analysis. Ann Arbor, MI: TerraSeer Press.Jacquez, G. M., Waller, L., Grimson, R., and Wartenberg, D. 1996. The analysis of diseaseclusters: Part I, State of the art. Infection Control and Hospital Epidemiology17: 319–27.Kaﬁdar, K. 1996. Smoothing geographical data, particularly rates of disease. Statistics inMedicine15: 2539–60.Kulldorff, M. 1997. A spatial scan statistic. Communications in Statistics: Theory and Methods26: 1481–96.Kulldorff, M. and Nagarwalla, N. 1995. Spatial disease clusters: Detection and inference.Statistics in Medicine14: 799–810.Lawson, A. B. 1989. Score Tests for Detection of Spatial Trend in Morbidity Data.Dundee:Dundee Institute of Technology.Lawson, A. B. and Kulldorff, M. 1999. A review of cluster detection methods. In A. B. Lawson,A. Biggeri, D. Böhning, E. Lesaffre, J.-F. Viel, and R. Bertollin (eds) Advanced Methodsof Disease Mapping and Risk Assessment for Public Health Decision Making.London:John Wiley and Sons, pp. 99–110.Lawson, A. B. and Waller, L. A. 1996. A review of point pattern methods for spatial modelling of events around sources of pollution. Environmetrics7: 471–87.Legendre, P. 1987. Constrained clustering. In P. Legendre and L. Legendre (eds)Developments in Numerical Ecology.Berlin: Springer-Verlag, pp. 289–307.Liebisch, N., Jacquez, G. M., Goovaerts, P., and Kaufmann, A. 2002. New methods to gener-ate neutral images for spatial pattern recognition. In M. J. Egenhofer and D. M. Mark(eds) GIScience2002: The Second International Conference on Geographic InformationScience.Berlin: Springer-VerlagLecture Notes in Computer Science No. 2478: 181–95.Maruca, S. L. and",
    "chunk_order_index": 255,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a637c5a48fbaa5c1f4157abc64048ac9": {
    "tokens": 1200,
    "content": "isch, N., Jacquez, G. M., Goovaerts, P., and Kaufmann, A. 2002. New methods to gener-ate neutral images for spatial pattern recognition. In M. J. Egenhofer and D. M. Mark(eds) GIScience2002: The Second International Conference on Geographic InformationScience.Berlin: Springer-VerlagLecture Notes in Computer Science No. 2478: 181–95.Maruca, S. L. and Jacquez, G. M. 2002. Area-based tests for association between spatialpatterns. Journal of Geographical Systems4: 69–84.Miller, B. A., Kolonel, L. N., Bernstein, L., Young Jr., J. L., Swanson, G. M., West, D., Key, C. R., Liff, J. M., Glover, C. S., Alexander, G. A., Coyle, L., Hankey, B. F., GloecklerRies, L. A., Kosary, C. L., Harras, A., Percy, C., and Edwards, B. K. 1996. Racial/EthnicPatterns of Cancer in the United States 1988–1992.Bethesda, MD: National Cancer InstitutePublication No. 96–4104.Moore, D. A. and Carpenter, T. E. 1999. Spatial analytical methods and Geographic Informa-tion Systems: Use in health research and epidemiology. Epidemiologic Reviews21: 143–61.Moran, P. A. P. 1950. Notes on continuous stochastic phenomena. Biometrika37: 17–23.National Cancer Institute. 2003. The National Cancer Institute’s (NCI) Planning andBudget Proposal for Fiscal Year 2004: The Nation’s Investment in Cancer Research. WWWdocument, http://plan.cancer.gov/discovery/index.html.Oden, N. 1995. Adjusting Moran’s I for population density. Statistics in Medicine14: 17–26.Openshaw, S., Charlton, M., Craft, A. W., and Birch, J. M. 1988. Investigation of leukaemiaclusters by use of a geographical analysis machine. Lancet1: 272–3.Ord, J. K. and Getis, A. 1995. Local spatial autocorrelation statistics: Distributional issuesand an application. Geographical Analysis27: 286–306.Pandya, A. S. and Macey, R. B. 1996. Pattern Recognition with Neural Networks in C++.Boca Raton, FL: CRC Press.Patil, G. P. and Taillie, C. 2004. Upper level set scan statistic for detecting arbitrarily shapedhotspots. Environmental and Ecological Statistics11: 183–97.Rushton, G. 1997. Improving public health through geographical information systems: Aninstructional guide to major concepts and their implementation (CD-ROM; Version 2.0).Iowa City, IA: Department of Geography, University of Iowa (available at http://www.uiowa.edu/~geog/).THO_C22  20/03/2007  15:15  Page 415 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f416GEOFFREY M. JACQUEZRushton, G. and Elmes, G. 2000. Considerations for improving Geographic Information Systemresearch in public health. Journal of the Urban and Regional Information SystemsAssociation12: 31–49.Rushton, G., Peleg, I., Banerjee, A., Smith, G., and West, M. 2004. Analyzing geographicpatterns of disease incidence: Rates of late-stage colorectal cancer in Iowa. Journal of MedicalSystems28: 223–36.Sidak, Z. 1967. Rectangular conﬁdence regions for the means of multivariate normal dis-tributions. Journal of the American Statistical Association62: 626–33.Simes, R. J. 1986. An improved Bonferroni procedure for multiple tests of signiﬁcance.Biometrika73: 751–4.Smith, G. H. 2003. Disease cluster detection methods: The impact of choice of shape on the power of statistical tests. Unpublished report, Department of Geography University ofIowa.Sun, Y. 2002. Determining the size of spatial clusters in focused tests: Comparing two methods by means of simulation in a GIS. Journal of Geographical Systems4: 359–70.Tango, T. 1995. A class of tests for detecting “general” and “focused” clustering of rarediseases. Statistics in Medicine14: 2323–34.Tango, T. 2007. A class of multiplicity-adjusted tests for spatial clustering based on case-control point data. Biometrics 63: in press.Tango, T. and Takahashi, K. 2005. A ﬂexibly shaped spatial scan statistic for detecting clusters. International Journal of Health Geographics 4:1.Turnbull, B. W., Iwano, E. J., Burnett, W. S., Howe, H. L., and Clark, L. C. 1990. Monitoringfor clusters of disease: Application to leukemia incidence in upstate New York. AmericanJournal of",
    "chunk_order_index": 256,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-294b5163469910f90df93d424ac51a41": {
    "tokens": 1200,
    "content": ": in press.Tango, T. and Takahashi, K. 2005. A ﬂexibly shaped spatial scan statistic for detecting clusters. International Journal of Health Geographics 4:1.Turnbull, B. W., Iwano, E. J., Burnett, W. S., Howe, H. L., and Clark, L. C. 1990. Monitoringfor clusters of disease: Application to leukemia incidence in upstate New York. AmericanJournal of Epidemiology132: S136–43.Urban, D. L. 2004. Multivariate Analysis: Nonhierarchical Agglomeration, Spatially Con-strained Classiﬁcation. WWW document, http://www.env.duke.edu/landscape/classes/env358/mv_pooling.pdf.Waller, L. A. and Jacquez, G. M. 1995. Disease models implicit in statistical tests of diseaseclustering. Epidemiology6: 584–90.Waller, L. A., Turnbull, B. W., Clark, L. C., and Nasca, P. 1992. Chronic disease surveillanceand testing of clustering of disease and exposure: Application to leukemia incidence andTCE-contaminated dumpsites in upstate New York. Environmetrics3: 281–300.THO_C22  20/03/2007  15:15  Page 416 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 23Terrain AnalysisYongxin Deng, John P. Wilson, and John C. GallantDigital terrain analysis seeks to construct mathematical abstractions of the terrainsurface (for example, Moore, Grayson, and Landson 1991, Florinsky 1998a) todelineate or stratify landscapes (for example, Hammond 1964, Dikau 1989, Burrough,Wilson, van Gaans, and Hanson 2001) and to examine or deﬁne the relationshipsbetween the terrain surface and various biophysical processes/patterns (for example,Moore, Gessler, Nielsen, and Peterson 1993, Franklin 1995, Beven 1997). The essential scientiﬁc value of these three tasks relies on three simple facts: (1) terrainposes signiﬁcant control over other biophysical elements, (2) the former is mucheasier to measure than the latter; and (3) both tend to vary continuously over spacein a correlated fashion (Burrough and McDonnell 1998). The computed terrainattributes often provide important, if not the only, clues indicating key biophysicalpatterns and processes, and sometimes serve as a spatial prediction tool directly (forexample, Moore, Gessler, Nielsen, and Peterson 1993, Bell, Grigal, and Bates 2000).These roles of terrain analysis represent a bridge from the known to the unknown,and are often vital for resource inventory and environmental modeling, especially attopo- (that is, hillslopes of 50–200 m in length) to meso-scales (that is, watersheds of10–100 km2in extent). They also point to the strong multi-disciplinary characterof many terrain analysis applications.Terrain analysis is nonetheless different from most scientiﬁc approaches to the study of the biophysical environment in that it is enabled by GIS and relatedcomputer technologies, and is supported more by digital terrain data (mostly gridded DEMs – digital elevation models) than by direct ﬁeld observations or laboratory measurements of biophysical properties. Terrain analysis is quantitative,implying high precision in terms of outputs, but these results may simultaneouslybe plagued with uncertainties in terms of the relationship between terrain and biophysical attributes – implying the possibility of low accuracy. The commonapproaches employed in soil-landscape analyses (Park, McSweeney, and Lowery 2001)– statistical correlation (for example, Moore, Gessler, Nielsen, and Peterson 1993),classiﬁcation of terrain attributes based on pre-deﬁned criteria (for example, Zhu1997), and statistical clustering of terrain indices (for example, Irvin, Ventura, andTHO_C23  19/03/2007  11:29  Page 417 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f418YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANTSlater 1997, McBratney and Odeh 1997) – provide typical examples of how terrainanalysis results tend to be used. They all deal primarily with the probability, insteadof the certainty, that we can: (1) use knowledge of soil–landscape relationships toinfer soil conditions from terrain properties, and (2) extrapolate the relationshipsto other places or interpolate them to other scales. This is fundamentally differentfrom conventional sciences such as chemistry in which chemical reactions can bothbe reproduced and explained with certainty.The relative ease with which terrain analysis can be performed points to numer-ous opportunities, but implies tremendous challenges because of these inherent uncertainties. In other words, terrain analysis is more a science dealing with uncer-tainty than with certainty. These uncertainties are often linked to issues such asterrain data quality",
    "chunk_order_index": 257,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-721c735fbf0d0b5843458a27665bb1eb": {
    "tokens": 1200,
    "content": ", and (2) extrapolate the relationshipsto other places or interpolate them to other scales. This is fundamentally differentfrom conventional sciences such as chemistry in which chemical reactions can bothbe reproduced and explained with certainty.The relative ease with which terrain analysis can be performed points to numer-ous opportunities, but implies tremendous challenges because of these inherent uncertainties. In other words, terrain analysis is more a science dealing with uncer-tainty than with certainty. These uncertainties are often linked to issues such asterrain data quality (Adkins and Merry 1994, Bolstad and Stowe 1994, Hunter andGoodchild 1997, Krupnik 2000, Deng, Wilson, and Goodchild 2006), algorithmreliability (Skidmore 1989, Desmet and Govers 1996a, Florinsky 1998b, Quinn, Beven,Chevallier, and Planchon 1991), spatial scale effects (Chang and Tsai 1991, Zhangand Montgomery 1994, Florinsky and Kuryakova 2000, Gertner, Wang, Fang, andAngerson 2002), objects with indeterminate boundaries (Burrough and Frank 1996),and ontological discrepancies regarding landform deﬁnitions (Hudson 1992, Zhu1997, Burrough, Wilson, van Gaans, and Hanson 2001, Mark and Smith 2003).They signify the intrinsic complexity of terrain-environment relationships, as wellas our relative lack of appreciation and understanding of these issues. The growthof new terrain data sources, terrain analysis programs, and terrain-based environ-mental models provide many new opportunities for biophysical study, although they should all be assessed carefully in terms of their scientiﬁc basis prior to wide-spread deployment. They may directly lead to an increase in precision, but do notnecessarily imply a corresponding improvement in accuracy.This chapter examines several essential aspects of terrain analysis based on theaforementioned general vision. Under the heading “Terrain Attributes – State ofthe Art” we describe terrain attributes as scale- and algorithm-dependent descriptionsof the terrain surface and related biophysical processes. Three examples are usedto identify the strengths and weaknesses of terrain-based environmental models and landscape stratiﬁcations in the second section, “Modeling and Synthesis.” Thethird section, “Enduring Challenges,” examines the effects of spatial scale and dataquality on terrain analysis, and the ﬁnal section highlights some of the developmentsthat are likely to occur by the 2020s.Terrain Attributes – State of the ArtAll three of the terrain analysis tasks listed at the start of this chapter rely on calculated terrain attributes. A distinction is generally drawn between primary attri-butes that are computed directly from the DEM and composite attributes that involvecombinations of primary attributes (Moore, Lewis, and Gallant 1993, Florinsky1998a, Wilson and Gallant 2000a). Elevation is unique because its computation doesnot rely on other points; however, we often make assumptions about the characterof the land surface – in terms of its continuity and smoothness – to estimate eleva-tion in a DEM using sparse source data in practice (for example, Hutchinson 1989).THO_C23  19/03/2007  11:29  Page 418 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTERRAIN ANALYSIS419Florinsky (1998a) also distinguished local primary attributes that are calculated asa function of their surroundings and non-local primary attributes that require theanalysis of a larger, non-local land surface area from a computational perspective.Wilson and Burrough (1999) later explained this distinction between local versusnon-local terrain attributes in terms of the existence of local interactions betweenneighboring points and “action-at-distance” forces (see Figure 23.1 for details).Most primary attributes are calculated from the geometric derivatives of the terrain surface using either a second-order ﬁnite difference scheme (for example,Skidmore 1989, Moore, Lewis, and Gallant 1993b, Florinsky 1998b) or a bivariateinterpolation function z =f(x,y) that has been ﬁtted to the DEM (Mitasova,Hoﬁerka, Zlocha, and Iverson 1996). Typical examples of local primary attributesinclude slope, aspect, and plan and proﬁle curvatures; non-local primary attri-butes include ﬂow path length, proximity to nearest ridgeline, dispersal area, andupslope contributing area. More complete lists can be found in Moore, Grayson,and Ladson (1991), Moore, Lewis, and Gallant (1993b), Florinsky (1998a), andGallant and Wilson (2000).By deﬁnition, the local terrain shape – which is usually thought of as the continu-ous variation of elevation values over the terrain surface from point to point – hasan enormous impact on local terrain attributes, but this role is inﬂuenced by dataand computational factors. Florinsky (1998b) suggested that local attributes, suchas slope gradient, aspect, and curvatures, are mathematical variables rather thanreal-world values. This statement may be extended to all local terrain attributes fortwo reasons. First, local terrain shape can have different mathematical descriptions,so that the calculated local attributes depend on algorithm selection. Second, theAtBtCtSite specific(t)Local interactions(t)Action-at-distance(t)UtSite specific(t)",
    "chunk_order_index": 258,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-2ac0fa018bec28148e358edc5a4a181d": {
    "tokens": 1200,
    "content": "enced by dataand computational factors. Florinsky (1998b) suggested that local attributes, suchas slope gradient, aspect, and curvatures, are mathematical variables rather thanreal-world values. This statement may be extended to all local terrain attributes fortwo reasons. First, local terrain shape can have different mathematical descriptions,so that the calculated local attributes depend on algorithm selection. Second, theAtBtCtSite specific(t)Local interactions(t)Action-at-distance(t)UtSite specific(t)Time series inputsLocal-global interactionsTemporal feedbackUt = f(At, Bt, Ct, ...)STATE (U) = f(point inputs/outputs A, neighborhood interactions B, actions-at-a-distance, C)Fig. 23.1Schematic diagram showing site-speciﬁc, local, and regional interaction as a function of timeFrom Wilson and Burrough 1999THO_C23  19/03/2007  11:29  Page 419 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f420YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANTterrain shape portrayed by DEMs is a function of scale, combining the complex-ity of the terrain, scale or resolution of data, and spatial scale at which the terrainsurface is observed. Thus it is possible to use the same local attribute to describeterrain shape at different scales (resolutions). The special feature of non-local primaryattributes is that they rely on the terrain shape of a larger, non-neighbor area andneed to be deﬁned with reference to other, non-local points. Therefore, calculatingnon-local attributes is more difﬁcult because it incurs additional efforts in constructingpoint-to-point connections over the landscape and involves more complex algorithms(for example, Desmet and Govers 1996a, Gallant and Wilson 2000).Secondary or composite attributes account for the spatial variability of biophys-ical processes as a function of topographic effects (Moore, Grayson, and Ladson1991). They are often used to quantify the role played by the terrain surface inredistributing water and sediments over the landscape and in modifying theamount of solar radiation received at various surface locations. Wilson and Gallant(2000b), for example, described three sets of composite attributes – topographicwetness, sediment transport capacity, and solar radiation indices – and some of theways they have been deployed to interpret selected hydrologic, geomorphic, andecological processes and patterns. The topographic wetness index (Wor WT) is prob-ably the most popular of these composite indices and is calculated using one of thefollowing equations depending on whether uniform soil transmissivity (T) undersaturation is assumed or not:(23.1)or(23.2)where a (m2m−1) is the speciﬁc catchment area and β(°) is the slope gradient (Kirkby1976, Beven and Kirkby 1979, Moore, Grayson, and Ladson 1991). Provided certain conditions are met (Beven and Kirkby 1979), the wetness index describesthe pattern of depth to water table in a catchment and hence the pattern of hydro-logic response. It has frequently been used as an index of position in the landscapeand of accumulation of materials for predicting soil properties.Modeling and SynthesisBoth primary and composite attributes are frequently used to provide input datafor various environmental models or landscape delineations based on attribute distributions. The outputs of these applications take the form of identiﬁed terrain–environment relationships, spatio-temporal predictions of environmental properties,and the delineation of meaningful spatial units over the landscape. Three examplesare utilized below to demonstrate how new knowledge may be garnered throughthese modeling and synthesis activities. They also illustrate three enduring issues in  WaTT =⎛⎝⎜⎞⎠⎟ ln tanβ  Wa  lntan=⎛⎝⎜⎞⎠⎟βTHO_C23  19/03/2007  11:29  Page 420 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTERRAIN ANALYSIS421terrain analysis: (1) the impact of the choice of spatial scale or landscape unit onmodel predictions; (2) the difﬁculties encountered representing spatial continuity;and (3) the problem of “equiﬁnality.”Soil erosion/deposition modelingThe large number and complexity of factors inﬂuencing soil erosion rates coupledwith the relative paucity of data at ﬁne scales (that is, 5–10 meter grid cells) haveslowed soil erosion model development since the 1950s. The ﬁrst proposals for combining soil erosion models and Geographic Information Systemns (GIS) werepublished nearly two decades ago (for example, Ventura, Chrisman, Connors, Gurda,and Martin 1988, Warren, Diersing, Thompson, and Goran 1989) and may be contrasted with several of the more recent models that have been implemented inGIS environments from the outset (for example, Mitasova, Hoﬁerka, Zlo",
    "chunk_order_index": 259,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9d9ce0e7535b4c464909e060aacd30c2": {
    "tokens": 1200,
    "content": "the 1950s. The ﬁrst proposals for combining soil erosion models and Geographic Information Systemns (GIS) werepublished nearly two decades ago (for example, Ventura, Chrisman, Connors, Gurda,and Martin 1988, Warren, Diersing, Thompson, and Goran 1989) and may be contrasted with several of the more recent models that have been implemented inGIS environments from the outset (for example, Mitasova, Hoﬁerka, Zlocha, andIverson 1996, Mitas and Mitasova 1998).The most popular, and in many ways most important, soil erosion model up to this point in time is the Universal Soil Loss Equation (USLE), an empirical equation derived from observations of more than 10,000 plot-years on farmlands(Wischmeier and Smith 1978; see Wilson and Lorang 1999 for a detailed review).It incorporates six factors – rainfall–runoff, soil erodibility, slope length, slope gradient, crop management, and conservation practices – and calculates the meanerosion rate (t ha−1yr−1) by comparing the conditions of the target slope (slope length, gradient, erodibility, management, etc.) with a standard soil-loss plot thatis 22.13 m long and has a uniform width and slope gradient (9 percent).This model is intrinsically limited to: (1) landscapes in which erosion is detachmentlimited; (2) planar slopes (except where the special rules for irregular slopes pro-posed by Foster and Wischmeier (1974), which divided irregular slopes into a seriesof planar slope facets, are implemented); and (3) those parts of the landscape thatexperience net erosion over the long term (this requirement will often exclude foot-slopes and valley bottoms in semi-arid and humid areas for example; see Wilson andLorang 1999 for additional discussion of this limitation). Two reasons explain theselimits. First, the model uses the entire slope as the basic spatial unit, and does notincorporate within-slope change in runoff direction and speed (that is, convergence,divergence, acceleration, and deceleration). These changes are a function of surfaceshape (that is, curvatures along or perpendicular to the steepest slope direction)and they are key to the successful prediction of within-slope variation of sedimenttransport processes (detachment, transport, deposition, and detainment). Second,slopes are conceptualized as isolated spatial units, so that the impact of input sedi-ment ﬂow and the possibility of net deposition are not taken into account.The topographic or length-slope factor (LS) for the USLE, originally computed asa function of overall slope length and average slope gradient (Wischmeier and Smith1978), is primarily responsible for the aforementioned limits of the USLE (Wilsonand Lorang 1999). Wilson (1986) proposed a way around these limits that involvedsampling slopes in watersheds and using topographic map information along withthe irregular slope estimation method of Foster and Wischmeier (1974) to generatefrequency distributions of LSfor speciﬁc watersheds (that is, catchments). This methodfacilitated watershed-level comparisons (for example, Wilson and Ryan 1988, WilsonTHO_C23  19/03/2007  11:29  Page 421 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f422YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANT1989) but was not able to characterize the erosion hazard at ﬁner scales.Grifﬁn,Beasley, Fletcher, and Foster (1988) later generalized the topographic or length-slopefactor so that the USLE was able to estimate the soil erosion potential at speciﬁc places(that is, points) in the landscape (so long as the original model assumptions notedearlier held true). However, this approach greatly increased the time and effort neededto implement the USLE and, as a consequence, it attracted little attention prior tothe widespread adoption and use of GIS for natural resource assessment.It was therefore not surprising when Desmet and Govers (1996b) proposed a GIS-based method to calculate the topographic factor over a two-dimensional land-scape that automated the approach of Grifﬁn, Beasley, Fletcher, and Foster (1988),although with one important modiﬁcation. They utilized the upslope contributingarea in place of upslope ﬂowpath length and then concluded that the original (thatis to say, manual) method leads to an underestimation of the erosion risk becausethe effect of ﬂow convergence is not taken into account.Moore and Wilson (1992) had several years earlier proposed a dimensionless, unitstream power-based sediment transport capacity index Tto replace LS in certainlandscape conditions:(23.3)where ais the speciﬁc catchment area (m2 m−1) and β(°) is the slope gradient. Foster(1994) criticized this approach because it relied on different assumptions (most notablythat the erosion rate is transport- rather than detachment-limited) and attemptedto modify just one of several components in this empirical model (the USLE is fundamentally a series of nested regression models and changing one componentmay necessitate changes to one or more other components). It is clear that thesesame criticisms would apply to the approach of Desmet and Govers (1996b) g",
    "chunk_order_index": 260,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-217d04f5bd3ec9573c2b75ed0f20d443": {
    "tokens": 1200,
    "content": "is the slope gradient. Foster(1994) criticized this approach because it relied on different assumptions (most notablythat the erosion rate is transport- rather than detachment-limited) and attemptedto modify just one of several components in this empirical model (the USLE is fundamentally a series of nested regression models and changing one componentmay necessitate changes to one or more other components). It is clear that thesesame criticisms would apply to the approach of Desmet and Govers (1996b) giventhe similarities between the two methods. Moore and Wilson (1994) subsequentlyacknowledged these shortcomings and went on to show that their equation pro-duced similar results to the original USLE for certain slopes (that is, planar slopeswith lengths <100 m and gradients <14°) despite the fact their approach relied ondifferent assumptions to the original USLE.Moore and Wilson (1992, 1994) also suggested calculating a second index:∆Tcj=Φ[amsj−(sinβj−)n−amsj(sinβj)n](23.4)where ∆Tcjis the change in Talong the ﬂow direction over a grid cell, Φis a constant, asis the speciﬁc catchment area (m2 m−1), subscript jsigniﬁes the outletof cell jand j-signiﬁes the inlet to cell j, and β(°) is the slope gradient (as in Equa-tion 23.3). They proposed using this equation to distinguish those parts of the landscape likely to experience net erosion (∆T>0) from those parts likely to experience net deposition (∆T≤0), although this would clearly only work for landscapes in which soil erosion is transport limited.Mitasova, Hoﬁerka, Zlocha, and Iverson (1996) and Mitas and Mitasova (1998)later incorporated some of these same ideas in a soil erosion model that relied onthe solution of bivariate ﬁrst principles water and sediment ﬂow equations. These  Tamn  .sin .=⎛⎝⎜⎞⎠⎟⎛⎝⎜⎞⎠⎟221300896βTHO_C23  19/03/2007  11:29  Page 422 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTERRAIN ANALYSIS423equations can be used to characterize the relationship between erosion/depositionrates and terrain curvatures on slopes with varying soil and cover properties. Theirmodels, which incorporated detachment- as well as transport-limited conditions andboth proﬁle and tangential curvatures, provide a sound theoretical explanation forthe results of ﬁeld experiments reported by Sutherland (1991), Busacca, Cook, andMulla (1993), Quine, Desmet, Govers, Vandaele, and Walling (1994), and Heimsath,Deitrich, Nishiizumi, and Finkel (1997). The highest erosion rates were observedon divergent shoulder elements and deposition on convergent footslope elementsin the ﬁrst pair of studies, whereas the maximum soil loss was observed from theslope convexities and maximum gain in both the slope concavities and the mainthalwegs in the ﬁnal two studies. These results illustrate how small variations interrain shape and soil and land cover can have a dramatic impact on the locationand rates of soil erosion and deposition.This discussion of terrain analysis and soil erosion models would not be com-plete without some mention of the Water Erosion Prediction Project (WEPP) model(Flanagan and Nearing 1995). The tremendous progress towards physically-basederosion models achieved within this project since at least the mid 1990s means that the USLE in its various forms is best suited to preliminary assessments and/orsituations where data is limited nowadays. The WEPP model can be implementedat various levels and can predict erosion and deposition. The WEPP watershed model (Ascough, Baffaut, Nearing, and Liu 1997, Baffaut, Nearing, Ascough, andLiu 1997), for example, is an extension of the WEPP hillslope model and can beused for estimating watershed erosion and sediment yield. However, the applicationof WEPP to watersheds requires that hillslopes be delineated and channels identiﬁed(Figure 23.2). Each hillslope, represented as a rectangle in WEPP, must be assigneda representative length, width, and slope proﬁle (as illustrated in the third part ofFigure 23.2). Cochrane and Flanagan (1999) noted that GIS analysis using DEMsprovides a useful tool for parameterization of hillslopes, channels, and representat-ive slope proﬁles for WEPP simulations and set out to describe and evaluate threemethods for integrating GIS and WEPP to facilitate watershed level applications thatare often of interest to resource managers and policy analysts. This integration isrelatively straightforward but it cannot overcome the fact that the WEPP family ofmodels is based on a one-dimensional sediment routing over planar hillslopes (Foster,Flanagan, Nearing, et al. 1995) and that in many instances this approach will onlypartially explain the impact of terrain shape and the spatial variability of soil andland cover at the watershed scale (Mitas and Mitasova",
    "chunk_order_index": 261,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-441d0fb9714bd1328a48eef0f7d165c4": {
    "tokens": 1200,
    "content": "applications thatare often of interest to resource managers and policy analysts. This integration isrelatively straightforward but it cannot overcome the fact that the WEPP family ofmodels is based on a one-dimensional sediment routing over planar hillslopes (Foster,Flanagan, Nearing, et al. 1995) and that in many instances this approach will onlypartially explain the impact of terrain shape and the spatial variability of soil andland cover at the watershed scale (Mitas and Mitasova 1998).Soil mapping and landform classiﬁcationConventional soil–landscape analysis and soil mapping (Hudson 1992) are basedon a crisp conceptual model that allows a data point to belong to only one class,and thus a sample location (such as a grid point) to fall in only one map unit. Soil variation only occurs across boundaries in geographic space and between the central concepts of prescribed soil classes in attribute space (Zhu 1997). From autilitarian point of view, this leads to loss of soil information because: (1) minordeviations of local soil from the prescribed soil central concept may be known bylocal soil experts but cannot be included in a crisp soil map; and (2) soil bodiesTHO_C23  19/03/2007  11:29  Page 423 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f424YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANTsmaller than the minimum map unit either will be ignored or combined into anothersoil class (Zhu, Hudson, Burt, Lubich, and Simonson 2001).The problems with this soil–landscape model follow from the fact that naturalsoils often exist as spatial continua and natural soil boundaries only exist underspecial circumstances (Burrough 1993, Burrough and Frank 1996, McBratney andOdeh 1997, Zhu 1997). It is also debatable whether soil should always be viewedas spatial objects or as the surrogate of aggregated soil properties, because there is “no agreement on what a basic or fundamental unit of soil is” (Arnold 1983).Hence, there could be endless combinations of dynamic soil conditions (properties),although individual soil properties are usually the major concern in applications suchas soil and water conservation, non-point source pollution control, and precision agri-culture (for example, Burrough 1993, Indorante, et al. 1996, Berry, Delgado, Khosla,and Pierce 2003). These two “discontinuity” and “object” problems in conventionalsoil mapping often occur simultaneously and help to explain the limitations of knowledge-based interpretations of soil–landscape relationships (Zhu, Hudson, Burt,Lubich, and Simonson 2001), which can be more precisely captured as correlationsbetween soil properties and landscape attributes (for example, Burrough 1993, Moore,Gessler, Nielsen, and Peterson 1993, Florinsky and Kuryakova 2000).Based on fuzzy logic, Zhu (1997, 2000), Zhu, Band, Dutton, and Nimlos (1996),Zhu, Band, Vertessy, and Dutton (1997), and Zhu, Hudson, Burt, Lubich, and1. GIS Maps2a. Manual method2b. Hillslope method3. WEPP formatWchannel4. Run WEPPManual discretizationof hillslopes, channels, andrepresentative slope profilesAutomatic discretizationof hillslopes, channels, andrepresentative slope profilesHillslopes draininto channels fromtop, left and right.Representativeslope profile(cid:127) DEM(cid:127) Soils(cid:127) Management/CropsAree = ALFig. 23.2Watershed modeling with GIS and WEPPFrom Cochrane and Flanagan 1999THO_C23  19/03/2007  11:29  Page 424 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTERRAIN ANALYSIS425Simonson (2001) provided a solution for both sets of above-mentioned problems usinga soil similarity model. This approach describes local soil as a similarity vector toprescribed soil classes (central concepts) through three steps: (1) identiﬁcation of aset of central concepts according to existing soil classiﬁcations or expert knowledge;(2) deﬁnition of the linkages between these central concepts (or soil classes) and higherresolution landscape properties; and (3) calculation of the similarity (for example,values from 0 to 1) of each data point to each central concept through a comparisonof their landscape properties. The soil properties of a point can then be derived bycombining its similarity vector with the soil properties of the central concepts (Zhu,Band, Vertessy, and Dutton 1997, Zhu, Hudson, Burt, Lubich, and Simonson 2001).Terrain analysis offers several useful inputs for describing environmental condi-tions and constructing the soil–landscape models in this approach (Zhu, Hudson,Burt, Lubich, and Simonson 200",
    "chunk_order_index": 262,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-527a62fd000c87d6504955a89f7f53d2": {
    "tokens": 1200,
    "content": "their landscape properties. The soil properties of a point can then be derived bycombining its similarity vector with the soil properties of the central concepts (Zhu,Band, Vertessy, and Dutton 1997, Zhu, Hudson, Burt, Lubich, and Simonson 2001).Terrain analysis offers several useful inputs for describing environmental condi-tions and constructing the soil–landscape models in this approach (Zhu, Hudson,Burt, Lubich, and Simonson 2001). The net effect of using terrain attributes is toincorporate continuous spatial variations of the biophysical environment into theoutput fuzzy soil classes at a higher resolution than conventional soil maps.Soil mapping in the US, nevertheless, is a special case of natural resource invent-ory because it has a long history and has involved large human investments to provide rich resources for the identiﬁcation of central soil concepts. When sufﬁcientmapping resources and/or expert knowledge do not exist to support the central concepts (for example, Franklin 1995) the fuzzy k-means landform classiﬁcationmethod will usually provide a better solution for the continuous delineation of thebiophysical environment. This approach uses terrain attributes as input data to deﬁnethe most representative clusters of the data following an iterative, unsupervised clus-tering procedure that can differentiate the data to a maximum extent (McBratneyand Odeh 1997, Irvin, Ventura, and Slater 1997, Burrough and McDonnell 1998,Burrough, Wilson, van Gaans, and Hanson 2001). Class centers so deﬁned are similar to central concepts in soil classiﬁcation. The membership (similarity) of eachdata point to each class center is deﬁned as the attribute distance between the pointand the class center in the attribute space, which is calculated using a selected dis-tance function (Irvin, Ventura, and Slater 1997). The biophysical meanings of fuzzyk-means landform class centers must be post-interpreted, rather than pre-deﬁned,based on the terrain attributes that were used. Furthermore, some additional workwill usually be required to select the terrain attributes (and weights) that will beused to identify the speciﬁc biophysical pattern(s) of interest.Terrain analysis might also be used to create explicit environmental stratiﬁcationsfor survey design and to provide quantitative spatial predictions of individual soilproperties. McKenzie, Gessler, Ryan, and O’Connell (2000), for example, describeda two-step stratiﬁed random sampling strategy for the Bago-Maragle study area inNew South Wales, Australia that combined geologic information (that is, publishedgeologic map units supported by airborne gamma radiometric remote sensing) withthe Prescott Index (which is a function of mean monthly precipitation and potentialevapotranspiration), and the topographic wetness index. A ﬁeld survey of 144 selectedsample sites was then conducted and the data used for quantitative spatial predictionof key land qualities, including soil erodibility, nutrient status, and the soil–waterregime (McKenzie and Ryan 1999). Terrain analysis variables can be used in con-junction with these other variables (climate geology, remote sensing, etc.) to extendpoint observations of individual soil properties using statistical models so long as theTHO_C23  19/03/2007  11:29  Page 425 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f426YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANTexplanatory variables are easier to obtain than soil variables. Hence, Gessler (1996)used a regression tree approach to predict solum depth in the above-mentioned study area, and Bell, Grigal, and Bates (2000) used a series of linear and exponential statistical models to predict soil organic carbon in the Cedar Creek Natural HistoryArea in Minnesota. Interested readers can learn more about the challenges and sub-tleties of the statistical methods employed in these types of modeling applicationsin McKenzie and Austin (1993), Gessler, Moore, McKenzie, and Ryan (1995), Gessler(1996), and McKenzie and Ryan (1999).TOPMODELThe original TOPMODEL introduced by Beven and Kirkby (1979) estimates over-land runoff by integrating a spatially variable contributing area model with a simple,lumped soil water response (storage) model (Kirkby 1976). It deﬁnes the saturatedarea on the landscape Acas the area where:W>ST/m−S3/m+λ(23.5)where Wis the topographic wetness index (Equation 23.1), STis the local maximumwater storage (sum of surface interception, depression, near surface inﬁltration, andsubsurface storage), and mand λare constants. Given the assumption of a time-independent steady state rainfall rate, overland ﬂow (qof) is estimated as:qof=iAc(23.6)where iis an instantaneous rainfall intensity and Acis the saturated area calculatedwith Equation 23.5.Wand Acwere the only spatial variables used in the original model. All of theother variables – such as ﬂow velocity, interception, inﬁltration, subsurface storage,and channel routing – were treated as lumped parameters and had to be measuredor estimated. Beven (1997) discussed the equiﬁnality problem in his critique of TOP",
    "chunk_order_index": 263,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4927c6891ad3cd7cd6efa55b564890af": {
    "tokens": 1200,
    "content": "Ac(23.6)where iis an instantaneous rainfall intensity and Acis the saturated area calculatedwith Equation 23.5.Wand Acwere the only spatial variables used in the original model. All of theother variables – such as ﬂow velocity, interception, inﬁltration, subsurface storage,and channel routing – were treated as lumped parameters and had to be measuredor estimated. Beven (1997) discussed the equiﬁnality problem in his critique of TOPMODEL and noted that many different sets of parameter values can simulateobserved data (that is, the hydrograph) almost equally well in terms of some quan-titative goodness-to-ﬁt measure. Beven and Binley (1992) attributed the difﬁculty ofﬁnding a global optimum parameter set to the complexity of the multi-dimensionalattribute space involved in hydrological modeling that is a function of the use ofthreshold parameters, intercorrelation between parameters, autocorrelation and heteroscedascity in the residuals, and inclusion of insensitive parameters. Beven (1993) and Savenije (2001) also linked this equiﬁnality problem to scales of hydro-logical processes and “laws,” as well as to the effects of aggregation and averaging(lumping) across scales during modeling.Beven and Binley (1992), Beven (1997) and Beven and Freer (2001) have advocatedusing the GLUE (generalized likelihood uncertainty estimation) method to manage theequiﬁnality problem. This method is based on Monte Carlo simulations in whichthe predictions of each parameter set realization are given a likelihood weightingaccording to how well that model ﬁts the observed data (Beven 1997). The likelihoodweights of the parameter sets can be updated when more data (that is, observations)THO_C23  19/03/2007  11:29  Page 426 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTERRAIN ANALYSIS427become available. With the use of the GLUE method, the uncertainty of models canbe deﬁned more precisely and TOPMODEL applications can potentially become aniterative process of model selection, rejection, and optimization. Approaches similarto GLUE may see potential use in terrain analysis because the selection of terrainattributes and terrain analysis scales is currently based on data availability and itis likely that different combinations of scales (resolutions) and attributes (as wellas their weights) may achieve the same terrain analysis goal. The advent of ﬁnerresolution DEMs may improve the deﬁnition of uncertainty in models using thesetypes of uncertainty estimation methods.Enduring ChallengesData qualityThe key role of terrain shape in terrain analysis indicates that the distribution, insteadof the magnitude, of elevation errors should be the primary focus of DEM qualityassessments (Hunter and Goodchild 1997; Burrough and McDonnell 1998, pp. 244–7;Heuvelink 1998; see Hutchinson, Chapter 8 of this volume, for additional discussionof the role of shape in DEM quality assessments). However, most DEM producersonly provide aggregated error indicators (for example, RMSE or root mean squarederror) that are calculated based on more accurate elevations of a few control pointsto report the mean magnitude of elevation errors over one tile (or map area) of the DEM. Some DEM users have utilized mutually independent sample points tolink point elevation errors to the accuracy of calculated point terrain attributes (for example, Isaacson and Ripple 1990, Adkins and Merry 1994, Bolstad and Stowe1994). The reliance on isolated points in both instances precludes the assessmentof local distribution of error and the impact of these errors on terrain shape (seeWise 2000 for an extensive review of some of the key issues here). Table 23.1 showsthat terrain shape may be severely distorted by local errors in DEMs that have a small RMSE and vice versa, and that the local standard deviation of errors calculated with a moving window is a better statistic to describe local distortionsof terrain shape, given the availability of an error surface.The focus on point or average errors dominated error assessments provided withDEMs of coarser resolutions (for example, 30 m or 3 arc second US GeologicalSurvey DEMs), which are aggregated representations of toposcale surface conditions(that is, they are capable of identifying and characterizing 50–150 m long slopes).This focus presents even larger problems when applied to new DEM data sources ofhigher resolutions, because 10 m or ﬁner DEMs can delineate within-slope variationsmuch more precisely and accurately than previous 30 m or 3 arc second DEMs.For example, the subtle variations of landform structures on a slope (topographichollows or local convexities) may be contained, or hidden, in the width of one 30 ×30 m DEM cell, but be manifest on a 10 m or ﬁner resolution DEM. In themeantime, a 0.2 m elevation error of one point on a 10 percent uniform slope maycause the estimate of slope gradient to change from 10 percent to 10.7 percent on a30 m DEM, but from 10 percent to 12 percent on a 10 m DEM, and from 10 per-cent to 30 percent on a 1 m DEM. These two examples indicate that the emergenceTHO_C23  19/03/2007  11:29  Page 427 Downloaded from",
    "chunk_order_index": 264,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-886d725144eb77d1110a8b938eef5c22": {
    "tokens": 1200,
    "content": "error of one point on a 10 percent uniform slope maycause the estimate of slope gradient to change from 10 percent to 10.7 percent on a30 m DEM, but from 10 percent to 12 percent on a 10 m DEM, and from 10 per-cent to 30 percent on a 1 m DEM. These two examples indicate that the emergenceTHO_C23  19/03/2007  11:29  Page 427 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f428YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANTof 10 m, 5 m, or even 1 m DEMs implies more than increasing detail in terrainsurface modeling. Instead, these higher resolutions, compared to previous 30 m or 3 arc second ones, may represent a major shift of spatial scales incorporated inthe DEMs, thus a more imminent need to evaluate the effects of DEM error dis-tributions. In other words, we may be simultaneously facing more precise (in termsof horizontal resolution) and more erroneous (in terms of terrain shape) terrain surface depictions, given the same magnitude of RMSE of elevations reported forthese high resolution DEMs as for the previous coarser resolution ones.New methods are needed to circumvent the unavailability of a true error surface.Hunter and Goodchild (1997) proposed that, instead of dealing with error itself, wecould deﬁne data or model uncertainty, or the extent to which we are uncon-ﬁdent in the obtained results. Speciﬁcally, they suggested that a worst-case scenario could be identiﬁed by introducing into DEMs a set of error ﬁelds that incorporatedifferent degrees of spatial autocorrelation. All possible uncertainties caused by DEMerrors could only occur within a range deﬁned by this worst case scenario. Thisapproach thus directs the research focus from the DEM errors themselves to thepossible effects of DEM errors. A similar approach was adopted by Ehlschlaeger,Shortridge, and Goodchild (1997), who added a series of error surfaces with variousautocorrelation and disturbance variables to an interpolation process and generatedanimated visualizations of data uncertainty with 250 realizations of interpolated30 m DEMs (from a 3 arc second source DEM). Deng, Wilson, and Goodchild(n.d.) argue that it is also necessary to adopt a spatially explicit view to deﬁne the differences between various DEM sources and suggest that a DEM differencesurface calculated from two DEMs can be used to develop spatial tools to estimateeither the DEM errors themselves or the effects of terrain shape distortion on cal-culated terrain attributes.Table 23.1DEM errors, shape representation, and appropriate/inappropriate statistics(adapted from Deng, Wilson, and Goodchild n.d.)Scenarios1234Distribution of point2228880240816elevation errors2228882048016(imagined units)2228884021608Local mean error2828Local RMSE28√(20/3)√(320/3)Error descriptionlowhighlowhighbased on RMSELocal standard002/√38/√3deviation of errorsDistortion ofnonenonelowhighterrain shapeNote: The word “local” refers to the 3 ×3 window shown in the four scenarios. It also implies that a 3 ×3 moving window can be applied to the entire area of interest to generate distributederror statistics.THO_C23  19/03/2007  11:29  Page 428 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTERRAIN ANALYSIS429Spatial scaleMoore, Lewis, and Gallant (1993) identiﬁed four scale-related issues in terrain analysis– basic element size, choice of attribute algorithms, merging of data sources,and scale differences between model and data – that still resonate today. Indeed, twoadditional issues should be added to this list given the recent emergence of numeroushigh-resolution DEMs; the need to: (1) deﬁne geomorphic units at various scales; and(2) calculate terrain attributes at appropriate scales with high-resolution data. TheDEM spatial resolution was linked to issues of data quality and modeling uncertaintyin the previous section – a fact that has been long observed (for example, Changand Tsai 1991, Wolock and Price 1994, Zhang and Montgomery 1994, Mitasova,Hoﬁerka, Zlocha, and Iverson 1996, Bian 1997, Wilson, Spangrud, Nielsen, Jacobsen,and Tyler 1998, Hutchinson and Gallant 2000, Gertner, Wang, Fang, and Angerson2002) but has increased in importance in recent years. All these perspectives indicatethe need to interpret the spatial scale in terrain analysis as an independent dimensionthat is related to all terrain analysis practices in either an explicit or implicit manner.The basic (spatial) element size has attracted the most attention in the study ortreatment of scale-dependencies of terrain analysis. For example, the topographicanalysis for the ﬁrst applications of TOPMODEL were based on a set of uniformareal elements that were approximately 5,",
    "chunk_order_index": 265,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f09e4c517cb51ecc6d3d9b96f9363b9b": {
    "tokens": 1200,
    "content": "increased in importance in recent years. All these perspectives indicatethe need to interpret the spatial scale in terrain analysis as an independent dimensionthat is related to all terrain analysis practices in either an explicit or implicit manner.The basic (spatial) element size has attracted the most attention in the study ortreatment of scale-dependencies of terrain analysis. For example, the topographicanalysis for the ﬁrst applications of TOPMODEL were based on a set of uniformareal elements that were approximately 5,500 m2in extent and delineated by divid-ing the basin according to ﬂow lines, contour lines, and steepest slope lines (Bevenand Kirkby 1979). Wood, Sivapalan, Beven, and Band (1988) adopted a similarapproach based on the concept of representative elementary areas to deﬁne the scale effects of hydrological modeling. The consideration of landscape features (forexample, ﬂow lines, uniform slopes, etc.) in these applications produced irregularsubdivisions that may provide a higher “actual” resolution than regular grid cellsof the same size (Florinsky 1998a).Most of these studies have examined the effects of the selected DEM resolutionon calculated terrain attributes and modeling results given the widespread use ofgridded DEMs. Isaacson and Ripple (1990), for example, observed very low cor-respondence between grid point slope gradient and aspect values calculated from30 m and 3 arc second (roughly 65 ×92 m) US Geological Survey DEMs respectively.Chang and Tsai (1991) concluded that the accuracy of the same two attributesdecreased with the increase of DEM cell size from 8 m to 80 m. Zhang and Mont-gomery (1994), Mitasova, Hoﬁerka, Zlocha, and Iverson (1996), and Florinsky andKuryakova (2000) identiﬁed threshold DEM resolutions for the modeling of soilmoisture, overland ﬂow, and erosion processes. Florinsky and Kuryakova (2000)interpreted the regular grid cell size, or DEM resolution, in terms of its adequacyfor the description of speciﬁc landscape properties. Various statistical measures (forexample, means, standard deviations, terrain–environment correlation coefﬁcients,fractal dimensions, etc.) have been used in these types of studies to characterize the effects of spatial scale on computed terrian attributes (for example, Florinskyand Kuryakova 2000; see Moore, Lewis, and Gallant 1993 for a comprehensivereview).Figure 23.3 shows that spatially aggregated statistical analysis may not sufﬁci-ently capture the impact of DEM resolution on calculated terrain attributes. Hence,the effect of resolution variation varies from place to place and a simple assessmentTHO_C23  19/03/2007  11:29  Page 429 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f430YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANTof attribute value change in magnitude may hide the fact that β1,β2, andβ3in Figure 23.3 have different topographic, as well as biophysical, meanings. A moredramatic impact could be reasonably expected with greater change of spatial resolu-tions and/or in more complex terrain. Therefore, a spatially explicit approach thatincorporates more complete interpretations of terrain attributes (for example, com-bining slope gradient with aspect) may need to be developed to account for thescale effects of terrain analysis.Several other scale issues warrant further investigation as well. One is the potentialproblem of using a single-sized neighborhood window to estimate terrain charac-teristics. Multi-scale terrain analysis – the use of expanding neighborhood windowsto calculate and compare terrain attributes – can potentially identify threshold window sizes across which the attribute values change abruptly to help clarify themeaning of different attributes and delineate natural landform boundaries. Gallantand Dowling (2003) demonstrate a method that combines terrain attributes at different scales into a single multi-scale attribute to represent geomorphic objects(valley bottoms) that occur at a range of scales.Other key questions regarding spatial scales in terrain analysis that also requireanswers include:•How do the model and attribute scale interact with one another?•How can the various spatial resolutions of different attributes be incorporatedinto the same model according to their different process scales (or scales at work,see Bian 1997)?•How do different terrain analysis algorithms behave with the change of scales?X578 m B1A1A2B2C2554 m 540 m 528 m 560 m C1584 m586 m 2(at 90 m)3(at 150 m)1(at 30 m)1 = (554 m – 528 m) × 100% / 30 m = 87%, 1 is the slope gradient for X at30 m spatial resolution, pointing from A1 to A22 = (578 m – 560 m) × 100% / 90 m = 20%, 2 is the slope gradient for X at90 m spatial resolution, pointing from B1 to B23 = (586 m – 584 m) × 100% / 150 m = 1%, 3 is the slope gradient for X at150 m spatial resolution, pointing from C2 to C1βββββββββFig. 23.3Scale effects of terrain analysis",
    "chunk_order_index": 266,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b1729eb10455e3b4bd100d58cf0266a1": {
    "tokens": 1200,
    "content": "– 560 m) × 100% / 90 m = 20%, 2 is the slope gradient for X at90 m spatial resolution, pointing from B1 to B23 = (586 m – 584 m) × 100% / 150 m = 1%, 3 is the slope gradient for X at150 m spatial resolution, pointing from C2 to C1βββββββββFig. 23.3Scale effects of terrain analysis. Slope gradients (β1,β2,andβ3) for the same point B (or d) are deﬁned in different ways due to the change of spatial resolution. The resultant slopegradients are different not only in magnitudes, but also in terms of topographic meaningsTHO_C23  19/03/2007  11:29  Page 430 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTERRAIN ANALYSIS431•What modeling effects should be expected (that is to say anticipated) when com-bining data sources that incorporate different spatial scales?SUMMARYWe brieﬂy reviewed several key characteristics of terrain analysis and discussed several emerging perspectives, including the role of fuzzy logic, equiﬁnality, shape-based data quality evaluations, and multi-scale terrain analysis. Several soil erosionmodels were reviewed to demonstrate the importance and great difﬁculties that are encountered delineating landscape units in these types of modeling applications.The traditional approach to soil–landscape analysis was described to portray howdigital terrain analysis, together with new methodologies such as fuzzy logic, canimprove soil classiﬁcation and support a shift from crisp to continuous paradigms invarious environmental modeling domains. The guiding principles of TOPMODELwere brieﬂy discussed and used as an example to explain the equiﬁnality problem andits potential signiﬁcance to terrain analysis. The limitations encountered in manag-ing spatial scale and data quality problems were identiﬁed as enduring challengesto terrain analysis and our ability to use computed terrain attributes to describeenvironmental patterns and processes of interest.REFERENCESAdkins, K. F. and Merry, C. J. 1994. Accuracy assessment of elevation data sets using the global positioning system. Photogrammetric Engineering and Remote Sensing60:195–202.Arnold, R. W. 1983. Concepts of soils and pedology. In L. P. Wilding, N. E. Smeck, andG. F. Hall (eds) Pedogenesis and Soil Taxonomy: Concepts and Interactions. New York:Elsevier, pp. 1–22.Ascough, J. C., Baffaut, C., Nearing, M. A., and Liu, B. Y. 1997. The WEPP watershedmodel: I. Hydrology and erosion. Transactions of the American Society of AgriculturalEngineers40: 921–33.Baffaut, C., Nearing, M. A., Ascough, J. C., and Liu, B. Y. 1997. The WEPP watershedmodel: II. Sensitivity and discretization.Transactions of the American Society of Agri-cultural Engineers40: 935–43.Bell, J. C., Grigal, D. F., and Bates, P. C. 2000. A soil-terrain model for estimating spatialpattern of soil organic carbon. In J. P. Wilson and J. C. Gallant (eds) Terrain Analysis:Principles and Applications. New York: John Wiley and Sons, pp. 295–310.Berry, J. K., Delgado, J. A., Khosla, R., and Pierce, F. J. 2003. Precision conservation forenvironmental sustainability.Journal of Soil and Water Conservation58: 332–9.Beven, K. J. 1993. Prophecy, reality and uncertainty in distributed hydrological modeling.Advances in Water Resources16: 41–51.Beven, K. J. 1997. TOPMODEL: A critique. Hydrological Processes11: 1069–85.Beven, K. J. and Binley, A. 1992. The future of distributed models: Model calibration anduncertainty prediction. Hydrological Processes6: 279–98.Beven, K. J. and Freer, J. 2001. Equiﬁnality, data assimilation, and uncertainty estimation inmechanistic modeling of complex environmental systems using the GLUE methodology.Journal of Hydrology249: 11–29.THO_C23  19/03/2007  11:29  Page 431 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f432YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANTBeven, K. J. and Kirkby, M. J. 1979. A physically based variable contributing area modelof basin hydrology. Hydrology Science Bulletin24: 43–69.Bian, L. 1997. Multiscale nature of spatial data in scaling up environmental models. In D. A. Quattrochi and M. F. Good",
    "chunk_order_index": 267,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-88bdcba6ada64a2ce6b979a48806d222": {
    "tokens": 1200,
    "content": "432YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANTBeven, K. J. and Kirkby, M. J. 1979. A physically based variable contributing area modelof basin hydrology. Hydrology Science Bulletin24: 43–69.Bian, L. 1997. Multiscale nature of spatial data in scaling up environmental models. In D. A. Quattrochi and M. F. Goodchild (eds) Scale in Remote Sensing and GIS. New York:Lewis Publishers, pp. 13–26.Bolstad, P. V. and Stowe, T. 1994. An evaluation of DEM accuracy: Elevation, slope andaspect. Photogrammetric Engineering and Remote Sensing23: 387–95.Burrough, P. A. 1993. Soil variability: A late 20th century view. Soils and Fertilizers56:531–61.Burrough, P. A. and Frank, A. U. (eds). 1996. Geographic Objects with IndeterminateBoundaries. London: Taylor and Francis.Burrough, P. A. and McDonnell, R. A. 1998. Principles of Geographical Information Systems.Oxford: Oxford University Press.Burrough, P. A., Wilson, J. P., van Gaans, P. F. M., and Hanson, A. J. 2001. Fuzzy k-meansclassiﬁcation of topo-climatic data as an aid to forest mapping in the Greater YellowstoneArea, USA. Landscape Ecology16: 523–46.Busacca, A. J., Cook, C. A., and Mulla, D. J. 1993. Comparing landscape scale estimationof soil erosion in the Palouse using Cs-137 and RULSE. Journal of Soil and WaterConservation48: 361–7.Chang, K. and Tsai, B. 1991. The effect of DEM resolution on slope and aspect mapping.Cartography and Geographic Information Systems18: 69–77.Cochrane, T. A. and Flanagan, D. C. 1999. Assessing water erosion in small watersheds usingWEPP with GIS and digital elevation models. Journal of Soil and Water Conservation54:678–85.Deng, Y. X., Wilson, J. P., and Goodchild, M. F. n.d. New DEM data sources and the portrayal of terrain shape. International Journal of Geographic Information Science: Inpreparation.Desmet, P. J. J. and Govers, G. 1996a. Comparison of routing algorithms for digital eleva-tion models and their implications for predicting ephemeral gullies. International Journalof Geographical Information Systems10: 311–31.Desmet, P. J. J. and Govers, G. 1996b. A GIS procedure for automatically calculating theUSLE LS factor on topographically complex landscape units. Journal of Soil and WaterConservation51: 427–33.Dikau. R. 1989. The application of a digital relief model to landform analysis in geomor-phology. In J. Raper (ed.) Three Dimensional Applications in Geographic InformationSystems. London: Taylor and Francis, pp. 1–77.Ehlschlaeger, C. R., Shortridge, A. M., and Goodchild, M. F. 1997. Visualizing spatial datauncertainty using animation. Computers and Geosciences23: 387–95.Flanagan, D. C. and Nearing, M. A. (eds). 1995. Water Erosion Prediction Project: HillslopeProﬁle and Watershed Model Documentation. West Lafayette, IN: USDA-ARS NationalSoil Erosion Research Laboratory Report No. 10.Florinsky, I. V. 1998a. Combined analysis of digital terrain models and remotely sensed datain landscape investigations. Progress in Physical Geography22: 33–60.Florinsky, I. V. 1998b. Accuracy of local topographic variables derived from digital eleva-tion models. International Journal of Geographic Information Science12: 47–61.Florinsky, I. V. and Kuryakova, G. A. 2000. Determination of grid size for digital terrainmodeling in landscape investigations: Exempliﬁed by soil moisture distribution at a micro-scale. International Journal of Geographical Information Science14: 815–32.Foster, G. R. 1994. Comment on “Length-slope factors for the Revised Universal Soil LossEquation: Simpliﬁed method of estimation.” Journal of Soil and Water Conservation49:171–3.THO_C23  19/03/2007  11:29  Page 432 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTERRAIN ANALYSIS433Foster, G. R., Flanagan, D. C., Nearing, M. A., Lane, L. J., Risse, L. M., and Finkner, S. C.1995. Hillslope erosion component. In D. C. Flanagan and M. A. Nearing (eds) WaterErosion Prediction Project: Hillslope Proﬁle and Watershed Model Documentation. WestLafayette, IN: USDA-ARS National Soil Erosion Research Laboratory Report No. 10:11",
    "chunk_order_index": 268,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-2d1e8f0457fab613b1882c575c5d7f3c": {
    "tokens": 1200,
    "content": ", D. C., Nearing, M. A., Lane, L. J., Risse, L. M., and Finkner, S. C.1995. Hillslope erosion component. In D. C. Flanagan and M. A. Nearing (eds) WaterErosion Prediction Project: Hillslope Proﬁle and Watershed Model Documentation. WestLafayette, IN: USDA-ARS National Soil Erosion Research Laboratory Report No. 10:11.1–11.12.Foster, G. R. and Wischmeier, W. H. 1974. Evaluating irregular slopes for soil loss pre-diction. Transactions of the American Society of Agricultural Engineers17: 305–9.Franklin, J. 1995. Predictive vegetation mapping: Geographic modeling of biospatial patterns in relation to environmental gradients. Progress in Physical Geography 19:474–99.Gallant, J. C. and Dowling, T. I. 2003. A multi-resolution index of valley bottom ﬂatnessfor mapping depositional areas. Water Resources Research39: 1347–60.Gertner, G., Wang, G., Fang, S., and Angerson, A. B. 2002. Effect and uncertainty of digitalelevation model spatial resolutions on predicting the topographical factor for soil loss estimation. Journal of Soil and Water Conservation57: 164–74.Gallant, J. C. and Wilson, J. P. 2000. Primary topographic attributes. In J. P. Wilson andJ. C. Gallant (eds) Terrain Analysis: Principles and Applications. New York: John Wileyand Sons, pp. 51–86.Gessler, P. E. 1996. Statistical Soil-landscape Modeling for Environmental Management.Unpublished Ph.D. Dissertation, Centre for Resource and Environmental Studies, AustralianNational University.Gessler, P. E., Moore, I. D., McKenzie, N. J., and Ryan, P. J. 1995. Soil-landscape modelingand spatial prediction of soil attributes. International Journal of Geographical Informa-tion Science9: 421–32.Grifﬁn, M. L., Beasley, D. B., Fletcher, J. J., and Foster, G. R. 1988. Estimating soil loss ontopographically non-uniform ﬁeld and farm units. Journal of Soil and Water Conservation43: 326–31.Hammond, E. H. 1964. Analysis of properties in landform geography: An application tobroad-scale landform mapping. Annals of the Association of American Geographers 54:11–9.Heimsath, A. M., Dietrich, W. E., Nishiizumi, K., and Finkel, R. C. 1997. The soil produc-tion function and landscape equilibrium. Nature388: 358–61.Heuvelink, G. B. M. 1998. Error Propagation in Environmental Modelling with GIS. London:Taylor and Francis.Hudson, B. D. 1992. Soil genesis, morphology and classiﬁcation: The soil survey asparadigm-based science. Soil Science Society of America Journal56: 836–41.Hunter, G. J. and Goodchild, M. F. 1997. Modelling the uncertainty of slope and aspectestimates derived from spatial databases. Geographical Analysis29: 35–49.Hutchinson, M. F. 1989. A new procedure for gridding elevation and streamline data withautomatic removal of pits. Journal of Hydrology106: 211–32.Hutchinson, M. F. and Gallant, J. C. 2000. Digital Elevation Models and representationsof terrain shape. In J. P. Wilson and J. C. Gallant (eds) Terrain Analysis: Principles andApplications.New York: John Wiley and Sons, pp. 29–50.Indorante, S. J., Hammer, R. D., Thompson, B. W., and Alexander, D. L. 1996. Positioningsoil survey for the 21st century. Journal of Soil and Water Conservation 51: 21–8.Irvin, B. J., Ventura, S. J., and Slater, B. K. 1997. Fuzzy and isodata classiﬁcation of landformelements from digital elevation data in Pleasant Valley, Wisconsin. Geoderma77: 137–54.Isaacson, D. L. and Ripple, W. J. 1990. Comparison of 7.5-minute and 1-degree digital elevation models. Photogrammetric Engineering and Remote Sensing56: 1523–27.Kirkby, M. J. 1976. Hydrograph modelling strategies. In R. Peel, M. Chrisholm, and P. Haggett(eds) Process in Physical and Human Geography. London: Heinemann, pp. 69–90.THO_C23  19/03/2007  11:29  Page 433 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f434YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANTKrupnik, A. 2000. Accuracy assessment of automatically derived digital elevation modelsfrom SPOT images. Photogrammetric Engineering and Remote Sensing66: 1017",
    "chunk_order_index": 269,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ed3fe9a1e5f0bdf6698e029b07483daf": {
    "tokens": 1200,
    "content": "]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f434YONGXIN DENG, JOHN P. WILSON, AND JOHN C. GALLANTKrupnik, A. 2000. Accuracy assessment of automatically derived digital elevation modelsfrom SPOT images. Photogrammetric Engineering and Remote Sensing66: 1017–23.McBratney, A. B. and Odeh, I. O. A. 1997. Application of fuzzy sets in soil science: FuzzyLogic, fuzzy measurements, and fuzzy decisions. Geoderma77: 85–113.McKenzie, N. J. and Austin, M. P. 1993. A quantitative Australian approach to medium- andsmall-scale surveys based on soil stratigraphy and environmental correlation. Geoderma57: 329–55.McKenzie, N. J., Gessler, P. E., Ryan, P. J., and O’Connell, D. A. 2000. The role of terrainanalysis in soil mapping. In J. P. Wilson and J. C. Gallant (eds) Terrain Analysis: Principlesand Applications.New York: John Wiley and Sons, pp. 245–65.McKenzie, N. J. and Ryan, P. J. 1999. Spatial prediction of soil properties using environ-mental correlation. Geoderma89: 67–94.Mark, D. M. and Smith, B. 2003. A science of topography: Bridging the qualitative–quantitative divide. In M. P. Bishop and J. Shroder (eds) Geographic Information Scienceand Mountain Geomorphology. Chichester: Springer-Praxis, pp. 1–23.Mitas, L. and Mitasova, H. 1998. Distributed soil erosion simulation for effective erosionprevention. Water Resources Research34: 505–16.Mitasova, H., Hoﬁerka, J., Zlocha, M., and Iverson, L. R. 1996. Modeling topographic potential for erosion and deposition using GIS. International Journal of GeographicalInformation Systems10: 629–41.Moore, I. D., Gessler, P. E., Nielsen, G. A., and Peterson, G. A. 1993. Soil attribute predic-tion using terrain analysis. Soil Science Society of America Journal 57: 443–52.Moore, I. D., Grayson, R. B., and Ladson, A. R. 1991. Digital terrain modeling: A reviewof hydrological, geomorphological, and biological applications. Hydrological Processes 5: 3–30.Moore, I. D., Lewis, A., and Gallant, J. C. 1993. Terrain attributes: Estimation methodsand scale effects. In A. J. Jakeman, M. B. Beck, and M. J. McAleer (eds) Modelling Changein Environmental Systems. New York: John Wiley and Sons, pp. 189–214.Moore, I. D. and Wilson, J. P. 1992. Length-slope factors for the revised Universal Soil Loss Equation: Simpliﬁed method of estimation. Journal of Soil and Water Conservation47: 423–8.Moore, I. D. and Wilson, J. P. 1994. Reply to comments by Foster. Journal of Soil andWater Conservation49: 174–80.Park, S. J., McSweeney, K., and Lowery, B. 2001. Identiﬁcation of the spatial distributionof soils using process-based terrain characterization. Geoderma103: 249–72.Quine, T. A., Desmet, P. J. J., Govers, G., Vandaele, K., and Walling, D. E. 1994. A com-parison of the roles of tillage and soil erosion in landform development and sediment exporton agricultural land near Leuven, Belgium. In L. J. Olive (ed.) Variability in Stream Erosionand Sediment Transport.Gentbrugge, Belgium: International Association of HydrologicalSciences Publication No. 224: 77–86.Quinn, P. F., Beven, K. J., Chevallier, P., and Planchon, O. 1991. The prediction of hillslopeﬂow paths for distributed hydrological modeling using digital terrain models. HydrologicalProcesses5: 59–79.Savenije, H. H. G. 2001. Equiﬁnality, a blessing in disguise? Hydrological Processes15: 283–8.Skidmore, A. K. 1989. A comparison of techniques for calculating gradient and aspect froma gridded digital elevation model. International Journal of Geographical Information Systems3: 323–34.Sutherland, R. A. 1991. Caesium-137 and sediment budgeting within a partially closed drainagebasin. Zeitschrift für Geomorphologie35: 47–63.Ventura, S. J., Chrisman, N. R., Connors, K., Gurda, R. F., and Martin, R. W. 1988. Aland information system for soil erosion control planning. Journal of Soil and WaterConservation43: 230–3.THO_C23  19/03/2007  11:29  Page 434 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library",
    "chunk_order_index": 270,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-217fb0fd4067c9b044bd72a374fca311": {
    "tokens": 1200,
    "content": "J., Chrisman, N. R., Connors, K., Gurda, R. F., and Martin, R. W. 1988. Aland information system for soil erosion control planning. Journal of Soil and WaterConservation43: 230–3.THO_C23  19/03/2007  11:29  Page 434 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fTERRAIN ANALYSIS435Warren, S. D., Diersing, V. E., Thompson, P. J., and Goran, W. D. 1989. An erosion-based land classiﬁcation system for military installations. Environmental Management13: 251–7.Wilson, J. P. 1986. Estimating the topographic factor in the Universal Soil Loss Equationin watersheds. Journal of Soil and Water Conservation41: 179–84.Wilson, J. P. 1989. Soil erosion from agricultural land in the Lake Simcoe-Couchiching Basin,1800–1981. Canadian Journal of Soil Science69: 137–51.Wilson, J. P. and Burrough, P. A. 1999. Dynamic modeling, geostatistics, and fuzzyclassiﬁcations: New sneakers for a new geography? Annals of the Association of AmericanGeographers89: 736–46.Wilson, J. P. and Gallant, J. C. 2000a. Digital terrain analysis. In J. P. Wilson and J. C. Gallant (eds)Terrain Analysis: Principles and Applications. New York: John Wileyand Sons, pp. 1–27.Wilson, J. P. and Gallant, J. C. 2000b. Secondary topographic attributes.In J. P. Wilsonand J. C. Gallant (eds)Terrain Analysis: Principles and Applications. New York: JohnWiley and Sons, pp. 87–132.Wilson, J. P. and Lorang, M. S. 1999. Spatial models of soil erosion and GIS. In A. S. Fotheringham and M. Wegener (eds) Spatial Models and GIS: New Potentials andNew Models. London: Taylor and Francis, pp. 83–108.Wilson, J. P. and Ryan, C. M. 1988. Landscape change in the Lake Simcoe-CouchichingBasin, 1800–1983. Canadian Geographer206–22.Wilson, J. P., Spangrud, D. J., Nielsen, G. A., Jacobsen, J. S., and Tyler, D. A. 1998. Globalpositioning system sampling intensity and pattern effects on computed topographicattributes. Soil Science Society of America Journal62: 1410–7.Wischmeier, W. H. and Smith, D. D. 1978. Predicting Rainfall Erosion Losses: A Guide to Conservation Planning.Washington DC: US Department of Agriculture Handbook No. 537.Wise, S. 2000. Assessing the quality for hydrological applications of digital elevation models derived from contours. Hydrological Processes14: 1909–29.Wolock, D. M. and Price, C. B. 1994. Effects of digital elevation model and map scale and data resolution on a topography-based watershed model. Water Resources Research30: 3041–52.Wood, E. C., Sivapalan, M., Beven, K. J., and Band, L. E. 1988. Effects of spatial variabil-ity and scale with implications to hydrologic modeling. Journal of Hydrology102:29–47.Zhang, W. H. and Montgomery, D. R. 1994. Digital elevation model grid size, landscaperepresentation, and hydrologic simulations. Water Resources Research30: 1019–28.Zhu, A.-X. 1997. A similarity model for representing soil spatial information. Geoderma77: 217–42.Zhu, A.-X. 2000. Mapping soil landscape as spatial continua: The neural network approach.Water Resources Research36: 663–77.Zhu, A.-X., Band, L. E., Dutton, B., and Nimlos, T. J. 1996. Automated soil inference underfuzzy logic. Ecological Modeling90: 123–45.Zhu, A.-X., Band, L. E., Vertessy, R., and Dutton, B. 1997. Derivation of soil propertiesusing a soil land inference model (SoLIM). Soil Science Society of America Journal 61:523–33.Zhu, A.-X., Hudson, B., Burt, J., Lubich, K., and Simonson, D. 2001. Soil mapping usingGIS, expert knowledge, and fuzzy logic. Soil Science Society of America Journal65: 1463–72.THO_C23  19/03/2007  11:29  Page 435 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are",
    "chunk_order_index": 271,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-41d5d0e29ca9a8ea2185c180d72626a6": {
    "tokens": 1200,
    "content": "Soil Science Society of America Journal65: 1463–72.THO_C23  19/03/2007  11:29  Page 435 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 24Dynamic ModelingJochen AlbrechtMost Geographic Information Systems (GIS) are an epitome of static, which is whyto many people the word “dynamic GIS” is an oxymoron. GIS usually is about dataand to a much lesser degree about what can be accomplished with the data. As such,GIS can be compared to early twentieth-century geography – an Aristotelian descrip-tion of “where is what” and “what is where” (Barnes 1984). Process, and the notionof change, are acknowledged on the sidelines of Geographic Information Science (GISc)research but have not yet become the mainstream in terms of everyday GIS use.This is in spite of some 15 years since Tomlin’s (1990) “cartographic modeling,” thesuccess of the GIS and Environmental Modeling conference series (for example, Good-child, Steyaert, Parks, et al. 1996, Clarke and Parks 2001), and well-establishedpockets of spatial process modeling research such as Peter Burrough’s group at theUniversity of Utrecht in the Netherlands. This chapter will reframe some of the workusually subsumed under the header of geocomputation by focusing on a single butnew dimension – time – and uncovering low-level structural problems (Burrough 1992)that make it so hard to merge the spatial and temporal aspects of GIS data models(see also Chapter 9 by Yuan in this volume, for further discussion of this topic).Similar to the diversity of disciplinary origins of GIS in the 1970s (US CensusBureau 1969, Tomlinson 1973, Dutton 1978), current approaches to dynamic GIScome from a variety of backgrounds. IT-related approaches include cellular automataand agent-based modeling systems (Itami 1988, Clarke and Gaydos 1998), classicalphysical geography software development focuses on the marriage between tradi-tional ﬂuid dynamics modeling and GIS (Maidment 1993, Wesseling, Karssenberg,Burrough, and van Deursen 1996), civil engineers expand the realm of computeraided design (CAD) by adding sophisticated schedulers (SCADA 1991, Miller andShaw 2001, Zlatanova, Holweg, and Coors 2003), and 2004 marked the ﬁrst yearthat a major vendor released a scripting tool that allows end users rather than developers to create their own dynamic spatial models (ESRI 2003). So far, therehave been few efforts to combine all these approaches and to give them a coherentscientiﬁc foundation. As such, this chapter is as much deﬁning a GISc research agendaas it is reporting on the early successes of such research.THO_C24  19/03/2007  11:28  Page 436 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fDYNAMIC MODELING437Among the earliest of such endeavors were, quite appropriately, a series of dis-sertations in the early 1990s that independently aimed to summarize differentapproaches to the incorporation of temporal elements into GIS analysis (Hazelton1991, Kelmelis 1991, Al-Taha 1992, Langran 1992, Hamre 1994). Accompaniedby academic prototypes, they all sought to add temporal querying capabilities toexisting GIS structures. These temporal extensions to GIS have predominantly beenmodeled either as snapshots, where each layer represents an instance in time, or byamendment vectors, where each entity is associated with a list that contains informa-tion regarding each change in the entity (Langran 1992, Peuquet 1994).The “snapshot” data model, the earliest representation of time in GIS, organizesspace over time, where each raster layer is used to represent a state of the world ata point in time (Wachowicz 1999). A collection of those spatio-temporal snapshotsis used to represent a 4D space-time cube, where at each time step there is a tupleof object id, space, and time (Peuquet 2001). This snapshot model is conceptuallyintuitive, convenient, and easily adapts to available data sources such as satelliteimagery, hence it remains prevalent due to its simplicity (for example, Chen andZaniolo 2000). Problems of large-scale data redundancy, where over time phenomenado not change everywhere, produced an alternative, the base-state with amendmentmodel. This model updates states from the initially complete snapshot for only thoseobjects that undergo change (Langran 1992). For both these approaches, change isinterpolated, whether it be between system states or object states.Incorporating time into the raster and vector data models is seen as the obvioussolution to representing dynamics. However, as argued by Peuquet (1994), time andspace exhibit important differences that do not comply with the neat addition ofdimensions. Recognition that “simply extending a spatial data model to include temporal data, or",
    "chunk_order_index": 272,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7709af9ffcc05559ed76560f16a51891": {
    "tokens": 1200,
    "content": "snapshot for only thoseobjects that undergo change (Langran 1992). For both these approaches, change isinterpolated, whether it be between system states or object states.Incorporating time into the raster and vector data models is seen as the obvioussolution to representing dynamics. However, as argued by Peuquet (1994), time andspace exhibit important differences that do not comply with the neat addition ofdimensions. Recognition that “simply extending a spatial data model to include temporal data, or vice versa, will result in inﬂexible and inefﬁcient representationsfor space-time data” (Peuquet 2001, p. 15) has produced a slew of spatio-temporalalternatives. Then again, time can be represented by space, as has been developed intime geography, which implements Hägerstrand’s (1967) classic model of temporalphenomena. Computational implementations of time geography represent the potentialpath of an individual as a spatial extent which changes over time as the individualmoves through space over time (Huisman and Forer 1998, Miller 2003).A different approach, ﬁrst described by Kirby and Pazner (1990) and expandedby Smith, Su, El-Abbadi, et al. (1995), Pullar (2001, 2003), and Pedrosa, Fonseca,Câmara, Carneiro, and Souza (2002) is the idea to concatenate GIS procedures to modeling scripts. While these are add-ons to existing GIS structures, Wesseling,Karssenberg, Burrough, and van Deursen (1996) went one step further with theintegration of a full-ﬂedged dynamic modeling language into their PCRaster sys-tem. Both ESRI’s geoprocessing framework (ESRI 2003) and PCRaster’s modelinglanguage integration have proven the validity of this approach by being marketable.However, there are many limitations to this coupling of inherently discrete and con-tinuous modeling approaches, which have been well documented (Waters 2002).As Kemp (1997, p. 232) notes, “In order to fully integrate the two we need to adddynamics and continuity to our understanding of spatial data and spatial interactionand functionality to the environmental models.”Object-orientation has been hailed as a new basis for representing environmentalprocesses (for example, Raper and Livingstone 1995, Wachowicz 1999, Bian 2000).THO_C24  19/03/2007  11:28  Page 437 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f438JOCHEN ALBRECHTObject-orientated approaches typically handle time by time-stamping objects or time-stamping their attributes (Stefanakis 2003). Yuan (1996, 2001; Chapter 9 in thisvolume) developed typologies of modeling change, where change is represented as anew state with a new time stamp. This expression draws apart the temporal, spatialand attribute dimensions, reducing change to a variety of distinct forms. For captur-ing change in spatial objects, various temporal interpolation methods have beenproposed for geometric changes of spatial objects (Zhang and Hunter 2000).While all of the above-mentioned work can be seen as a natural extension ofGIS technology, other, usually more social-science oriented researchers started tolook at cellular automata (CA) and agent-based modeling (ABM) systems in an attemptto capture individual spatial behaviors. The majority of CA-based research(Couclelis 1985, 1997; Batty and Xie 1994; Wu 1998; Batty, Xie, and Sun 1999;Shi and Pang 2000; O’Sullivan 2001a, b; Benenson, Omer, and Portugali 2002)uses this simulation environment to determine which spatial conﬁgurations and whatset of rules (behavior) lead to a desired or observed urban form. University Collegeof London’s Centre for Advanced Spatial Analysis has been the source for an impres-sive array of software tools that mix and match CA and ABM to mimic urban land-scapes. Similar to Batty and Longley’s (1994) fractal cities, the emphasis is onprediction and the exploration of new techniques.More theoretically oriented is the use of ABM by a group of European regionalscientists (Bura, Guerin-Pace, Mathian, Pumain, and Sanders 1996, Nijkamp andReggiani 1998, Sembolini 2000, Benenson and Torrens 2004), who seek to developsoftware environments that help to create explanatory spatiotemporal models. Thesemodels are formal speciﬁcations of conceptual models in settlement geography, regional economics, political geography, and in one rare case coastal geomorphology(Raper and Livingstone 1995, Raper, Livingstone, Bristow, and Horn 1999) andas such are aimed at conﬁrming existing or developing new theories. This is in starkcontrast to their US counterparts (for example, Smith, Beckman, Baggerly, Anson,and Williams 1993, Westervelt and Hopkins 1999, Villa 2000, Agarwal, Green,Grove, Evans, and Schweik 2001, Jenerette and Wu 2001, Gimblett 2002, Waddell2002), who are very application oriented.These developments have lead to what",
    "chunk_order_index": 273,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-1de4a00830cf8311cbc9cab352071196": {
    "tokens": 1200,
    "content": "ming existing or developing new theories. This is in starkcontrast to their US counterparts (for example, Smith, Beckman, Baggerly, Anson,and Williams 1993, Westervelt and Hopkins 1999, Villa 2000, Agarwal, Green,Grove, Evans, and Schweik 2001, Jenerette and Wu 2001, Gimblett 2002, Waddell2002), who are very application oriented.These developments have lead to what has been termed dynamic GIS (DeVasconcelos, Gonçalves, Catry, Paúl, and Barros 2002). Here the lines between thetraditional ﬁelds of GIS and computational simulation are rapidly blurring, withboth the increasing integration of GIS data structures into computational simulationtools and the converse of the import of simulation tools into a GIS environment. Forexample, De Vasconcelos, Gonçalves, Catry, Paúl, and Barros (2002) present a dyn-amic GIS which is based on a “geounit”, a CA-like data structure which extends thatsimple formalism to any form of spatial structure and is combined with scheduled andevent-based events. A further example of the integration of computational simula-tion and GIS is the development of CA within a GIS, for example, Wesseling, et al.(1996) developed a spatially distributed hydrological model in PCRaster (an opensource GIS developed at the University of Utrecht), which is essentially a CA.In either case, CA and ABM systems do little to address the fundamental short-comings of GIS (Chrisman 1987, Burrough 1992, Raper 2000). One of the ﬁrst tobasically start from scratch with the development of a new four-dimensional datamodel was Peuquet (1992, 1994), whose work resulted in a series of research projectsTHO_C24  19/03/2007  11:28  Page 438 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fDYNAMIC MODELING439(MacEachren, Wachowicz, Edsall, and Haug 1999, Peuquet and Guo 2000) andsparked a new generation of truly geographic (as opposed to computer-science as dis-cussed later) data modeling literature (Yuan and Lin 1992, Peuquet and Wentz 1994,Peuquet and Duan 1995, Tryfona and Jensen 1999, Wachowicz 1999, Yuan 1999and Chapter 9 in this volume, Mennis, Peuquet, and Qian 2000, Renolen 2000).Although the discipline of geography adopted the notion of process around theturn of the twentieth century, it failed almost completely to scrutinize the funda-mental role of time. Non-computational exceptions were Blaut (1961) Hägerstrand(1967), Carlstein, Parkes, and Thrifts (1978), and Pred (1981). Now, we experiencea renaissance of “time geography” and the works of Egenhofer and Golledge (1998),Kwan (1998), Frank, et al. (2001), Bian (2000), Raper (2000), Frihida, Marceau,and Thériault (2002), and Pereira (2002) provide the ﬁrst usable geographic con-ceptualizations that were compiled with an implementation on a computer in mind.The crucial difference to FORTRAN hacks of previous generations is that these are genuine geographic models and not mere adaptations of physics. Miller (Millerand Wentz 2003; Miller 2005) summarizes the current state of geographic con-ceptualizations of space and time.The next step in implementing these new geographic models on a computer isto develop formal spatio-temporal speciﬁcations or ontologies. Starting withCasati, Smith, and Varsi (1998), this has become an important new thread of GIScresearch (for example, Hornsby and Egenhofer 2002, Mota, Bento, and Botelho 2002,Bittner and Smith 2003, Reitsma and Bittner 2003). Philosophers, computer scientists,and geographers are now concentrating on two phenomena and their conceptualiza-tion, representation, and analysis (Erwig, Güting, Schneider, and Vazirgiannis 1999):one is the notion of “process” (Claramunt and Thériault 1996, Chen and Molenaar1998, Pang and Shi 2002) and the other that of “change” (Frank et al. 2001, Galton2000, Hornsby and Egenhofer 2000, Worboys 2001).Traditional representations of geographic phenomena (Berry 1964, Goodchild 1990) are object centered, where an object has a location (x,y,z), some attributes(a,b,c), and rarely also some time stamp (t). This is usually represented as G =f(x,y,z,[t],a,b,c,...). The geographic object G can be one or more raster cells orsome vector geometry, in which case a, b, c, t would be held constant over what-ever area G covers.Complementary to this object-centered perspective is a process-based one, wherethe primitive is a tuple of the form (x1,y1,z1,t1,a1,b1,c1,∆,x2,y2",
    "chunk_order_index": 274,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a2664b9762e726a4b685de01f6231ce3": {
    "tokens": 1200,
    "content": "is usually represented as G =f(x,y,z,[t],a,b,c,...). The geographic object G can be one or more raster cells orsome vector geometry, in which case a, b, c, t would be held constant over what-ever area G covers.Complementary to this object-centered perspective is a process-based one, wherethe primitive is a tuple of the form (x1,y1,z1,t1,a1,b1,c1,∆,x2,y2,z2,t2,a2,b2,c2).Vector ∆represents some form of transformation, including the null transformation, wherenothing changes, in which case x1=x2, a1=a2, etc. Process as primitive providesleverage for querying and analyzing the geographic processes that have for so longeluded analysis. Crucial to the identity of a process is its pattern of change, vector∆from above.Example 1: Air Trafﬁc Control (ATC)The ultimate goal of ATC is to get airplanes safely from one place to another. Safelymeans that there should be a minimum distance between planes, measured in minutes(between takeoffs) or miles (3miles horizontal, 1000′vertical near the airport, 5 milesTHO_C24  19/03/2007  11:28  Page 439 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f440JOCHEN ALBRECHTand 2000′vertical further away). The main process is the ﬂight itself, a path deter-mined by waypoints and time stamps. Both aircraft separation and ﬂight plan areobviously easily represented in the tuple structure given above. This main process canbe divided into eight sub-processes, which form the eight different classes of ﬂightdirectives that an air trafﬁc controller may communicate to the pilot (Figure 24.1).Auxiliary processes govern the communication between air trafﬁc controllers andmanagement of up to 30 airplanes per individual controller; they are well codiﬁed(Wickens, Mavor, Purusurum, and McGee 1998) and include all the contextual andrelational information that we would place into our blackboard structure such as:the hierarchy of the system command center, route trafﬁc control centers, sectors,TRACONs (Terminal Radar Approach Control – typically, the TRACON controlsaircraft approaching and departing between 5 and 50 miles of the airport), andterminal air trafﬁc control towers; the system of airspace classes, and especially theprotocol for transferring responsibility from one controller to the next one alongthe ﬂight path. This all works fairly well until bad weather or human error movesa complicated system into a state of complexity. Example 2 deals with the weather.Example 2: Advanced Regional Prediction System (ARPS)ARPS is a development of the Center for Analysis and Prediction of Storms at theUniversity of Oklahoma. In their 700+page user manual (APRS 2006) the Centerdescribes a model for storm prediction.A storm is the movement of air masses, the prediction of which is dependent onmomentum, heat, mass, water transfer, and turbulent kinetic energy. The model isholdingpatternvector forspacingvector forspacingvmaxvmaxvmaxdetourshortcutFig. 24.1Eight possible ATC commands for a single aircraftFrom Bayen, Grieder, and Tomlin 2005THO_C24  19/03/2007  11:28  Page 440 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fDYNAMIC MODELING441essentially an equation of state that is initialized using prescribed analytical functions.The basic model variables are deﬁned as:u(x,y,z,t) =u(z) +u′(x,y,z,t)v(x,y,z,t) =v(z) +v′(x,y,z,t)w(x,y,z,t) =w′(x,y,z,t)θ(x,y,z,t) =θθ(z) +θ′(x,y,z,t)p(x,y,z,t) =p(z) +p′(x,y,z,t)2(x,y,z,t) =4(z)+2′(x,y,z,t)qv(x,y,z,t) =qv(z)+qv′(x,y,z,t)qli(x,y,z,t) =qli′(x,y,z,t)where u, v and w are the Cartesian components of velocity (momentum), θthepotential temperature, p the pressure, 2the density, qv the water vapor mixing ratio,and qli one of the hydrometeorological categories (vapor, rain, snow, hail). Thebold-faced variables represent the base state and the primed variables are the devi-ations (APRS 2006, p. 6:5).ARPS solves prognostic equations for u,v,w,θ′,p′and q,ψ,which are, respect-ively, the x, y and z components of the Cartesian velocity, the perturbation potentialtemperature and perturbation pressure, and the six categories of water substance (watervapor, cloud water, rain",
    "chunk_order_index": 275,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4779d0cade131b52e810e877ce334023": {
    "tokens": 1200,
    "content": "hail). Thebold-faced variables represent the base state and the primed variables are the devi-ations (APRS 2006, p. 6:5).ARPS solves prognostic equations for u,v,w,θ′,p′and q,ψ,which are, respect-ively, the x, y and z components of the Cartesian velocity, the perturbation potentialtemperature and perturbation pressure, and the six categories of water substance (watervapor, cloud water, rainwater, cloud ice, snow, and hail). The whole ARPS model ishence one huge tuple of the form (x1,y1,z1,t1,a1,b1,c1,∆,x2,y2,z2,t2,a2,b2,c2).The challenge (and opportunity) in linking the air trafﬁc control model with thestorm prediction model is to determine when what characteristic of ∆of the ARPSmodel is likely to have a negative impact on ∆in the ATC model. The beauty ofthis example is that everything is fairly straightforward because we use compatiblemathematical notations. Wesseling’s success with PCRaster is based on its designfor application areas whose conceptual models lend themselves to be formalized inalgebra. The advantage built into the above example is a shared conceptualizationof space and time.This is unfortunately not true across all geographically relevant domains. Whatwe need is a “language of change.” This language needs to be: (1) high-level to letdomain scientists rather than highly specialized information scientists encode theirmodels; and (2) extensible and open enough to allow for different notions of spaceand time at a range of scales. Conceptually, Reitsma and Albrecht’s (2005) nenmodelhas this kind of openness but it has yet to be supported by a process ontology thatcan express rules deﬁning the thresholds of process change, and operations express-ing the behavior of the process. The semantic web rule language (W3C 2005) iscurrently the most promising candidate for such tools that would allow us to buildtruly interoperable libraries of geospatial process models.REFERENCESAgarwal, C., Green, G., Grove, M., Evans, T., and Schweik, C. 2001. A Review and Assessmentof Land-use Change Models: Dynamics of Space, Time, and Human Choice.Bloomington,IN: Indiana University, Center for the Study of Institutions, Population, and EnvironmentalChange Collaborative Report No. 1.THO_C24  19/03/2007  11:28  Page 441 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f442JOCHEN ALBRECHTAl-Taha, K. 1992. Temporal Reasoning in Cadastral Systems. Unpublished PhD Disserta-tion, Department of Spatial Information Science and Engineering, University of Maine.ARPS. 2006. Advanced Regional Prediction System User’s Guide (Version 5). Norman, OK:University of Oklahoma, Center for Analysis and Prediction of Storms (available athttp://www.caps.ou.edu/ARPS/arpsdoc.html).Barnes, J. (ed.). 1984. The Complete Works of Aristotle. Oxford: Oxford University Press.Batty, M. and Longley, P. A. 1994. Fractal Cities. London: Academic Press.Batty, M. and Xie, Y. 1994. From cells to cities. Environment and Planning B21: 31–48.Batty, M., Xie, Y., and Sun, Z. 1999. Modeling urban dynamics through GIS based cellularautomata. Computers Environment and Urban Systems23: 205–33.Bayen, A., Grieder, P., and Tomlin, C. 2005. Lagrangian delay predictive model for sectorbased air trafﬁc ﬂow. AIAA Journal on Guidance, Control and Dynamics28: 1015–26.Benenson, I., Omer, I., and Portugali, J. 2002. Entity-based modeling of urban residentialdynamics: the case of Yaffo, Tel Aviv. Environment and Planning B29: 491–512.Benenson, I. and Torrens, P. 2004. Geosimulation: Automata-based Modeling of UrbanPhenomena. London: John Wiley and Sons.Berry, B. 1964. Approaches to regional analysis: A synthesis. Annals of the Association ofAmerican Geographers54: 2–11.Bian, L. 2000. Object-oriented representation of modeling mobile objects in an aquatic environment. International Journal of Geographical Information Science14: 603–23.Bittner, T. and Smith, B. 2003. Granular spatio-temporal ontologies. In Proceedings of the AAAISpring Symposium on Foundations and Applications of Spatio-temporal Reasoning(FASTR).Palo Alto,CA, USA. Menlo Park, CA: American Association for Artiﬁcial Intelligence.Blaut, J. 1961. Space and process. Professional Geographer 13: 1–7.Bura, S., Guerin-Pace, F., Mathian, H., Pumain, D., and Sanders, L. 1996. Multiagent systems and the dynamics of a settlement system. Geographical Analysis 28: 161–78.Burrough, P. A. 1992. Are GIS data structures too simple",
    "chunk_order_index": 276,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b5653127672eb0de4fa6092bb043919e": {
    "tokens": 1200,
    "content": "for Artiﬁcial Intelligence.Blaut, J. 1961. Space and process. Professional Geographer 13: 1–7.Bura, S., Guerin-Pace, F., Mathian, H., Pumain, D., and Sanders, L. 1996. Multiagent systems and the dynamics of a settlement system. Geographical Analysis 28: 161–78.Burrough, P. A. 1992. Are GIS data structures too simple minded? Computers and Geosciences19: 395–400.Carlstein, T., Parkes, D., and Thrift, N. (eds). 1978. Timing Space and Spacing Time. London:Edward Arnold.Casati, R., Smith, B., and Varzi, A. 1998. Ontological tools for geographic representation.In N. Guarino (ed.) Formal Ontology in Information Systems. Amsterdam: IOS Press, pp. 77–85.Chen, C. and Zaniolo, C. 2000. SQLST: A spatio-temporal data model and query language.In Proceedings of the Nineteenth International Conference on Conceptual Modeling (ER’00),Salt Lake City, UT, USA. New York: Association of Computing Machinery, pp. 96–111.Chen, T. and Molenaar, M. 1998. A process-oriented spatio-temporal data model to supportphysical environmental modeling. In Proceedings of the Eighth International SymposiumonSpatial Data Handling, Vancouver, British Columbia, pp. 418–30.Chrisman, N. 1987. Fundamental principles of geographic information systems. In Proceed-ings of AutoCarto 8,Baltimore, MD: 32–41.Claramunt, C. and Thériault, M. 1996. Toward semantics for modeling spatio-temporal processes within GIS. In M. Kraak and M. Molenaar (eds) Proceedings of the SeventhInternationalSymposium on Spatial Data Handling. London: Taylor and Francis, pp. 47–63.Clarke, K. and Gaydos, L. 1998. Loose coupling a cellular automaton model and GIS: Longterm urban growth prediction for San Francisco and Washington/Baltimore. InternationalJournal of Geographical Information Systems12: 699–714.Clarke, K. and Parks, B. O. (eds). 2001. Geographic Information Systems and EnvironmentalModeling. Upper Saddle River, NJ: Prentice-Hall.Couclelis, H. 1985. Cellular worlds: A framework for modeling micro-macro dynamics.Environment and Planning A 17: 585–96.THO_C24  19/03/2007  11:28  Page 442 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fDYNAMIC MODELING443Couclelis, H. 1997. From cellular automata to urban models: New principles for model development and implementation. Environment and Planning B24: 165–74.De Vasconcelos, M., Gonçalves, A., Catry, F., Paúl, J., and Barros, F. 2002. A working prototype of a dynamic geographical information system. International Journal of Geo-graphicInformation Science 16: 69–91.Dutton, G. (ed.). 1978. Harvard Papers on Geographic Information Systems: Proceedingsof the First International Symposium on Topological Data Structures for GeographicInformation Systems. Reading, MA: Addison-Wesley.Egenhofer, M. and Golledge, R. (eds). 1998. Spatial and Temporal Reasoning in GeographicInformation Systems. Oxford: Oxford University Press.Erwig, M., Güting, R., Schneider, M., and Vazirgiannis, M. 1999. Spatio-temporal data types:An approach to modeling and querying moving objects in databases. GeoInformatica3:269–96.ESRI. 2003. ArcGIS 9: Extending the ArcGIS platform. ArcNews Online Fall 2003(availableat http://www.esri.com/news/arcnews/fall03articles/arcgis9.html).Frank, A., Raper, J., and Cheylan, J. (eds). 2001. Life and Motion of Socio-economic Units.London: Taylor and Francis.Frihida, A., Marceau, D., and Thériault, M. 2002. Spatio-temporal object-oriented data modelfor disaggregate travel behavior. Transactions in GIS6: 277–94.Galton, A. 2000. Qualitative Spatial Change. Oxford: Oxford University Press.Gimblett, H. (ed.). 2002. Integrating Geographic Information Systems and Agent-basedModeling Techniques for Simulating Social and Ecological Processes. Oxford: OxfordUniversity Press.Goodchild, M. F. 1990. Geographical data modeling. In A. Frank and M. F. Goodchild (eds) Two Perspectives on Geographical Data Modeling. Santa Barbara, CA: Universityof California National Center for Geographic Information and Analysis Technical Report No. 90–11.Goodchild, M. F., Steyaert, L., Parks, B., Johnston, C., Maidment, D., Crane, M., andGlendenning, S. (eds). 1996. GIS and Environmental Modeling: Progress and ResearchIssues. Fort Collins, CO: GIS World Books.Hägerstrand,",
    "chunk_order_index": 277,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-195186a2bf9b7a903d60dd39a67b253d": {
    "tokens": 1200,
    "content": "eds) Two Perspectives on Geographical Data Modeling. Santa Barbara, CA: Universityof California National Center for Geographic Information and Analysis Technical Report No. 90–11.Goodchild, M. F., Steyaert, L., Parks, B., Johnston, C., Maidment, D., Crane, M., andGlendenning, S. (eds). 1996. GIS and Environmental Modeling: Progress and ResearchIssues. Fort Collins, CO: GIS World Books.Hägerstrand, T. 1967. Innovation Diffusion as a Spatial Process. Chicago: University of ChicagoPress.Hamre, T. 1994. An object-oriented conceptual model for measured and derived data in 3Dspace and time. In T. Waugh and R. Healey (eds) Proceedings of the Sixth InternationalSymposium on Spatial Data Handling: London: Taylor and Francis, pp. 868–81.Hazelton, N. 1991. Integrating Time, Dynamic Modeling and Geographical Information Sys-tems: Development of Four-dimensional GIS. Unpublished PhD Dissertation, Departmentof Geospatial Sciences, RoyalMelbourne Institute of Technology.Hornsby, K. and Egenhofer, M. 2000. Identity-based change: A foundation for spatio-temporal knowledge representation. International Journal of Geographical InformationScience14: 207–24.Hornsby, K. and Egenhofer, M. 2002. Modeling moving objects over multiple granularities.Annals of Mathematics and Artiﬁcial Intelligence36: 177–94.Huisman, O. and Forer, P. 1998. Computational agents and urban life-spaces: A pre-liminary realization of the time geography of student lifestyles. In Proceedings of the ThirdInternationalConference on GeoComputation. Bristol, United Kingdom (available athttp://www.geocomputation.org/1998/68/gc_68a.htm).Itami, R. 1988. Cellular automatons as a framework for dynamic simulations in geographicinformation systems. In Proceedings of GIS/LIS ’88,Phoenix, AZ, USA. Bethesda, MD:American Congress on Surveying and Mapping and American Society for Photogrammetryand Remote Sensing, pp. 590–7.THO_C24  19/03/2007  11:28  Page 443 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f444JOCHEN ALBRECHTJenerette, G. and Wu, J. 2001. Analysis and simulation of land-use change in the centralArizona–Phoenix region, USA. Landscape Ecology16: 611–26.Kelmelis, J. 1991. Time and Space in Geographic Information: Towards a Four-dimensionalSpatio-temporal Data Model. Unpublished PhD Dissertation, Department of Geography,PennsylvaniaState University.Kemp, K. 1997. Fields as a framework for integrating GIS and environmental process models:Part 1, Representing spatial continuity. Transactions in GIS 1: 219–34.Kirby, K. and Pazner, M. 1990. Graphic map algebra. In Proceedings of the Fourth Inter-national Symposium on Spatial Data Handling, Zürich, Switzerland. Columbus, OH:International Geographical Union.Kwan, M.-P. 1998. Space-time and integral measures of individual accessibility: A comparativeanalysis using a point-based network. Geographical Analysis30: 191–216.Langran, G. 1992. Time in Geographic Information Systems. London: Taylor and Francis.MacEachren, A., Wachowicz, M., Edsall, R., and Haug, D. 1999. Constructing knowledgefrom multivariate spatio-temporal data. International Journal of Geographic InformationScience13: 311–34.Maidment, D. 1993. GIS and hydrologic modeling. In M. Goodchild, B. Parks, and L. Steyaert (eds) Environmental Modeling with GIS. New York: Oxford University Press,pp. 147–67.Mennis, J., Peuquet, D., and Qian, L. 2000. A conceptual framework for representing com-plex and dynamic phenomena in geographic information systems. International JournalofGeographical Information Science14: 501–20.Miller, H. 2003. Activities in space and time. In D. Hensher (ed.) Handbook in Transport:5, Transport Geography and Spatial Systems. New York: Pergamon, pp. 647–60.Miller, H. 2005. A measurement theory for time geography. Geographical Analysis37: 17–45.Miller, H. and Shaw, S. 2001. Geographic Information Systems for Transportation: Prin-ciples and Applications. New York: Oxford University Press.Miller, H. and Wentz, E. 2003. Representation and spatial analysis in geographic informa-tion systems. Annals of the Association of American Geographers93: 574–94.Mota, L., Bento, J., and Botelho, L. 2002. Ontology deﬁnition languages for multi-agentsystems: The geographical information ontology case study. In Proceedings of the Work-shopon Ontologies in Agent Systems (OAS ’02), Bologna, Italy. New York: Associationof Computing Machinery.Nijkamp, P. and Reggiani, A. 1998. The Economics of Complex Spatial Systems. Amsterdam:Elsevier.O’Sullivan, D. 2001a.",
    "chunk_order_index": 278,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-664d28d6ff1f90c2fe2f165c614f9272": {
    "tokens": 1200,
    "content": "J., and Botelho, L. 2002. Ontology deﬁnition languages for multi-agentsystems: The geographical information ontology case study. In Proceedings of the Work-shopon Ontologies in Agent Systems (OAS ’02), Bologna, Italy. New York: Associationof Computing Machinery.Nijkamp, P. and Reggiani, A. 1998. The Economics of Complex Spatial Systems. Amsterdam:Elsevier.O’Sullivan, D. 2001a. Exploring spatial process dynamics using irregular graph-based cellularautomaton models. Geographical Analysis33: 1–18.O’Sullivan, D. 2001b. Graph-cellular automata: A generalized discrete urban and regionalmodel. Environment and Planning B28: 687–705.Pang, M. and Shi, W. 2002. Development of a process-based model for dynamic interactionin spatio-temporal GIS. GeoInformatica6: 323–44.Pedrosa, B., Fonseca, F., Câmara, G., Carneiro, T., and Souza, R. 2002. TerraML: A lan-guage to support spatial dynamic modeling. In Proceedings of the Second InternationalConference on Geographic Information Science, Boulder, CO, USA. Santa Barbara, CA:National Center for Geographic Information and Analysis.Pereira, G. 2002. A typology of spatial and temporal scale relations. Geographical Analysis34: 21–33.Peuquet, D. 1992. Toward the Representation and Analysis of Spatiotemporal Processes in Geographic Information Systems. University Park, PA: Pennsylvania State UniversityTechnical Report.THO_C24  19/03/2007  11:28  Page 444 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fDYNAMIC MODELING445Peuquet, D. 1994. It’s about time: A conceptual framework for the representation of temporaldynamics in geographical information systems. Annals of the Association of AmericanGeographers84: 441–61.Peuquet, D. 2001. Making space for time: Issues in space-time data representation. Geo-Informatica 5: 11–32.Peuquet, D. and Duan, N. 1995. An event-based spatiotemporal data model (ESTDM) fortemporal analysis of geographic data. International Journal for Geographic InformationSystems9: 7–24.Peuquet, D. and Guo, D. 2000. Mining spatial data using an interactive rule-based approach.In Proceedings of the First International Conference on Geographic Information Science,Savannah, GA, USA. Santa Barbara, CA: National Center for Geographic Information andAnalysis.Peuquet, D. and Wentz, E. 1994. An approach for time-based analysis of spatio-temporaldata. In Proceedings of the Sixth International Symposium on Spatial Data Handling,Edinburgh, Scotland, pp. 489–504.Pred, A. (ed.). 1981. Space and Time in Geography: Essays Dedicated to Torsten Hägerstrand.Lund, Sweden, Gleerup.Pullar, D. 2001. MapScript: A map algebra programming language incorporating neighborhoodanalysis. GeoInformatica 5: 145–63.Pullar, D. 2003. Simulation modeling applied to runoff modeling using MapScript. Transactionsin GIS 7: 267–84.Raper, J. 2000. Multidimensional Geographic Information Science. London: Taylor and Francis.Raper, J. and Livingstone, D. 1995. Development of a geomorphological spatial model using object-oriented design. International Journal of Geographical Information Systems9: 359–83.Raper, J., Livingstone, D., Bristow, C., and Horn, D. 1999. Developing process responsemodels for spits. In D. Kraus (ed.) Proceedings of Coastal Sediments. Long Island, NY:American Society of Civil Engineers, pp. 1755–69.Reitsma, F. and Albrecht, J. 2005. Implementing a new data model for simulating processes.International Journal of Geographic Information Science 19: 1073–90.Reitsma, F. and Bittner, T. 2003. Scale in object and process ontologies. In W. Kuhn, M. Worboys, and S. Timpf (eds) Spatial Information Theory: Foundations of GeographicInformation Science. Berlin, Springer Lecture Notes in Computer Science No. 2825:13–27.Renolen, A. 2000. Modeling the real world: Conceptual modeling in spatiotemporal informa-tion system design. Transactions in GIS4: 23–42.SCADA. 1991. SCADA: A Special Collection of Past Conference Proceedings on AM/FMSCADA Integration.Englewood, CO: AM/FM International.Semboloni, F. 2000. The growth of an urban cluster into a dynamic self-modifying spatialpattern. Environment and Planning B27: 549–64.Shi, W. and Pang, M. 2000. Development of Voronoi-based cellular automata: An integrateddynamic model for geographical information systems. International Journal of GeographicalInformation Science14: 455–74.Smith, L., Beckman, R., Baggerly, K., Anson, D., and Williams, M. 1993. Overview of TRAN-SIMS.Los Alamos, NM, Los Alamos",
    "chunk_order_index": 279,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-14c2cd4ba9659ebc7b0aea258b45f132": {
    "tokens": 1200,
    "content": "and Planning B27: 549–64.Shi, W. and Pang, M. 2000. Development of Voronoi-based cellular automata: An integrateddynamic model for geographical information systems. International Journal of GeographicalInformation Science14: 455–74.Smith, L., Beckman, R., Baggerly, K., Anson, D., and Williams, M. 1993. Overview of TRAN-SIMS.Los Alamos, NM, Los Alamos National Laboratories.Smith, T., Su, J., El-Abbadi, A., Agrawal, D., Alonso, G., and Amitabah, S. 1995. Computa-tional modeling systems. Information Systems20: 127–53.Stefanakis, E. 2003. Modeling the history of semi-structured geographical entities. Inter-national Journal of Geographic Information Science 17: 517–46.Tomlin, D. 1990. Geographic Information Systems and Cartographic Modeling. EnglewoodCliffs, NJ: Prentice-Hall.THO_C24  19/03/2007  11:28  Page 445 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f446JOCHEN ALBRECHTTomlinson, R. 1973. A Technical Description of the Canada Geographic Information System.Ottawa, Lands Directorate, Environment Canada.Tryfona, N. and Jensen, C. 1999. Conceptual data modeling for spatio-temporal applications.GeoInformatica3: 245–68.US Census Bureau. 1969. The DIME Encoding System. Washington, DC: US Census BureauCensus Study Report No. 4.Villa, F. 2000. Design of multi-paradigm integrating modeling tools for ecological research.Environmental Modeling Software 15: 169–77.Wachowicz, M. 1999. Object-Oriented Design for Temporal GIS. London: Taylor and Francis.Waddell, P. 2002. UrbanSim: Modeling urban development for land use, transportation andenvironmental planning. Journal of the American Planning Association68: 297–314.Waters, N. 2002. Modeling the environment with GIS: A historical perspective. In K. Clarke,B. Parks, and M. Crane (eds) Geographic Information Systems and Environmental Modeling.Upper Saddle River, NJ: Prentice-Hall, pp. 1–35.Wesseling, C. G., Karssenberg, D., Burrough, P. A., and van Deursen, W. P. A. 1996. Integratingdynamic environmental models in GIS: The development of a dynamic modeling language.Transactions in GIS 1: 40–8.Westervelt, J. and Hopkins, L. 1999. Modeling mobile individuals in dynamic landscapes.International Journal for Geographical Information Science13: 191–208.Wickens, C., Mavor, A., Purusurum, R., and McGee, B. 1998. The Future of Trafﬁc Control.Washington, DC: National Academy of Sciences.Worboys, M. 2001. Modeling changes and events in dynamic spatial systems with referenceto socio-economic units. In A. Frank, J. Raper, and J. Cheylan (eds) Life and Motion ofSocio-Economic Units. London: Taylor and Francis, pp. 129–37.Wu, F. 1998. SimLand: A prototype to simulate land conversion through the integrated GIS and CA with AHP derived transition rules. International Journal of GeographicalInformationScience12: 63–82.W3C. 2005. Semantic Web Rule Language First Order Logic Submission to W3C. WWWdocument, http://www.w3.org/Submission/2005/SUBM-SWRL-FOL-20050411/.Yuan, M. 1996. Temporal GIS and spatio-temporal modeling. In NCGIA (eds) Proceedingsof the Third International Conference on Integrating GIS and Environmental Modeling,Santa Barbara, CA: University of California, National Center for Geographic Informationand Analysis: CD-ROM.Yuan, M. 1999. Use of three-domain representation to enhance GIS support for complexspatio-temporal queries. Transactions in GIS3: 137–59.Yuan, M. 2001. Representing complex geographic phenomena in GIS. Cartography andGeographic Information Science 28: 83–96.Yuan, M. and Lin, H. 1992. Spatio-temporal modeling of wildﬁre in geographic informa-tion systems. In Proceedings of the Symposium of Chinese Professionals in GeographicInformationSystems, pp. 194–200.Zhang, W. and Hunter, G. 2000. Temporal interpolation of spatially dynamic objects.GeoInformatica 4: 403–18.Zlatanova, S., Holweg, D., and Coors, V. 2003. Geometrical and topological model for real-time GIS. In Proceedings of the Next Generation Geospatial Information Conference,Cambridge, MA (available at http://dipa.spatial.maine.edu/NG2I03/CD_Contents/EA/latanovaa_Siyka_01.pdf).THO_C24  19/03/2007  11:28  Page 446 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley",
    "chunk_order_index": 280,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9cda3ad8261fb446beef21a55cddaf36": {
    "tokens": 1200,
    "content": "topological model for real-time GIS. In Proceedings of the Next Generation Geospatial Information Conference,Cambridge, MA (available at http://dipa.spatial.maine.edu/NG2I03/CD_Contents/EA/latanovaa_Siyka_01.pdf).THO_C24  19/03/2007  11:28  Page 446 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPart VIGeographic InformationSystems and SocietyThe next set of six chapters examines a series of broader issues that inﬂuence the development, conduct, and impacts of geographic information technologies. Theﬁrst of these chapters (Chapter 25 by David L. Tulloch) examines institutional GIS and GI partnering. This chapter starts out with a description of institutional GIS,building a working model of the processes at hand and describing recent researchon monitoring the status of institutional GIS, including the models, barriers, andbeneﬁts that characterize GIS implementation, and the incorporation of GIS intodecision-making and public participation. The chapter then examines GI partneringin some detail – discussing the role of consortia, collaboration, and cooperation(the 3 Cs) and the character and importance of national and global spatial datainfrastructures. The chapter concludes with a brief discussion of future trends anddirections.In Chapter 26, the next chapter in this group, Daniel Weiner and Trevor M. Harrisexamine public participation GIS (PPGIS). It shows how the GIS and Society debatesconcerning the diffusion of geographic technologies shaped early participatory GISprojects and explores how the term has evolved through several variant forms thatreﬂect important developments. The various examples introduced in this chapterexplore PPGIS methods, the nature of participation in PPGIS, and the regional anddomain areas in which these systems have been developed – taken as a whole, theseexamples show how the focus has remained centered on systems and projects thatlink communities with GIS and related geospatial technologies.Chapter 27, the third chapter in this group, by Piotr Jankowski and Timothy L.Nyerges, examines GIS and participatory decision-making. The chapter commenceswith a review of empirical research on collaborative and group decision-making –exploring group support systems, spatial decision support systems, and frameworksfor using information technologies to support participatory decision-making – andthen takes the best of the concepts and ideas to specify methods for GIS-supportedparticipatory decision-making. The chapter concludes with a plea for systematic evaluation of these technologies to ensure that they efﬁciently, effectively, and equit-ably support both large and small groups of decision makers.THO_C25  19/03/2007  11:28  Page 447 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f448GEOGRAPHIC INFORMATION SYSTEMS AND SOCIETYThe fourth chapter of the group (Chapter 28 by Peter H. Dana) uses examplesfrom several participatory mapping projects in Central America to illustrate thedynamic interplay between conceptions of people and place and the methods usedto survey them. Dana reviews many different mapping methods (including GPS technologies in some detail) and explains why surveys of people and place are apart of a process through which ideas of ethnicity and landscape are formulated,explored, altered, and articulated. The examples used throughout this chapter showwhy the mapping of people and place is a complex process involving numerousmethodological choices that may impact the ways in which territory is perceivedas well as the ways in which territory is eventually portrayed and/or used as thebasis for spatial analysis.George C. H. Cho examines the relationship between GIS, personal privacy, andthe law across a variety of jurisdictions in the next chapter in the group, Chapter 29.This chapter is divided into three major parts. The ﬁrst examines the philosoph-ical and doctrinal issues that deﬁne the structure and character of the problem ofprivacy and geographic information technologies. The legal, regulatory, and policyframework that underlies the source of this interest is evaluated in the context of considering privacy as a “right” in the middle part. The European Union DataDirective is used as a case study and the “Safe Harbor” framework is describedtogether with a series of alternatives adopted in other countries to respond to thisdata directive here. The ﬁnal section of this chapter reviews some of the differentgeographic information technologies that promote intrusiveness, enhance privacyprotection, and are sympathetic to privacy protection.The ﬁnal chapter in this set is Chapter 30 by Joseph J. Kerski, which examinesthe history and character of GIS in education, including the major developmentsand organizations involved and the opportunities for educating oneself in GIS. GISin education is conceptualized in four distinct ways – professional development,research about GIS, teaching about GIS, and teaching and learning with GIS – and the history, goals, and needs in each of these diverse settings are described.Kerski concludes this chapter by noting that the diversity of the ﬁeld of GeographicInformation Science (GISc) is reﬂected in the diversity of educational issues, andwhy the steadily increasing need for educated practitioners will continue to drivethe development of new educational opportunities worldwide.THO_C25  19/03/2007  11:28  Page 448 Downloaded from https://",
    "chunk_order_index": 281,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-eaa5d32a8bd0db31ca9f4926a4efa30c": {
    "tokens": 1200,
    "content": "with GIS – and the history, goals, and needs in each of these diverse settings are described.Kerski concludes this chapter by noting that the diversity of the ﬁeld of GeographicInformation Science (GISc) is reﬂected in the diversity of educational issues, andwhy the steadily increasing need for educated practitioners will continue to drivethe development of new educational opportunities worldwide.THO_C25  19/03/2007  11:28  Page 448 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 25Institutional Geographic Information Systems and Geographic Information PartneringDavid L. TullochInstitutional Geographic Information Systems (GIS) has gained recognition as a critical element in the ongoing global establishment and expansion of GeographicInformation (GI) practices, particularly in the public sector. When GIS ﬁrst emergedthey were often used for short-term applications. The adoption of this innovativetechnology by agencies for use in addressing their day-to-day needs brought newproblems ranging from funding to data maintenance to access to interoperability.Quickly, system developers found themselves less involved in developing new codeand more involved in establishing relationships, rules, standards, and budgets. Theresult is something often described as institutional GIS.While institutional GIS includes some of the more traditional Geographic Infor-mation Science (GISc) research regarding status and implementation, it goes muchfurther. Institutionalized GIS is necessary to provide sufﬁcient support for manypublic resource decisions (planning, public works, etc.) with the incorporation of public participation into many of those decisions. Similarly, institutional GIS drivesmuch of the spatial data infrastructure research, increasingly referred to as GI part-nering. Institutional GIS research also includes the investigation of the beneﬁts andcosts of system implementation. Underlying much of this work is an understandingthat relationships or partnerships are the glue that makes institutional GIS func-tion. Understanding these GI partnerships can help us with many of the remainingquestions about institutional GIS.As organizations have undertaken the process of implementing GIS, two majorcategories of GIS activities have emerged shaping community systems development.Institutional GIS and GI partnering are two closely related concepts that reﬂect theevolving ways in which systems are implemented and GIS is applied by organiza-tions with long-term interests. Institutional GIS refers to permanent organizationaland technological structures that have evolved to provide and support GI overextended periods of time. Within the larger conception of institutional GIS is GIpartnering which generally refers to the active relationships that individuals andinstitutions formed for cooperation on projects and data exchange, but it places aTHO_C25  19/03/2007  11:28  Page 449 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f450DAVID L. TULLOCHgreat emphasis on the complex spatial data infrastructures (SDIs) that rely heavilyon partnering. Both represent ways GIS is incorporated into the working structureof countless institutions, impacting the uses and understandings of the technologyin some of its most common and accessible forms.Like other emerging topics in GIS, institutional GIS and GI partnering have bothsurfaced supported by a signiﬁcant amount of relevant existing research but verylittle deﬁning scholarship. This chapter endeavors to present these topics as they aregenerally treated presently in the literature and describe the directions in which eachis advancing. However, these concepts have often been used and treated somewhatinconsistently (particularly institutional GIS) and multiple interpretations should beexpected for the time being. The professional nature of many of the related problemsmakes this a difﬁcult area to track; much of the derived information does not comethrough traditional research, and much of the information is shared through variousforms of “grey literature.” This chapter is broken into two distinct sections – ﬁrstinstitutional GIS and then GI partnering – with unavoidable overlap between the two.The institutional GIS section establishes a working understanding of the processes athand and describes three major areas of related research. The GI partnering sectionprovides an overview of two major categories of GI partnering activities. Finally, adiscussion is provided exploring implications and directions for this rich research area.Institutional GISPermanence was not always a common attribute or goal of GIS developers; instead,many of the early examples were project-oriented systems designed and implementedto serve on a short-term basis. Many GIS histories (Sinton 1991; Steinitz 1993a,b, c; Foresman 1997) describe individual projects as exemplars of foundational workin the ﬁeld. These early projects often assembled data and used it for the durationof a single project, sometimes lasting only a semester or a year. While the data mayhave been preserved for future parallel projects, practical limitations like funding oftenforced the data sets to remain static, not reﬂecting the constantly changing land-scape that they purported to represent. Certainly, there was little expectation thatnew projects could beneﬁt signiﬁcantly from pre-existing data produced elsewhere.Without a reliance on external data, partnering and data sharing relationships werenot common attributes of systems.In pace with the technological changes in GIS, changes occurred in the integrationof GIS data as a central element in the processes of government. Organizations beganto update their digital data as regularly as their analog records. The institutional-ization of these systems came with the",
    "chunk_order_index": 282,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-99bd3bb3941a6b229ec45af3311ae59b": {
    "tokens": 1200,
    "content": "that they purported to represent. Certainly, there was little expectation thatnew projects could beneﬁt signiﬁcantly from pre-existing data produced elsewhere.Without a reliance on external data, partnering and data sharing relationships werenot common attributes of systems.In pace with the technological changes in GIS, changes occurred in the integrationof GIS data as a central element in the processes of government. Organizations beganto update their digital data as regularly as their analog records. The institutional-ization of these systems came with the development of appropriate arrangementsto support and maintain the systems including: sustained funding, appropriate stafﬁng,development of rules and practices for the operation of the systems and the treat-ment of data, the incorporation of the system into a larger organizational context,and the development of relationships for data sharing, coordination, and partnering.This change in perspective is reﬂected in the consensus derived deﬁnition of GISthat emerged in 1989, describing it as “a system of hardware, software, data, people,organizations, and institutional arrangements for collecting, storing, analyzing, anddisseminating information about areas of the Earth” (Dueker and Kjerne 1989, THO_C25  19/03/2007  11:28  Page 450 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINSTITUTIONAL GIS AND GI PARTNERING451pp. 7–8). This broad deﬁnition clearly reﬂects the sort of long-term perspective commonly associated with institutionalized systems.Institutionalizing GIS requires signiﬁcant commitment. Institutional GIS needs sus-tained, reliable funding to ensure that system maintenance is sufﬁcient and to preventthe system from being co-opted by one-shot project funding. The institutionaliza-tion of GIS requires leadership that recognizes the future value of the system aswell as the current costs. Sometimes institutionalizing GIS requires organizationalrestructuring and occasionally institutionalization requires a signiﬁcant change inthe very culture of an institution. For example, an agency that has grown comfort-able with obscure land use decisions made without public input may ﬁnd that atransparent and publicly accessible database makes these decisions much harder.Institutional GIS can be described and perceived according to a variety of per-spectives. Campbell and Masser (1992) present three distinct perspectives of implementation (and ultimately institutionalization): technological determinism,managerial rationalism, and social interactionism. The importance of understandingdiffering perspectives has been driven home in the intersecting (or colliding) dialogsof the early GIS and Society literature (for example, Dobson 1983, 1993, Taylor andOverton 1991, Openshaw 1991, Smith 1992, Sheppard 1995, Pickles 1995, Curry1998). This is one area where the multi-disciplinary nature of GIS can be problem-atic as it promotes miscommunication and misunderstandings. The human elementand the roles it can play including concerns about power structures, discomfort withuncertainty, and broad cultural biases make far-reaching GI applications complex(de Man 2003; see Chapter 28 by Dana in this volume for additional discussionof this topic).Only recently have there been some clear efforts to deﬁne and contextualize institutional GIS as an explicit developing sub-ﬁeld within GIS (Campbell 1999, deMan 2003). Since institutional GIS is only recently coming into its own, a theoret-ical framework for understanding institutional GIS must be assembled relying onresearch from a variety of related areas. The GIS literature includes several areasfrom which this research area draws:•Monitoring status and modeling implementation;•Barriers and beneﬁts; and•Decision making and public participation.Each of these is described in the following sections. Additionally, important theoretical foundations come from other disciplines. Much of the literature relat-ing to institutional GIS is founded on understandings of economics and institutions(North 1990), organizations and organizational change (Handy 1993), and the rolesof computers, technology, and innovations in changing institutions and organiza-tions (Zaltman, Duncan, and Holbek 1973, Keen 1981, Eason 1988, Morton 1991)from outside the traditional GI literature.Monitoring status and modeling implementationA signiﬁcant area of early research about the development of institutional GIS wasmonitoring the adoption and diffusion of the technology. Since many researchersTHO_C25  19/03/2007  11:28  Page 451 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f452DAVID L. TULLOCHquickly recognized that GIS adoption comes in many ﬂavors (for example, bothwithin an agency and among different agencies), the research sometimes evolved intoa process of monitoring the status of system development. Much of the interest inthis area focused on larger, public systems making these investigations ultimatelypart of an ongoing study of the institutionalization of GIS.A number of the early efforts at monitoring system status came as part of agencyefforts to identify potential or future data sources within their jurisdiction. In the US, many states used surveys of local governments as a means of identifyingpotential partners or participants in statewide GI initiatives (for example, ArizonaGeographic Information",
    "chunk_order_index": 283,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-37c1986e6419b9a2a6a0a57bd684a263": {
    "tokens": 1200,
    "content": "a process of monitoring the status of system development. Much of the interest inthis area focused on larger, public systems making these investigations ultimatelypart of an ongoing study of the institutionalization of GIS.A number of the early efforts at monitoring system status came as part of agencyefforts to identify potential or future data sources within their jurisdiction. In the US, many states used surveys of local governments as a means of identifyingpotential partners or participants in statewide GI initiatives (for example, ArizonaGeographic Information Council 1992, Sandberg 1992, Wisconsin Land Informa-tion Board 1995, Renner and Waldon 1995, Minnesota Governor’s Council on Geographic Information 1994, New Jersey State Mapping Advisory Committee 1997). Some states, like Wisconsin, have assessed status longitudinally and fairlyconsistently in ways that become quite informative in regards to the overall devel-opment patterns of institutional GIS (Hart, Koch, Moyer, and Niemann 2001). These monitoring surveys continue for purposes of governmental accountability, but havethe additional consequence of monitoring the slow and subtle changes that occuras these systems evolve from project-oriented to permanent, institutional systems.Similar, although generally more rigorous or consistent work has been conductedat regional and national levels. British local governments were surveyed by Campbelland Masser (1995) showing that GIS had been widely adopted while raising ques-tions about the ways it was being used. In the US surveys included military bases(Cullis 1995), planning agencies (Budic 1994), and local governments (Budic 1993,Tulloch and Niemann 1996, Tulloch, Niemann, Ventura, and Epstein 1996). Inwhat might have been the largest such survey, the US Federal Geographic DataCommittee (FGDC) and the National States Geographic Information Consortium(NSGIC) collaborated in the late 1990s to distribute over 15,000 questionnaires of potential data producers (Tulloch and Robinson 2000). Of the 5,200 surveysreturned, over half indicated they were producing geospatial data that might contri-bute to the US National Spatial Data (NSDI) – 836 of these were county governments(Tulloch and Fuld 2001). More recently, similar efforts have expanded to catalog,examine, and compare multiple nations. In a European Science Foundation (ESF)funded effort, Masser, Campbell, and Craglia (1996) compiled a series of assessmentsof the status of local government GIS within a number of European countries. Mostrecently, a variety of efforts have loosely followed this tradition in developing information for SDI – and particularly Global Spatial Data Infrastructure (GSDI)– assessments.These survey efforts led to the development of theoretical models and descriptionsof the ways in which these systems evolve. While unique to GIS, this research oftenbuilt on the larger tradition of research on the adoption and diffusion of innovations.At the center of this tradition is the work of Everett Rogers (summarized well inRogers 1995) whose achievements in the ﬁeld include the widely used s-shaped adoption curve (see an example of its use in Goodchild 1997). While Rogers’ writ-ing was mostly meant as an overarching evaluation of all types of innovations, hedid contribute to the GIS literature (Rogers 1993). The theoretical models of GISadoption and development reﬂect greatly on this early innovation and technologyresearch, a form of GIS institutionalization (Masser and Onsrud 1993).THO_C25  19/03/2007  11:28  Page 452 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINSTITUTIONAL GIS AND GI PARTNERING453While not often explicitly stated, the GIS adoption and development models oftendescribe the institutionalization of GIS in public agencies. While this adoption anddiffusion literature has ranged from conceptual frameworks (for example, Anderson1996, Nedovic-Budic and Pinto 1999) to theoretical models (for example, Crainand MacDonald 1984, Ezigbalike, Coleman, Cooper, and McLaughlin 1988, Azad and Wiggins 1995, Tulloch 1999, Chan and Williamson 1999), it has devel-oped an important basis for describing the ways that GIS has moved from beingdiscussed as a temporary, project-based technology plagued by instability to a com-plex, permanent, enterprise-wide, institution. The author has previously publisheda six-stage theoretical model of multi-purpose land information systems (MPLIS)development (Tulloch 1999) which culminates in a ﬁnal stage of democratization.The MPLIS development process (Figure 25.1) is described with a speciﬁc under-standing that public (or community-based) systems are often not fully establisheduntil they are utilized by a user community that extends far beyond the internalgroup of GIS users contributing to the system’s development. This carries the under-standing of system development far past implementation and allows an examina-tion of what happens after GIS is inside the institution.Monitoring research could be typiﬁed by traditional surveys of GIS institutionsseeking to measure the nature and extent of GIS implementation and partnerships.This research could include improved monitoring of clearinghouses and data hold-ings as a means of creating comprehensive assessments of data availability. Certainly,this should be conducted in ways that contribute to a longitudinal understandingof a GIS program. A key step is the establishment of the best possible baseline dataabout as many systems",
    "chunk_order_index": 284,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-051bfbd933a80e67cc40f40afd164b04": {
    "tokens": 1200,
    "content": "ina-tion of what happens after GIS is inside the institution.Monitoring research could be typiﬁed by traditional surveys of GIS institutionsseeking to measure the nature and extent of GIS implementation and partnerships.This research could include improved monitoring of clearinghouses and data hold-ings as a means of creating comprehensive assessments of data availability. Certainly,this should be conducted in ways that contribute to a longitudinal understandingof a GIS program. A key step is the establishment of the best possible baseline dataabout as many systems as possible.Fig. 25.1A conceptual diagram of multipurpose land information system development. The diagram illustrates six primary stages and the associated outcomes – efﬁciency, effectiveness, and equityFrom Tulloch 1999TIMEEfficiencyEffectivenessEquityOUTCOMESForces of change*THO_C25  19/03/2007  11:28  Page 453 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f454DAVID L. TULLOCHBarriers and beneﬁtsAs part of the exploration of adoption and diffusion research, researchers have examined the factors that either facilitate or limit GIS implementation. An improvedunderstanding of the reasons for system development and investment would be verybeneﬁcial to the broader GIS-user community. This has been an area negativelyimpacted by the struggle to keep GIS from being treated as simply an appendageof IT work and research. Within GIS this vein of research has already emerged asa strong area of study but it remains an understudied area in need of continuedattention.Early research exploring both the barriers and beneﬁts of institutionalizing GISemerged from anecdotal reports of GIS successes and failures (for instance, Huxhold1982, Croswell 1989, 1991, Coffeen 1994). While technical barriers received a greatdeal of attention (as described in Obermeyer and Pinto 1994), organizational andinstitutional issues were clearly identiﬁed as playing a key role in the process (Budic1994, Ventura 1995, Cullis 1995). With an emphasis on measuring the impact of dis-tinct barriers, Onsrud and Pinto (1993) undertook a thorough survey of GIS users.The results demonstrated the importance of overcoming a series of non-technicalbarriers in order for a system to become established. While this area of researchhas not fully captured the change, the gradual reduction in cost of technology and increase of IT support within most public agencies has changed the nature and extent to which cost and technical issues serve as barriers to implementation andinstitutionalization.With similar roots in the professional literature, descriptions of the beneﬁts ofsystem development have played an important role in the contemporary understand-ing of successful system development. Ranging from early conjecture (Cook andKennedy 1966) to case studies (Onsrud, Pinto, and Azad 1992, 1993, Gillespie 1994,Craig and Johnson 1997) to spreadsheet accounting (Antenucci, Brown, Croswell,Kevany, and Archer 1991), extensive work has been invested in accounting for the beneﬁcial outcomes of GIS and its institutionalization. Traditional economicsserve as a useful basis for measuring outcomes (Larsen, Clapp, Miller, Niemann,and Ziegler 1978, Wunderlich and Moyer 1984, Moyer 1993, Gillespie 1994), how-ever many ﬁnd this to be either daunting or inappropriate for their needs. Theseeconomic studies have often placed a premium on measuring efﬁciency and/or effectiveness. A broad perspective was brought to the topic by the National Centerfor Geographic Information and Analysis (NCGIA) Initiative 4 studying the Useand Value of Geographic Information (Onsrud, Calkins, and Obermeyer 1989). Moresocially-oriented research has incorporated concerns about beneﬁts (and associatedcosts) of systems that are passed along to the communities they are intended to serve(Chrisman 1987, Kishor, Niemann, Moyer, et al. 1990, Cowen 1994, Sheppard1995, Epstein and Marble 2002). These system beneﬁts have been summarized byTulloch and Epstein (2002) in three broad categories: efﬁciency, effectiveness, andequity/empowerment/engagement. Efﬁciency is related to improvements on tradi-tional recordkeeping, usually internal within the ofﬁce in which the automation has occurred. Effectiveness describes potential beneﬁts from improved analysis and related techniques, often with the larger agency within which the GIS has beeninstitutionalized. Equity, empowerment, and engagement describe the ways that THO_C25  19/03/2007  11:28  Page 454 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINSTITUTIONAL GIS AND GI PARTNERING455members of the larger community can beneﬁt (sometimes unknowingly) from theuse and applications of an institutionalized system. These system beneﬁts (referredto colloquially as the 3 Es) represent an important element in institutional GIS becausethey create the support needed to preserve and",
    "chunk_order_index": 285,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b0965efc56f95cfa026854db39432506": {
    "tokens": 1200,
    "content": "iley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINSTITUTIONAL GIS AND GI PARTNERING455members of the larger community can beneﬁt (sometimes unknowingly) from theuse and applications of an institutionalized system. These system beneﬁts (referredto colloquially as the 3 Es) represent an important element in institutional GIS becausethey create the support needed to preserve and maintain permanent and accessiblepublic systems.Decision making and public participationMuch of the signiﬁcance of GIS in institutions involves its incorporation into formaldecision-making processes. For public institutions this often includes public participa-tion in determining the outcome of spatially-based policies and individual decisions.In the USA, a variety of federal and state laws mandate the incorporation of publicparticipation into proposed government plans, decisions and actions before ﬁnaldecisions are made. The incorporation of the technology into existing decision processes has required developments in areas such as multiple criteria decision mak-ing which are slowly become institutionalized like the systems used to apply them.Since other chapters of this book include signiﬁcant information on both decisionmaking (DM) (see Chapter 27 by Jankowski and Nyerges ) and public participa-tion GIS (PPGIS) (see Chapter 26 by Weiner and Harris) they will only be discussedbrieﬂy here.Institutionally, DM becomes critical because many larger systems are developedwith a direct interest in supporting policy and decision making. An insufﬁcient effort in the development of the supporting system can render the resulting deci-sions and policy weakened or indefensible. An ongoing and repetitive DM process(like wetlands permitting or long-term management of a timber property) requiresdata to be accessible, consistent, reliable, and appropriate to the legally requiredstandards for the permit or process. For frequently changing data, this creates ademand for a systematic institutionalization providing a rigorous system of rulesand procedures as well as assurances regarding data quality. As major institutions andagencies move towards incorporating GIS data directly into decisions or policy processes, it will become increasingly important for a measure of data quality tobe a part of an institutionalized GIS. While DM and PPGIS may seem like entirelydistinct topics, Jankowski and Nyerges (2001, 2003) have done an elegant job ofdemonstrating their intersection.Technological advances have played a signiﬁcant role in altering access to spatialdata as GIS has moved from mainframes and magnetic tape to networked PCs andinternet map services. Increased access to GIS, especially through Internet mappingand downloadable data, have created a burgeoning sub-ﬁeld of PPGIS (a strong set of examples are presented clearly in Craig, Harris, and Weiner 2002). Whileaccess and participation are distinct characteristics (Tulloch and Shapiro 2003) theyare both embedded with institutional issues (de Man 2003) with some of the moredramatic PPGIS examples relying partially on an existing institutionalized system.This represents a larger trend within institutional GIS with movement from an enterprise-wide model to a larger societal model. As institutional GIS develops, formal and informal policies develop addressing format, access, and dissemination,all impacting the ability of groups to participate in policy processes or view thepublic processes with appropriate transparency.THO_C25  19/03/2007  11:28  Page 455 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f456DAVID L. TULLOCHGI PartneringWithin the larger area of institutional GIS, a signiﬁcant amount of attention hascome to be focused on GI partnering activities. Needs for cooperative efforts emerge as local and regional governments collect or develop spatial data about theirjurisdictions. As communities across an entire nation cooperate and as countriesaround the world work together, large spatial data infrastructures (SDIs) are beingconstructed to facilitate broad access to these many data sources. The tantalizingpossibility of seamless access to the enormous volume of locally-produced spatialdata from around the world is nearly irresistible. A parallel effort to develop a GSDIhas also become a dominant element in discussions of SDI issues. Whether localor global, GI partnering can be both rewarding and challenging with technical and institutional problems. Particularly notable is the recent dramatic emergencein the USA of national and homeland security issues in preventing access to or inthe dissemination of signiﬁcant public data sources.GI partnering often requires a dramatic degree of cooperation between organiza-tions and individuals. The sharing of spatial data is a cornerstone of these relation-ships (Onsrud and Rushton 1995). Cooperative and collaborative relationships canbe very difﬁcult and unpredictable as they introduce a variety of human factors intoa seemingly technical process, including cultural conﬂicts (Hofstede 2001) and inter-personal issues like trust (Harvey 2003). The technical difﬁculties and political barriers expose these high visibility long-term processes to a great deal of criticism(for example, Hissong 2002) and reﬂective review (Tosta 1999, Lachman, Wong,Knopman, and Gavin 2002) often asking whether such an SDI can ever be builtfor a nation as large and complex as the United States.The 3 Cs of regional and state partnering: consortia, collaboration,and cooperationMuch of the early history of GIS is interwoven with stories of local governmentsystem development. Some of the early examples reﬂect the need to coordinate and cooperate internally in order",
    "chunk_order_index": 286,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-44bb114bcfcd24cd4644150025d44d9e": {
    "tokens": 1200,
    "content": "�ective review (Tosta 1999, Lachman, Wong,Knopman, and Gavin 2002) often asking whether such an SDI can ever be builtfor a nation as large and complex as the United States.The 3 Cs of regional and state partnering: consortia, collaboration,and cooperationMuch of the early history of GIS is interwoven with stories of local governmentsystem development. Some of the early examples reﬂect the need to coordinate and cooperate internally in order for municipal or county agencies to satisfy their mandates. One broad set of examples of these efforts are those represented in the MPLIS literature. Research in MPLIS (and previously multi-purpose cadastres)looked at the sharing of land information between departments in a single organ-ization and the resulting institutional complications ranging from data standardsto database structures to power struggles to professional cultural conﬂicts (NationalResearch Council 1980, 1983, Niemann and Moyer 1988). Many of the lessonslearned from these internal organizational efforts are often applicable for largerregional, national, and global efforts.Regional (sub-national) consortia and collaborative efforts are providing an import-ant test bed for clearinghouses and other cooperative efforts. One interesting typeof collaboration that has become somewhat common is voluntary consortia of communities who bind themselves together for collaboration in the acquisition, development, and dissemination of GI. While often initiated as a means for creat-ing a sufﬁcient mass to acquire a bulk of data or imagery as a reasonable price,THO_C25  19/03/2007  11:28  Page 456 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINSTITUTIONAL GIS AND GI PARTNERING457the result can be a small region united under common data standards and lastingformal and informal relationships between communities and agencies. The emergenceof regional planning agencies, although often resisted by local governments, hascreated unusual opportunities for data sharing. Examples like Portland’s Metro(Bosworth, Donovan, and Couey 2002) and San Diego’s SanGIS (Regional UrbanInformation System 1997) demonstrate how cooperation and collaboration can leadto powerful regional GIS institutions.In the USA, states have also become important loci for GI partnering efforts. Whilesome examples of this continue to be coordination programs meant to satisfy theneeds of a single agency, more often these programs signify a major shift towardscollective efforts satisfying many goals. In some cases, like Wisconsin, the state legislature has actively worked to create a state-wide data infrastructure supportedby the state but acted out primarily at the local level (Kuhlman and Niemann 1993).Other states have instead created an agency tasked with encouraging and facilitatingcooperative efforts at the local level, but lack the political power or resources toaddress the situation comprehensively. Technical reports and professional literaturehave captured much of this activity (see the earlier section on status monitoring)and the development of a theoretical base for describing collaboration, consortia, andcooperation at local and state levels has begun (for example, Harvey 2001), but muchremains to be done.National and global spatial data infrastructuresWith enormous amounts of data being produced and an understanding that locally-produced data is usually better than nationally-produced data, many members ofthe GIS community have pursued national and global SDIs aggressively. With thepromise of access to seamless, timely data from countless local sources, NSDI andGSDI hold immeasurable promise, but may ultimately require more action than isreasonable to expect from the agencies involved. Nancy Tosta, formerly responsiblefor the US NSDI efforts, writes about the many issues that prevented more “action”from contributing to the development of the NSDI with human nature being a keyobstacle (Tosta 1999).Nationwide strategies to coordinate data and standardize production while con-tinuing to allow local control of the processes and data are no longer uncommon.Masser (1998) details and compares a variety of national approaches with varyingmixtures of top-down and bottom-up control. While some of the early signiﬁcantinterest in SDIs came from the USA with an interest in its NSDI (National ResearchCouncil 1993, 2001), prominent projects outside the USA are now advancing underthe umbrella of GSDI projects. Elements of the US model (FGDC 1995, 1997) stillseem to dominate with a popular interest in voluntary participation and selectinga set of common framework layers both serving as recurring themes. There certainlyhas been some clear leadership and cooperation for GSDI efforts from both theUSA (particularly through the FGDC) and European nations (through mechanismslike EUROGI and INSPIRE) (Craglia and Masser 2003).The basic visions for the US NSDI and the GSDI have come from a fairly simpleexpectation that if all of the freely available data were made available in a looselycoordinated mechanism then the results would be much more useful for many usersTHO_C25  19/03/2007  11:28  Page 457 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f458DAVID L. TULLOCHthan any one national or global data set. The early visions (like that of the National",
    "chunk_order_index": 287,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6cbbc5676482c4b8ca854d2a5cdadb53": {
    "tokens": 1200,
    "content": "ed from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f458DAVID L. TULLOCHthan any one national or global data set. The early visions (like that of the NationalResearch Council 1993) were optimistic, but with the 1994 establishment of a USFederal Geographic Data Committee tasked to create a NSDI, analyses began torecognize the dramatic nature of the institutional barriers that exist (NAPA 1998).While sometimes these grand and complex visions have drifted into something morepragmatic like a single “national map” (US Geological Survey 2001, National ResearchCouncil 2003) or “digital earth” (NASA Digital Earth Ofﬁce 2000), SDIs shouldtruly serve as an infrastructure constructed to provide access to many different(although sometimes conﬂicting) dynamic data sources.An important development has been the formal creation of an organization callingitself GSDI, with the stated goal of supporting “all societal needs for access to anduse of spatial data” (GSDI 2004, p. 1). It has become quite difﬁcult to track the manyindividual and multi-national efforts that contribute to this growing movement accur-ately, but there is documentation of over 50 countries with national spatial dataclearinghouses (Crompvoets and Bregt 2003). Despite the common understandingof SDIs as being, in part, a digital network serving up data, it is conceivable thatthe GSDI could be considered quite successful if it simply continues to serve as an informal network of spatial data-producing nations and organizations who meetregularly, exchange ideas, make connections, and produce materials to gently guidealong global spatial data development and access (for instance, Nebert 2001).A few key themes emerge from among these many efforts to create GIS institutionsto facilitate access to spatial data. Data standards are frequently a focus of SDI discussions because of their importance for the technical exchange and integrationof the many data sets comprising or passing through the SDI. Clearly a greater awareness of infrastructure issues and mechanisms will be necessary for further con-tinuing advances in this area. Questions linger about educating producers and ownersof spatial data about the beneﬁts they will receive and incentives that can be usedto encourage participation. Finally, simple as it may seem, improved communica-tion practices (including GIS-speciﬁc forms of communication like GI metadata) arefrequently noted as a crucial element that is often overlooked in developing andmaintaining the relationships that underlie SDI networks.DiscussionInstitutional issues and characteristicsWhile institutional GIS appears as a relatively new idea, both the idea and notableexamples have existed for long enough to begin identifying important patterns. After all, there do exist some notable historic exceptions to the project-based bias of early systems. For example, much of the early history of the Canadian GeographicInformation System (CGIS) in the 1960s seems clearly designed to emphasize a long-term system addressing long-term issues (Tomlinson 1997, Niemann and Niemann1999). In fact, the CGIS was institutionalized with an explicit interest in providinga stable base for an ongoing series of public decisions.Examples of institutional GIS are often shaped by some of the same structuralfactors that affect many types of institutions. Institutions can be viewed as beingTHO_C25  19/03/2007  11:28  Page 458 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINSTITUTIONAL GIS AND GI PARTNERING459shaped by their power structure and the manner in which it empowers or limitsthe individuals within the institution. Similarly, institutions require an appropriatepolicy or rules structure – formal or informal – that ﬁts the goals and culture withinand around the system. These rules and power structures often shape many of theother important structural factors cited when describing these systems including issuesof management, communication, access, and standards.Of the previously described structural issues, access has emerged as a notable issueof great interest throughout the GIS community. Access directly impacts the poten-tially irresolvable debate over privacy. As an issue, privacy (see Chapter 29 by Choin this volume) has the ability to illustrate the ways that a community’s expectationscan dominate over long-standing practices within an institution. Decisions about theaccess structures and policies will determine participation and ultimately shape the public support for a system and its applications.Communication serves as another signiﬁcant structural element within institutionalGIS. Rogers’ adoption and diffusion work stressed the importance of communica-tion in the wide adoption of an innovation. But communication remains critical ina complex network of data users, producers, and maintainers. Since so many of thesenetworks rely on relationships with a human element, communication is central toprotecting and preserving these connections. Communications can work in both a personal and a technical way, as is often proved by the widely varying forms ofmetadata that different ofﬁces use.Finally, institutional GIS may rely on an appreciation of the fact that it is, indeed,institutional. For spatial data infrastructures to succeed, they rely on an ongoingeffort from local data producers across a wide (perhaps global) scale. Moreover, theselocal data producers need to recognize that while they may focus on",
    "chunk_order_index": 288,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-aef995d8dba23af49d416703497bc5c2": {
    "tokens": 1200,
    "content": "ing and preserving these connections. Communications can work in both a personal and a technical way, as is often proved by the widely varying forms ofmetadata that different ofﬁces use.Finally, institutional GIS may rely on an appreciation of the fact that it is, indeed,institutional. For spatial data infrastructures to succeed, they rely on an ongoingeffort from local data producers across a wide (perhaps global) scale. Moreover, theselocal data producers need to recognize that while they may focus on their own dataand its quality, they have to be aware of the larger infrastructure and their placewithin it. Their day-to-day work must continue with its internally focused attentioninformed by a larger awareness of the data infrastructure and its rules about datastandards, access, and timeliness.Looking aheadA recognition of the importance that GI partnering and institutional GIS will holdin the future is demonstrated by the placement of these issues in the list of researchpriorities chosen by the US University Consortium for Geographic Information Science (UCGIS). In developing its research agenda, UCGIS identiﬁed InsitutionalAspects of SDIs (Tulloch 2002) and Geographic Information Partnering (Nedovic-Budic 2002) as two key areas in which it should direct attention. Unfortunately,while it does show that these are high priorities within the GIS research community,it does not assure that they will be successful in getting further attention from thefunding agencies or the professional GIS community.Institutional GIS and GI partnering play a critical role in almost any scenariofor the future of GIS (National Research Council 1997). While the emergence ofnew technologies (for example, wireless applications and internet mapping) will haveuntold impacts on the future of GI and its applications, GI partnering and the deﬁningGIS institutions will ultimately determine how these impacts play out. Preparinginstitutions for the different GI applications that will be needed is a difﬁcult task,THO_C25  19/03/2007  11:28  Page 459 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f460DAVID L. TULLOCHbut efforts to promote an appropriate awareness in both users and decision-makerswill certainly be rewarded.Barriers to institutionalization are common and need to be better understood.Instead of simply raising awareness, more needs to done to understand the manymotivations behind data sharing, coordination, and partnerships. The varying motiva-tions – mandates, idealism, generosity, politics, expectations of access in return –behind data sharing become great barriers to advancing large SDI projects. Theseprojects are often undertaken with little or no formal recognition of the complexitythis adds to its networks of data providers and users.Increasingly, institutionalized GIS requires “advanced decision making” – agencyleaders decide far in advance of unforeseen problems to invest in a system, at somelater time their community can be rewarded for their commitment. While it no longertakes decades to establish these systems, institutionalization often outlasts electedpolitical administrations. This demonstrates the importance of educating leaders tothe long-term and unanticipated outcomes that make their decisions so signiﬁcant.It may also speak to a need for public and agency expectations that could be raisedin ways that would make it difﬁcult for elected ofﬁcials to resist.We also need to demand more of these institutionalized systems. It should not beenough that our public agencies are developing the data, because they also need tobe institutionalizing the process of disseminating them. Included in this are publicaccess policies that free the data to serve the public better, and engage in practicesthat improve the usability of these data (like maintaining metadata). As participantsin these larger policy debates we should also demand that agencies seek improvedcoordination and cooperation in data development and use. Institutionalized GISmeans that these agencies can develop interdependent policies, but it also requirestrust.Educators need to raise student awareness of the ultimate potential for a per-manent spatial information infrastructure system developing, integrating, and supplying local, state, and federal data. Some students may go on to help raise expectations, while some may apply the lessons by developing institutionalized GIS.But educators can hope that some students will ﬁnd unanticipated opportunitiesand leverage their communities’ institutionalized GIS to shape their landscapes inways that we could never imagine.REFERENCESAnderson, C. S. 1996. GIS development process: A framework for considering the initiation,acquisition, and incorporation of GIS technology. URISA Journal8(1): 10–26.Antenucci, J. C., Brown, K., Croswell, P. L., Kevany, M. J., and Archer, H. 1991. Geo-graphic Information Systems:A Guide To The Technology. New York: Van NostrandReinhold.Arizona Geographic Information Council. 1992. Arizona Geographic Information Council(AGIC) Survey of Existing Digital Spatial Data and Future Needs.Phoenix, AZ: DataManagement Division, Arizona Department of Administration.Azad, B. and Wiggins, L. L. 1995. Dynamics of inter-organizational geographic data sharing:A conceptual framework for research. In H. J. Onsrud and G. J. Rushton (eds) SharingGeographic Information. New Brunswick, NJ: Center for Urban Policy and Research: 22–43.THO_C25  19/03/2007  11:28  Page 460 Downloaded from https://onlinelibrary.wiley.com/doi/ by",
    "chunk_order_index": 289,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ece4a49292ee32aab8277f871e7ecde7": {
    "tokens": 1200,
    "content": ", L. L. 1995. Dynamics of inter-organizational geographic data sharing:A conceptual framework for research. In H. J. Onsrud and G. J. Rushton (eds) SharingGeographic Information. New Brunswick, NJ: Center for Urban Policy and Research: 22–43.THO_C25  19/03/2007  11:28  Page 460 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINSTITUTIONAL GIS AND GI PARTNERING461Bosworth, M., Donovan, J., and Couey, P. 2002. Portland Metro’s dream for public involve-ment. In W. Craig, T. Harris, and D. Weiner (eds) Community Participation and GIS.London: Taylor and Francis, pp. 125–36.Budic, Z. 1994. Effectiveness of geographic information systems in local government planning.Journal of the American Planning Association60: 244–63.Budic, Z. 1993. GIS use among southeastern local governments. URISA Journal 5(1): 4–17.Campbell, H. J. 1999. Institutional consequences of the use of GIS. In P. A. Longley, M. F. Goodchild, D. J. Maguire, and D. W. Rhind (eds) Geographical Information SystemsVol. 2. New York: John Wiley and Sons, pp. 621–31.Campbell, H. and Masser, I. 1992. GIS in local government: Some ﬁndings from Great Britain.International Journal of Geographical Information Systems6: 529–46.Campbell, H. and Masser, I. 1995. GIS and Organizations: How Effective are GIS in Practice?London: Taylor and Francis.Chan, T. O. and Williamson, I. P. 1999. The different identities of GIS and GIS diffusion.International Journal of Geographical Information Science13: 267–81.Chrisman, N. R. 1987. Design of geographic systems based on social and cultural goals.Photogrammetric Engineering and Remote Systems53: 1367–70.Coffeen, S. 1994. Using GIS to support the “reverse urbanization” process: A case study ofthe Presidio. URISA Conference Proceedings9: 517–26.Cook, R. N. and Kennedy, J. L. 1966. Proceedings of the Tri-State Conference on aComprehensive Uniﬁed Land Data System (CULDATA). Cincinnati, OH: College of Law,University of Cincinnati.Cowen, D. J. 1994. The importance of GIS for the average person. In Proceedings of theFirst Federal Geographic Technology Conference on GIS in Government: The FederalPerspective, Washington DC, USA. Fort Collins, GIS World Books, pp. 7–11.Craglia, M. and Masser, I. 2003. Access to geographic information: A European perspective.URISA Journal15(1): 51–9.Craig, W. and Johnson, D. 1997. Maximizing GIS beneﬁts to society. Geo Info Systems 7(3):14–8.Craig, W., Harris, T., and Weiner, D. (eds). 2002. Community Participation and GIS. London:Taylor and Francis.Crain, I. K. and MacDonald, C. L. 1984. From land inventory to land management.Cartographica21: 40–6.Crompvoets, J. and Bregt, A. 2003. World status of national spatial data clearinghouses.URISA Journal15(1): 43–50.Croswell, P. L. 1989. Facing reality in GIS implementation: Lessons learned and obstaclesto be overcome. URISA Conference Proceedings4: 15–35.Croswell, P. L. 1991. Obstacles to GIS implementation and guidelines to increase the oppor-tunities for success. URISA Journal 3(1): 43–56.Cullis, B. J. 1995. An Exploratory Analysis of Responses to Geographic Information SystemAdoption on Tri-Service Military Installations.Vicksburg, MS: US Army Corps ofEngineers Waterways Experiment Station.Curry, M. R. 1998. Digital Places: Living with Geographic Information Technologies.NewYork: Routledge.de Man, E. 2003. Cultural and institutional conditions for using geographic information:Access and participation. URISA Journal15(1): 29–33.Dobson, J. 1983. Automated geography.Professional Geographer35: 135–43.Dobson, J. 1993. The geographic revolution: A retrospective on the age of automated geo-graphy. Professional Geographer 45: 431–9.Dueker, K. J. and Kjerne, D. 1989. Multipurpose cadastre terms and deﬁnitions. In Proceed-ings of the American Society for Photogrammetry and Remote Sensing and AmericanTHO_C25  19/03/2007  11:28  Page 461 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and",
    "chunk_order_index": 290,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b7bd55814a088cb87d1fbc79a44396ef": {
    "tokens": 1200,
    "content": "urpose cadastre terms and deﬁnitions. In Proceed-ings of the American Society for Photogrammetry and Remote Sensing and AmericanTHO_C25  19/03/2007  11:28  Page 461 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f462DAVID L. TULLOCHCongress on Surveying and Mapping. Bethesda, MD: American Society for Photogrammetryand Remote Sensing and American Congress on Surveying and Mapping, pp. 94–103.Eason, K. 1988. Information Technology and Organisational Change.London: Taylor andFrancis.Epstein, E. and Marble, D. (uncredited eds). 2002. Geographic Information Science &Technology in a Changing Society: A Research Deﬁnition Workshop.Columbus, OH: Centerfor Mapping and School of Natural Resources, Ohio State University.Ezigbalike, I., Coleman, D., Cooper, R., and McLaughlin, J. 1988. A land information sys-tem development methodology. URISA Conference Proceedings. Bedford Park, IL: Urbanand Regional Information Systems Association 3: 282–96.FDGC. 1995. Development of a National Digital Geospatial Data Framework. Washington,DC: Federal Geographic Data Committee.FDGC. 1997. Framework Introduction and Guide. Washington, DC: Federal GeographicData Committee.Foresman, T. W. (ed.). 1997.The History of Geographic Information Systems: Perspectivesfrom the Pioneers. Upper Saddle River, NJ: Prentice Hall.Gillespie, S. R. 1994. Measuring the beneﬁts of GIS use: Two transportation case studies.URISA Journal6(2): 62–7.GSDI. 2004. Global Spatial Data Infrastructure Newsletter(January 2004). Reston, VA: GSDISecretariat.Goodchild, M. F. 1997. What next? Reﬂections from the middle of the growth curve. In T. W. Foresman (ed.)The History of Geographic Information Systems: Perspectives fromthe Pioneers. Upper Saddle River, NJ: Prentice Hall: 369–82.Handy, C. 1993. Understanding Organizations. New York: Oxford University Press.Hart, D., Koch, T., Moyer, D. D., and Niemann, B. J. 2001. Land Information Modern-ization Activity in Wisconsin: Impacts, Status and Future Tasks.Madison, WI: LandInformation and Computer Graphics Facility, University of Wisconsin-Madison (report toWisconsin Legislature).Harvey, F. 2001. Constructing GIS: Actor networks of collaboration. URISA Journal 13(1):29–37.Harvey, F. 2003. Developing geographic information infrastructures for local government:The role of trust. Canadian Geographer47: 28–36.Hissong, F. 2002. The Sisyphean death of the US NSDI: Oh, Prometheus...Prometheus?Earth Observation Magazine 11(11): 31.Hofstede, G. 2001. Culture’s Consequences: Comparing Values, Behaviors, Institutions andOrganizations across Nations.Thousand Oaks, CA: Sage.Huxhold, W. E. 1982. An evaluation of the City of Milwaukee automated geographic information and cartographic system in retrospect. In Proceedings of Seminar on Land-Related Information Systems, Municipal/Provincial Integration, Toronto, Canada.Jankowski, P. and Nyerges, T. 2001. Geographic Information Systems for Group DecisionMaking.London: Taylor and Francis.Jankowski, P. and Nyerges, T. 2003. Toward a framework for research on geographic information-supported participatory decision-making. URISA Journal 15(1): 9–17.Keen, P. 1981. Information systems and organizational change. Communications of the ACM24: 24–33.Kishor, P., Niemann, B. J., Moyer, D. D., Ventura, S. J., Martin, R. W., and Thum, P. G. 1990.Lessons from CONSOIL: Evaluating GIS/LIS. Wisconsin Land Information Newsletter6(1): 1–13.Kuhlman, K. and Niemann, B. J. 1993. Modernizing land records: Tracking GIS/LIS tech-nology in Wisconsin and beyond. URISA Journal 7(1): 60–3.THO_C25  19/03/2007  11:28  Page 462 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINSTITUTIONAL GIS AND GI PARTNERING463Lachman, B., Wong, A., Knopman, D., and Gavin, K. 2002. Lessons for the Global SpatialData Infrastructure: International Case Study Analysis.Santa Monica, CA: RAND Scienceand Technology Policy Institute.Larsen, B., Clapp, J., Miller, A. H., Niemann, B. J., and Ziegler, A. L. 1978. Land Records:The Cost to",
    "chunk_order_index": 291,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ce0b79d34d955ab7fc16358c5b3fd9d7": {
    "tokens": 1200,
    "content": "UTIONAL GIS AND GI PARTNERING463Lachman, B., Wong, A., Knopman, D., and Gavin, K. 2002. Lessons for the Global SpatialData Infrastructure: International Case Study Analysis.Santa Monica, CA: RAND Scienceand Technology Policy Institute.Larsen, B., Clapp, J., Miller, A. H., Niemann, B. J., and Ziegler, A. L. 1978. Land Records:The Cost to the Citizen to Maintain the Present Land Information Base: A Case Study ofWisconsin. Madison, WI: Department of Administration, Ofﬁce of Program and Manage-ment Analysis.Masser, I. 1998. Governments and Geographic Information. London: Taylor and Francis.Masser, I., Campbell, H., and Craglia, M. (eds). 1996. GIS Diffusion: The Adoption andUse of Geographical Information Systems in Local Government in Europe. London: Taylorand Francis.Masser, I. and Onsrud, H. (eds). 1993. Diffusion and Use of Geographic InformationTechnologies. Dordrecht: Kluwer.Minnesota Governor’s Council on Geographic Information. 1994. Minnesota GIS Survey ofGIS Organizations, Geographic Data Files, and Data Needs. Minneapolis, MN: MinnesotaGovernor’s Council on Geographic Information and Minnesota GIS/LIS Consortium.Morton, M. (ed.). 1991. The Corporation of the 1990s: Information Technology andOrganizational Transformation.New York: Oxford University Press.Moyer, D. D. 1993. Economics of MPLIS: Concepts and tools. In P. M. Brown and D. D. Moyer (eds). Multipurpose Land Information Systems: The Guidebook. Washington,DC: Federal Geodetic Control Committee 15.1–15.25.NAPA. 1998. Geographic Information for the 21st Century: Building a Strategy for the Nation.Washington, DC: National Academy of Public Administration.NASA Digital Earth Ofﬁce. 2000. What is Digital Earth?Washington, DC: NationalAeronautics and Space Administration.National Research Council. 1980. Need for a Multipurpose Cadastre.Washington, DC:National Academy Press.National Research Council. 1983. Procedures and Standards for a Multipurpose Cadastre.Washington, DC: National Academy Press.National Research Council. 1993. Toward a Coordinated Spatial Data Infrastructure forthe Nation. Washington, DC: National Academy Press.National Research Council. 1997. The Future of Spatial Data and Society. Washington, DC:National Academy Press.National Research Council. 2001. National Spatial Data Infrastructure for the Nation.Washington, DC: National Academy Press.National Research Council. 2003. Weaving a National Map: Review of the U.S. GeologicalSurvey Concept of The National Map. Washington, DC: National Academy Press.Nebert, D. (ed.). 2001. Developing Spatial Data Infrastructures: The SDI Cookbook GlobalSpatial Data Infrastructure (GSDI), USA, Version 1.1. WWW document, http://www.gsdi.org.Nedovic-Budic, Z. 2002. Geographic Information Partnering. Washington, DC: Univer-sity Consortium for Geographic Information Science Research Brief (available at http://www.ucgis.org/priorities/research/2002researchPDF/shortterm/m_gi_partnering.pdf).Nedovic-Budic, Z. and Pinto, J. K. 1999. Understanding inter-organizational GIS activities:A conceptual framework. URISA Journal11(1): 53–64.New Jersey State Mapping Advisory Committee. 1997. New Jersey GIS Resource Guide,1997. Trenton, NJ: New Jersey State Mapping Advisory Committee (HTML-formatteddocument distributed on New Jersey Geographic Information System).Niemann, B. J. and Moyer, D. D. (eds). 1988. A Primer on Multipurpose Land InformationSystems.Madison, WI: University of Wisconsin-Madison, Institute for Environmental StudiesReport No. 133.THO_C25  19/03/2007  11:28  Page 463 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f464DAVID L. TULLOCHNiemann, B. J. and Niemann, S. 1999. Roger F. Tomlinson: The father of GIS. Geo InfoSystems9(3): 40–1, 43–4.North, D. C. 1990. Institutions, Institutional Change, and Economic Performance. New York:Cambridge University Press.Obermeyer, N. J. and Pinto, J. K. 1994. Managing Geographic Information Systems. NewYork: Guilford.Onsurd, H. J., Calkins, H. W., and Obermeyer, N. J. (eds). 1989. Use and Value of GeographicInformation: Initiative Four Specialist Meeting Final Report.Santa Barbara, CA: NationalCenter for Geographic Information and Analysis Technical Report.Onsrud, H. J. and Pinto, J. K. 1993. Evaluating correlates of GIS adoption success and thedecision process of GIS acquisition. URISA Journal 5(1): 18–39.Onsrud, H. J., Pinto, J. K., and Azad, B. 1992. Case study research methods for geographicinformation",
    "chunk_order_index": 292,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9509b1cdb5d448513d719f17016dba86": {
    "tokens": 1200,
    "content": ": Initiative Four Specialist Meeting Final Report.Santa Barbara, CA: NationalCenter for Geographic Information and Analysis Technical Report.Onsrud, H. J. and Pinto, J. K. 1993. Evaluating correlates of GIS adoption success and thedecision process of GIS acquisition. URISA Journal 5(1): 18–39.Onsrud, H. J., Pinto, J. K., and Azad, B. 1992. Case study research methods for geographicinformation systems. URISA Journal4(1): 32–44.Onsrud, H. J., Pinto, J. K., and Azad, B. 1993. Testing Technology Transfer Hypotheses inGIS Environments Using a Case Study Approach.Santa Barbara, CA: National Centerfor Geographic Information and Analysis Technical Report No. 93–8.Onsrud, H. J. and Rushton, G. J. (eds). 1995. Sharing Geographic Information.New Brunswick,NJ: Center for Urban Policy Research, Rutgers University.Openshaw, S. 1991. A view on the crisis in geography, or using GIS to put Humpty-Dumptyback together again. Environment and PlanningA 23: 621–8.Pickles, J. (ed.). 1995. Ground Truth: Social Implications of Geographic Information Systems.New York: Guilford.Regional Urban Information System. 1997. RUIS Strategic Plan. San Diego, CA: RegionalUrban Information System.Renner, P. J. Y. and Waldon, J. L. 1995. Kentucky Fish and Wildlife Resource InformationManagement Survey.Frankfort, KY: Kentucky Department Fish and Wildlife Resources.Rogers, E. M. 1993. The diffusion of innovations model. In I. Masser and H. Onsrud (eds)Diffusion and Use of Geographic Information Technologies. Dordrecht: Kluwer, pp. 9–24.Rogers, E. M. 1995. Diffusion of Innovations.New York: The Free Press.Sandberg, B. 1992. A Geographic Information Systems User Survey: The Emerging GISCommunity in Michigan. East Lansing, MI: Center for Remote Sensing, Michigan StateUniversity.Sheppard, E. 1995. GIS and society: Towards a research agenda. Cartography and GeographicInformation Systems22: 5–16.Sinton, D. 1991. Reﬂections on 25 years of GIS. GIS World4: special insert.Smith, N. 1992. History and philosophy of geography: Real wars, theory wars. Progress inHuman Geography 16: 257–71.Steinitz, C. 1993a. GIS: A personal historical perspective. GIS Europe2(5): 19–22.Steinitz, C. 1993b. GIS: A personal historical perspective – Part 2: A framework for theoryand practice in landscape planning. GIS Europe2(6): 42–5.Steinitz, C. 1993c. GIS: A personal historical perspective – Part 3: The changing face of GIS from 1965–1993. GIS Europe2(7): 38–40.Taylor, P. and Overton, M. 1991. Commentary: Further thoughts on geography and GIS.Environment and PlanningA 23: 1087–94.Tomlinson, R. 1997. The Canada Geographic Information System. In T. Foresman (ed.) TheHistory of Geographic Information Systems: Perspectives of Pioneers. Upper Saddle River,NJ: Prentice-Hall, pp. 21–32.Tosta, N. 1999. NSDI was supposed to be a verb: A personal perspective on progress in theevolution of the U.S. National Spatial Data Infrastructure. In B. Gittings (ed.)IntegratingInformation Infrastructures with GI Technology.Philadelphia, PA: Taylor and Francis,pp. 13–24.THO_C25  19/03/2007  11:28  Page 464 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINSTITUTIONAL GIS AND GI PARTNERING465Tulloch, D. L. 1999. Theoretical model of multipurpose land information systems develop-ment. Transactions in GIS3: 259–83.Tulloch, D. L. 2002. Institutional aspects of SDIs. Washington, DC: University Consortiumof Geographic Information Science Research Brief (available at http://www.ucgis.org/priorities/research/2002researchPDF/shortterm/l_institutional_gis.pdf).Tulloch, D. L. and Epstein, E. F. 2002. Beneﬁts of community MPLIS: Efﬁciency, effective-ness, and equity. Transactions in GIS6: 195–212.Tulloch, D. L. and Fuld, J. 2001. County-level production of framework data: Pieces of aNational Spatial Data Infrastructure? URISA Journal 13(2): 11–21.Tulloch, D. L. and Niemann, B. J. 1996. Evaluating innovation: The Wisconsin LandInformation Program. Geo Info Systems6(10): 40–4.Tulloch, D. L., Niemann, B. J., Ventura, S. J., and Epstein, E. F. 1996. Measuring GIS/L",
    "chunk_order_index": 293,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-010b6dcc8a6ddf861b0cf2c07f537eea": {
    "tokens": 1200,
    "content": "of framework data: Pieces of aNational Spatial Data Infrastructure? URISA Journal 13(2): 11–21.Tulloch, D. L. and Niemann, B. J. 1996. Evaluating innovation: The Wisconsin LandInformation Program. Geo Info Systems6(10): 40–4.Tulloch, D. L., Niemann, B. J., Ventura, S. J., and Epstein, E. F. 1996. Measuring GIS/LISprogress in local governments: Land records modernization and its outcomes. In Proceedingsof the Seventeenth International ESRI User Conference,Palm Springs, CA, USA: CD-ROM.Tulloch, D. L. and Robinson, M. 2000. A progress report on a U.S. national survey of geo-spatial framework data. Journal of Geographic Information Systems27: 285–98.Tulloch, D. L. and Shapiro, T. 2003. The intersection of data access and public participation:Impacting GIS users’ success? URISA Journal 15(2): 55–60.US Geological Survey. 2001. The National Map: Topographic Mapping for the 21st Century.Reston, VA: Ofﬁce of the Associate Director for Geography, US Geological Survey.Ventura, S. J. 1995. The use of geographic information systems in local government. PublicAdministrative Review55: 461–7.Wisconsin Land Information Board. 1995. 1994 Annual Status Report Survey to theWisconsin Land Information Board. Madison, WI: University of Wisconsin-Madison, LandInformation and Computer Graphics Facility.Wunderlich, G. and Moyer, D. D. 1984. Economic features of land information systems. InB. J. Niemann (ed.) Seminar on the Multipurpose Cadastre: Modernizing Land Informa-tion Systems in North America.Madison, WI: University of Wisconsin-Madison, Institutefor Environmental Studies Report No. 123: 183–202.Zaltman, G., Duncan, R., and Holbek, J. 1973. Innovations and Organization. New York:John Wiley and Sons.THO_C25  19/03/2007  11:28  Page 465 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 26Participatory Geographic Information SystemsDaniel Weiner and Trevor M. HarrisIt is now twenty years since Chrisman (1987) provided one of the very early con-tributions to what subsequently became known as the Geographic Information System(GIS) and Society debate by proposing that GIS be developed in the context of social,economic, and ethical needs. In 1991, both Pickles (1991) and Edney (1991) pre-sented papers concerning the transforming nature of GIS technology on society atthe Applied Geography Conference in Toledo and the topic was also discussed at a 1991 Asso-ciation of American Geographers (AAG) Annual Meeting session onGIS and Society. In the same year a sharp exchange of words between Openshaw(1991) and Taylor and Overton (1991) occurred over the future role of GIS in thediscipline of Geography and Openshaw’s view of GIS as the superglue to put “HumptyDumpty” (that is to say, Geography) back together again.It was the Friday Harbor, Washington conference, however, sponsored by theNational Center for Geographic Information and Analysis (NCGIA) that broughtthe academic GIS and social theory communities together, face to face, for the ﬁrsttime with the explicit purpose of discussing the potential societal impacts of GIS.The positive attitude of the Friday Harbor conference signiﬁcantly moved the debateforward in identifying salient issues and putting in place institutional proceduresand forums for continued discussion. Out of the Friday Harbor conference wasborn NCGIA Initiative 19 and the subsequent workshop in Minnesota (Harris andWeiner 1996) and the special edition of Cartography and Geographic InformationSystemson GIS and Society published in January, 1995. Central to the broaderdissemination of the GIS and Society discussion was, of course, the publication ofthe seminal book entitledGround Truth: The Social Implications of GeographicInformation Systems(Pickles 1995).Public Participatory GIS (PPGIS) was one of the more substantive methodolog-ical and political themes to arise out of the GIS and Society debate. Speciﬁc focuson the intersection of participatory development and geospatial technologies wasformalized in an NCGIA Varenius initiative Empowerment, Marginlization and PublicParticipation GIS (http://www.ncgia.ucsb.edu/varenius/varenius.html). This resultedin the publication in 2002 of a collection of essays on Community Participation andTHO_C26  19/03/2007  11:27  Page 466 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPARTICIPATORY GIS467Geographic Information Systems(Craig, Harris, and Weiner 2002). This book con-tains 28 chapters from 48 contributing authors, comprises 10 conceptual chaptersand 18 case studies, and provides a valuable perspective on",
    "chunk_order_index": 294,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a11586d1f17fa2a878c8dc2bc57181d7": {
    "tokens": 1200,
    "content": "06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPARTICIPATORY GIS467Geographic Information Systems(Craig, Harris, and Weiner 2002). This book con-tains 28 chapters from 48 contributing authors, comprises 10 conceptual chaptersand 18 case studies, and provides a valuable perspective on developments in theﬁeld of PPGIS. In this review we draw upon the ﬁndings of the book, complementedby our own personal research and ﬁeld-based experiences. This chapter was writtensoon after the book was published and important additional research on Participat-ory GIS has been subsequently published (see, for example, Fox, Suryanata, andHershock 2005, Hawthorne, Dougherty, Elmes, et al. 2006, IIED 2006, Jankowskiand Nyerges, Chapter 27 in this volume, Schlossberg and Shuford 2004).Initially we seek to deﬁne what is meant by PPGIS; especially as the term hasevolved through several variant forms that reﬂect reﬁnements important to the ﬁeld.Despite these variant forms, however, the focus remains on systems and projectsthat link communities with GIS and other geospatial technologies. Subsequent toidentifying the current forms of PPGIS, the review focuses on exploring PPGIS methods, the nature of participation in PPGIS, and the regional and domain areasin which these systems have been developed.Deﬁning Participatory Geographic Information SystemsThe concept of PPGIS arose primarily out of the broader discussions on GIS andSociety as discussed above. This origin is signiﬁcant because of the inﬂuence of the debate on the nature of “early” PPGIS projects and their subsequent forms.Signiﬁcantly, PPGIS arose not from an applied ﬁeld of inquiry, or even out of participatory development, but from a distinctly academic GIS and Society debate.Considerable discussion at the NCGIA Initiative 19 workshop in Minnesota focusedon how GIS might methodologically address the issues raised by the social theoreticcritique (Harris and Weiner 1996). Scenarios based on existing GIS software andusage were considered (labeled version 1.0) along with possible modiﬁed usage ofsoftware currently available (labeled version 1.2). Much of the discussion, how-ever, revolved around speculation about alternative forms of GIS that would bringabout a substantive shift toward addressing core GIS and Society issues. These alternative systems were labeled GIS 2. Envisaging an alternative system in the context of differential public access to data, hardware, software, and expertise, toquestions of distorted knowledge databases and the perceived exclusion of com-munity knowledge and to broad issues of democratic GIS-based decision-making,led ensuing discussion to consider the development of PPGIS. PPGIS provided asuitable vehicle that would address the social theoretical critique of GIS andcon-tribute to the methodological development of GIS and the move toward GIS 2. Ata subsequent workshop held at the University of Maine the term PPGIS was moreformally deﬁned (Schroeder 1996).In 1998, Project Varenius brought together a number of researchers, again prim-arily from the academic community, with experience in the implemention of PPGISprojects (Craig, Harris, and Weiner 1999). The intent of the workshop was to movebeyond theory and to explore the methodological and participatory issues thrownup by the ﬁeld-based experiences and project development. The workshop paperswere subsequently updated and formed the core of a new book (Craig, Harris, andTHO_C26  19/03/2007  11:27  Page 467 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f468DANIEL WEINER AND TREVOR M. HARRISWeiner 2002). Subsequent variations in terminology have appeared that reﬂect sub-tleties in the conceptualization of PPGIS. Thus Community-integrated GIS (CiGIS)(Harris and Weiner 1998) speciﬁcally seeks to position PPGIS in the context of thepolitical economy of differential access to resources, data, and knowledge repres-entation. Developing PPGIS without consideration of how such systems are to beresourced or sustained misses a central concern of the GIS and Society critique. CiGISwas designed to broaden public participation in GIS decision-making based on theassumption that state and local government agencies, along with NGOs, will pro-vide the resources and the infrastructure to support such efforts. In this respect thecore of a CiGIS is focused on how communities gain access to such systems and howtheir knowledge might complement traditional top-down GIS data typical of moretraditional systems (see the early part of Chapter 28 by Dana in this volume for anapplication illustrating these issues). Further to this, the term PPGIS has increasinglybeen shortened to Participatory GIS (PGIS). Speciﬁcally, this term acknowledgesnot just the involvement of the public in the development and use of such systemsbut that of other governmental and non-governmental agencies and private sectormembers of a community as well. In addition, the term Participatory GIS placesthe greater emphasis on participatory methods in the production of a GIS. For theremainder of",
    "chunk_order_index": 295,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e1cff2414a220d9be5a4e236124abc7d": {
    "tokens": 1200,
    "content": "application illustrating these issues). Further to this, the term PPGIS has increasinglybeen shortened to Participatory GIS (PGIS). Speciﬁcally, this term acknowledgesnot just the involvement of the public in the development and use of such systemsbut that of other governmental and non-governmental agencies and private sectormembers of a community as well. In addition, the term Participatory GIS placesthe greater emphasis on participatory methods in the production of a GIS. For theremainder of this chapter we use the preferred term of PGIS.It is notable that much of the PGIS work of the 1990s, perhaps epitomized bythe collection of case studies in Craig, Harris, and Weiner (2002), are primarilylocated in the GIS and Society literature. The studies invariably originate from anacademic environment, are steeped in GIS and Society themes, are project-based,and are driven by a concern to pursue social justice issues as well as research PGISthemes. In more recent years, several other trends can be discerned. One such trendmirrors developments in GIS itself and especially the move toward GeographicInformation Science (GISc). Use of the term Participatory Geographic InformationScience (PGISc) (MacMaster 2002; see also Pickles 1999 and Sheppard, Couclelis,Graham, Harrington, and Onsrud 1999) seeks to position PGIS less as a focus onthe information system than on the science of spatial information. While the termPGISc has been used extensively in panel discussions and has been used in generaldiscussion, there is as yet no clear deﬁnition of what such PGISc would comprise,nor has a demonstration project been developed that distinguishes between PGISand PGISc. In essence, PGISc acknowledges that PGIS is situated within the evolv-ing ﬁeld of GISc. In one respect this ﬁts well with the emergence of PGIS that areas much dependent on related geospatial technologies, such as remote sensing andthe Internet, as they are on GIS per se. However, the positioning of PGIS in thecontext of a science paradigm would appear to raise epistemological and philosophicalissues that are even further at odds with the GIS and Society issues and alternativeconceptualizations of space and place that the debate raised.A further trend in PGIS may be identiﬁed as a result of the diffusion of PGISconcepts among a broader user community. This should perhaps be expected as theﬁeld becomes more widely known. In particular, as PGIS becomes more distant fromthe incubating academic environment of its origins, and less situated within the broader GIS and Society discussion, so the nature of PGIS will reﬂect such distancing.This change is perhaps best reﬂected in the Annual Urban and Regional InformationSystems Association(URISA) PPGIS conferences that started in 2002, and a 2005THO_C26  19/03/2007  11:27  Page 468 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPARTICIPATORY GIS469Mapping for Change International Conference on Participatory Spatial InformationManagement and Communicationthat was held in Nairobi (IIED 2006).PGIS Methods and Forms of ParticipationPGIS explicitly situate GIS within participatory research and, as a result, local know-ledge is incorporated into GIS production and use. In blending local knowledgewith “expert” information, PGIS projects have in common the application ofgeospatial technologies to address concerns articulated by community participants.As a result, data products and the scale of analysis must be appropriate for theneeds of the participating community, and community data production and accessis assumed.Given the characteristics of PGIS outlined above, it is surprisingly difﬁcult to explicitly identify its core methods. Indeed, therein lies the challenge. PGIS methodscan range from conventional ﬁeld-based participatory development methods thatprimarily utilize digital mapping, to Internet-dependent spatial multimedia. Digitalcartography remains the core of many PGIS efforts as the “power of maps” is extendedto participant communities. Such has been the extent of community mapping initiat-ives under the name of PGIS that there have been calls to change the term toCommunity Mapping Systems, for in many PGIS projects very little GIS function-ality is used beyond the mapping component. However, PGIS methods also includegeo-visualization, sketch mapping, satellite image and air photo interpretation, GPStransect walks, mental mapping exercises, spatial multimedia, and, in the case ofsome contemporary work, even virtual GIS (Harris, Alagan, and Rouse 2002). GPStransect walks are sometimes utilized to locate community resource access and forlandscape interpretation. In cases where communities do not have access to suchresources, mental mapping with tracing paper overlaid on GIS products has provento be very useful. Mental maps are a useful method for communities to expresstheir perceptions of landscape and to collect socially differentiated community local knowledge that can be digitized and analyzed as GIS data (Harris and Weiner2002). They are a platform for individual and community “spatial story telling”(Aitken 2002). Sketch maps are also a proven development planning method forinvestigating community perceptions of local landscapes and for communities toarticulate their spatial needs, aspirations, and frustrations without the constraintsof cartographic accuracy or the constraints of boolean logic (Sheppard 1993). An important challenge in the production of PGIS is, therefore, the integration ofvaluable qualitative local knowledge such as",
    "chunk_order_index": 296,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b94fbc06b549186582a354cb727b3936": {
    "tokens": 1200,
    "content": "2002). They are a platform for individual and community “spatial story telling”(Aitken 2002). Sketch maps are also a proven development planning method forinvestigating community perceptions of local landscapes and for communities toarticulate their spatial needs, aspirations, and frustrations without the constraintsof cartographic accuracy or the constraints of boolean logic (Sheppard 1993). An important challenge in the production of PGIS is, therefore, the integration ofvaluable qualitative local knowledge such as sound, voice, text, photos, and videowith GIS. Spatial multimedia systems are becoming increasingly common and theInternet provides a powerful technology for performing such integration (Harris,Weiner, Warner, and Levin 1995, Kingston 2002, Shiffer 2002).It is of some interest to explore the range of approaches used in the recent com-pendium of case studies that link community participation with GIS (Craig, Harris,and Weiner 2002). An exploration of the case studies suggests that three dominantcomponents are apparent: participatory methods, the Internet, and GIS (Figure 26.1).The respective contribution of each component in the case studies indicates that fourof the 18 case studies make extensive use of the Internet. Interestingly, this does notTHO_C26  19/03/2007  11:27  Page 469 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f470DANIEL WEINER AND TREVOR M. HARRISimply the use of Internet GIS but of peer-to-peer capability for data, information,and e-mail exchange between communities often separated by considerable distances.Participatory methods, as one would expect, are extensively used and are familiarto a range of academic disciplines and development practitioners. Of all the threedimensions, it is GIS that exhibits the least complexity. While a few projects havesought to augment GIS through multimedia technology, very few go beyond digitalmapping. It could be postulated that as PGIS evolves so there will be a migrationtoward the far top right of the box, though this assumes that greater technologicaland participatory complexity will produce more effective participatory systems. Asearlier comments should indicate, this is by no means an acceptable assumptionand it could be that the simplest mapping system could still produce very effectivesolutions.Regardless of the speciﬁc PGIS methods used, community participation is essentialfor successful project implementation. Importantly, participation is not a uniformhomogenous method and it is the nature of participation employedthat is central tounderstanding PGIS. Community participation has long been a mantra in develop-ment planning and ﬁeld-based academic research. Unfortunately, most participationassociated with development planning can stand accused of being participation aslegitimization, and such models could equally well apply in PGIS. Thus, communitymeetings are held, local input is gathered, the GIS is generated, reports are pro-duced, and top-down planning under the legitimating guise of PGIS is maintained.In this context, participation could assist in legitimizing decisions that are not neces-sarily popular within impacted communities.In the academic world, participation has come to designate a conﬁguration ofqualitative methods designed to understand complex social processes in ways thatconventional quantitative methods cannot achieve. Efforts to hear the voices of “ordinary” people and to represent “local knowledge” are well intentioned, but inmany instances these are forms of participation for publication, in which academicsundertake research to produce books and journal articles while leaving the subjectInternet100100806040GIS GIT2000204060Public Participation80100755025Fig. 26.1The relations of GIS, participation, and the Internet in the case studies (Craig, Harris, and Weiner 2002)THO_C26  19/03/2007  11:27  Page 470 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPARTICIPATORY GIS471communities with little (if any) tangible beneﬁts. This type of participatory practicetends to be exploitative. Popular participation, in the sense that we use it, is an attemptto locate community participation within the context of local and democratic con-ﬁgurations of power within civil society (Levin and Weiner 1997). Participatoryprocesses then become part of the structures of everyday life, and ordinary people areable to express their opinions as openly as possible. There are, therefore, inherentcontradictions in the marriage of community participation with GIS. Participationis a highly contested “development” theory and practice that is compounded stillfurther with the introduction of geospatial information technologies.PGIS projects are, at their core, political because they attempt to broaden accessto digital spatial information and empower historically disempowered people andcommunities. PGIS projects are also political because they involve community participation, which is again essentially a political process. This suggests thatunderstanding the politics and associated power relationships of PGIS projects iscritical in order to unpack their impacts, wherever and however implemented.Participatory GIS is a reﬂection of the politics of the builders and users of suchsystems, although these politics extend beyond the local impacts on participatingand non-participating communities. The issue of who has access to GIS and wh",
    "chunk_order_index": 297,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0c063c70f5dac236ef9bb98a260c8714": {
    "tokens": 1200,
    "content": "communities. PGIS projects are also political because they involve community participation, which is again essentially a political process. This suggests thatunderstanding the politics and associated power relationships of PGIS projects iscritical in order to unpack their impacts, wherever and however implemented.Participatory GIS is a reﬂection of the politics of the builders and users of suchsystems, although these politics extend beyond the local impacts on participatingand non-participating communities. The issue of who has access to GIS and whobeneﬁts from such systems is, therefore, a fundamental yet complex question.PGIS ImplementationThe coming together of community participation with GIS, and geospatial tech-nologies more generally, is global in its scope and occurring in a diversity of social and environmental contexts (Abbot, Chambers, Dunn, et al. 1998, Craig, Harris,and Weiner 2002). GIS are being integrated in communities in a wide variety ofways, to serve many purposes, and with various degrees of effectiveness (Leitner,McMaster, Elwood, McMaster, and Sheppard 2002). Some communities use GISto administer and manage territory under their control (Elwood 2002, Walker, Leitch, De Lai 2002, Kwaku-Kyem 2002, Jordan 2002, Bond 2002) and to makeinformed input into local planning processes (Sieber 2002, Parker and Pascual 2002, Ventura, Niemann, Suttphin, and Chenoweth 2002, Kingston 2002, Bosworth,Donovan, and Couey 2002). There are also cases where GIS have helped commun-ities to develop their own spatial strategies and policies (Sawicki and Burke 2002,Tulloch 2002, McNab 2002, Laituri 2002, Harris and Weiner 2002). Bosworth,Donovan, and Couey (2002) show the multiple ways government can make dataavailable to communities, while Kingston (2002) and Ventura, Niemann, Suttphin,and Chenoweth (2002) demonstrate how PGIS is rapidly merging with the Internet.Some of the earliest applications involved indigenous natural resource mapping inarctic and tropical regions within the Americas (Marozas 1993; see also Chapter 28by Dana in this volume). There is also a rapidly growing network of planning professionals interested in PGIS in the context of neighborhood revitalization andurban planning (Aitkin and Michel 1995; Craig and Elwood 1998; Talen 1999,2000; Leitner, McMaster, Elwood, McMaster, and Sheppard 2002; Sawicki andPeterman 2002). Environmental groups are also experimenting with community GISapplications to promote environmental equity and address environmental racismTHO_C26  19/03/2007  11:27  Page 471 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f472DANIEL WEINER AND TREVOR M. HARRIS(Kellog 1999, Sieber 2000). Furthermore, NGOs, aid organizations, and govern-mental agencies are linking communities with GIS as they seek to promote morepopular and sustainable development projects (Hutchinson and Toledano 1993,Obermeyer and Pinto 1994, Gonzalez 1995, Harris, Weiner, Warner, and Levin1995, Weiner, Warner, Harris, and Levin 1995, Dunn, Atkins, and Townsend 1997,Mitchell 1997, Elwood and Leitner 1998, Jordan and Shrestha 1998, Kwaku-Kyem1999, Rambaldi and Callosa 2000, Weiner and Harris 2003).One of the greatest difﬁculties involved in implementing a PGIS is the incorpora-tion of complex and socially differentiated information within a GIS. Harris andWeiner (2002) confronted this problem using socially differentiated mental maps withparticular themes, and incorporating that information into a spatial multimediadatabase. Al-Kodmany (2002) employed an innovative graphic design method to extendGIS to incorporate block-speciﬁc community views. But community organizationsdo not necessarily represent the views of the majority of community members. Kwaku-Kyem’s (2002) case study in Ghana identiﬁes the common contradictions inherentin practices of community participation. For example, women are often excluded,some people are intimidated by the technology, clans have difﬁculty collaborating,and the existing power structure is often disinterested in empowering citizens.Bosworth, Donovan, and Couey (2002) use a communication pyramid to show thatmany people choose not to get involved in community activity, but clearly thereare aspects of organizations and technology that tend to systematically exclude someindividuals.A further point is that participation in PGIS should not be viewed solely as amethod but as a process. Walker, Leitch, De Lai, et al. (2002) demonstrate thatcommunities working together to create a GIS center helped resolve many conﬂictsamong the participating groups. Process was also a central theme of Jordan’s (2002)case study in Nepal and the study by Meridith, Yetman, and Frias (2002) in Canadaand Mexico. The latter identiﬁed “second order cybernetics” whereby peopleworking together became more aware of their situation, and thus made personaladaptations to accommodate community needs and desires.",
    "chunk_order_index": 298,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d54645e01fa0ca242f5a3447e083b8d0": {
    "tokens": 1200,
    "content": "thatcommunities working together to create a GIS center helped resolve many conﬂictsamong the participating groups. Process was also a central theme of Jordan’s (2002)case study in Nepal and the study by Meridith, Yetman, and Frias (2002) in Canadaand Mexico. The latter identiﬁed “second order cybernetics” whereby peopleworking together became more aware of their situation, and thus made personaladaptations to accommodate community needs and desires. Many PGIS projectsdo not include community participation as part of the GIS production process. Forexample, some community information needs can be met by conventional maps andreports delivered by a government service center on compact disk or over the Internet.Casey and Pederson (2002) refer to this as a “public records GIS,” and many citiesand counties now provide this type of public data inventory. For example, the Data and Policy Analysis Group of the Atlanta Project provides sophisticated maps to assist local committees in understanding the nature of prioritized community issues, and to help develop policy recommendations (Sawicki and Burke 2002). Such an approach does not, however, fulﬁll the needs of what Casey and Pedersoncall “community-based GIS” that should provide not only relevant local data butbe capable of performing spatial analysis for participating communities.But what have been the impacts of this rapid merging of community participationwith geospatial technologies? How have PGIS initiatives contributed to individualand community empowerment? And, are there cases of PGIS disempowerment? While it is still very early in the adoption process, and the nature of PGIS is inﬂux, there is evidence of success stories in the areas of crime prevention, housingcondemnation and renovation, smart growth and land-use planning; natural resourceTHO_C26  19/03/2007  11:27  Page 472 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPARTICIPATORY GIS473management, and the conservation and preservation of indigenous territories. PGISgive communities access to advanced IT map and/or spatial analysis applicationsand include their voices in the resulting GIS products. This contributes to communityempowerment through digital countermaps that communicate community spatialstories that are integrated into local decision-making politics. Furthermore, the pro-cess of participation itself can be empowering, as communities are “experts” aboutthe local landscape and teachers of the development practitioners. In New Zealand,for example, “the construction of community-based GIS has provided the iwi (tribes)with the opportunity to identify meaningful applications of their particular areasfrom their own perspective rather than applications based only on Euro-Americanmodels of resource management and land use. Tribal people were not only the GISusers, but the GIS designers as well” (Laituri 2002, p. 273).Parker and Pascual document a similar empowerment process in a San Franciscogentriﬁcation case study:It is unlikely that the Planning Department would have engaged in such a detailedstudy and invited public participation had it not been of the actions of a very informedand sophisticated group of community activists. At the core of this effort was the GIS-generated living neighborhood map, which empowered the community, educatedcommunity members, and offered a means by which people could shed their individualopinions and judgments in order to see the situation for what it truly was. By bothimproving the quality of information available and providing a means for people towork together, the living neighborhood map allowed people to stop reacting based onemotion, hearsay, and opinions and develop a more credible and powerful voice withwhich to argue in the public arena for their rights as a community. (Parker and Pascual2002, p. 64)There is also evidence that PGIS mapping of indigenous lands is empowering par-ticipant communities in the United States. Bond concludes that:...many tribes are using geospatial technology to manage their natural and culturalresources. The Yakima Tribe in Washington State, the White Mountain Apache inArizona and the Salish Kootenai in Montana utilize GIS technology to inventory, ana-lyze, map and make decisions regarding tribal resources. Examples of such resourcesinclude timber production, grazing and farm land, water rights, wildlife, native plants,cultural sites, environmental data and hazardous site monitoring, historical preservation,health and human resources. (Bond 2002, p. 292)In the case of inner city housing decay and renovation, a Minneapolis communityorganization (PPNA) produced a PGIS to:...address several critical housing issues in Powderhorn Park. They have been used mostextensively in making plans for housing improvement in the neighborhood. For example,in 1998, PPNA’s Housing and Land-Use committee relied extensively on analysis ofthese data to inform residents in making housing improvements...the organizationwas able to, for the ﬁrst time, conduct comprehensive geographic analysis of hous-ing issues...For instance, a staff member’s analysis showing the concentration of dilapidated rental properties along the neighborhood’s major transportation corridorsinspired the committee to design assistance programs speciﬁcally targeted to theimprovement of rental properties...(Elwood 2002, p. 81)THO_C26  19/03/2007  11:27  Page 473 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use",
    "chunk_order_index": 299,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d2a291c09184861f462dabd8d894785a": {
    "tokens": 1200,
    "content": "improvement of rental properties...(Elwood 2002, p. 81)THO_C26  19/03/2007  11:27  Page 473 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f474DANIEL WEINER AND TREVOR M. HARRISHowever, this Minneapolis case study also demonstrates how marginalization canoccur simultaneously with empowerment:Neighborhood deliberations about housing improvements increasingly utilize languagethat requires detailed knowledge of City or County housing policies...In the past,residents relied on visual attributes in their descriptions of housing conditions...Forresidents who have experience in planning or housing issues, either through their com-munity activities or their professional employment, these changes are not problematic.For residents without such expertise, these changes constitute a signiﬁcant barrier to their participation in PPNA’s planning efforts. In Powderhorn Park, the residentswho are most affected by this shift in language and expertise are those who have traditionally been marginalized from neighborhood organizations – people of color,renters, senior citizens, and non-native English speakers. (Elwood 2002, p. 85)In this case, disempowerment was observed through the reconﬁguration of estab-lished community groups. Changes in the planning discourse associated with PGISaltered existing community power relationships. Disempowerment can also take placewhen government agencies limit data access to community groups that are deemedto be too radical. Sieber (2002), for example, came to the conclusion that in California:...research demonstrated that environmental groups use and value GIS...All [ﬁve]groups exhibit an indigenous demand for GIS, backed by a history of scientiﬁc andtechnical knowledge. A leader committed to championing GIS innovation, so critical ingovernment implementation, emerged in each of the cases. Improvisation demonstratedthat resources did not represent a barrier to GIS implementation. This was not thecase for acquiring digital data, however, which favored groups engaged in proactiveand non-confrontational agendas. (Sieber 2002, p. 169).The politics of data access were also observed in a project in the Ashanti Regionof Ghana. A PGIS was developed to help build collaborative forest managementand was successful in involving local “forest user groups” (Kwaku-Kyem 2002).But resistance from local elites was also observed as the “rich and powerful peoplein the community objected to the open and participatory uses of GIS. Some wereparticularly resentful of the inclusion on the forest committee of representatives oflocal farmers. The resentment about participatory uses of GIS could hinder futureadoptions of the technology for the empowerment of less privileged groups”(Kwaku-Kyam, 2002, p. 229).Unequal access to the Internet – and computer skills in general – also empowerand disempower simultaneously and are important considerations in Internet-basedPGIS initiatives. For example, Ventura, Niemann, Suttphin, and Chenoweth (2002)are involved in a very successful land use planning project in Wisconsin, in one ofthe fastest growing counties in the region. They are sponsoring local land-use forumsand innovative uses of the Internet with WebGIS to involve residents in county land-use planning. Community participation was impressive, but:...citizens come into the process with a relatively high level of computer acumen.Ninety-two percent of the participants in the land use forums had home computersand 70 percent had Internet access. Though these were citizens motivated to becomeTHO_C26  19/03/2007  11:27  Page 474 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPARTICIPATORY GIS475involved in county-wide land use issues, approximately the same percentages of accessto computers and the Internet were recorded in the survey of all households in theTown of Verona (Ventura, Niemann, Suttphin, and Chenoweth 2002, p. 122).A similar pattern was observed in Portland (Oregon) in a project concerned withgrowth management through land use and transportation planning (Bosworth,Donovan, and Couey 2002). Their innovative Metro-Map is an interactive web-basedapplication for accessing GIS data layers of metropolitan Portland and to enablepublic input. As with the Wisconsin example, participation is high, but is biasedtowards community members with home computer and Internet access.These case studies provide examples of how a diversity of PGIS applications impact community power relations and local decision-making. They also demon-strate the political nature of PGIS. To date, however, we have seen only glimpsesof this empowerment/disempowerment process. As a result, the speciﬁc mechan-isms by which PGIS empower and disempower people and communities remains a fundamental area for PGIS research.SUMMARY AND CONCLUSIONSThe marriage of community participation with GIS remains in its infancy. Never-theless, much has been learned and observed in the decade since the initial GIS 2was conceptualized. In this chapter, we offer some reﬂections about PGIS that canbe summarized with ten broad observations:1PGIS emerged out of an academic debate but have now become a spontaneousmerging of community development initiatives with new information techno-log",
    "chunk_order_index": 300,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-eb4a0461ac7e0cc07c5b2a0fdfee9a58": {
    "tokens": 1200,
    "content": "communities remains a fundamental area for PGIS research.SUMMARY AND CONCLUSIONSThe marriage of community participation with GIS remains in its infancy. Never-theless, much has been learned and observed in the decade since the initial GIS 2was conceptualized. In this chapter, we offer some reﬂections about PGIS that canbe summarized with ten broad observations:1PGIS emerged out of an academic debate but have now become a spontaneousmerging of community development initiatives with new information techno-logies. Differential access to digital geospatial technologies and the (re)discoveryof the power of maps are driving their rapid diffusion.2There are many forms of PGIS and they are emerging in all world regions.PGIS projects simultaneously empower and marginalize individuals and com-munities, contribute to the development of placed-based methodologies, promotemore inclusive community spatial decision-making, and incorporate multiplerealities of landscape.3PGIS in core industrialized regions are increasingly Internet-based spatial multi-media systems, whereas in underdeveloped regions they tend to be participatorydevelopment projects with an IT component. Furthermore, PGIS in the peri-phery tend to be participatory development projects with a GIS interface whereasin the core they tend to be GIS projects with a participation interface.4There has been a tendency to overstate the technical complexities of PGIS projects while the importance of political context – which is scale dependent– has been underestimated.5There is a need to distinguish between PGIS research that is academically intentioned and projects with the primary objective of community empower-ment. The intermediary technical expert remains a substantial part of the PGISprocess.THO_C26  19/03/2007  11:27  Page 475 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f476DANIEL WEINER AND TREVOR M. HARRIS6PGIS are purposefully value-laden and redeﬁne the meaning of “accuracy.”7PGIS are characterized by the creation and use of countermaps and narrativesthat help represent complex socio-economic, cultural, and political landscapes.Whether such mapping can be translated into real power and political inﬂu-ence remains to be seen though there are now intriguing case studies in whichPGIS augment place-speciﬁc political struggles by “jumping scale” (Aitken 2002,Stonich 2002).8An unintended but important and valuable outcome of early PGIS is that theyprovided a platform for integrating qualitative and quantitative information.This is signiﬁcant for social scientists because of the historic dualism betweenresearchers who employ qualitative methods and those who employ quantitativemethods, and because of the methodological difﬁculties in merging the two. PGIShighlights place, and does so in ways that conventional GIS normally do not.9Most current PGIS projects do not utilize GIS functionality for advanced spatialanalysis and are essentially participatory digital mapping projects. Internet mapping systems are likely to play a signiﬁcant role in future PGIS initiatives.Internet-based PGIS will further complicate the deﬁnition of a community andthe practices of participation. Virtual communities present signiﬁcant oppor-tunities and challenges as participation is broadened, but becomes placeless.Community participation from the home computer will ultimately transformPGIS in ways that we do not yet understand.10The primary challenges for the successful implementation of PGIS projects area complex web of technological, social, and political factors that are locallyconstituted and promote more inclusive spatial decision-making. To date, therehas been no systematic evaluation of the contribution of PGIS to local andregional spatial planning. This is understandable given that PGIS is only nowpenetrating the administrative and bureaucratic structures of planning agencies,development organizations, universities, NGOs, and the private sector. The monitoring and evaluation of projects over a longer time span will provideinsight into the effectiveness of such implementations (Barndt 2002).We have proposed in this chapter that GIS and Society debates concerning the diffusion of geospatial technologies shaped early PGIS applications. There is nouniversal PGIS model, but rather place-based methods that navigate local politicsand production relations. There is some concern, however, that the rapid growthof PGIS projects might be submerging a critical theory of GIS. PGIS is not a panacea,and must not undermine the robust debate and research agenda concerned withthe political economy, epistemology, philosophy, and contested practices of GIS.REFERENCESAbbot, J., Chambers, R., Dunn, C., Harris, T., de Merode, E., Porter, G., Townsend, J., andWeiner, D. 1998. Participatory GIS: Opportunity or oxymoron. PLA Notes33: 27–34.Aitken, S. C. 2002. Public Participation, technological discourses and the scale of GIS. InW. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation and GeographicInformation Systems. London: Taylor and Francis, pp. 357–66.THO_C26  19/03/2007  11:27  Page 476 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPARTICIPATORY GIS",
    "chunk_order_index": 301,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-12b2bc3b51b017376fd8460827bbf9f8": {
    "tokens": 1200,
    "content": ".THO_C26  19/03/2007  11:27  Page 476 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPARTICIPATORY GIS477Aitkin, S. and Michel, S. 1995. Who contrives the “Real” in GIS? Geographic information,planning, and critical theory. Cartography and Geographic Information Systems22:17–29.Al-Kodmany, K. 2002. GIS and the artist: Shaping the image of a neighborhood throughparticipatory environmental design. In W. J. Craig, T. M. Harris, and D. Weiner (eds)Community Participation and Geographic Information Systems. London: Taylor andFrancis, pp. 320–29.Barndt, M. 2002. A model for evaluating public participation GIS. In W. J. Craig, T. M. Harris,and D. Weiner (eds) Community Participation and Geographic Information Systems. London:Taylor and Francis, pp. 346–56.Bond, C. 2002. The Cherokee Nation and tribal uses of GIS. In W. J. Craig, T. M. Harris,and D. Weiner (eds) Community Participation and Geographic Information Systems. London:Taylor and Francis, pp. 283–93.Bosworth, M., Donovan, J., and Couey, P. 2002. Portland Metro’s dream for public involve-ment. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation andGeographic Information Systems. London: Taylor and Francis, pp. 125–36.Casey, L. and Pederson, T. 2002. Mapping Philadelphia’s neighborhoods. In W. J. Craig,T. M. Harris, and D. Weiner (eds) Community Participation and Geographic InformationSystems. London: Taylor and Francis, pp. 65–76.Chrisman, N. R. 1987. Design of geographic information systems based on social and cultural goals. Photogrammetric Engineering and Remote Sensing53: 1367–70.Craig, W. J. and Elwood, S. 1998. How and why community groups use maps and geo-graphic information. Cartography and Geographic Information Systems25: 95–104.Craig, W. J., Harris, T. M., and Weiner, D. 1999. Empowerment, Marginalization and PublicParticipation GIS.Santa Barbara, CA: National Center for Geographic Information andAnalysis, Varenius Specialist Meeting Report.Craig, W. J., Harris, T. M., and Weiner, D. (eds). 2002. Community Participation andGeographic Information Systems. London: Taylor and Francis.Dunn, C., Atkins, P., and Townsend, J. 1997. GIS for development: A contradiction in terms?Area29: 151–9.Edney, M. H. 1991. Strategies for maintaining the democratic nature of geographic infor-mation systems. Papers and Proceedings of the Applied Geography Conferences14:100–8.Elwood, S. 2002. The impacts of GIS use for neighborhood revitalization in Minneapolis.In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation and GeographicInformation Systems. London: Taylor and Francis, pp. 77–88.Elwood, S. and Leitner, H. 1998. GIS and community-based planning: Exploring the diversity of neighborhood perspectives and needs. Cartography and Geographic Informa-tion Systems25: 77–88.Fox, J., Suryanata, K., and Hershock, P. (eds). 2005. Mapping Communities: Ethics, Values,Practise. Honolulu, HI: East West Center.Gonzalez, R. M. 1995. KBS, GIS and documenting indigenous knowledge. IndigenousKnowledge and Development Monitor3(1) (available at http://www.nufﬁc.nl/ciran/ikdm/3-1/articles/gonzalez.html).Harris, T., Alagan, R., and Rouse, J. 2002. Geo-visualization approaches to PGIS decision-making in Environmental Impact Assessment. In Proceedings of the First Annual URISAPublic Participation GIS (PPGIS) Conference, Rutgers University, NJ, USA. Bedford Park,IL: Urban and Regional Information Systems Association, pp. 180–3.Harris, T. M. and Weiner, D. 1996. GIS and Society: The Social Implications of How People,Space and Environment are Represented in GIS.Santa Barbara, CA: National Center forGeographic Information and Analysis Scientiﬁc Report for Initiative No. 19.THO_C26  19/03/2007  11:27  Page 477 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f478DANIEL WEINER AND TREVOR M. HARRISHarris, T. M. and Weiner, D. 1998. Empowerment, marginalization and community-integratedGIS. Cartography and Geographic Information Systems25: 67",
    "chunk_order_index": 302,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e831e87357bd3c1b4c9e825a70d05b0b": {
    "tokens": 1200,
    "content": "/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f478DANIEL WEINER AND TREVOR M. HARRISHarris, T. M. and Weiner, D. 1998. Empowerment, marginalization and community-integratedGIS. Cartography and Geographic Information Systems25: 67–76.Harris, T. M. and Weiner, D. 2002. Implementing a community-integrated GIS: Perspectivesfrom South African ﬁeldwork. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Com-munity Participation and Geographic Information Systems. London: Taylor and Francis,pp. 246–58.Harris, T. M., Weiner, D., Warner, T., and Levin, R. 1995. Pursuing social goals throughparticipatory GIS: Redressing South Africa’s historical political ecology. In J. Pickles (ed.)Ground Truth: The Social Implications of Geographic Information Systems. New York:Guilford, pp. 196–222.Hawthorne, T. L., Dougherty, M., Elmes, G., Fletcher, C., McCusker, B., Pinto, M., andWeiner, D. 2006. Beyond the public meeting: Building a ﬁeld-based Participatory Geo-graphic Information System for land use planning in Monongalia County, West Virginia.In S. Balram and S. Dragicevic (eds) Collaborative Geographic Information Systems, Hershey,PA: Idea Group Inc., pp. 43–65.Hutchinson, C. F. and Toledano, J. 1993. Guidelines for demonstrating geographical informa-tion systems based on participatory development. International Journal of GeographicalInformation Systems7: 453–61.IIED. 2006. Special issue on mapping for change: Practice, technologies and communication.Participatory Learning and Action 54: 1–150.Jordan, G. 2002. GIS for community forestry user groups in Nepal: Putting people beforethe technology. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participa-tion and Geographic Information Systems. London: Taylor and Francis, pp. 232–45.Jordan, G. and Shrestha, B. 1998. Integrating Geomatics and Participatory Techniques forCommunity Forest Management: Case Studies from Yarsha Khola Watershed. Katmandu,Nepal, International Centre for Integrated Development.Kellog, W. 1999. From the ﬁeld: Observations on using GIS to develop a neighborhood environmental information system for community-based organizations. URISA Journal11(1):15–32.Kingston, R. 2002. Web-based PPGIS in the United Kingdom. In W. J. Craig, T. M. Harris,and D. Weiner (eds) Community Participation and Geographic Information Systems. London:Taylor and Francis, pp. 101–12.Kwaku-Kyem, P. 1999. Examining the discourse about the transfer of GIS technology totraditionally non-western societies. Social Science Computer Review17: 69–73.Kwaku-Kyem, P. A. 2002. Promoting local community participation in forest manage-ment through a PPGIS application in Southern Ghana. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation and Geographic Information Systems. London:Taylor and Francis, pp. 218–31.Laituri, M. 2002. Ensuring access to GIS for marginal societies. In W. J. Craig, T. M. Harris,and D. Weiner (eds) Community Participation and Geographic Information Systems. London:Taylor and Francis, pp. 270–82.Leitner, H., McMaster, R. B., Elwood, S., McMaster, S., and Sheppard, E. 2002. Modelsfor making GIS available to community organizations: Dimensions of difference and appro-priateness. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participationand Geographic Information Systems. London: Taylor and Francis, pp. 37–52.Levin, R. and Weiner, D. 1997. No more tears: Struggles for land in Mpumalanga, SouthAfrica. Trenton, NJ: Africa World Press.MacMaster, R. 2002. GIS and Society. Panel presentation at Annual Meeting of the Associ-ation of American Geographers, Los Angeles, CA, USA.McNab, P. 2002. There must be a catch: Participatory GIS in a Newfoundland ﬁshing com-munity. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation andGeographic Information Systems. London: Taylor and Francis, pp. 173–91.THO_C26  19/03/2007  11:27  Page 478 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPARTICIPATORY GIS479Marozas, B. A. 1993. A culturally relevant solution for the implementation of geographicinformation systems in Indian Country. In Proceedings of the Thir",
    "chunk_order_index": 303,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0689bda0b98bc4d2fe73c206fbbc2066": {
    "tokens": 1200,
    "content": "doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPARTICIPATORY GIS479Marozas, B. A. 1993. A culturally relevant solution for the implementation of geographicinformation systems in Indian Country. In Proceedings of the Thirteenth Annual Inter-national ESRI User Conference, San Diego, CA, USA. Redlands, CA: Environmental SystemsResearch Institute, Inc., pp. 365–81.Meredith, T. C., Yetman, G. G., and Frias, G. 2002. Mexican and Canadian case studiesof community-based spatial information management for biodiversity conservation. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation and GeographicInformation Systems. London: Taylor and Francis, pp. 205–17.Mitchell, A. 1997. Zeroing In:Geographic Information Systems at Work in the Community.Redlands, CA: ESRI Press.Obermeyer, N. and Pinto, J. 1994. Managing Geographic Information Systems. New York:Guilford.Openshaw, S. 1991. A view on the GIS crisis in geography, or, using GIS to put Humpty-Dumpty back together again. Environment and PlanningA23: 621–8.Parker, C. and Pascual, A. 2002. A voice that could not be ignored: Community GIS andgentriﬁcation battles in San Francisco. In W. J. Craig, T. M. Harris, and D. Weiner (eds)Community Participation and Geographic Information Systems. London: Taylor and Francis:55–64.Pickles, J. 1991. Geography, GIS, and the surveillant society. Papers and Proceedings of AppliedGeography Conferences14: 80–91.Pickles, J. (ed.) 1995. Ground Truth: The Social Implications of GIS. New York: Guilford.Pickles, J. 1999. Arguments, debates, and dialogues: The GIS-social theory debate and con-cerns for alternatives. In P. A. Longley, M. F. Goodchild, D. J. Maguire, and D. W. Rhind(eds) Geographical Information Systems: Principles, Techniques, Management, andApplications. New York: John Wiley and Sons, pp. 49–60.Rambaldi, G. and Callosa, J. 2000. Manual on Participatory 3-Dimensional Modeling forNatural Resource ManagementVol. 7. Manila: Philippines Department of Environmentand Natural Resources.Sawicki, D. S. and Burke, P. 2002. The Atlanta Project: Reﬂections on PPGIS practice. InW. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation and GeographicInformation Systems. London: Taylor and Francis, pp. 89–100.Sawicki, D. S. and Peterman, R. 2002. Surveying the extent of PPGIS practice in the UnitedStates. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation andGeographic Information Systems. London: Taylor and Francis, pp. 17–36.Schlossberg, M. and Shuford, E. 2004. Delineating public and participation in PPGIS. URISAJournal16(2): 15–26.Schroeder, P. 1996. Report on Public Participation GIS Workshop. In T. Harris and D. Weiner(eds) GIS and Society: The Social Implications of How People, Space and Environmentare Represented in GIS. Santa Barbara, CA: National Center for Geographic Informationand Analysis Technical Report No. 96–7.Sheppard, E.1993. GIS and society: Ideal and reality. In Proceedings of the NCGIA Geo-graphic Information and Society Workshop,Friday Harbor, WA, USA. Santa Barbara,CA: National Center for Geographic Information and Analysis.Sheppard, E., Couclelis, H., Graham, S., Harrington, J., and Onsrud, H. 1999. Geographiesof the information society. International Journal of Geographical Information Science13: 797–823.Shiffer, M. J. 2002. Spatial multimedia representations to support community participation.In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation and GeographicInformation Systems. London: Taylor and Francis, pp. 309–19.Sieber, R. E. 2000. Conforming (to) the opposition: The social construction of geographicalinformation systems in social movements. International Journal of Geographical InformationScience14: 775–93.THO_C26  19/03/2007  11:27  Page 479 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f480DANIEL WEINER AND TREVOR M. HARRISSieber, R. E. 2002. Geographic information systems in the environmental movement. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation and GeographicInformation Systems. London: Taylor",
    "chunk_order_index": 304,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-369afc47f2a019883d29d2951d4669a8": {
    "tokens": 1200,
    "content": "https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f480DANIEL WEINER AND TREVOR M. HARRISSieber, R. E. 2002. Geographic information systems in the environmental movement. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation and GeographicInformation Systems. London: Taylor and Francis, pp. 153–72.Stonich, S. C. 2002. Information technologies, PPGIS, and advocacy: Globalization of resistance to industrial shrimp farming. In W. J. Craig, T. M. Harris, and D. Weiner (eds)Community Participation and Geographic Information Systems. London: Taylor andFrancis, pp. 259–69.Talen, E. 1999. Constructing neighborhoods from the bottom up: The case for resident generated GIS. Environment and PlanningB26: 533–54.Talen, E. 2000. Bottom-up GIS. A new tool for individual and group expression in parti-cipatory planning. APA Journal66: 279–94.Taylor, P. J. and Overton, M. 1991. Further thoughts on geography and GIS. Environmentand PlanningA23: 1087–94.Tulloch, D. L. 2002. Environmental NGOs and community access to technology as a forcefor change. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participationand Geographic Information Systems. London: Taylor and Francis, pp. 192–204.Ventura, S. J., Niemann Jr. B. J., Suttphin, T. L., and Chenoweth, R. E. 2002. GIS-enhancedland-use planning. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participa-tion and Geographic Information Systems. London: Taylor and Francis, pp. 113–24.Walker, D. H., Leitch, A. M., De Lai, R., Cottrell, A., Johnson, A. K. L., and Pullar, D.2002. A community-based and collaborative GIS joint venture in rural Australia. In W. J. Craig, T. M. Harris, and D. Weiner (eds) Community Participation and GeographicInformation Systems. London: Taylor and Francis, pp. 137–52.Weiner, D. and Harris, T. 2003. Community-integrated GIS for land reform in South Africa.URISA Journal15: 61–73.Weiner, D., Warner, T., Harris, T. M., and Levin, R. M. 1995. Apartheid representationsin a digital landscape: GIS, remote sensing, and local knowledge in Kiepersol, South Africa.Cartography and Geographic Information Systems22: 30–44.THO_C26  19/03/2007  11:27  Page 480 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 27Geographic Information Systems andParticipatory Decision MakingPiotr Jankowski and Timothy L. NyergesDecision making is a fundamental part of Geographic Information System (GIS)use, particularly in the context of decision-making groups that are increasingly becom-ing agents of change within a variety of organizational, community, and societalsettings. Many of the intended changes, for example those involving implementa-tionof public-private policies about the use of common-pool resources, such as water,are mired in controversy. Locational conﬂict often arises due to peoples’ differencesin values, motives, and/or locational perspectives about what is to be accomplished.In such situations, conﬂict, and therefore negotiation management with shared deci-sion making, is a fundamental concern in coming to consensus about choices to bemade. Dealing with location-based resource conﬂicts in an open manner is becom-ing more important as stakeholder participation increases in land use, natural resource,and environmental decision making. The idea of participatory decision making isas old as democracy. Participatory decision making has exempliﬁed the democraticmaxim that those affected by a decision should participate directly in the decision-making process (Smith 1982).In the domain of local decisions affecting land use, transportation, access to publicspaces, and use of natural resources public participation was limited for a long timeto gathering input about decision alternatives that had already been prepared. Morerecently the idea of public participation in decision making has been enjoying arenaissance. Terms such as participatory spatial decision making, place-based deci-sion making or community participation in decision making, have been used to reﬂectthe idea of people taking an active role in decision-making processes concerning theirlocales. The renewed interest in public participation has been largely driven by boththe growing demand of communities for a greater say in decisions impacting on theirdaily lives and the growing involvement of various agents helping communities increase their participation in local decision making. Many of these efforts have beenonly partially successful due to a gap between communities’ knowledge, skills, andresources and those of problem domain experts and decision makers.Using geographic information technology to support public participation in locationaldecisions dates back to the beginning of the 1990s. In the Geographic InformationTHO_C27  19/03/2007",
    "chunk_order_index": 305,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-81ebb7f1701a28316a087fcc203562ff": {
    "tokens": 1200,
    "content": "greater say in decisions impacting on theirdaily lives and the growing involvement of various agents helping communities increase their participation in local decision making. Many of these efforts have beenonly partially successful due to a gap between communities’ knowledge, skills, andresources and those of problem domain experts and decision makers.Using geographic information technology to support public participation in locationaldecisions dates back to the beginning of the 1990s. In the Geographic InformationTHO_C27  19/03/2007  11:26  Page 481 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f482PIOTR JANKOWSKI AND TIMOTHY L. NYERGESScience (GISc) community much of it transpired through a series of research work-shops and specialist meetings sponsored by the National Center for Geographic Informa-tion Analysis (NCGIA) and organized in the USA between 1993 and 1998. Meetingsin the USA were paralleled by workshops in Europe. In the planning community anon-proﬁt organization – PlaceMatters – that promotes the development of decisionsupport tools for participatory community planning and design has been organizingconferences on “Tools for Community Decision Making and Design” since 1998.In this chapter we present concepts and methods for participatory decision makingsupported by geographic information technologies (GIT). We begin the chapter withan overview of empirical research on collaborative/group decision-making since thisserves as the precursor to research on the use GIT in support of participatory spatialdecision making.Conceptual and Empirical Foundations for Participatory Spatial Decision MakingThere are many arguments in the literature of decision making suggesting that moreparticipatory arrangements are likely to lead to greater effectiveness of decision pro-cesses – irrespective of which criterion of measuring the effectiveness is employed(Coenen, Huitema, and Toole 1998). Collaborative learning, shaping of preferences,and social construction of meaning through interpretative processes are seen as signiﬁc-ant beneﬁts of more open decision processes. Similarly, processes that involve partiesin conﬂict are seen as increasing the credibility and perceived legitimacy of resultingdecisions. Beneﬁts attributed to more open decision processes include considerationof diverse perspectives and interests resulting in better understanding of others’ views,and improvement in communication and cooperation through sharing values andinterests (Schneider, Oppermann, and Renn 1998).Group Support SystemsDevelopment of group support systems (GSS) technology (Coleman and Khanna1995), including group decision support systems (GDSS) (DeSanctis and Gallupe1987, Hwang and Lin 1987), as well as theoretical and empirical studies of its use(Gray, Alter, DeSanctis, et al. 1992, Jessup and Valacich 1993, Chun and Park 1998),have been carried out in the management and decision sciences since the early 1980s.Most of the empirical studies have been laboratory experiments conducted in con-ference room settings with subject groups using GDSS software. A major purposeof the experiments was to understand the implications of using decision-supportsoftware for group decision processes and decision outcomes. Chun and Park (1998)suggest that the results of these experiments, although mixed and inconclusive, pro-vide valuable insights into the effects of using group decision support software ongroup performance, group member attitudes, level of participation, and group conﬂict.They further suggest, predictably, that group performance, represented by decision time,depend on the familiarity of users with GDSS tools. They also suggest that there isno advantage of using GDSS for improving decision quality in simple problems. How-ever, the use of GDSS becomes advantageous in complex decision problems. UserTHO_C27  19/03/2007  11:26  Page 482 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND PARTICIPATORY DECISION MAKING483attitudes measured by user satisfaction with the decision process depend stronglyon the presence or absence of a group facilitator. The presence of a facilitator enhancesusers’ satisfaction with computer-supported decision processes. Another interestingﬁnding concerns heightened conﬂict level among groups supported by GDSS, to the contrary of an earlier supposition suggesting that the anonymity of electroniccommunications would increase the number of interpersonal exchanges and reducethe chance of one or a few “strong” individuals dominating a meeting. Yet, theanonymity feature, enabled by computer network-driven GDSS, can help emboldengroup members to communicate more forcefully, thus increasing the perception ofconﬂict in the group (Chun and Park 1998). In contrast to laboratory experiments,the results of the few ﬁeld studies reported in the literature are more consistent andpositive. They demonstrate both the increased decision quality and shortened meet-ing time when using GDSS as compared to conventional meetings (Chun and Park1998). They also demonstrate high user satisfaction and enhanced decision conﬁdenceindependent of prior user experience with a GDSS.Spatial Decision Support SystemsOn the heels of the above research, during the 1990s GIS and their offspring – spatial decision support systems (SDSS) – were suggested as GIT aids to supportdecision making for groups, including groups embroiled in environmental",
    "chunk_order_index": 306,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ba098516570ccfb550b71ca61a8dfb1c": {
    "tokens": 1200,
    "content": "increased decision quality and shortened meet-ing time when using GDSS as compared to conventional meetings (Chun and Park1998). They also demonstrate high user satisfaction and enhanced decision conﬁdenceindependent of prior user experience with a GDSS.Spatial Decision Support SystemsOn the heels of the above research, during the 1990s GIS and their offspring – spatial decision support systems (SDSS) – were suggested as GIT aids to supportdecision making for groups, including groups embroiled in environmental conﬂict(Godschalk, McMahon, Kaplan, and Qin 1992, Armstrong 1993, Faber, Knutson,Watts, et al. 1994, Faber, Wallace, and Cuthbertson 1995, Couclelis and Monmonier1995, Heywood, Oliver, and Tomlinson 1995). Clearly, research concerning col-laborative decision making for geographically oriented public policy problems continues to gain momentum (Shiffer 1992, Densham, Armstrong, and Kemp 1995,Nyerges, Moore, Montejano, and Compton 1998a, Nyerges, Oshiro, and Dadswell,Reitsma 1996, Reitsma, Zigurs, Lewis, Wilson, and Sloane 1996, Kingston, Carver,Evans, and Turton 2000, Jankowski and Nyerges 2001b, Craig, Harris, and Weiner2002). Reducing the complexity of a decision process by reducing the cognitive workload of decision makers is one goal of developing GIS capabilities for par-ticipatory decision-making. Reducing cognitive workload will hopefully lead to a more thorough treatment of information, exposing initial assumptions more clearly, and subsequently resulting in more participatory decisions (Obermeyer andPinto 1994).A fruitful approach to developing GIS capabilities for participatory decision making is to learn through experimental studies about human–computer–humaninteractions during collaborative decision processes. Reitsma, Zigurs, Lewis, Wilson,and Sloane (1996), Stasik (1999), Jankowski and Nyerges (2001a), report on laboratory experiments and Nyerges, Jankowski, Tuthill, and Ramsey (2006), and Jankowski, Nyerges, Robischon, Tuthill, and Ramsey (2006) report on ﬁeld experiments with GIS tools that support participatory decision making. In termsof comparability across the experiments, their results underscore that groupswould rather have facilitators and/or chauffeurs help them work through prob-lems. Individuals having access to technology in the Reitsma experiment were frustrated with the complexity of the software. In land use planning experimentsconducted by Stasik, the role of facilitator was partially fulﬁlled by a computer THO_C27  19/03/2007  11:26  Page 483 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f484PIOTR JANKOWSKI AND TIMOTHY L. NYERGESserver, which managed the collaboration process. The participants expressed a strongpreference for making a complex collaborative spatial decision support softwarethat they used as easy as a standard WWW browser. Many of them essentially wantedthe software to look and act as a standard WWW browser. In the laboratory exper-iment concerned with the selection of habitat restoration sites in the DuwamishWaterway of Seattle, Washington, Jankowski and Nyerges (2001a) found out that different phases of the decision process had two different levels of conﬂict: an exploratory–structuring phase characterized by a lower level of conﬂict and an analytic–integrating phase characterized by a high conﬂict level. The higher levelof conﬂict during the analytic–integrating phase tells us that decision aids aimed atconﬂict management are likely to help participants work through conﬂict; especiallynow that conﬂict is recognized as a necessary part of making progress in publicdecision problems. The same two authors and their colleagues conducted more recentlya ﬁeld experiment study of groups using spatial decision support tools in develop-ing decision alternatives for conjunctive administration of water resources in theBoise River Basin in Idaho. They found that decision support tools, such as tables,maps, graphs, and Structured Query Language (SQL) queries, if operated only bya facilitator, are likely to result in group members engaging more in deliberationthan in data analysis. Additionally, they observed that full facilitation, includingboth the group process and handling of decision support software by a facilitator,promotes a higher level of consensus, most likely because there are more oppor-tunities for deliberation among participants. However, fewer options are exploredthan in a situation, in which facilitation involves primarily a group decision pro-cess and group members operate decision support tools. Such participant-driven decision support settings promote generation and exploration of more options atthe expense of group consensus.The aforementioned studies about participatory decision making for geograph-ically oriented public policy problems offer guidelines for the design of GITs forparticipatory decision making, such that:1The tools for participatory decision making should offer decisional guidance tousers in the form of an agenda.2The tools should not be restrictive but rather allow the users to select tools andprocedures in any order.3The tools should be comprehensive within the realm of spatial decision prob-lems and thus offer a number of decision space exploration tools and evaluationtechniques.4The user interface should",
    "chunk_order_index": 307,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e1ff567cee796f87eb7b55ffc743a21a": {
    "tokens": 1200,
    "content": "public policy problems offer guidelines for the design of GITs forparticipatory decision making, such that:1The tools for participatory decision making should offer decisional guidance tousers in the form of an agenda.2The tools should not be restrictive but rather allow the users to select tools andprocedures in any order.3The tools should be comprehensive within the realm of spatial decision prob-lems and thus offer a number of decision space exploration tools and evaluationtechniques.4The user interface should be both process and data oriented allowing an equallyeasy access to task-solving techniques as well as maps and data visualizationtools.5The tools should be capable of supporting facilitated meetings and hence allowfor the information exchange to proceed among group members and between groupmembers and the facilitator. It should also support space- and time-distributedcollaborative work by facilitating information exchange, electronic submissionof solution options, and voting.6Tool functionality should be capable of supporting participatory exploratory-structuring and analytic-integrating phases of a decision process.THO_C27  19/03/2007  11:26  Page 484 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND PARTICIPATORY DECISION MAKING485Frameworks for using information technologies to supportparticipatory decision makingThere is a wide array of frameworks about decision making. The literature includesmanagerial (Simon 1977), public participation (Renn, Webler, Rakel, Dienel, andJohnson 1993), landscape planning (Steinitz 1990), environmental (Dobson, Urban,and Kelly 1998) and community-based (Electrical Power Research Institute 1998)decision-making frameworks.Simon (1977) recognizes that the four steps: intelligence, design, choice, and revieware essential tasks as part of individual decision making in an organizational con-text. Renn, Webler, Rakel, Dienel, and Johnson (1993) have used a three-step pro-cess: criteria development, options generation, and options evaluation, in publicparticipatory decision making in both the USA and Germany to help recommendenvironmental policy. Steinitz (1990) sees six steps in modeling for landscape planning, which include representation models, process models, evaluation models,change models, impact models, and decision models. Dobson, Urban, and Kelly (1998) describe a sequence of tools for data gathering and analysis that could includemore or fewer steps depending on the situation at hand. The Electrical Power ResearchInstitute (1998) recommends using their SmartPlaces Series E GIS (oriented to com-munity development decision making) as part of a ten-step process. The NationalResearch Council effort concerning analytic–deliberative decision making about risk-oriented hazards suggested that multiple groups be involved in such processes, andthat the processes should be determined by the groups being convened. The pointis that each of the above strategies consists of a variable number of steps that areappropriate for a variety of decision situations.There is something systematic about each of the steps in the above decision frame-works. Bhargarva, Krishnan, and Whinston (1994) articulated the idea that Simon’s(1977) steps of intelligence, design, and choice each had within them an iterativeprocess of intelligence, design, and choice. That is, when undertaking an intelli-gence step for decision making, it is natural that people pursue intelligence (that is,gathering information), design (that is, organizing information), and choice (thatis, selecting information). The same would occur for the subsequent steps of designand choice, that is to say each has within it, intelligence, design, and choice. As such,complex decision processes are recursive at two levels: a conceptual level involvingprocess steps, and a task level involving details of each step. Jankowski and Nyerges(2001b) used these two levels to formulate a macro–micro frameworkfor organiz-ing participatory decision processes supported by GIT. The macrocomponent of theframework is ﬂexible and depends on the decision problem at hand, informationneeds, participation dynamics, goals, and objectives of decision process convenersand participants, and organizational context. Any of the frameworks mentionedabove could be used to provide steps for the macro component. Although differentmacro-steps are likely to be appropriate for different contexts, a micro-strategy isnonetheless at play for each macro-step associated with a work task. That micro-stepstrategy, encouraged by fundamentals of human information processing, includesgathering, organizing, selecting, and reviewing information.The macro–micro perspective allows us to appreciate that every macro-phase in amacro strategy can have a different set of information needs, based on the collectiveTHO_C27  19/03/2007  11:26  Page 485 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f486PIOTR JANKOWSKI AND TIMOTHY L. NYERGESneeds of the micro-step activities. Consequently, a macro–micro decision strategymotivates the requirements for decision support tools. Such information needs andthe associated decision support tool requirements can only be addressed by a goodunderstanding of the decision situation at the time and place (context) within whichit occurs.Methods for GIS-supported Participatory Decision Making",
    "chunk_order_index": 308,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-dcfb73c5ff986acf998297e4413449ff": {
    "tokens": 1200,
    "content": "use; OA articles are governed by the applicable Creative Commons License\f486PIOTR JANKOWSKI AND TIMOTHY L. NYERGESneeds of the micro-step activities. Consequently, a macro–micro decision strategymotivates the requirements for decision support tools. Such information needs andthe associated decision support tool requirements can only be addressed by a goodunderstanding of the decision situation at the time and place (context) within whichit occurs.Methods for GIS-supported Participatory Decision MakingThe macro–micro framework can be used to formulate a speciﬁc macro–micro decision strategy guiding the selection of participatory decision support tools. One such strategy, ﬁtting many participatory decision problems, can be formulatedby synthesizing the Renn, Webler, Rakel, Dienel, and Johnson (1993) three-steppublic-participation decision process with the Simon (1977) three-step process forthe macro-level of a macro–micro decision strategy. The decision strategy consists ofthree macro phases – Intelligence on Criteria, Design of Options Set, and Choiceof Options (Simon 1977, Renn, Webler, Rakel, Dienel, and Johnson 1993); eachphase composed of four micro activities: Gather, Organize, Select, and Review (Simon1977, Bhargarva, Krishnan, and Whinston 1994). It is possible to use this strategyto relate types of decision support methods and tools to the phase activities as pre-sented in Table 27.1 (Jankowski and Nyerges 2001b).Each cell in the table contains a speciﬁc method/tool, which we identiﬁed as poten-tially useful for supporting a speciﬁc phase activity. Some methods/tools addressPhase 1, as for example with representation aidsthat organize discussions and/orpresent information about goal(s) and objective(s). Other methods/tools might helpwith structuring a problem in Phase 2, in the sense of designing an approach foranalysis and generating options. This is where GIS plays a signiﬁcant role, startingout with the computations necessary to manipulate spatial characteristics of deci-sion options. Then, in Phase 3, decision analysis methods help with evaluating options,as in the case of choice modelsand judgment reﬁnement techniques. Consequently,a suite of methods/tools is likely to be needed to address complex decision prob-lems, since no single method/tool addresses all phases.In the intelligence phase of the decision process the Activity Phases 1A–1D aremeant to encourage the articulation of values, objectives, criteria, constraints, andstandards for characterizing solutions. The methods and tools potentially useful for these activity phases are:1Information managementand structured-groupprocess techniquesthat help gather participant input on values underlying the decision process from whichgoals and objectives can be determined.2Representation aidsthat help organize goal and objectives into structures thatcan be analyzed and symbolized using text and graphics.3Group collaboration support methodsthat help select criteria on the bases ofobjectives, and articulate those criteria in terms of measurements.4Group collaboration support methodsthat aid in the review of criteria, con-straints, and standards for option generation.THO_C27  19/03/2007  11:26  Page 486 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND PARTICIPATORY DECISION MAKING487The intelligence phase can be supported by open group discussion, but more commonly stakeholder interviews have been performed to gather information about values. The goal is to draw out ideas and synthesize them for each stakeholder group.In organizing the material from stakeholder interviews information managementtechniquescan be useful. An example of a useful technique is “value tree analysis”(von Winterfeldt 1987). Value trees are hierarchical (tree-like) representations ofvalues, objectives, and criteria, where values are roots, objectives are nodes to branches,and criteria are leaves at the ends of branches. Objectives stem from values as concerns that are to be considered. Criteria, stemming from objectives, are measur-able characteristics for evaluating performance of options. The “tree” is a way oforganizing ideas/issues into a hierarchy of values, objectives, and criteria. Once thevalues, objectives, and criteria have been identiﬁed for each stakeholder group and represented as a “value tree,” then it is recommended that the individual treesbe consolidated into an overall tree so that all groups know where they “stand”in regards to overall concerns. Some roots, branches (nodes) might be shared and others might not.Table 27.1Methods and tools for GIT-supported participatory decision-making derivedmacro–micro decision strategyMicro – Decision Strategy ActivitiesA GatherB OrganizeC SelectD ReviewMacro – Decision Strategy Phases1 Intelligence about values, objectives, and criteriaParticipant input on values, goals, and objectives using information management, and structured-group process techniquesGoals and objectives using representation aidsCriteria to be used in decision process using group collaboration support methodsCriteria, resources, constraints, and standards using group collaboration support methods2 Design of a feasibleoption setData and models (GIS and spatialanalysis, processmodels, optimization,simulation) to generateoptionsSynthesis of decisionoptions usingstructured-groupprocess techniques and modelsDecision options fromoutcomes generated by group processtechniques and modelsDecision options andidentify feasible optionsusing informationmanagement and choice models3 Choice aboutdecision optionsValues, criteria andfeasible decisionoptions using groupcollaboration supportmethodsValues, criteria, andfeasible decisionoptions using choicemodelsGoal- and consensus-achieving",
    "chunk_order_index": 309,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-38b13b0ff064c77c441104fba86d7a8b": {
    "tokens": 1200,
    "content": "option setData and models (GIS and spatialanalysis, processmodels, optimization,simulation) to generateoptionsSynthesis of decisionoptions usingstructured-groupprocess techniques and modelsDecision options fromoutcomes generated by group processtechniques and modelsDecision options andidentify feasible optionsusing informationmanagement and choice models3 Choice aboutdecision optionsValues, criteria andfeasible decisionoptions using groupcollaboration supportmethodsValues, criteria, andfeasible decisionoptions using choicemodelsGoal- and consensus-achieving decisionoptions using choicemodelsRecommendation(s)of decision optionsusing judgmentreﬁnement techniquesTHO_C27  19/03/2007  11:26  Page 487 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f488PIOTR JANKOWSKI AND TIMOTHY L. NYERGESIf the process of eliciting values, objectives, and criteria were to take place in a collaborative setting, rather than through stakeholder interviews, then structured-group process techniquescould likely be useful. One such structured-group processtechnique is the Technology of Participation (ToP) developed and used by the Institutefor Cultural Affairs (Spencer 1989). ToP helps people share an understanding ofwhat is at issue by attempting to generate consensus during strategic planning through a four-step process that aims to (1) generate and cluster ideas from everyone,(2) identify constraints and barriers that might impinge on those issues, (3) prioritizeissues in line with the constraints, and (4) ﬂesh out a plan developed from the prioritized issues. Value trees can be constructed off-line by processing stakeholderinterviews, or they may be constructed on-line with support of a structured-groupprocess technique.In the review activity, a decision is made as to whether a single, consensus-basedset of criteria will be used or multiple (stakeholder) sets of criteria will be used in thedesign phase involving options generation. If a single set, then which set, or a com-bined set? This review might involve negotiation among the groups to see whichcriteria, hence objectives, hence values, move forward to the next phase. In a sense thisis actually negotiation of a problem deﬁnition, as certain criteria (called attributesin a GIS context) will describe options differently to how other criteria (attributes)would describe them. This negotiation leads to specifying types of options that would be considered as feasible solutions to the problem and can be aided by groupcollaboration support methodssuch as Delphi combined with mediation. Delphi isa method for systematically developing and expressing the views of participants.The method involves a series of questioning rounds. Structured questionnaires aresubmitted to the participants listing pros and cons of the criteria being considered.The results of the responses are described in terms of numbers of respondents whohold each position, and are then returned to the participations along with a newquestionnaire especially developed for the next round. After several cycles of judgmentand feedback, there is usually some convergence toward a common set of goals. Ifdifﬁculties appear, a mediation process can be used to help arrive at an agreement.The mediator must be neutral and perceived as such by all participants. The par-ticipants work toward reaching a consensus. The third party makes suggestions forpossible compromise positions and otherwise helps the participants to negotiate.In the design phase (Phase 2) it is appropriate to allow each group to generatethe options they feel can address the goal of the decision problem in line with thecriteria that have been established. To do this, groups would:1Gather dataabout the outcomes of criteria to be used as a basis for option generation, that is, criteria which drive the generation of scenarios that becomedecision options; different types of modelscan also generate the data;2Organize and apply an approach for generating feasible options using one ormore structured-group process techniquesor computer models– structured-groupprocess techniques may include brainstorming, Delphi, or ToP; models may rangefrom suitability models implemented in GIS to optimization models generatingdecision option scenarios that satisfy the decision objectives;3Select the full array of options to be considered, despite immediate constraints,resources, and standards identiﬁed in activity-phase 1D;THO_C27  19/03/2007  11:26  Page 488 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND PARTICIPATORY DECISION MAKING4894Review the option set(s) in line with constraints, resources, and standards fromActivity Phase 1D and select feasible decision options. Information managementtools and choice models can support the selection of feasible options.In the design phase, groups work in Activity Phase 2A to identify the basis forcreating options. Primary attribute(s) are used to identify options, differentiatingamong fundamental choices ﬁrst, and then identifying secondary attributes that areused in determining “feasibility.” For example, a “land” parcel is a primary attributethat once set, allows a decision analyst to examine the entire range of land parcelsfor feasible options. In Activity Phase 2B various techniques can be used to processthe secondary attributes (for example, parcel size, cost per hectare, tax rate, etc.)to establish a feasibility (minimum threshold) for each option to be included in the feasible set. Examples",
    "chunk_order_index": 310,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-1faaccae8b89b00a0c592bd0e9a1a9ec": {
    "tokens": 1200,
    "content": "then identifying secondary attributes that areused in determining “feasibility.” For example, a “land” parcel is a primary attributethat once set, allows a decision analyst to examine the entire range of land parcelsfor feasible options. In Activity Phase 2B various techniques can be used to processthe secondary attributes (for example, parcel size, cost per hectare, tax rate, etc.)to establish a feasibility (minimum threshold) for each option to be included in the feasible set. Examples of these techniques include decision option enumerationthrough group conversation, standards articulation and minimum thresholds, GISanalysis, and/or modeling such as location-allocation optimization analysis. No single tool has surfaced that speciﬁes the “best way” to identify options, but GISis a tool that has grown in use because it allows large data sets to be processed toﬁnd feasible options. The use of a technique must properly match the character ofa decision situation to be effective. For example, a location-allocation model can beused to identify “optimal” options under varying conditions of an objective function.Those options might be the “best cases” to be used in starting a search for decisionoptions, relaxing the objective function to one of satisﬁcing rather than optimizing.Thus, the challenge of Activity Phase 2B is to have participants recognize whichkind of problem they are facing, in addition to what data are available, in orderto provide the most effective decision support for option generation. The ActivityPhase 2C has participants listing the full array of feasible options. This list mightcome from various stakeholder groups, or it might have been generated as the resultof considering different parameters and constraints in models describing a decisionsituation. During Activity Phase 2D participants from different groups can cometogether to share an understanding of the different options that each sees as feasibleoptions for the problem. The activity is one of reviewing the principal goal of theprocess, understanding that certain equitable concerns might need to be addressed.The equitable concerns might in fact be “geographic area” related, but are likelyidiosyncratic to the decision situation at hand. Because of these differences it is possible to conceive of various scenarios that might be generated, each scenariohaving an option set associated with it. An example here can be a transportationinfrastructure improvement scenario comprised of a number of speciﬁc improvementprojects. The result of Phase 2 could be a plan describing one or more scenarios eachwith option set(s) for consideration in Phase 3.The choice phase (Phase 3) involves evaluation of the option set(s), within oneor more scenarios. In general the evaluation process involves the following phaseactivities:1Gathering information using group collaboration support methods about howto proceed with evaluation of decision options based on values and criteria arti-culated in Phase 1 and options identiﬁed in Phase 2;2Organizing an approach to evaluating decision options using choice models;THO_C27  19/03/2007  11:26  Page 489 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f490PIOTR JANKOWSKI AND TIMOTHY L. NYERGES3Selecting a prioritized/ordered list of options, using choice models, consensusbuilding, negotiation, mediation, or arbitration;4Reviewing how the recommendation(s) address decision situation goal(s) in linewith values consideration, using judgment reﬁnement techniques.In activity phase 3, decision participants gather information from Phase 1 in termsof values and criteria to be considered and from Phase 2 in terms of option set(s)for one or more scenarios. At this time it is possible that various stakeholder groups might elect to enter into discussion about what values, objectives, criteria,resources, constraints, and option lists have been identiﬁed to this point before evaluation (in many cases a negotiated evaluation) takes place. A value and criteriaassessment is a good lead into the prioritization of options that takes place withina group. Next, in Activity Phase 3 participants might use GIS and/or multiple criteria choice models. Standard GIS operations only allow performing a non-compensatory evaluation of decision options. That is, a threshold range(s) is setfor one or more criteria, and all options that fall within that range pass throughthe “ﬁlter.” With choice models, a compensatory (tradeoff) analysis can be per-formed. In compensatory analysis, when evaluating a decision option, a satisfactoryoutcome for a high priority criterion can “compensate” for less than satisfactory out-comes on lower priority criteria. For example, less than desirable size of a given landparcel can be compensated by a favorable tax rate. In Activity Phase 3 “selecting achoice” can be accomplished through option evaluation using choice models, con-sensus voting, negotiation, mediation, and/or arbitration. Consensus voting combinesthe prioritized lists of all separate stakeholder groups. Such a consensus vote mightbe the start of a negotiation process. Negotiation might involve taking the overalllist of priorities as a start and then discussing how one option might move aboveanother if certain of the criteria were weighted in a different way. Option sets might be devised to help with this negotiation. Such sets could be developed as an “equity agreement” whereby certain options from a given area are discussed inrelation to each other, but the options in different sets are not discussed in relationto each other. That is, “if you get one, then I get one, and so does she.” Alternat-ively, the participants might turn to mediation or arbitration to affect a decision.When negotiation does not work",
    "chunk_order_index": 311,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-90b01a7ef5ad06a1f0932a3368678209": {
    "tokens": 1200,
    "content": "weighted in a different way. Option sets might be devised to help with this negotiation. Such sets could be developed as an “equity agreement” whereby certain options from a given area are discussed inrelation to each other, but the options in different sets are not discussed in relationto each other. That is, “if you get one, then I get one, and so does she.” Alternat-ively, the participants might turn to mediation or arbitration to affect a decision.When negotiation does not work, mediation using a third party go-between mightprove beneﬁcial. The third party helps to balance the negative feelings between the (commonly) two perspectives (sides). Having more perspectives complicates the mediation process even further. Discussing the differences using “decision aids” canhelp externalize the disagreements before agreement is reached. Regardless of whatparty establishes the recommended decision outcome, a review takes place. Such areview can be supported by judgment reﬁnement techniques. Judgment reﬁnementand ampliﬁcation techniques facilitate a “what-if” analysis of impacts on the selecteddecision option in response to changes in assumptions and baseline conditions. A common approach to facilitate judgment reﬁnement is sensitivity analysis. Manyimplementations of multiple criteria evaluation techniques provide sensitivity analysiscapability by which a user can change his/her preferences and observe the consequencesof such change on the solution. During the review of recommended choice(s) inActivity Phase 3, the options are discussed in terms of the original values devisedfrom Phase 1.THO_C27  19/03/2007  11:26  Page 490 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND PARTICIPATORY DECISION MAKING491The above decision process is but one of many normative processes that can beestablished as an agenda agreed upon by participants – or at least the convener andthose responsible for the process. A different set of macro phases might shorten orlengthen the process agenda in different situations. In any case, no matter how manymacro phase steps might exist, the micro activities for each phase set the stage forrequirements analysis of information needs.CONCLUSIONSBoth large and small groups are increasingly acting as agents of change in society.Since externalities resulting from the impacts of peoples’ activities on each other andthe environment are increasing, and approval of corrective action is increasinglyparticipatory, GIS support for participatory decision making is likely to increasesubstantially. All techniques that are invented for single user GIS, can be used in aparticipatory setting. When we add the need for communications technology to struc-tured participation technology to decision modeling software technology, and all thatto the standard GIS technology, we then arrive at the functionality needed to supportgroups. Systematic evaluation of that technology is needed to ensure that the softwareintegration problem is tackled in a manner that efﬁciently, effectively and equitablysupports groups both large and small. Systematic evaluation through empirical studiesprovides evidence to improve the guidelines for participatory system designs.REFERENCESArmstrong, M. P. 1993. Perspectives on the development of group decision support systemsfor locational problem solving. Geographical Systems1: 69–81.Bhargarva, H. K., Krishnan, R., and Whinston, A. D. 1994. On integrating collaborationand decision analysis techniques. Journal of Organizational Computing4: 297–316.Chun, K. J. and Park, H. K. 1998. Examining the conﬂicting results of GDSS research.Information and Management33: 313–25.Coenen, F., Huitema, D., and Toole, L. J. O. 1998 Participation and Environment. Dordrecht:Kluwer.Coleman, D. and Khanna, R. 1995. Groupware: Technologies and Applications. Upper SaddleRiver, NJ: Prentice Hall.Couclelis, H. and Monmonier, M. 1995. Using SUSS to resolve NIMBY: How spatial understanding support systems can help with the “not in my back yard” syndrome.Geographical Systems2: 83–101.Craig, W. J., Harris, T., and Weiner, D. 2002. Community Participation and GeographicInformation Systems. London: Taylor and Francis.Densham, P. J., Armstrong, M. P., and Kemp, K. 1995. Report from the Specialist Meet-ing on Collaborative Spatial Decision Making.Santa Barbara, CA: National Center forGeographic Information and Analysis.DeSanctis, G. and Gallupe, R. B. 1987. A foundation for the study of group decision supportsystems. Management Science33: 589–609.Dobson, J. E., Urban, R. D., and Kelly, J. L. 1998. EnvironAid: A Proposed ConceptualDesign for a National Environmental Decision-making Information Infrastructure.Knoxville,TN: National Center for Environmental Decision-Making Report No. 98-05.THO_C27  19/03/2007  11:26  Page 491 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f492PIOTR JANKOWSK",
    "chunk_order_index": 312,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-919a64d511f62aa5dcb21955633106c4": {
    "tokens": 1200,
    "content": "27  19/03/2007  11:26  Page 491 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f492PIOTR JANKOWSKI AND TIMOTHY L. NYERGESElectrical Power Research Institute. 1998. Smart Places: Intelligent Solutions for Commerce.WWW document, http://www.smartplaces.com.Faber, B., Knutson, J., Watts, R., Wallace, W., Hautalouma, J., and Wallace, L. 1994. AGroupware-enabled GIS. In Proceedings of the Eighth Annual Symposium on GeographicInformation Systems (GIS’94), Vancouver, British Columbia. Fort Collins, CO: GISWorld Inc.Faber, B., Wallace, W., and Cuthbertson, J. 1995. Advances in collaborative GIS for land resource negotiation. In Proceedings of the Ninth Annual Symposium on GeographicInformation Systems (GIS’95), Vancouver, British Columbia. Fort Collins, CO: GISWorld Inc.Godschalk, D. R., McMahon, G., Kaplan, A., and Qin, W. 1992. Using GIS for computer-assisted dispute resolution. Photogrammetric Engineering and Remote Sensing58:1209–12.Gray, P., Alter, S. L., DeSanctis, G., Dickson, G. W., Johansen, R., Kraemer, K. L., Olfman, L., and Vogel, D. R. 1992. Group Decision Support Systems. In E. A. Stohr andB. R. Konsynski (eds) Information Systems and Decision Processes.Los Alimitos, CA: IEEEPress: 75–135.Heywood, D. I., Oliver, J., and Tomlinson, S. 1995. Building an exploratory multi-criteriamodeling environment for spatial decision support. In P. Fisher (ed.) Innovations in GIS.London: Taylor and Francis, pp. 127–36.Hwang, C. and Lin, M. 1987. Group Decision Making Under Multiple Criteria. New York:Springer-Verlag Lecture Notes in Economics and Mathematical Systems No. 281.Jankowski, P. and Nyerges, T. 2001a. GIS-Supported collaborative decision making: Resultsof an experiment. Annals of the Association of American Geographers91: 48–70.Jankowski, P. and Nyerges, T. 2001b. Geographic Information Systems for Group DecisionMaking. London: Taylor and Francis.Jankowski, P., Robischon, S., Tuthill, D., Nyerges, T., and Ramsey, K. 2006.Design con-siderations for collaborative, spatio-temporal decision support systems. Transactions in GIS10: 335–54.Jessup, L. and Valacich, J. 1993. Group Support Systems: New Perspectives. New York:Macmillan.Kingston, R., Carver, S., Evans, A., and Turton, I. 2000. Web-based public participationgeographical information systems: An aid to local environmental decision-making.Computers, Environment and Urban Systems24: 109–25.Nyerges, T., Moore, T. J., Montejano, R., and Compton, M. 1998. Interaction coding sys-tems for studying the use of groupware. Journal of Human-Computer Interaction13: 127–65.Nyerges, T., R. M., Oshiro, C., and Dadswell, M. 1998. Group-based geographic informa-tion systems for transportation site selection. Transportation Research C: EmergingTechnologies5: 349–69.Nyerges, T., Jankowski, Tuthill, D., and Ramsey, K. 2006. Collaborative water resource decision support: Results of a ﬁeld experiment. Annals of the Association of AmericanGeographers96: 699–725.Obermeyer, N. and Pinto, J. 1994. Managing Geographic Information Systems. New York:Guilford.Reitsma, R. 1996. Structure and support of water-resources management and decision making. Journal of Hydrology177: 253–68.Reitsma, R., Zigurs, I., Lewis, C., Wilson, V., and Sloane, A. 1996. Experiment with simula-tion models in water-resources negotiation. Journal of Water Resources Planning andManagement122: 64–70.Renn, O., Webler, T., Rakel, H., Dienel, P., and Johnson, B. 1993. Public participation indecision making: a three-step procedure. Policy Sciences26: 189–214.THO_C27  19/03/2007  11:26  Page 492 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND PARTICIPATORY DECISION MAKING493Schneider, E., Oppermann, B., and Renn, O. 1998. Implementing structured participationfor regional level waste management planning. Risk: Health, Safety and Environment9:379–95.Shiffer, M.",
    "chunk_order_index": 313,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-36c7a9f09285a6817f9bd19d5a172db0": {
    "tokens": 1200,
    "content": "]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS AND PARTICIPATORY DECISION MAKING493Schneider, E., Oppermann, B., and Renn, O. 1998. Implementing structured participationfor regional level waste management planning. Risk: Health, Safety and Environment9:379–95.Shiffer, M. J. 1992. Towards a collaborative planning system. Environment and PlanningB19: 709–22.Simon, H. 1977. The New Science of Management Decision (3rd edn). Englewood Cliffs,NJ: Prentice-Hall.Smith, L. G. 1982. Alternative mechanisms for public participation in environmental policy-making. Environments14: 21–34.Spencer, L. 1989. Winning through Participation. Dubuque, IA: Kendall/Hunt.Stasik, M. I. 1999. Collaborative Planning and Decision Making under Distributed Spaceand Time Conditions. Unpublished PhD Dissertation, Department of Geography, Univer-sity of Idaho.Steinitz, C. 1990. A framework for theory applicable to the education of landscape architects(and other design professionals). Landscape Journal9: 136–43.Von Winterfeldt, D. 1987. Value tree analysis: An introduction and an application to offshore oil drilling. In P. R. Kleindorfer and H. C. Kunreuther (eds) Insuring andManaging Hazardous Risks: From Seveso to Bhopal and Beyond.Berlin: Springer-Verlag:349–85.THO_C27  19/03/2007  11:26  Page 493 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 28Surveys of People and PlacePeter H. DanaThis chapter uses examples from recent participatory mapping projects in CentralAmerica to illustrate the dynamic interplay between conceptions of people and placeand the methods used to survey them. Surveyors, census takers, and map makershave long been characterized as agents of power. J. B. Harley suggested in a work-shop twenty years ago that “as much as guns and warships, maps have been theweapons of imperialism” and that “surveyors marched alongside soldiers, initiallymapping for reconnaissance, then for general information, and eventually as a toolof paciﬁcation, civilization, and exploitation of the deﬁned colonies” (Harley 1988,p. 282). More than a dozen years ago Benedict Anderson reminded us, in the con-text of colonial nation-building, that the map and the census “shaped the grammarthat would in due course make possible ‘Burma’ and ‘Burmese,’ ‘Indonesia’ and‘Indonesian’” (Anderson 1991, p. 185). Mark Monmonier coupled the idea that“the map is the perfect symbol of the state” with his caustically worded assertionthat “maps made it easy for European states to carve up Africa and other heathenlands, to lay claim to land and resources, and to ignore existing social and politicalstructures” (Monmonier 1991, p. 90). In the past few years individuals, communities,and special interest groups of all kinds have accepted Denis Wood’s propositionthat “the interest the map serves can be yours” (Wood 1992, p. 182). In 1995 PeterPoole reported on 60 projects around the world applying geomatics to bolster landclaims, manage resources, gather traditional knowledge, and mobilize indigenousgroups (Poole 1995). Since then many more projects have been undertaken withvarying levels of success. The past decade has seen an increasing awareness of theinﬂuence that use and misuse of spatial data can have on the welfare of people andplace (Chapin, Lamb, and Threlkeld 2005). Phrases such as counter-mapping, participatory mapping, community participation in Geographic Information Systems(GIS), and public participation in GISare now commonplace in the ﬁeld and inthe literature of the social sciences, representing a wide range of activities that have begun to restore the balance of power in the realm of mapping, surveying,and census taking (see Chapters 26 and 27 of this volume by Weiner and Harris andJankowski and Nyerges for additional information about participatory GIS and GISand participatory decision making, respectively).THO_C28  19/03/2007  11:26  Page 494 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE495Increasingly, geographers have shown an interest in “mapping the landscape ofidentity” (Knapp and Herlihy 2002). Ethnicity and landscape are tightly coupledand in some ways exhibit similar characteristics. Just as ethnicity is a concept thatshifts with time, space, and point of view, so too landscape is a complex and ﬂuidnotion. It is not surprising that ethnicity and identity often reﬂect context and cir-cumstance. It",
    "chunk_order_index": 314,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-87e7c35788d2a0eac6cd1ce51935771c": {
    "tokens": 1200,
    "content": "PEOPLE AND PLACE495Increasingly, geographers have shown an interest in “mapping the landscape ofidentity” (Knapp and Herlihy 2002). Ethnicity and landscape are tightly coupledand in some ways exhibit similar characteristics. Just as ethnicity is a concept thatshifts with time, space, and point of view, so too landscape is a complex and ﬂuidnotion. It is not surprising that ethnicity and identity often reﬂect context and cir-cumstance. It is no less common for ideas about the use, value, ownership, andpossession of land to be unstable, especially when people and places are threatened.The problem, then, for geographers and other social scientists, is how to survey thelandscapes of people and place in an appropriate manner when the very subjectsof study are so difﬁcult to characterize.The premise of this chapter is that surveys of people and place are not simplythe end result of GIS projects; they are a part of a process through which ideas ofethnicity and landscape are formulated, explored, altered, and articulated. Mappingpeople and place is a complex process involving choices in methods and techniquesthat can impact the ways in which territory is perceived as well as the ways in whichterritory is eventually portrayed or used as the basis for spatial analysis.Central American Case StudiesTo illustrate the interactive relationship between methods and ideas of territory,examples are used from two participatory mapping projects in Nicaragua andHonduras completed over a period of years in the early 2000s (Figure 28.1).From the spring of 1997 to the fall of 1998, a World Bank funded project toresearch and analyze the land claims of indigenous communities on the Caribbeancoast of Nicaragua was carried out under the direction of the Caribbean CentralAmerican Research Council (CCARC – known prior to 2004 as CACRC). Thisproject resulted in the mapping of the claims of 127 indigenous, Garifuna, and Creolecommunities, many of which had not been depicted on maps before (Dana 1998,Gordon, Gurdián, and Hale 2003). CCARC directed another study in 2002, alongthe northern Caribbean coast and Mosquitia of Honduras, mapping the claims of theGarifuna and Miskitu communities. Both projects were participatory in nature, linkedto land rights and indigenous groups, and were accomplished with the help of GISand Global Positioning System (GPS) technologies.Representations of Territory in the GIS ProcessThe idea of deﬁning territories with speciﬁed boundaries is not a modern concept.Clay maps and petroglyphs from as long ago as 2,500 bcappear to show propertylines and ﬁeld boundaries (Harvey 1980). Cadastral maps may have been among theﬁrst preserved maps and their history suggests that control of bounded space is avery old notion. Modern notions of national, provincial and other administrativeboundaries, and the private and communal property deﬁned within them come outof a long tradition of bounding space. Rivers, coastlines, and mountain ridges haveoften provided natural linear features with which to bound territory. The less well-deﬁned midpoints of impenetrable regions of wetlands, deserts, or jungles have beenused as convenient divisions between adjacent groups. Where territory is not wellTHO_C28  19/03/2007  11:26  Page 495 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f496PETER H. DANAdeﬁned by natural or artiﬁcial linear boundaries, divisions between places reﬂect thepatterns on the land made by settlements and land use practices.When maps became tools of empire, natural features, populated places, and loca-tions in empty spaces on maps were connected with intangible lines that eventuallybecame realized boundaries. In the last few centuries, with the advent of celestialpositioning technologies, boundary lines have been constructed with meridians, CACRC Nicaraguan Project, 1997–98CACRC Honduran Project, 2002MEXICOBELIZEHONDURASNICARAGUACOSTA  RICAGUATEMALAEL SALVADORFig. 28.1CCARC Central American mapping projectsTHO_C28  19/03/2007  11:26  Page 496 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE497parallels, or paths between points deﬁned by longitudes and latitudes. Then and now,these conceptual boundaries very often have no relationship to people and placeson the ground. In some cases people living on or near national borders, park bound-aries, or concession limits may have little or no knowledge of the existence of theselines. More often they have little control over the forces that put these lines on themap and that control events from afar.Territory is sometimes deﬁned or claimed within an indeterminate spatial extent.Land use patterns, historical claims, built environments, and the signiﬁcance of certain locations can implicitly deﬁne space without requiring boundary lines, eithernatural or artiﬁcial. For communities, ethnic groups, indigenous organizations, orsett",
    "chunk_order_index": 315,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e1561cd24599a97c57c586fda6201bc9": {
    "tokens": 1200,
    "content": "or no knowledge of the existence of theselines. More often they have little control over the forces that put these lines on themap and that control events from afar.Territory is sometimes deﬁned or claimed within an indeterminate spatial extent.Land use patterns, historical claims, built environments, and the signiﬁcance of certain locations can implicitly deﬁne space without requiring boundary lines, eithernatural or artiﬁcial. For communities, ethnic groups, indigenous organizations, orsettlers in regions where neither private property nor administrative district bound-aries have signiﬁcant impact, territorial claims may be based on land use withinonly vaguely agreed-upon limits.GIS practitioners are familiar with the ﬁeld and object views of space. Points,lines, areas, and volumes deﬁned by points and directions are the fundamental objectsof vector-based GIS. Spaces partitioned into two- or three-dimensional compart-ments ﬁlled with attribute values are the ﬁelds of raster-based representations ofgeographic entities. While modern GIS platforms can handle both approaches, theraster and vector views of the world still impact the way we view territory.Territory without speciﬁed boundaries or limits is not easily deﬁned within a GISplatform. While we are used to grouped and nested polygons, with enclave andexclave features sometimes conceptualized as islandsorlakes, space is usually mappedin vector-based GIS with deﬁned polygons. In raster-based GIS, ﬁelds are explicitlyﬁlled with contiguous cells that represent unique identiﬁers signifying connectionwith a particular territory.The ﬂuid and seasonally-dependent territories of nomadic groups are also difﬁcultto represent in GIS platforms, whether raster- or vector-based. While both methodscan easily handle multiple layers of territorial identiﬁcation, neither lends itself toviews of territory that are not based in concepts of deﬁned, delimited, and demarcatedextent. People living within territories neither encompassed by natural boundaries norconstrained by neighboring community extents may not be able to ﬁt their ideas ofthe land into the bounded spaces of GIS polygons or deﬁned grid cell contents.We only have to look at the complicated multiple polygons of hunting regionsin British Colombia in the “Maps and Dreams” of Hugh Brody (1982) or the “Fiftyversions of the Great Plains boundary ” in Rossum and Lavin (2000, p. 546) tosee the difﬁculties in trying to represent convoluted space, real or imagined, in GIS.When surveying more complex environments with multiple ethnicities and con-tested landscapes the difﬁculty of representing a multiplicity of ideas of territorywithin the same space can become almost unmanageable.The Interaction between Method and ResultWhen territory is not well deﬁned or when its deﬁnition is contested, the measure-ment techniques selected for the survey and the representational models chosen foranalysis may inﬂuence the ways in which territory is ultimately perceived and deﬁned.In some cases the effects of mapping and conceptions of territory may be beneﬁcialTHO_C28  19/03/2007  11:26  Page 497 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f498PETER H. DANAto all concerned. In other situations there may be unintended and unforeseen con-sequences that can result in an increase in the level of contestation. The hope isthat with attention to appropriate measurement and analysis methods and their effecton notions of territory we might be able to do a better job than with methods lessin touch with the territories under study.The vector view of territory is of space bounded by lines and populated by objectsat locations of interest. This point, line, and area view of the world gives specialsigniﬁcance to coordinates, points in Cartesian space, and to linear boundaries even where none may exist on the ground being mapped. Populated places withconsiderable spatial extent and complex shapes are often represented on maps by single points. Wetlands, streams, and river networks are sometimes signiﬁed bya single line. Intricate distributions of variously deﬁned ethnic groups are locatedwithin databases and on maps with discrete linear boundaries. The vector approachoften ignores those elements of the territory that do not easily lend themselves tovector descriptions.Raster-based approaches to mapping usually classify space through rectangular gridsof regularly spaced cells, each of which has an attribute described with thematicor numeric attributes. Raster views of territory, especially those that model withmultiple layers of grids, allow a conception of territory that is content or use-basedrather than one deﬁned by spatial limits. Land use, land cover, ethnicity, elevations,rainfall amounts, and other complex continuous or semi-continuous spatial dis-tributions lend themselves to raster display and analysis. The raster view does noteasily handle those cases where territory is deﬁned by the points and lines of polit-ical boundaries or where rivers and coastlines form natural linear boundaries. Sinceeach cell in a conventional raster layer can only signify a single attribute value, theraster approach often results in the implication that in a single thematic layer, eachpoint on the ground can only be classiﬁed in a single, discrete way.In most mapping projects, some combination of these vector and raster views is helpful. Conventional land surveying techniques have long been based on themeasurement of distances and angles. These are points deﬁned by angles and radiiin a local polar coordinate system, resolved using simple planar geometry into points,lines, and areas. GPS receivers measure points in space deﬁned within some localrect",
    "chunk_order_index": 316,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-bd9c13be8ffa5f63479955489eb5597c": {
    "tokens": 1200,
    "content": "in a single thematic layer, eachpoint on the ground can only be classiﬁed in a single, discrete way.In most mapping projects, some combination of these vector and raster views is helpful. Conventional land surveying techniques have long been based on themeasurement of distances and angles. These are points deﬁned by angles and radiiin a local polar coordinate system, resolved using simple planar geometry into points,lines, and areas. GPS receivers measure points in space deﬁned within some localrectangular coordinate system or by latitude and longitude. The result of these measurements made with varying degrees of precision and accuracy should morereasonably be thought of as centers of probability clusters, rather than the dimen-sionless mathematical point they emulate. Lines are constructed on the map as connections between points. Areas are formed from boundaries made from lines.The noise, biases, and blunders found in surveying and mapping technologies prop-agate from their original measurement into the line and area features found on ﬁnalmaps. Lines on maps should be considered as having some ﬁxed or variable widthrather than as inﬁnitely thin mathematical constructions. Areas deﬁned as mappedregions also share the uncertainty of the points and lines that deﬁne them.When mapping contested lands, approximations may be appropriate even if higherlevels of accuracy are possible and affordable. During the 1997–98 mapping periodin Nicaragua the US Government was still applying the intentional degradation ofthe civil service called Selective Availability (SA) to GPS signals. SA added biasesof many tens of meters to each satellite signal in a pseudo-random manner thatTHO_C28  19/03/2007  11:26  Page 498 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE499caused time-varying biases resulting in horizontal position errors of about 100 m.For this project, mapping using 100 m precision was a desirable feature. Rather thanworking with a precision that implied some ﬁnality and legal weight we preferreda precision that implied approximation. To display this appropriate and useful imprecision, we used large point symbols and hatched boundary lines on the ﬁnal maps(for example, Figure 28.2).In a place where territory is not well-deﬁned, methods used in mapping can change views of territory. Local conceptions of territory can be unconstrained byconventional ideas about extents and boundaries. When territory is unmarked andunbounded, a mapping project may result in the territorializing of people and place,changing, for good or bad, the perception of landscape in fundamental ways (Sack1986). During the Nicaraguan project mapping process many of the 127 commun-ities selected for inclusion in the study chose not to make claims or be mapped asindividual communities. Communities, faced with fractures and contested individualboundaries, formed regional groupings that melded into bloques, larger regions withinwhich internal boundaries were not measured or mapped. Figure 28.3 illustratesthe complex tiling and overlaps in the ﬁnal maps.The result of this mapping project was a tiling of territory within the study areathat left few of the un-mapped regions sometimes considered “empty” and designatedas “state land.” Since the purpose for the study was to set out initial claims, notto produce land titles or ﬁnal demarcation we expected overlaps between claims.Overlaps were common, and are now the subject of considerable negotiation betweencommunities.Fig. 28.2CCARC Nicaraguan map detail with large point symbols and line hatching indicatingsurvey imprecisionTHO_C28  19/03/2007  11:26  Page 499 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f500PETER H. DANAPoint markers signify extents of territories. This does not imply that these monu-ments are necessarily points along a polygonal boundary. In early Asian empires thesepoint features were often regarded as the end points of conceptual lines emanatingfrom a power center (Anderson 1991, p. 172). In Miskitu settlements along theCaribbean coast of Nicaragua monuments sometimes mark community extent with-out implying any ﬁxed line between them. If a mapping project is designed to delimitterritory with regional boundaries, points previously conceptualized as isolated markers may become the vertices of polygons. Neighboring communities may endup with boundary lines between them that they neither needed nor wanted.This happened at the beginning of the CCARC Nicaraguan study. We conducteda pilot project with the permission and assistance of the community of Krukira.After community meetings in which ideas of territory and community boundarieswere discussed, we set off to ﬁnd and measure important boundary turning pointswith GPS. Included were a coco palm at Barra Sahnawala on the coast and theremains of a concrete/rebar monument at Yulu Tingni. That night on a small note-book computer, I prepared the ﬁrst project draft map (Figure 28.4). The next daycommunity members agreed on the placement of all the monuments but were sur-prised by my choice of boundary line placement. They all agreed that the straightline I had placed between Barra Sanawala and Yulu Tingni was quite wrong. Therewas no",
    "chunk_order_index": 317,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-cb6964eb9c7fb3c6058fa08fc1271c8d": {
    "tokens": 1200,
    "content": "at Barra Sahnawala on the coast and theremains of a concrete/rebar monument at Yulu Tingni. That night on a small note-book computer, I prepared the ﬁrst project draft map (Figure 28.4). The next daycommunity members agreed on the placement of all the monuments but were sur-prised by my choice of boundary line placement. They all agreed that the straightline I had placed between Barra Sanawala and Yulu Tingni was quite wrong. Therewas no agreement on how the line might be better placed and no suggestion on theplacement of other turning points. In short, the assumption that the boundary shouldfollow a vector between two points was inappropriate for the local conceptions ofterritory.Where communities do want boundary lines, the methods used to mark them canchange their placement. If paper maps are used, the features selected for inclusionon those maps by the agency that produced them can inﬂuence the placement ofboundary turning points and connecting lines. If remote sensing is used, featuresNicaraguaCosta RicaHondurasFig. 28.3Tiling and overlaps in CCARC Nicaraguan BloquesTHO_C28  19/03/2007  11:26  Page 500 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE501with recognizable visual patterns on aerial photographs or particular electromagneticsignatures in satellite imagery may take precedence over sacred sites, traditional hunt-ing regions, or the sources for medicinal plants, that are important to communitiesbut utterly lost to those technologies.If a project selects traditional surveying equipment to help deﬁne boundaries, theresulting boundary lines may well reﬂect the line-of-sight path that the demarcationteam follows as they proceed, often an easier and simpler path than the more difﬁculttransect through swamps, jungles, and difﬁcult terrain that might have formed theboundary of the community were a less arduous method chosen.Appropriate TechnologiesMeasurement technologies should be selected that respect and faithfully reﬂect local perspectives on territory. Approaches to mapping people and place range from BegnkWalpataReference markKrukiraYulu TigniKukutaSahnawala BarKilometers0510Lambert Conformal Conic (WGS-84)Area = 24,030 HectaresPerimeter = 60.64 KilómetrosKRUKIRABORRADORCACRC 2/20/97 Peter H. DanaKrukiraFig. 28.4Draft map of Krukira with straight lines between pointsTHO_C28  19/03/2007  11:26  Page 501 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f502PETER H. DANAinformal interviews and sketch maps to remote sensing and GIS displays. In betweenthese is a broad range of measurement tools and information gathering techniques(Poole 1998).Mapping from interviews, narratives, or discussions can be useful as part of amapping project or as the fundamental mapping methodology. Historical and currentland use, from speciﬁc agricultural zones to more vaguely deﬁned regions of cere-monial importance, may be more easily determined through interviews than from anyanalysis of imagery or ground survey. Both of the CCARC projects were based onethnographies gathered by trained investigators. These detailed histories of occupa-tion and descriptions of past and present land use were important for establishingthe validity of land claims.Sketch maps, from those drawn in the earth during an informal discussion to thosecarefully drafted on waterproof paper during a visit to a new area, can be usefulat every stage of a mapping process. Often suggested as a tool in the map designprocess, informal sketching has been called “graphic ideation” (Dent 1999, p. 239).“Compilation worksheet” is the more formal term for the draft map produced dur-ing the map design process (Robinson, Morreson, Muehrcke, Kimerling, and Guptill1995, p. 426). We often used sketch maps to work out conceptions of territorialboundaries and land use such as the sketch map made during a community visitto Auka, Honduras shown in Figure 28.5.NSOEPantonoCarreteraCroquis de aukaAero puartoCasariolisangreacarrenterisquebradagareidHondurasJardinEscuetaEriqueCuraI. MoravaConrrosonluacamine a kayu sivpipulperiaI. BrutistaRio erutaICatolicaparquswailassPuanteCentro SaludCaminoCorreteraViviendasIglesiaCamenterioCamino a Liwakuria?RioquabradapiesaresBostice haja anchaEsaiela of Jardin & deninorFig. 28.5Sketch map of Auka, HondurasTHO_C28  19/03/2007  11:26  Page 502 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinel",
    "chunk_order_index": 318,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-cef7a892632127bc13503072550e92a3": {
    "tokens": 1200,
    "content": "RioquabradapiesaresBostice haja anchaEsaiela of Jardin & deninorFig. 28.5Sketch map of Auka, HondurasTHO_C28  19/03/2007  11:26  Page 502 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE503Base maps are general-purpose reference maps that deﬁne the basic geographicfeatures of a region (Muehrcke, Muehrcke, and Kimerling 2001, p. 188). Thematicmaps produced in a participatory mapping project can be made by overlaying newinformation on a base map. Base maps can be produced especially for a mappingproject, but in most places some form of base map already exists. Existing basemaps need to be used with care. They have often been produced by agencies withmilitary or commercial agendas. The places and the place names on maps may reﬂectthese agendas more than they do the ground truth. Roads connecting mines andports may be present while paths more important to community members may notbe shown at all.Base maps that exist in digital form may be expensive or tightly controlled by map-ping agencies. Scanning paper maps (especially in color and in detail) is expensive andsometimes difﬁcult without special equipment. All maps contain omissions, gener-alizations, and exaggerations. Base maps produced by and for groups not concernedwith community conceptions of territory may not contain any useful features toaid in community mapping. Unfamiliar grids and coordinate systems, combined with toponyms in the language of the mapping agency may have little meaning tocommunity members and may make mapping more difﬁcult rather than aid in par-ticipatory mapping. Appropriate base maps that reﬂect the conceptions of territoryheld by participants may be difﬁcult or impossible to ﬁnd.The base maps we used in the CCARC projects suffered from some of these limitations. Maps of both Nicaragua and Honduras are available as 1:50,000-scale topographic sheets. In general they use Spanish names and often do not con-tain information important to indigenous communities. They almost never containmonument symbols or boundaries that represent communities. Produced usually bymilitary or resource management agencies, existing maps sometimes reduce com-munities to just a few symbols on a map. Paths, health centers, churches, and otherfeatures are often not portrayed on these reference maps. Compare the sketch mapof Auka in Figure 28.5 to the Honduran government topographic map of the sameregion in Figure 28.6. With the contour lines removed, the latter would be a veryempty map.In the CCARC projects, we tried to keep pre-existing maps out of the processof community discussions of land tenure. Maps sometimes inﬂuence decisions bydeﬂecting interest from actual territory in favor of the simpliﬁed versions they depict.Administrative boundaries, particular roads and streams selected for mapping, settle-ment patterns that may no longer reﬂect the status of neighboring communities,and even the grid pattern superimposed on the mapped ground can shape views of the land. Once conceptions of territory had been established there were manytimes when maps were useful in the ﬁeld particularly in navigating from place toplace once sketch maps and discussions had determined community extents. Scannedmaps became the base maps on which community boundaries were placed for ﬁnaldisplay. CCARC had to scan, crop, and georegister 103 Nicaraguan map sheets.In Honduras we had access to a complete set of 1:50,000-scale maps already scannedand stored in MrSID format.There are many time-honored methods that are sometimes overlooked when aGIS-based project is planned. There are still plenty of places where 120–240 voltAC power for recharging a battery is not available. Solar-based recharging systemsTHO_C28  19/03/2007  11:26  Page 503 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f504PETER H. DANAare heavy, fragile, and may not be able to handle the power requirements of multipledevices. There are places where even ﬁnding a few “AA” batteries is a challenge.The Caribbean coast of Nicaragua and the Mosquitia of Honduras are challeng-ing environments. Outside of the towns of Bilwi, Blueﬁelds and Puerto Lempira,electrical power is intermittent or unavailable. Finding a set of “AA” batteries isdifﬁcult or impossible in many places. These Caribbean coastal regions experiencesome of the highest annual rainfalls in the tropics. This is not a place for keyboards,electrical cables, rechargeable batteries, or dependence on computers. For both pro-jects we designed very “low-tech” measurement approaches. Participants carriedwaterproof boxes into the ﬁeld containing low-cost water-resistant GPS receivers,extra batteries, waterproof notebooks, pencils, and inexpensive magnetic compasses(Figure 28.7).The magnetic compass is a valuable tool in mapping projects. At the least it cankeep investigators oriented in the ﬁeld. Relative angular measurements can be madeto a few degrees of arc irrespective of magnetic variation, allowing the compass toact as an al",
    "chunk_order_index": 319,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-be343dc6377c0dd330346011f6387def": {
    "tokens": 1200,
    "content": "pro-jects we designed very “low-tech” measurement approaches. Participants carriedwaterproof boxes into the ﬁeld containing low-cost water-resistant GPS receivers,extra batteries, waterproof notebooks, pencils, and inexpensive magnetic compasses(Figure 28.7).The magnetic compass is a valuable tool in mapping projects. At the least it cankeep investigators oriented in the ﬁeld. Relative angular measurements can be madeto a few degrees of arc irrespective of magnetic variation, allowing the compass toact as an alidade. When combined with the practiced pacing of distances, the com-pass can be an effective tool for a reconnaissance survey. Magnetic variation, thedifference between true north and the direction of the magnetic poles is marked onmost topographic map sheets. Variation changes over time and so absolute directionrequires up-to-date variation information. Local anomalies can cause signiﬁcant localchanges in variation so projects should be wary of absolute measurements madewith magnetic compasses. Use of a magnetic compass within a range of 1,000 kmof the magnetic pole is not advised. An important consideration for participatorymapping projects is the problem of magnetic dip. The north pole of a magnet pointstoward the magnetic north pole which is not in a direction horizontal to the locallevel surface, but rather down, in a direct line to the pole through the Earth. TheAucaCementerioLisangniaCrique43CuraLisangnia30Yabaltara72CriqueFig. 28.6Topographic map of Auka, HondurasTHO_C28  19/03/2007  11:26  Page 504 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE505needle of a compass must be adjusted for this “dip” to keep it from scraping the baseof the compass as it turns. Magnetic compasses are adjusted by the manufacturerto work within speciﬁc latitude ranges (ﬁve degree latitude ranges are common).There are newer “international” or “global” compasses with a separate needle andmagnet that work at all latitudes. During both the Nicaraguan and Honduran pro-jects where obstructions made GPS measurements at boundary points, or, as in thecase of small islands that had to be measured offshore from small boats where it wasimpossible to reach the boundary point, participants included compass bearings andestimated distance from the GPS receiver to the point. Final point positions werecomputed in the GIS from the measured point and the distance and magnetic bear-ing corrected for local variation.The alidade and plane table can still be effective mapping tools, especially formapping in the ﬁeld under conditions that might make one-time mapping the onlypractical method. Based on the intersections of lines of sight from two or more points,the alidade is simply a ruler with a sight on it, usually an optical telescope attachedto a metal rule. The alidade is placed on top of a piece of paper attached to a “plane table,” a drafting table on a tripod. Leveled and aligned along a baseline,the plane table supports the alidade which is pointed at objects to be mapped. Movedfrom place to place, the intersection of lines to common points marks their positionon the paper map as the process continues. By combining intersecting lines for morethan three points the process allows the mapper to estimate error and correct forFig. 28.7Waterproof kit contents: GPS receiver, ﬁeld notebook, pencils, compass, and extrabatteriesTHO_C28  19/03/2007  11:26  Page 505 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f506PETER H. DANAmistakes while still in the ﬁeld. Without batteries, computers, or communicationsystems, these are still viable tools for participatory mapping projects. As a point-demarcation process, the technique lends itself to conceptions of territory that arebased on discrete point features.Positioning with sextant and celestial almanacs is a means of ﬁnding latitude andlongitude at sea. On land, with the stable platform of a leveled tripod, latitude and longitude can be determined to within a few meters. Requiring precision opticalvertical angle measurements, access to precise time, and accurate almanacs describingpositions of objects in the sky, these methods are still used by surveyors to establishpoints of beginning and base lines. They are perhaps best used to establish a fewgeodetic points where GPS or other more accurate and more easily used methodsare not available.The surveyor’s theodolite is an optical and mechanical angle measuring device thatallows horizontal and vertical angle measurements with respect to a baseline and alocal level plane deﬁned by gravity. Combined with a tape (or chain) for measur-ing distance, the theodolite can measure the metes and bounds of a survey traverse.Theodolites are expensive, require calibration, and take considerable training andpractice to use effectively. Damage that occurs in the ﬁeld will not likely be repairedwithout expert help. The traverse approach to area boundaries with such instrumenta-tion requires a clear and level line of sight from one traverse point to another. Thetape must be physically connected from point to point, making boundary surveysacross swamps, through jungles,",
    "chunk_order_index": 320,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-21a71f135d339054d1072d07d130e107": {
    "tokens": 1200,
    "content": "theodolite can measure the metes and bounds of a survey traverse.Theodolites are expensive, require calibration, and take considerable training andpractice to use effectively. Damage that occurs in the ﬁeld will not likely be repairedwithout expert help. The traverse approach to area boundaries with such instrumenta-tion requires a clear and level line of sight from one traverse point to another. Thetape must be physically connected from point to point, making boundary surveysacross swamps, through jungles, and along rivers difﬁcult.Where electrical power can be used and where access to the supporting suppliesof batteries, cables, computers and disks can be found, one can manage projects withall of the tools available to the modern mapper or surveyor. Where temperature,humidity, and security allow their continued use, they can be effective tools. Onesharp jolt from a fall or a bump in the road can ruin or damage an expensive devicerequired for project completion. Perhaps worse, difﬁcult conditions can cause aninstrument to become inaccurate, often without any indication of a problem until afterthe survey. The digital theodolite can measure angles and automatically record themon a small handheld calculator or data collector. They require battery recharging andconsiderable care. They come with or without laser pointers to facilitate alignmentwith targets. Visible laser alignment aids can only be used within 50 m of so of theinstrument. Infrared laser measurements of distance can be made with ElectronicDistance Measurement (EDM) devices. Prism reﬂectors placed at a target return acoded laser signal to the EDM device, and range is calculated from travel time. Thesedevices can measure ranges as long as 4 km under good atmospheric conditions.Normal operating range limits are in the 2 km range. Range accuracies are typic-ally 2 mm plus two parts per million (4 mm total over a 2 km distance). Newerreﬂectorless devices can measure the return signal from a target without a prism, butare only useful for distances of less than 100 m. Use of non-prism EDMs can intro-duce blunder errors when the reﬂected signal is not from the intended target. Inthe ﬁeld, small EDM devices can replace or augment the tape or chain to providedistances without the requirement for a physical path between one point and another.Measuring across rivers or gorges can be simpliﬁed through the use of EDM.The Total Station, an electronic theodolite with digitally encoded angle measure-ments combined in a single instrument with EDM, can measure and record bothTHO_C28  19/03/2007  11:26  Page 506 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE507angles and distances. Usually coupled with handheld data collectors these instru-ments, which can measure angles to between 2 and 5 arc-seconds, have largely replacedthe conventional theodolite and chain. The Total Station is expensive (in the rangeof US$10,000), heavy (10 kg), and requires regular recharging of batteries.Binoculars with built-in magnetic compasses can provide relative angle measure-ments over long distances. Costing in the range of US$500 these devices are soldto mariners and so can often be found in waterproof conﬁgurations requiring nobatteries (some require battery power to illuminate the compass); they can be valu-able aids to mapping projects. Incorporating EDM laser techniques within handheldbinocular packages, rangeﬁnding binoculars can be used as lightweight total stations.They can be used to measure distances over ranges as long as 2 km to accuracies of2–3 m. These do require batteries, but for ﬁeld work and preliminary surveys theycan be effective tools in mapping projects. Laser rangeﬁnders with approximate anglemeasuring capabilities (about a half a degree of arc) cost about US$3,000 and canbe used as handheld replacements for the Total Station when high accuracy is notrequired. They make useful accessories for GPS projects that require offset rangeand bearing measurements.GPS ApproachesThe fundamental concept of GPS is the estimation of three-dimensional point posi-tion in a geodetic reference system from measurements of the relative arrival timesof satellite signals. As a point positioning system, GPS lends itself to projects inwhich territory is conceived of as discrete points which form either turning pointsin polygonal boundaries or represent the centers of places. GPS can be used to measure points, paths between points, and the spatial extent of areas. There are threemajor categories of GPS methods. Unaided code-phase GPS is the use of the civilGPS service with a single receiver that tracks the GPS codes, resulting in horizontalaccuracies of between 2–20 m. Differentially corrected code-phase GPS can pro-vide horizontal accuracies of between 1–2 m within 300 km of a suitable referencestation supplying corrections to the GPS signals. Carrier-phase GPS is always dif-ferential in nature and can provide position accuracies of a few centimeters within10–30 km of a suitable reference station. These three techniques differ signiﬁcantlyin their accuracy, cost, and complexity.Unaided code-phase GPSThe US Department of Defense maintains GPS. A civil service is provided that allowsunrestricted access to part of the GPS signal structure. The C/A code (coarse acquisi-tion code) contains timing edges that are used within a GPS receiver to measurerelative arrival times from each tracked satellite. The timing edges are coded witha repeating sequence of",
    "chunk_order_index": 321,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-37f944ed28f083e07609e575b5e9408f": {
    "tokens": 1200,
    "content": "of a suitable reference station. These three techniques differ signiﬁcantlyin their accuracy, cost, and complexity.Unaided code-phase GPSThe US Department of Defense maintains GPS. A civil service is provided that allowsunrestricted access to part of the GPS signal structure. The C/A code (coarse acquisi-tion code) contains timing edges that are used within a GPS receiver to measurerelative arrival times from each tracked satellite. The timing edges are coded witha repeating sequence of bits such that each millisecond can be resolved into 1,023distinct intervals. Fractions of an interval can be measured with precisions of a few nanoseconds (three nanoseconds is about one meter of range). System informa-tion, satellite clock corrections, and satellite orbital data are contained within theNavigation Message broadcast by each satellite. The GPS receiver uses the C/A codeTHO_C28  19/03/2007  11:26  Page 507 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f508PETER H. DANAarrival times and the Navigation Message from at least four satellites to resolve thecommon clock offset from the relative arrival times in order to compute the three-dimensional position of the receiver. GPS receivers typically track all the satellitestheir antennas can acquire and produce position reports in latitude, longitude, andheight for display or recording.Ionospheric and tropospheric signal delays, clock and orbital data errors, andlocal reﬂections result in position accuracies of between 2–20 m depending on thenumber of satellites tracked and the geometry of the receiver-antenna with respectto the satellite positions in space. Because the satellites are always moving, this geo-metric relationship and the combination of satellites in view are always changing.All GPS receivers must have a clear and unobstructed view of the sky in order toacquire and track the necessary GPS satellite signals.Differential code-phase GPSA special purpose GPS receiver at a precisely known location can compute the differences between the relative ranges it measures and those predicted for that location. These differences are the basis for Differential GPS (DGPS) correctionsthat can mitigate the bias errors from atmospheric delays and system errors thatare common to a reference receiver and a remote receiver up to a few hundredkilometers away. The DGPS corrections are computed for each satellite and arerange-domain corrections. They are not position-domain corrections. One cannotsimply shift the position of a remote receiver based on the position error measured atthe reference receiver unless both receivers are tracking the same set of satellites at the same time, have the same geometric relationship to the satellites, and are usingidentical clock and orbital data sets. This commonality in the position domain isalmost impossible to achieve. DGPS works by providing the remote receiver withrange and rate of range change corrections for each satellite. These are then used tocorrect the measured ranges used in the position solution in the remote receiver. Whenthe reference receiver is close to the remote receiver much of the bias error is commonand can be differentially removed. Local reﬂections (multipath) and receiver-inducederrors cannot be removed by DGPS. In situations where the remote receiver geometryor signal strength is insufﬁcient DGPS cannot help.DGPS corrections can be applied in real-time if a radio link is available to send reference station corrections to the remote receiver. This requires licensing andmaintaining a radio link that can reach the remote receiver. There are an increas-ing number of public and private sources for real-time DGPS corrections. The USgovernment operates the Wide Area Augmentation System (WAAS). This system isbased on a network of reference stations that are used to produce correction signalsthat are transmitted to receivers over communications satellite links in a format thatis relatively simple for GPS designers to incorporate into GPS receivers. Where aWAAS-enabled GPS receiver can track either of the two WAAS satellite signals, itcan usually estimate position to within 2–3 m. Care must be taken not to use WAAScorrections outside of the regions for which corrections have been calculated. Inparts of Central America, WAAS signals can be received but their use can actuallydegrade rather than enhance position accuracy. Low frequency beacons are used bymany nations to provide coastal coverage for maritime use and can be used inland asTHO_C28  19/03/2007  11:26  Page 508 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE509well where signal strengths allow. Most of the US coast and the east and west coastsof Canada are covered by transmitters operated by the US and Canadian Coast Guard.Several commercial communications-satellite based DGPS services offer coverageover much of the world.For post-processed DGPS, a receiver capable of saving DGPS data ﬁles is neededalong with a local DGPS reference station equipped to provide ﬁles for post-processing. Dedicated DGPS reference receivers can be established at a cost of aboutUS$20,000 including the computer required to log data for post-processing. Whilethere are hundreds of Community Base Stations (CBS) located throughout the world,locating one and obtaining permission to access to the data ﬁles can be difﬁcult.Recent versions of Trimble’s Pathﬁ",
    "chunk_order_index": 322,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a22d06c77c2e257579e5fbd30cdc9b75": {
    "tokens": 1200,
    "content": "receiver capable of saving DGPS data ﬁles is neededalong with a local DGPS reference station equipped to provide ﬁles for post-processing. Dedicated DGPS reference receivers can be established at a cost of aboutUS$20,000 including the computer required to log data for post-processing. Whilethere are hundreds of Community Base Stations (CBS) located throughout the world,locating one and obtaining permission to access to the data ﬁles can be difﬁcult.Recent versions of Trimble’s Pathﬁnder Ofﬁce software include Internet addressesfor hundreds of cooperating CBSs, but there are hundreds more that are not partof this list.Carrier-phase surveyingSpecial purpose GPS receivers can track both the code edges of the civil GPS signalsand the microwave signals that carry them. Tracking the “carrier” signal makes itpossible to measure relative arrival times to accuracies of about a centimeter. Thetechnique is limited because these carrier-phase measurements are difﬁcult to resolveinto relative ranges. Unlike the C/A code edges there is no marking that differentiatesone carrier wavelength cycle from another. In addition, the signal-to-noise ratiosfor carrier-phase measurements are lower than for C/A code-phase measurements.Special hardware is required to track these low level signals and complex softwaremethods are required to resolve wavelength ambiguities.Static techniques have been developed that can provide centimeter relative rangeswith respect to the position of a reference receiver within 30 km of the remote receiver.Software must have access to the continuous measurement of carrier phase at bothreceivers. These systems cost from US$10,000 to US$25,000 and require consider-able training to operate. Real-time-kinematic (RTK) techniques make it possible tomove the remote receiver while making relative position measurement with respectto a reference receiver. RTK techniques require a special RTK reference receiverwithin 10 km of the remote, a continuous radio link between reference and remote,and the simultaneous tracking of ﬁve or more satellites at both receivers. Theserestrictions, the additional need for training, and the expense (these RTK systemscost more than US$50,000), make RTK difﬁcult to use in many projects.Data attribute collectionWhatever GPS technique is used, data attribute collection must be considered before,during, and after a mapping project. Names, distinguishing features, topologicalconnections, entity attributes, times, dates, and quality control information are allrequired in the data collection phase of a project. While inexpensive (some aroundUS$100), recreational GPS receivers have very limited capabilities for recording morethan a time, date, position, and a name. Complex mapping projects will require someform of data collection method, devices, and procedures. Professional GPS equipmentsuites usually include some form of data attribute collection software and hardware.THO_C28  19/03/2007  11:26  Page 509 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f510PETER H. DANAThese systems consist of a dedicated computer or a program resident in a notebookor handheld computer. Attribute collection software platforms have functions fordeﬁning data dictionaries or forms for entering attributes. A data dictionary pre-deﬁnes ﬁelds and menus that enable the operator to quickly and efﬁciently selectfrom attribute choices or ﬁll in alpha-numeric records. Data collection software will usually attach time, date, geometry, and tracked satellite lists to each record.Newer palm-sized devices that attach to GPS receivers can be programmed to acceptdata attributes in both text and graphic format. Figure 28.8 shows a “Pocket PC”running ESRI’s ArcPad software connected to an inexpensive WAAS enabledDGPS receiver with external antenna.For both CCARC projects, where power and maintenance of electronic equipmentposed a serious problem, we developed a “low-tech” data collection approach. Weheld workshops in Nicaragua and Honduras teaching the fundamentals of geodesy,GPS, and GIS. Investigators and community participants then went into the ﬁeldto existing or new boundary turning points and recorded position information andFig. 28.8DGPS receiver and pocket PC with ArcPad data collection softwareTHO_C28  19/03/2007  11:26  Page 510 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE511sketches of locations in waterproof notebooks (Figure 28.9). Crucial in this pro-cess was the construction of preliminary community maps with the order of pointscarefully marked. To deﬁne a speciﬁc polygon the order of the points is required.In both projects we experienced difﬁculties when investigators and participants hadtrouble deﬁning point order unambiguously.Because most of the communities we helped map seemed to perceive boundaryturning points as an appropriate way to deﬁne territory, determining the locationsof these points was central to the projects. Because the land claims resulting fromthese projects were contested between communities and between communities andother agencies it was important that communities should show that they really didoccupy and use these territories right up to the boundaries. Participants understoodthe symbolic importance of occupying and physically measuring turning points. Theyoften made extraordinary efforts to reach and measure points at the extent of theirlands. For the most part investigators were able to reach points by boat, vehicle",
    "chunk_order_index": 323,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-adacd162d0f6af2d11a39849acb60ea9": {
    "tokens": 1200,
    "content": "ne territory, determining the locationsof these points was central to the projects. Because the land claims resulting fromthese projects were contested between communities and between communities andother agencies it was important that communities should show that they really didoccupy and use these territories right up to the boundaries. Participants understoodthe symbolic importance of occupying and physically measuring turning points. Theyoften made extraordinary efforts to reach and measure points at the extent of theirlands. For the most part investigators were able to reach points by boat, vehicle,or on foot. Most of these accessible points could be directly measured while othersrequired GPS measurements from a few hundred meters away. Combined with compass bearings and distance estimates, these indirect GPS readings were convertedlater in the GIS to boundary point position. In many communities, natural line features such as streams and coastlines formed community limits. In order to incor-porate these boundaries into community maps, we had to establish the geodeticFig. 28.9GPS waterproof notebook pagesTHO_C28  19/03/2007  11:26  Page 511 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f512PETER H. DANAposition of these features, often misplaced on maps or missing in digital databases.In these cases we asked participants to measure enough points along streams andcoastlines to establish their correct position in space. Then we were able to placethe natural features on georegistered maps. Where turning points were inaccessibleto participants because the terrain was too difﬁcult or because land owners preventedaccess, we encouraged participants to use maps or other descriptions to “mark”points they could not reach to occupy safely.With lessons learned in Nicaragua we developed a methodology for point measure-ment and description in the Honduran project that seemed to handle these differentcases quite well. We deﬁned four point types: (1) Direct GPSpoints, where thereceiver was co-located with the point; (2) Indirect GPSpoints where GPS was notpossible at the point but could be measured at some distance and direction away;(3) GPS Registeredpoints that were established from maps and databases after GPS measurements established the position and orientation of natural features; and(4) Estimatedpoints, with a geodetic position estimated from maps or imagery. Thislast set of points provides the least authority in establishing land claims. Figure 28.10shows each of these point types and their symbolization on ﬁnal maps.Point information, including place names, position, and the all-important pointorder in completed ﬁeld notebooks was entered into Excel spreadsheets for importa-tion into GIS. Offset range and bearing computations and geodetic datum shiftswere all accomplished within the GIS process. In workshops conducted in Nicaraguaand Honduras, investigators produced draft maps of community boundaries on1:250,000-scale scanned base maps.Draft maps with measured community boundaries were returned to commun-ities for land use annotation. In this validation phase, communities veriﬁed or askedfor revisions of boundaries or additional turning points. Land use, crucial for thedevelopment of land claims, is a difﬁcult concept in regions of multiple and con-tested uses for territory. Land use is also perhaps the most difﬁcult attribute to collect in the ﬁeld. There are so many conﬂicting, overlapping, and contested usesfor land that any attempt to map land use is bound to be a compromise. For theCCARC projects, focused on land claims, land use was determined and categorizeddifferently than it often is within the resource-management tradition of land cover/land use schemes. We were as much interested in land signiﬁcance as in vegetationcover or the planned use of lumber product by forestry agencies, so we developed,with the help of the communities, a set of land use categories that had signiﬁcanceto communities, representing their traditional and customary land uses, irrespect-ive of what remote sensing might decide through the analysis of electromagneticPuntosGPS DirectoGPS IndirectoGPS RegistradoEstimadoFig. 28.10Position types: Direct, indirect, registered, and estimatedTHO_C28  19/03/2007  11:26  Page 512 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE513signatures. Many so-called land useschemes include categories that are more appro-priately termed land cover. For instance, forested land is a category that does littleto suggest the hunting and ﬁshing activities or fallow status that might be the actualland use. To help establish and defend land claims CCARC categories included placesof historical signiﬁcance, social gathering places, and ecological reserves. Figure 28.11shows the land use categories in Spanish and Miskitu developed by community members for Nicaragua. Figure 28.12 shows the land use categories for Hondurasin their Spanish/Garifuna and Spanish/Miskitu versions.Map Production and GIS AnalysisGIS were used as the basis for map-making in both projects. MapInfo was selectedfor Nicaragua because at that time it was the only entry-level platform that couldhandle coordinate system and geodetic datum shifts without special scripting. InHonduras, ESRI’s ArcView 3.x was used in many government, resource agency,and non-government",
    "chunk_order_index": 324,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b92062d39e3a922297623a22c78b4556": {
    "tokens": 1200,
    "content": ". Figure 28.12 shows the land use categories for Hondurasin their Spanish/Garifuna and Spanish/Miskitu versions.Map Production and GIS AnalysisGIS were used as the basis for map-making in both projects. MapInfo was selectedfor Nicaragua because at that time it was the only entry-level platform that couldhandle coordinate system and geodetic datum shifts without special scripting. InHonduras, ESRI’s ArcView 3.x was used in many government, resource agency,and non-governmental organization settings. To maintain a compatibility with avariety of organizations and to make distribution of project results easier, we selectedArcView 3.x, which by 2002 had added rudimentary coordinate system and datumconversion capabilities to earlier versions.MineriaMain nani pliskaMaderaDus nani pliskaPescaInska pliskaAgricultura permanenteDus aiura pliskaAgricultura anualInsla pliskaCaseriaAntin pliskaGanaderíaDaiwan sahwaia pliskaValor histórico-culturalBlasi kulkan bri pliskaLugares segrados religiososHuli tasbaya kulkan bri pliskaReserva EcológicaTasba ritska apahkaia pliskaInteracción-social recreativaImpaki ris takaia pliska naniInfraestructura decomunicación y transporteYabal tara an briks naniLeyenda Para El Contenido Ethnográfico Del MapaFig. 28.11Land use categories and symbols for NicaraguaTHO_C28  19/03/2007  11:26  Page 513 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f514PETER H. DANAScanned 1:50,000-scale maps were used as base maps. Geodetic datum and co-ordinate system conversions were accomplished to keep all layers in a common coordinate system. Community boundary points with name, longitude, latitude, and point order were processed with a MapBasic or Avenue script that resulted inGul sikbaia plikisaMineria/GuiriserosUso de la TierraUso de la TierraDus nani pliskaMaderaInska miskaia pliskaPescaInsla pliskaAgriculturaAntin pliskaCaseriaBip sahwaia pliskaGanaderiaBlasi kulkan bri pliskaValor Historical-CulturalHuli tasbaya kulkan bri pliskaLugares Sagrados ReligiososTasba ritska apahkaia pliskaReserva EcologicoImpaki ris takaia pliska naniInter-Accion Social RecreativoYabal tara an briks naniInfraestructura de Comunicacion y TransporteSika wahaia an wakiaPlantas MedecinalesLata tani wina kirb ankaTurismoDus nani yus muni diara paskaiaMaterial de ConstruccionDaiwan alki pliskaRecoleccion Iguana Verde, otros AnimalesCatei gebeti lindaMineríaFulansuMaderaOuchahaniPescaIchariAgriculturaAgaliuhaniCaseríaPouteuGanaderíaWalanganteValor Histórico-CulturalGabusanduLugares Sagrados ReligiososDaviruguReserva EcologicoAnaguni unguaInter-Acción Scoial RecreativoBunagueInfraestructura de Comunicación y TransportaciónHiduru lun araniPlantas MedecinaiesLuchudiguti~naTurismoTubu~ne MunaMaterial de ConstrucciónAgaliujaniRecolección lguana Verde, otros animalesFig. 28.12Land use categories and symbols for HondurasTHO_C28  19/03/2007  11:26  Page 514 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE515point and polygon ﬁles for use in the GIS process. Land use symbols were thentransferred from the draft maps to point databases. Named boundary turning points,community boundary polygons, and land use symbol point ﬁles were mapped overthe scanned base maps. GIS were used to produce area and perimeter values andto compute the area of overlaps between communities. Figure 28.13 illustrates acompleted community map for the Honduran Mosquitia.GIS were the basis for mapping and were used for measurements of distance andarea, but a GIS-based project offers much more. Once information is captured ingeoreferenced layers, all sorts of analysis become possible. As an example, we foundthat land use, so critical for land claims, was often very differently designated byadjoining communities along boundaries and within overlaps. Figure 28.14 showsthe areas of matching and non-matching land use in the overlap between twoHonduran communities.Because all our project information was in GIS form, we were able to use alloca-tion (proximity) and cost-weighted allocation analysis to quantify the spatial extentimplied by land use point symbols placed on maps. We were able to use spatialstatistics such as the kappa coefﬁcient to evaluate percentages of land use correla-tion in overlaps or along boundaries between communities. Using GIS processes wemeasured the relationship between regions of matching land use and proximity tostreams that forms much of the visual pattern in Figure 28.14. We have since foundsimilar land use differences",
    "chunk_order_index": 325,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-28fea87bc49a4ff113eb943421b8dcf0": {
    "tokens": 1200,
    "content": "tion (proximity) and cost-weighted allocation analysis to quantify the spatial extentimplied by land use point symbols placed on maps. We were able to use spatialstatistics such as the kappa coefﬁcient to evaluate percentages of land use correla-tion in overlaps or along boundaries between communities. Using GIS processes wemeasured the relationship between regions of matching land use and proximity tostreams that forms much of the visual pattern in Figure 28.14. We have since foundsimilar land use differences in Nicaragua and in adjoining communities in Belize asdepicted in another participatory mapping project (Toledo Maya Cultural Counciland Toledo Alcaldes Association 1997).Fig. 28.13Final map of Auka, HondurasTHO_C28  19/03/2007  11:26  Page 515 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f516PETER H. DANACONCLUSIONSSurveys of people and place should attempt to discover and use methods and technologies that reﬂect local conceptions of territory. Boundary and point-basedconceptions of territory lend themselves to point measurement methods, vector carto-graphic representations, and vector-based GIS processing. Where land use deﬁnesterritory, remote sensing, raster-based mapping, and raster-based GIS may be moreappropriate. Solid lines deﬁning territory may be inappropriate where territory is contested or poorly deﬁned. In many cases mapping processes and notions ofterritory will interact with each other.The selection of mapping technologies such as interviews, sketch maps, and remotesensing that favor land use mapping may be more appropriate for some projectsthan boundary-based technologies such as conventional traverses or GPS measure-ments that favor bounded conceptions of territory. Relative position measurementsmay require complete boundary traverses where such point-to-point access to landis dangerous or costly. Injudicious selection of base maps, such as selecting a basemap produced by an agency of an unpopular government, can change a locally controlled participatory mapping project from one with an appearance of self-determination to one that requires that its community boundaries be based on the Fig. 28.14Land use differences in overlap between Ahuas and Wawina, HondurasTHO_C28  19/03/2007  11:26  Page 516 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fSURVEYS OF PEOPLE AND PLACE517product(s) of a faction competing for land rights. Selection of high-precision surveytechniques may require hundreds of point measurements to accomplish a boundarysurvey that would more appropriately be accomplished with just a few points in areconnaissance survey. Contested boundaries might be better measured with appro-ximate methods to avoid confrontations and resistance to modiﬁcation with respectto the claims of neighboring communities.Map projections, geodetic datums, and coordinate systems should be selected with respect to scale and accuracy requirements while respecting local independencefrom the reference systems often imposed by colonial powers or military mappingagencies. Surveying methods that use independent measurements of absolute positionmay be difﬁcult to repeat or to link to physical features on the ground, makinglegal land titling impossible in a context in which local laws require reference tophysical ground features or existing boundary markers. In the CCARC projects,for example, there is often no direct link between monuments on the ground andthe GPS-derived points. This makes legal land tenure claims using the CCARC datasets difﬁcult, lessening the chance that these approximate boundary claims will resultin disputes over exact boundary placement.Problems of supply, maintenance, and replacement of sophisticated electronic equipment, while not unique to mapping in remote areas, are often insurmount-able where budgets typical of participatory mapping projects are limited. Climaticconditions, often extreme in tropical or polar environments, can cause failure of instrumentation on the ground. Cloud cover can render some remote sensing methods useless. Language-based processes embedded in modern electronic devicesmay not be suitable for use in many parts of the world. GIS processes bring to aproject assumptions about space embedded in the software. Current GIS are limitedin their ability to handle temporal change, uncertain boundaries, and multiple orcontested land use. If local notions of territory are ﬂuid and shifting, an entirelynew or modiﬁed GIS platform might be required to handle complex or differentnotions of territory.Ideas of territory and the mapping of territory are intertwined in an inseparablerelationship. The ways in which territory is perceived inﬂuences its portrayal onmaps, and methods used to make maps can change notions of territory. Any GIS-based mapping project is at the juncture of this process. Successful surveys of peopleand place require a synthesis of appropriate technologies and local participation.REFERENCESAnderson, B. 1991. Imagined Communities.London: Verso.Brody, H. 1982. Maps and Dreams. New York: Pantheon Books.Chapin, M., Lamb, Z., and Threlkeld, B. 2005. Mapping Indigenous lands. Annual Reviewof Anthropology34: 619–38.Dana, P. H. 1998. Nicaragua’s “GPSistas”: Mapping their lands on the Caribbean coast.GPS World(September): 32–42.Dent, B. D. 1999",
    "chunk_order_index": 326,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-c035c0dc2ffb179d87b3c700c63549f5": {
    "tokens": 1200,
    "content": "Verso.Brody, H. 1982. Maps and Dreams. New York: Pantheon Books.Chapin, M., Lamb, Z., and Threlkeld, B. 2005. Mapping Indigenous lands. Annual Reviewof Anthropology34: 619–38.Dana, P. H. 1998. Nicaragua’s “GPSistas”: Mapping their lands on the Caribbean coast.GPS World(September): 32–42.Dent, B. D. 1999. Cartography: Thematic Map Design.Boston, MA: McGraw Hill.Gordon, E. T., Gurdián, G. C., and Hale, C. R. 2003. Rights, Resources, and the SocialMemory of Struggle: Reﬂections on a study of indigenous and black community land rightson Nicaragua’s Atlantic coast. Human Organization62: 369–81.THO_C28  19/03/2007  11:26  Page 517 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f518PETER H. DANAHarley, J. B. 1988. Maps, knowledge and power. In D. Cosgrove and S. Danials (eds) TheIconography of Landscape: Essays on the Symbolic Representation, Design, and Use ofPast Environments. Cambridge: Cambridge University Press, pp. 277–312.Harvey, P. D. A. 1980. The History of Topographical Maps: Symbols, Pictures, andSurveys. New York: Thames and Hudson.Knapp, G. and Herlihy, P. 2002. Mapping the Landscape of Identity. In G. Knapp (ed.)Latin America in the 21st Century: Challenges and Solutions. Austin, TX: University ofTexas Press, pp. 251–68.Monmonier, M. 1991. How to Lie with Maps. Chicago: University of Chicago Press.Muehrcke, P. C., Muehrcke, J. O., and Kimerling, A. J. 2001. Map Use: Reading, Analysis,Interpretation (4th edn). Madison, WI: JP Publications.Poole, P. 1995. Land Based Communities, Geomatics, and Biodiversity Conservation: A Surveyof Current Activities. Cultural Survival Quarterly18(4): 74–6.Poole, P. 1998. Appropriate geomatic technology for local earth observation. Yale F & ESBulletin98: 156–66.Robinson, A. H., Morreson, J. L., Muehrcke, P. C., Kimerling, A. J., and Guptill, S. C. 1995.Elements of Cartography(6th edn). New York: John Wiley and Sons.Rossum, S. and Lavin, S. 2000. Where are the Great Plains? A Cartographic Analysis.Professional Geographer52: 543–52.Sack, R. D. 1986. Human Territoriality: Its Theory and History. Cambridge: CambridgeUniversity Press.Toledo Maya Cultural Council and Toledo Alcaldes Association. 1997. Maya Atlas: TheStruggle to Preserve Maya Land in Southern Belize. Berkeley, CA: North Atlantic Books.Wood, D. 1991. The Power of Maps. New York: Guilford Press.THO_C28  19/03/2007  11:26  Page 518 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 29Geographic Information Science,Personal Privacy, and the LawGeorge C. H. ChoThe relationship between Geographic Information Science (GISc), personal privacy,and the role of regulation and self-regulation is at best nebulous, and uncertain. Whiletidy minds might wish a strict dividing line between what is private and what ispublic in reality there seems to be a “zone” of privacy. This zone delineates thoseparts of our lives that provide strategic information about ourselves, our ﬁnancialstatus, health, and education. At different times what might be private informationmay meld into what might be considered public. The tools of GISc deal with geo-spatial information in which spatial relationships are thefundamental data. But, GIScmay also handle a diverse range of personal information from the truly “personal”ones through to those of a more general nature – age, gender, height, home address,social security number, marital status, religion, and so on. By its very nature the toolsof GISc allow these kinds of information to be collected, manipulated, displayed,and transmitted cheaply, easily, and speedily. But the very capabilities of geospatialtools in information analysis and transfers have raised a multitude of novel andinteresting information and personal privacy issues.Professor Arthur Miller of the Beckman Center for Internet and Society, HarvardLaw School has described privacy as an intensely, perhaps uniquely, personal value.The word stems from a Latin root privarewhich means “to separate.” To wantprivacy is to want to be separate, to be individual. Another meaning of the Latinis “to deprive,” and privacy also means leaving something behind.1In the common law world the",
    "chunk_order_index": 327,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-fb7cba8df116f21fe7e0cba0de9a00da": {
    "tokens": 1200,
    "content": "analysis and transfers have raised a multitude of novel andinteresting information and personal privacy issues.Professor Arthur Miller of the Beckman Center for Internet and Society, HarvardLaw School has described privacy as an intensely, perhaps uniquely, personal value.The word stems from a Latin root privarewhich means “to separate.” To wantprivacy is to want to be separate, to be individual. Another meaning of the Latinis “to deprive,” and privacy also means leaving something behind.1In the common law world the claim to privacy as a right rather than merely an “interest” to be protected is a relatively recent development because the pro-tection of privacy in the past has been ad hoc. The Australian Constitution has no vested power over privacy protection while the common law protects privacyrights indirectly. For example, the law of defamation, negligence, and passing offgive a semblance of an overarching umbrella, as does the shield provided by con-tract including the duty of conﬁdence. Likewise, in the USA the origins of the privacy right may be traced to a law review article by Warren and Brandeis (1890).In a famous dissenting opinion, Judge Louis Brandeis in 1928 reiterated the rightTHO_C29  20/03/2007  15:09  Page 519 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f520GEORGE C. H. CHOto be left alone as “the most comprehensive of rights and the right most cherishedby civilized men.”2Based on the principle of the right to be left alone, US law hasdeveloped along the lines of a common law right and those rights found underAmendments to the US Constitution.In this chapter, the ﬁrst section examines the doctrinal issues that provide thebasis of discussion of the nature and structure of the problem of personal privacyand geospatial technologies. Then in the second section the legal, regulatory, andpolicy framework that underlies the source of this interest is evaluated in the con-text of considering privacy as a “right” in some circumstances. In the third sectiona review of the different geospatial technologies that promote intrusiveness, enhanceprivacy protection, or are sympathetic to privacy protection is undertaken.Nature of the ProblemThere are three interrelated matters that need to be resolved initially. The ﬁrst iswhether Geographic Information Systems (GIS) are a threat to personal privacy.The second matter is that there seems to be a lack of understanding of privacy issues,just as there is, for instance, some fuzzy thinking about whether we are attempt-ing data protection on the one hand or protecting the privacy of that information.Finally, there are, inevitably, some ethical questions in the use of geospatial techno-logies especially where privacy issues are involved and what the “right” thing todo might be.GIS is not personal data intensiveFlaherty (1994), in relating his experiences with privacy protection and GIS in anational and provincial context, has said that the technology is “not personal dataintensive” and that information privacy issues are alwayssolvable by applying fairinformation practices.GIS has the power to integrate diverse information from multiple sources. Someof the data are of a personal nature where individuals may be identiﬁed or identiﬁ-able, while others are of a spatial nature that may be used to locate individualsthrough geocoded data such as a home address. The privacy threat is from the newinferences that may be made by correlating geographic information with personalinformation.Data on geographical location when combined with other data transforms GIScinto a powerful tool for tracking, storing, and analyzing personal information. Tracking,data integration, and analysis capabilities give Geographic Information (GI) tech-nologies the potential to be more invasive of personal privacy than many other technologies.Dobson (1998) promotes the view that geo-information in combination with personal information clearly poses a privacy threat. But there is a tension betweenthe two fundamental values of privacy on the one hand and the public’s right toknow on the other. For example, the differences between satellites monitoring afarmer’s use of water and the public’s acceptance of CCTV and video cameras inshopping malls, buses, and taxis, in city streets and in dorms and apartments.THO_C29  20/03/2007  15:09  Page 520 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW521Lack of understanding of privacy issuesThere seems to be a lack of understanding of privacy issues among many who usegeospatial tools. For instance, there may be confusion in terms of the differencesbetween data protection, privacy of information, and personal privacy.Data protection, whether by legislation or by a code of practice, relates to theprotection of data rather than about the people themselves. The protection is asmuch of a concern for both the data subject (a natural person and, in certain instances,corporations and legal persons) as the organization or agency that collects and pro-cesses the data in order to ensure legislative compliance.The privacy of information relates to undertakings to keep the information privateand the various interests individuals may have in controlling and signiﬁcantly inﬂuen-cing the handling of these data. The privacy of information is often taken for grantedand",
    "chunk_order_index": 328,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-1870124d41de6d175ae13d2e45608329": {
    "tokens": 1200,
    "content": ". The protection is asmuch of a concern for both the data subject (a natural person and, in certain instances,corporations and legal persons) as the organization or agency that collects and pro-cesses the data in order to ensure legislative compliance.The privacy of information relates to undertakings to keep the information privateand the various interests individuals may have in controlling and signiﬁcantly inﬂuen-cing the handling of these data. The privacy of information is often taken for grantedand we willingly provide personal information to others who request the informa-tion because we believe that the receiver has undertaken to abide by some privacyguidelines. Here we may be equating private with conﬁdential.Informational privacy relates to knowledge about some person that is kept privateand conﬁdential. This is quite different from personal privacy where an individualmay have chosen to be left alone and facts about that person shielded from view.The former is about the protection of personal information kept conﬁdential and thelatter is about a person acting and taking steps to keep personal facts private.Informational privacy becomes a problem where the datum may be traced to a person. Another dilemma is whether, while one may have divulged personal infor-mation for one reason or another, one’s consent should be given again. The dilemmais particularly pointed when that information is either disguised in aggregate formor re-purposed in some other form so that new, synthesized data are vastly differentfrom what was given by an individual initially.Ethical use of geospatial technologiesA ﬁnal issue is the ethical use of geospatial technologies, in which users and pro-ponents of this potentially invasive technology need to be reminded of their heavysocial responsibilities and to use the technology ethically and in an ethical mannerin all ways and at all times (Ball 2003).3Geospatial technologies include GIS as amapping tool for decision-making through to those technologies that amass data byspatial attributes including global positioning systems (GPS), and transponders andother intelligent computer chips embedded in some devices that can report locationas well as an identity. The latter are in a class of intelligent spatial technologiesthat can declare both personal information as well as locational and device-speciﬁcinformation in response to a poll by another device either in a pre-established rela-tionship or to a new, soon to be established, relationship.Geospatial technologies are in daily use and have heightened locational informa-tion personal privacy concerns. For instance, in using geospatial technologies, anapparent legal fallacy may have arisen, if only by accident. The idea is that if thereis a legal right to do something then it follows that it must be the right thing to do.So, if it is permissible to undertake data aggregation activities using a number ofdatabases, then it is lawful to do so. But really, the issue is that the legal right mustTHO_C29  20/03/2007  15:09  Page 521 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f522GEORGE C. H. CHOonly be the starting point rather than the end point for justifying one’s actions. Thefact that something is legal does not mean it is either right or a wise thing to do.Thus, data taken out of context – acontextualdata– and used in that sense mayproduce results that may be highly unjust and totally incorrect in particular cases.This is where ethical questions are raised that should be foremost in the thinkingand practice of GI scientists. Some would like to consider ethics as a continuum inwhich there is both a duality of a right and a wrong way of undertaking activitiesas well as ethics being a way of dealing with a right way and a better way of doingthings. In equitable jurisdictions and civil cases there may be a claim to a right, butit is the one who has the better claim that often wins out.Today the right to be left alone is being vigorously defended, and there is resist-ance to increased surveillance in parts of our private lives. But it seems that thereal threat is the creeping acquiescence to all sorts of intrusions without the accom-panying public debate, information, and education. It used to be that when a videocamera was installed, say in the computer lab, the spectre of George Orwell’s 1984and “Big Brother is watching you” was raised (Orwell 1990).Today, it appears that we have grown accustomed to all sorts of cameras watch-ing us in all kinds of circumstances. The reality TVgenre of the “Big Brother” typewhere the public is invited to watch the antics of four or ﬁve couples displayingtheir private, sexual habits raises no public outrage. On the other hand, employerskeeping watch on the Internet use of their employees and monitoring their e-mailtrafﬁc has raised civil liberty concerns. This can be particularly serious when thesemonitoring records are used as grounds for dismissal because of workplace abuse,which would no doubt raise both moral and ethical outrage. The really big questionis: which is the greater sin – protecting personal privacy or surveillance?It has been observed that the surrender to surveillance is now happening and it is taking place “one step at a time, and each step is attractive and relatively benign” (Dobson 2000, p. 24). Clarke (2001) has asked how such advanced, well-educated, well-informed free societies have been so myopic as to permit what hecalls “dataveillance” to have taken place. The answer to him seems to be that thesesoc",
    "chunk_order_index": 329,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-832e6de3e1e23d8d0ba425d957f80ea2": {
    "tokens": 1200,
    "content": "personal privacy or surveillance?It has been observed that the surrender to surveillance is now happening and it is taking place “one step at a time, and each step is attractive and relatively benign” (Dobson 2000, p. 24). Clarke (2001) has asked how such advanced, well-educated, well-informed free societies have been so myopic as to permit what hecalls “dataveillance” to have taken place. The answer to him seems to be that thesesocieties have been conditioned by Orwell’s 1984. In the past ﬁfty years or so, technology has developed and delivered far superior surveillance tools than Orwellhad imagined and to cap it all “we didn’t even notice” (Clarke 2001).So the message is that the public, users of GIS, and policy-makers have to beever-vigilant requiring particular sensitivity in the application, design, and use ofinherently privacy invasive technologies such as those embedded in a GIS.Privacy: The Legal and Regulatory FrameworkIn the developed world, the legal and regulatory framework concerning personalprivacy is characterized by its recency and ad hocregulation and control. No less,its complexity and multiple dimensions have led to conﬂicting views as to how tostructure such a framework. Legislative instruments are usually passed after muchdebate and discussion at various fora and legislative bodies. Such laws may be con-trasted with the common law that is the result of litigation in courts that producesprecedents that are subsequently followed by the courts. Some countries, however,THO_C29  20/03/2007  15:09  Page 522 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW523have promulgated a civil code and these follow rules and regulations that have beencodiﬁed. Examples of these countries are to be found in the European tradition –France, Germany, Austria.To begin with the Australian situation, the Australian Constitution does notempower the Commonwealth Parliament to enact a general law for the protectionof privacy throughout Australia.4However, the Australian government has beenobligated to protect personal privacy stemming from various international covenants,agreements, and treaties to which Australia is a signatory, for example the UniversalDeclaration of Human Rights (UDHR) adopted in 1948.5A “right to privacy” is absent in the US Constitution or the Bill of Rights. However,the US Supreme Court has interpreted a right to individual privacy under the First,Fourth, Fifth, Ninth, and Fourteenth Amendments.6Many privacy decisions in theUS federal courts are based on the Fourth Amendment, which generally provides forthe right of people to be secure in their persons, houses, papers, and effects againstunreasonable searches and seizures.7In 1965, the US Supreme Court suggested thatthere may be “zones of privacy” implicit in the Bill of Rights in the leading caseof Griswold v. Connecticut.8Common law right to privacySince the majority decision in Victoria Park9it has generally been accepted that acause of action for the breach of privacy does not exist in the common law of Australiaany more than it existed in the common law of England.10The issue of a right toprivacy was revisited in Australia recently in a High Court case.11In the UK the rightof privacy of a corporation has been held to exist.12Also, more recently, privacyrights have also been extended to individuals drawn from the fundamental value ofpersonal autonomy.13Courts in several other jurisdictions have also addressed theavailability under common law of an actionable wrong of invasion of privacy –Canada, India, and New Zealand.14One Canadian court has recognized a generalright to privacy and to protect privacy interests under the rubric of nuisance law.15In New Zealand the tort of invasion of privacy has been recognized and s 14 ofthe New Zealand Bill of Rights Act1990 (NZ), while it does not confer a right toprivacy, ensures the freedom of expression (Tobin 2000).In the USA the tort based upon the right to privacy has been developed and is stillevolving in response to the encroachments upon privacy by the media and others.The common law of tort has identiﬁed four activities that give rise to liability for theinvasion of privacy. These are: (1) intrusion upon seclusion; (2) appropriation of name or likeness; (3) publicity given to private life; and, (4) publicity placing a person in a false light.16Some states do not, however, recognize such claims; forexample, New York does not have a false light claim provision.17Other states pro-tect a larger class of persons and private persons, as well as celebrities, such as theCalifornian and New York laws on misappropriation of name or likeness.Privacy legislation – AustraliaIn Australia there are four federal acts that are of importance that deal directlywith privacy: the Privacy Act 1988,Privacy Amendment Act 1990, Data MatchingTHO_C29  20/03/2007  15:09  Page 523 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f524GEORGE C. H. CHOProgram (Assistance and",
    "chunk_order_index": 330,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-3048c3d24099f72431c6b8aec4e43e09": {
    "tokens": 1200,
    "content": "2007  15:09  Page 523 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f524GEORGE C. H. CHOProgram (Assistance and Tax) Act1991, and Privacy Amendment (Private Sector)Act 2000. Each of these pieces of legislation has been passed in response to speciﬁcobligations under the UDHR, International Covenant on Civil and Political Rights(ICCPR) 1966, Organization of Economic Cooperation and Development (OECD)Guidelines of 198018and the United Nations (UN) 1990 Guidelines for the Regula-tion of Computerized Personal Data Files.19Privacy legislation in the USThe Privacy Act of 1974,5 USC §552provides limited privacy protection for government-maintained databases. In general the Act prohibits any government agency from concealing the existence of a personal data record-keeping system. ThePrivacy Act applies to all collections of spatial data collected by federal agencies.The Federal Geographic Data Committee (FGDC) established under the Ofﬁce ofManagement and Budget (OMB) has endorsed a policy on access to public informa-tion and the protection of personal privacy in federal geospatial databases.20In par-ticular, the policy applies to all federal geospatial databases from which personalinformation may be retrieved.In terms of direct legislation, Congress has passed a number of laws that affect theprotection of privacy in general and those regulations applying to the online world inparticular. Privacy protection legislation has been passed to address speciﬁc activitiesincluding ﬁnancial information, education, health, electronic communications, videohiring habits, drivers’ licenses, and children.Many States in the USA have a general privacy act that mirrors the federal government’s Privacy Act. In general the state acts are designed to control the information that a state agency or local government may gather on individuals andthe manner of their use. In addition, most states have separate acts that address theprotection of privacy in speciﬁc situations.Other jurisdictionsThe Privacy Act 1993 (NZ) favors the development of a tort for breach of privacyin respect of public disclosures of true private facts where the disclosure would behighly offensive and objectionable to a reasonable person of ordinary sensibilities.21Unsurprisingly, Privacy Acts that provide for a tort of privacy have been enactedin the provinces of British Columbia, Manitoba, and Saskatchewan in Canada.22A selection of various privacy acts and provisions in 20 countries can be found inCampbell and Fisher (1994).The issue of privacy exempliﬁes the contrasting approaches of Australia, NorthAmerica and Europe. In Europe, for example, private industry codes of conduct aretantamount to no regulation or certainly insufﬁcient regulation. In Australia andNorth America, by contrast, self-regulation is seen as an effective way to achievethe balance between consumer privacy concerns and business needs.Evolving fair information privacy principlesPrivacy per se, serves several valuable functions and more generally it is the abilityto control what other people can know about you. The right to keep identity THO_C29  20/03/2007  15:09  Page 524 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW525information secret serves to help protect the individual from stalkers, abusive ex-spouses, and others whose company that individual may wish to avoid. In the onlineworld, privacy makes identity theft – the wrongful use of a person’s identifyinginformation to obtain goods and services fraudulently – less likely while anonymityenables an individual to blow the whistle on wrongdoing without fear of retributionas well as affording protection for the “whistleblower.” The handling of personalinformation would therefore need to give respect to the emerging “right” to privacyand its protection, and other competing interests that may require the free ﬂow ofinformation.Over the past quarter of a century, governments in Australia, the USA, Canada,and Europe have examined and analyzed their “information practices,” the safeguardsfor the collection and use of personal information, and the adequacy of privacyprotection. Fair information practice principles were comprehensively articulatedin the US Department of Health, Education and Welfare’s seminal report entitledRecords, Computers and the Rights of Citizensin 1973. Five core principles of fairinformation privacy protection gleaned from the various codes noted above relateto Notice–Awareness, Choice–Consent, Access–Participation, Integrity–Security, andEnforcement–Redress.23A particular example of an evolving and developing use offair information practice principles is the EU Data Directive which marks a majorshift in the shaping of global privacy protection but also demonstrates the impactof a foreign protective schema on the remainder of the world.The EU Data DirectiveThe European Union promulgated comprehensive privacy legislation entitled TheDirective on the Protection of Individuals with regard to the Processing of PersonalData and on the Free Movement of such Data24that became effective on October 25,1998. Article 25 of the regulations requires that transfers of personal data take place only to non-EU countries that have an “adequate” level of privacy protection.This is designed to prevent the circumvention of the directive and the creation of“data havens” outside the EU.Before entering into an agreement with a foreign country to allow free circul",
    "chunk_order_index": 331,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-972bdc3144e59941e26eaedb09bc459f": {
    "tokens": 1200,
    "content": "on the Protection of Individuals with regard to the Processing of PersonalData and on the Free Movement of such Data24that became effective on October 25,1998. Article 25 of the regulations requires that transfers of personal data take place only to non-EU countries that have an “adequate” level of privacy protection.This is designed to prevent the circumvention of the directive and the creation of“data havens” outside the EU.Before entering into an agreement with a foreign country to allow free circula-tion of personal data outside the EU, an evaluation of the adequacy of data andprivacy protection in that country has to be undertaken. Several countries have done this including Australia,25Switzerland, Hungary, the USA,26and Canada.27In the case of the USA, it has taken a long time to reach a decision since it related to a speciﬁc system applied in that country known as the “safe harbor”principle.28A safe harbor system permits US companies to satisfy the European “adequacy”standard while maintaining their traditional self-regulatory approach to data pro-tection. In July 2000 the European Commission approved the safe harbor frameworkas meeting the “adequacy” standard (Harvey and Verska 2001, Yu 2001).The implications of the EU Data Directive for other countries, however, are uncer-tain. Australia’s Privacy Amendment (Private Sector) Act 2000 (Cwlth) puts in placeregulations for the use and handling of personal information by individuals and pri-vate companies. One of the NPPs obligates companies to secure all personal andsensitive electronic data that is stored, processed, or communicated in their software,systems, and networks (Handelsmann 2001).THO_C29  20/03/2007  15:09  Page 525 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f526GEORGE C. H. CHOThe Data Protection Act 1998 (UK) replaced the Data Protection Act1984 (UK)and took effect from 1999. The new Act governs the collection, processing, anduse of data in the UK by any organization that requires registration with the DataProtection Commissioner. Transfer of data or permitting its access by anyone out-side the EU, for example via the Internet, is heavily regulated and data controllershave to ensure compliance with the regulations governing such transfers.The Canadian Personal Information Protection and Electronic Documents Act2001 (PIPEDA) (Canada) came into effect on January 1, 2001 and regulates theuse and collection of personal information (Krause 2001). The Act applies not onlyto Canadian companies but also potentially to any entity that collects personal information in Canada and/or personal information from Canadian residents. Thisenactment ensures that Canada complies with the EU Directive’s standard for “adequacy” for the protection of privacy.Geospatial Technologies and Privacy ImplicationsGeospatial technologies in common use that rely on both spatial attributes as wellas other personal and feature information have the “ability” to track people, theirshopping, and travel habits, the places that they go to for recreation and for whatduration, and in some instances to make an inference of the purposes of that event.Here we consider location-based services (LBS) that rely on the key ingredients of timeand space (see Chapter 32 by Brimicombe in this volume, for further discussion ofthese services). LBS may be considered to be no different from geodemographics,an information technology that enables marketers to predict behavioral responsesof consumers based on statistical models of identity and residential location (Goss1994, 1995).LBS have become commonplace because of the use of geocodes and GPS andother mobile communication and tracking technologies. LBS inferentially involvesthe tracking of people through the use of credit card data that may result in proﬁlingexercises, statistical modeling, and pattern analysis. More generally, GISc, using suchtechnologies, may give the game away as to who we are, where we are, and what wehave been doing either by way of speech, purchases, or simply being at a location.There is one view that without legislation to curb the (mis)use of such data therewould be chaos. However, an equally compelling but opposing view is that there shouldbe no legislation but rather just self-regulation by industry itself (Westin 1967, 1971).Data aggregation and databasesPrivate sector commercial applications of both GIS and LBS are perhaps the fastestgrowing areas of business and this has fed the need for more data. For example,in order to maintain a competitive edge, marketers need good databases to maketheir decisions while simultaneously handling geographical data efﬁciently. Patterns,relationships, and trends become clearer when depicted visually in graphs, charts,and maps rather than just columns of numbers or text.A database called EQUIS, developed by National Decision Systems, “maintainsa database of ﬁnancial information for over 100 million Americans on more thanTHO_C29  20/03/2007  15:09  Page 526 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW527340 characteristics including age,",
    "chunk_order_index": 332,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6906981a43d35a6eb24834aae63c8608": {
    "tokens": 1200,
    "content": "7  15:09  Page 526 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW527340 characteristics including age, marital status, residential relocation history, creditcard activity, buying activity, credit relationships (by number and type), bankruptcies,and liens. This information is updated continuously at a rate of over 15 millionchanges per day” (Curry 1992, p. 264).In 1993 Equifax and National Decision Systems announced Infomark-GIS – afully integrated GIS speciﬁcally designed for marketing applications and decisionmaking (Equifax National Decision Systems 1993). There are other US companiestoo that are also engaged in the collection, processing, and storage of data pertain-ing to individuals.29These ﬁrms obtain consumer information from credit bureaus,public records, telephone records, professional directories, surveys, customer listsand other data aggregators.In view of the commercial market for data, databases, and data aggregation services, Curry (1994) has suggested that the use of geospatial technologies willproduce multi-faceted problems that would similarly require multi-dimensional solutions. The concerns raised include the fact that the technologies consist of andpromote the widespread availability of unregulated data. This leads to the difﬁcultyof regulating data matching that must take place if the geospatial tools are to produce meaningful results. Further, geospatial technology is inherently visual but this strength also exposes a major weakness in that it may produce map inferences that may be both statistically and ecologically fallacious. Finally, there is the alteredexpectation of privacy rights because the case law may promote an erosion of thoseaspects of life where a person can feel safe, secure from search and surveillance,and most importantly with information kept private.Geospatial technologies are said to do best at the intersection of location, time,and content. But each of these elements tends to produce tensions of their own. Forexample, in regard to letting people know where they may be and keeping this facthidden because they may not wish to be found. Here we have a technology that isemploying the power of “place.” GIS-based geostatistical models using locationsand space have been used to study the home range of animals, for instance. In ananalogous way, geographical proﬁling may be applied to the “home range” of pre-datory humans who may have inadvertently patterned habitual routes when stalkingpotential victims.Leipnik, Bottelli, von Essen, et al. (2001) reported on the important role of geo-spatial technologies in investigating and gathering evidence of a locational nature inorder to convict a serial killer. When the serial killer Robert Lee Yates was arrestedin April 2000 in Spokane County, Washington, he is reported to have told his wifeto “destroy the GPS receiver.” This was because there were incriminating data onit showing the 72 waypoints associated with several journeys that had been usedin disposing of the bodies of the victims. Indeed, this example demonstrates theextent to which GIS and GPS technologies are permeating society and their use –both by law enforcement agencies and criminals. However, a court appeal couldchallenge the validity and use of the GPS data. The argument could be that usingthe GPS to track suspects without their knowledge might involve an invasion ofprivacy rights as well as failing to meet the legal test of ﬁnding the “least obtrusivemeans” for police to gather information about a suspect. But, in counter argument,it may be submitted that sometimes consent needs to be conspicuously absent incases in which the suspicions of the “quarry” are not to be aroused prematurely.THO_C29  20/03/2007  15:09  Page 527 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f528GEORGE C. H. CHOThe question may be asked “Is there any special data protection or privacy issueassociated with locational data?” The answer is in the afﬁrmative but its explanationmust be given indirectly. “Sensitive personal data” is regarded as data that identiﬁes,among other things, a person’s ethnic background, religion, political afﬁliations, or sexual habits. However, the location of a person is not considered sensitive personal data. Yet, when processing data on persons, especially when locations areinvolved, say in terms of visiting synagogues on a regular basis or particular areasof ethnic concentrations, it is arguable that sensitive data are being processed and unintended inferences are being made about a person’s religion or ethnicity(Rowe and McGilligan 2001).Location, tracking and dataveillanceMost geographers will understand location to mean the relative positions of entitiesin space and time and of events taking place. Locational information describes thewhereabouts of a person or entity in relation to other known objects or referencepoints.In this context, tracking refers to the plotting of the trail or sequence of locationswithin a space that is taken by an entity over a period of time. The “space” withinwhich the entity’s location is tracked can be a physical or a geographical space.However, such a space can also be “virtual” in cases in which that person mayhave had successive",
    "chunk_order_index": 333,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-44981d35cb17261dccbd3faef07c6a05": {
    "tokens": 1200,
    "content": "and of events taking place. Locational information describes thewhereabouts of a person or entity in relation to other known objects or referencepoints.In this context, tracking refers to the plotting of the trail or sequence of locationswithin a space that is taken by an entity over a period of time. The “space” withinwhich the entity’s location is tracked can be a physical or a geographical space.However, such a space can also be “virtual” in cases in which that person mayhave had successive interactions in time with different people either simultaneouslyor at different times.Data surveillance, abbreviated to dataveillance, is the systematic use of personaldata in the investigation or monitoring of actions or communications of one ormore persons. Conceptually there may be two separate classes – personal surveil-lancebeing the surveillance of identiﬁed persons for various purposes. This mayinclude investigation, monitoring, or gathering information to deter particularactions by that person or particular behaviors of that person. Mass surveillance,on the other hand, is the surveillance of large groups of people, again for the purpose of investigation or monitoring, which may aid in the identiﬁcation of persons of interest about whom a surveillance organization has cause for concern(Clarke 1999a).Geospatial technology applications: home locationWhile geospatial applications based on remote sensing of the Earth on regional scales,and the use of GIS in very small-scale city planning are relatively well known, theapplication of such technologies to home location are less prominent. In general,utility companies may use home location data to track usage of power, gas, andwater, whereas social security beneﬁt providers and license administrators may makeuse of street addresses to tag locations for administrative purposes.Telecommunication services to the home via the double-twisted copper wire pro-vide home location information to the Public Switched Telephone Network (PSTN)of a phone utility. All phone communications to and from the home address can berecorded, stored, analyzed and made available to others. Telephone trafﬁc data maybe analyzed as call records and have been used for billing and invoicing purposes.THO_C29  20/03/2007  15:09  Page 528 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW529The data also give paired locational information of the origin and destination ofcalls (dyads) that may be analyzed for particular information.More recently, home telephone services have facilities such as caller id, calling-lineid (CLI), and calling-number display (CND) that give information of a caller, thecaller’s phone number, and the time of the call. Caller, line, and number identiﬁcationsare now generally available and have been used by telecommunication companies,law enforcement agencies, and consumers as a means of screening calls.Australia on Disk (AOD) is a directory of every residential and business phonenumber in the country. This comprises all 55 national phone directories giving atotal of 1.3 million business listings and 6.9 million residential phone numbers in2005. While there are obvious environmental beneﬁts in not having to produce papercopies of telephone directories, there are equally potent privacy implications not to do so given that a disk containing residential information may be put to otherthan legitimate uses.30AOD does not permit reverse searching – that is, if you havea phone number and you want to search to ﬁnd out the street address to which it is connected, the product will be unable to answer the query. However, AODpermits searches and printing of whole lists by whatever criteria are speciﬁed suchas post codes, surnames, or “target” markets. The information obtained can thenbe used to individually address letters to be sent out or used in a phone market-ing campaign. An additional product, the AOD Mapperpresents data and mapswith areas of interest color coded to show their relative importance. The maps couldidentify hotspots where the residents are most likely to match particular proﬁles,as with, for example, the suit-buying yuppie, the private school targeting high-incomeearners with young families, or health insurance companies looking for low risk,single, professionals.31Tracking movements of individuals over spaceThe tracking of individuals over borders has normally been controlled and monitoredat immigration counters by checking and stamping national passports and by the use of identity cards. More recently, such travel documents have had electronicchips embedded in them that permit electronic scanning and automatically provideentry and egress at checkpoints. The data captured may yield patterns of entry anddeparture of citizens and visitors alike. At a micro-scale, movements within buildingsmay be monitored using video surveillance equipment. In combination with videoevidence, movement over time and space within buildings, analyses using patternrecognition and/or matching algorithms may yield greater insights to movement patterns of individuals or groups of people and the most trafﬁcked areas. However,while the system may provide greater effectiveness to the security of a particularbuilding, the technology is highly intrusive of the privacy of its users.The US Department of Transport (DOT) Intelligent Transportation Systems (ITS)32program has made extensive use of GIS technologies, along with surveillance andother computer technology, to provide in-vehicle mapping as well as both laggedand real-time transportation management services.The ITS concept is one where there is an interactive link from a vehicle’s elec-tronic system with roadside sensors, satellites, and a centralized trafﬁc managementsystem to constantly monitor each vehicle’s location and the road trafﬁc conditions.THO_C29  20/03/2007",
    "chunk_order_index": 334,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0303efe12462b74d01ada39f691ad812": {
    "tokens": 1200,
    "content": "Systems (ITS)32program has made extensive use of GIS technologies, along with surveillance andother computer technology, to provide in-vehicle mapping as well as both laggedand real-time transportation management services.The ITS concept is one where there is an interactive link from a vehicle’s elec-tronic system with roadside sensors, satellites, and a centralized trafﬁc managementsystem to constantly monitor each vehicle’s location and the road trafﬁc conditions.THO_C29  20/03/2007  15:09  Page 529 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f530GEORGE C. H. CHOMore advanced systems include the reception of alternative road information inreal-time via two-way communications, on-board TV screens, and mapping systems.While few will argue with the efﬁcacy of such a system in regard to public safetyand convenience there are other unintended outcomes that must be considered. Policymakers and developers of these systems must contend with its impact on individualprivacy.Highway surveillance and pattern recognition can potentially be both valuablesupervisory tools for regulators as well as investigative and forensic weapons forlaw enforcement agencies.Tracking transactionsThere has been a variety of methods used to capture transaction data. These includecheques that carry data in MICR – magnetic ink character recognition – and turn-around documents with OCR – optical character recognition – where the form hasalready been ﬁlled-in automatically for the client to authenticate and return. Othermeans of data capture are magnetic strips, embossed data codes, bar coding, or adevice with a location identity such as a phone socket in the home environment. Themain applications are in ﬁnancial transactions from deposits, to loan repayments,salaries, cash withdrawals at automatic teller machines (ATMs), use of credit/debitcards and electronic funds transfer-point of sale (EFTPOS), and others. These seem-ingly helpful and efﬁcacious systems, however, turn previously unrecorded and/oranonymous activities into recorded-identiﬁed transactions. Even more important, thedata are being aggregated in a far more intense manner than before and these datahave an associated location tag in the data trail. There are also real-time locationmechanisms built into some of these electronic transaction tools so that passive monitoring and surveillance can now be re-purposed for law enforcement activities.Tracing communicationsWhile locational information and address tags may be readily available when usingthe PSTN, mobile telephony services including the use of pagers, personal digitalassistants (PDAs), analog/digital and satellite phones make the tracing of personsand locations difﬁcult. With mobile telephony the tracing of a device and its usageeither in real-time or logged-in message banks is more difﬁcult because its locationis constantly changing.The global plan to give each home phone its own e-mail address has also raisedprivacy concerns. An alliance between the telecommunications industry and the Internet Engineering Task Force (IETF) is seeking to create a protocol called ENUM.33This protocol is used to map telephones, facsimile machines, and other devices froma phone number to the Internet. The plan is to use the domain name system (DNS)for the storage of E.164 numbers. E.164 is the International TelecommunicationsUnion (ITU) standard that deﬁnes the format of telephone numbers, speciﬁcally forinternational subscriber dialler numbers (ISDN).34Thus, with ENUM you have asingle electronic access point or address (International Telecommunications Union2001). However, Clarke (2002) is not sanguine about this prospect because the effectof ENUM would establish a single unique contact number for each individual. IfTHO_C29  20/03/2007  15:09  Page 530 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW531it were successful, it would represent a unique personal identiﬁer, with all of thedangers to privacy and freedoms that this entails.A combination of national security, law enforcement, and corporate marketinginterests is pushing for the provision of handsets that are locatable to within a few meters; just as in the case of the location of callers to the emergency number911 in USA or 112 in Europe.35The US Federal Communications Commission (FCC)has now imposed requirements on wireless carriers to provide emergency call services with far more precise locational identiﬁers. Handset-based solutions mustbe identiﬁed to within 50 m of a call while for network solutions the identiﬁcationmust be within 100 m.36Convergence of locational and tracking technologiesBy far the technology of most relevance for present discussion is GPS. This techno-logy depends on a constellation of satellites to give positional information in fourdimensions: latitude, longitude, altitude, and time. With the presidential edict of turn-ing off selective availability (SA) – the purposeful degrading of positional information– users of GPS are now able to poll satellites for positional information and be givenreferences to within a meter of their location.37Differential GPS (DGPS) uses thesame technology except that locations are determined as a differential to the datareceived in addition to and relative to a surveyed point on the ground. Hence, theaccuracy obtained by DGPS methods can be quite",
    "chunk_order_index": 335,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9bfbb279d8ec1a779040d16f9e3c4b48": {
    "tokens": 1200,
    "content": "altitude, and time. With the presidential edict of turn-ing off selective availability (SA) – the purposeful degrading of positional information– users of GPS are now able to poll satellites for positional information and be givenreferences to within a meter of their location.37Differential GPS (DGPS) uses thesame technology except that locations are determined as a differential to the datareceived in addition to and relative to a surveyed point on the ground. Hence, theaccuracy obtained by DGPS methods can be quite precise. Assisted GPS (AGPS) technology, on the other hand, has been developed in conjunction with informationcommunication technology (ICT), which uses a server at a known geographical location in the network. This information reduces the time, complexity, and powerrequired in determining location (see Chapter 28 by Dana in this volume for addi-tional information on Global Positioning Systems).With the advent of wireless communications, location information has come underscrutiny. In the USA the Telecommunications Act of 1996 included location informa-tion as Customer Proprietary Network Information (CPNI) that gave time, date, andduration of a call, and the number dialed. In the EU the Directive on Privacy andElectronic Communications(2002/58/EC) established a technology-neutral legal standard for privacy protection in the processing of personal data for all electroniccommunications. By the end of 2003 only four countries – Denmark, Sweden, Finlandand Spain – had implemented the Directive.38RFID is an abbreviation for radio frequency identiﬁcation, a technology similarto bar code identiﬁcation. With RFID the electromagnetic or electrostatic couplingin the radio frequency portion of the electromagnetic spectrum is used to transmitsignals. RFID systems can be used just about anywhere, from clothing tags to mis-siles to pet tags to food – anywhere a unique identiﬁcation system is needed.39Privacy risks with locational and tracking technologiesThere is a saying that “a man’s home is his castle.” However, this bastion of privacyis slowly being eroded not only in regards to a loss in physical terms but also inregards to a loss of privacy of the airwaves, and, perversely, thermal emissions froma property and visual monitoring.THO_C29  20/03/2007  15:09  Page 531 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f532GEORGE C. H. CHOWith geospatial technologies there has already been litigation on the basis of such“trespass” to land properties. The grounds on which these cases have been arguedinclude the idea of an “objective” expectation to privacy as may be found in the FourthAmendment to the US Constitution or a “subjective” expectation as provided undercase law interpretations as the following cases demonstrate.In Dow Chemical v. United States(1986)40although the District Court held that the aerial photography was a “violation of Dow’s reasonable expectation ofprivacy and an unreasonable search in violation of the Fourth Amendment,” theUS Supreme Court held that the “open ﬁeld” doctrine applied to the case, and there-fore there was no invasion of privacy. Similarly in California v. Ciraolo41the SupremeCourt found that it was acceptable for the police to ﬂy over a fenced-in backyardat an altitude of 1,000 feet to undertake monitoring. Also in Florida v. Riley42acourt approved the use of a helicopter, hovering at 400 feet, to observe marijuanaplants through a hole in the roof of a defendant’s greenhouse.The remit to observe from the air has also extended to monitoring emissions. In United States v. Penny-Feeny43a Hawaii District Court endorsed the police use ina helicopter of a forward looking infrared (FLIR) device to discern heat emissionsfrom a garage to gather information on illegal activities. Beepers and identity tagshave also been endorsed to track the location of individuals in motor vehicles andthen use GIS to map and trace routes.44In United States v. Smith45a US Court of Appeals for the Fifth Circuit has ruledthat technological advances may be capable of expanding the legally protected rangeof privacy that individuals enjoy.The discussion so far suggests that there may be three different types of techno-logies that either invade or enhance the privacy of individuals. Some are expresslyprivacy-invasive technologies (PIT) including “data-trail generation through denialof anonymity, data-trial intensiﬁcation as in identiﬁed phones, stored valued cards(SVC), and intelligent transport systems (ITS), data warehousing and data mining,stored biometrics, and imposed biometrics” (Clarke 1999b). Then, since around themid-1990s, there has emerged those that are expressly designed as privacy-enhancingtechnologies (PET) seemingly as a reaction and bid to reverse trends in technologythat have hitherto been privacy invasive. Tools that have been developed to assistthe protection of privacy interests include those that make individuals genuinelyuntraceable and anonymous. The third type of technology, labeled privacy sym-pathetic technologies (PST), are capable of delivering genuine anonymity. Such PSTare further subdivided into anonymity services, pseudonymity services, and personaldata protection.46These services use various devices that provide outright anonymityto those that encrypt identity tags which may only be shared with selected parties.In between there are pseudo-anonymous devices that give a semblance of anonymitybut from which identity may be traced. Such technologies provide cogent remindersthat we should always be conscious about maintaining a balance between privacyand other interests such as accountability.To ass",
    "chunk_order_index": 336,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4ec7f87e784eb8b789ce4821b3858c6e": {
    "tokens": 1200,
    "content": "capable of delivering genuine anonymity. Such PSTare further subdivided into anonymity services, pseudonymity services, and personaldata protection.46These services use various devices that provide outright anonymityto those that encrypt identity tags which may only be shared with selected parties.In between there are pseudo-anonymous devices that give a semblance of anonymitybut from which identity may be traced. Such technologies provide cogent remindersthat we should always be conscious about maintaining a balance between privacyand other interests such as accountability.To assuage consumer privacy concerns both legislators and those in the geo-spatial technologies industries are battling to ﬁnd the right balance: a solution thatprovides PET and PST while at the same time preserving the functionality of thetechnology even if it may have the effect of PIT.It may be appropriate here to make two ﬁnal observations. First, location informa-tion should only be used to provide services to users. It will be inappropriate forTHO_C29  20/03/2007  15:09  Page 532 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW533location information to be used for secondary purposes, such as marketing basedon an individual’s location or by government for law enforcement and national security purposes as it may create the dataveillanceof society without the necessaryinvestigatory mandate. Second, while voluntary standards and codes of conduct may work well in Australia, UK, Canada, the USA, and elsewhere, in the EU thepreferred route to stem the erosion of personal privacy is through the use of legis-lation and mandatory standards. Whatever the solution, the strong message is thatlaws and regulations specifying how consumers authorize access to their privacyneed to be clear, consistent, and technology-neutral.The use of legislation as a means of protecting personal privacy and the soft-touch,self-regulatory approach to such protection may reﬂect differences in cultures, his-tories, and philosophies. It may be that for economies like Australia, the UK, Canadaand the USA there is reluctance for governments to interfere with market forces andthey thus choose to have minimal legislation. Most of these countries use sectoralapproaches that rely on a mix of legislation, regulation, and self-regulation, whilethe European approach is one of strict regulation. Moreover, a sceptical citizenrymay be suspicious of, and loath to permit governments to have greater control ofprivate information than is necessary. The soft-touch approach will permit a middleground with industry self regulating itself as well as giving governments some con-trol over privacy protection. It is still an open question whether the marketplaceor legislation can decide what is best for the protection of personal informationalprivacy. As a special case, with globalization as well as the commodiﬁcation of personal data, the EU Data Directive portends a different future.Table 29.1 synthesizes the material presented in this section.CONCLUSIONSThis chapter has canvassed the issues of personal and informational privacy and theuse of geospatial technologies. The question of how invasive GI technology has beenor can potentially be is answered in the negative, that is, the technology is not per-sonal data invasive. Nevertheless, there is a need for vigilance as well as the ethicaluse of such technologies even if there are social beneﬁts. The legal and regulatoryframework governing the issues of privacy was then discussed using the Australianjurisdiction as the backdrop and contrasting it with the US regime. While there areno constitutional impediments in preserving a right to privacy in Australia, thereare four so-called privacy laws supported by the common law in protecting theconﬁdentiality and disclosure of personal information. Supplementing the law areindustry codes of conduct and self-regulation that complete the privacy package.Analyses of geospatial applications with regard to home location, the trackingof individuals over space, tracing ﬁnancial transactions and communications hasidentiﬁed privacy risks inherent in the use of such technologies. The identiﬁed privacyrisks may be categorized as invasive, enhancing, or sympathetic. The implicationsfor user organizations is that geospatial technology applications are but one of thearray of different kinds of surveillance and in particular that of dataveillance. Equally,technology providers should be reminded of these sorts of privacy issues and thatthey should genuinely strive for anonymity in the use of personal information whenmarketing their products.THO_C29  20/03/2007  15:09  Page 533 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f534GEORGE C. H. CHOTable 29.1Privacy risk status and geospatial technologiesGeospatial technologies related toLOCATION:Home address:FixedMobileMOVEMENTIndividualMassTRANSACTIONSFinancialRetailCOMMUNICATIONSFixedMobileCONVERGENTTECHNOLOGIESInformation TechnologyMobile, on personPrivacy status: E – enhancing; I – intrusive, N – neutral.ApplicationsUtilities, beneﬁt providers, licence administrationInhabitant registration systemsWhite Pages, ex-Directory, silent numbersReverse White PagesGPS/DGPS/AGPSAuto-reporting mobile devicesTrans-border (passports)Credentialed building accessBiometricsTranspondersCCTVPattern recognition; pattern matchingIntelligent Transport Systems and imposedidentiﬁers (travel cards)Check data with magnetic ink character recognitionTurnaround documents with optical characterrecognition",
    "chunk_order_index": 337,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d4ae80ca1b3bb56c1a8528591c34f669": {
    "tokens": 1200,
    "content": "– enhancing; I – intrusive, N – neutral.ApplicationsUtilities, beneﬁt providers, licence administrationInhabitant registration systemsWhite Pages, ex-Directory, silent numbersReverse White PagesGPS/DGPS/AGPSAuto-reporting mobile devicesTrans-border (passports)Credentialed building accessBiometricsTranspondersCCTVPattern recognition; pattern matchingIntelligent Transport Systems and imposedidentiﬁers (travel cards)Check data with magnetic ink character recognitionTurnaround documents with optical characterrecognitionEncoding, magnetic stripsBar codingATMs, EFTPOS, Credit/debit cardsLoyalty schemesSmart cards, stored valued cardsReal-time locater mechanismsPSTN trafﬁc data, call recordsReal-time tracing, interceptionMobile telephony, pagers, analogue/digital/satellitephones/PDAPersonal phone numbers, ENUMCaller id, CLI, CNDVoice data TCPIP/VoIPRFID computer wearEPIBIdentity tags (prisoners, children)Privacy statusN/IIEEIIN/IIIN/IINN/INNNNIIEIIIN/ININ/IIIITHO_C29  20/03/2007  15:09  Page 534 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW535The implications for policy makers including privacy and data protection com-missioners is one where the tensions between economic rationalism and the socialgood is stretched and seemingly irreconcilable. But this need not be the case if governments are focused on both law and order, as well as striving for stability,consistency, and sensitivity that are supportive of privacy protection.Geospatial technologies such as LBS may “push” content but at the same time “pull”in locational information. Their use should not have a chilling effect on personalbehaviors or actions. That effect may only be apparent where there is the dangerof the acontextualuse of personal information and data. Hence, it is imperativethat the idea of a “zone of privacy” around one’s personal and private affairs shouldbe fostered and encouraged so that the onus is on those who intrude into the zoneto justify their conduct. This zone will then demarcate a boundary to a private anda “public” area with a nebula in between where everyone can interact and relatewith each other and in which technology can be freely used. Privacy need no longerbe “too indeﬁnite a concept to sire a justiciable issue” (Tapper 1989, p. 325).While technology will continue to be both a problem and a solution, technologicaladvances such as LBS, geoinformatics, and GISc will continue to push the privacyenvelope. But, technological means alone cannot help manage and enhance pri-vacy protection, legislation, corporate policy, and social norms may, in the ﬁnalanalysis, eventually dictate the use of location information generated from trackingdevices and geospatial technologies.Fair information practices are the cornerstone of many privacy laws today. However,these practices may be found wanting, especially when they have to deal with datamanipulation using disparate databases joined together in geospatial technologiessuch as a GIS. The solutions may lie in a mix of international standards, self-regulation, legislation, and government policy. While the harmonization of laws and regulations and achieving consistency of privacy protection, especially acrossall jurisdictions, is very difﬁcult, yet, international standards must of necessity emerge.One way forward would be to keep canvassing for a global convergence of privacyregulation. It is may be counter-productive for each country to impose a separateprivacy regime. We are all responsible for keeping an eye on the world in order toprevent abuse of surveillance technologies not by government regulation but by amutual, shared responsibility for the world in which we live and disdain for thosewho abuse and misuse the privilege (Waters 2000).ENDNOTES1See Beckman Center for Internet and Society and in particular the course syllabus for“Privacy in Cyberspace” at http://eon.law.harvard.edu/privacy99/syllabus.html.2Olmstead v. US,277 US 438 (1928).3See Legal Information Institute at http://lii.law.cornell.edu/ and theConcise OxfordDictionary(Oxford, Clarendon Press) for deﬁnitions of ethics relating to morals, treat-ing of moral questions; morally correct, honourable.4Australian Law Reform Commission (ALRC) 1983 Report No. 23, Privacy.Canberra:AGPS, p. xliv.5UDHR 1948 Universal Declaration of Human Rights, December 10, 1948, Article 12athttp://www.un.org/Overview/rights.htmland Article 17 of the ICCPR 1976 Inter-THO_C29  20/03/2007  15:09  Page 535 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f536GEORGE C. H. CHOnational Covenant on Civil and Political Rights (New York, United Nations) at http://www.privacy.org/pi/ intl_orgs/un/international_covenant_civil_political_rights.txt.",
    "chunk_order_index": 338,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a8f4610f1516651bb1d21315331171b0": {
    "tokens": 1200,
    "content": "on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f536GEORGE C. H. CHOnational Covenant on Civil and Political Rights (New York, United Nations) at http://www.privacy.org/pi/ intl_orgs/un/international_covenant_civil_political_rights.txt.6The First Amendment guarantees freedom of communications and the expression of ideas;the Fourth Amendment guarantees freedom from unreasonable search and seizure, includ-ing (in some cases) electronic, aural, visual, and other types of surveillance; the FifthAmendment guarantees freedom from self-incrimination, and guarantees due process ofthe law with regard to the Federal government; the Ninth Amendment recognizes thatrights not speciﬁed in the Constitution are vested with the people; and the FourteenthAmendment guarantees due process and equal protection of the law with regard to thestates.7The Fourth Amendment of the US Constitution provides that “[t]he right of the peopleto be secure in their persons, houses, papers, and effects, against unreasonable searchesand seizures, shall not be violated, and no Warrant shall issue, but upon probable cause,supported by Oath or afﬁrmation, and particularly describing the place to be searched,and the persons or things to be seized.”8Griswold v. Connecticut, 381 US 479, 14 L.Ed.2d 510, 85 S. Ct. 1678 (1965).9Victoria Park Racing and Recreation Grounds Co Ltd v. Taylor (1937) 58 CLR 479;43 ALR 597 (HCA).10R v. Khan[1997] AC 558 at pp. 582–3.11Australian Broadcasting Corporation v. Lenah Game Meats Pty Ltd[2001] HCA 63,November 15, 2001.12R v. Broadcasting Standards Commission; ex parte British Broadcasting Corporation;[2000] 3 WLR 1327; [2000] 3 All ER 989.13Douglas v. Hello! Ltd [2001] 2 WLR 992; [2001] 2 All ER 289 per Sedley LJ at p. 120.14Aubrey v....ditions Vice-Versa Inc. [1998] 1 SCR 591; Govind v. State of MadhyaPradesh (1975) 62 AIR (SC) 1378; P v D[2000] 2 NZLR 591.15Canadian Tort Law, 6th edn (1997) at 56; Aubry v. Duclos (1996) 141 DLR (4th) 683.16Restatement of the Law (Second) Torts§ 652A.17See Howell v. New York Post Co.,596 N.Y.S.2d 350; 612 N.E.2d 699 (Ct. App.) (1993).18OECD 1980 Guidelines on the Protection of Privacy and Transborder Flows ofPersonal Data, Recommendation by the OECD Council of 23 September 1980. Seehttp://www.oecd.org/document/18/0,2340,en_2649_34255_1815186_1_1_1_1,00.html,http://www.oecd.org/document/18/0,2340,en_2649_34255_1558954_1_1_1_1,00.html,and http://www.oecd.org/documentprint/0,2744,en_2649_201185_15589524_1_1_1_1,00.html. See also EEC 1980 Council of Europe Convention for the Protection of Individ-uals with regard to Automatic Processing of Personal Data, Brussels, EEC and Councilof Europe 1981 Council of Europe Convention for the Protection of Individuals withregard to Automatic Processing of Personal Data,Brussels, CE (at http://www.privacy.org/pi/intl_orgs/coe/dp_convention_108.txt).19United Nations 1990 Guidelines for the Regulation of Computerized Personal Data Filesat http://www.datenschutz-berlin.de/gesetze/internat/aen.htm.20See FGDC Policy on Access at http://www.fgdc.gov/Communications/policies/policies.html.21Bradley v. Wingnut Films Ltd[1993] 1 NZLR 415; P v D [2000] 2 NZLR 591.22See Lord v. McGregor (2000) 50 CCLT (2d) 206; [2000] BCSC 750.23See Information Infrastructure Task Force Privacy Working Group at http://www.ntia.doc.gov/ntiahome/privwhitepaper.html. See also Federal Trade Commission(FTC), Privacy Online: A Report to Congress (1998) at http://www.ftc.gov/reports/privacy3/index.htm and FTC Privacy Online: Fair Information Practices in the ElectronicMarketplace(May 2000) at http://www.ftc.gov/os/2000/05/index.htm#22.THO_C29  20/03/2007  15:09  Page 536 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW53724European Union",
    "chunk_order_index": 339,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7902c8308baaa740945d6fad194fc555": {
    "tokens": 1200,
    "content": "/2007  15:09  Page 536 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW53724European Union Data Directive 1995 Directive on the Protection of Individuals withregard to the Processing of Personal Data and on the Free Movement of such Data,Brussels, European Commission, Directive 95/46/CE, Ofﬁcial Journal of the EuropeanCommission(L 281) and at http://ec.europa.eu/justice_home/fsj/privacy/docs/95-46-ce/dir1995-46_part1_en.pdf and http://ec.europa.eu/justice_home/fsj/privacy/docs/95-46-ce/dir1995-46_part2_en.pdf.25See Australia, Privacy Amendment Act2000 (Cwlth) approved December 22, 2000;http://www.privacy.gov.au.26Ofﬁcial Journal of the European CommissionL 215 of August 25, 2000, pp. 1, 4 and7, respectively.27See http://europa.eu.int/comm/external_relations/canada/summit_12_99/e_commerce.htmand Ofﬁcial Journalof the European CommissionL 002, 04/01/2002, pp. 0013–6. Seealso the EU “adequacy” standard agreement at http://europa.eu.int/comm/internal_market/en/dataprot/wpdocs/wp39en.pdf.28Safe Harbor Principles are available at http://europa.eu.int/comm/internal_market/en/dataprot/news/shprintiples.pdf.29A search of those ﬁrms classiﬁed under the Standard Industrial Classiﬁcation (SIC) code 7374 for companies engaged in marketing and business research services yieldedapproximately 50 companies.30Each year in Australia Sensis/Telstra produces about 55,000 tonnes of directories or 18 million sets of Yellow Pages and White Pages of which 80 percent is recycled. Butthat still means about 11,000 tonnes go into landﬁlls each year. See Lowe (1994).31Because of an ongoing litigation between Sensis (Telstra) and Australia On Disc, bothparties reached an out of court settlement that forced the publisher of AOD to imme-diately stop distributing the product as of December 29, 2003. See http://www.bsgi.biz/aodspecial.htm and Hull (1994).32Also known as Intelligent Vehicle Highway Systems (IVHS), and used interchangeably here.33See Internet Engineering Task Force website at http://www.ietf.org.34IETF 2000 “E.164 Number and DNS” RFC 2916 September 2000 at http://www.ietf.org/rfc/rfc2916.txt.35The 112 emergency number is incorporated in the international global system for mobilecommunications (GSM) and can be dialled from anywhere in the world where there isGSM coverage with the call transferred to that country’s primary emergency call servicenumber. The 106 emergency calls service number is for the exclusive use of text-based tele-communication users, especially the hearing or speech impaired. See Australian Commun-ications Authority (ACA) 2004 Location, Location, Location, January, Melbourne, ACA.36See FCC requirements at http://www.fcc.gov/911/enhanced/.37The White House, Ofﬁce of the Press Secretary 2000 “Statement by the President regard-ing the United States’ decision to stop degrading global positioning system accuracy,”May 1 at http://www.ostp.gov/html/0053_2.html.38In Japan the guidelines on the protection of personal data in telecommunications business established a clear standard for consent to use of location information. In May 2003 the Diet passed a package of bills known as the Personal Data ProtectionLaw that codiﬁes the requirement for informed opt-in consent (Ackerman, Kempf, andMiki 2003).39See Webopedia deﬁnition of RFID at http://www.webopedia.com.40106 S. Ct. 1819, 90 Led 2d 226 (1986).41106 S. Ct. 1809 (1986).42488 US 445 (1988).43773 F. Supp. 220 (D. Haw. 1991).44United States v. Knotts 460 US 276 (1983); United States v. Karo 468 US 705 (1984).THO_C29  20/03/2007  15:09  Page 537 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f538GEORGE C. H. CHO45No. 91-5077 5th Cir. November 12, 1992.46Anonymity services make use of identiﬁers for the purpose of records or transactionswhereas pseudonymity services are those where one cannot, in the normal course of events,be associated with a particular individual. When an person uses a pseudo-identiﬁer thena digital persona, e-persor a nymis born; this is the model of an individual’s publishedpersonality",
    "chunk_order_index": 340,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d542dbddfad4099d805764ac62a68d2f": {
    "tokens": 1200,
    "content": "No. 91-5077 5th Cir. November 12, 1992.46Anonymity services make use of identiﬁers for the purpose of records or transactionswhereas pseudonymity services are those where one cannot, in the normal course of events,be associated with a particular individual. When an person uses a pseudo-identiﬁer thena digital persona, e-persor a nymis born; this is the model of an individual’s publishedpersonality, based on data, maintained by transactions and intended for use as a proxyfor that individual. See Clarke (1999b).REFERENCESAckerman, L., Kempf, J., and Miki, T. 2003. Wireless Location Privacy: Law and Policy in theU.S., E.U., and Japan. WWW document, http://www.isoc.org/brieﬁngs/015/index.shtml.Ball, M. 2003. Concerning ourselves with privacy. GIS World16(2) (available at http://www.geoplace.com/gw/2003/0302/0302ed.asp).Campbell, D. and Fisher, J. (eds). 1994. Data Transmission and Privacy. Dordrecht: MartinusNijhoff.Clarke, R. 1999a. Introduction to Dataveillance and Information Privacy, and Deﬁnition ofTerms. WWW document, http://www.anu.edu.au/people/Roger.Clarke/DV/intro.html.Clarke, R. 1999b. The Legal Context of Privacy-enhancing and Privacy-sympathetic Techno-logies. WWW document, http://www.anu.edu.au/people/Roger.Clarke/DV/Florham.html.Clarke, R. 2001. The end of privacy: While you were sleeping...surveillance technologiesarrived. AQ: Journal of Contemporary Analysis73: 9–14.Clarke, R. 2002. ENUM. WWW document, http://www.anu.edu.au/people/Roger.Clarke/DV/Enum.html.Curry, D. J. 1992. The New Marketing Research Systems: How to Use Strategic DatabaseInformation for Better Marketing Decisions. New York: John Wiley and Sons.Curry, M. R. 1994. In Plain and Open View: Geographic Information systems and the Problemof Privacy. WWW document, http://www.spatial.maine.edu/tempe/curry.html.Dobson, J. 1998. Is GIS a privacy threat? GIS World 11(7): 34–5.Dobson, J. 2000. What are the ethical limits of GIS? GeoWorld13(5) (available at http://www.geoplace.com/gw/2000/0500/0500g.asp).Equifax National Decision Systems. 1993. InfoMark-GIS: Tomorrow’s Technology for Today’sBusiness Success. Atlanta, GA: Equifax, Inc.Flaherty, D. H. 1994. Privacy Protection in Geographic Information Systems: AlternativeProtection Scenarios. WWW document, http://www.spatial.maine.edu/tempe/ﬂaherty.html.Goss, J. D. 1994. Marketing the new marketing: The strategic discourse of GeodemographicInformation Systems. In J. Pickles (ed.) Ground Truth: the Social Implications ofGeographic Information Systems. New York: Guilford Press: 130–70.Goss, J. 1995. We know who you are and we know where you live: The instrumental ration-ality of Geodemographic Systems. Economic Geography71: 171–98.Handelsmann, A. 2001. Strategies for Complying with Australia’s Privacy Principles. WWWdocument, http://www/gigalaw.com/articles/2001/handelsmann-2001-11-p1.html.Harvey, J. A. and Verska, K. A. 2001. What the European Data Privacy Obligations Mean forU.S. Businesses. WWW document, http://www.gigalaw.com/articles/harvey-2001-02-p1.html.Hull, C. 1994. “Privacy question in phone-book CDs,” The Canberra Times, August 1, p. 13.International Telecommunications Union (ITU). 2001. ENUM. WWW document, http://www.itu.int/osg/spu/enum/index.html.Krause, B. 2001. An Overview of the Canadian Personal Information Protection and Elec-tronic Documents Act. WWW document, http://www.gigalaw.com/articles/2001/krauser2001-02.html.THO_C29  20/03/2007  15:09  Page 538 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGISc, PERSONAL PRIVACY, AND THE LAW539Leipnik, M., Bottelli, J., von Essen, I., Schmidt, A., Anderson, L., and Cooper, T. 2001.Coordinates of a Killer. WWW document, http://www.geoinfosystems.com/1101/101spokane.html.Lowe, S. 1994. “Indecent disclosures,” The Sydney Morning Herald, March 21, p. 47.Orwell, G. [1949] 1990. Nineteen-Eighty-Four. New York: New American Library, Inc.Rowe, H. and McGilligan, R. 2001. Data",
    "chunk_order_index": 341,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7a5963d330655dd8c4bfa2f0e011daeb": {
    "tokens": 1200,
    "content": "1.Coordinates of a Killer. WWW document, http://www.geoinfosystems.com/1101/101spokane.html.Lowe, S. 1994. “Indecent disclosures,” The Sydney Morning Herald, March 21, p. 47.Orwell, G. [1949] 1990. Nineteen-Eighty-Four. New York: New American Library, Inc.Rowe, H. and McGilligan, R. 2001. Data protection: Location technology and data pro-tection. Computer Law and Security Report17: 333–5.Tapper, C. 1989. Computer Law (4th edn). Harlow: Longman.Tobin, R. 2000. Invasion of privacy. New Zealand Law Journal216.Warren, S. and Brandeis, L. 1890. The right to privacy. 4 Harvard Law Review193.Waters, N. 2000. GIS and the bitter fruit: Privacy issues in the Age of the Internet.Geoworld6(5) (available at http://www.geoplace.com/gw/2000/0500/0500edg.asp).Westin, A. F. 1967. Privacy and Freedom. New York: Atheneum.Westin, A. F. 1971. Information Technology in a Democracy. Cambridge, MA: HarvardUniversity Press.Yu, P. 2001. An introduction to the EU Directive on the Protection of Personal Data. WWWdocument, http://www.gigalaw.com/articles/2001/yu-2001-07a-p1.html.THO_C29  20/03/2007  15:09  Page 539 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 30Geographic Information Systems in EducationJoseph J. KerskiAs Geographic Information Systems (GIS) quietly transformed decision making inuniversities, government agencies, industry, and nonproﬁt organizations, demand forGIS education has mushroomed. During the 1970s, GIS education, along with thedevelopment of GIS software, was proceeding at the Computer Graphics Laboratoryat Harvard University in the USA and the Experimental Cartography Unit of theRoyal College of Art in the UK. Advanced students and professors learned how tointegrate traditional theories about spatial information, computational geometry,and computer science into a set of basic concepts useful for the computer processingof spatial information (Coppock and Rhind 1991).From these beginnings, GIS technology developed more rapidly than the corres-ponding educational opportunities. Once GIS became a rewarding commercial venture, software vendors established extensive training programs in their own soft-ware. During these early years, education about GIS was largely synonymous withprofessional development, focusing on those who had already completed their formaluniversity education. People learned about GIS to become more familiar with soft-ware tools so that they could apply GIS methodology on the job. GIS professionaldevelopment mirrored the development of GIS itself, beginning with natural sciencesin the 1970s, expanding to urban planning and business during the 1980s, and bythe 1990s into virtually every major career path.Between 1985 and 1992, the advent of Idrisi, MapInfo, PC Arc/Info and ArcViewdesktop software diffused GIS within organizations. Increased computing capabilitiesand more powerful software attracted additional users. Spatial data sets became moreaccessible and available, beginning with LANDSAT and SPOT satellite imagery, USGSDigital Line Graphs, Digital Elevation Models, commercial satellite imagery, UKOrdnance Survey data, Digital Orthophotoquads, and Census TIGER ﬁles (see Chapter 1 by Cowen in this volume for additional details about present-day spatialdata resources). GIS users ﬁnally had a rich source of data to use as base layers withdata sets they collected themselves.By 1992, a research base for GIS had been established with strong ties to the dis-ciplines of geography, cartography, geodesy, computer science, and remote sensing.THO_C30  19/03/2007  11:25  Page 540 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS IN EDUCATION541With the maturing of Geographic Information Science (GISc) (Goodchild 1992),education became more complex. People were still interested in learning about GIS applications to address real-world societal issues and problems. However, others developed an educational framework to learn about GISc as a discipline. Othersexamined GIS education in the framework of research about GISc. Still others soughtto use GIS as a tool and method in education, to teach geography, environmentalstudies, history, and other disciplines.Today, GIS education is in demand more than ever as spatial tools have becomewidely available as desktop clients and over the web. The integration of GIS, GlobalPositioning Systems (GPS), and remote sensing tools into standard ofﬁce productivitysoftware and in everyday devices such as mobile telephones and in-vehicle naviga-tion systems fuels the demand. This chapter examines the history and spectrum ofGIS education, including the major developments and organizations involved, andopportunities for educating oneself in GIS.GIS in education can be conceptualized",
    "chunk_order_index": 342,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-50a2ffb1f24a35b84a87e337507ede73": {
    "tokens": 1200,
    "content": "than ever as spatial tools have becomewidely available as desktop clients and over the web. The integration of GIS, GlobalPositioning Systems (GPS), and remote sensing tools into standard ofﬁce productivitysoftware and in everyday devices such as mobile telephones and in-vehicle naviga-tion systems fuels the demand. This chapter examines the history and spectrum ofGIS education, including the major developments and organizations involved, andopportunities for educating oneself in GIS.GIS in education can be conceptualized in four distinct ways: (1) professionaldevelopment, (2) research aboutGIS, (3) teaching aboutGIS, and (4) teaching andlearning withGIS. Teaching and learning about GIS (after Sui 1995) takes placeon three well-developed levels involving thousands of people, organizations, andprograms: (1) professional development, or skill-building, (2) research about GIS,and (3) teaching about GIS. The goal of teaching and learning about GIS is to become familiar with the theories concerning GISc and the acquisition of skills tomanage GIS and operate GIS software. Courses emphasize topics such as topology,data structures, database management, map scale and projections, data quality, andgeneralization.By contrast, teaching and learning with GIS is smaller in scope. It focuses not onGIS, but on the disciplines that are home to the issues being addressed, using GISas tools and spatial analysis to understand the Earth. This group of practitionershas a research base and has experienced modest growth since 1990.Fig. 30.1PC monitor in Texas high school showing series of themes for AfricaTHO_C30  19/03/2007  11:25  Page 541 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f542JOSEPH J. KERSKIMuch GIS education occurs outside of educational institutions in government agencies and private GIS software companies. Inside educational institutions, teach-ing about GIS dominates at the university level, where courses in methods and theory of GIS are taught. However, it has made considerable inroads in variousdisciplines across university campuses during the past ten years, and many coursesand programs in both IT and the environmental sciences now incorporate GISc concepts and tools. Teaching with GIS began and still dominates at the primary andsecondary level, where it is used as an instructional method in established subjectcontent areas. Through such initiatives as the National Institute for Technology inLiberal Education, teaching with GIS is expanding at the university level in history,language, business, and even art.GIS vocations continue to expand, including system administrators and managers,application developers, database designers, spatial analysts, and researchers. The typesof jobs a GIS professional may do suggests an equally long list of knowledge areasthat might be addressed in GIS education: general awareness of the technology and applications, systems operation, computer science, management skills, spatialinformation, and geographic science, to name a few. The appropriate combina-tion of these different knowledge areas varies with the professional activity. Forexample, a system operator needs to know much about system operation, but maynot require extensive exposure to management skills.The combinations of skills and knowledge may be best understood by identifyingpedagogic dimensions that need to be considered when planning and implementinga GIS curriculum (Figure 30.2). One dimension contrasts teaching technical skills insystem operation against teaching basic concepts. This is often referred to as training(skills) versus education (skills and concepts). A second dimension contrasts emphasison GIS theory versus an emphasis on the applications of GIS. A third dimension placeseducation about the management of GIS at the opposite pole from education aboutthe use of GIS. While these dimensions overlap, recognition of the fundamental ped-agogic differences between each is useful during course planning.We now turn to the ﬁrst component of teaching about GIS, the one that manypeople associate with GIS education – professional development.As Tools andMethods:ProfessionalDevelopmentAs aResearchTopic:Researchabout GISAs aDiscipline:Teachingabout GISIn OtherDisciplines:Teaching andLearningwith GISWith GISGIS in EducationAbout GISFig. 30.2Dimensions of GIS educationTHO_C30  19/03/2007  11:25  Page 542 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS IN EDUCATION543GIS Education as Professional DevelopmentNeedMost people who want to learn about GIS for professional development reasons havetwo motivations. One is to get a job. Despite the ups and downs of most informa-tion technology (IT), GIS has been expanding at over 15 percent per year since the1980s. Many students believe that having a record of successful completion of oneor more GIS courses will help them obtain their ﬁrst job. Other people seek out GISas a possible new career ﬁeld when their former professions become obsolete.However, a much larger number of people now ﬁnd that they need to learn aboutGIS because the technology is becoming part of their current job. In addition tothose who want to learn about GIS, there are also many who need to learn aboutGIS but do not realize it. Politicians, administrators, and the general public increas-ingly interact with GIS or its products. They need to know what GIS is and howit can be used so that they can make informed decisions about acquiring and",
    "chunk_order_index": 343,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-f73fc2acaec75c09f5b5352288f63078": {
    "tokens": 1200,
    "content": ".However, a much larger number of people now ﬁnd that they need to learn aboutGIS because the technology is becoming part of their current job. In addition tothose who want to learn about GIS, there are also many who need to learn aboutGIS but do not realize it. Politicians, administrators, and the general public increas-ingly interact with GIS or its products. They need to know what GIS is and howit can be used so that they can make informed decisions about acquiring and main-taining it in their organizations. How can education, awareness, and training bedesigned to meet their needs? How can we create a spatially literate society? Sucha society would ultimately provide the base necessary to support the types of researchand teaching that the GISc community advocates.Therefore, in terms of professional development, three groups of people exist whowant or need to study GIS: (1) people who want to be GIS experts; (2) people who want to know about GIS as a supplement to their job duties; and (3) people whoshould know about GIS because they will make decisions about its implementationor because they are using information derived from a GIS.Historical developmentUp through 1990, GIS was not considered as a discipline, but rather as a powerfulnew set of computer tools. The overriding need of those seeking GIS education wasprofessional development. To use GIS on the job they needed some theoretical back-ground, but the bulk of the training required was commands and procedures speciﬁcto a particular type of software.Owing to the complexity of GIS software, most GIS trainers emphasized one type of software and one type of data model because early GIS software tended toemphasize either the vector or raster model. GIS software companies taught muchGIS, and therefore, training tended to develop along software lines, dividing theuser community to this day.Because of the lack of base data, GIS professional development also emphasizedcollecting data. Digitizing tablets and large format scanners were ubiquitous in earlylabs, and many GIS professionals today have grim memories of beginning their careerscrouched over these large pieces of equipment!Professional development training was conducted in hands-on mode in expensivecomputer laboratories. Even graphics monitors such as the Tektronix were speciallybuilt for GIS users and cost thousands of dollars. Consequently, the subject waslargely taught by employees of large government organizations and universities thatcould afford the training facilities. GIS was run on mainframe and minicomputersTHO_C30  19/03/2007  11:25  Page 543 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f544JOSEPH J. KERSKIin raised-ﬂoor, closed-door computer laboratories; the software was difﬁcult to learn,dominated by punch card and command-line input. GIS naturally became the specialtyof just a few staff in each organization.The GIS community quickly realized that personal networking was essential to eachperson’s success as a GIS professional. AutoCarto and GIS/LIS provided annual pro-fessional development opportunities for GIS professionals. These conferences providednetworking through workshops, presentations, and exhibits. Professional societiessuch as AM/FM International (Automated Mapping and Facilities Management)from the utilities industry, later the Geospatial Information Technology Association(GITA), and Urban and Regional Information Systems Association (URISA) fromcity planners interested in GIS began holding their own conferences.Current statusSince 1990, professional development has been characterized by growth, specializa-tion, and increased reliance on web-based tools. Hundreds of consultants workingalone or in large companies provide training for tens of thousands of users annually.No longer conﬁned to a limited number of expensive laboratories, GIS training takesplace in many venues – on laptop computers, mobile hand-held devices in the ﬁeld,and in ﬁeld vehicles. Blurring boundaries between GIS and Remote Sensing andComputer Aided Drafting (CAD) has further widened GIS professional develop-ment. Many trainers focus on speciﬁc GIS applications such as law enforcement orbusiness applications.Online training is commonplace. ESRI’s Virtual Campus now offers over 60 courses and has seen 250,000 users since its launch in the late 1990s. The UNIGISInternational Network is a consortium of more than 20 universities spread across14 countries on four continents, offering graduate degrees and certiﬁcates with over 1,400 students enrolled at any one time. Pennsylvania State University, theUniversity of Redlands, University of Denver, and others offer distance courses anddegrees in GIS.Today’s GIS professional development still tends to divide along a single brandof GIS software. The ﬁeld is dominated by ESRI (ArcGIS and others), Intergraph(GeoMedia), MapInfo, Caliper (Maptitude), and Clark Labs (Idrisi). Accordingly,GIS software companies still provide much of the training. Finally, professional development still emphasizes hands-on acquisition of skills needed to accomplishspeciﬁc tasks using a chosen brand of software.GIS education as professional development is an enormous industry, involvingprivate companies; regional, national, and international conferences; professionalsocieties; government agencies; and nonproﬁt organizations. In a 1990s survey, 49 percent responded that they had received their GIS training on the job, 22 per-cent from a workshop, 19 percent from university courses or their university degree,and 4 percent through a certiﬁcate program (Huxhold 1999). Companies involvedin GIS education range from sole proprietorships to large companies such as ESRIand Intergraph.Despite web-based meetings and training,",
    "chunk_order_index": 344,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-80c91f8eb2ed2c1081d9061d2a1ef106": {
    "tokens": 1200,
    "content": "; government agencies; and nonproﬁt organizations. In a 1990s survey, 49 percent responded that they had received their GIS training on the job, 22 per-cent from a workshop, 19 percent from university courses or their university degree,and 4 percent through a certiﬁcate program (Huxhold 1999). Companies involvedin GIS education range from sole proprietorships to large companies such as ESRIand Intergraph.Despite web-based meetings and training, face-to-face GIS conferences continueto serve as one of the primary means of GIS professional development. GIS is notjust about hardware, software, and methods, it is about people. Human networkingTHO_C30  19/03/2007  11:25  Page 544 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS IN EDUCATION545is the primary reason for the rapid growth of GIS throughout society, made morerapid by the enthusiastic nature of the GIS user community that is eager to shareinformation and expand their ﬁeld.As evidence, the annual ESRI International User Conference has grown in 25 yearsto 13,000 attendees from 150 countries who give over 1,200 papers annually. TheAssociation for Geographic Information’s (AGI’s) conference in the UK, and India’sannual MapIndia event are just a few of the global events that occur each year.GeoPlace, Intergraph, MapInfo, URISA, and GITA’s annual GIS conferences eachattract thousands, and, in addition, most regions and states hold their own GIS con-ferences and workshops. The annual conferences of the Association of AmericanGeographers (AAG), American Planning Association, and others now include signiﬁc-ant GIS strands. Theme-based GIS conferences such as in health and national securityare increasing.ContentIn 1993, the US Department of Labor added “GIS Specialist” to its Dictionary of Occupational Titles (Huxhold 1999). Its skill sets form the basis of much GISprofessional development: (1) information technology, including database design,data management, user interface design, requirements deﬁnition, graphics, and imageprocessing; (2) geography and cartography; (3) GIS technology; (4) other skills, includ-ing coordinate geometry, topology, and presentation and training skills.In all areas of education a debate exists about how much theory should be taughtversus skills. For GIS professionals, while the emphasis is on skills, theory pro-vides context. For example, changing map projections in GIS menus does not makesense unless the operator understands why map projections are necessary and theirinherent advantages and disadvantages. When spatial data are in digital form, thepotential for misuse increases with the numbers of users and applications. Becauseof the power of the computer to manipulate, combine, and derive data, users canperform these even if the combinations and derivations make no sense, and hence,theory is included in education.International GIS educationAs most of the development of GIS began in North America and the UK, GIS education diffused to the world using the model developed by these countries. Asfree trade agreements mature in the Americas and in Europe, professionals in allﬁelds begin to cross national borders. As a result, people are asking how we canensure that GIS professionals are sufﬁciently qualiﬁed for international work, andhow qualiﬁcations are recognized internationally.Regional diversity in GIS education is suggested with some countries placing GIS within the “cadastral” sphere and others placing it more in the “geographic”context. Disciplinary differences are often reﬂected in the choice of data model. Forexample, GIS specialists working with transportation systems require topologic-ally structured data models while ground water specialists will more likely dependupon raster models. Clearly, each GIS professional must determine his or her owneducational needs given this diversity. This has led some professional organizationsTHO_C30  19/03/2007  11:25  Page 545 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f546JOSEPH J. KERSKIto campaign for a professional development framework that indicates what a GISprofessional should know. Once formalized, individuals can use the framework toorganize their own educational requirements. GIS certiﬁcation is one attempt tomeet this need.CertiﬁcationOver the past decade, the GIS community has been asking itself whether it shouldestablish a professional certiﬁcation in the ﬁeld. Many argued that because GIS represented a specialized body of knowledge, had a mission, had formal organiza-tions, required specialized training, and had its own culture, it qualiﬁed as a pro-fession (Huxhold 1999) as identiﬁed by Pugh (1989) and Obermeyer (1993). Increasedrecognition, salary, and knowledge are cited as beneﬁts to certiﬁcation. Efforts byURISA, AGI, the International Standards Organization, University Consortium of Geographic Information Science (UCGIS), ASPRS, and others culminated in theestablishment of a certiﬁcation process. The nonproﬁt GIS Certiﬁcation Institute(www.gisci.org) operates the program; 2003 saw the ﬁrst graduates",
    "chunk_order_index": 345,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a226a592c8fa7140c36bcd838fe4ff48": {
    "tokens": 1200,
    "content": "and Obermeyer (1993). Increasedrecognition, salary, and knowledge are cited as beneﬁts to certiﬁcation. Efforts byURISA, AGI, the International Standards Organization, University Consortium of Geographic Information Science (UCGIS), ASPRS, and others culminated in theestablishment of a certiﬁcation process. The nonproﬁt GIS Certiﬁcation Institute(www.gisci.org) operates the program; 2003 saw the ﬁrst graduates of the programand the North Carolina Information Coordinating Council became the ﬁrst stateto endorse GISCI’s certiﬁcation program in December 2004.GIS Education as Research about GIScResearch about GISc provides guidance to professional development and becomesthe theoretical basis for GISc. Because this provides the content of what GISc is,re-search about GISc therefore dictates what GIS is taught, and what GIS is learned.Research about GISc represents the breadth of GIS – software, teaching, learning,tools, and methods. There is a difference between how GIS is used for research andhow it is used in research. In some cases, GIS itself is the focus of research, and inothers, GIS is a tool and way of thinking that assists research in other domains.Research in teaching and learning about GIS forms an important part of the agendaof the investigators, many of whom have cognitive science backgrounds.In 1988, the National Science Foundation in the USA established the NationalCenter for Geographic Information and Analysis (NCGIA) at the University ofCalifornia-Santa Barbara, State University of New York at Buffalo, and Universityof Maine. Through the mid 1990s, NCGIA researchers coordinated much of theinitial research in GISc.The UCGIS was launched in 1995 to serve as an effective, uniﬁed voice for theGISc research community, to foster multi-disciplinary research and education, andto promote the informed use of GISc for the beneﬁt of society.Some of the rapidly expanding GISc research focuses on the analysis, design, visual-ization, and generation of various forms of maps, and how people think about theirgeographic surroundings. Software developers use the research generated by these scientists to make GIS more powerful and easier to use. The education priorities ofthese researchers include emerging technologies for delivering GIS education, includingdistance education, supporting infrastructure to ensure that education happens, accessTHO_C30  19/03/2007  11:25  Page 546 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS IN EDUCATION547and equity (Pisapia 1994), alternative designs for curriculum content and evaluation,professional education, learning with GIS, certiﬁcation, and accreditation.Beginning in 2000, the NCGIA, Association of American Geographers (AAG),Association of Geographic Information Laboratories in Europe (AGILE), and UCGIShave organized a biennial conference entitled, simply, “GIScience.” The GIScience2000, 2002, 2004, and 2006 conferences became a key means of the education ofthe GISc research community.GIS Education as Teaching about GIScBy the mid 1980s, it was clear that there was a growing scarcity of people educatedin this rapidly spreading technology. Only one textbook in the ﬁeld existed, thatof Burrough (1986). This led to the initiation of a US National Science Foundationfunded curriculum development project that culminated in the development of theNCGIA Core Curriculum in GIS. The project was founded on the premise thatgrowth of GIS education opportunities could be encouraged by the preparation anddistribution of materials designed to help university instructors develop introductorycourses. The Core Curriculum project sought to bring together and formalize a wide-ranging set of topics, and included volumes focused on introductory, technical, andapplication issues in GIS. By 1995, over 1,300 copies of the 1,000-page curriculumhad been distributed to faculty and practitioners in over 70 countries (Kemp 1998).The NCGIA Core Curriculum in GISbecame the recognized guideline that educatorsshould use in teaching about GISc and for several years, it was really the only com-prehensive curriculum in the ﬁeld.Curriculum development is a difﬁcult, labor-intensive process, particularly so ina new, complex ﬁeld such as GISc. Jenkins (2000) describes curriculum developmentas “an interaction between aims and objectives, methods of assessment, teachingmethods and content.” Educationalists often insist that curriculum development mustbe driven by a set of objectives – “what one expects students to know or do as aresult of a particular course.” Nevertheless, other efforts made to determine generic,“core,” or “model” GIS curricula began. The Royal Institution of Chartered Sur-veyors (RICS) in the UK funded a workshop that produced a remarkably similarsyllabus for the teaching of GIS. The Canadian geomatics industry survey was oneof many conducted to determine the basic skill set for geomatics practitioners. Theﬁrst extensive study to determine the necessary components for an internationalEuropean postgraduate GIS course was conducted by the Technical University ofVienna in 1993. Intensive formal courses were organized by international agenciessuch as the United Nations Institute for Training and Research, by national trainingagencies such as FORMEZ in Italy and by universities such as the Technical Universityin Vienna (Kemp 1995).Teaching about GISc is almost exclusively the domain of higher education. Thosewho teach about GISc in educational institutions face difﬁculties that some in indus",
    "chunk_order_index": 346,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-112a785dc5833c859934fd79cbfa4e9f": {
    "tokens": 1200,
    "content": "European postgraduate GIS course was conducted by the Technical University ofVienna in 1993. Intensive formal courses were organized by international agenciessuch as the United Nations Institute for Training and Research, by national trainingagencies such as FORMEZ in Italy and by universities such as the Technical Universityin Vienna (Kemp 1995).Teaching about GISc is almost exclusively the domain of higher education. Thosewho teach about GISc in educational institutions face difﬁculties that some in indus-try and government do not experience. GIS involves a great investment of time foruniversity faculty, as they not only have to teach the concepts and skills, but alsomust prepare and test lessons, download and format spatial data, and a myriad ofother technical and pedagogical tasks. This conﬁnes it to small numbers of faculty.THO_C30  19/03/2007  11:25  Page 547 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f548JOSEPH J. KERSKIFurthermore, as GIS education becomes more popular, diffuse, and directed at anincreasing diversity of audiences, there is less cohesiveness and agreement on whatneeds to be taught and when.Despite these challenges, GIS education has become well established in geographydepartments and/or programs in nearly every university and community college inNorth America, Australia, and Europe, is expanding in other departments on thesecontinents and added to universities in Asia, South America, and Africa. In someuniversities, GIS is introduced in a geography fundamentals course, where studentsare exposed to a range of geographic techniques. In most universities, GIS is taughtas a skills course, in a manner similar to the way statistics or computer sciences aretaught to non-majors. Some graduate programs in GIS focus on learning how toapply the software and completing a detailed project, whereas others concentrateon theory.A three-volume reference book on GIS Principles and Applications was publishedin 1991 (Maguire, Goodchild, and Rhind 1991) and widely used. Today, with atleast 60 major GIS textbooks now in existence, GIS is starting to be considered afoundation subject across a broad range of disciplines. Indeed, there is more evid-ence that spatial literacy and geographic problem solving are core educational needsthroughout society, as documented in the report on GIS across the curriculum published in 2006 (NRC 2006).What should GIS courses teach?Any education program must begin with a clear recognition of the audience it isintended to reach and their needs. While learning about the technology drives manyto learn GIS, all GIS educators must impress upon their students important basicprinciples that transcend the technology. First, because they are making maps, GISspecialists need to know some principles of cartography – map projections, scale,and symbology. Producing a choropleth map has become simple, but when is aquantile classiﬁcation preferable over a Jenks natural breaks classiﬁcation?Second, GIS specialists should learn something about geography, the science ofspace and place on the Earth’s surface. Geographers describe the changing patternsof places in words, maps, and images, explain how these patterns come to be, andunravel their meaning. GIS is powerful because it depends upon and emphasizesthe very principles geographers have been studying for centuries.Third, geographers have long been developing sophisticated quantitative tech-niques for analyzing how location affects components of the human and physicalenvironment. Since spatial analysis predated GIS, the GIS specialist needs to under-stand these techniques so they can think “outside the box” when grappling withcomplex problems. Geographically referenced data is unique because of spatial auto-correlation that recognizes that places close together are more similar than placesfar apart. Many traditional statistical techniques that assume independence betweenobservations or samples are invalid when used on geographic data. This problemhas led statisticians to develop a wide range of spatial statistical techniques, whichrequire knowledge of the underlying theory before they can be properly interpretedfor other people’s use (see Chapter 22 by Jacquez in this volume for examples ofspatial statistical techniques that can be implemented inside GIS).THO_C30  19/03/2007  11:25  Page 548 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS IN EDUCATION549A GIS curriculum should include spatial information concepts, skills, and represent-ation, determining and representing location, modeling reality, data sources, develop-ment and applications of GIS, and needs analysis. It should emphasize database issues,spatial data, spatial analysis, systems design, organizational implementation, projectmanagement, and GIS in society. GIS curricula should include a practical project ofthe student’s own choosing.GIS education reinforces skills such as information retrieval, independent work,working comfortably with a computer, organizing team projects, working with professionals in the ﬁeld, solving problems, managing a project, educating others,speaking and writing, using graphics, and, perhaps most important of all, being crit-ical of and knowing the limitations of information, particularly on a computer.We do not yet know with complete certainty what core skills and knowledge are needed by those who use GIS. Furthermore, the approach changes dependingon the discipline. One needs to",
    "chunk_order_index": 347,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-308249844cc36eb53bd51fb31397b063": {
    "tokens": 1200,
    "content": "information retrieval, independent work,working comfortably with a computer, organizing team projects, working with professionals in the ﬁeld, solving problems, managing a project, educating others,speaking and writing, using graphics, and, perhaps most important of all, being crit-ical of and knowing the limitations of information, particularly on a computer.We do not yet know with complete certainty what core skills and knowledge are needed by those who use GIS. Furthermore, the approach changes dependingon the discipline. One needs to consider the spatial concepts relevant within thoseother disciplines and how they are implemented, modeled, and used there. The UCGIShas adopted this view in developing the model curricula in Geographic InformationScience and Technology (GIS&T). The current draft emphasizes curricular pathsthat incorporate a number of common features but lead to signiﬁcantly differentoutcomes for the undergraduate. The goal is curricula that will result in more highlyand relevantly educated graduates, greater consistency in GIS&T degree-grantingprograms, and increased communication across academic disciplines with an interestin GIS&T (UCGIS Model Curriculum Task Force 2003).GIS Education as Teaching with GISWhy teach with GIS?The goal in teaching withGIS is to use GIS to help students understand a prob-lem or issue in geography, chemistry, biology, environmental science, mathematics,business, history, and other disciplines (Barstow 1994, Fazio and Keranen 1995,McGarigle 1997). Factors encouraging the use of GIS in education include the educational standards movement, pedagogy, workforce development (Braus 1999),and holding public education ﬁscally accountable.Educational systems in many countries have been moving toward educational content standards and national curricula, specifying what students should know andbe able to do at certain benchmark educational levels. For example, the UK’s NationalCurriculum, and the USA’s national content standards in geography (GeographyEducation Standards Project 1994), social studies (National Task Force for SocialStudies Standards 1994), science (NRC 1996), and technology (International Societyfor Technology in Education 2000) state that students must use real-world toolsin the same “hands-on” manner as a scientist would to solve real-world problems.Because GIS was created as a problem-solving tool, it ﬁnds a natural home in thecurriculum.Furthermore, educators have progressed toward a model of “inquiry-based” instruc-tion that emphasizes hands-on, research-based learning experience. Inquiry drawsupon learning theory known as constructivism, which holds that rather than beingTHO_C30  19/03/2007  11:25  Page 549 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f550JOSEPH J. KERSKItransferred from teacher to student, knowledge is constructed by the learner basedon his or her own experiences and making connections (Driver, Asoko, Leach,Mortimer, and Scott 1994). The USA’s national geography standards state that “thepower of a GIS is that it allows us to ask questions of data” (Geography EducationStandards Project 1994, p. 256). Students using this inquiry approach form researchquestions, develop a methodology, gather, and analyze data, and draw conclusions.The use of GIS in education is increasingly viewed as active learning that engagesstudents in critical thinking skills. Students are attracted to the visual learning that GIS offers. Its interdisciplinary character is appealing: Many argue that inter-disciplinary education, rather than teaching each subject in isolation, may be a moreeffective means to help students solve problems (Jacobs 1989). Some educators feelthat implementing GIS into the curriculum may encourage students to examine datafrom a variety of viewpoints (Furner and Ramirez 1999, Sarnoff 2000). GIS allows“authentic assessment,” in which instructors evaluate student performance basedon assessing student portfolios or projects, rather than examinations.Educators worldwide bemoan the fact that young people feel disengaged fromlocal and national decision-making. Some view GIS as helping students to engage incommunity-based issues such as the siting of landﬁlls, urban sprawl, water quality,crime, energy, and transportation, and thus to achieve excellence in citizenship education (Kerski 2004).Rather than using GIS to add more information to a project, educators advocatethat it can help students to use information more effectively to arrive at a decisionby using generative, rather than inert knowledge (Dede 1995). GIS is used to makedecisions given incomplete information, inconsistent objectives, and uncertain con-sequences, reﬂecting the world outside of the classroom. Sustainable lessons thatcan be easily used, modiﬁed, and transferred are those most in demand.Concurrent with these developments in pedagogy has been a renewed emphasis onpreparing students to become productive members of the workforce. The US LaborSecretary’s Commission on Achieving Necessary Skills (SCANS) stated that the mosteffective way to teach skills is in the context of an established subject (US Depart-ment of Labor 1991). SCANS competencies include identifying and using resources,working with others, and understanding complex interrelationships (Hill 1995a, b).These activities mirror the types of tasks that students engage in when they useGIS, termed “authentic practice.” School-to-career and workforce development grantsare more commonplace and likely to include GIS in the “tool belt” that educatorsbelieve students should have by the time they graduate. Information literacy, com-puter literacy, and",
    "chunk_order_index": 348,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-cde108e99c8d0f4b8be970e6a8e872b8": {
    "tokens": 1200,
    "content": "ment of Labor 1991). SCANS competencies include identifying and using resources,working with others, and understanding complex interrelationships (Hill 1995a, b).These activities mirror the types of tasks that students engage in when they useGIS, termed “authentic practice.” School-to-career and workforce development grantsare more commonplace and likely to include GIS in the “tool belt” that educatorsbelieve students should have by the time they graduate. Information literacy, com-puter literacy, and the ability to integrate information from different sources areincreasingly considered important to teach. GIS is one of the few tools to fully takeadvantage of the full power of the computer.Challenges in teaching with GISThe trouble with education...is that the best teaching methods are in fact the mostdifﬁcult. (Piaget 1929)Challenges in teaching with GIS have slowed its implementation in the primary,secondary, and university curricula. Challenges lie more with the structure of THO_C30  19/03/2007  11:25  Page 550 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS IN EDUCATION551educational systems themselves than on software and hardware. Indeed, with theprice of a school site license of ArcView GIS for one year at only US$75 on a CDdistributed with the Mapping Our World book (Malone, Palmer, and Voigt 2002),cost is the least of the concerns. Technology is a “process; a systematic blend ofpeople, materials, methods, and machines” (Ely, Foley, Freeman, and Scheel 1992).In addition, GIS is by deﬁnition a system – it is both a technology and a set ofmethods. Integrating GIS into classroom practice is a complex process. Guided inquiryentails changes in the social organization and management of the classroom (Powell1999) and involves unpredictable results and student-directed learning that manyeducators are not equipped to deal with (Audet and Paris 1997). The lack of train-ing at the preservice stage slows implementation, because most instructors learnabout GIS at the inservice stage – when they are already on the job (Boehm, Brierley,and Sharma 1994, Bednarz and Audet 1999).A survey of 1,520 secondary school teachers who own GIS software in the USA showed that student projects were community-based, ﬁeldwork-based, inter-disciplinary, and open-ended, involving ill-structured problems with real-world data(Kerski 2003). However, it also revealed that the challenges facing educators includethe lack of training, lack of time in the curriculum, limited access to the computerlab,lack of software for Macintosh computers, inadequate understanding aboutspatial concepts, and the curricular “ﬁt” of GIS. This study and others (Alibrandi2003, Baker and Case 2003) made it clear that geotechnologies in education mustbe used within the context of reform for long-term impact (Means 1994).Although educational content standards point to the use of tools such as GIS, mostassessment instruments emphasize memorizing facts. Using GIS goes beyond facts,focusing on understanding spatial patterns, linkages, and trends, and if students arenot scoring higher on standardized tests because of GIS, its use will be restricted(Kerski 2003).A lack of research on the effectiveness of geotechnologies identiﬁed in a 1967study persists, slowing advancements in teaching with GIS: “the research-orientedgeographer and educator have paid scant attention to assessing the effectiveness of one tool over another” (Gross 1967). The organizers of the ﬁrst conference oneducational GIS asked “What is the learning that GIS allows that other ways donot?” (Salinger 1994). Administrators and educators want to see evidence of thebeneﬁts of GIS to student learning before they will invest time and effort necessaryto implement it (Downs 1994).Status of teaching with GIS in the curriculumDespite these challenges, teaching with GIS continues to expand, especially at theprimary and secondary level (Figure 30.3). More science teachers in the USA use GISthan geography teachers, reﬂecting the relative importance of science in the educa-tional curriculum (Kerski 2003); the situation is exactly the opposite in the UK andNew Zealand. Using Binko’s (1989) four stages of learning – awareness, understand-ing, guided practice, and implementation – GIS is barely in the awareness phase formost teachers. In a diffusion of innovation model (Rogers 1995), GIS is primarilyused by the “early adopters.” The publication of the ﬁrst two textbooks containingcurriculum (Malone, Palmer, and Voigt 2002, 2003) hastened curricular adoption.THO_C30  19/03/2007  11:25  Page 551 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f552JOSEPH J. KERSKIToday, two different philosophies of software use dominate. The ﬁrst is to use exist-ing off-the-shelf GIS software. Proponents of this method believe that students receivethe most educational and career beneﬁts",
    "chunk_order_index": 349,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d6106356dae1d6647dcd84cb9b4dc132": {
    "tokens": 1200,
    "content": "11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f552JOSEPH J. KERSKIToday, two different philosophies of software use dominate. The ﬁrst is to use exist-ing off-the-shelf GIS software. Proponents of this method believe that students receivethe most educational and career beneﬁts by using the same tools as those used in theworkplace. The second group believes that using software created for educational useprovides students the beneﬁts of spatial thinking without the technological demandsand complexity that accompanies industry-grade GIS software. Examples includeDigital Worlds from Canterbury Christ Church University College in England,MyWorld from Northwestern University, and GEODESY (Radke 1999).Organizations promoting GIS in education are grant-funded organizations, private companies, individuals, professional societies, universities, and governmentagencies. Active grant-funded organizations include the Center for Image Processingin Education, the Technological Education Research Center (TERC), the Univer-sity Corporation for Atmospheric Science (UCAR), the Digital Library for EarthSystems Education (DLESE), the Global Learning and Observations to Beneﬁt the Environment (GLOBE) project, the Missouri Botanical Garden, Kansas GIS(www.kangis.org), and the Upper Midwest Aerospace Consortium. Professional societies such as the AGI and Royal Geographical Society in the UK and GITA inthe USA include outreach staffs who conduct training and loan GPS equipment toschools. ESRI and Intergraph have staffed education teams since the 1990s. Univer-sity researchers and government organizations such as the Ordnance Survey in theUK and USGS in the USA are also active in promoting GIS with grant funding,training, curriculum development, and technical support. Individuals and privatecompanies such as GISetc. concentrate on providing GIS training for educators.Informal education – a term for that which occurs outside walls of formal educa-tional institutions – is increasingly important as evidenced by ESRI’s support ofgeotechnologies for the estimated 400,000 National 4-H groups across the USA.These organizations view the advancement of GIS in education as critical for creating the spatially literate populace needed to solve critical twenty-ﬁrst-centuryFig. 30.3Student displaying the results of his GIS analysis in 3DTHO_C30  19/03/2007  11:25  Page 552 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS IN EDUCATION553problems. The approach of all of these organizations is not “How can we get GISinto the curriculum?” but “How can GIS help meet curricular goals?”The effect of teaching with GIS on educationGIS alters communication patterns and traditional roles of students and teachers,with a greater time spent on small group instruction, coaching, working more closely with weaker students, cooperation, peer-to-peer mentoring, student-to-teachermentoring, and authentic assessment based on products and progress (Robison 1996,Walker, Casper, Hissong, and Rieben 2000). There is a shift from covering materialto sampling material, and from unilaterally declaring what is worth knowing todiscovering what is important. There is value in requiring students to “dig out”information rather than handing it to them. It is one of the few tools to take advant-age of computer, relational, and content skills.Students are becoming more adept at GIS software, but not necessarily at ask-ing inquiry-based geographic questions. The teacher’s role is therefore critical tolearning with GIS. Teachers are more likely to adopt GIS if they have previous com-puter experience, a problem-solving approach, a geographic perspective, a positiveattitude towards work change, and active networking and communication skills(Kerski 2003). Instructors need lessons and guidelines, but software proﬁciency isonly a means to the end goal of teaching how to think geographically, scientiﬁcally,and environmentally. GIS is an enabling technology.CONCLUSIONSThe demand for GIS education continues to grow. The expansion of GIS technologyand applications into many different career paths ensures a continuous supply ofnew workers in the ﬁeld and sustained demand for professional development. They need general training and support followed by specialized training in theirown application area. These are people who use or would like to use GIS on thejob, and seek additional training in the ﬁeld to become more proﬁcient at GIS tools and methods. New versions of the software and new ways to use the tech-nology means that existing users also require ongoing professional development.Educators are increasingly using GIS for teaching and learning, opening up newdemand for professional development for these educators to learn how to teachwith GIS.The diversity of the ﬁeld of GISc is reﬂected in the diversity of its educationalapplications and issues. GISc is a growing enterprise and the need for educated prac-titioners will continue to drive the development of new education opportunities worldwide.ACKNOWLEDGEMENTSComments from Dr Karen Kemp were used to improve the initial draft of this chapter.THO_C30  19/03/2007  11:25  Page 553 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are",
    "chunk_order_index": 350,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-cfc0b2568fc1b6b5cdb8c5fc30afcfd4": {
    "tokens": 1200,
    "content": "Dr Karen Kemp were used to improve the initial draft of this chapter.THO_C30  19/03/2007  11:25  Page 553 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f554JOSEPH J. KERSKIREFERENCESAlibrandi, M. 2003. GIS in the Classroom: Using Geographic Information Systems in SocialStudies and Environmental Science.Portsmouth, NH: Heinemann.Audet, R. H. and Paris, J. 1997. GIS implementation model for schools: Assessing the critical concerns. Journal of Geography96: 293–300.Baker, T. and Case, S. 2003. The effects of GIS on students’ attitudes, self-efﬁcacy, and achieve-ment in middle school science classrooms. Journal of Geography102: 243–54.Barstow, D. 1994. An introduction to GIS in education. In Proceedings of the First NationalConference on the Educational Applications of Geographic Information Systems (EdGIS),Washington, DC, Cambridge, MA, TERC, pp. 14–9.Bednarz, S. W. and Audet, R. H. 1999. The status of GIS technology in teacher preparationprograms. Journal of Geography98: 60–7.Binko, J. B. 1989. Spreading the Word.Washington, DC, National Geographic Society.Boehm, R. G., Brierley, J., and Sharma, M. 1994. The Bete Noire of geographic education:Teacher training programs. In R. S. Bednarz and J. F. Petersen (eds) A Decade of Reformin Geographic Education: Inventory and Prospect.Indiana, PA: National Council forGeographic Education: 89–98.Braus, P. 1999. ABCs of GIS: Education Professionals are Discovering that GIS SoftwareProvides a Powerful Classroom Resource. WWW document, http://directionsmag.com/features.asp?FeatureID=6.Burrough, P. A. 1986. Principles of Geographical Information Systems for Land ResourcesAssessment. Oxford, Oxford University Press.Coppock, J. T. and Rhind, D. W. 1991. The history of GIS. In D. J. Maguire, M. F. Goodchild,and D. W. Rhind (eds) Geographical Information Systems: Principles and Applications.Harlow: Longman, pp. 21–43.Dede, C. 1995. The evolution of constructivist learning environments: Immersion in distributed,virtual worlds. Educational Technology35(5): 46–52.Downs, R. M. 1994. The need for research in geography education: It would be nice tohave some data. Journal of Geography93: 57–60.Driver, R., Asoko, H., Leach, J., Mortimer, E., and Scott, P. 1994. Constructing scientiﬁcknowledge in the classroom. Educational Researcher23: 5–12.Ely, D. P., Foley, A., Freeman, W., and Scheel, N. 1992. Trends in educational technology1991. In D. P. Ely (ed.) Educational Media and Technology Yearbook 1992.Englewood,CO: Libraries Unlimited: 1–29.Fazio, R. P. and Keranen, K. 1995. Mapping a course with GIS. Science Teacher62: 16–9.Furner, J. M. and Ramirez, M. 1999. Making connections: Using GIS to integrate mathem-atics and science. TechTrends43: 34–9.Geography Education Standards Project. 1994. Geography for Life: National GeographyStandards.Washington, DC: National Geographic Society.Goodchild, M. F. 1992. Geographic information science. International Journal of Geo-graphical Information Systems6: 31–46.Gross, H. H. 1967. Research Needs in Geographic Education.Normal, IL: National Councilfor Geographic Education.Hill, A. D. 1995a. Geography standards, instruction, and competencies for the new worldof work. Geographical Education8: 47–9.Hill, A. D. 1995b. Projections and perceptions. Editorial comments: Learning for the newworld of work through geographic inquiry. Geographical Bulletin37: 65–7.Huxhold, W. E. 1999. Certifying GIS Professionals. WWW document, http://www.urisa.org/GIS_CERT_PRES/sld001.htm.THO_C30  19/03/2007  11:25  Page 554 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS IN EDUCATION555International Society for Technology in Education. 2000. National Education TechnologyStandards for Students: Connecting Curriculum and Technology. Eugene, OR: InternationalSociety for Technology in Education.Jacobs, H. 1989. Interdisciplinary Curriculum: Design and Implementation.Alexandria, VA:Association for Supervision and Curriculum Development.Jenkins, A.",
    "chunk_order_index": 351,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7362e902fab7a440f8ac19e095f77fe9": {
    "tokens": 1200,
    "content": "-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGIS IN EDUCATION555International Society for Technology in Education. 2000. National Education TechnologyStandards for Students: Connecting Curriculum and Technology. Eugene, OR: InternationalSociety for Technology in Education.Jacobs, H. 1989. Interdisciplinary Curriculum: Design and Implementation.Alexandria, VA:Association for Supervision and Curriculum Development.Jenkins, A. 2000. The relationship between teaching and research: Where does geographystand and deliver? Journal of Geography in Higher Education24: 325–51.Kemp, K. K. 1995. Teaching and Learning about GIS. WWW document, http://www.ptr.poli.usp.br/labgeo/congressos/simp3.html.Kemp, K. K. 1998. The NCGIA core curricula in GIS and remote sensing. Transactions inGIS2: 181–90.Kerski, J. J. 2003. The implementation and effectiveness of geographic information systemtechnology and methods in secondary education. Journal of Geography102: 128–37.Kerski, J. J. 2004. GIS for citizenship education. In A. Kent and A. Powell (eds) Geographyand Citizenship Education: Research Perspectives.London: University of London Instituteof Education (Papers from the IGUCGE London Symposium in April 2003).Maguire, D. J., Goodchild, M. F., and Rhind, D. W. (eds) 1991. Geographical InformationSystems: Principles and Applications.Harlow: Longman.Malone, L., Palmer, A. M., and Voigt, C. L. 2002. Mapping Our World: GIS Lessons forEducators. Redlands, CA: ESRI Press.Malone, L., Palmer, A. M., and Voigt, C. L. 2003. Community Geography: GIS in Action.Redlands, CA: ESRI Press.McGarigle, B. 1997. High school students win national awards with GIS. GovernmentTechnology9: 1.Means, B. 1994. Technology and Education Reform: The Reality behind the Promise. SanFrancisco, CA: Jossey-Bass.NRC. 1996. National Science Education Standards. Washington, DC: National AcademyPress.NRC. 2006. Learning to Think Spatially: GIS as a Support System in the K-12 Curriculum.Washington, DC: National Academy Press.National Task Force for Social Studies Standards. 1994. Expectations of Excellence: CurriculumStandards for Social Studies. Washington, DC: National Council for the Social Studies.Obermeyer, N. J. 1993. Certifying GIS professionals: Challenges and priorities. URISA Journal5: 67–75.Piaget, J. 1929. The Child’s Conception of the World. London: Routledge.Pisapia, J. 1994. Technology: The Equity Issue. Richmond, VA: Metropolitan EducationalResearch Consortium Research Brief No. 14.Powell, J. C. 1999. The Relationship between Teachers’ Beliefs and the Use of Reform-oriented Science Curriculum Materials. Unpublished PhD Dissertation, University ofColorado, Boulder.Pugh, D. L. 1989. Professionals in public administration. Public Administration Review49:1–8.Radke, S. L. 1996. GEODESY: An Educational Series for Youth. WWW document, http://gis.esri.com/library/userconf/proc96/TO350/PAP316/P316.HTM.Robison, L. 1996. Plotting an island’s future. Geo Info Systems6: 22–7.Rogers, E. M. 1995. The Diffusion of Innovations(4th edn). New York: Free Press.Salinger, G. L. 1994. Remarks at the First National Conference on the Educational Applicationsof Geographic Information Systems. In D. Barstow, M. D. Gerrard, P. M. Kapisovsky, R. F. Tinker, and V. Wojtkiewicz (eds) First National Conference on the EducationalApplications of Geographic Information Systems (EdGIS) Conference Report.Cambridge,MA: TERC Communications: 123.THO_C30  19/03/2007  11:25  Page 555 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f556JOSEPH J. KERSKISarnoff, H. 2000. Census 1790: A GIS Project. WWW document, http:// www.cssjournal.com/sarnoff.html.Sui, D. Z. 1995. A pedagogic framework to link GIS to the intellectual core of geography.Journal of Geography94: 578–91.UCGIS Model Curriculum Task Force. 2003. Straw Report: Model Curricula Draft. WWWdocument, http:/www.ucgis.org/priorities/education/strawmanreport.htm.US Department of Labor. 1991. Secretary’s Commission on Achieving Necessary Skills (SCANS),Blueprint for Action: Building Community Coalitions.Washington, DC: Government PrintingOfﬁce.Walker, M., Casper, J., Hissong, F., and Rieben, E. 2000. GIS: A new way to see. Scienceand Children37: 33–40.T",
    "chunk_order_index": 352,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0efbefa42156e4454161d4968e38573d": {
    "tokens": 1200,
    "content": ", http:/www.ucgis.org/priorities/education/strawmanreport.htm.US Department of Labor. 1991. Secretary’s Commission on Achieving Necessary Skills (SCANS),Blueprint for Action: Building Community Coalitions.Washington, DC: Government PrintingOfﬁce.Walker, M., Casper, J., Hissong, F., and Rieben, E. 2000. GIS: A new way to see. Scienceand Children37: 33–40.THO_C30  19/03/2007  11:25  Page 556 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fPart VIIFuture Trends and ChallengesThe ﬁnal four chapters take the book full circle in that they examine future trendsand challenges. The ﬁrst chapter in this group, Chapter 31 by Christopher B. Jones and Ross S. Purves, examines the role of the World Wide Web in movingGeographic Information Systems (GIS) out from their organization- and project-based roles to meet people’s personal needs for geographic information. The variouselements of web-based GIS are discussed, with special emphasis on the opportunitiesthey provide for querying and visualizing geographic information, the provision ofmaps and geographic data, and the role of the Web as networked infrastructurefor GIS. This discussion is followed by a review of web-GIS technology, the roleof open standards for GI Services, and some examples of the functionality of speciﬁcweb-GIS. The chapter concludes by considering some of the ways in which the Webitself is being extended to become geographically intelligent when searching the content of the Web itself.The second chapter in Part VII, Chapter 32 by Allan J. Brimicombe examinesthe emergence of location-based services (LBS) as an important new application ofGIS. This chapter explores some of the data implications of LBS, how LBS users arepositioned so that the system knows where they are, and how queries are handled.The chapter concludes by reviewing some applications of LBS and some predictionsas to what the future might hold for these types of services.In the third chapter in this ﬁnal set (Chapter 33), Michael F. Goodchild seeks toidentify the challenges and issues that are likely to guide Geographic InformationScience (GISc) research for the next decade or more. This chapter starts out by review-ing the research agendas published by various groups of scholars over a span ofnearly 25 years and moves from these initiatives to discussions of the need to improveour understanding of the nature of the geographic world and the broader themeswithin science and the extent to which they might serve as the basic research chal-lenges for GISc. Goodchild concludes this chapter with a discussion of the DigitalEarth concept and why this might serve as a grand challenge – a theme that is capable of directing research to a common, distant, but imaginable end – in theforeseeable future.THO_C31  19/03/2007  11:24  Page 557 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f558FUTURE TRENDS AND CHALLENGESChapter 34 is the last chapter in this group and in the book, and in it AndreasReuter and Alexander Zipf examine the developments that are likely to occur in thenext 10 to 15 years along three dimensions: concepts and methods, applications,and platforms. Reuter and Zipf assume that the push towards integration will continue and that GIS will be instrumental in integrating data and services fromheterogeneous sources into a uniform architecture, using new concepts and methods,delivering these services via the Grid, and thereby promoting and facilitating a wholerange of new applications. Such a future points to the need for continued growthand innovation in GISc in the years ahead.THO_C31  19/03/2007  11:24  Page 558 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 31Web-based Geographic Information SystemsChristopher B. Jones and Ross S. PurvesThe World Wide Web has brought about major changes in the way GeographicInformation Systems (GIS) are used and in the way in which they are implemented.GIS were dominated until the early 2000s by the creation of software technologyand geographic data resources dedicated to the needs of professional users of geo-information. The typical GIS has been an isolated collection of technology and data,purchased for and installed within the conﬁnes of an individual organization. TheInternet and the World Wide Web were rapidly recognized to have the potential totransform this closed world view of GIS by, for example, “dramatically increasingthe applications of GIS...through integration of mapping, GIS and non-spatialinformation technologies...to create new forms of representation and new waysto address problems important to society” (MacEachren 1998, p. 575).As a communication network the Web caters equally to the needs of commerceand industry, and to individual members of the public, irrespective of",
    "chunk_order_index": 353,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-bd8b7613a83fdae001001c981df3f2e5": {
    "tokens": 1200,
    "content": "World Wide Web were rapidly recognized to have the potential totransform this closed world view of GIS by, for example, “dramatically increasingthe applications of GIS...through integration of mapping, GIS and non-spatialinformation technologies...to create new forms of representation and new waysto address problems important to society” (MacEachren 1998, p. 575).As a communication network the Web caters equally to the needs of commerceand industry, and to individual members of the public, irrespective of their personalor work-based afﬁliations. In the context of GIS these communication facilities arebeing exploited in several ways. They serve to link together different organizationsand parts of the same organization, and also open access to geographic informationservices and functionality to a wide community of users. GIS are growing thereforefrom their original organization and project-based roles to meet people’s personalneeds for geographically-speciﬁc information. In doing so, they serve to increase aware-ness and participation in developments and activities at local and regional levels.From its very beginnings the Web has incorporated spatial information, with anearly paper describing the concept of the World Wide Web (Berners-Lee, Cailliau,Groff, and Pollermann 1992) including the “authors coordinates” as examples ofthe information which might be served by the, then hypothetical, World Wide Web.The Web provides access both to text, and other “unstructured” media, and tointeractive services for retrieving specialized information or data from online data-bases. Many types of information are geographically referenced and most serviceshave a geographical dimension, based either on the location of the service itself or onthe user of the service. The geographical dimensionality of information has thereforeintroduced a requirement for aspects of the Web to become spatially-intelligent, inTHO_C31  19/03/2007  11:24  Page 559 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f560CHRISTOPHER B. JONES AND ROSS S. PURVESthe sense of being able to understand and respond to requests for geographically-speciﬁc information and in being aware of the location of individuals. Further-more, the distributed infrastructure of the Internet, on which the Web is based, can enhance the effectiveness of the traditional in-house GIS. This is reﬂected inthe possibility of world-wide access to geographic data and to remote geographicdata processing facilities and in allowing members of an organization to retrieveand maintain geographical information from multiple locations, whether ofﬁce orﬁeld-based.In the following section of this chapter we examine the elements of web-basedGIS with regard to the introduction of maps to the Web, the provision of facilitiesfor querying and visualizing geographical information, the provision of geographicdata, and the role of the Web as networked infrastructure for GIS. This is followedby a review of web GIS technology, with reference to open standards for GI Servicesand some examples of the functionality of speciﬁc web GIS. The chapter concludesby considering the way in which the Web itself is being extended to become geo-graphically intelligent for purposes of searching the content of websites.Elements of Web-based GISMaps on the WebFrom the earliest days of the World Wide Web, the facility to display images wasexploited to present maps which provide geographical context to information. A very early interactive map server was developed by Xerox Parc and used by manyservices to display simple web maps (Putz 1994, Towers and Gittings 1995). Busi-nesses often use maps on the Web to show their location, while news agencies suchas the BBC (http://news.bbc.co.uk/) use maps to help people understand where eventsare taking place. Websites such as the BBC are constantly being updated, but newitems referred to on the home page will often include maps. The simplest types ofweb map are static, non-interactive images, and this is the norm for these contextualmaps. The standard facilities of HTML, the original mark-up language for web docu-ments, can, however, be used to provide some degree of interactivity, whereby themap includes clickable icons, or hot spots, which provide hyperlinks to informationabout the highlighted location or map symbol (van Elzakker 2001).Tourist maps such as those of Paris (http://www.paris.org/Maps/MM/) andWashington DC (http://maps/mapnetwork.com/wctc/dispmap.asp?map=1) containsuch hyperlinks which lead to further web pages containing text and images, andsometimes more maps, relating, for example, to museums and monuments. A vari-ation on the use of clickable hot spots is to provide pull-down menus that allowthe user to select some particular type of associated information. This is found on theweb map of the London underground transport system (http://www.visitlondon.com/tubeguru/), in which users can point to stations on a map and select menu itemsabout timetables and associate transport networks.The requirement for navigational and other geographical contextual informationabout commercial and public services can be met by web mapping services such asMultiMap (http://www.multimap.com/), Map 24 (http://www.mapsolute.com/) andTHO_C31  19/03/2007  11:24  Page 560 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library",
    "chunk_order_index": 354,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-9b4f549d95e545c118dacdaaff095c81": {
    "tokens": 1200,
    "content": "http://www.multimap.com/), Map 24 (http://www.mapsolute.com/) andTHO_C31  19/03/2007  11:24  Page 560 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS561MapQuest (http://www.mapquest.com/) which can provide a link from a companyweb site to one of their online maps, which might then contain a symbol markingthe location of the advertised facility. Yellow pages services can link all their entriesdirectly to these mapping services, or a business directory may be integrated with theweb mapping service, as in Google Maps (http://maps.google.com/), which operatesas a stand-alone facility or can be called via an application programming interface(API). These sorts of web mapping services provide extensive geographical coverage,such as for Europe, the USA, or, indeed, the world. Users of these sites can obtainmaps of an area of interest by several methods, such as pointing to and zoominginto a displayed map, or by entering an address, place name, or postcode. The lattermethod will then present a map centered on the speciﬁc location and provide facilities for zooming and panning around the map. The maps themselves are typic-ally retrieved from a database of web maps at different levels of detail but withﬁxed geographic content. Thus the features displayed on the map are predeterminedand do not adapt signiﬁcantly to the interests of the user except with regard tolocation and level of detail.In addition to these navigation-oriented websites there are other services on theWeb that deliver essentially static maps and remotely-sensed images relating to manydifferent domains. The National Libraries of Scotland maintains a collection of mapsdrawn by Timothy Pont in the 1580s and 1590s that are among the earliest existingmaps of Scotland. These maps have been scanned as high resolution images, and aremade publicly available on the Web as jpegs at http://www.nls.uk/pont/ and constitutean amazing set of examples of early cartography (Figure 31.1). Such mechanismsFig. 31.1Example from the Pont map collectionCopyright National Libraries of ScotlandTHO_C31  19/03/2007  11:24  Page 561 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f562CHRISTOPHER B. JONES AND ROSS S. PURVEStransform access, with materials previously only accessible at a single location nowavailable to anyone, anywhere who has a connection to the Internet.The US Geological Survey (USGS; http://www.usgs.gov) is a rich source of maps which can be accessed either directly or via sites such as TerraServer-USA(http://terraserver-usa.com/), which specializes in aerial image data. Maps illustrat-ing emergency situations such as due to ﬂoods and earthquakes, can be found at(http://www.reliefweb.int/w/map.nsf/home/).Querying and visualizing geographic information on the WebGIS are used in many types of organizations, including local government, utility com-panies, environmental monitoring, mineral exploitation, marketing, healthcare, andthe police. See, for example, Part 4 (Applications) of Longley, Goodchild, Maguire,and Rhind (1999) for an extensive set of examples of the application of GIS in theprivate and public sectors.There is a role for web GIS in all these areas. For some organizations the Webis a means of public access to information, while for others it provides a networkinfrastructure that enables employees to access central databases remotely, eitherfrom ofﬁces in multiple geographic locations or, for ﬁeldwork activities such as landsurveying or utility maintenance, from “the ﬁeld” using wireless communications.Local government organizations usually have a responsibility to make informa-tion about their services available to the public and, as a result, web interfaces to GIShave provided a tremendous opportunity for raising awareness of local servicesand,in some cases, of consulting with the local population. In the website for GreenwoodCounty, South Carolina in the USA (http://165.166.39.5/giswebsite/default.htm) the user is given options for layer-based selection of map features representing, for example, boundaries for census and school districts, utility services, topographicfeatures, soil types, and recreation areas. The various features can be then iden-tiﬁed interactively. In the UK the use of web GIS promotes what is referred to ase-government and is reﬂected in many municipal websites that seek to improve communication with the local residents. For example, the city of Rotherham’s website allows users to employ a postcode as a search key for information such asrefuse disposal, schools, local taxation, and planning (development) applications.The website for the UK town of Huntingdon (http://www.huntsdc.gov.uk/) allowsusers to submit planning applications online, in coordination with a national plan-ning portal.A particularly effective example of the use of web GIS in communicating localinformation is seen in the context of monitoring transport systems. The HoustonTranStar website (http://trafﬁc.houstontranstar.org/incmap/) provides up-to-dateinformation on road trafﬁc in Houston with an interactive",
    "chunk_order_index": 355,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-8a7fcd64736cb2314aef58d3e266fe9d": {
    "tokens": 1200,
    "content": "planning (development) applications.The website for the UK town of Huntingdon (http://www.huntsdc.gov.uk/) allowsusers to submit planning applications online, in coordination with a national plan-ning portal.A particularly effective example of the use of web GIS in communicating localinformation is seen in the context of monitoring transport systems. The HoustonTranStar website (http://trafﬁc.houstontranstar.org/incmap/) provides up-to-dateinformation on road trafﬁc in Houston with an interactive map that displays currenttrafﬁc speeds and the presence of road accidents. Clicking on the map provides localdetails including graphs of past and present road speeds and live images of the trafﬁcon the relevant section of road. Speeds of vehicles are determined using an auto-matic vehicle identiﬁcation (AVI) system in which transponder tags within individualvehicles are detected by roadside tag readers. The average speeds of tagged vehiclescan then be calculated by monitoring the progress of individual vehicles. For moreexamples of transport GIS see Peng and Tsou (2003).THO_C31  19/03/2007  11:24  Page 562 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS563Although many municipal websites provide what is essentially a one-way channelof communication, it has been recognized for some time that web GIS have thepotential to facilitate public participation in decision making (Obermeyer 1998,MacEachren 2000, Carver 2001). This potential role in facilitating democratiza-tion is illustrated by the Virtual Slaithwaite website (Kingston 2002; http://www.ccg.leeds.ac.uk/slaithwaite).Another perspective on the role of GIS in decision making is provided by themunicipal websites that promote industrial development. For example, followingmassive local job losses associated with the closure of a shipyard, the city of Vallejoin California developed a web-GIS (http://www.ci.vallejo.ca.us/) which supports those searching for vacant properties within the city boundaries (Figure 31.2). A user may specify the characteristics of suitable properties (for example, size and cost) and can view information about existing businesses in the area. There isalso an option of querying the demographic proﬁle of the inhabitants of the sub-areas of the region, which might be used to predict take up of some proposed newservices.Fig. 31.2City of Vallejo economic development information system From http://gis.ci.vallejo.ca.us/THO_C31  19/03/2007  11:24  Page 563 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f564CHRISTOPHER B. JONES AND ROSS S. PURVESIn the UK, the provision of census data via the Web is another example of thepromotion of e-government. Census results from Scotland, England, and Wales areavailable as dynamically produced thematic maps in response to user queries. Someof the mapping is available as Scalable Vector Graphics (SVG) (see “Presentationand interaction with geographic information on the Web,” below, for more on SVG)which facilitates interactive map query of individual areas for their local statistics.The Scottish Census Results Online website (http://www.scrol.gov.uk/scrol/common/home.jsp) enables the user to specify combinations of variables to plot and to exertconsiderable control over the presentation of these data (Figure 31.3).Such applications come very close to delivering the functionality expected by aprofessional working with GIS, and providing that response times are sufﬁcientlyfast and high-quality printouts are available (through downloadable PDF or post-script ﬁles for example) they can replace a desktop GIS for many purposes.In the Louisiana Statewide GIS (http://atlas.lsu.edu/) demographic data are madeavailable in combination with topographic information. This quite extensive web-site presents scanned maps, vector boundary data, satellite images, and aerial photographs. Interactive maps are used to access recent and historic demographicinformation derived from user-selected census data on a parish by parish level. Themaps allow the user to control the use of color symbols to indicate the values of theselected statistics for each parish, while the user can also click on individual parishesto obtain parish-speciﬁc statistics. There are interactive maps of the historical parishboundaries. The satellite imagery “tour” of the state is based on Landsat ThematicMapper 30 m resolution scenes and is accompanied by informative textual accountsof physical and cultural features visible in the individual images. It is also possibleto download geographic data on several themes, including biological, socio-economic,infrastructure, and geophysical topics.Fig. 31.3Options for thematic map and resulting presentation of Scottish census data2001 Census data supplied by the General Register Ofﬁce for Scotland; © Crown CopyrightTHO_C31  19/03/2007  11:24  Page 564 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA",
    "chunk_order_index": 356,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0294ce1e8760627dbdccf32fce2e0787": {
    "tokens": 1200,
    "content": "data supplied by the General Register Ofﬁce for Scotland; © Crown CopyrightTHO_C31  19/03/2007  11:24  Page 564 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS565There are many more examples of web GIS applications in the above applica-tion areas and in others such as emergency response, agriculture, leisure activities,and utility maintenance (see Peng and Tsou 2003 for additional examples).The Web as a source of spatial dataWe have described above some uses of web GIS to communicate geographical informa-tion, usually visualized as some form of map. An increasingly important use of webGIS is, however, in locating and downloading spatial data for use in desktop GISand other programs. From the approach of the USA, where many data sets are madefreely available, to that of many European countries, where much data is only avail-able after payment of a licensing fee, the accessibility of data sets online varies greatly.The vast array of spatial data (and data with a spatial component) has also led to thedevelopment of digital libraries and portals, which act as clearinghouses for largecollections of related spatial data (see Chapter 1 by Cowen in this volume for additional discussion of these types of innovations).For example, the USGS has developed a spatially seamless data server (http://seamless.usgs.gov/) to deliver a wide range of its data holdings. Users can specifyparticular data sets and extents for retrieval through an intuitive map interface and,depending on the resulting data volumes, a ﬁle is made available for transfer eitherover the Internet or as a CD-ROM (Figure 31.4). Such approaches are graduallybecoming a commonplace technique, and as they proliferate several challenges are becoming apparent.Chief among these challenges is the distribution and use of accurate and up-to-datemetadata (Green and Bossomaier 2002). As users combine data sets, the potentialincreases for generating inappropriate or erroneous results as a consequence of differing source scales, collection periods and data qualities. The data sets deliveredby the USGS data server described above come bundled with Federal GeographicData Committee (FGDC) metadata (FGDC 1997). Production and delivery of FGDCmetadata for all US government bodies was made a legal requirement by anExecutive Order from the President in 1994 (http://www.fgdc.gov/).Digital libraries such as the Alexandria Digital Library (ADL) project set out to provide access via the Web to georeferenced materials such as maps and images (Andresen, Carver, Dolin, et al. 1995; http://www.alexandria.ucsb.edu/). An essential aspect of this provision is the maintenance of geographic metadata,such as an enclosing minimum bounding rectangle and the names of settlementsand states, in association with the stored resources. The tasks of generating the metadata and of searching for the resources are facilitated by the presence of gazetteers and ontologies of spatial information (Hill, Frew, and Zheng 1999, Jones,Abdelmoty, Finch, Fu, and Vaid 2004) that provide the link between place namesand geographic coordinates. Digital libraries aim to store not only explicit geo-spatial data (such as topographic or elevation data), but also any data which canbe georeferenced – for example, documents describing events at a particular time(Buttenﬁeld 1997). Another geolibrary, which illustrates this diversity of materialsis the Go-Geo project that has developed a service allowing users in UK HigherEducation to “discover” geographic and geographically-referenced data via the Web (Reid, Higgins, Medyckyj-Scott, and Robson 2004). Figure 31.5 shows an THO_C31  19/03/2007  11:24  Page 565 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f566CHRISTOPHER B. JONES AND ROSS S. PURVESexample of a search for research project reports related to Edinburgh. In “A SpatiallyAware Web,” below, we pursue the subject of web search of spatially referencedinformation in more detail.The Web as an integral part of GISEarlier in this section we showed how the Web is playing an important role in usingGIS to communicate geographically-referenced information to a very wide audience.In addition to this role as a presentation medium, the Web and associated Internettechnology is also starting to become an integral element of the maintenance, andindeed of the structure, of some GIS. At the time of writing the most obvious aspectof this is in organizations that require their employees to be located at multiplelocations for purposes of data acquisition and maintenance. Other aspects which canFig. 31.4The interface of the USGS seamless data distribution system with selected data highlighted in green (i.e. darkest shade in map window)Data available from US Geological Survey, at the National Center for EROS, Sioux Falls, SD, USATHO_C31  19/03/2007  11:24  Page 566 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online",
    "chunk_order_index": 357,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-41e8058f406b9be1883cb88ddb66d42a": {
    "tokens": 1200,
    "content": "aspects which canFig. 31.4The interface of the USGS seamless data distribution system with selected data highlighted in green (i.e. darkest shade in map window)Data available from US Geological Survey, at the National Center for EROS, Sioux Falls, SD, USATHO_C31  19/03/2007  11:24  Page 566 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fFig. 31.5An example search for data with GeoXWalk © EDINA National Data CentreWEB-BASED GIS567THO_C31  19/03/2007  11:24  Page 567 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f568CHRISTOPHER B. JONES AND ROSS S. PURVESbe expected to develop further are the use of the Web to access data for immediateuse at remote data servers and the use of the Web to access GIS functionality in adistributed manner.Intra-organization maintenance of GISSome organizations operate in an essentially distributed manner in the sense thatemployees may work at multiple locations in order to acquire and update data for input to a GIS. Primary examples of this area are in topographic and otherenvironmental survey organizations and in the utility and facilities maintenance industries.In the case of geographic survey organizations, it has been commonplace for many years to employ mobile computers to record data in the ﬁeld. In the past,the surveyor may have carried a copy of the relevant part of the spatial databaseand recorded new data on a disk on the mobile device. The updated componentswould then have been transported in some way to a central ofﬁce. With the arrivalof the Internet it became possible to transfer data quickly to a central data serverfrom a local Internet connected ofﬁce. With the advent of wireless Internet com-munications technologies it has become possible to transmit to and receive datadirectly from a main spatial data server irrespective of location, provided that it iswithin range of a wireless communications infrastructure. In the latter scenario the surveyor can download data directly to their mobile device and then send backnew data in the course of an online session. The mobile device is simply a remotelylocated component of the GIS.Similar efﬁciencies are gained by the use of the Internet in organizations that mayhave multiple geographically distributed ofﬁces all contributing to a central spatialdatabase. In these situations, which might not depend so much on mobile com-munication technology, the Internet effectively closes the geographical gap betweendifferent parts of the same organization.Inter-organization distributed GISThe idea of distributed functionality of a GIS within an organization as outlinedabove is well established. A further development of distributed functionality, so farmuch less well established, is that in which different functional components of aGIS may be located within different organizations. In such a case one organizationmay provide specialized GIS functionality concerned, for example, with networkanalysis, geostatistics, or spatial interaction modeling which another organizationaccesses on demand. Thus the user organization may have some data on which theywish to perform the particular analysis.The converse of this situation is one in which an organization may have relevantGIS processing power but require access to some particular data resource on whichto perform an analysis in its own right, or which may need to be integrated withan existing “in-house” set of data.A third possibility in this context is that of an organization that requires accessboth to remote data resources and to remote functionality. In this situation, it couldbe that the user organization has no permanent GIS functionality or data store, butaccesses both types of resource on demand.THO_C31  19/03/2007  11:24  Page 568 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS569This view of distributed GIS leads to the concept of GI Services and it is one thatdepends very much upon effective interoperability at the level of both data and func-tionality. Peng and Tsou (2003) give a good introduction to the ramiﬁcations of thisapproach. It is a very interesting prospect in that it abandons the traditional rathermonolithic view of GIS in favor of a much more ﬂexible service-based approach. Itsviability is yet to be proven and, as can be envisaged, it raises important questionsregarding the willingness of some organizations to hand over responsibility for bothfunctionality and data access to third parties, as well as issues such as ensuringconsistency of provision of functionality and data for a particular organization overprotracted periods of time.Implementing Web-based GISIn this section, we introduce the technical foundations for web GIS. We identifythe main components of typical systems, before describing brieﬂy some of the con-tributions of the Open GIS Consortium to the development of geographical webservices and giving some examples of how these concepts are employed in a fewweb GIS applications.Architectures for Delivering Web Services",
    "chunk_order_index": 358,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-0651e809d0a6dd0415445c49ed93f3d4": {
    "tokens": 1200,
    "content": "issues such as ensuringconsistency of provision of functionality and data for a particular organization overprotracted periods of time.Implementing Web-based GISIn this section, we introduce the technical foundations for web GIS. We identifythe main components of typical systems, before describing brieﬂy some of the con-tributions of the Open GIS Consortium to the development of geographical webservices and giving some examples of how these concepts are employed in a fewweb GIS applications.Architectures for Delivering Web ServicesThe Internet is essentially a series of protocols, or agreements, that allow com-puters acting as servers to be accessed from remote locations by other computersacting as clients (for example, Spainhours and Eckstein 2002). The protocol mostcommonly used on the World Wide Web is known as HTTP (hypertext transferprotocol). Through this protocol a client (commonly a web browser) uses a URL(uniform resource locator) to ask a server to send data back to the client. Usuallythese data are sent in the form of HTML (hypertext mark up language), which isthen rendered in the web browser according to the browser’s interpretation of themark-up commands. HTML is concerned with describing how contained text andimages, and the associated hypertext link URLs, should be formatted and presentedwith regard to factors such as size, color, and type of text font, and the form ofparagraphs and tables. Thus HTML contains both content and speciﬁcation of thestyling of that content (Raggett, Le Hors, and Jacobs 1999).There are many possible ways to implement web servers to respond to requestsfrom clients. The most simple web servers store HTML documents as ﬁles that are transmitted in response to a request from the client. However, for websites with a large amount of content this approach lacks ﬂexibility with regard to accessand update of particular types of information and with regard to the way in whichinformation is presented to the user. These shortcomings are overcome by using a database management system to store information contentwhich can then beretrieved selectively in response to a user request and formatted with a commonstyling before being transmitted to the client as HTML. This solution separates con-tent from styling, which as we will see is also an important concept in deliveringmaps over the Internet. It is normally combined with facilities for the client to solicit the user’s requirements via menus and text boxes. This user input is thensent to the server in order to formulate a query to the database.THO_C31  19/03/2007  11:24  Page 569 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f570CHRISTOPHER B. JONES AND ROSS S. PURVESThree-tier architecture for Web GISDelivering both maps and data to clients over the Internet can be accomplished inmany different ways. At the most basic level a website could store a collection ofHTML pages that contain maps in the form of GIF or JPEG images, examples of which were presented above in “Maps on the Web.” This suffers from the inﬂex-ibility referred to above. In practice a web GIS will usually generate a map in HTMLor another markup language on the ﬂy in response to a user query. The typicalweb GIS architecture consists of separate components, or tiers, responsible for presentation, application logic (also called business logic), and data management(see, for example, ESRI 2004).The presentation tier is responsible for displaying data to the user and inter-acting with user requests, for example to pan and zoom a map, or a query to aparticular feature. The application logic translates a request from the presentationtier for a map or data into a query for data from one or more data sources. Thisquery formulation is normally performed by what are referred to as spatial serversor map servers, of which there may be several types differentiated according to the type of data that they retrieve. The application tier may also deal with loadbalancing between these servers (ensuring that performance is not compromised bymaking excessive demands upon an individual server). Furthermore, it can handleauthorization and authentication requirements and some aspects of data process-ing and analysis associated with the required data. The data management tier iswhere the data are stored, generally in databases, although sometimes in simple ﬁlestructures. The data management tier can consist of several different types of data-base and data representation and they may be located either on the same computeras the application logic or on different, possibly remote computers. Figure 31.6 illustrates the architecture of a typical web GIS solution.Interoperability and the OpenGIS ConsortiumThe implementation of these web GIS components requires specialized software.However, it should be apparent to a user familiar with GIS that some of the func-tionality of these components can be found as elements of many desktop GIS. A keytask in web GIS is to separate the components to allow interoperabilitybetweenapplication logic, data, and presentation tiers. Thus the functionality and location ofeach component is relatively independent of the other, but they can all communicateeffectively. Interoperability has long been a holy grail for GIS users, as anyone whoFig. 31.6Three-tier web GIS architectureMapsTextImagesGraphs tablesPresentationSpatialserver(s)ApplicationLogicVector dataImagesMapsMetadataData StoreTHO_C31  19/03/2007  11:24  Page 570 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https",
    "chunk_order_index": 359,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4173d3cf73bcf701781b2af10ce9024c": {
    "tokens": 1200,
    "content": "grail for GIS users, as anyone whoFig. 31.6Three-tier web GIS architectureMapsTextImagesGraphs tablesPresentationSpatialserver(s)ApplicationLogicVector dataImagesMapsMetadataData StoreTHO_C31  19/03/2007  11:24  Page 570 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS571has spent long afternoons converting between data stored in different formats willbe all too aware of. The basic concepts of interoperability involve the developmentof a set of standard interfacesspecifying which operations can be performed byparticular services (as opposed to how they are implemented), in combination withstandard languages and formats for representing and transferring information.A host of different proprietary and open standards exist to deliver spatial datato web browsers. Proprietary solutionsare those which are speciﬁc to an individualsoftware application or data format and generally require users to buy a speciﬁcpiece of software. Open standardsare free to use and are used by both commercialand non-commercial developers. The OpenGIS Consortium (OGC) was founded in1994 to develop open interfaces and standards to allow geographic software anddata to interoperate. One of the early contributions of OGC was to deﬁne an XML(extensible Markup Language) “vocabulary” for representing and communicatingspatial and non-spatial properties of geographic information on the Web. This isthe Geographical Markup Language (GML), which is described in more detail byKnoblock and Shahabi in Chapter 10 of this volume.Open Web Services Framework (OSF)A key concept in the OGC’s vision for interoperability is that of services which pro-vide various types of functionality and data (Cuthbert 1999). The OSF is intendedto facilitate interoperability between services through the use of standard interfacesand to facilitate publishing and discovering the presence of services. The OSF cat-egorizes services as registry, data, portrayal, processing, and application services(Figure 31.7).Registry servicesare concerned with maintaining information about data and ser-vices, that is to say metadata, that may be employed to discover the existence and thenature of these resources. They are linked with the use of catalogs that store metadata.Once a client has established the existence of relevant data, it may employ a dataserviceto access the data from its respective database (or “repository”). The OGCReference Model (OpenGIS 2003) refers speciﬁcally to four types of data service,namely Feature Access Services (for example, the OGC Web Feature Service WFS),Coverage Access Services, Sensor Collection Services, and Image Archive Services.OSF processing servicesare concerned with operations upon geographic data andinclude services such as those for coordinate transformation, image registration, trans-formations between spatial data models, geocoding, and route ﬁnding. Portrayalservicesprovide functionality for displaying geographic data and images and includethe generation of maps and terrain model visualizations. Speciﬁc types of portrayalservices may be dedicated to maps, coverages, and to the requirements of mobiledevices.OSF application servicestypically make use of the previous services of registry,data, and portrayal for speciﬁc applications such as resource discovery, map viewing,image exploitation, web-based sensor access, and mobile location-based services. Anapplication service may consist of a chain of other services such that, for example,a registry service identiﬁed a data access service which was employed to retrievesome contents of an application-speciﬁc data repository, prior to user display in aportrayal service.THO_C31  19/03/2007  11:24  Page 571 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f572CHRISTOPHER B. JONES AND ROSS S. PURVESWe now describe two of the most familiar OGC interfaces, the Web Map Service,which is a portrayal service, and the Web Map Feature Service, which is a dataservice.Web Map Services (WMS)A WMS delivers geo-referenced mapping to a client browser in respond to a request(OpenGIS 2002, 2003). Maps are in the form of an image, in either raster or vectorform, which portrays an underlying set of spatial data. A WMS is required to imple-ment two operations:•GetCapabilities: A request to a WMS for its capabilities delivers XML meta-data specifying the possible options that can be used when making a requestfor a map;•GetMap: Requests that a WMS deliver a map to the client according to somegiven parameters.A GetMap request would typically specify at least the geographical bounding box ofthe map (for example, 56°→57°N; 3°W→2°W) to be produced and the corres-ponding image size and format (for example, 200 ×200 pixels, jpeg), and the namesDiscoveryApplication ServicesFindBindMapViewerImageryExploitationValue-AddSensorWebLocationOrganizerMobileLocationServiceDataRegistryRegistry ServicesServiceRegistryDeviceRegistryStyleRegistryFASData ServicesCASSCS*Directory*GatewayIASMPSPortrayal ServicesCPS*MobilePresent.TPSChainingProcessing Services = OpenGIS Service Interface* = OpenLS Service/EncodingCoord.Trans",
    "chunk_order_index": 360,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-2940eef089959d36ed928a0cb61e5505": {
    "tokens": 1200,
    "content": "produced and the corres-ponding image size and format (for example, 200 ×200 pixels, jpeg), and the namesDiscoveryApplication ServicesFindBindMapViewerImageryExploitationValue-AddSensorWebLocationOrganizerMobileLocationServiceDataRegistryRegistry ServicesServiceRegistryDeviceRegistryStyleRegistryFASData ServicesCASSCS*Directory*GatewayIASMPSPortrayal ServicesCPS*MobilePresent.TPSChainingProcessing Services = OpenGIS Service Interface* = OpenLS Service/EncodingCoord.Transf.Geocoder*RouteDetermin.*ReverseGeocoderGazetteerEncodingsGMLXIMASLDServiceMetadataSensorMLObs& Meas*XLSImageMetadataLOFPublishFig. 31.7Open web services framework From OpenGIS, 2003; Copyright 2006 OGCTHO_C31  19/03/2007  11:24  Page 572 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS573of the layers to be mapped (for example, roads, railways, lakes). Since a WMS maybe capable of producing transparent maps it is possible to overlay the results of aquery to one WMS on top of another – for example with the topographic datafrom a National Mapping Agency WMS providing a backdrop to wildlife sightingsproduced at a local WMS. Figure 31.8 illustrates such a process.Web Feature Servers (WFS)WFS deliver not maps but data in response to a request (OpenGIS 2002). Thesedata are delivered in the form of GML and consist of “simple” geometric primitivesin the form of points, lines, and polygons and collections of these primitives. A WFSmust also implement a GetCapabilities command describing what features it maydeliver. A WFS must also implement two further operations:•DescribeFeatureType: Describes the nature of a feature;•Get Feature: Delivers a feature according to some request, which may be spatiallyconstrained.Since a WFS delivers data, and a WMS delivers portrayals of data it is possible tochain together a WMS with a WFS to provide a service to deliver mapping on theInternet. Such an approach makes clear the separation of content from styling.A WMS may provide the user with options, through a set of named styles, todeliver a number of different portrayals of the same data. Such predeﬁned styles maybe useful in, for example, a corporate environment, where a number of differentmap styles are used in different applications. Much greater ﬂexibility is providedthrough the solution described above where a WFS and WMS interact. Here, theWMS can have extended capabilities which allow the client to pass it a Styled LayerInternetSpatial database(Wildlife observationsand forestry parcelboundaries)WMSSpatial database(Topographic data)WMSSpatial database(Meteorologicalobservations)WMSUser 1 (Querying formeteorologicalobservations withtopographic backdrop)User 1 (Querying fordeer observations withtopographic backdrop)Fig. 31.8Interoperating web map servicesAfter ESRITHO_C31  19/03/2007  11:24  Page 573 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f574CHRISTOPHER B. JONES AND ROSS S. PURVESDescriptor (SLD). This SLD is essentially an XML template which speciﬁes howlayers retrieved from the WFS should be drawn, before being returned to the clientthrough the WMS. This last solution allows a consistent user-deﬁned styling to beapplied for portrayal of data from a variety of sources (Figure 31.9).Open standards as described above have many attractions and have been widelyadopted by vendors (see http://www.opengis.org/resources/?page=products foradditional details). Indeed, open standards do not in any way preclude proprietarysolutions, but rather specify a set of operations which will provide compliance withthe standard. However, proprietary solutions are equally, if not more, common on theInternet for a variety of reasons, often related to the provision of speciﬁalized func-tionality and performance. For example, ESRI’s ArcIMS(Internet Map Server) provides presentation, business logic and data management tiers. If these individualtiers implement open standards, for example the WMS for purposes of presenta-tion, it becomes possible for them to interoperate with other compliant services toprovide seamless mapping or data to the user.Fig. 31.9Two representations of the same data using different style layer descriptors and an extractfrom the SLD for the representation given on the rightAll from http://www.cubewerx.comTHO_C31  19/03/2007  11:24  Page 574 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS575Presentation and interaction with geographic information on the WebGenerally the ﬁ",
    "chunk_order_index": 361,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d6ed8249a9070660d405ae285cb64dbb": {
    "tokens": 1200,
    "content": "11:24  Page 574 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS575Presentation and interaction with geographic information on the WebGenerally the ﬁrst realization of a map (or data set) is not exactly what the userrequired. They may wish to reﬁne their choice by zooming in or out, panning toinclude another location, turning on or off speciﬁc layers of data, or choosing to addsymbols to the rendered map. For an example of the techniques required to deliver“intelligent zooming,” see Cecconi and Galanda (2002).The user may also wish to query attributes of data presented or even producealternative visualizations of the same data, perhaps in the form of graphs or charts.In order to perform any of these operations the user must interact with the datathrough the user interface.The implementations of user interfaces for web GIS take two basic forms: so called thin clients and thick clients. A thin client is usually conﬁned to gatheringinformation from the user, submitting it as a query to the server, and renderingthe document that is retrieved from the server. Thus, when the user pans or zooms,a request is sent to the server and a new map is delivered. Thick clients move someof the work from the server to the client. Here, for example, vector data may bedelivered to the client which is then responsible for rendering the data as an image(by means for example of a Java applet). With such an approach it is possible to deliver data to the client as a continuous stream in anticipation of a request.Bertolotto and Engenhofer (2001) describe an approach to progressive delivery ofa stream of such data to maximize response times. For instance, after an initialrequest for data, information about the surrounding area may be also delivered tothe thick client, on the not unreasonable assumption that the user is likely to panaround within the initial selection. Whether a thin or think client is used, it is vitalthat response times are short and controls are intuitive. Examples of client- andserver-based web mapping tools are given in Medyckyj-Scott and Morris (1998)and Jankowski, Stasik, and Jankowska (2001).Both of the examples shown in Figure 31.10 deliver raster data to the client. Thus,if the user desires information about an individual feature, a query for a locationmust be made, and attribute information to be displayed for all features at thatlocation returned from the server. A much more ﬂexible solution, where attributeinformation related to features is required, is provided by the use of vector data,for example through Scalable Vector Graphics (SVG) (see http://www.adobe.com/svg/main.html and Ferraiolo, Fujisawa, and Jackson 2003 for additional details).SVG delivers an XML-based data format to a client, which can be visualized througha plug-in. The SVG data contains the speciﬁcation of how the data are to be sym-bolized on the display. It is possible to produce SVG by applying a styling to GMLdata. Figure 31.11 shows SVG representing Ordnance Survey MasterMapdata. Asthe user moves the mouse around the screen, different objects are highlighted anda unique identiﬁer is displayed below.Much more complex interaction with SVG is possible, and Figure 31.12 showsan example developed at the ETH Cartography Department with a wide range ofoptions to vary the rendering of the map. See the SVG series of conferences for a widerange of examples of the use of the SVG (http://svgopen.org/). All of the examplesdescribed here focus on 2D visualization of spatial data. However, as described byTHO_C31  19/03/2007  11:24  Page 575 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f576CHRISTOPHER B. JONES AND ROSS S. PURVESCartwright (1999), there are many ways of visualizing spatial data. For example,Purves, Dowers, and Mackaness (2002) described techniques to integrate georefer-enced 3D visualizations of terrain with 2D mapping and navigation tools using acombination of Java, HTML, and the Virtual Reality Modeling Language (VRML),Fig. 31.10A thin client (http://www.multimap.com) and a thick client (http://www.mappy.com).Note controls for panning and zooming in both cases. The thick client solution provides for displayof a subset of the imagery that it storesImage reproduced by permission of Multimap.com and Collins BartholomewFig. 31.11Ordnance Survey MasterMap data displayed as SVG From http://www.ordnancesurvey.co.uk/oswebsite/xml/resource/index.html; © Crown Copyright,Ordnance Survey mapping, all rights reservedTHO_C31  19/03/2007  11:24  Page 576 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://",
    "chunk_order_index": 362,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-38785aa0af5b686c8338896e659bfb4d": {
    "tokens": 1200,
    "content": "Survey MasterMap data displayed as SVG From http://www.ordnancesurvey.co.uk/oswebsite/xml/resource/index.html; © Crown Copyright,Ordnance Survey mapping, all rights reservedTHO_C31  19/03/2007  11:24  Page 576 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS577a mark-up language developed speciﬁcally for producing 3D visualizations (Ames,Nadeau, and Moreland 1997). However, 3D GIS has been slow to develop on theWeb with limitations imposed by plug-in development and lack of a universallyagreed standard, together with difﬁculties in interaction and navigation for users.A Spatially Aware WebGIS are normally associated with processing highly structured geographic data, spatially referenced by means of geometric coordinates. At present the Web is par-ticularly effective in retrieving unstructured, usually textual, information. Much ofthis is spatially referenced implicitly, in that web documents often refer to placesthat provide context for their subject matter. The place information may occur, forexample, within addresses of businesses or within free text descriptions in whichpeople, events, and social and environmental processes may be associated with geographic location designated by place names and landmarks.Fig. 31.12Example of the use of SVGFrom http://www.carto.net/papers/svg/tuerlersee/; with permission of Andreas Neumann, ETH Zurich;background data ©SwissTopoTHO_C31  19/03/2007  11:24  Page 577 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f578CHRISTOPHER B. JONES AND ROSS S. PURVESIt is only in the past ﬁve or so years (since around 2000) that web search engineshave provided no facilities specialized for access to the geographic dimension ofweb resources. Geographic search would depend upon ﬁnding documents that includedexact matches to place names in the user query expression. A few search enginesdo incorporate specialized geographic search facilities that let the user specify location in the form of place names, addresses, or post codes separately from thethematic subject of their query. An example of such functionality may be found in Google’s specialized geographic search facilities (http://local.google.com/ andhttp://earth.google.com/). These types of web search provide a new form of GISthat differs radically from the conventional form in focusing on access to text andother media documents and in making their functionality freely available to all usersof the Internet.Web-based geographic information retrieval technology depends upon facilitiesfor recognizing the presence of place names in a user query; classifying web docu-ments according to their geographic context; indexing the documents with respectboth to their textual content and to space; and ranking relevance in a manner thatcombines geographic and thematic context. In order to achieve this functionality itis essential to have access to some form of geographic ontology based on gazetteersor geographic thesauri. This could contain lists of place names, geometric footprintsrepresenting the spatial extent of places, and some spatial relationships between places,such as those of containment (Jones, Purves, Ruas, et al. 2002, Jones, Abdelmoty,and Fu 2003, Jones, Abdelmoty, Finch, Fu, and Vaid 2004).CONCLUSIONSWe have seen in this chapter how web GIS is transforming the traditional view ofGIS as a specialist professional resource to one that can be shared by a much widercommunity of people who have interests in geographic information. The Web isalso helping major users of “in house” GIS technology, such as local governmentand environmental agencies, to promote their activities effectively, and in some cases to allow the public to participate in decision making. For the professionalusers of GIS the Web provides the potential for convenient access to remote datasources and remote geographic processing power. It facilitates mobile work modes for topographic and environmental survey organizations in which data may beacquired and updated in ﬁeld operations that involve direct communications withcentralized or distributed data servers. The opportunities for distributed access togeographic information can be exploited by the general public using location-awarein-vehicle and hand-held devices, to obtain information about local services andtourist attractions.At the time of writing, web GIS technology is very much in a state of ﬂux, dueto rapid developments in Internet technology. While providing many opportunitiesthe Web is also raising interesting research challenges that must be addressed if these opportunities are to be fully realized. These include solving problems ofcompatibility and hence interoperability between disparate data sources andbetween geographic information software. Progress will also need to be made inimproving the quality of user interfaces of mobile devices and geographic web searchTHO_C31  19/03/2007  11:24  Page 578 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS579facilities, for example to accommodate the",
    "chunk_order_index": 363,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-8591a514104ab82948de0a638646d4b4": {
    "tokens": 1200,
    "content": "/2007  11:24  Page 578 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fWEB-BASED GIS579facilities, for example to accommodate the map display limitations of small devicesand the need for people to be able to communicate with geographic web servicesusing natural language terminology. There is also a need to ﬁnd better ways to categorize web documents automatically and accurately with regard to their geo-graphic relevance.REFERENCESAmes, A. L., Nadeau, D. R., and Moreland, J. L. 1997. VRML 2.0 Sourcebook. London:John Wiley and Sons.Andresen, D., Carver, L., Dolin, R., Fischer, C., Frew, J., Goodchild, M. F., Ibarra, O., Kothuri, R., Larsgaard, M., Manjunath, B., Nebert, D., Simpson, J., Smith, T., Yang, T.,and Zheng, Q. 1995. The WWW Prototype of the Alexandria Digital Library. InProceedings of the International Symposium on Digital Libraries (ISDL ’95),Tokyo, Japan,pp. 17–27. (Available at http://www.dl.slis.tsukuba.ac.jp/DLW_E/.)Berners-Lee, T., Cailliau, R., Groff, J., and Pollermann, B. 1992. World-wide web: The in-formation universe. Electronic Networking: Research, Applications and Policy1: 74–82.Bertolotto, M. and Egenhofer, M. J. 2001. Progressive transmission of vector map data overthe World Wide Web. GeoInformatica5: 345–73.Buttenﬁeld, B. P. 1997. Delivering maps to the information society: A digital library for cartographic data. InProceedings of the Seventeenth Conference of the InternationalCartographic Association, Stockholm, Sweden. Stockholm: International CartographicAssociation, pp. 1409–16.Cartwright, W. E. 1999. Extending the map metaphor using web delivered multimedia.International Journal of Geographical Information Science13: 335–53.Carver, S. 2001. Public participation using web-based GIS. Environment and Planning B28: 803–4.Cecconi, A. and Galanda, M. 2002. Adaptive zooming in web cartography. Computer GraphicsForum21: 787–99.Cuthbert, A. 1999. OpenGIS: Tales from a small market town. In A. Vokovski and K. E. Brassel(eds) Interoperating Geographic Information Systems. Berlin: Springer-Verlag LectureNotes in Computer Science No. 1580: 17–28.ESRI. 2004. ArcIMS 9 Architecture and Functionality White Paper. WWW document,http://downloads.esri.com/support/whitepapers/ims_/arcims9-architecture.pdf.FGDC (Federal Geographic Data Committee). 1997. FGDC Standards Reference Model. WWWdocument, http://www.fgdc.gov/standards/refmod97.pdf.Ferraiolo, J., Fujisawa, J., and Jackson, D. 2003. Scalable Vector Graphics (SVG): 1.1,Speciﬁcation. WWW document, http://www.w3.org/TR/2003/REC-SVG-20030114/.Green, D. and Bossomaier, T. 2002. Online GIS and Spatial Metadata. London: Taylor andFrancis.Hill, L. L., Frew, J., and Zheng, D. 1999. Geographic names: The implementations of agazetteer in a georeferenced digital library. D-LibMagazine5(1) (available at http://www.dlib.org/dlib/january99/hill/01hill.html).Jankowski, P., Stasik, M. I., and Jankowska, M. A. 2001. A map browser for an Internet-based GIS data repository. Transactions in GIS5: 5–18.Jones, C. B., Purves, R., Ruas, A., Sanderson, M., Sester, M., van Kreveld, M., and Weibel, R.2002. Spatial information retrieval and geographical ontologies: An overview of the SPIRITproject. InProceedings of the Twenty-ﬁfth Annual ACM International SIGIR Conferenceon Research and Development in Information Retrieval (SIGIR ’02), Tampere, Finland,pp. 387–8.THO_C31  19/03/2007  11:24  Page 579 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f580CHRISTOPHER B. JONES AND ROSS S. PURVESJones, C. B., Abdelmoty, A. I., and Fu, G. 2003. Maintaining ontologies for geographicalinformation retrieval on the Web. In R. Meersman, Z. Tari, and D. C. Schmidt (eds)Proceedings of the OTM Confederated International Conferences, CoopIS",
    "chunk_order_index": 364,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-d6979e1fb98559dad268e5c07d6e89e6": {
    "tokens": 1200,
    "content": "Library for rules of use; OA articles are governed by the applicable Creative Commons License\f580CHRISTOPHER B. JONES AND ROSS S. PURVESJones, C. B., Abdelmoty, A. I., and Fu, G. 2003. Maintaining ontologies for geographicalinformation retrieval on the Web. In R. Meersman, Z. Tari, and D. C. Schmidt (eds)Proceedings of the OTM Confederated International Conferences, CoopIS, DOA, andOOBASE,Catania, Italy: Springer Lecture Notes in Computer Science No 2888: 934–51.Jones, C. B., Abdelmoty, A., Finch, D., Fu, G., and Vaid, S. 2004. The SPIRIT spatial searchengine: Architecture, onologies and spatial indexing. In M. Egenhofer, C. Freksa, and H. Miller (eds) Geographic Information Science: Third International Conference, GIScience2004.Berlin: Springer Lecture Notes in Computer Science No 3234: 125–39.Kingston, R. 2002. Web-based PPGIS in the United Kingdom. In W. J. Craig, T. M. Harris,and D. Weiner (eds) Community Participation and Geographic Information Systems.London:Taylor and Francis, pp. 101–12.Longley, P. A., Goodchild, M. F., Maguire, D. J., and Rhind, D. W. 1999. GeographicalInformation Systems.New York: John Wiley and Sons.MacEachren, A. M. 1998. Cartography, GIS and the World Wide Web. Progress in HumanGeography22: 575–85.MacEachren, A. M. 2000. Cartography and GIS: Facilitating collaboration. Progress in HumanGeography24: 445–6.Medyckyj-Scott, D. J. and Morris, B. 1998. The virtual map library: Providing access toOrdnance Survey digital map data via the WWW for the UK higher education community.Computers, Environment and Urban Systems21: 31–45.Obermeyer, N. 1998. The evolution of public participation GIS. Cartography andGeographic Information Systems25: 65–6.OpenGIS Consortium. 2002. OpenGIS Web Feature Service Implementation Speciﬁcation1.0.0.2002. WWW document, http://www.opengeospatial.org/docs/02-058.pdf.OpenGIS Consortium. 2003. OpenGIS Reference Model 0.1.2.2003. WWW document,http://www.opengis.org/docs/03-040.pdf.Peng, Z.-R. and Tsou, M.-H. 2003. Internet GIS: Distributed Geographic Information Servicesfor the Internet and Wireless Networks. Hoboken, NJ: John Wiley and Sons.Purves, R. S., Dowers, S., and Mackaness, W. A. 2002. Providing context in Virtual Reality:The example of a CAL for mountain navigation. In P. F. Fisher and D. Unwin (eds) VirtualReality in Geography.London: Taylor and Francis: 175–89.Putz, S. 1994. Interactive Information Services Using the World-Wide Web, Hypertext in the First International World-Wide Web Conference. WWW document, http://www.parc.xerox.com/istl/projects/www94/iisuwwwwh.html.Raggett, D., Le Hors, A., and Jacobs, I. 1999. HTML 4.01 Speciﬁcation. WWW document,http://www.w3,org/TR/html401/.Reid, J., Higgins, C., Medyckyj-Scott, D., and Robson, A. 2004. Spatial data infrastructuresand digital libraries: Paths to convergence. D-Lib Magazine 10 (available at http://www.dlib.org/dlib/may04/reid/05reid.html.Spainhours, S. and Eckstein, R. 2002. Webmaster in a Nutshell(3rd edn). Cambridge: O’Reilly.Towers, A. L. and Gittings, B. M. 1995. Earthquake monitoring and prediction. A case studyof GIS data integration using the Internet. In P. F. Fisher (ed.) Innovations in GIS 2.London:Taylor and Francis: 233–43.Van Elzakker, C. P. J. M. 2001. Use of maps on the Web. In M. J. Kraak and A. Brown(eds) Webcartography: Developments and Prospects.London: Taylor and Francis: 37–52.THO_C31  19/03/2007  11:24  Page 580 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 32Location-based Services andGeographic Information SystemsAllan J. BrimicombeA century ago, motoring was about as young as Geographic Information Systems(GIS) are today. When veteran cars were new, roads were neither numbered norsignposted. Most towns, villages, and roads did not announce their names on signsas one entered them. In fact, ﬁnding one’s way around became so troublesome thatmotoring associations such as the AA and RAC sprang up not just to assist withmechanical breakdowns but also to assist in wayﬁnding",
    "chunk_order_index": 365,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-2de5cf7253a5e02065a69c7e82c7bb20": {
    "tokens": 1200,
    "content": "BrimicombeA century ago, motoring was about as young as Geographic Information Systems(GIS) are today. When veteran cars were new, roads were neither numbered norsignposted. Most towns, villages, and roads did not announce their names on signsas one entered them. In fact, ﬁnding one’s way around became so troublesome thatmotoring associations such as the AA and RAC sprang up not just to assist withmechanical breakdowns but also to assist in wayﬁnding with maps and signage, andthis continues to be their dual function. Today we take road signage including allthe highway code mandatory and advisory notices for granted – and what a lot thereare! Next time you go out in a car, just count how many signs you pass. Giventhe volume of trafﬁc, could we be trusted today to drive safely without them? Given the huge analog information infrastructure we have surrounding just one formof transport – motoring – could GIS today be on the cusp of ubiquity (Li and Maguire2003) that motoring was a century ago? Suppose all our wayﬁnding infrastructurefor all forms of transport (including pedestrian) and for all forms of informationwas digital and accessible through an electronic mobile device, and anytime we wantedinformation tailored to where we were and what we were doing, all we would haveto do would be to consult it. Suppose, further, that the in-built intelligence could tellus things we would like (or ought) to know even without being asked, just basedon who we are, where we are, where we’ve been, and what time of day it is. Couldwe then get through the day without GIS? Welcome to the brave new future oflocation-based services!In this chapter, I will set the context for the emergence of location-based services(LBS) as an application of GIS. LBS can then be deﬁned and placed alongside otherGIS-based technologies. I will be exploring some of the data implications of LBS,how LBS users are positioned so that the system knows where they are, and howqueries can be expedited. I then explore some applications of LBS and conclude by reading some of the signposts as to what lies on the road ahead. LBS is a newlyemerging technology, and as with most other technologies we cannot be sure whereit will lead us. All I can do here is reveal what is known, cut through the inevitablehype, and scan the horizon of our possible futures. But one thing is for sure, LBSTHO_C32  19/03/2007  11:24  Page 581 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f582ALLAN J. BRIMICOMBEis an application of exciting potential which integrates nearly all aspects of Geo-graphic Information Science (GISc) as presented in the other chapters of this book.Context: Technological ConvergenceWe live in a networked society founded upon modern information and commun-ication technologies (ICT) linking computers with computers, computers with individuals and between individuals on an unprecedented scale. For example, in 2003an average of 55 million text messages were sent every day from mobile phones inBritain. We appear to have reached the stage where our understanding of and inter-action with the real world is mediated through ICT and computers and any furtherevolution of our species may well be symbiotic with technology. According to Castells(1989, 1996), the ICT revolution of the late 1980s and 1990s has re-structured thematerial basis of society such that wealth creation is information-centered: informa-tion is both a raw material and an output of production as a tradable commodity.Technology time lines, such as those of the National Research Council (1997) andBrimicombe (2003), chart the pace of development. It is sobering to consider thatthe ﬁrst IBM PC was launched in 1982, mobile telephones came on the market in themid 1980s and the World Wide Web (WWW) was launched in 1990 – all of thesenow ubiquitous technologies and yet emergent within the lifetime of most readersof this chapter. In 2003, mobile phone subscribers will have topped one billionworld wide (IDC 2001), pushing ahead of the number of people with online Internetaccess (ComputerScope 2001). As a commodiﬁed product, information tends to have a time-bound currency, a sort of “use by date” beyond which its value or itsability to generate wealth or other utility dramatically declines. This can be bothin absolute terms (knowing when to buy or sell some shares on the basis of newinformation) or in relative/cyclic terms (knowing today’s menu at nearby restaurants).Thus the ability to access information at anytime, anywhere, and in any circumstanceis not only a desirable end for which organizations and individuals are willing topay but is now achievable. Fixed-line and wireless broadband offers to make usswitched-on and online permanently.That the technological innovations of the late twentieth century have changedforever the way people work, communicate, relax or otherwise live their lives isbeyond doubt. But this trajectory is far from ﬁnished. A wide and ever growing rangeof consumer products contain microprocessors. Whether it be a mobile phone, a DVDplayer or a car engine, there is likely to be a ﬂow of digital data and the running ofsoftware algorithms to make them work properly. In recent years, the convergenceand miniaturization of technologies has lead to signiﬁ",
    "chunk_order_index": 366,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-dfdcbfa58da2e51a9eec84a534774c2e": {
    "tokens": 1200,
    "content": "forever the way people work, communicate, relax or otherwise live their lives isbeyond doubt. But this trajectory is far from ﬁnished. A wide and ever growing rangeof consumer products contain microprocessors. Whether it be a mobile phone, a DVDplayer or a car engine, there is likely to be a ﬂow of digital data and the running ofsoftware algorithms to make them work properly. In recent years, the convergenceand miniaturization of technologies has lead to signiﬁcant blurring of the more traditional means of accessing electronically-stored information. Thus static devices(for example, the desktop PC) can be serviced by both ﬁxed-line and wireless net-works; wireless connectivity has released our ties to static devices for going onlinethus allowing greater mobility (for example, there are, at the time of writing, inexcess of 100 publicly accessible wireless hotspots in central London where laptop andhandheld computers can go online); the Internet is accessible from both static and mobile devices (for instance, mobile phones); some new models of mobile phonecontain most of the functionality of a personal digital assistant (PDA); PDAs canTHO_C32  19/03/2007  11:24  Page 582 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fLOCATION-BASED SERVICES AND GIS583dial-up for a data connection, and so on. A mobile phone is now a device for thetwo-way communication of voice, music, data, text, graphics, photos, and video.The increasing mobility of information-access technologies and their ability to belocation-aware, that is to be able to have their geographic position ﬁxed continu-ously and automatically, is giving rise to the possibility of customizing informationservices and their content based on the location of the recipient.Deﬁning Location-Based ServicesThe technological niche occupied by LBS is best discussed in relation to Figure 32.1where it falls at the intersection of GIS, the Internet, and new information and com-munication technologies (NICTs).NICTs are deﬁned here as small portable electronic devices that can be location-aware and incorporate wireless ICT. Examples of such devices would be mobilephones, in-vehicle navigation devices, PDAs, pocket and tablet PCs, certain typesof data loggers, and even laptop PCs, though these latter few devices would needthe appropriate peripherals to be location-aware and have wireless communicationin order to qualify. What is meant by location-awareness is further discussed belowunder the heading “Queries for LBS,” but put simply, it is the ability to know thegeographic location of a device (and hence its user) either through means internalto the device (such as integral GPS) or external to the device (such as interfacedGPS or wireless network triangulation).While the acronym GIS is commonly associated with the software tools for stor-ing, analyzing, and displaying spatial data (for example, ArcView, MapInfo), a broadersystems view would extend to the organizational and institutional arrangements thatsupport, for example, the collection of spatial data and dissemination of informa-tion products that are equally important as aspects of GIS. On the other hand, spatially-enabled databases such as Oracle Spatial that can be used for the storageand query of spatial data would not on their own be regarded as GIS. This raisesthe debate as to whether GIS as we currently know them really are at the heart ofGIS /Spatial DatabasesLBSInternetGISWirelessGISWirelessInternetInternetNICTsFig. 32.1The technological niche of LBSAfter Brimicombe 2002THO_C32  19/03/2007  11:24  Page 583 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f584ALLAN J. BRIMICOMBELBS, whether LBS can be adequately driven in the main by spatial databases orwhether new hybridized forms of GIS will evolve for LBS. There is insufﬁcient spacein this chapter to fully explore this debate (but see Brimicombe and Li 2007) thougha ﬂavor can be gained from the sections that follow.Wireless Internet refers to the ability of 2.5G and 3G mobile phones (and otherNICTs) to access web pages, email, and other Internet services through a wirelessconnection. The distinction between Internet GIS and wireless GIS is a ﬁne one,but one which is nevertheless made (see, for example, Braun 2003). The term InternetGIS as used here covers web-based and online GIS and refers to client-side accessto GIS hosted on a server where the access is facilitated via the Internet. Usuallythe client-side device (PC) is online with an interface to the server-side GIS througha web browser. In the case of mobile GIS, GIS software and data are resident client-side on a mobile device that can then be taken into the ﬁeld; examples areESRI’s ArcPad and MapInfo’s MapX Mobile which run on PDAs. However, dataare normally up- or down-loaded periodically on visiting an ofﬁce (or home) wherethe mobile device can be attached to the organization’s main network. Thus mobileGIS allow ﬁeld mobility but not real-time access to data and are increasingly usedfor",
    "chunk_order_index": 367,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-bdc77b8d0cd09a23efb0ca2c5935ae50": {
    "tokens": 1200,
    "content": "mobile GIS, GIS software and data are resident client-side on a mobile device that can then be taken into the ﬁeld; examples areESRI’s ArcPad and MapInfo’s MapX Mobile which run on PDAs. However, dataare normally up- or down-loaded periodically on visiting an ofﬁce (or home) wherethe mobile device can be attached to the organization’s main network. Thus mobileGIS allow ﬁeld mobility but not real-time access to data and are increasingly usedfor data collection. Wireless GIS are an extension of mobile GIS for which accessto an organization’s databases can be real-time via wireless telecommunications and/orlocal wireless networks. This means that current versions of a database can be accessedat all times as well as having updates initiated from the ﬁeld. Thus wireless GIShave tended to focus on business operations such as those concerning work ordersand inspections. With future increases in bandwidth and improved roaming ability,GIS and other software may become resident server-side with a browser interfaceclient-side thus blurring, though not completely dissolving, the current distinctionbetween Internet GIS and wireless GIS.With LBS at the intersection of what has been deﬁned above, they will includeaspects of all the technologies just discussed. LBS, however, are in the early stagesof development with current research establishing both the feasibility and the demand(Leonhardt, Magee, and Dias 1996, Laurini, Servigne, and Tanzi 2001, Sage 2001),and therefore any deﬁnition given to LBS at this time should not be taken as deﬁnitivebut as reﬂecting our current knowledge of their intended purpose. At their heart,then, location-based services are the delivery of data and information services wherethe content of those services is tailored to the current or some projected locationof the user. It is usually implied that the user is on the move and the delivery ofservices is to a NICT. The data or information delivered are not restricted to beingspatial but could be any information whether conveyed as text, voice, images, orindeed as maps. The important spatial component refers to the known or projectedlocation of the individual requesting the service. Thus, for example, a request byan individual for information might be “what are today’s opening hours for Marks& Spencer?” with the response giving today’s opening and closing times for thenearest branch of Marks & Spencer to where the individual is (as text or voice)accompanied perhaps by a map showing the location of the branch relative to theindividual. Requests for information can of course be spatial – “where can I ﬁnd...?, “how do I get to...?” – and it is therefore envisaged that major applica-tions of LBS will be in wayﬁnding and navigation, though by no means being restrictedTHO_C32  19/03/2007  11:24  Page 584 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fLOCATION-BASED SERVICES AND GIS585to these. An LBS experimental interface for wayﬁnding applications incorporatingvoice, text, and maps is given in Figure 32.2.With the deﬁnition for LBS comes its basic system architecture, which is discussedin relation to Figure 32.3. The system architecture has ﬁve broad components:•The real world in which the user is situated and about which information isrequired tailored to the user’s current or projected location;•The choice and nature of NICT employed by the user for receiving LBS;•The positioning systems, such as GPS, which geographically locate the NICT;•The wireless network through which the query and LBS response are commun-icated between NICT and server;•The GIS, database, and distributed services and data components, includingInternet connections to the World Wide Web, used to resolve the query andformat the response. The data used to resolve the query are, of course, derivedfrom the real world, thus implicitly closing the loop within the system.Fig. 32.2Experimental PDA interface for LBS that provides map, text and voice wayﬁndinginstructionsCopyright C. Li, used with permissionTHO_C32  19/03/2007  11:24  Page 585 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f586ALLAN J. BRIMICOMBEData ImplicationsData are key to any information service, but LBS have implications for data overand above that which is currently required for GIS (Tsou and Buttenﬁeld 2002,Grejner-Brzezinska, Li, Haala, and Toth 2004, Smith, Kealy, Mackaness, andWilliamson 2004). In this section three aspects in particular will be discussed: thedata themselves; their collection, and their organization. Data and information accessvia queries will be discussed in the section entitled “Applications” below.Demand for services inevitably depends on the utility that can be derived from theirpurchase. In the case of LBS, this will largely depend on the currency, granularity,and ﬁtness-for-purpose of the information provided for decision-making as well asresponse times and the comprehensibility of the products delivered. Bearing in",
    "chunk_order_index": 368,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-45e7974b34f47c63b419bb78fbd5a5b8": {
    "tokens": 1200,
    "content": "three aspects in particular will be discussed: thedata themselves; their collection, and their organization. Data and information accessvia queries will be discussed in the section entitled “Applications” below.Demand for services inevitably depends on the utility that can be derived from theirpurchase. In the case of LBS, this will largely depend on the currency, granularity,and ﬁtness-for-purpose of the information provided for decision-making as well asresponse times and the comprehensibility of the products delivered. Bearing in mindthe deﬁnition of LBS, requests for services are likely to be highly local in nature andtherefore data will need to be ﬁne-grained (high resolution) and up-to-date. Thiswill inevitably mean that data sets will grow dramatically as the granularity is increasedand as additional attributes are added. Consider, for example, the sizes of sometypical data sets for the UK given in Table 32.1. These are indicativenumbers ofrecords, not ﬁle sizes. For comparison, taking Greater London as an example, whilethe Ordnance Survey’s Code-Point for the 196,512 postcodes is 12 MB as a textPDAGPSwireless networkserver withGIS softwareservices and databasesInternet – WWWmobile phoneand/or?Fig. 32.3Basic system architecture for LBSTHO_C32  19/03/2007  11:24  Page 586 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fLOCATION-BASED SERVICES AND GIS587ﬁle, Address-Point for the 3.6 million addresses is 745 MB as a text ﬁle. LBS wouldrequire address-level data to be effective, particularly for urban applications. Theclasses of data that would be required for LBS would typically include: (1) base map-ping (particularly street and building level data); (2) points-of-interest (landmarks,destinations), services-of-interest (timetables, availability); (3) navigation informa-tion (intersections, signage); (4) real-time information (trafﬁc conditions, weatheradvisories/warnings); and (5) imagery (aerial, terrestrial, virtual).As can be seen from the example given in the previous paragraph, it is inevitablethat the move towards LBS and its need for high resolution data will result in substantial bulking of spatial databases. The classes of data (themes) accessible through LBS would need to be broadened beyond those of traditionally focusedGIS applications. The spatial coverage of data would need to be national, even inter-national. Many of the attributes of interest would not be resident in databases butwould come from web pages (similar to a Google or Yahoo search). This makes theintegration of data for LBS into a single database repository very unlikely. Indeed,LBS as a viable set of technologies is dependent upon the current trajectory towardsinteroperable, open systems software (for example, Buehler and McKee 1998), the use of distributed services and software components as facilitated by CORBA,Java, and .NET (Peng and Tsou 2003), and the use of distributed data objects (Tsou and Buttenﬁeld 2002) as an evolution of distributed databases in a networked environment. While some core data sets, such as road networks, may be kept cen-trally at the main server coordinating an LBS provider’s service, all other data willbe distributed over intranets and the Internet for which there will be protocols andagreements covering syndication, access, use, and charging. In such a distributedenvironment, with large and diverse data sets to consider in quickly resolving aninformation request, metadata play a key role (Flewelling and Egenhoffer 1999).These descriptions of the content and quality of data sets are necessary because ofthe impracticality of browsing through large and distributed data sets in order tocomprehend them. While metadata content standards exist (for example, FGDC1997) and form the basis for online data clearinghouses, such content advises ondata reliability at the point of purchase while providing only limited indication ofinformation potential when combined with other data sets in resolving a query to provide sufﬁcient utility or ﬁtness-for-use (Brimicombe 2003). LBS providers will need to compile (and continually update) metadata databases that reﬂect userTable 32.1Indicative size of some typical LBS data sets for the UK (2003)Data categoryIndicative size (approximate no. of records)Addresses24 millionPostcodes1.7 millionStreet gazetteer764,000 entries (Navtech)Financial & legal services190,000 banks, building societies, estate agents, etc.Hotel, restaurants, pubs162,000 locationsLocal services230,000 local service and retail companiesRecreation and culture87,000 locationsTHO_C32  19/03/2007  11:24  Page 587 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f588ALLAN J. BRIMICOMBEperspectives of information utility for a range of user contexts (for example, daytimeversus night-time) so as to automate rapid data selection and combination.Another implication of the LBS data",
    "chunk_order_index": 369,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-ea2897ac4c06125bddcfa91f08dd3823": {
    "tokens": 1200,
    "content": "Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f588ALLAN J. BRIMICOMBEperspectives of information utility for a range of user contexts (for example, daytimeversus night-time) so as to automate rapid data selection and combination.Another implication of the LBS data market will be the need for faster updatecycles and the means of achieving this. The currency of information is inevitably akey determinant of its utility. Fortunately, the bundle of technologies that are mak-ing LBS a reality are also making real-time data collection and update a reality.Beyond mobile and wireless GIS as technologies for efﬁcient ﬁeld data collection(in conjunction with GPS and remote sensing), there is the telemetry (by ﬁxed-lineor wireless links) of data collected at ﬁxed and mobile installations. Examples ofthese would include the automated collection and transmission to an operationscenter of meteorological data, trafﬁc data, river ﬂow, and water level, transport ofhazardous materials or the progress of a bus through a congested urban area. Laurini,Servigne, and Tanzi (2001) have classed this as TeleGeoInformation and noted thatit has both spatial and temporal components. Grejner-Brzezinska, Li, Haala, andToth (2004) consider that we are witnessing a paradigm shift in the acquisition,processing, and management of spatial data through a fusion of geoinformatics (geomatics), telecommunications, and mobile computing to produce an emergingdiscipline of telegeoinformatics (see also Karimi and Hammad 2004). The step changefrom traditional mapping will result in automatically extracted and integrated vector geometry and imagery that result in high resolution 3D data sets with shortupdate cycles. This will allow, for example, LBS users to access virtual urban modelsthat permit realistic visualization.Finally, the delivery of LBS to users can in itself be a means of data collection.The technology’s location awareness means that the user’s location can be tracked.This in itself may provide important contextual information that allow responsesto queries to be better personalized particularly if there is sufﬁcient user history toextract a personal proﬁle or if a proﬁle has been pre-customized by the user. Real-time feedback from users via their NICT on, say, the accuracy of information provided can be used as triggers for data update.Locating the UserKey to LBS is knowing the location of the user so as to appropriately tailor servicedelivery. Many queries will be based on the current location of the user which thenneeds to be determined. Within the deﬁnition of LBS, however, location may notnecessarily refer to the current geographical position of the user but may be someprojected (future) location of the user. This latter scenario may take two forms: a medium- to longer-term projected time and location supplied by the user (“Arethere any concerts in Edinburgh tonight?”) or a short-term projection based on current position and trajectory (vector of movement, such as moving at 100 kphalong a motorway). Again, in the latter example, current position of the user needsto be tracked. In this section we will consider global positioning system (GPS) andnetwork-based techniques of locating the user. For a fuller treatment of this topic,see Grejner-Brzezinska (2004) or Brimicombe and Li (2007).GPS consists of a constellation of 21 operational satellites (plus some spares) orbiting at an altitude of approximately 20,000 km. The ﬁrst was launched in 1978THO_C32  19/03/2007  11:24  Page 588 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fLOCATION-BASED SERVICES AND GIS589and there is a program of continual replenishment of the constellation as satellitesgo out of service. The important feature of the orbital conﬁguration is that ﬁve toeight satellites should always be visible from any point on the Earth. Each satelliteemits a time-coded signal which allows the receiver to work out the distance to the satellite. Because each satellite is of known position in its orbit, a minimum ofthree satellite signals is sufﬁcient for a receiver to calculate its co-ordinate positionand elevation on the Earth’s surface. Up until May 2, 2000, these signals were inten-tionally degraded by the US military using Selective Availability. Since SelectiveAvailability has now been switched off, a handheld GPS receiver (no bigger thana mobile phone) can achieve 2D accuracy of 3 to 5 m (see Chapter 28 by Dana inthis volume for additional information about GPS technologies). Although PDAscan be readily linked with GPS receivers, the actual chip that receives the signal andcarries out the calculations is now about the size of a postage stamp and can thus bereadily incorporated into a PDA or mobile phone at the point of manufacture. Thiswould seem ideal at not much extra cost in the hardware, but GPS has an importantdrawback: it only works when there is a clear view of the sky. In other words it willnot work indoors, in covered car parks, or in tunnels, and will work poorly if thereceiver is inside a car, train, woodland, or if it is in an “urban canyon” surroundedby high buildings. For this reason, service",
    "chunk_order_index": 370,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-b6bcda2e98ec3c7d6bb594f3c03f7437": {
    "tokens": 1200,
    "content": "into a PDA or mobile phone at the point of manufacture. Thiswould seem ideal at not much extra cost in the hardware, but GPS has an importantdrawback: it only works when there is a clear view of the sky. In other words it willnot work indoors, in covered car parks, or in tunnels, and will work poorly if thereceiver is inside a car, train, woodland, or if it is in an “urban canyon” surroundedby high buildings. For this reason, service providers have been looking at a rangeof alternative techniques based on the telecommunications network itself.In order to deliver services to mobile phones, providers (e.g. Orange, Vodaphone,Verizon) install a network of cellular base stations (transmitters and receivers) usu-ally country-wide in order to achieve a commercially viable coverage. When a mobilephone is switched on it is registered with the nearest base station (so the providerknows how to route a service to it). The area covered by a base station is called acell and each cell has an ID or cell global identity (CGI); as the user moves, so the registration is handed over to whichever cell becomes the nearest. Thus a provideralways knows where an in-range user is by the cell-ID holding the registration. In urban areas the size of a cell might have a radius of 100 m but in rural areasthis may increase to upwards of 30 km. While positioning by cell-ID is quick andinexpensive, it remains too coarse for most LBS. Cell-ID can be augmented by refer-ence to a mobile phone’s timing advance (TA) and the directional sector within acell from which the signal is received. Since it is common for a number of mobilephones to be using a cell simultaneously at the same wavelength, each base stationhas a system for scheduling the timing of transmission to each mobile phone sothey do not interfere with each other. Because distance will cause a delay in thetime taken to receive a transmission, each phone is instructed by the base stationto advance its transmission time so it arrives correctly for its scheduled time slot.This gives a rough measure of the distance a user is from a base station and canbe further augmented by the directional sector. While this provides useful sub-celllocation within large rural cells, its usefulness within small urban cells becomesmarginal. Although registration is with one cell at a time, a mobile phone will have some communication with all cells within range so that a smooth handoverof registration to any adjacent cell can be achieved. Using the time difference ofarrival (TDOA) of the signal at three or more base stations allows triangulation of the 2D position. For 3G networks in urban areas, this would give a theoreticalaccuracy of about 20 m provided the mobile phone is within range of three baseTHO_C32  19/03/2007  11:24  Page 589 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f590ALLAN J. BRIMICOMBEstations, which might not always be the case. While the discussion here on network-based positioning methods has been in the context of mobile phones, the same principles apply for any device on a wireless network.GPS and network-based methods both have their advantages and disadvant-ages and cannot be expected to work well in all situations. One longer-term hybridsolution is to couple the two by augmenting GPS with cell-ID and transmitted GPSsignals from network base stations to give a theoretical accuracy of 10 to 15 m(Bedford 2004).Queries for LBSHaving requested information from some automated system, we are usually impatientfor a response, more so if we are on the move and need to make decisions. As a rule,our patience tends to run out after about 10 seconds and this is taken as the upperlimit, for example, in designing web usability (Nielsen 2000). For a high speed pro-cessor 10 seconds is ample time to process millions of instructions, but for an LBSquery it is not very long at all. Principally, geographically-based queries take muchlonger to transact than queries on well-structured attributes. Other components thatintroduce time delay are: the initial transfer of the query from the user to the server,augmentation of the query with the speciﬁcity of the user’s location, parsing of thequery to identify/interpret which data sets are required to fulﬁll the query, the accesstime required for the server to obtain the distributed data components and any necessary software services, the formatting of the response (perhaps as a map visual-ization or as a table), and the ﬁnal transmission of the response to the user.The transmission time for substantial amounts of data as would be necessary, forexample, in responding to a query with colored vector maps capable of interroga-tion or 3D virtual reality models, is being taken care of by advances in cellular network technologies. Current Global System for Mobile Communications (GSM)technology (2-G) would be “painfully slow” at 10 kbps (Peng and Tsou 2003, p. 458) while General Packet Radio Services (GPRS) (2.5-G) has a maximum dataspeed of 115 kbps. The projection for 3-G technologies when fully implemented willbe 2 Mbps which is equivalent to ISDN lines. More than ample for any currentlyconceived LBS application will be 4-G, scheduled for around 2010 with a trans-mission rate of up to 100 Mbps. For a complete description of",
    "chunk_order_index": 371,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-3989c00b3bc6440ae9dd013820ac0c2e": {
    "tokens": 1200,
    "content": "ou 2003, p. 458) while General Packet Radio Services (GPRS) (2.5-G) has a maximum dataspeed of 115 kbps. The projection for 3-G technologies when fully implemented willbe 2 Mbps which is equivalent to ISDN lines. More than ample for any currentlyconceived LBS application will be 4-G, scheduled for around 2010 with a trans-mission rate of up to 100 Mbps. For a complete description of these technologies,see Peng and Tsou (2003).Query augmentation is going to be an important element of LBS and is deﬁnedas the increase in speciﬁcity of a natural language query on the basis of additionalknown parameters and contextual information pertaining to the user who gener-ated the query. If, for example, we return to the query “what are today’s openinghours for Marks & Spencer?” this would need to be augmented with today’s date(today could be a Sunday, a public holiday, or a day on which there are extendedopening hours in the run-up to Christmas) and for the response to be tailored geo-graphically, the query would need to be augmented automatically with the user’slocation (whether GPS-derived co-ordinates, cell ID, and so on). Furthermore, ifby tracking the user’s location it is evident that the user is moving along a railwayline, then context would suggest the query did not pertain to the Marks & SpencerTHO_C32  19/03/2007  11:24  Page 590 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fLOCATION-BASED SERVICES AND GIS591nearest to the user’s current location and the server would need to clarify this with the user and appropriately augment the query on the basis of the response.Furthermore, suppose, for example, there was an archived request concerned withrail timetables and the purchase of a ticket and seat reservation for today’s date,then the query might be automatically augmented with the user’s destination. Theaugmented natural language query will then need to be translated into a formalquery language that instructs a Database Management System (DBMS) on how toresolve the query and parsed to identify which data sets are required. Traditionally,GIS queries are constructed ab initiousing formal language (such as SQL) or throughthe intermediary of a user interface that structures the query. Such formalisms directly(and exactly) specify the data sets (or GIS coverages) to be used (see Chapter 7 byShekhar and Vatsavai in this volume for more information about database queries).Progress towards natural language queries in GIS is summarized by Wang (2003).Most natural language queries are fuzzy in nature – terms such as “near” or “onthe way to” are vague – and will either need to be translated into the existing pre-cise formalisms (for example, Wang 2003) or both the ambiguity of the query andthe data sets need to be captured and resolved within the formalism of the querylanguage and the spatial data structures on which they operate (see, for example,Brimicombe 1997, 1998). In parsing the query, use would have to be made of themetadata databases discussed above under the heading “Data Implications” in orderto select relevant data sets, but recourse to Internet search engines and on-the-ﬂydata mining may also be needed.GIS-based queries of spatial relations are traditionally based on the topology of static objects. A body of GIS research has focused on deﬁning and providing amathematical framework of 2D topological relationships (for example, Egenhoferand Herring 1990, Mark and Egenhofer 1994). For a pair of region objects in 2Dspace there are eight basic spatial relations (separate, meets, partial overlap, covers,is covered by, is inside, contains, equal overlap) while for a linear object and a regionobject there are 19 basic spatial relations. When looking at temporal relationshipsbetween objects, such as “αhappens before β” or “αhappens at the same time asβ,” there are 13 basic topological relations (Peuquet 1999). But again, these arefor temporally static objects. In LBS the problem is made more complex in that theuser may not be static but dynamic. The nearest commercial GIS come to perform-ing queries concerning dynamic objects is in resolving shortest path (or some other criteria) along a network. GIS queries will need to resolve new dynamic relationssuch as “α[dynamic] approaches β[static]” or “α[dynamic] and β[dynamic] con-verge.” Theodoridis (2003) has recently devised a set of ten benchmark databasequeries for LBS with relations based on co-ordinates, distance, direction, nearest-neighbor, topology (including network), and buffer. Queries for LBS will continueto be an important research area.ApplicationsTrue applications of LBS are at an early stage and it is inevitable that the emergenceof any new technology is accompanied by considerable hype as providers attempt toattract customers and carve out a market share. With rapidly growing numbers ofTHO_C32  19/03/2007  11:24  Page 591 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley",
    "chunk_order_index": 372,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-63dc9d62bb0c3de3749ce18dba235ee6": {
    "tokens": 1200,
    "content": "inevitable that the emergenceof any new technology is accompanied by considerable hype as providers attempt toattract customers and carve out a market share. With rapidly growing numbers ofTHO_C32  19/03/2007  11:24  Page 591 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f592ALLAN J. BRIMICOMBEindividuals using NICTs – already in excess of one billion – the market is potentiallybig business. Growth in LBS is, however, very much dependent on the roll out of3G technologies which, to date, have been slow to materialize. Applications arelikely to be as varied as any other technology that is ﬂexible, scalable, and has wideappeal. There are a number of ways we could classify these applications. One is todifferentiate “pull,” that is user-initiated, from “push” which would be provider-initiated. An example of a pull application would be a request for trafﬁc information.A push application might be the automatic broadcast of a relevant warning (forexample, burst water main causing road closure and/or cut-off of water supply) oronline advertising of “specials” and discounts as one comes into range of the relevantoutlet. Whether we are ready to cope with what might be a ﬂood of pushed onlineadvertising segmented and differentiated by the geo-demographics of our home post-code is another matter! Another way to classify LBS applications is by broad areasof activity regardless of “push” or “pull.” Thus, the presently envisaged areas ofactivity likely to take advantage of LBS for some, if not all, of the time are:•Navigation, such as in-car navigation systems, which identify appropriate routesfor a vehicle to be driven from some start point to a destination (or series ofdestinations);•Wayﬁnding, which is the discovery of routes, modes of transport, and other spatially located objects by an individual on the move. The distinction between navigation and wayﬁnding varies between disciplines;•Mobile commerce (m-commerce), which would incorporate both transactionsmade by individuals on the move via their NICT or the receiving of intelligence(advertising, marketing materials) of opportunities for transactions that are loca-tion speciﬁc;•Real-time tracking of vehicle ﬂeets, business associates, social contacts (to knowwhen a friend is nearby) or one’s family members (such as tracking childrenhome from school by parents who are at work);•User-solicited information for all kinds of business and social purposes such asweather forecast, trafﬁc conditions, delays to trains and ﬂights, ﬁlm showingsand ticket availability, menus, local maps, and so on;•Location-based tariffs such as differentials in road pricing, pay-as-you-go carinsurance, and similar schemes;•Fulﬁllment of ﬁeld-based work orders including deliveries, inspections, and datacollection;•Coordinating emergency and maintenance responses to accidents, interruptionsof essential services and disasters;•Artistic expression in the community.Given the pace of development, this list should not be taken as exhaustive. Some of these may sound far-fetched, but they are based on services that are eitherunder development or are offered now. For example, Japanese parents are alreadyable to track their kids traveling home after school through the cell ID of children’smobile phones. In the UK, Vodaphone has started allowing third parties to offerLBS over its network. At present these are driven by text keywords sent using ashort-code service with replies by a Short message service (SMS). Thus “club” sentTHO_C32  19/03/2007  11:24  Page 592 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fLOCATION-BASED SERVICES AND GIS593to 80400 will return the address of the nearest club frequented by celebrities. In Germany, the city of Darmstadt offers a more sophisticated service: Da-Mobil(Janosch 2003). Through a wireless Local area network (LAN), enabled PDAs candownload route maps providing navigation information, video, 3D visualizationsand web pages on surrounding points of interest. Interactive in-car navigation sys-tems are already a standard feature in luxury cars and a not so expensive optionalextra available for all vehicles. In Times Square, passers-by can engage in a Yahoocellphone game displayed on a building facade. Norwich Union, one of the UK’slargest insurance companies, is collaborating with network provider Orange to developa pay-as-you-go car insurance scheme so that premiums would be based on when,where, and how often a vehicle is used. The Urban Tapestries project (Lane 2003,http://research.urbantapestries.net) has conducted experiments in Bloomsbury,London, whereby individuals using wireless-enabled PDAs can create or follow virtual threads (annotated with text, sound, and images) which link individual experience and contexts to local features as a means of social and artistic expres-sion. Perhaps the most bizarre application of LBS to date is a GPS-enabled phonestrapped to hunting dogs in Finland so that the dogs can be tracked. The ownercan tell what type of animal the",
    "chunk_order_index": 373,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4d69e15c5b43d7664551a339bdf45cde": {
    "tokens": 1200,
    "content": ".urbantapestries.net) has conducted experiments in Bloomsbury,London, whereby individuals using wireless-enabled PDAs can create or follow virtual threads (annotated with text, sound, and images) which link individual experience and contexts to local features as a means of social and artistic expres-sion. Perhaps the most bizarre application of LBS to date is a GPS-enabled phonestrapped to hunting dogs in Finland so that the dogs can be tracked. The ownercan tell what type of animal the dog is hunting from the dog’s bark and the ownercan relay orders to the dog. Not so much wayﬁnding as woof-ﬁnding!Numerous applications for mobile devices are in various stages of development,offering different degrees of sophistication depending on the nature of the expecteduser and the class of NICT available to them. The next ﬁve to ten years will seean exponential expansion in the numbers of services offered, some free others tobe paid for. Their common characteristic is that they are location-speciﬁc, tailoredto where one is. These are location-based services.Only the BeginningThis chapter has focused on a number of key technological aspects of LBS. Manyof these depart from the usual discussions of GISc, and indeed GISc per sehas notfeatured prominently. GIS as technology or toolbox was around for nearly 30 yearsbefore debates around the scientiﬁc foundation for such a substantive technologyarose (see Goodchild 1992 for details). It was not until 1997, for example, thatone of the leading research journals in the ﬁeld changed its name from the Inter-national Journal of Geographical Information Systemsto the International Journalof Geographical Information Science.Now we are reaching an important new phase:if science is about discovering new knowledge and making it available to society,engineering is the systematic and reliable application of that knowledge in society.At the heart of LBS is geographic location; at the heart of LBS technology is theapplication of most aspects of GISc for managing, processing, and delivering spatial information. LBS is therefore a prime example of an emerging ﬁeld of endeavorwhich we can label: geo-information engineering. Like most engineered products,as lay users we are mostly unaware of the detailed scientiﬁc foundations. Thus weuse bridges, lifts, and home appliances in the belief that they are safe and withouta detailed knowledge of their engineering. The challenge for GIS is for ubiquitousapplications, such as LBS, to emerge without users being particularly aware thatTHO_C32  19/03/2007  11:24  Page 593 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f594ALLAN J. BRIMICOMBEthey are engaging with GISc, that GISc can be a foundation science and technologyin everyday engineered products. That the public can engage with GISc withoutreally knowing it will mean the difference between GIS remaining a niche technologyand emerging as a quotidian technology. I’m conﬁdent that the GISc community canrise to the challenge.We should, however, end on a cautionary note. Tenner’s (1997) revenge theoryof technological innovation means that new technologies never ultimately solve theproblem for which they were designed without creating new ones along the way.What is more, the new problems tend to be shifted in space and time becoming morehidden and therefore dangerous. But these are also opportunities for researchersand providers of LBS alike. As with other forms of engineering, new applications canchallenge or question the science and any outstanding problems and failures mustbe carefully analyzed for new knowledge that is then fed back into research. Weare, however, only at the beginning of LBS; a rich journey lies ahead.REFERENCESBedford, M. 2004. Are you ready for the ride? GEOconnexionUK3: 50–1.Braun, P. 2003. Primer on Wireless GIS.Park Ridge, IL: Urban and Regional InformationSystems Association.Brimicombe, A. J. 1997. A universal translator of linguistic hedges for the handling of uncertainty and ﬁtness-for-use in Geographical Information Systems. In Z. Kemp (ed.)Innovations in GIS 4.London: Taylor and Francis, pp. 115–26.Brimicombe, A. J. 1998. A fuzzy co-ordinate system for locational uncertainty in space andtime. In S. Carver (ed.) Innovations in GIS 5.London: Taylor and Francis, pp. 143–52.Brimicombe, A. J. 2002. GIS: Where are the frontiers now?In Proceedings of GIS 2002,Manama, Bahrain, pp. 33–45.Brimicombe, A. J. 2003. GIS, Environmental Modelling and Engineering. London: Taylorand Francis.Brimicombe, A. J. and Li, C. 2007. Location-Based Services and Geo-Information Engineering.Chichester: John Wiley and Sons.Buehler, K. and McKee, L. 1998. The Open GIS Guide: Introduction to InteroperableGeoprocessing and Open GIS Speciﬁcation.Wayland, MA: Open GIS Consortium Inc.Castells, M. 1989. The Informational City: Information Technology, Economic Restructuringand the Urban-regional Process. Oxford: Blackwell.Castells, M. 1996. The Information Age: Economy, Society and Culture: Volume 1, TheRise of the Network Society. Oxford: Blackwell.Com",
    "chunk_order_index": 374,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-38e3d1e3f9eae72325c160ecf91532c5": {
    "tokens": 1200,
    "content": "8. The Open GIS Guide: Introduction to InteroperableGeoprocessing and Open GIS Speciﬁcation.Wayland, MA: Open GIS Consortium Inc.Castells, M. 1989. The Informational City: Information Technology, Economic Restructuringand the Urban-regional Process. Oxford: Blackwell.Castells, M. 1996. The Information Age: Economy, Society and Culture: Volume 1, TheRise of the Network Society. Oxford: Blackwell.ComputerScope. 2001. How Many Online?Dublin: ComputerScope Ltd.Egenhofer, M. J. and Herring, J. R. 1990. A mathematical framework for the deﬁnition of topological relationships. In Proceedings of the Fourth International Symposium on SpatialData Handling, Zurich, Switzerland. Columbus, OH: International Geographical Union,pp. 803–13.FGDC. 1997. Content Standard for Digital Geospatial Metadata.Washington, DC: FederalGeographic Data Committee.Flewelling, D. M. and Egenhofer, M. J. 1999. Using digital spatial archives effectively.International Journal of Geographical Information Science13: 1–8.Goodchild. M. F. 1992. Geographical information science. International Journal of Geo-graphical Information Systems6: 31–45.THO_C32  19/03/2007  11:24  Page 594 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fLOCATION-BASED SERVICES AND GIS595Grejner-Brzezinska, D. A. 2004. Positioning and tracking approaches and technologies. InH. A. Karimi and H. Hammad (eds) Telegeoinformatics: Location-Based Computing andServices.Boca Raton, FL: CRC Press, pp. 69–110.Grejner-Brzezinska, D. A., Li, R., Haala, N., and Toth, C. 2004. From mobile mapping totelegeoinformatics: Paradigm shift in geospatial data acquisition, processing and manage-ment. Photogrammetric Engineering and Remote Sensing70: 197–210.IDC. 2001. Erratic Signals: Worldwide Handset Market Forecast and Analysis, 2000–2005.Framington, MA: International Data Group.Jasnoch, U. 2003. GIS-based location services: A new service for the City of Darmasdt.GeoInformatica6: 24–5.Karimi, H. A. and Hammad, H. 2004. Telegeoinformatics: Location-Based Computing andServices.Boca Raton, FL: CRC Press.Lane, G. 2003. Urban Tapestries: Wireless Networking, Public Authoring and Social Know-ledge. WWW document, http://www.probiscus.org.uk/urbantapestries/Unis_WW_paper.html.Laurini, R., Servigne, S., and Tanzi, T. 2001. A primer on TeleGeoProcessing and TeleGeo-Monitoring. Computers,Environment and Urban Systems25: 248–65.Leonhardt, U., Magee, J., and Dias, P. 1996. Location service in mobile computing environ-ments. Computers and Graphics20: 627–32.Li, C. and Maguire, D. 2003. The handheld revolution: Towards ubiquitous GIS. In P. A. Longleyand M. Batty (eds) Advanced Spatial Analysis.Redlands, CA: ESRI Press, pp. 93–210.Mark, D. M. and Egenhofer, M. J. 1994. Modeling spatial relations between lines and regions:Combining formal mathematical models and human subjects testing. Cartography andGeographic Information Systems21: 95–212.National Research Council. 1997. The Future of Spatial Data and Society.Washington, DC:National Academy Press.Nielsen, J. 2000. Designing Web Usability. Indianapolis, IN: New Riders.Peng, Z. R. and Tsou, M. H. 2003. Internet GIS: Distributed Geographic Information Servicesfor the Internet and Wireless Networks. Hoboken, NJ: John Wiley and Sons.Peuquet, D. J. 1999. Time in GIS and geographical databases. In P. A. Longley, M. F.Goodchild, D. Maguire, and D. W. Rhind (eds) Geographical Information Systems:Principles and Technical Issues.New York: John Wiley and Sons, pp. 91–103.Sage, A. 2001. Future positioning technologies and their application to the automotive sector. Journal of Navigation54: 321–8.Smith, J., Kealy, A., Mackaness, W., and Williamson, I. 2004. Spatial data infrastructurerequirements for location based journey planning. Transactions in GIS8: 23–44.Tenner, E. 1997. Why Things Bite Back: Technology and the Revenge of Unintended Con-sequences. New York: Vintage Books.Theodoridis, Y. 2003. Ten benchmark database queries for location-based services. ComputerJournal46: 713–25.Tsou, M. H. and Buttenﬁeld, B. P. 2002. A dynamic architecture for distributed geographicinformation services. Transactions in GIS6: 355–81.Wang,",
    "chunk_order_index": 375,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-e9af6407ad57f3d6b3c4916b5640f45a": {
    "tokens": 1200,
    "content": "enner, E. 1997. Why Things Bite Back: Technology and the Revenge of Unintended Con-sequences. New York: Vintage Books.Theodoridis, Y. 2003. Ten benchmark database queries for location-based services. ComputerJournal46: 713–25.Tsou, M. H. and Buttenﬁeld, B. P. 2002. A dynamic architecture for distributed geographicinformation services. Transactions in GIS6: 355–81.Wang, F. 2003. Handling grammatical errors, ambiguity and impreciseness in natural lan-guage queries. Transactions in GIS7: 103–21.THO_C32  19/03/2007  11:24  Page 595 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 33Geographic Information Science: The Grand ChallengesMichael F. GoodchildMany chapters in this book have touched on aspects of the research agenda – theresearch questions that arise in the mind of a user of Geographic Information Systems(GIS); the research problems that need to be solved to enable the next generationof GIS technology; in essence the science behind the systems. Since 1992 there havebeen various broader efforts to deﬁne a more-or-less-complete agenda for Geo-graphic Information Science (GISc), and many of them have been framed in termsof challenges to the research community. More broadly still, many ﬁelds of sciencehave attempted to provide long-term motivation – and not incidentally to open sourcesof funding – by identifying grand challenges, themes that are capable of direct-ing research to a common, distant, but imaginable end. President John F.Kennedy’s famous challenge of 1960 – to “put a man on the Moon by the end ofthis decade” – resulted in an unprecedented peacetime integration of science, engineering, political support, and, of course, a successful ending. In a somewhatsimilar vein biologists have been calling for the completion of “the web of life,”the identiﬁcation of all of the species (only a fraction of which are currently knownto science; May 1988). The mapping of the human genome is a similarly integratedeffort across a multitude of laboratories and institutions, tied together by computernetworks. Could there be a grand challenge in GISc that could drive a decade-longeffort by the research community?In the ﬁrst part of the chapter I review the various published research agendas ofGISc. I then discuss a further type of challenge: the need to understand the natureof the geographic world. The third major section examines broader themes withinscience, and the degree to which they might translate into research challenges forGISc and institutional challenges for the GISc community. The ﬁnal major sectiondiscusses the concept of Digital Earth as a grand challenge for GISc.THO_C33  19/03/2007  11:23  Page 596 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: THE GRAND CHALLENGES597The Research Agendas of GIScThe late 1980sIt seems appropriate to begin this review in the late 1980s, because several eventsat that time helped to dramatically alter the landscape of the mapping sciences. Inthe UK, the Department of the Environment’s Committee of Enquiry into the Handlingof Geographic Information (the Chorley Committee; Department of the Environ-ment 1987) saw three speciﬁc stimuli: the rapidly falling costs of hardware, whichhad reduced the cost of entry into GIS and related activities from US$500,000 at the beginning of the decade to US$10,000 at the end; the advent of COTS (commercial, off-the-shelf) software to perform the basic operations of GIS; andrapid growth in the availability of spatially referenced digital data. In the USA, theNational Science Foundation announced a competition for a National Center forGeographic Information and Analysis (NCGIA), to advance the theory and methodsof GIS, to promote the use of GIS across the sciences, and to increase the nation’ssupply of experts in GIS.Rhind (1988) presented a research agenda for GIS, identifying problems in what he termed the handling of geographic data: the volumes of data involved, thenumerous types of queries that might be addressed, the prevalence of uncertaintyin geographic data; the need for integration of data among organizations; and thelack of awareness of such issues as scale. He recognized that the solution of themore generic of these issues would come with time from mainstream informationtechnology; but that issues that were more speciﬁc to the geographic case wouldhave to be solved by an active research community focused on GIS. He saw a sub-stantial role for knowledge-based or expert systems in the automated extraction of features from images, the integration of disparate data sets, the development ofintelligent search procedures, the automation of cartographic generalization, the development of machine-based tutors, and the elicitation of knowledge from data.He also recognized the importance of research into better methods of visualizationfor geospatial data, the role of organizations, the legal issues of liability and intel-lectual property, and the costs and beneﬁts of",
    "chunk_order_index": 376,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-df0e5ddc4ca112dd54f19e6c5e998501": {
    "tokens": 1200,
    "content": "sub-stantial role for knowledge-based or expert systems in the automated extraction of features from images, the integration of disparate data sets, the development ofintelligent search procedures, the automation of cartographic generalization, the development of machine-based tutors, and the elicitation of knowledge from data.He also recognized the importance of research into better methods of visualizationfor geospatial data, the role of organizations, the legal issues of liability and intel-lectual property, and the costs and beneﬁts of GIS.The NCGIA research agenda (NCGIA 1989) has much in common with Rhind’s,but already shows signs of a search for the more fundamental issues of GISc, incontrast to the practical issues of GIS. Five major research areas are identiﬁed:•Spatial analysis and spatial statistics, the techniques used to model uncertaintyin geospatial data, to mine data for patterns and anomalies, and to test theoriesby comparison with reality;•Spatial relationships and database structures, addressing the representation ofreal geographic phenomena in digital form, and the interface between digitalstructures and human reasoning;•Artiﬁcial intelligence and expert systems,reﬂecting Rhind’s concern for the roleof advanced machine intelligence in GIS operations;•Visualization,and the need to advance traditional cartography to reﬂect the vastlygreater potential of digital systems for display of geographic data;THO_C33  19/03/2007  11:23  Page 597 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f598MICHAEL F. GOODCHILD•Social, economic, and institutional issues, the host of social issues surroundingGIS.The NCGIA went on to propose 12 speciﬁc research initiatives within this generalframework:•Accuracy of spatial databases,focusing on error models for geographic data withstrong links to the discipline of statistics;•Languages of spatial relations, including principles of spatial cognition and linguistics;•Multiple representations, the need to integrate representations of the Earth’s surface at different scales and levels of generalization;•Use and value of geographic information in decision making;•Architecture of very large GIS databases;•Spatial decision support systems,the design of systems to support decision-making by groups of stakeholders;•Visualization of the quality of geographic informationthrough methods that explicitly display information about the uncertainty associated with data;•Expert systems for cartographic design,using intelligent systems to augment theskill of cartographers;•Institutions sharing geographic information,including research on the impedi-ments to sharing between agencies;•Temporal relations in GIS,the extension of GIS data models to include time;•Space-time statistical models in GIS, the extension of spatial analysis to includetime;•Remote sensing and GIS, researching the issues involved in the integration ofdata acquired by remote sensing with data from other sources.Eventually, NCGIA sponsored a total of 21 research initiatives between 1988 and1996; reports, papers, and other products are available at http://www.ncgia.org.The 1990sVery substantial progress was made on most of these topics in the years followingtheir publication. In addition, four factors contributed to the evolution of these researchagendas in the 1990s: (1) the continued arrival of new technologies, including mostnotably the WWW, the Global Positioning System, object-orientation, and mobilecomputing; (2) the broadening of the research community to include active participa-tion by new disciplines, notably cognitive science, computer science, and statistics;(3) the trend away from technical issues of systems to fundamental issues of science;and (4) the recognition that certain topics were, in effect, dead ends. This last factorperhaps accounts for the virtual disappearance of expert systems, despite their pro-minence in Rhind’s 1988 agenda.In 1996 the recently formed University Consortium for Geographic InformationScience (http://www.ucgis.org) published the ﬁrst edition of its research agenda (UCGIS 1996), the result of a successful consensus-building exercise amongst theTHO_C33  19/03/2007  11:23  Page 598 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: THE GRAND CHALLENGES59930 or so research institutions that were then members (the number has since risento more than 60). The agenda had 10 topics:•Spatial data acquisition and integration, including new sources of remote sensing,ground-based sensor networks, and fusion and conﬂation of data from differentsources;•Distributed computingand the issues of integrating data and software over largeheterogeneous networks;•Extensions to geographic representations, addressing particularly the third spatial dimension and time;•Cognition of geographic information, including studies of the processes by whichpeople learn and reason with geographic data, and interact with GIS;•Interoperability of geographic information, including research to overcome thedifﬁculties of different formats and lack of shared understanding of meaning;•Scaleand the complex issues surrounding representations at different levels ofdetail;•Spatial analysis in a GIS environment, advancing the analytic capabilities of GIS;•The future of the spatial information infrastructureand the institutionalarrangements that provide the context for GIS;•Uncertainty in geographic data and GIS-based analysisincluding the",
    "chunk_order_index": 377,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-1299080ec56a85c9c10de8c821141843": {
    "tokens": 1200,
    "content": "and reason with geographic data, and interact with GIS;•Interoperability of geographic information, including research to overcome thedifﬁculties of different formats and lack of shared understanding of meaning;•Scaleand the complex issues surrounding representations at different levels ofdetail;•Spatial analysis in a GIS environment, advancing the analytic capabilities of GIS;•The future of the spatial information infrastructureand the institutionalarrangements that provide the context for GIS;•Uncertainty in geographic data and GIS-based analysisincluding the modelingand visualization of data quality;•GIS and society, the study of the impacts of GIS on society, and the societalcontext in which the technology is used.UCGIS later added four emerging themes to the list:•Geospatial data mining and knowledge discovery, the development of methodsfor extracting patterns and knowledge from very large data sources;•Ontological foundations of geographic information science, addressing the fundamental components on which our knowledge of the Earth’s surface is based;•Geographic visualization;•Remotely acquired data and information in GI Science.The UCGIS completely revised this list in 2002, replacing it with lists of long-termresearch challenges and short-term research priorities.The theme of visualization has been taken up and developed by the Interna-tional Cartographic Association’s (ICA’s) Commission on Visualization and VirtualEnvironments. The four-part research agenda (MacEachren and Kraak 2001)includes:•Cognitive and usability issues in geovisualization;•Representation and its relationship with cartographic visualization;•The integration of geographic visualization with knowledge discovery in data-bases and geocomputation;•User interface issues for spatial information visualization.THO_C33  19/03/2007  11:23  Page 599 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f600MICHAEL F. GOODCHILDMore generally, the list of commissions of the ICA reﬂects the broad interests ofthe association, including many research topics.The International Society for Photogrammetry and Remote Sensing also pro-vides a useful insight into contemporary research needs, with particular emphasison imaging systems. Its seven permanent commissions address:•Sensors, platforms, and imagery;•Systems for data processing, analysis, and representation;•Theory and algorithms;•Spatial information systems and digital mapping;•Close-range vision techniques;•Education and communications;•Resource and environmental monitoring.In 1998, NSF sponsored a workshop under its Digital Government Initiative toexplore ways of improving geographic information services (National Computa-tional Science Alliance 1999). The workshop made 10 recommendations, all aimedat advancing GISc research:•Advance research efforts directed toward the study of optimizing geographic querymechanisms and incorporating geometry and spatial relational operations;•Develop improved mechanisms for storing and representing time-varying geo-spatial data;•Support research on integrating spatial data fusion from multiple agencies, dis-tributed data, and multiple collection devices;•Support research on multiple representations/interfaces focused on task-speciﬁc(procedural) workﬂow classes;•Support research in developing algorithms for knowledge discovery applied tovery large, frequently updated spatial data sets such as those derived from space-borne Earth-monitoring sensors;•Support research in the theory and methods of representing data with varyingdegrees of exactness and reliability;•Support research in the context of decision-making to improve the representa-tion of diverse data and the dynamics of geographic phenomena;•Extend the promise of cognitive research to make geographic information techno-logies more accessible to inexperienced and disadvantaged users and also examinehow government information policies affect access to and use of geospatial datafor a broad spectrum of public and private sector stakeholders;•Support research to examine commerce’s issues in geospatial information suchas preserving privacy despite geographic locators and breaking potential bottle-necks in distributing geographic information services due to GIS’s uniqueworkﬂow processes;•Develop a Geospatial Digital Government Prototyping Center to create a networkfor testing and developing processes consistent with US priorities for geographicinformation technologies and services in the government workplace.THO_C33  19/03/2007  11:23  Page 600 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: THE GRAND CHALLENGES601More recently, the Center for Mapping of The Ohio State University organizeda 2002 workshop on Geographic Information Science and Technology (GIS&T) ina Changing Society. The perspective of the workshop was notably toward societalissues, and it identiﬁed six research areas:•Geospatial data availability: its sources and inﬂuences;•GIS&T workforce studies;•Conditions associated with the adoption of GIS&T-based approaches;•Spatial understandings, or the cognitive ability of people to work with spatialdata;•Cross and longitudinal studies of the use of GIS&T;•Improved tools for the societal evaluation of GIS&T activities.Finally, the National Research Council’s Computer Science and TelecommunicationsBoard reported in 2003 on a study of research needs at the intersection of GIScand computer science (NRC 2003). It identiﬁed two over-arching themes: the needfor an integrative, multidisciplinary approach to research, and the need to addressissues of policy. Within this context, it",
    "chunk_order_index": 378,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-a74022caa3290bd7808cf35db4cbf905": {
    "tokens": 1200,
    "content": "•Cross and longitudinal studies of the use of GIS&T;•Improved tools for the societal evaluation of GIS&T activities.Finally, the National Research Council’s Computer Science and TelecommunicationsBoard reported in 2003 on a study of research needs at the intersection of GIScand computer science (NRC 2003). It identiﬁed two over-arching themes: the needfor an integrative, multidisciplinary approach to research, and the need to addressissues of policy. Within this context, it proposed eight research topics:•Accessible location-sensing infrastructure, based on systems that know their location;•Mobile environments, freeing users from the desktop;•Geospatial data models and algorithms;•Geospatial ontologies;•Geospatial data mining;•Geospatial interaction technologies;•Geospatial for everyone, everywhere;•Collaborative interactions with geoinformation.Towards SynthesisAlthough each of these studies and reports contains an extensive list of topics, several common themes are apparent, as well as several consistent trends throughtime. Mark (2003) has analyzed several of the lists, including the topics includedin my 1992 paper in which I proposed the term “geographic information science”(Goodchild 1992).A somewhat different approach to framing the research agenda was taken byNCGIA’s Project Varenius, a research effort begun in 1996 to advance the funda-mentals of GISc, with funding from the National Science Foundation (Good-child, Egenhofer, Kemp, Mark, and Sheppard 1999, Mark, Freksa, Hirtle, Lloyd,and Tversky 1999, Egenhofer, Glasgow, Günther, Herring, and Peuquet 1999,Sheppard, Couclelis, Graham, Harrington, and Onsrud 1999). In this strikingly simple model, GISc was anchored by three concepts – the individual, the computer,and society – represented by a triangle, with GISc at the core. Research about theindividual would be dominated by cognitive science, and its concern for understandingTHO_C33  19/03/2007  11:23  Page 601 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f602MICHAEL F. GOODCHILDof spatial concepts, learning and reasoning about geographic data, and interactionwith the computer. Research about the computer would be dominated by issues ofrepresentation, the adaptation of new technologies, computation, and visualization.Finally, research about society would address issues of impacts and societal con-text. Many research issues would involve the interaction between the three cornersof the triangle.A Natural Science?It will be clear from the previous section that the research agenda of GISc is diverse,covering issues of technology, society, and human cognition. This section introducesa fourth, which as been largely neglected to date – the dependence of GISc on anunderstanding of the nature of the Earth’s surface.Many decisions are made in the design of a GIS, and more generally the designof any technology that must process geographic information. They include decisionsabout data models, data structures, indexing schemes, and algorithms – and aboutthe set of analytic routines and processing functions. Many of these decisions are,in turn, dependent on expectations about the nature of geographic information. Forexample, a decision to represent rivers as polylines (sequences of points connectedby straight segments) is a compromise, balancing the disadvantages of representinga smoothly bending river with a series of straight lines and sharp corners againstthe advantages of using such a simple geometry (intersections between straight linesare much easier to compute than intersections between curves). Yet, while thereclearly are expectations about the nature of geographic information, very few attemptshave been made to research the topic systematically, or to assemble what is knownin coherent fashion.The best-known statement is probably Tobler’s, generally known as the First Law of Geography: “all things are related, but nearby things are more related thandistant things.” This ﬁrst appeared in a paper on urban growth in Detroit (Tobler1970), and formed the subject of a recent forum in the Annals of the Associationof American Geographers(see Sui 2004, Barnes 2004, Miller 2004, Phillips 2004,Smith 2004, Goodchild 2004, and Tobler 2004 for additional details). More form-ally it is a statement about the endemic presence of positive spatial autocorrelationin geographic information, and thus of the principle underlying the entire ﬁeld ofgeostatistics.The consequences of Tobler’s First Law (TFL) for GIS design are profound. If it were not true, and nearby things were as different as distant things, then all forms of spatial interpolation would be impossible, along with the derivative processesof contour mapping and resampling. All advanced GIS data structures would be impossible, since there would be no basis for assuming that terrain could be repres-ented as a mesh of triangles, or that points with similar characteristics could begrouped into polygons. One can go further and argue that a geographic world with-out TFL would be impossible to learn about or describe, since every point wouldbe independent of its most immediate surroundings. There are of course exceptions,and TFL is not a deterministic law. It is possible, for example, for spatial inde-pendence to exist over distances in excess of what geostatisticians would deﬁne asTHO_C33  19/03/2007  11:23  Page 602 Downloaded from https://onlinelibrary.wiley.com",
    "chunk_order_index": 379,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-dc1448236621d96a574fad71741a6352": {
    "tokens": 1200,
    "content": "TFL would be impossible to learn about or describe, since every point wouldbe independent of its most immediate surroundings. There are of course exceptions,and TFL is not a deterministic law. It is possible, for example, for spatial inde-pendence to exist over distances in excess of what geostatisticians would deﬁne asTHO_C33  19/03/2007  11:23  Page 602 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: THE GRAND CHALLENGES603the phenomenon’s range, and it is possible for negative spatial autocorrelation toexist at certain scales (at the scale of the cells in a checkerboard, for example).Anselin (1989) has argued that TFL, or the principle of positive spatial auto-correlation, is one of two endemic properties of geographic information. The otheris spatial heterogeneity, or the tendency for properties to vary from one area toanother over the Earth’s surface. In the terms of spatial statistics, this is a ﬁrst-order effect, or a property of places taken one at a time, while TFL describes a second-order effect, a property of places taken two at a time. For that reason itmight be preferable if TFL were the Second Law, and spatial heterogeneity the basisof a First Law.The consequences of spatial heterogeneity are also profound. If the Earth’s sur-face is heterogeneous, it follows that standards and design decisions adopted in one region, and designed for the conditions of that region, will be different fromthose adopted in other regions. Spatial heterogeneity thus explains the lack of inter-operability between the various classiﬁcation schemes used in geographic informa-tion, and the tension between local geodetic datums and global ones. It dictatesthat the results of any analysis will depend explicitly on the bounds of the analysis,and will change when the bounds change. It also makes a compelling case for thenew place-based or locally centered methods of spatial analysis, such as Geograph-ically Weighted Regression (Fotheringham, Brunsdon, and Charlton 2002) and LISA(Anselin 1995).Additional generalizations can be made not so much about the nature of geographicinformation, as about the nature of its representation. Many geographic phenomenareveal more detail as they are examined more closely, and the rate at which addi-tional detail is revealed is to some degree predictable. Mandelbrot (1982) termed suchphenomena fractals, and showed that fractal properties were broadly characteristicof geographic information. They imply a degree of predictability in the effects of scalechange, allowing better-informed design decisions to be made regarding hierarch-ical structures in GIS. I have argued that the endemic presence of uncertainty inGIS representations has profound impacts on GIS design, and leads to an entirelydifferent approach to the representation of position (Goodchild 2002).These cases all point to the need for GISc to address the nature of geographicinformation, and in effect to become in part a natural science, comparable to physics,chemistry, or biology, with its own unique domain of study in the natural world.Of course this vision of the domain of GISc must include phenomena that are ofhuman origin, or are inﬂuenced by humans.Broader ThemesSince its inception in the 1960s, GIS has become useful and almost indispensablein a vast range of human activities, from Earth science to human health, and fromtransportation to resource management. It is the enabling technology that has per-mitted utility companies to move to a higher level of efﬁciency in their managementof distributed networks, and package delivery companies to save millions in deliverycosts. Advances in GISc are essential to the further development of GIS, and thekey to the success of the technology’s next generation.THO_C33  19/03/2007  11:23  Page 603 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f604MICHAEL F. GOODCHILDDespite its importance, however, GIS remains a comparatively small applicationof information technology, and as such it must rely on the larger mainstream formany developments. The relational and object-oriented databases now widely usedin GIS are mainstream products, that would probably not have been developed ifGIS was their only market; and at the same time GIS has relatively little inﬂuenceon such developments.In this context, one might argue that the future of GIS lies not in the specializedresearch agenda of GISc, but in broader research agendas that will determine thefuture of information technology. Many of the research agenda topics identiﬁedabove are indeed more general than GIS, and one can expect a broader set of mindsto be interested in them. To what extent, for example, are issues of ontology andinteroperability unique to GIS, and to what extent are they common to a muchlarger domain? Semantic interoperability is a problem common to all applicationsthat rely on the meaning of terms, and one might therefore expect solutions to comefrom a number of disciplines, not only from GISc.This argument has two important implications. First, it suggests that GISc mustcontinue to look more broadly to developments that may have potential for GIS.A case",
    "chunk_order_index": 380,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-087f05f22a6f6eacc3864cc818a7c8bc": {
    "tokens": 1200,
    "content": "what extent, for example, are issues of ontology andinteroperability unique to GIS, and to what extent are they common to a muchlarger domain? Semantic interoperability is a problem common to all applicationsthat rely on the meaning of terms, and one might therefore expect solutions to comefrom a number of disciplines, not only from GISc.This argument has two important implications. First, it suggests that GISc mustcontinue to look more broadly to developments that may have potential for GIS.A case in point is the Grid, a term that encompasses a range of technologies andresearch efforts aimed at integrating the distributed computing resources of widelydispersed communities into transparent wholes. The bandwidth of the Internet now makes it possible for the components of computing – the processor, data, and software – to be distributed virtually anywhere, and for a user at a desktop to access what amounts to a previously unimaginable resource. Services need nolonger be provided at the desktop, but can be invoked from servers located any-where on the network, and might include any of the functions currently performedlocally by a GIS. Several GI Services are already available (the Geography Network,http://www.geographynetwork.com, includes a directory), but much research remainsto be done to explore GIS applications of the Grid.Second, it suggests that it is in the strategic interest of the GISc community to generalize its efforts wherever possible. One such generalization would be fromgeographic to spatial, to explore domains deﬁned by spaces other than that of theEarth’s surface. The space of the human brain, for example, has similarities andalso important differences, that can lead both to new applications for GIS, and alsoto the cross-fertilization of research. While there is only one Earth, each humanbrain is different, requiring brain researchers to develop techniques for deﬁning ageneric brain, and for mapping each individual brain to it. One can ask whetherother spaces display the same properties as are observed for geographic space, suchas TFL, and whether information system design considerations are therefore thesame or different for these other spaces.A Grand Challenge: Digital EarthThe previously cited NSF workshop (National Computational Science Alliance 1999) asked whether grand challenges existed for GIS, and in its report listed fourresearch themes that it felt might merit this distinction:THO_C33  19/03/2007  11:23  Page 604 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: THE GRAND CHALLENGES605•To ﬁnd ways to express the inﬁnite complexity of the geographical world in thebinary alphabet and limited capacity of a digital computer (the representationchallenge);•To ﬁnd ways of summarizing, modeling, and visualizing the differences betweena digital representation and real phenomena (the uncertainty challenge);•To achieve better transitions between cognitive and computational representa-tions and manipulations of geographic information (the user interface challenge);and•To create simulations of geographic phenomena in a digital computer that areindistinguishable from their real counterparts (the modeling challenge; in effecta Turing test of GIS-based modeling).All of these have intellectual depth, but somehow lack the compelling appeal ofa mega-project. But the concept of Digital Earth (DE) perhaps has the ability tocapture popular imagination. The term was coined by Gore in 1992 and elaboratedin a much-quoted 1998 speech (http://www.digitalearth.gov/VP19980131.html):Imagine, for example, a young child going to a Digital Earth exhibit at a local museum.After donning a head-mounted display, she sees Earth as it appears from space. Usinga data glove, she zooms in, using higher and higher levels of resolution, to see con-tinents, then regions, countries, cities, and ﬁnally individual houses, trees, and othernatural and man-made objects. Having found an area of the planet she is interested inexploring, she takes the equivalent of a “magic carpet ride” through a 3-D visualiza-tion of the terrain. Of course, terrain is only one of the numerous kinds of data withwhich she can interact. Using the system’s voice recognition capabilities, she is able torequest information on land cover, distribution of plant and animal species, real-timeweather, roads, political boundaries, and population. She can also visualize the environ-mental information that she and other students all over the world have collected aspart of the GLOBE project. This information can be seamlessly fused with the digitalmap or terrain data. She can get more information on many of the objects she sees byusing her data glove to click on a hyperlink. To prepare for her family’s vacation toYellowstone National Park, for example, she plans the perfect hike to the geysers, bison,and bighorn sheep that she has just read about. In fact, she can follow the trail visuallyfrom start to ﬁnish before she ever leaves the museum in her hometown. She is notlimited to moving through space, but can also travel through time. After taking a vir-tual ﬁeld-trip to Paris to visit the Louvre, she moves backward in time to learn aboutFrench history, perusing digitized maps overlaid on the surface of the Digital Earth,newsreel footage, oral history, newspapers and other primary sources. She sends someof this information to her personal e-mail address to study later. The time-line, whichstretches off in the distance, can be set for days, years, centuries, or even geologicalepochs, for those occasions when she wants to",
    "chunk_order_index": 381,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-584fd174182d0d76391ccca45c8ad958": {
    "tokens": 1200,
    "content": "eld-trip to Paris to visit the Louvre, she moves backward in time to learn aboutFrench history, perusing digitized maps overlaid on the surface of the Digital Earth,newsreel footage, oral history, newspapers and other primary sources. She sends someof this information to her personal e-mail address to study later. The time-line, whichstretches off in the distance, can be set for days, years, centuries, or even geologicalepochs, for those occasions when she wants to learn more about dinosaurs. (Gore 1992)This vision of DE raises numerous problems (Goodchild 1999, 2000). First, itimplies that data structures can be found that support a smooth zooming from resolutions as coarse as 10 km (whole-Earth view) to near 1 m (individual housesand trees). Research on this topic has been under way for many years, and imple-mentations are now widely available (in ESRI’s ArcGlobe and Google Earth, forexample). Second, it presents enormous problems of data volume, since there areTHO_C33  19/03/2007  11:23  Page 605 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f606MICHAEL F. GOODCHILD5 ×1014m2on the Earth’s surface. It raises problems of visual rendering, sincealthough some data (for example, terrain elevation) are easily rendered in three-dimensional views, others (for example, average income) would have to be commun-icated symbolically. Perhaps more problematic are the institutional issues, since DE would require smooth interoperability between data sets, and collaboration bynumerous data suppliers and custodians. But all of these are, of course, exactly whatis required for a grand challenge – the collaboration of many disciplines, agencies,and communities making progress towards a commonly held vision.DE is presented by Gore as an educational tool, a way for a younger generationto acquire knowledge of the planet, and particularly of its environmental problemsand ways in which they might be solved. Another major beneﬁt of DE would lie inits ability to serve as an experimental environment, allowing planners to evaluatethe consequences of management and development alternatives. One can imagineevaluating the consequences of a steady rise in atmospheric CO2using DE, as analternative to the inﬁnitely costly and dangerous experiment that humanity is currently conducting on the real thing (for a Japanese effort along these lines seehttp://www.nec.com/global/features/index9/index.html). GIS is currently used for thispurpose, of course, but only over much smaller domains. Again, these are the kindsof massive beneﬁts one would expect from the solution of a grand challenge.CONCLUSIONSIn the previous sections I have implied numerous criteria for grand challenges, someexplicitly and some implicitly. In this ﬁnal section I will review these and examinethe extent to which they are satisﬁed by the various proposals.First, a grand challenge should focus many apparently disparate forms of researchon a common goal. DE clearly satisﬁes this test, since it involves researchable issuesthat are both technical and institutional, and which touch on the disciplines of geo-graphy, computer science, cognitive science, and any of the many disciplines thatstudy the processes responsible for the evolution of the Earth’s surface.Second, there are expectations regarding the magnitude of a grand challenge,whether measured in numbers of investigators, levels of funding, or numbers ofpapers produced. DE has already spawned several conferences, and research on manyof its sub-problems continues throughout the GISc community, though often with-out explicit recognition of its relevance to DE. DE has many pseudonyms: VirtualEarth, Earth System, and Digital Globe all produce numerous WWW hits on DE-like projects. The Japanese Earth Simulator project alone represents an investmentof several hundred million dollars.Third, a grand challenge should capture the popular imagination, and thus polit-ical support. The results to date on this test are much less clear for DE, and alsofor GIS and GISc. While there is now very extensive name recognition of GIS, andits value is without question, its development clearly has not attracted the kind ofwidespread public attention accorded to the lunar landings, or even the mappingof the human genome. It is, quite simply, a very useful tool that we can no longerdo without – and DE a very useful vision of where it might be headed in the yearsto come.THO_C33  19/03/2007  11:23  Page 606 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: THE GRAND CHALLENGES607REFERENCESAnselin, L. 1989. What Is Special about Spatial Data? Alternative Perspectives on SpatialData Analysis.Santa Barbara, CA: National Center for Geographic Information and AnalysisTechnical Paper No. 89–4.Anselin, L. 1995. Local indicators of spatial association: LISA. Geographical Analysis27:93–115.Barnes, T. J. 2004. A paper related to everything but more related to local things. Annalsof the Association of American Geographers94: 278–83.Department of the Environment. 1987. Handling",
    "chunk_order_index": 382,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-895552bcb741e68f947ed9cf7fe50b90": {
    "tokens": 1200,
    "content": "SpatialData Analysis.Santa Barbara, CA: National Center for Geographic Information and AnalysisTechnical Paper No. 89–4.Anselin, L. 1995. Local indicators of spatial association: LISA. Geographical Analysis27:93–115.Barnes, T. J. 2004. A paper related to everything but more related to local things. Annalsof the Association of American Geographers94: 278–83.Department of the Environment. 1987. Handling Geographic Information: The Report ofthe Committee of Enquiry Chaired by Lord Chorley.London: Her Majesty’s StationeryOfﬁce.Egenhofer, M. J., Glasgow, J., Günther, O., Herring, J. R., and Peuquet, D. J. 1999. Progressin computational models for representing geographic concepts. International Journal ofGeographical Information Science13: 775–98.Fotheringham, A. S., Brunsdon, C., and Charlton, M. 2002. Geographically WeightedRegression: The Analysis of Spatially Varying Relationships. New York: John Wiley andSons.Goodchild, M. F. 1992. Geographical information science. International Journal ofGeographical Information Systems6: 31–45.Goodchild, M. F. 1999. Implementing Digital Earth: A research agenda. In G. Xu and Y.Chen (eds) Towards Digital Earth: Proceedings of the International Symposium onDigital Earth, Beijing, China.Beijing: Science Press, pp. 21–6.Goodchild, M. F. 2000. Cartographic futures on a digital Earth. Cartographic Perspectives36: 3–11.Goodchild, M. F. 2002. Measurement-based GIS. In W. Shi, P. F. Fisher, and M. F.Goodchild (eds) Spatial Data Quality.New York: Taylor and Francis, pp. 5–17.Goodchild, M. F. 2004. The validity and usefulness of laws in geographic information scienceand geography. Annals of the Association of American Geographers94: 300–3.Goodchild, M. F., Egenhofer, M. J., Kemp, K. K., Mark, D. M., and Sheppard, E. S. 1999.Introduction to the Varenius project. International Journal of Geographical InformationScience13: 731–46.Gore, A. 1992. Earth in the Balance: Ecology and the Human Spirit. Boston, MA: HoughtonMifﬂin.MacEachren, A. M. and Kraak, M. J. 2001. Research challenges in geo-visualization.Cartography and Geographic Information Science18: 3–12.Mandelbrot, B. B. 1982. The Fractal Geometry of Nature. San Francisco, CA: Freeman.Mark, D. M. 2003. Geographic information science: Deﬁning the ﬁeld. In M. Duckham, M. F. Goodchild, and M. F. Worboys (eds) Foundations of Geographic Information Science.New York: Taylor and Francis, pp. 3–18.Mark, D. M., Freksa, C., Hirtle, S. C., Lloyd, R., and Tversky, B. 1999. Cognitive modelsof geographical space. International Journal of Geographical Information Science13: 747–74.May, R. M. 1988. How many species are there on earth? Science247: 1441–9.Miller, H. J. 2004. Tobler’s First Law and spatial analysis. Annals of the Association ofAmerican Geographers94: 284–9.NCGIA. 1989. The research plan of the National Center for Geographic Information andAnalysis. International Journal of Geographical Information Systems3: 117–36.National Computational Science Alliance. 1999. Toward Improved Geographic InformationServices within a Digital Government: Report of the NSF Digital Government InitiativeGeographic Information Systems Workshop. Champaign, IL: University of Illinois at Urbana-Champaign.THO_C33  19/03/2007  11:23  Page 607 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f608MICHAEL F. GOODCHILDNRC. 2003. IT Roadmap to a Geospatial Future.Washington, DC: National Academy Press.Phillips, J. D. 2004. Doing justice to the law. Annals of the Association of AmericanGeographers94: 290–3.Rhind, D. W. 1988. A GIS research agenda. International Journal of GeographicalInformation Systems2: 23–8.Sheppard, E. S., Couclelis, H., Graham, S., Harrington, J. W., and Onsrud, H. 1999. Geo-graphies of the information society. International Journal of Geographical InformationScience13: 797–824.Smith, J. M. 2004. Unlawful relations and verbal inﬂation. Annals of the Association ofAmerican Geographers94: 294–9.Sui, D. Z. 2004. Tobler’s First Law of Geography: A big idea for a small world? Annals ofthe Association of American Geographers94: 269–77.Tobler, W. R. 1970. A computer",
    "chunk_order_index": 383,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4ed476a7e51af833e0b19de8beac9215": {
    "tokens": 1200,
    "content": "Science13: 797–824.Smith, J. M. 2004. Unlawful relations and verbal inﬂation. Annals of the Association ofAmerican Geographers94: 294–9.Sui, D. Z. 2004. Tobler’s First Law of Geography: A big idea for a small world? Annals ofthe Association of American Geographers94: 269–77.Tobler, W. R. 1970. A computer movie: Simulation of population change in the Detroit region.Economic Geography46: 234–40.Tobler, W. R. 2004. On the First Law of Geography: A reply. Annals of the Association ofAmerican Geographers94: 304–10.UCGIS. 1996. Research priorities for geographic information science. Cartography andGeographic Information Science23: 115–27.THO_C33  19/03/2007  11:23  Page 608 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fChapter 34Geographic Information Science:Where Next?Andreas Reuter and Alexander ZipfThe title question “Where next?” is based on a number of assumptions in (at least)three dimensions, the analysis of which will actually help in answering the ques-tion itself.In order for the “where” to be meaningful there needs to be a frame of refer-ence within which to determine the current position as well the target location andthe route taking us from here to there. The “next” part of the question implies atemporal dimension, together with a unit speed of the clock ticks. And ﬁnally, we have to make assumptions about the momentum of the object under consid-eration, that is Geographic Information Science (GISc): Does the “where next?”mean we picture Geographic Information Systems (GIS) resting at some position,leisurely pondering which path to choose now, or do we assume a system in motionfor which we try to extrapolate the trajectory?Clearly, without making all those assumptions explicit, the chapter cannot possibly make much sense. On the other hand, all the choices that need to be madeare subjective to a certain degree, biased by the background of the authors, and soit should not be too surprising if some readers disagree with the frame of referencechosen, others with the temporal units, and yet others with the calculation of thetrajectory. But this is not a problem at all because, in order to disagree, one needsto consciously make one’s own choices, deﬁne a frame of reference, etc., therebycoming up with a different prognosis – which is just as good as the authors’. Andthink about it: the real value of any of those technological predictions, extrapola-tions, forecasts, or whatever does not lie in what they say, but in the reactions theyprovoke in the readers’ minds.A simple approach towards answering the question would be to focus on theinner consistency of the present volume and maintain that of course GISc shouldstrive to meet the grand challenges outlined in the previous chapter. That wouldkeep this chapter very short indeed, but it would answer the wrong question. A grand challenge is typically deﬁned as “a ca.15-year project with clearly de-ﬁned criteria of success or failure, resulting in fundamental and radical advancesin basic science or engineering.” The title question, however, asks where next, andTHO_C34  19/03/2007  11:23  Page 609 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f610ANDREAS REUTER AND ALEXANDER ZIPFwe certainly don’t want to suggest that the clock of progress in GISc ticks in unitsof 15 years.So our question boils down to the problem of which path to take in order to get there. Clearly, GISc is not an isolated ﬁeld: on the contrary, it is closely inter-acting with other fast-moving disciplines such as Computer Science, and one canexpect most progress in those areas where it is possible to leverage new results inother ﬁelds, provided they are in line with one’s own agenda. Incidentally, a groupof Computer Scientists around Tony Hoare has been discussing grand challengesfor CS for some time, and it is interesting to note that at least two of the topicsnamed are immediately relevant for our discussion. Quoting from a recent versionof the list (http://www.nesc.ac.uk/esi/events/Grand_Challenges/index.html), we ﬁnd(together with brief references to projects addressing those challenges):•Science for Global Ubiquitous Computing: Within 20 years computers will beubiquitous and globally connected, and academics and scientists believe they will be regarded collectively as a single Global Universal Computer (GUC). Pro-fessor Robin Milner of the University of Cambridge says the challenge is to workout who will program the GUC, who will beneﬁt, how will they beneﬁt, andhow do we trust it.•Memories for Life: In 10 to 20 years digital data and images that are uniqueto us will have grown substantially. These data will include digital pictures, emails,phone numbers and audio recordings. The project will seek to establish a wayin which",
    "chunk_order_index": 384,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7bbaffe7eb779b3ed3af40bf9dcbdbeb": {
    "tokens": 1200,
    "content": "Computer (GUC). Pro-fessor Robin Milner of the University of Cambridge says the challenge is to workout who will program the GUC, who will beneﬁt, how will they beneﬁt, andhow do we trust it.•Memories for Life: In 10 to 20 years digital data and images that are uniqueto us will have grown substantially. These data will include digital pictures, emails,phone numbers and audio recordings. The project will seek to establish a wayin which all these data can be securely stored and searched. Professor AaronSloman of the University of Birmingham says research will attempt to establishhow someone can search all records and data stored on their system – whateverform that may take – in a secure environment, from wherever is convenient.The ﬁrst topic should be immediately obvious: Global ubiquitous computing willrequire deeply integrated facilities for locating devices, for navigation, and for manyother types of spatial referencing.The second topic might be less obvious, but is potentially even more interesting.Most of the data/information pertaining to a person’s life has explicit (and moreoften implicit) spatial dependencies, which may not be important at the time ofrecording, but will be relevant for retrieval in various contextual settings.So let us now deﬁne the “here” and “there” in terms of the themes appearingin the list of Grand Challenges, keeping in mind that “next” should refer to a fore-seeable future rather than some 15+years down the road. We are convinced thatthe “next” important developments in GISc will happen along the following threedimensions: concepts and methods, applications, and platforms. Of course, one can name additional dimensions, which might be interesting to consider, but forthe current purposes, we will ﬂatten them out and just take into account the onesmentioned. The remainder of the chapter will illustrate the anticipated developmentsin some detail, but let us brieﬂy summarize what we are going to discuss:•Concepts and Methods: GISc will incorporate formal models for describing deepsemantics of a large variety of spatial phenomena. This will enable new levelsof quality in spatial reasoning, thereby enabling common-sense modeling, whichnecessarily requires profound understanding of space.THO_C34  19/03/2007  11:23  Page 610 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: WHERE NEXT?611•Applications: GISc will enable and support new applications. As an exampleconsider the Virtual Telescope, which already has proved to be a research vehicleproper (www.cnn.com/2002/TECH/space/10/02/radio.telescope/).•Platforms:The results of GISc will be delivered on and will inﬂuence the development of new platforms, such as the Grid. The NGG2-report (NGG2 2004) contains a number of scenarios illustrating the need for sophisticated spatial referencing. For instance, the idea of a mobile assistant with a large repertoire of user support functions not only requires locating the device in somecoordinate system but also requires the automatic analysis of the device’s (i.e.the user’s) trajectory to support trip planning and scheduling – just to mentionone example.In the following discussion, we assume that all the developments under considera-tion will follow a trend that can be observed in many areas of IT and its supportingdisciplines: Integration.Many of the current efforts are directed at integrating information and servicesfrom different domains and contexts, such that they can be used and exploited in a uniform way. The success of XML and all its derivates is due to the strongmomentum behind the idea of integration. Web services carry the idea from datato applications, and, again, integration is the name of the game. Semantic modelingin its many different guises aims at integration of information from heterogeneoussources, and even a well-established ﬁeld such as databases is undergoing a transition,which some observers call a “revolution” (Gray 2004), because of the integrationof data of arbitrary types into a single consolidated overall architecture.So our main hypothesis is that GISc will, in the foreseeable future, participate in and contribute to the ongoing effort of large-scale information integration. GISis well-positioned for that task, because it has a tradition of working towards theintegration of heterogeneous data sets like raster and vector data with alphanu-meric information.Wrapping everything together in one sentence, we can say that GIS will be instru-mental in integrating data and services from heterogeneous sources into a uniformarchitecture, using new concepts and methods, delivering these new services via theGrid, thus enabling a whole range of new applications.Let us now consider the trends in each of the three dimensions in turn.Concepts and Methods (Dimension 1)Semantic geoinformationIn terms of concepts and methods, we expect the most interesting developments in approaches to modeling semantic aspects of space and spatial objects. So far,modeling has been largely restricted to mathematical formalisms and – to a certaindegree – image processing techniques. However, for integrating geo objects withinformation from other domains and for reasoning about spatial phenomena, a deeper semantic representation of spatial relationships is needed. This is in line withobservations from other ﬁelds, where the traditional specialized models are also foundto be too narrow for integrating data with information from different domains. TheTHO_C34  19/03/2007  11:23  Page 611 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/",
    "chunk_order_index": 385,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-528586d3c96af906c30b54afac15a63c": {
    "tokens": 1200,
    "content": "for reasoning about spatial phenomena, a deeper semantic representation of spatial relationships is needed. This is in line withobservations from other ﬁelds, where the traditional specialized models are also foundto be too narrow for integrating data with information from different domains. TheTHO_C34  19/03/2007  11:23  Page 611 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f612ANDREAS REUTER AND ALEXANDER ZIPFmost notable expression of this diagnosis is the development of what is summarilycalled the Semantic Web (Berners-Lee, Hendler, and Lassila 2001). Whereas in thecurrent WWW one can search for data by specifying reference strings, the goal ofthe Semantic Web is to provide means for searching at a semantic level, that is tosay for concepts rather than words, for relationships between those concepts, bethey causal, temporal, or spatial (see Chapter 31 by Jones and Purves in this volumefor some additional discussion of Web-based GIS capabilities).Currently, a number of languages suited for that type of semantic modeling andquerying are being developed. The latest achievement is the Web Ontology LanguageOWL which builds on the Resource Description Framework (RDF) (Smith, Welty,and McGuinness 2003). OWL allows the deﬁnition of ontologies, which are explicitformal descriptions of concepts or classes in a domain of discourse, which expressa shared speciﬁcation of a conceptualization. OWL thus provides the possibility ofexpressing and sharing information associated with people, events, devices, places,time, space, etc.A number of current GIS issues are related to a lack of formal expression of semantics of the domain of discourse. The challenge, therefore, is to deﬁne reason-ably general ontologies dealing with spatial phenomena expressed in OWL. Thesethen need to be integrated into the current major standardization effort for GI services and data – the OGC open web services (OWS), as the technical funda-mentals for Spatial Data Infrastructures (SDI). In particular, ontologies seem to berelevant in the area of Global Ubiquitous Computing (see the Applications section).This is because they are needed to model the diverse aspects of the context of asituation. Apart from that they are, of course, relevant for semantic interoperabil-ity due to the semantic heterogeneity of geographic information. This has alreadytriggered intense research efforts (for example, Frank 1997, Winter 2000, Fonseca,Egenhofer, Agouris, and Câmara 2002). A spatial ontology primarily deals withphysical space and spatial relations, but also with abstract spaces that can be mappedonto the physical primitives. Along with the research within GISc, related pro-posals for ontologies were developed outside the GISc ﬁeld, like DAML-Space,OpenCyc, SUMO, or the Region Connection Calculus (RCC). One can also ﬁndexamples of draft ontologies identifying relevant domains for integrated ubiquitousapplications (for example, Chen 2004). Among others these usually include the following domains:•Spatial objects and their relationships•Temporal relations•Person proﬁles/user models•Events•Device proﬁles•Digital document models•Security and privacy policiesThe spatial and temporal domains have been the primary focus of GI Science. A temporal ontology generally describes time and temporal relations using “timeinstants” and “time intervals.” Similarily Zipf and Krüger (2001) presented a con-ceptual model and its application to GML.THO_C34  19/03/2007  11:23  Page 612 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: WHERE NEXT?613But, of course, semantic modeling might not be the miracle cure solving all theopen problems in integrating data from heterogeneous sources. Ontologies are neces-sary to model and represent semantic knowledge. But the question of which arethe stable basic concepts from which to build the whole domain such that reason-ing about those concepts will be powerful enough to support future applicationsis still under debate. The early attempts, made some 15 to 20 years ago, undernames like “expert systems” were only moderately successful and typically limitedto a very narrow domain. This time, the real challenge is to model spatial semantics(and all the others) such that their integration will yield a useful formal model ofwhat is sometimes referred to as “common knowledge,” something projects likeCyc have strived to accomplish for years (Lenat, Guha, Pittman, Pratt, and Shepherd1990).Applications (Dimension 2)UbiGIS: Ubiquitous GI ServicesUbiquitous Computing(UbiComp, UC) is regarded as one of the coming long-termtrends in information technology. The term describes the pervasive use of com-puter services – the possibility of the use of computer-aided services as a ubiquity.The underlying system will contain billions of tiny, wireless, connected computingdevices (mostly not computers as we know them), which are integrated into a multitude of objects of everyday life (Weiser 1991). Among others, the followingitems characterize Ubiquitous Computing:•",
    "chunk_order_index": 386,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-c727e39c8d4765d54c653f0006e599fd": {
    "tokens": 1200,
    "content": ", UC) is regarded as one of the coming long-termtrends in information technology. The term describes the pervasive use of com-puter services – the possibility of the use of computer-aided services as a ubiquity.The underlying system will contain billions of tiny, wireless, connected computingdevices (mostly not computers as we know them), which are integrated into a multitude of objects of everyday life (Weiser 1991). Among others, the followingitems characterize Ubiquitous Computing:•Spontaneous networks, service description, service discovery•Wireless and mobile communication•New man-machine interfaces and interaction paradigms•Adaptation to context and situation, in particular localizationWe want to focus on the last item in the list, which has a more fundamentalrelationship to GISc. In the light of UbiComp, the relationship between spatial datainfrastructures (SDI) and LBS becomes obvious: both concepts support the accessto GI Services at any time at any place using different clients based on an infra-structure providing open interfaces. The need for transparent access to computer-ized services independent of further restrictions is also one of the main objectivesof UbiComp. As a broader topic behind all of this we ask the following question:“How can GISc support the ubiquitous access to and use of the wide variety of geo-graphic information and applications in an optimal way?” So the term “ubiquitous”extends the anywhere, anytime, to anyone approach of Location Based Services (LBS) to the paradigm: the right thing at the right time the right way to the rightperson(s) (See Chapter 32 by Brimicombe in this volume, for more on location-based services and GIS).Implied by the idea of an interoperable spatial data infrastructure (SDI) as wellas a consequence of new developments in mobile computing and Human ComputerInteraction (HCI), one can expect GI Services to be available ubiquitously to allTHO_C34  19/03/2007  11:23  Page 613 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f614ANDREAS REUTER AND ALEXANDER ZIPFusers. For this the term Ubiquitous Geographic Information Services =UbiquitousGIS =UbiGIS has been suggested (Zipf 2004, see also http://www.ubigis.org). Thisterm can be deﬁned as: pervasive services based on UbiComp technology and devices,supporting context-dependent (that is, adaptive) interaction, realized by informa-tion and functions of geographic information services based on interoperable SDI.Often LBS are parameterized by coordinates in some spatial frame of reference.In the UbiComp-approach, however, a more general approach is needed, takingthe contextof the overall situation into account. Dey and Abowd (2000) character-ize context as “any information that can be used to characterize the situation of anentity. An entity is a person, place, or object that is considered relevant for the inter-action between a user and an application, including the user and the applicationthemselves.” Therefore any information that is available at the time of an interactioncan be considered as context information.As a simple example, consider a system that allows a user to ask questions suchas: “What are the interesting objects in my vicinity?” Depending on where the useris, what he or she wants to achieve and what the general current situation (whichmight be modeled through a variety of application speciﬁc parameters) is, his/herdeﬁnitions of both “vicinity” and “interesting object” may vary considerably fromfashion shops in driving distance to prehistoric artifacts in a museum. The informa-tion about the situation and environment (the context) can be (and has been) categorized in many ways, but an agreed-upon formalization is still missing. Whilethe ﬁrst context-aware systems have presented progress there are still improvementsnecessary for supporting knowledge sharing and context reasoning.The adaptability of GI Services to context can be seen as one of the next stepsfor GISc research in order to achieve more intuitively usable GIS. In this over-view we only can present hints as to which adaptive services might be suitable within the context of GI Services. This is derived from ﬁrst results regarding adapt-ive mobile GI Services in our projects. The following categories of adaptation havebeen identiﬁed:•Adaptation of the visual presentation of the contents offered – both of the textand the graphic information (pictures, maps, video, VR models);•Adaptation of route planning (by individual weighting and restrictions);•Adaptation of queries (combined location- and interest-based tips); and•Adaptation of the offered contents (for example, concerning degree of detail, topic).In GISc, the ﬁrst work on context-awareness has focused on mobile maps (Meng,Zipf, and Reichenbacher 2004; Zipf 1998, 2002), navigation support (Kray 2002)or wayﬁnding with landmarks (Winter, Raubal, and Nothegger 2004) as well asspace-time accessibility (for example, Raubal, Miller, and Bridwell 2004). Furtherexamples for adaptive GI applications include the computation of routes based oncontext-related criteria (Joest and Stille 2003) or a user-aware spatial push of infor-mation (Zipf and Aras 2002).But apart from the possibility of using context as a parameter for adapting GI Services, there is one even more important aspect to context",
    "chunk_order_index": 387,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6997066e10ad8b798b577c6d5223648b": {
    "tokens": 1200,
    "content": "hegger 2004) as well asspace-time accessibility (for example, Raubal, Miller, and Bridwell 2004). Furtherexamples for adaptive GI applications include the computation of routes based oncontext-related criteria (Joest and Stille 2003) or a user-aware spatial push of infor-mation (Zipf and Aras 2002).But apart from the possibility of using context as a parameter for adapting GI Services, there is one even more important aspect to context that makes it important for the GISc community to work on this issue in more detail: contextTHO_C34  19/03/2007  11:23  Page 614 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: WHERE NEXT?615parameters are related to space. This is, in fact, sort of a corollary to Tobler’s FirstLaw of Geography (Tobler 1970). In more detail the following principles apply tocontext (Schmidt 2002):•Context has an origin location;•The relevance of the context reaches its maximum at this origin;•The relevance of the context decreases with distance from that origin;•Exceeding a certain distance the context is no longer relevant; and•If there are multiple identical sensors (for sensing context information) available,the one which is spatially most close has the highest relevance.This relationship can for example be modeled by fuzzy functions. Generally thisis not stationary, but can move (for example, with the user) and may be distortedin a direction, for instance where the user walks to. Furthermore there is usually alarge range of context factors present which overlap in space. All of these principlesapply not only to space, but also to time, resulting in an interesting spatio-temporalmodeling task.Platforms (Dimension 3)Spatial data infrastructures (SDI)The current main effort regarding the integration of GI Services and data is thedevelopment of spatial data infrastructures (SDI). From a simpliﬁed technical pointof view, SDI can be regarded as the provision of distributed GI Services and geo-data by means of web services using open standards. On the other hand, mobileGIS offer GI functionality on handheld computers (for example, for mapping, dataacquisition, or infrastructure maintenance, etc.) dependent from their location. Thisrequires an infrastructure of GI Services and wireless access to geodata, which isbased on open interfaces – in other words a wireless SDI. We cannot dig deeper intothose technical issues, but one can see that National Spatial Data Infrastructures(NSDI) are currently evolving in all parts of the world. This should lead to a newquality of improved access to spatial data in the mid-range future.Integrating ubiquitous positioning facilities and location modelsPositioning is a basic functionality for LBS and ubiquitous services, with indoor pos-itioning being as important as global positioning. Considerable work has been conducted in mobile computing, leading to location models that are not based onthe earth-bound coordinate systems we are accustomed to in GIS. So GISc needsto provide mappings between emerging ego-centric or object-centric location modelsbased, for example, on network topology (for example, Beigl, et al. 2001) as depictedin Figure 34.1 and conventional geographic or geodetic spatial reference systems.Applying these to intelligent positioning and navigation support, for example, wouldcombine several approaches that mutually improve or replace themselves in caseof partial failure (Kray 2003).THO_C34  19/03/2007  11:23  Page 615 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f616ANDREAS REUTER AND ALEXANDER ZIPFNetworks of location-aware sensorsClassically, sensors in the context of GI comprise those built for measuring envir-onmental data (remote sensing being the most prominent example), but recentlynetworks of stationary or mobile sensors for heterogeneous parameters are com-ing into focus. Therefore researchers are investigating the interoperable integrationof sensors through the OGC Sensor Web Enablement initiative. Apart from thisclassical view, location-aware sensors for whatever parameters constitute import-ant elements for both context awareness and personalization within UbiComp.Through the availability of such new sensors the development of adaptive applica-tions becomes possible. Such a location-aware interoperable sensor infrastructureis also important for non-GI applications, because of the relation between spaceand context as outlined above. Such sensors are being equipped with basic pro-cessing and communication capabilities, for instance in projects like “Smart Dust”(Kahn, Katz, and Pister 1999) or “smart-its” (http://www.smart-its.org), leading to a georeferenced distributed global computing platform. When we envisage suchlarge future networks of sensors delivering masses of data all the time (again remotesensing serves as a primary example) we are faced with the problem of mining thesehuge amounts of distributed data sources for interesting patterns. This requires new middleware concepts, which leads us to that the idea of Grid computing (seeChapter 19 by Miller in this volume for more detailed discussion of recent workon geographic data mining and knowledge discovery).The GeoGRID: Towards geospatial GRID computingGRID Computing (GC) is",
    "chunk_order_index": 388,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-30137f652010bae1f7c1c84fe723c6e7": {
    "tokens": 1200,
    "content": "suchlarge future networks of sensors delivering masses of data all the time (again remotesensing serves as a primary example) we are faced with the problem of mining thesehuge amounts of distributed data sources for interesting patterns. This requires new middleware concepts, which leads us to that the idea of Grid computing (seeChapter 19 by Miller in this volume for more detailed discussion of recent workon geographic data mining and knowledge discovery).The GeoGRID: Towards geospatial GRID computingGRID Computing (GC) is a new concept for distributed high-performance com-puting through a coordinated use of geographically distributed large virtual collec-tions of computation resources realized through use of computer clusters. This shouldnot be confused with the term “Grid” in the sense of data structure for raster data,user angleobject anglecenter of objectuser positionRoom ZonedistanceaspectdimensionofobjectObject ZoneUser Angle Segment 1Evaluator 1Object Angle Segment 1Object Angle Segment 2Object Angle Segment 3Evaluator 1Evaluator 1Evaluator 1Fig. 34.1Object-centric location modelsGoßmann and Specht 2002THO_C34  19/03/2007  11:23  Page 616 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: WHERE NEXT?617as is frequently used in GISc. GC applications utilize high-speed networks and anew generation of middleware linking networks, computing resources, and tradi-tional geospatial applications. Tasks of this middleware include security and resourcemanagement for example. As the concept of GC also supports the aim of makinghigh-performance computer-processing power available ubiquitously, there is a clear relationship to Ubiquitous Computing, which is also highlighted in the NextGeneration Grids Report (NGG2 2004). Through the distribution of data, software,and computing resources we ﬁnd three aspects of GC related to space. In order torealize a Grid the use of standards and open protocols and interfaces is necessary,which builds a bridge to the already mentioned activities of both the OGC and thedevelopment of SDI. Again we ﬁnd our topic of integration, as these worlds needto come together to realize the vision of the Global Ubiquitous Computer that couldbe used in a range of tasks. A scenario in which all of this can easily be integratedwould be the case of support for disaster management, that really brings togetherthe vision of Ubiquitous Computing and Grid computing (NGG2 2004, Zipf 2004)with several clear relationships to GISc and therefore realizes an ideal scenario forUbiGIS. The ﬁrst actual examples of GI applications using GC technology are theGlobus Toolkit middleware for spatial interpolation or watershed modeling on rasterdata (Wang, Armstrong, and Bennett 2002).In order for the Grid to achieve its integrative goal, more is needed than just aset of middleware standards. As is pointed out in Gray (2003), seamless integra-tion will also require the nucleus of a “global information schema,” which can unifythe following categories: (1) units, (2) accuracy, (3) precision, (4) deﬁnition of quantities, (5) representation, and (6) semantics. Those unifying means have to becross-domain, and they have to support automatic schema generation and trans-lation. And again, since many data have a spatial connotation, GIS will have tocontribute to building this global information schema.SUMMARYThe above discussion has focused on various projects and ideas related to the three dimensions of progress we had identiﬁed in the beginning. But one could ask,“Assuming that integration is indeed the prevailing direction of innovation, whatcould be the result of integrating GI services into other platforms?”That’s a hard question; but let us try to come up with an answer anyway. Considertoday’s mobile phones. They provide you with an infrastructure for commun-icating from (almost) any location; the contents can be voice, images, and data. Itwould be extremely useful to augment this technology with location and naviga-tion services in all conceivable contexts and frames of reference. Of course, eachof those contexts refers to a different type of application, but there needs to be anenabling platform that supports them all and allows for seamlessly switching fromone to the next. Providing the principles and speciﬁcations for such a platform and integrating it into the existing framework of mobile computing is deﬁnitely an attractive and attainable goal.Besides technical questions, a range of social issues need to be examined that wecould not examine here concerning acceptance, social consequences, data security,THO_C34  19/03/2007  11:23  Page 617 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f618ANDREAS REUTER AND ALEXANDER ZIPFand privacy (for example, Dobson and Fisher 2003; but see also Cho, in Chapter 29of this volume, for an extended discussion of the current ways in which privacyissues are being handled in various countries). Hence, it is often claimed that theacquisition of personal and context information needs to be open to the end user,which is, in fact, seldom realized",
    "chunk_order_index": 389,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-dffda775c724d2d474c3da653d2c89e0": {
    "tokens": 1200,
    "content": "governed by the applicable Creative Commons License\f618ANDREAS REUTER AND ALEXANDER ZIPFand privacy (for example, Dobson and Fisher 2003; but see also Cho, in Chapter 29of this volume, for an extended discussion of the current ways in which privacyissues are being handled in various countries). Hence, it is often claimed that theacquisition of personal and context information needs to be open to the end user,which is, in fact, seldom realized. This means that the user should always have fullknowledge and control over the data that is being collected and that only authorizedpersons and systems can access these.ACKNOWLEDGEMENTSWe should like to thank all our colleagues at EML for the fruitful discussions thathelped to shape the ideas expressed here.REFERENCESBerners-Lee, T., Hendler, J., and Lassila, O. 2001. The semantic web. Scientiﬁc American284(5): 34–45.Beigl, M., Gellersen, H.-W., and Schmidt, A. 2001. Mediacups: Experience with design anduse of computer-augmented everyday artifacts. Computer Networks35: 401–9.Beigl, M., Zimmer, T., and Decker, C. 2002. A location model for communicating and pro-cessing of context. Personal and Ubiquitous Computing6: 341–57.Britt, R. R. 2004. Black Holes Multiply in New Observations. WWW document, http://www.cnn.com/2004/TECH/space/05/31/black.holes/index.html.Chen, H. 2004. SOUPA: Standard Ontology for Ubiquitous and Pervasive Applications. WWWdocument, http://pervasive.semanticweb.org/.Dey, A. K. and Abowd, G. D. 2000. Towards a better understanding of context and con-text awareness. In Proceedings of theCHI 2000 Workshop on the What, Who, Where,When, and How of ContextAwareness,The Hague, Netherlands. New York: Associationof Computing Machinery.Dobson, J. E. and Fisher, P. F. 2003. Geoslavery. IEEE Technology and Society Magazine22: 47–52.Frank, A. U. 1997. Spatial ontology: A geographical information point of view. In O. Stock(ed.) Spatial and Temporal Reasoning. Dordrecht: Kluwer, pp. 135–53.Fonseca, F., Egenhofer, M., Agouris, P., and Câmara, G. 2002. Using ontologies for integratedgeographic information systems. Transactions in GIS6: 231–57.Goßmann, J. and Specht, M. 2002. Location models for augmented environments. Personaland Ubiquitous Computing6: 334–40.Gray, J. 2003. Making grid computing ubiquitous. Unpublished talk presented at GlobusWorld Conference, January 15, San Diego, CA, USA (available at http://research.microsoft.com/~Gray/talks/Open%20Issues%20in%20Grid.ppt).Gray, J. 2004. The next database revolution. In Proceedings of the ACM SIGMOD 2004Conference on Management of Data,Paris, France. New York: Association of ComputingMachinery, pp. 1–4.Joest, M. and Stille, W. 2002. A user-aware tour proposal framework using a hybrid optimization approach. In Proceedings of the Tenth ACM International Symposium onAdvances in Geographic Information Systems,McLean, VA, USA. New York: Associationof Computing Machinery.THO_C34  19/03/2007  11:23  Page 618 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fGEOGRAPHIC INFORMATION SCIENCE: WHERE NEXT?619Kahn, J. M., Katz, R. H., and Pister, K. S. J. 1999. Next century challenges: Mobile net-working for “smart dust.” In Proceedings of the Fifth Annual ACM/IEEE InternationalConference on Mobile Computing and Networking (MobiCom ’99),Seattle, WA, USA.New York: Association of Computing Machinery, pp. 271–8.Kray, C. 2003. Situated Interaction on Spatial Topics.Berlin: AKA Verlag DISKI Series No. 274.Kray, C., Baus, J., and Krüger, A. 2002. Position information and navigation assistance. InJ. Strobl and A. Zipf (eds) Mobile Geoinformation. Heidelberg, Hüthig Verlag, pp. 98–108(in German).Lenat, D. B., Guha, R. V., Pittman, K., Pratt, D., and Shepherd, M. 1990. Cyc: Towardprograms with common sense. Communications of the ACM33: 30–49.Meng, L., Zipf, A., and Reichenbacher, T. (eds). 2004. Map-based Mobile Services: Theories,Methods and Implementations. Heidelberg: Springer-Verlag.NGG2. 2004. Next Generation Grids Report: Final Report by EU Expert Group on NextGeneration Grids. WWW document, http://www.cordis.lu/.Raubal, M., Miller, H., and Bridwell, S.",
    "chunk_order_index": 390,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-adca279206f1dcc70aaa058a0b8b93e5": {
    "tokens": 1200,
    "content": "30–49.Meng, L., Zipf, A., and Reichenbacher, T. (eds). 2004. Map-based Mobile Services: Theories,Methods and Implementations. Heidelberg: Springer-Verlag.NGG2. 2004. Next Generation Grids Report: Final Report by EU Expert Group on NextGeneration Grids. WWW document, http://www.cordis.lu/.Raubal, M., Miller, H., and Bridwell, S. 2004. User centered time geography for location-based services. Geograﬁska Annaler B86: 245–65.Schmidt, A. 2002. Ubiquitous Computing: Computing in Context. Unpublished PhD Dis-sertation, Department of Computer Science, Lancaster University.Smith, M. K., Welty, C., and McGuinness, D. 2003. Owl Web Ontology Language Guide.WWW document, http://www.w3.org/TR/owl-guide/.Tobler, W. R. 1970. A computer movie: Simulation of population change in the Detroit region.Economic Geography46: 234–40.Wang, S., Armstrong, M. P., and Bennett, D. A. 2002. Conceptual basics of middlewaredesign to support grid computing of geographic information. In Proceedings of the SecondInternational Conference on Geographic Information Science,Boulder, CO, USA. SantaBarbara, CA: National Center for Geographic Information and Analysis.Weiser, M. 1991. The computer for the twenty-ﬁrst century. Scientiﬁc American265(3): 94–104.Winter, S. (ed.). 2000. Geographical Domain and Geographical Information Systems.Vienna, Institute for Geoinformation.Winter, S., Raubal, M., and Nothegger, C. 2004. Focalizing measures of salience for routedirections. In A. Zipf, L. Meng, and T. Reichenbacher (eds). Map-based Mobile Services:Theories, Methods, and Implementations. Berlin: Springer, pp. 127–42.Zipf, A. 1998. DEEP MAP: A prototype context sensitive tourism information system forthe city of Heidelberg. In Proceedings of GIS Planet 98, Lisbon, Portugal.Zipf. A. 2002. User-Adaptive Maps for Location-Based Services (LBS) for Tourism. In K. Woeber, A. Frew, M. Hitz (eds) Information and Communication Technologies in Tourism2002. Heidelberg: Springer, pp. 329–38.Zipf, A. 2004. Mobile Anwendungen auf Basis von Geodateninfrastrukturen: von LBS zuUbiGIS. In L. Bernard, J. Fitzke, and R. Wagner (eds) Geodateninfrastrukturen.Heidelberg:Wichmann Verlag, pp. 225–34.Zipf, A. and Aras, H. 2002. Proactive exploitation of the spatial context in LBS throughinteroperable integration of GIS services with a multi agent system (MAS). In Proceedingsof the International Conference on Geographic Information Science of the Association ofGeographic Information Laboratories in Europe,Palma, Spain. Wageningen: Associationof Geographic Information Laboratories in Europe.Zipf, A. and Krüger, S. 2001. TGML – Extending GML by temporal constructs: A proposalfor a spatiotemporal framework in XML. In Proceedings of the Ninth ACM InternationalSymposium on Advances in Geographic Information Systems, Atlanta, GA, USA. NewYork: Association of Computing Machinery, pp. 94–9.THO_C34  19/03/2007  11:23  Page 619 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\faggregation37, 41, 44–5, 97, 99, 359,360, 387–9see alsospatial aggregationair trafﬁc control439–40airborne laser scanning (ALS)150aircraft49, 51, 439–40Akaike’s Information Criterion (AIC)349Alexandria Digital Library (ADL)565alidade505–6allocation515ambiguity45, 80–1, 82American Community Survey43angle498, 504animated map299animation90, 267, 296, 309applications558, 610, 611appropriateness384Arc/Info379, 383, 385, 540ArcGIS65, 379, 383, 544ArcGlobe328ArcIMS574ArcMap379ArcView379, 382–3, 513, 540area boundary5, 10, 37, 44, 54, 500see alsoboundaryareal interpolation45–6see alsointerpolationareas44, 54, 82, 239, 240, 498artiﬁcial environment seevirtualenvironmentartiﬁcial intelligence276, 397, 5972D172, 317GIS319–23, 3252.5Dsurface244view250, 2523D173, 317, 319–23, 599extrusion320GIS320, 322–3, 325, 576–7graphic environments320manifold surface244model252object244view250world317Abstract Data Type (ADT)116, 117,129–30, 131, 138–9accessibility modeling44accuracy56,",
    "chunk_order_index": 391,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-085b341dc8caa9926b2062458fa44eb5": {
    "tokens": 1200,
    "content": "2D172, 317GIS319–23, 3252.5Dsurface244view250, 2523D173, 317, 319–23, 599extrusion320GIS320, 322–3, 325, 576–7graphic environments320manifold surface244model252object244view250world317Abstract Data Type (ADT)116, 117,129–30, 131, 138–9accessibility modeling44accuracy56, 57, 80, 94, 95, 98, 384,516, 598positional80acontextual data522active learning550Adaptive Neuro-Fuzzy Inference System(ANFIS)263address listings45administrative records35, 38, 39–41aerial photography1, 3, 51, 149, 252,469, 532agent234, 367–8, 370agent-based modeling systems436, 438–9IndexTHO_D01-Index  20/03/2007  15:10  Page 620 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINDEX621Artiﬁcial Neural Network (ANN)56, 66,69, 72, 262–3, 357, 397aspect157, 158, 250–2, 419Association of American Geographers(AAG)69, 466, 547Association of Geographic InformationLaboratories in Europe (AGILE)547association rules354, 356, 361spatial361atmospheric air pressure239, 240attribute122attribute information1, 51, 82, 509–13quality56–8audio seesoundaugmented reality311avatar318, 325, 326, 331Avenue380, 383awareness543base maps503, 516see alsotopographic mapsbathymetry5bias80, 98binoculars507biogeography6boundary5, 10, 37, 44, 54, 81, 399,495–6, 500–1, 511, 516crisp259gradual259overlap399–400, 406–7uncertain81, 83, 88–9, 259, 418boundary pixels56browser206brushing295, 383cadastre13, 39, 52–3, 495career543cartographer222, 227, 235cartography6, 63, 64, 69, 199, 222–3,235, 295, 307, 363, 469, 548automated226, 598catchment421–2Cave Automatic Virtual Environment(CAVE)311, 319, 324, 328, 331CD-ROM205Cellular Automata (CA)56, 436, 438–9cellular telephone operators39see alsomobile phonescensus9, 35, 36, 38, 41–3, 494block114data384, 564Census Bureau TIGER16, 17centrality73centroid247–8characteristic function260change of support problem99chi-squared test337choice486, 489choropleth map56, 240–1, 297, 307,391Clark Labs544class85–6, 129, 354, 356, 361hierarchies129–30classiﬁcation44, 53, 56, 97–8, 101,356–7accuracy56data-driven fuzzy262fuzzy6, 259–68neuro-fuzzy262–3spatial361clearinghouses24–5, 26, 456see alsoFGDC clearinghousescluster354, 357, 361, 395–6analysis390, 395–413association399–403change404–11disparities409–11morphology403–4overlap401–3persistence404–11statistics398–9see alsoclusteringclustering53, 301–2, 306, 357, 390fuzzy263–4hierarchical69, 390spatial362, 395–413tools411–13co-kriging162co-location361cognition75–6, 294, 310, 599cognitive science63, 598, 601collaboration447, 456–7, 484, 486collection81, 129collective interactive computing324–5color76, 266, 292ﬁll249, 251hue250, 251saturation251scheme249, 250THO_D01-Index  20/03/2007  15:10  Page 621 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f622INDEXcommunication368, 459community470–1, 472–4, 481, 494, 550completeness95complex objects129component planes66computational techniques63, 69, 307Computer Aided Design (CAD)113, 117,318, 320, 322, 544Computer Aided Geometric Design (CAG",
    "chunk_order_index": 392,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-7cfe78a7e88a025bd0362f66c8519bef": {
    "tokens": 1200,
    "content": "-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f622INDEXcommunication368, 459community470–1, 472–4, 481, 494, 550completeness95complex objects129component planes66computational techniques63, 69, 307Computer Aided Design (CAD)113, 117,318, 320, 322, 544Computer Aided Geometric Design (CAGD)244Computer Aided Manufacturing (CAM)113computer graphics247computer science63, 69, 294, 386, 598,610concept61–2, 114, 558, 610, 611–13concept graph296, 303, 305concept hierarchy354, 359see alsoconcept graphConditional AutoRegression (CAR)347conﬁdence interval340conﬁdentiality40, 41, 44, 45, 521conﬂation188–92, 262conﬂict481confusionindex266matrix101consortia447, 456–7constructor129Content Standard for Digital GeospatialMetadata (CSDGM)21–2context-awareness614–15context model54contingency table101continuous population survey43continuousﬁeld83gradient90phenomenon239surface46contour map248–9contours145, 148–9, 150, 239, 241–4,251color ﬁlled249, 251derived from a DEM157convex hull231cooperation447, 456–7coordinate systems52, 119, 379, 384–6,516geographic385projected385copyright14core81, 89coupling382–33coverage39curse of dimensionality161curvature250–2data11aggregation521, 526–8availability11, 565–6cleaning354displays62, 295distribution17encapsulation130exploration62, 305, 383integration383–4, 611licensing15management15, 383–4model111multivariate292–4pre-processing354projection296protection40, 520, 521quality10, 95–6reduction296, 354repositories62selection354semi-structured64surveillance seedataveillancestructured64, 70transfer14unstructured64, 70–1utility96see alsogeographic data and spatial datadata cube355–6, 360Data Deﬁnition Language (DDL)124Data Modiﬁcation Language (DML)124,125Data Mining (DM)63, 180, 293, 311,353–5data warehousing355–8database language112DataBase Management Systems (DBMS)6, 109, 111fuzzy object-oriented10, 84–5object-oriented (OODBMS)6, 83–4,109, 111–13, 116, 122, 129–30object-relational (ORDBMS)6, 109,113, 116–17, 122, 130–41relational (RDBMS)6, 83–4, 109,111–13, 114, 121–9THO_D01-Index  20/03/2007  15:10  Page 622 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINDEX623spatial (SDBMS)83, 113, 116–21,131–41transactional355dataveillance522, 528, 533daytime locations37decision-making447, 455, 481–91, 521,550, 563, 597decision tree57, 300–1declassiﬁcation51defuzziﬁcation266Delauney triangulation244see alsoTriangulated Irregular NetworkDemographic Data Viewer12derivatives245, 250–2design485, 488–9Differential GPS (DGPS)508–9, 531see alsoGPS methodsDigital Earth557, 596, 604–6Digital Elevation Model (DEM)3, 109,144–67, 239, 241–4, 246, 417,418, 427–8, 429accuracy157interpolation150–5quality156–8, 427–8regular grid145resolution155–6, 427–8, 429digital image analysis57Digital Landscape Model (DLM)224,226digital libraries565–6digital representation11, 44–6digital scanning49digitization97dimensionality reduction69, 72–5, 295,310disaggregation97, 99discriminant analysis386displacement52distance61, 76, 120, 292, 498, 504distance courses544distance-similarity metaphor75–6distortion52distributed computing599distributed environment587distributed GIS568–9distributed infrastructures364domain expert276, 283drainage152analysis157connectivity145, 152enforcement algorithm152draping250–2dwelling unit36dynamicdisplays267GIS436–41; see alsotemporal GISmaps310modeling173user591e-government12, 25, 562, 564Earth sciences49Earth’s surface49, 111, 144echo sounding49ecological fallacy37ecological modeling147education448, 540–53educational institutions542electoral registration39electromagnetic radiation",
    "chunk_order_index": 393,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-5946833b1a1df8bc776cfe5e3fa70910": {
    "tokens": 1200,
    "content": "152analysis157connectivity145, 152enforcement algorithm152draping250–2dwelling unit36dynamicdisplays267GIS436–41; see alsotemporal GISmaps310modeling173user591e-government12, 25, 562, 564Earth sciences49Earth’s surface49, 111, 144echo sounding49ecological fallacy37ecological modeling147education448, 540–53educational institutions542electoral registration39electromagnetic radiation49electronic atlas203–4Electronic Distance Measurement (EDM)device506–7elevation144–67, 239, 241, 418, 508see alsoterrain elevationenergy usage44environmental data6, 56environmental modeling144, 158–62,404, 417Environmental Systems Research Institute(ESRI)31–2, 380, 382, 437, 544entity81, 114cultural53spectral53error52, 56, 80, 89, 94–5, 149, 158,159, 259, 340, 386, 427, 508matrix101of commission56, 57, 101of omission56, 57, 101propagation94roundoff386ethics520, 521–2ethnicity495ethnography276Euclidean space121, 358Exploratory Data Analysis (EDA)349Exploratory Spatial Data Analysis (ESDA)395, 396, 403, 411eXtensible Markup Language (XML)70–1, 369, 571THO_D01-Index  20/03/2007  15:10  Page 623 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f624INDEXextractingareas52–4attribute information55–8data186–7lines54–5points54–5spatial information52–5urban road networks54–5family unit36feasibility489feature81, 82atomic88connected88distributed88extraction97homogeneous88inhomogeneous88labels74federalagencies12government15, 17policy15Federal Geographic Data Committee(FGDC)9, 12, 19–25, 452, 457–8, 565FGDC clearinghouses9, 24–5see alsoclearinghousesFGDC standards20see alsostandardsﬁeld56, 88, 133, 240File Transfer Protocol (FTP)205ﬁltering97, 154–5ﬁrst law of cognitive geography75–6ﬁtness for use95–6, 97, 103fractals603frequency histogram158fuzziﬁcation261, 262fuzzy10aggregation operators261classiﬁcation259–68classiﬁcation with a priori knowledge260–2c-means (FCM) algorithm263clustering262, 263–4data-driven classiﬁcation262–3interpolation264–5k-means seefuzzy c-meanslogic259, 260, 262, 281–7, 424–5mapping259–68maximum operator284–5minimum operator283–4rule-based models261–2rules26, 281–7set260, 262set theory259visualization265–7Geary statistic57generalization6, 130, 222–35, 354algorithms227–30cartographic224–6conceptual models226–7functional228methods227–30model224rule-based230–3of spatial databases224genetic algorithms56, 397geocomputation1, 347geographic data6, 64acquisition6, 12, 599availability11distribution6licensing14marketplace13production6providers12see alsospatial dataGeographic Data Mining (GDM)7, 277,352–64, 599see alsoGeographic KnowledgeDiscovery, Data Mining and SpatialData MiningGeographic Information Science (GISc)1,10, 61, 63, 77, 144, 273, 317–19,325, 328, 352, 373–4, 436, 519,541, 546, 557–8, 559, 581,596–606, 609–18research agendas596, 597–602grand challenges596, 604–6, 609Geographic Information Systems (GIS)1, 11, 35, 64, 69, 73, 81, 94, 109,113–14, 169, 170, 188, 199, 232,239, 244, 259, 273, 309, 311, 320,337, 364, 380, 381, 383, 386, 436,450–1, 466, 469–70, 481, 513–16,520, 540, 557, 583, 609raster-based83, 176, 497temporal169, 172vector-based83, 176, 497geographic information services7THO_D01-Index  20/03/2007  15:10  Page 624 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/",
    "chunk_order_index": 394,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-be36abf2f49b2570353f4745c55c4e29": {
    "tokens": 1200,
    "content": "-based83, 176, 497temporal169, 172vector-based83, 176, 497geographic information services7THO_D01-Index  20/03/2007  15:10  Page 624 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINDEX625geographic information technologies7Geographic Knowledge Discovery (GKD)7, 352–3, 358–64see alsoGeographic Data MiningGeographic Markup Language (GML)185, 371geographic metaphors62geographic visualization seegeovisualizationGeographical Analysis Machine (GAM)348, 386, 387, 403Geographically Weighted Regression(GWR)346, 347, 349, 389,390–1, 603geography548Geography Network12, 31–2GeoInformatics1GeoMedia544geometric correction52geometric distortion52GeoProcessing1georeferencing36, 45Geospatial Data Clearinghouses seeclearinghousesGeospatial Data Mining seeGeographicData MiningGeospatial One-Stop (GOS)9, 12, 25–6geospatial semantic web7, 367–76see alsosemantic webgeostatistics98, 109, 158–62, 380, 602geovisualization62–3, 328, 363, 469,599see alsovisualizationGetis-Ord statistic57–8GI partnering449, 456–60GI Science seeGeographic InformationScienceGIS certiﬁcation546GIS clearinghouses see clearinghousesGIS curriculum542, 547–9GIS data market12, 14GIS data portals12GIS education540–54international545–6GIS professional development542, 543–6GIS software companies12, 542, 544Global Positioning Systems (GPS)1, 3,148, 217, 268, 352, 367, 385, 498,505, 507–13, 516, 521, 531, 583,585, 588–9, 598Global Spatial Data Infrastructure (GSDI)452, 456, 457–8Global Ubiquitous Computing610, 612,617government agencies542GPS data collection509–13GPS methods507–13assisted GPS531carrier phase GPS509differential code-phase GPS508–9, 531unaided code-phase GPS507–8GPS transect walk469graph67, 71, 296, 303, 305graph theory228graph layout algorithms73graphicdesign294techniques295variables75Graphic Interchange Format (GIF)205,570grid145, 173, 241, 616spacing145see alsoresolutionGrid Computing (GC)616–17ground data collection44group collaboration support methods488Group Decision Support Systems (GDSS)482–3haptic296, 309health records3, 39hedonic modeling381–2height seeelevationheight ﬁeld241–3, 246hierarchical tree67, 73, 296higher education542, 547–8hillshading246, 251histogram300, 301home location528–9homomorphism51household35–7, 41Human-Computer Interaction (HCI)63,235, 319, 483, 613hydro-ecological modeling147hydrology5, 144, 147, 152, 157, 426hypermap204hypermedia200, 203–4hypertext200HyperText Mark-up Language (HTML)203, 560, 569THO_D01-Index  20/03/2007  15:10  Page 625 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f626INDEXHyperText Transfer Protocol (HTTP)569hypothesisgeneration305–6, 353testing339–40, 348identity theft525IDRISI90, 540, 544illumination292, 309image114processing188see alsoremotely sensed imageryimmersion317, 323–4imprecision82, 84imputation of missing values44in-car navigation systems3, 583independent observations337, 338, 386indexing113, 131indicator geostatistics101individual36inference6, 37, 222, 337–50, 395Bayesian338, 342–5classical338, 339–42, 386computational approach338, 347–8key concepts338process model338, 347spatial346–9task338inferential framework338, 339–45, 349information353–4, 582Information and CommunicationTechnologies (ICT)582information and library science63, 69information management techniques487inheritance116, 130INSPIRE457–8instance129institutional GIS449, 450–5barriers454–5beneﬁts454–5implementation451–3monitoring status451–3integratingvector and imagery188–91maps and imagery191–2spatial and temporal data193–4,436–41intelligence485, 486–7Intelligent Transportation Systems (ITS)529",
    "chunk_order_index": 395,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-4a1a0dcc3353e17d4f0d161f6c12d58a": {
    "tokens": 1200,
    "content": "ICT)582information and library science63, 69information management techniques487inheritance116, 130INSPIRE457–8instance129institutional GIS449, 450–5barriers454–5beneﬁts454–5implementation451–3monitoring status451–3integratingvector and imagery188–91maps and imagery191–2spatial and temporal data193–4,436–41intelligence485, 486–7Intelligent Transportation Systems (ITS)529–30interactive maps6, 564interaction6, 62, 293, 318, 323–4,575–7interestingness354–5Intergraph544International Cartographic Association(ICA)311, 599–600International Society for Photogrammetryand Remote Sensing (ISPRS)600Internet17, 200–1, 205, 324, 367–76,455, 469–70, 474–5, 522, 557,559–79, 583Internet GIS see web-based GISinteroperability19, 110, 131, 185, 371,570–1, 587, 599, 603interpolation45–6, 97–8, 148, 149,150–5, 157, 243–4, 247, 264–5,320, 388, 391, 419, 602interview276, 502, 516Inverse Distance Weighting (IDW)150isoline map248–9isolines239, 240, 241–4Kohonen map seeSelf-Organizing Mapknowledge353–4acquisition276–7, 283construction62, 354elicitation335–6engineer276semantic353syntactic353Knowledge Discovery from Databases(KDD)6, 9, 61, 63, 180, 277,311, 353–5, 599kriging100, 150, 158–62, 264detrended159regression159land cover51, 55, 100, 101, 263–4, 513land surface144land surveying498land use44, 51, 512–13, 515, 516landform classiﬁcation423–7LANDSAT540landscape144, 417, 423, 495landscape interpolationsee alsointerpolation74language368laser49latitude119, 385, 508law519–38layer85–6, 322, 329, 515THO_D01-Index  20/03/2007  15:10  Page 626 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINDEX627Level Of Detail (LOD)246Light Detection and Ranging (LiDAR)1,3, 242line simpliﬁcation97lineage95lines44, 54, 82, 239, 498linking295local governments15–16, 452, 456, 562Local Indicators of Spatial Autocorrelation(LISA)398–9, 403, 408, 603local regression57local spatial statistical measures57–8local surface patches151locally adaptive gridding151–4, 162location1–2, 61, 384–6, 588–90, 617Location-Aware Technologies (LAT)352,364, 583, 616location-awareness583Location-Based Services (LBS)7, 217–18,364, 374, 526, 535, 557, 581–94,613, 614, 615applications591–3logicBoolean277–80, 285–8fuzzy259, 260, 262, 281–8operators278–9, 283–4logical consistency95longitude119, 385, 508low orbit spacecraft51m-commerce seemobile commercemachine learning186, 293, 311macro language380–1, 383, 391magnetic compass504–5Management Association for PrivatePhotogrammetric Surveyors(MAPPS)32–3map4, 51, 300, 496–7metaphor172map comparison problem399–403map cube360–1map generalization222–37automated223rule-based230–3MapInfo379, 513, 540, 544Map Machine12map projection379, 384–6, 516Map Store12mappingpredictive273–6rule-based273–90mapping organization11market research surveys43marketing527marketplace12–14measurement97–8technologies501–7medical information6, 40membership81, 85–7, 260degree86function9, 260, 261, 277–8, 281–3,348partial81mental map469meta-mining359metadata9, 13–14, 21, 185, 367, 565–6,587metric120–1mixed pixels (mixels)56, 259mobilecommerce592computing268, 598, 615devices216–18, 530–1, 582GIS584phones3, 216, 530–1, 582–3, 589–90,617Modiﬁable Areal Unit Problem (MAUP)37, 99, 240, 359, 386Monte Carlo simulation341, 345, 347,426Moran’s I57, 398motion292, 318",
    "chunk_order_index": 396,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6ff2aaa118b69f0cd4dd0751b0494621": {
    "tokens": 1200,
    "content": "259mobilecommerce592computing268, 598, 615devices216–18, 530–1, 582GIS584phones3, 216, 530–1, 582–3, 589–90,617Modiﬁable Areal Unit Problem (MAUP)37, 99, 240, 359, 386Monte Carlo simulation341, 345, 347,426Moran’s I57, 398motion292, 318multi-agent systems234multi-resolution segmentation53multi-scaledatabases226segmentation53multi-user worlds325MultiDimensional Scaling (MDS)66, 72multimedia113, 199, 204, 359, 363–4,469cartography218information system (MMIS)117multiple criteria choice models490multiplebivariate views300linked displays4, 296virtual worlds319multiple hypothesis testing348–9multiple inheritance85multiple representation226–7, 598multiple testing411THO_D01-Index  20/03/2007  15:10  Page 627 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f628INDEXmultivariatedata analysis293–4statistics65, 109, 145, 158–62, 293,389visualization6, 65, 292–312National Atlas12, 30–1National Center for GeographicInformation Analysis (NCGIA)466, 481, 546, 547, 597–8National Map9, 12, 16, 27–30National Mapping Agency223National Spatial Data Infrastructure(NSDI)9, 12, 19–25, 352, 452,457–8, 615national statistical organizations45natural resource management49navigable views252–4navigation322–3, 329, 584–5, 592, 617neighborhood36–7, 41network67, 173citation67, 72, 73communication6displays75–6graph71transportation6, 173neural network seeartiﬁcial neural networkNew Information and CommunicationTechnologies (NICT)583–5, 592night-time population37non-georeferenced data67non-spatial analysis57object81, 83, 114, 129, 439ﬁxed89ﬂuid89fuzzy spatial89identity (OID)129–30moving89permanent89solid89three-dimensional89two-dimensional89variable89object-orientation437–8, 598object-oriented query languages130object-oriented software paradigm116Object Query Language (OQL)112, 130object relationship modeling53observing users276OnLine Analytical Processing (OLAP)136, 355–6, 360online data sources186–7OnLine Transaction Processing (OLTP)136ontology35, 62, 169, 170–2, 296, 305,369–70, 371, 372–3, 374–5, 418,439, 565, 599, 603, 612creation374–5ﬁeld-based170–1, 173integration375languages370, 612management374–5object-based170–1, 173spatio-temporal171–2, 439temporal171, 612Ontology Web Language (OWL)370,372, 612Open Data Consortium33Open Geospatial Consortium seeOpen GISConsortiumOpen GIS Consortium (OGIS or OGC)12, 19, 85, 117, 131, 137, 185,311, 371, 374, 569, 570–4, 612,617open standards570–4Open Web Services (OWS)571–2, 612operations on spatial objects119–21directional120dynamic121set-oriented120topological120optical effects76optochemical photography49, 52Oracle138, 139Ordnance Survey15, 384orientation120outlier354, 357, 361, 383spatial362paper maps11, 222–3, 226parallel algorithms364Parallel Coordinate Plot (PCP)65, 296,299–300participation470–1, 494participatory decision-making7, 447,481–91frameworks485–6macro-micro485, 486–7methods486–91see alsodecision-makingTHO_D01-Index  20/03/2007  15:10  Page 628 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINDEX629participatory GI Science468Participatory GIS (PGIS) seePublicParticipatory (PPGIS)participatory methods469–70Pathﬁnder Network Scaling (PFN)73pattern54, 61, 292, 305–6, 353, 361,389multivariate64spatial see spatial patternpattern matching399–403pattern recognition396–8people544–5perception75, 292, 294, 310personal data40Personal Digital Assistant (PDA)582–3,584, 589personal privacy448, 459, 519–38, 618see alsoprivacypersonal taxation39",
    "chunk_order_index": 397,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-dcd7dec2b42c0f136e2be01331f5d1af": {
    "tokens": 1200,
    "content": "PFN)73pattern54, 61, 292, 305–6, 353, 361,389multivariate64spatial see spatial patternpattern matching399–403pattern recognition396–8people544–5perception75, 292, 294, 310personal data40Personal Digital Assistant (PDA)582–3,584, 589personal privacy448, 459, 519–38, 618see alsoprivacypersonal taxation39perspective89, 292view250photograph51planar metric51planar topology51plane table505–6planning471–2planning agency452, 457platforms558, 610, 611, 615–17point44, 54, 82, 239, 240, 498, 500,512, 516point displays75–6point-in-polygon384point pattern analysis45policy448political acceptability41politics471polymorphism116population35–48census2, 3, 65; see alsocensusdensity239, 240, 248, 346ﬂow37, 41listing39register39threshold size41positioning615–16post-analysis389–91postal services39, 45precision80, 95, 98, 385–6double385–6single385–6prediction356–7spatial361preprocessing63, 69Principal Component Analysis (PCA)389–90principal coordinate plot65privacylegislation522–6, 532–3, 535of information520, 521risk531–3see alsopersonal privacyPrivacy-Enhancing Technologies (PET)532Privacy-Invasive Technologies (PIT)532Privacy-Sympathetic Technologies (PST)532probability distribution functions94–107process-based modeling439progressive shading90projection seemap projectionproperty tax39prototype analysis276proximity348, 358, 515psychology63public agencies453public domain15public participation7, 447, 449, 455,481, 563Public Participatory GIS (PPGIS)447,466–76, 494deﬁnition467–9implementation471–5methods469–71tools484public spatial data infrastructure seespatial data infrastructurepublic transportation44publicly funded data sources11quantitativeanalysis7, 548methods379–92query language111, 116, 117, 131, 169queries373, 562–5for LBS590–1see alsospatial queriesR382radar49THO_D01-Index  20/03/2007  15:10  Page 629 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f630INDEXradiation49absorbed49emitted49reﬂected49transmitted49radiometric correction52randomization41, 44raster99, 116, 359, 379, 498raw data14real estate13reconnaissance tools49reference interval functions240, 247–8reference station507reference systems120see alsocoordinate systemsreﬂection49region displays75–6regulation519relation114, 122degree of122relational instance122relational schema122, 124Remote Sensing (RS)9, 49–60, 262, 273,352, 404, 502, 516, 544, 598active49instruments50passive49platforms50, 51satellites50remotely senseddata43–4, 49–60, 599elevation data149–50, 154–5imagery1, 3, 49–60; see also satelliteimageryrendering248–50, 307, 320representationof query results90of spatial data82residential migration43residential postal address39residuals382, 389resolution89, 384spatial37, 50, 51, 56, 145, 242,385–6, 420, 429–31spectral51temporal50Resource Description Framework (RDF)369, 370, 372, 612review486rolling census model43rounding41, 44rubber-sheeting188rule-based linking53rule-based mapping6, 273–90fuzzy261–2rules261–2, 273–90, 361Boolean277–80, 285–7encoding277–87extraction276–7fuzzy281–7run-off426–7sampling97–8, 241–2satellite49, 367, 507imagery2, 51, 111, 188–92, 252, 469, 540; see alsoremotely sensedimageryremotely sensed images1, 3Scalable Vector Graphic (SVG)564, 575scale6, 61, 82, 89, 97, 99, 145, 222,223, 388, 418, 420, 429–31, 516,599scanned maps206, 208scatterplot65, 300, 306, 307scatterplot matrix300–1schema70sea-level144Seamless Data Distribution System28–9secondary data sets44segmentation53, 67, 71Self-Organizing Map (SOM)66, 69, 72,302self-regulation519semantic gap114semantic geoinformation611–13Semantic Import (SI)",
    "chunk_order_index": 398,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-2378792b229a11b5404264f4b184e53f": {
    "tokens": 1200,
    "content": "420, 429–31, 516,599scanned maps206, 208scatterplot65, 300, 306, 307scatterplot matrix300–1schema70sea-level144Seamless Data Distribution System28–9secondary data sets44segmentation53, 67, 71Self-Organizing Map (SOM)66, 69, 72,302self-regulation519semantic gap114semantic geoinformation611–13Semantic Import (SI)260, 281semantic interoperability603, 612semantic web367–76, 612see alsogeospatial semantic websemantics170, 368, 375setBoolean81classical81crisp81, 84fuzzy81, 84, 260theory81settlement extent44sextant506shaded relief157shapeﬁle382Shuttle Radar Topography Mission(SRTM)149THO_D01-Index  20/03/2007  15:10  Page 630 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINDEX631signiﬁcance339–40Similarity Relation (SR)260skeletonization228sketch map469, 502, 516slope250–2, 419, 423small areas41SNAP171, 172snapshot82, 173, 437social data9, 35–48aggregation37, 38attribute detail38ease of access38entities36–7representation44–6sources38–44uncertainty44society466–76, 599, 601, 617–18socio-economic characteristics37socio-economic GIS37soilerosion modeling421–3mapping423–7soil-landscape model423–4sonar scanning52sound49, 90, 267, 296, 309, 359spaceconceptualization62representation62three-dimensional121SpaceStat383SPAN171spatial aggregation38, 359, 360, 387–9see alsoaggregationspatial analysis3, 7, 46, 224, 228, 311,352, 364, 548, 597, 599Spatial Analyst382spatial association rules361spatial autocorrelation57, 99, 159, 347,386–7, 398–9, 602–3Spatial AutoRegression (SAR)347spatial bias44spatial classiﬁcation361–2spatial clustering7, 348, 362, 395–413see alsocluster and clusteringspatial data1–6, 9, 80, 94, 337, 346–9,353, 386–7acquisition1–2, 599displaying4formats185integration185–95, 383–4, 599management109, 383–4portal372properties379–80quality6, 10, 82, 95–107, 418, 427–8,598sets2–3standards17storage2, 82source565–6transmission2types117–19utility96see alsogeographic dataSpatial Data Cartridge138Spatial Data Infrastructure (SDI)12,449–50, 456, 457–8, 612, 613, 615Spatial Data Mining (SDM)353, 361–3see alsoGeographic Data MiningSpatial Data Transfer Standard (SDTS)17spatial data warehousing359–61spatial decision support systems (SDSS)49, 483–4, 598spatial dependency101, 103, 347, 358,386, 398spatial frame of reference111spatial heterogeneity603see alsospatial non-stationarityspatial index117spatial inference see inferencespatial interpolation seeinterpolationspatial kernel248spatial layout69, 72–5spatial metaphors6, 9, 61–79spatial non-stationarity347, 358spatial objects44, 119–21, 358spatial operations117see alsooperations on spatial objectsspatial outliers362, 386spatial overlay172spatial pattern94, 242, 307, 346, 361,381, 382, 389, 396–8, 401see alsopatternspatial prediction362spatial process94spatial reference384–6spatial regression383spatial relationships597spatial queries84, 90–1, 111, 591fuzzy84, 90spatial signal detection57spatial statistics9, 352, 383, 515, 548,597THO_D01-Index  20/03/2007  15:10  Page 631 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f632INDEXspatial transformations359spatialization9, 61–79, 309spatially encoded video1, 3spatio-temporalanalysis169concepts169data mining178–80, 364data modeling109, 169–70, 172–8,437, 598logic169integration193–4ontology109, 170–2, 439queries109, 170, 175,",
    "chunk_order_index": 399,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-6ec9529b0a6d0a4449096492af9c475d": {
    "tokens": 1200,
    "content": "OA articles are governed by the applicable Creative Commons License\f632INDEXspatial transformations359spatialization9, 61–79, 309spatially encoded video1, 3spatio-temporalanalysis169concepts169data mining178–80, 364data modeling109, 169–70, 172–8,437, 598logic169integration193–4ontology109, 170–2, 439queries109, 170, 175, 178–80representation109, 169–70, 172–8techniques62specialization130, 354spectralcharacteristics54signature54space57splines158–62SPOT155, 540spring models73SPSS380, 381, 389spurious sinks157SQL queries125–9, 134–7standards9, 17–18, 311, 570–1, 617see alsoFGDC standardsstatistical analysis4–5, 294, 311, 380conﬁrmatory4exploratory5statistical inference seeinferencestatistical pattern recognition396–8statistics243, 386, 397, 598stereoscopic interpretation149stochastic information systems103storm prediction440–1streamlines148–9, 150street centerlines19structured-group process techniques488Structured Query Language (SQL)112,116, 123–9, 131–41object-relational137–41spatial131–7surface speciﬁc point elevation147–8,150surface6, 44, 239–55, 292, 320, 322,417derivatives250–2, 419modeling239, 241–8polygonal244–7processes144reconstruction244representation239, 240–1visualization239, 246, 248–54surveillance522, 528, 529–30survey1–2, 9, 35, 38, 43, 494–517symbol construction296Synthetic Aperture Radar (SAR)149, 155systemdevelopment454–5effectiveness454efﬁciency454equity/empowerment/engagement454–5table114, 122, 125tactile feedback see haptictaxonomy296, 369, 372of objects with uncertain boundaries88–9teaching with GIS549–53telecommunication networks589–90telecommunication services528–9TeleGeoInformatics588teletext201–2televisionhyperlinked203two-way interactive203temporal data82, 169, 437temporal dimension31, 317temporal GIS169–81see alsodynamictemporal trend300territory495–501, 516terrainanalysis144–67, 417–31attributes418–20data quality427–8elevation7, 100, 144–67modeling244, 420–7see alsoelevationtessellation240thematic mapping41, 56, 297, 503theodolite506–7Thiessen polygons244see alsoVoronoi polygonsthinking aloud276time6, 89, 109, 169–81, 359, 406–7,436–41, 598, 599time-stamping173, 438, 439time geography437, 439THO_D01-Index  20/03/2007  15:10  Page 632 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\fINDEX633Tobler’s First Law (TFL) of Geography64, 75, 386, 602–3, 615topographic data147sources147–50topographicmaps11modeling158see alsobase mapstopographic wetness420, 426topological property120topological space121topology120, 239Total Station506–7tracking526, 528, 592communications530–1individuals529–30, 588transactions530trafﬁc ﬂow3, 44, 562training540, 542transport GIS562treemap73trend354, 361Triangulated Irregular Network (TIN)145, 148, 239, 244, 246–7triangulation150–1, 188tuple114, 122type129ubiquitous cartography218Ubiquitous Computing (UC)218, 613,616Ubiquitous GI Services (UbiGIS)613–15uncertainty4, 6, 9, 44, 80–93, 94–107,259, 286, 395, 418, 428, 599, 603attribute99–102conceptual96modeling10, 82–9positional90, 99–102propagation95, 101, 103quantiﬁcation94–107representation82–9standards95sources97–9visualization265–7Uniﬁed Modeling Language (UML)117Uniform Resource Identiﬁer (URI)369,373Uniform Resource Locator (URL)569Universal Soil Loss Equation (USLE)421–3Universal Transverse Mercator (UTM)133, 384–5University Consortium for GeographicInformation Science (UCGIS)459,546, 547, 598–9Urban and Regional Information SystemsAssociation (URISA)468–9, 544US Geological Survey (USGS)11, 30, 565usability75–6,",
    "chunk_order_index": 400,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-87752018f9385c03b7660da52f1b7614": {
    "tokens": 954,
    "content": "ﬁer (URI)369,373Uniform Resource Locator (URL)569Universal Soil Loss Equation (USLE)421–3Universal Transverse Mercator (UTM)133, 384–5University Consortium for GeographicInformation Science (UCGIS)459,546, 547, 598–9Urban and Regional Information SystemsAssociation (URISA)468–9, 544US Geological Survey (USGS)11, 30, 565usability75–6, 590, 599user-centred design294users373, 454utility5, 95utility companies39vagueness80–1, 82validating results305–6value-added data14variogram101, 159, 263vector99, 102, 116, 188–9, 359, 379,498layer114space121vector-to-raster conversion97vegetation cover149, 264vegetation information56Verbal Protocol Analysis (VPA)276versioning89video359video graphics310videodisc204videotext201–2virtualenvironment317, 319, 322, 469space318, 319–23Virtual Reality (VR)218, 252–4, 317–33environments319–23headset323–4, 325, 331media319, 323–7theater324, 331wireless325Virtual Reality Modeling Language(VRML)322, 576–7Visual Basic (VBA)383visual data mining357–8visualillusion298–9properties292representation296–7variables294, 298–9, 307, 309THO_D01-Index  20/03/2007  15:10  Page 633 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\f634INDEXvisualization3, 6, 63, 235, 248–54,292–312, 318, 357, 360, 390–1,397, 597, 599–600cartographic64, 599dynamic266–7examples297–305fuzzy265–6geographic seegeovisualizationhierarchical303–4immersive311, 317; see alsoVirtualRealityinformation63, 296interactive293–4methods295–7, 306multivariate292–312scientiﬁc63, 363systems307–10tasks305–7techniques see visualization methodsweb562–5, 575–7Voronoi polygons228, 244see alsoThiessen polygonswatershed421–2wavelengthsmicrowave49middle infra-red49thermal infra-red49visible49wayﬁnding581, 584–5, 592web-based GIS557, 559–79, 584web-based mapping system14web-based marketplaces12webarchitectures569, 570atlases213–14cartography206downloadable data stores211–12GI retrieval technology578GIS seeweb-based GISinformation services212, 611maps560–2, 570map and image collections210–11map generation services212–13mapping199, 206–16protocols569querying562–5search engines578sites12street-directories213–14travel information resources215–16tools544Web Feature Server (WFS)573–4Web Map Services (WMS)572–3WGS84385wireless216–18, 582–3, 584, 615communications530–1, 568GIS584Wireless Application Protocol (WAP)218World Wide Web (WWW)7, 199,200–1, 206, 367–8, 557, 559–79,582, 598, 611World Wide Web Consortium (W3C)368, 369, 370, 374Xgobi383zip code45zoning388THO_D01-Index  20/03/2007  15:10  Page 634 Downloaded from https://onlinelibrary.wiley.com/doi/ by University Of Texas Libraries, Wiley Online Library on [11/06/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License",
    "chunk_order_index": 401,
    "full_doc_id": "doc-f23ec0acc52d9c0e29db07c2cc8b0c27"
  },
  "chunk-c6236e2b749a509a77a24ebfbabd4a08": {
    "tokens": 1028,
    "content": "Professional Experience and Learning Pathways\nThe interviewee described a progression from academic exposure to spatial clustering concepts in university geography courses, to hands-on, applied learning in industry settings. The most significant practical learning occurred through real-world projects, where proprietary and open-source clustering techniques were used collaboratively with data scientists and GIS professionals. Mastery was developed by iterating between formal education, organizational best practices, and software toolsets for spatial analysis.\n\nCore Knowledge for Spatial Clustering\nDomain knowledge is foundational. For spatial clustering to provide value, the analyst must deeply understand the specific characteristics that define desirable clusters for the application domain (e.g., bank site selection, transportation safety).\n\nStatistical and mathematical concepts (distributional assumptions, spatial autocorrelation, hypothesis testing) are important, but secondary to domain-driven criteria. Robust tools are relied upon to enforce statistical rigor, while analysts concentrate on defining meaningful parameters and attributes.\n\nClustering tool selection is less important than articulating what needs to be solved. The primary challenge is to match analytical approaches to the decision context, not to master every algorithmic nuance.\n\nAcquiring and Applying Domain Expertise\nWhen facing unfamiliar problems, domain knowledge is acquired through:\n\nParticipating in discussions with subject-matter experts.\n\nReviewing feedback from field surveys, stakeholders, and iterative project meetings.\n\nAbsorbing organizational lessons from past cases, both successful and unsuccessful, to understand implicit criteria for clustering quality.\n\nDefining Success in Spatial Clustering\nIn business-driven settings, the definition of a successful cluster is determined by up-front criteria set by decision-makers. Analysts elicit these requirements through targeted conversations, translating them into operational metrics (e.g., high-end retail density within a catchment area).\n\nIn exploratory or less-structured contexts (such as national transportation safety analysis), the primary goal is to surface clusters that reveal systemic, non-random problems. Success is gauged by the relevance and actionability of the questions that emerge from clustering results, not merely statistical metrics.\n\nMetrics are context-specific and often straightforward: simple counts, densities, or rates normalized by appropriate denominators (e.g., incidents per traffic volume). Advanced statistical diagnostics are useful but are typically subsidiary to decision relevance.\n\nTypical Analytical Workflow\nA generalizable workflow for complex spatial clustering projects includes:\n\nInitial awareness: Stakeholders discover new analytical possibilities (e.g., via a spatial statistics workshop or demonstration).\n\nMotivation: The need for in-house, consistent evaluation standards drives project initiation, particularly when existing reporting systems are inconsistent or fragmented across jurisdictions.\n\nIterative tool application: Multiple clustering methods (e.g., DBSCAN, HDBSCAN, OPTICS) are tested to compare outputs and understand their interpretive strengths and weaknesses.\n\nFocused method selection: Methods are narrowed to those offering the clearest interpretability and alignment with user needs (e.g., OPTICS for its diagnostic charts and parameter transparency).\n\nManual validation and refinement: Results are reviewed in detail to identify data limitations, artifacts, and to refine analytical units (e.g., running clustering by highway segment to prevent spurious merging of unrelated features).\n\nLayered analysis: Clustering outputs are complemented with hotspot or rate-based analyses to construct multi-criteria “zones of concern” that integrate multiple perspectives.\n\nCommunication and feedback: Analysts cycle between analytical work and engagement with decision-makers, refining both criteria and outputs until results are robust and actionable.\n\nOrganization of Analytical Methods\nClustering methods are conceptualized as:\n\nDescriptive analysis: Tools to reveal and label existing spatial patterns (density-based clustering, hotspot analysis, spatiotemporal clustering).\n\nPrescriptive analysis: Tools designed to recommend optimal solutions or partitions based on predefined criteria (e.g., build balanced zones).\n\nFurther organization is based on the analytical target:\n\nLocation-based clustering: Grouping based solely on spatial proximity.\n\nAttribute-based clustering: Grouping based on feature characteristics or normalized rates.\n\nSpatiotemporal clustering: Incorporating both spatial and temporal dimensions.\n\nThe distinction between “statistical” and “machine learning” clustering is considered partly a matter of industry convention or marketing, rather than a fundamental analytical divide. The key practical difference is whether clustering is justified through formal significance testing (null hypothesis, p-values, Z-scores) or through data-driven, algorithmic exploration with interpretable diagnostics.\n\nAnalyst Skill Requirements\nEffective spatial clustering demands:\n\nStrong domain engagement: Ability to communicate with stakeholders, elicit relevant success criteria, and interpret real-world significance.\n\nAnalytical rigor: Confidence in applying and validating clustering methods, interpreting both statistical and practical quality of results.\n\nIterative synthesis: The analyst must navigate between defining questions with decision-makers and implementing/validating methods independently, ensuring outputs meet both mathematical and contextual standards.\n\nAdditional Insights\nReal-world use cases highlight that well-defined problems (e.g., business site selection) benefit from structured, criteria-driven clustering, while open-ended exploratory analyses (e.g., identifying traffic safety issues) rely on the analyst’s ability to surface meaningful patterns and generate relevant hypotheses.\n\nPractical evaluation often depends more on visual inspection and stakeholder feedback than on formal quantitative metrics.\n\nTool limitations (e.g., difficulty clustering along complex networks) are addressed through iterative problem decomposition and customized analytical units.",
    "chunk_order_index": 0,
    "full_doc_id": "doc-c6236e2b749a509a77a24ebfbabd4a08"
  }
}