2
2
0
2

r
p
A
7

]

G
L
.
s
c
[

2
v
3
8
7
5
1
.
3
0
1
2
:
v
i
X
r
a

Multiscale Clustering of Hyperspectral Images Through
Spectral-Spatial Diﬀusion Geometry

Sam L. Polk∗ and James M. Murphy

Department of Mathematics, Tufts University

Abstract

Clustering algorithms partition a dataset into groups of similar points. The primary contribution
of this article is the Multiscale Spatially-Regularized Diﬀusion Learning (M-SRDL) clustering algorithm,
which uses spatially-regularized diﬀusion distances to eﬃciently and accurately learn multiple scales of
latent structure in hyperspectral images. The M-SRDL clustering algorithm extracts clusterings at many
scales from a hyperspectral image and outputs these clusterings’ variation of information-barycenter as
an exemplar for all underlying cluster structure. We show that incorporating spatial regularization
into a multiscale clustering framework results in smoother and more coherent clusters when applied to
hyperspectral data, yielding more accurate clustering labels.

Keywords: Clustering, Diﬀusion Geometry, Hierarchical Clustering, Hyperspectral Imagery, Unsupervised
Machine Learning

1

Introduction

Hyperspectral images (HSIs) are datasets storing reﬂectance at many electromagnetic bands. HSIs provide
a rich characterization of a scene, enabling the precise discrimination of materials based on variations within
pixels’ spectral signatures. Indeed, success at material discrimination using HSIs has led to hyperspectral
imagery’s emergence as an important data source in remote sensing [1]. However, HSIs are generated in large
quantities, making manual analysis is infeasible. Moreover, HSIs are very high-dimensional and typically
encode multiple scales of latent structure, ranging from coarse to ﬁne in scale [2, 3, 4, 5]. Thus, eﬃcient
algorithms are needed to automatically learn multiscale structure from HSIs.

The main contribution of this article is the Multiscale Spatially-Regularized Diﬀusion Learning (M-
SRDL) algorithm, which is a multiscale extension of the Spatially-Regularized Diﬀusion Learning (SRDL)
algorithm [6]. SRDL uses spatially-regularized diﬀusion distances to eﬃciently extract a ﬁxed scale of cluster
structure from an HSI [6]. To learn multiscale structure from an HSI, M-SRDL varies a diﬀusion time
parameter in SRDL [2]. M-SRDL then ﬁnds the variation of information (VI)-barycenter of the extracted
clusterings: the partition of the HSI that best represents all scales of learned cluster structure [2, 7]. In this
sense, M-SRDL suggests multiple clusterings at diﬀerent scales in addition to the one that best represents
all underlying multiscale structure.

We organize this article in the following way. Background on unsupervised learning, diﬀusion geome-
try, and spatial regularization is provided in Section 2. M-SRDL is introduced in Section 3. Numerical
experiments are presented in Section 4, and conclusions are given in Section 5.

∗Corresponding Author. Present Address: 503 Boston Avenue, Medford, MA, USA.
Email Addresses:
Funding Statement: This work is funded in part by US National Science Foundation grants NSF-CCF 1934553, NSF-DMS
1924513, and NSF-DMS 1912737.

Samuel.Polk@Tufts.edu (Sam L. Polk), JM.Murphy@Tufts.edu (James M. Murphy)

1

 
 
 
 
 
 
2 Background

i=1 ⊂ RD (interpreted as a point cloud, where n is the num-
A clustering algorithm partitions an HSI X = {xi}n
ber of pixels and D is the number of spectral bands) into clusters of data points, denoted X1, X2, . . . , XK [8].
The partition C = {Xk}K
k=1 is called a clustering of X, and each pixel may be assigned a unique label cor-
responding to its Xk. In a good clustering of X, data from the same cluster are “similar,” while data from
diﬀerent clusters are “dissimilar.” The speciﬁc notion of similarity between points varies across the many
clustering algorithms in the literature [3, 4, 5, 8, 9, 10].

2.1 Background on Diﬀusion Geometry

Data-dependent, diﬀusion-based mappings are highly eﬀective at capturing an HSI’s intrinsic low dimension-
ality [11, 12]. These methods treat data points as nodes in an undirected graph. Edges between points are
2/σ2), where σ is a scale parameter reﬂecting the interac-
encoded in a weight matrix: Wij = exp(−(cid:107)xi − xj(cid:107)2
tion radius between points. Deﬁne the Markov transition matrix for a random walk on X by P = D−1W ,
where Dii = (cid:80)n
j=1 Wij. Assuming P ∈ Rn×n is reversible, aperiodic, and irreducible, there exists a unique
q ∈ R1×n satisfying qP = q. Denote (right) eigenvector-eigenvalue pairs of P by {(ψi, λi)}n
i=1, sorted so
that 1 = |λ1| > |λ2| ≥ . . . |λn| ≥ 0. The ﬁrst K eigenvectors of P tend to concentrate on the K most
highly-connected components of the underlying graph, making them useful for clustering.

Diﬀusion distances, deﬁned for xi, xj ∈ X at time t ≥ 0 by

Dt(xi, xj) =

(cid:118)
(cid:117)
(cid:117)
(cid:116)

n
(cid:88)

k=1

|(P t)ik − (P t)jk|2
qk

,

are a data-dependent distance metric well-suited to the clustering problem [2, 9]. If clusters are well-separated
and coherent, within-cluster diﬀusion distances will be small relative to between-cluster diﬀusion distances [9].
The diﬀusion map Ψt(x) = (ψ1(x), |λ2|tψ2(x), . . . , |λn|tψn(x)) is a closely related concept [11, 12]. Indeed,
diﬀusion distances can be identiﬁed as Euclidean distances in a data-dependent feature space consisting of
diﬀusion map coordinates: Dt(x, y) = (cid:107)Ψt(x) − Ψt(y)(cid:107)2 [11].

The time parameter t is linked to the scale of structure that can be separated using diﬀusion distances [2,
11, 12]. Small t enables the detection of ﬁne-scale local structure, while larger t enables the detection of
macro-scale global structures. Thus, the diﬀusion time parameter may be varied to learn the rich multiscale
structure encoded in HSI data [2].

2.2 The SRDL Clustering Algorithm

Nearby HSI pixels tend to come from the same cluster. Thus, incorporating spatial geometry (where pixels
are located within the HSI) into a clustering algorithm may result in smoother clusters [6, 13, 14]. The SRDL
algorithm (Algorithm 1) modiﬁes the graph underlying P to directly incorporate spatial geometry into the
diﬀusion process [6]. More precisely, each x is connected to its N (cid:96)2-nearest neighbors, chosen from pixels
within a (2R1 + 1) × (2R1 + 1) spatial square centered at x in the original image, where R1 ∈ N is called the
graph spatial window. Thus, nearby pixels may have edges between them, but pixels from diﬀerent segments
of the image will not. Diﬀusion distances computed using this modiﬁed graph are called spatially-regularized
diﬀusion distances [6].

Fix t ≥ 0 so that there is a single scale of latent cluster structure to be learned. Let p(x) be a kernel

density estimator (KDE) capturing empirical density:

p(x) =

1
Z

(cid:88)

y∈N NN (x)

(cid:18)

exp

−

(cid:107)x − y(cid:107)2
2
σ2
0

(cid:19)

,

where N NN (x) is the set of the N points in X closest to x in (cid:96)2-distance, σ0 is a KDE bandwidth, and Z
is a normalization constant so that (cid:80)

x∈X p(x) = 1. Let ρt(x) be deﬁned as

ρt(x) =

(cid:40)

maxy∈X Dt(x, y)
miny∈X {Dt(x, y)|p(y) ≥ p(x)}

x = argmaxy∈X p(y),
otherwise.

2

Algorithm 1: Spatially-Regularized Diﬀusion Learning (SRDL) clustering algorithm [6]

Input: X (data), t (time step), N (# nearest neighbors) σ (scale parameter),

σ0 (KDE bandwidth), R1 (graph spatial window), R2 (consensus spatial window)

Output: C (clustering), K (# clusters)

1 Build KNN graph with N (cid:96)2-nearest neighbors within a graph spatial window R1 > 0. Weight edges

according to a Gaussian kernel with scale parameter σ. Compute P from this graph;

2 Compute Dt(x) = p(x)ρt(x), where p(x) and ρt(x) are computed as described in Section 2.2;
3 Solve K = argmin1≤k≤n−1 Dt(xmk )/Dt(xmk+1), where {xmk }n

k=1 is a sorting of the points in X

according to Dt(x) in non-increasing order. Label data modes C(xmk ) = k for k = 1, . . . , K;
4 Labeling Stage 1 : In order of non-increasing p(x), for each x ∈ X, ﬁnd x∗ and C(s)(x) (if it exists),
as described in Section 2.2. If C(s)(x) exists but C(x∗) (cid:54)= C(s)(x), skip x in Labeling Stage 1.
Otherwise set C(x) = C(x∗);

5 Labeling Stage 2 : In order of non-increasing p(x), for each x ∈ X, ﬁnd x∗ and C(s)(x) (if it exists),
as described in Section 2.2. If C(s)(x) exists, set C(x) = C(s)(x). Otherwise, set C(x) = C(x∗).

Thus, ρt(x) returns the diﬀusion distance at time t between x and its Dt-nearest neighbor of higher density,
capturing diﬀusion geometry underlying the HSI. Maximizers of Dt(x) := p(x)ρt(x) are, thus, points with
large p-values (i.e., high density) and large ρt-values (i.e., high diﬀusion distances from any other high-density
points). These maximizers are deﬁned as data modes and are assigned unique cluster labels.

SRDL labels non-modal points in two stages. In Labeling Stage 1, for each non-modal point x ∈ X, SRDL
ﬁnds x∗ = argminy∈X {Dt(x, y) | C(y) (cid:54)= 0 ∧ p(y) ≥ p(x)}: the Dt-nearest neighbor of x that is higher density
and already labeled. SRDL then establishes the spatial consensus label of x, denoted C(s)(x). Namely, C(s)(x)
is the majority label among the labeled spatial neighbors of x located within a (2R2 + 1) × (2R2 + 1) spatial
square centered at x in the original image, where R2 ∈ N is a consensus spatial window that is typically
smaller than the graph spatial window used to generate P . SRDL assigns C(x) = C(x∗) unless C(s)(x) exists
and diﬀers from C(x∗). In this case, x is skipped in Labeling Stage 1. In Labeling Stage 2, each unlabeled
point is given its spatial consensus label (if one exists). If not, SRDL assigns the label of the Dt-nearest
neighbor that is higher-density and already labeled.

3 The M-SRDL Clustering Algorithm

SRDL has been shown to be eﬀective on a number of synthetic and real HSIs [6], but it is limited in that
it focuses on a single clustering scale. In this section, we introduce a multiscale extension of SRDL, which
we call the Multiscale Spatially-Regularized Diﬀusion Learning (M-SRDL) clustering algorithm (provided
in Algorithm 2). M-SRDL implements SRDL at an exponential range of time scales t ∈ {0, 1, 2, 22, . . . , 2T },
where T = (cid:100)log2[log|λ2(P )|(
Dt(x, y) ≤ τ . Hence,
τ (cid:28) 1 can be interpreted as a threshold for how small diﬀusion distances are allowed to become before termi-
nating cluster analysis. Importantly, since M-SRDL uses SRDL to extract clusterings, spatial regularization
is incorporated into label assignments at all scales.

min(q) )](cid:101). This cut-oﬀ is chosen so that, if t ≥ 2T , max

x,y∈X

2τ

After extracting multiscale cluster structure from the HSI, M-SRDL solves Ct∗ = argmin

u∈J V I(Ct, Cu),
2 )(cid:9) is the set of time steps during which SRDL extracts nontrivial clusterings of X
where J = (cid:8)ti|Kti ∈ [2, n
and V I is the variation of information (VI) distance metric between clusterings of X [7]. The clustering Ct∗
can be interpreted as the V I-barycenter of nontrivial clusterings generated by SRDL. Thus, M-SRDL inte-
grates information gained from spatially-regularized partitions at multiple scales into a single representative
clustering of X [2, 6].

t∈J

(cid:80)

3

Algorithm 2: Multiscale Spatially-Regularized Diﬀusion Learning (M-SRDL) clustering algorithm

Input: X (data), τ (threshold) σ (scale parameter), σ0 (KDE bandwidth),
R1 (graph spatial window), R2 (consensus spatial window)
Output: Ct∗ (optimal clustering), Kt∗ (no. clusters)

1 Build KNN graph with N (cid:96)2-nearest neighbors within a graph spatial window of R1 > 0. Weight
edges according to a Gaussian kernel with scale parameter σ. Compute P and q from this graph;

2 Compute T = (cid:100)log2[log|λ2(P )|(

2τ

min(q) )](cid:101). For each time step ti ∈ {0, 1, 2, 22, . . . , 2T }, calculate

[Cti, Kti] = SRDL(X, ti, N, σ, σ0, R1, R2);

3 For each t ∈ J = (cid:8)t(cid:12)
4 Solve Ct∗ = argmin{V I (tot)(Ct) | t ∈ J} and let Kt∗ be the number of clusters in Ct∗ ;

2 )(cid:9), calculate V I (tot)(Ct) = (cid:80)

u∈J V I(Ct, Cu) ;

(cid:12)Kti ∈ [2, n

4 Numerical Experiments

In this section, we present analysis of M-SRDL on the real-world Salinas A HSI (Fig. 1) [15], which was
generated by the Airborne Visible/Infrared Imaging Spectrometer over farmland in Salinas Valley, California,
USA. This HSI encodes 224 spectral bands across an 83 × 86 image.

In Fig. 3, we evaluate M-SRDL on the Salinas A HSI and compare its clusterings against those of the
M-LUND algorithm [2]. M-LUND is a multiscale extension of the LUND algorithm [9], which is identical
to SRDL except that LUND does not include spatial regularization into its predictions. More precisely,
LUND relies on a standard KNN graph to build P and does not use spatial consensus to label non-modal
points. M-LUND learns multiscale structure from X by varying the input t of LUND and outputs the
V I-barycenter of learned nontrivial cluster structure as a clustering exemplar. Thus, the one diﬀerence
between these two algorithms and their predictions is that M-SRDL incorporates spatial geometry into its
labeling and M-LUND does not. If spatial regularization changes neither λ2(P ) nor min(q), M-SRDL and
M-LUND have identical computational complexity [2, 6]. M-SRDL and M-LUND were implemented using
the same parameters N = 100, σ = 1.30, σ0 = 3.6 × 10−3, and τ = 10−5. For M-SRDL, we set R1 = 12
and R2 = 0. Thus, spatial consensus labels were not used, and the numerical experiments presented in this
section may be considered an ablation study for the use of spatially-regularized diﬀusion distances in the
setting of multiscale clustering.

Both M-LUND and M-SRDL successfully extracted multiscale structure from the HSI (Fig. 3). Indeed,
clusters are observed to merge as t increases, reﬂecting that fewer diﬀusion map coordinates contribute to
diﬀusion distances. However, spatial regularization clearly improved spatial smoothness of clusters, especially
near cluster boundaries in the 1st and 2nd columns of Fig. 3. Indeed, while M-LUND assigned noisy labels to
cluster boundaries, the spatial separation between clusters was strong for M-SRDL clusterings. Both methods
assigned the coarsest clustering (Kt∗ = 2 for M-LUND and Kt∗ = 3 for M-SRDL) as V I-barycenters. The
normalized mutual information [7] between these clusterings and the ground truth labels were 0.3016 for
M-SRDL and 0.2836 for M-LUND respectively. Thus, spatial regularization resulted in a partition closer to
the ground truth labels.

Figure 1: Ground truth labels and
spectra of a random sample of pix-
els from the Salinas A HSI [15].

4

50100150200Spectral Band Number-0.00500.0050.010.0150.020.025Recorded ReflectanceFigure 3: Multiscale cluster structure learned by M-LUND [2] and M-SRDL from the Salinas A HSI. Spatial
regularization yields smoother clusters, especially near cluster boundaries.

We provide software to replicate our numerical experiments in the following GitHub repository:

https://github.com/sampolk/MultiscaleDiﬀusionClustering.

5 Conclusions

We conclude that spatially-regularized diﬀusion geometry is well-equipped for ﬁnding latent multiscale struc-
ture in high-dimensional images like HSIs and that spatial regularization improves cluster coherence. Future
work includes extending past performance guarantees for M-LUND [2] to account for spatial regularization,
which we observe improves the spatial coherence of cluster structure in the Salinas A HSI. Additionally, M-
SRDL allows for diﬀerent spatial radii (graph and consensus), and analysis is needed on the interplay between
these in M-SRDL’s outputs. Finally, we expect that M-SRDL can be adapted for active learning, wherein a
carefully chosen subset of pixels are queried for ground truth labels and exploited for semi-supervised label
propagation to the entire HSI [14, 16, 17, 18].

References

[1] M. Eismann, Hyperspectral Remote Sensing, SPIE Press, 2012.

[2] J. M. Murphy and S. L. Polk, “A multiscale environment for learning by diﬀusion,” Appl Comput Harm

Anal, vol. 57, pp. 58–100, 2022.

[3] N. Gillis, D. Kuang, and H. Park, “Hierarchical clustering of hyperspectral images using rank-two
nonnegative matrix factorization,” IEEE Trans. Geosci. Remote Sens., vol. 53, no. 4, pp. 2066–2078,
2014.

5

[4] H. Yu, L. Gao, W. Liao, B. Zhang, A. Piˇzurica, and W. Philips, “Multiscale superpixel-level subspace-
based support vector machines for hyperspectral image classiﬁcation,” IEEE Geosci. Remote. Sens.
Lett., vol. 14, no. 11, pp. 2142–2146, 2017.

[5] S. Lee and M.M. Crawford, “Hierarchical clustering approach for unsupervised image classiﬁcation of

hyperspectral data,” in IGARSS. IEEE, 2004, vol. 2, pp. 941–944.

[6] J. M. Murphy and M. Maggioni, “Spectral-spatial diﬀusion geometry for hyperspectral image cluster-

ing,” IEEE Geosci. Remote. Sens. Lett., vol. 17, no. 7, pp. 1243–1247, 2020.

[7] M. Meil˘a, “Comparing clusterings–an information based distance,” J. Multivar. Anal., vol. 98, no. 5,

pp. 873–895, 2007.

[8] J. Friedman, T. Hastie, and R. Tibshirani, The Elements of Statistical Learning, vol. 1, Springer Ser.

Stat., 2001.

[9] M. Maggioni and J. M. Murphy, “Learning by unsupervised nonlinear diﬀusion,” J. Mach. Learn. Res.,

vol. 20, no. 160, pp. 1–56, 2019.

[10] Z. Meng, E. Merkurjev, A. Koniges, and A.L. Bertozzi, “Hyperspectral video analysis using graph

clustering methods,” Image Process. Line, vol. 7, pp. 218–245, 2017.

[11] R. R. Coifman and S. Lafon, “Diﬀusion maps,” Appl. Comput. Harmon. Anal., vol. 21, no. 1, pp. 5–30,

2006.

[12] R. R. Coifman, S. Lafon, A. B. Lee, M. Maggioni, B. Nadler, F. Warner, and S. W. Zucker, “Geometric
diﬀusions as a tool for harmonic analysis and structure deﬁnition of data: diﬀusion maps,” Proc. Natl.
Acad. Sci. U.S.A., vol. 102, no. 21, pp. 7426–7431, 2005.

[13] Y. Tarabalka, J. A. Benediktsson, and J. Chanussot, “Spectral-spatial classiﬁcation of hyperspectral
imagery based on partitional clustering techniques,” IEEE Trans. Geosci. Remote Sens., vol. 47, no. 8,
pp. 2973–2987, 2009.

[14] J. M. Murphy, “Spatially regularized active diﬀusion learning for high-dimensional images,” Pattern

Recognit. Lett., vol. 135, pp. 213–220, 2020.

[15] J. A. Gualtieri, S. R. Chettri, R. F. Cromp, and L. F. Johnson, “Support vector machine classiﬁers as

applied to AVIRIS data,” in JPL Airborne Geosci., 1999, pp. 217–227.

[16] M. Maggioni and J. M. Murphy, “Learning by active nonlinear diﬀusion,” Found. Data Sci., vol. 1, no.

3, pp. 271, 2019.

[17] J. M. Murphy and M. Maggioni, “Unsupervised clustering and active learning of hyperspectral images
with nonlinear diﬀusion,” IEEE Trans. Geosci. Remote Sens., vol. 57, no. 3, pp. 1829–1845, 2019.

[18] Z. Zhang, E. Pasolli, M. M. Crawford, and J. C. Tilton, “An active learning framework for hyperspectral
image classiﬁcation using hierarchical segmentation,” IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.,
vol. 9, no. 2, pp. 640–654, 2015.

6

