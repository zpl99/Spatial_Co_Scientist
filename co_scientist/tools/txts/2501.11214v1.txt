MITIGATING SPATIAL DISPARITY IN URBAN PREDICTION USING
RESIDUAL-AWARE SPATIOTEMPORAL GRAPH NEURAL
NETWORKS: A CHICAGO CASE STUDY

5
2
0
2

n
a
J

0
2

]

G
L
.
s
c
[

1
v
4
1
2
1
1
.
1
0
5
2
:
v
i
X
r
a

Dingyi Zhuang
Department of Civil and Environmental Engineering
Massachusetts Institute of Technology
Cambridge, MA 02139, USA
dingyi@mit.edu

Hanyong Xu
Department of Urban Studies and Planning
Massachusetts Institute of Technology
Cambridge, MA 02139, USA
hanyongx@mit.edu

Xiaotong Guo
Department of Civil and Environmental Engineering
Massachusetts Institute of Technology
Cambridge, MA 02139, USA
xtguo@mit.edu

Yunhan Zheng
Singapore–MIT Alliance for Research
and Technology Centre (SMART)
Singapore 138602
yunhan@mit.edu

Shenhao Wang
Department of Urban and Regional Planning
University of Florida
Gainesville, Florida, USA
shenhaowang@ufl.edu

Jinhua Zhao
Department of Urban Studies and Planning
Massachusetts Institute of Technology
Cambridge, MA 02139, USA
jinhua@mit.edu

January 22, 2025

ABSTRACT

Urban prediction tasks, such as forecasting traffic flow, temperature, and crime rates, are crucial
for efficient urban planning and management. However, existing Spatiotemporal Graph Neural
Networks (ST-GNNs) often rely solely on accuracy, overlooking spatial and demographic disparities
in their predictions. This oversight can lead to imbalanced resource allocation and exacerbate existing
inequities in urban areas. This study introduces a Residual-Aware Attention (RAA) Block and an
equality-enhancing loss function to address these disparities. By adapting the adjacency matrix during
training and incorporating spatial disparity metrics, our approach aims to reduce local segregation of
residuals and errors. We applied our methodology to urban prediction tasks in Chicago, utilizing a
travel demand dataset as an example. Our model achieved a 48% significant improvement in fairness
metrics with only a 9% increase in error metrics. Spatial analysis of residual distributions revealed
that models with RAA Blocks produced more equitable prediction results, particularly by reducing
errors clustered in central regions. Attention maps demonstrated the model’s ability to dynamically
adjust focus, leading to more balanced predictions. Case studies of various community areas in
Chicago further illustrated the effectiveness of our approach in addressing spatial and demographic
disparities, supporting more balanced and equitable urban planning and policy-making.

1

Introduction

Urban prediction tasks involve predicting various urban indicators (e.g., traffic flow, temperature, etc.) using urban big
data. These predictions are crucial for understanding urban patterns, which in turn benefit urban public administration
and transportation management (Wang et al., 2024a). Recent studies have applied various machine learning and deep
learning techniques to improve prediction accuracies in downstream tasks such as travel demand forecasting, crime

 
 
 
 
 
 
A PREPRINT - JANUARY 22, 2025

prediction, accident prediction, and weather forecasting (Derrow-Pinion et al., 2021; Fu et al., 2020; Mehrabi et al.,
2022). These enhanced prediction models not only aid in more efficient resource allocation and policy-making but
also play a vital role in addressing challenges related to urbanization, such as congestion, safety, and environmental
sustainability.

Among these methods, Spatiotemporal Graph Neural Networks (ST-GNNs) have become prominent tools for urban
prediction in various domains. ST-GNNs integrate the capabilities of Graph Neural Networks (GNNs) with architectures
designed to process sequential temporal data. This combination makes ST-GNNs particularly effective at capturing
both spatial and temporal dependencies in urban data. Thus, ST-GNNs are able to model the intricate relationships
between different urban regions and time points, providing significant advantages over traditional methods in delivering
more accurate and reliable forecasts.

A significant issue with previous ST-GNN models is their exclusive reliance on accuracy as the primary metric for
evaluating model performance, without considering the potential social impact of the model’s predictions. Figure 1
illustrates that the model STGCN’s predictions are positively correlated with minority rates in Chicago Yu et al. (2018).
This correlation is evidenced by positive residuals in regions with high minority rates and over-predictions in regions
with low minority rates. This discrepancy reveals distinct spatial patterns in over-prediction and under-prediction,
highlighting the spatial disparities inherent in the model’s predictions. These spatial disparities are intrinsically linked
to demographic disparities and segregation phenomena. See Figure 1b, in the Chicago region, different racial groups
predominantly reside in the northern and southern parts of the city, exacerbating the impact of demographic segregation
on the model’s performance.

There are two primary sources of disparity in ST-GNN model predictions: systematic sociodemographic biases in
data collection and inherent model biases in ST-GNNs that propagate these data biases. Disparities stemming from
data collection biases, such as over-policing in minority neighborhoods, result in higher bias in urban data (Franklin
et al., 2024). For example, crime reporting disparities often arise not from higher crime rates but from focused police
surveillance in certain communities. These data collection biases are inherently difficult to mitigate. However, models
that focus solely on prediction accuracy can amplify these biases, leading to over-prediction of crime events and
attracting even more surveillance, thereby exacerbating the disparity (Dong et al., 2022).

To mitigate these disparities and achieve equality, previous work has integrated demographic information into the model
design. The majority of models use demographic information as auxiliary information within the model architecture
and loss function designs (Zhang et al., 2023a) during training ST-GNN models. However, in practice, factors such as
privacy and regulation often preclude the collection of protected features or their use for training or inference, severely
limiting the applicability of traditional fairness research. Moreover, models trained with demographic information
directly use this data to guide the training, without fully addressing where the disparity originates within the ST-GNN
model, such as the message-passing mechanism (Zheng et al., 2023a). Therefore, we ask: How can we train an
ST-GNN based urban prediction model to improve equality when we do not even know the protected group
memberships?

In this paper, we address algorithmic equality and reduce prediction disparities by focusing on model design without
incorporating external demographic information. We aim to mitigate spatial disparities from ST-GNN models, reduce
spatial segregation, and thus address demographic disparities. Our methodology includes the Residual-Aware Attention
(RAA) Block and an equality-enhancing loss function. The RAA Block adapts the adjacency matrix during training
to dynamically adjust spatial relationships based on residuals, reducing local segregation of errors. The equality-
enhancing loss function integrates the mean squared error with terms that penalize similar residual patterns in adjacent
neighborhoods and incorporate spatial clustering or information redundancy metrics like Moran’s I or Generalized
Entropy Index (GEI). This approach identifies and mitigates the sources of disparity within the model itself, ensuring
urban prediction models do not further entrench existing inequities, thus supporting more balanced and just urban
planning and policy-making.

We conducted a case study on urban prediction tasks in Chicago using datasets including travel demand, crime,
and accident reports. Our model achieved a 48% significant improvement in fairness metrics while only incurring
a 9% increase in error metrics. Spatial analysis of residual distributions revealed that models with RAA Blocks
produced more equitable prediction results, particularly by reducing errors clustered in central regions. Case studies
of different community areas demonstrated how the attention mechanism within the RAA Block effectively adjusted
focus to address spatial and demographic disparities. The attention maps illustrated that our model identifies and
emphasizes relationships between regions with similar characteristics, leading to more balanced predictions. Overall, our
methodology significantly reduces disparities in urban prediction models with minimal impact on accuracy, supporting
more equitable urban planning and policy-making.

Our contributions are summarized as follows:

2

A PREPRINT - JANUARY 22, 2025

(a) STGCN Prediction Residual in Chicago.

(b) Minority Rate in Chicago

Figure 1: Comparison between prediction residual and demographic distributions. (a): the red colors represent under-
prediction while the blue colors represent over-prediction; (b): distribution of the racial minority groups in Chicago,
defined as the percentage of the non-white population in each community area.

1. We introduce residuals as indicators of fairness in predictions, demonstrating their utility in highlighting

disparities in ST-GNN model outputs.

2. We design the RAA Block and propose an equality-enhancing loss function that incorporates spatial and
demographic disparity metrics. This function balances prediction accuracy with fairness, ensuring that urban
prediction models do not entrench existing spatial disparities. We modify the message-passing mechanism in
GNNs to ensure the propagation of information that reduces bias.

3. We conduct a comprehensive case study applying our method to urban prediction tasks in Chicago using a
travel demand dataset as an example. Our model identifies and mitigates prediction disparities without relying
on demographic data, leading to more balanced resource allocation and fairer urban planning decisions.

2 Literature Review

2.1 Urban Prediction with GNNs

In recent years, with the advancement of GNN representing spatial data as graphs and its superiority of capturing
both spatial and temporal dependencies, we have seen more research in using GNNs to make predictions in the urban
computing context Jin et al. (2023a); Ye et al. (2022). One major field of application is within transportation. Various
studies leverage GNNs to make demand predictions in the context of ride-hailing Ke et al. (2017); Wang et al. (2019);
Ye et al. (2021); Geng et al. (2019); Wang et al. (2021b); Jin et al. (2022, 2020). For example, Wang et al. (2019) solves
the Origin-Destination Matrix Problem via introducing grid-embedding and multi-task learning modules to capture both
spatial and temporal attributes. Jin et al. (2020) leverages graph convolutional neural networks in combination with
pixel-level representations to capture the joint latent distribution of ride-hailing demands. Other kinds of prediction
focus on traffic incident Yu et al. (2021); Jin et al. (2023b); Wang et al. (2021a), travel time Fang et al. (2020); Huang
et al. (2022), human mobility Wang et al. (2021c), traffic flow Yang et al. (2024); Lu et al. (2022); Tian et al. (2023); Wu
et al. (2021); Fang et al. (2021), and trajectory Peng et al. (2021); Mohamed et al. (2020); Liu et al. (2022); Sighencea
et al. (2023). Yu et al. (2021) proposed a framework combining spatial graph convolutional network, spatiotemporal
standard convolutions, and the embedding layers to capture spatiotemporal and external features for traffic accident
prediction. (Wang et al., 2021c) incorporated multimodal-driven heterogeneous mobility information network and
external event-driven memory-augmented dynamic filter generator into the ST-Net to understand crowd movements.
(Derrow-Pinion et al., 2021) utilized GNNs into real-world ETA estimation in Google Maps, improving the model
application with design and operation strategies such as Meta-Gradients and semi-supervised training. Fang et al. (2021)
improved GNNs’ depth and capacity in order to extract long-range spatiotemporal dependencies while leveraging both
spatial and semantic neighbor nodes in traffic flow prediction.

3

42024Demand Prediction Residual20406080Racial Minority Ratio (%)A PREPRINT - JANUARY 22, 2025

Apart from prosperous applications in transportation, GNNs are also well developed in many other fields in urban
computing such as public safety and environment Jin et al. (2023a). GNNs have been popular in crime prediction due
to the spatiotemporal correlations of crime incidences Xia et al. (2021); Sun et al. (2022); Zhang and Cheng (2020);
Wang et al. (2022). Specifically, Zhang and Cheng (2020) introduced a framework with a gated network and localized
diffusion network to explain both temporal and spatial propagations in network-level crime prediction. Wang et al.
(2022) designed a network combining an adaptive region graph learning module, a homophily-aware constraint, and a
gated recurrent unit in the diffusion layer that learns correlations based on both distance and crime pattern similarities.
In remote sensing, Zhou et al. (2023) proposed a Siamese graph convolutional network to detect urban multi-class
change. Similarly, GNNs also embraced a wide adoption in the field of atmospheric and disaster predictions Liang et al.
(2018); Zhou et al. (2021); Farahmand et al. (2023).

Despite the abundance usage of the usage of GNNs in urban computation, existing research only focus on reaching better
prediction accuracy levels and ignores the prediction unfairness issues resulting from the algorithm designs.

2.2 Algorithmic Fairness
It is widely accepted that there are two different fairness goals, namely equality and equity Mehrabi et al. (2022). The
former describes each unit of analysis receiving the same amount of resources, while the latter describes each unit of
analysis as given enough resources for them to succeed Mehrabi et al. (2022). Similarly, in transportation, there are
vertical equity and horizontal equity describing the same concepts Litman (2023); Yan and Howe (2020). These binary
end goals are evaluated through either Disparate Treatment Analysis, which seeks fair treatment, or Disparate Impact
Analysis, which aims for fair impact or results Mehrabi et al. (2022); Pessach and Shmueli (2022); Caton and Haas
(2020), in algorithmic fairness literature. In this study, we will adopt equality or horizontal equity as our end goal,
aiming for similar treatment for all people and focusing on the equitable sharing of public resources. To evaluate the
disparities, we will focus on prediction residuals, the most straightforward measure to reflect under-prediction and
over-prediction treatments of the algorithm (Kallus and Zhou, 2018).

There are two lines of thought under the umbrella of the Disparate Treatment Analysis: fairness through awareness and
fairness through unawareness Mehrabi et al. (2022). The former describes achieving similar level results regardless
of protected attribute usage during the modeling process, while the latter avoids using such attributes in the decision-
making process Dwork et al. (2012); Kusner et al. (2017); Grgic-Hlacˇa et al.. In the field of transportation systems,
there have been emerging studies analyzing and mitigating algorithmic disparities. Zheng et al. (2021) highlighted
the unfairness in Deep Neural Networks and Discrete Choice Models and proposed a disparity mitigation solution
using absolute correlation regularization. Studies by Zheng et al. (2023b), Zhang et al. (2023b), and Guo et al. (2023)
addressed demand prediction fairness in ride-hailing and aimed to improve group fairness in prediction results, while the
latter also considers downstream operational impacts. However, they all sought to achieve fairness through awareness
by integrating demographic information within the model design, without addressing the origin of disparity within
the ST-GNN model, such as the message-passing mechanism. Furthermore, privacy and regulation issues often limit
the collection and use of protected features for training or inference, reducing the applicability of traditional fairness
research. Hence, we explore options to achieve fairness through unawareness in our model design.

3 Problem Description and Preliminaries

3.1 ST-GNN for Forecasting
We mathematically formulate ST-GNNs in this context as they are extensively utilized in urban prediction tasks Wu
et al. (2021); Zhuang et al. (2022); Han et al. (2019); Kong et al. (2020). Let the graph be denoted as G = (V, E, A),
where V represents the set of nodes (locations/regions), E denotes the set of edges, and A ∈ R|V|×|V| is the adjacency
matrix that describes the relationships between nodes.

In this study, we utilize spatiotemporal data collected at the city level, defining regions or census tracts as nodes, and
establishing edges based on the geographic distances between regions. Consequently, the adjacency matrix A reflects
the geographical affinities of the regions, with shorter distances indicating larger adjacency values.
We denote the urban spatiotemporal dataset inputs as X ∈ R|V|×t, where t is the number of time steps. The objective is
to predict the target value Y1:|V|,t:t+k for the future k time steps, given all past data up to time t, denoted as X1:|V|,1:t.
The goal of the ST-GNN models is to design a model fθ, parametrized by θ, such that:
ˆY1:|V|,t:t+k = fθ(X1:|V|,1:t; G) = fθ(X1:|V|,1:t; V, E, A),

(1)

where ˆY1:|V|,t:t+k is the predicted target value, typically X1:|V|,t:t+k in forecasting tasks. The performance of the
forecasting results is measured using residual-based metrics such as Root Mean Squared Error (RMSE) and Mean
Absolute Error (MAE). The prediction residuals are defined as r1:|V|,t:t+k = Y1:|V|,t:t+k − ˆY1:|V|,t:t+k. We denote

4

A PREPRINT - JANUARY 22, 2025

r1:|V|,t:t+k as r for short. The loss function used to optimize the model during training aims to minimize RMSE or
MAE to ensure prediction accuracy.

However, few studies have examined whether these accuracy-oriented approaches are equitable for urban planning.
Prediction biases may vary across different spatial regions or demographic groups, potentially leading to inequitable
transportation management and urban planning.

3.2 Measurement of Disparity in ST-GNN Prediction Results
The most straightforward measurement of disparities in ST-GNN prediction results is the prediction residuals. Disparities
are defined in terms of spatial and demographic factors.

Our models consider spatial disparities in order to address demographic disparities. Spatial disparity refers to the
prediction residuals exhibiting similar over-prediction or under-prediction patterns within local neighborhoods, resulting
in significant differences across the global space. For instance, the central of Chicago is consistently over-predicted
while the southern part is under-predicted, as shown in Figure 1a, which leads to structural differences that can affect
resource allocation. Over-predicted areas might receive more mobility resources, while under-predicted areas receive
less, leading to equality issues.

Mathematically, multiplying a vector by the adjacency matrix A aggregates information from neighboring nodes. Thus,
we define the spatial disparity Ds based on the sign-aware residual variance of the neighboring nodes’ prediction, as
shown in Equation 2:

Ds =

1
|V|

|V|
(cid:88)

(cid:104)

i=1

(Ar+

i − ¯s+)2 + (Ar−

i − ¯s−)2(cid:105)

,

(2)

where r+ and r− represent the positive and negative residuals, s+ and s− are the spatially weighted residuals, and ¯s+
and ¯s− are their respective averages. The adjacency matrix A captures the influence of neighboring nodes, and Ds
summarizes variance in residuals across neighbors.

Another type of disparity arises when over-prediction is positively correlated with specific demographic groups. A
positive correlation implies that prediction residuals favor the majority over the minority group. This paper focuses on
black and white populations as the minority and majority groups, respectively. Disparities with respect to demographic
groups can also be reflected in spatial disparities, especially in cases where different demographic groups are spatially
segregated, as seen in our case study area: Chicago, see Figure 1b. We define the demographic disparity as Equation
3:

Dd = |Corr(r, P opminor)| + |Corr(r, P opmajor)| ,
where Corr(r, P opminor) and Corr(r, P opmajor) represent the Pearson correlation coefficients between the residuals r
and the minority (P opminor) and majority population percentages (P opmajor), respectively.

(3)

3.3 Attention Mechanism Preliminary
The attention mechanism enhances neural networks by focusing on relevant parts of the input, enabling models to
capture dependencies in sequential and spatial data effectively.
Given an input data matrix X ∈ Rn×d, where n is the number of elements (e.g., time steps, nodes) and d is the
feature dimension, the query (Q), key (K), and value (V) matrices are computed as Q = XWQ, K = XWK, and
V = XWV , where WQ, WK, WV ∈ Rd×dk are learnable parameters, and dk is the feature dimension of the query,
key, and value vectors. The attention scores are calculated using the scaled dot-product of the query and key matrices
as:

S =

,

(4)

QK⊤
√
dk

where S ∈ Rn×n quantifies the relevance between input elements, with higher scores indicating stronger relation-
ships.

The attention weights are obtained by applying the softmax function to normalize the scores: H = softmax(S), where
H represents the importance of each element in the input.

This mechanism has become a cornerstone of modern neural networks, significantly improving performance in tasks
requiring an understanding of complex spatial and sequential relationships.

The practical significance of the attention mechanism lies in its ability to dynamically focus on the most relevant parts
of the input data. This capability is crucial for tasks such as natural language processing, where the context of words can
vary significantly, and for image recognition, where different parts of an image may hold varying degrees of importance.

5

A PREPRINT - JANUARY 22, 2025

By learning to prioritize certain elements, the attention mechanism enhances the model’s ability to understand and
process complex data structures.

The integration of the attention mechanism in neural networks has led to significant improvements in performance and
has become a foundational component in many state-of-the-art models, such as the Transformer architecture (Vaswani
et al., 2017). The flexibility and effectiveness of the attention mechanism make it an essential tool for advancing the
capabilities of machine learning and deep learning models.

4 Methodology

Figure 2: Prediction framework with residual aware attention block.

Our overall framework, depicted in Figure 2, enhances existing ST-GNN architectures for urban prediction by integrating
two key components to address disparities: 1) The RAA Block, which adapts the adjacency matrix during training to
reduce spatial disparities in the model outputs. This adaptation leverages the residuals to dynamically adjust the spatial
relationships within the graph, focusing less on the local segregation of residuals and errors. 2) An equality-enhancing
loss function that penalizes adjacent neighborhoods with similar residual patterns and incorporates a spatial clustering
redundancy metric. This function aims to reduce spatial disparities and, consequently, demographic disparities by
balancing the importance of prediction accuracy with spatial and demographic equality.

4.1 RAA Block
The adjacency matrix in GNN structures is crucial in shaping the GNN results by ensuring that neighboring information
is shared, leading to similar feature representations for adjacent nodes. This emphasis on local information can cause
spatial disparity, as discussed in Equation 2.

As introduced in Section 3.3, the attention mechanism is a powerful tool that allows models to focus on specific parts of
the data. To adaptively mitigate model disparities, we incorporate an RAA Layer using the residuals from each training
step as inputs. We plug in the inputs during training into the equations explained in Section 3.3.

As shown in Figure 2, during each training step, we obtain a residual vector r. The residuals are used to compute the
query (Q), key (K), and value (V) matrices through linear transformations. Activation function tanh is applied to
introduce non-linearity and map the values to [−1, 1]:






Q = tanh(Wq(r)),
K = tanh(Wk(r)),
V = tanh(Wv(r)).

6

(5)

Attention Map HAdjacency Matrix AXUpdated Adjacency Matrix A*Residual Aware BlockUrbanTime Series DataPredictionsResidualsSTGNNMean Squared Error+Sign-Aware Residual Variance+ Spatial Clustering/ Redundancy Metric Vanilla ModelEquity-EnhancingLoss FunctionTemperatureTuningThe attention scores and attention weights are then derived as follows:






S =

QKT
(cid:112)|K|
H = softmax(S).

,

A PREPRINT - JANUARY 22, 2025

(6)

which indicates the relative importance of each element.

The adapted adjacency matrix is then formed by applying an element-wise Hadamard product between the original
adjacency matrix and the attention weights:

Aadapted = A ⊙ H.

(7)

This adapted adjacency matrix is used in the next epoch of training, allowing the model to treat the adapted spatial
relationships within the graph, thereby focusing less on the segregation of residuals and errors in local communities.
By integrating this adaptive attention mechanism, our approach dynamically adjusts the model’s treatment of spatial
relationships, reducing spatial and demographic disparities in urban predictions.

4.2 Equality-enhancing Loss Function
To address disparities and achieve equality in urban prediction, we also propose the equality-enhancing loss function.
The loss function integrates the mean squared error (MSE) loss with additional terms that account for spatial disparities.
The overall loss function is:

Ljoint = Lprediction + λsDs + λdDd,
(8)
where Lprediction is the MSE loss, and λs and λd are regularization parameters balancing the importance of the terms,
which by default is 0.05 and is tunable according to different datasets. This approach ensures that urban prediction
models do not further entrench existing inequities, thereby supporting more equitable and just urban planning and
policy-making.

Specifically, the Ds is the sign-aware residual variance term that measures spatial disparity with the same definition as
Equation 2. The Dd term utilizes fairness metrics like Moran’s I or GEI to measure spatial clustering or information
redundancy, focusing on reducing the overall spatial unevenness of the prediction residuals. The detailed formulation of
these metrics is outlined in Section 5.3.

5 Experiments

5.1 Urban Data Collections in Chicago
The demographic dataset for this research is sourced from the American Community Survey (ACS) for the years
2017-2018. The ACS provides detailed sociodemographic information, including income brackets, age demographics,
racial compositions, commuting modes, and average commuting durations. This data is specific to each of the 811
census tracts within Chicago (Zhuang et al., 2024; Wang et al., 2024b). Key attributes include total population, age
groups, racial composition, education levels, economic status, and travel information such as commuting times1.
We use Chicago Data Portal (CDP) 2 to evaluate the effects of our model. CDP contains the trip records of
Transportation Network Providers (ride-sharing companies) in the Chicago area. The city of Chicago is divided into 77
zones and the trip requests with pick-up and drop-off zones are recorded every 15 minutes. We use 4-month observations
from September 1st, 2019 to December 30th, 2019.

We have chosen Chicago as a case study because of its heavy spatial segregation of different racial groups, for which
unfair algorithmic prediction results may lead to even worse segregation. Fig 1b shows the racial minority rate in
Chicago in 2019. It is clear that minority races cluster around the south and middle-west of the city, while regions in the
north have far fewer minorities than the other regions.

5.2 Model Comparison
We selected four prevalent ST-GNN models as base models to demonstrate the effectiveness of our proposed
method:

• Diffusion Convolutional Recurrent Neural Network (DCRNN) by Li et al. (2018) models traffic dynamics
using diffusion convolution. It captures spatial dependencies with bidirectional random walks on the graph
and temporal dependencies with an encoder-decoder architecture and scheduled sampling.

1https://www.census.gov/programs-surveys/acs/data.html
2https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p

7

A PREPRINT - JANUARY 22, 2025

• Dynamic Spatial-Temporal Aware Graph Neural Network (DSTAGNN) by Lan et al. (2022) learns
dynamic association attributes from data to represent the graph. It uses a multi-head attention mechanism for
spatial variances and handles temporal dependencies with features of multi-receptive fields.

• Spatio-Temporal Graph Convolutional Network (STGCN) by Yu et al. (2018) features two spatio-temporal
convolutional blocks that leverage graph convolutional layers to capture spatial dependencies and temporal
gated convolution layers for temporal dynamics.

• Adaptive Graph Convolutional Recurrent Network (AGCRN) by Bai et al. (2020) consists of two modules:
Node Adaptive Parameter Learning, which learns node-specific parameters from node embeddings, and Data
Adaptive Graph Generation, which generates a graph from the training data. This architecture captures
fine-grained variability in space and time.

For each model, the performance of the vanilla version will be compared with the performance of the models with the
RAA block and enhanced loss functions added. The vanilla version model implementations we used were based on the
repository by Liu et al. (2023)3.

5.3 Fairness Metrics
Fairness metrics are vital for evaluating equality in urban prediction models, addressing both spatial and demographic
disparities. These metrics collectively help us ensure that our models do not exacerbate existing disparities, promoting
fair and equitable urban predictions. We selected GEI, SDI, and Moran’s I to evaluate three aspects of the residual
distribution: entropy, correlation to the demographics features, and spatial clusteringness.

5.3.1 Generalized Entropy Index (GEI)
GEI is a metric developed by (Speicher et al., 2018) used to compare unfair algorithmic treatments to individuals in a
population, originating from existing economic inequality indices. It reflects spatial disparity rather than demographic
disparity.

We calculate the GEI of prediction residuals, where a smaller value indicates a more even distribution of residuals
across all units of analysis, resulting in fairer predictions. Denote a non-negative transformation of the residuals
bi = ri + m, where m ∈ R+ such that bi ≥ 0 ∀i, and ri represents the residual at node i. The formulation is as
follows:

GEI =

1
|V|α(α − 1)

|V|
(cid:88)

i=1

(cid:20)(cid:18) bi
¯b

(cid:19)α

(cid:21)

− 1

,

(9)

The parameter α controls the emphasis on larger residuals, and we set α = 2 in this research.

5.3.2 Moran’s I
Moran’s I is a metric in spatial statistics used to measure spatial auto-correlations. It measures spatial disparity from
the overall clustering of the data spatial distribution, ranging from -1 to 1. A value of 1 means total positive spatial
auto-correlation, meaning similar values are spatially clustered together. A value of 0 means random distribution. A
value of -1 means total negative spatial auto-correlation, meaning similar values are dispersed. Since we hope to avoid
spatial clustering, a lower value of Moran’s I is appreciated more than higher values.
The weight W is computed as: W = (cid:80)N
i=1
number of nodes. Moran’s I is then calculated as:

j=1 aij, where aij are elements of the adjacency matrix A, and N is the

(cid:80)N

(cid:80)N

i=1

I =

N
W

(cid:80)N

j=1 aij(ri − r)(rj − r)
(cid:80)N

i=1(ri − r)2

,

(10)

where ri and rj are residuals at nodes i and j, and r is the residual mean. In order to ensure non-negative values
for the loss function, we adjust as: I ∗ = I + 1. This adjustment supports penalizing spatial clustering in our loss
function.

5.3.3 Scaled Disparity Index
While we do not incorporate demographic disparities in model training, we still need to measure if mitigating spatial
disparities also reduces demographic disparities. Hence, we propose using the Pearson correlation coefficients between
prediction residuals and the minority populations (Corr(r, P opminor)) and residuals and the majority populations
(Corr(r, P opmajor)) to assess fairness.

3https://github.com/liuxu77/LargeST/

8

A PREPRINT - JANUARY 22, 2025

To quantify disparity, we introduce the SDI:

SDI =

|∆Corr|
|Corrminor| + |Corrmajor|

·

(cid:113)

|Corrminor · Corrmajor|,

(11)

The first term of the SDI normalizes the disparity by taking the difference between Corr(r, P opminor) and
Corr(r, P opmajor) and scaling it by the sum of their absolute values. The geometric mean of Corr(r, P opminor)
and Corr(r, P opmajor) then adjusts this normalized disparity by accounting for the magnitude of the correlations. This
scaling is crucial, as it distinguishes between scenarios where correlations have different magnitudes but similar patterns
of disparity.

Ultimately, the SDI yields non-negative values, with smaller values indicating greater fairness in our context. The SDI
can also be extended to compare other advantaged and disadvantaged groups, such as evaluating equality between poor
and rich communities.

5.4 Error Metrics
We also employ common error metrics to evaluate the accuracy of our predictions: the Symmetric Mean Absolute
Percentage Error (SMAPE) and the Mean Absolute Error (MAE).

The SMAPE is defined as:

SMAPE =

N
(cid:88)

1
N

2 |ˆyi − yi| + ϵ
|ˆyi| + |yi| + ϵ

,

(12)

i=1
where ˆyi represents the predicted values, yi represents the true values, N is the number of observations, and ϵ is a small
constant to avoid division by zero. SMAPE provides a normalized measure of the average absolute error, considering
the scale of the true values.

The MAE is defined as:

MAE =

N
(cid:88)

|ˆyi − yi| ,

(13)

1
N

i=1
where ˆyi represents the predicted values and yi represents the true values. MAE measures the average magnitude of the
errors in a set of predictions, without considering their direction, providing a straightforward interpretation of prediction
accuracy.

For all metrics mentioned (GEI, Moran’s I, SDI, SMAPE, MAE), lower values indicate better performance.

5.5 Experiment setup
The experiment explores two parts, the first part compares the accuracy and fairness performance of the original vanilla
model and the different variants of RAA-enhanced models. The second part of the experiment is an ablation study
investigating the effects of the RAA block, the sign-aware residual variance, and the Moran’s I or GEI metrics on the
performance of the model.

All our experiments are implemented on a machine with Ubuntu 22.04, with Intel(R) Core(TM) i9-10980XE CPU @
3.00GHz CPU, 128GB RAM, and NVIDIA GeForce RTX 4080 GPU.

5.6 Results
5.6.1 Overall Performance
We compare three variants in total for all four base models in Section 5.2, all of which include the RAA block in the
model architecture. The variants differ based on the choice of the Dd term in the loss function. They include:

• adding the RAA block and Ds in the loss function;
• additionally, adding the Moran’s I metric as the Dd term in the loss function;
• alternatively, adding the GEI metric as the Dd term in the loss function.

We have calculated the accuracy and fairness metrics for each model and their variants in Table 1. The base model
performance metrics and the RAA variants are shown on the left and right sides of the table. The green color highlights
metric improvements whereas the red color highlights the opposite. The percentages followed by each metric result
demonstrate the amount of improvement or declination compared to the base model.

In general, the introduction of the RAA blocks and the additional equality-enhancing loss functions improve the fairness
metrics compared to the base model. On average, the GEI, SDI, and Moran’s I decreased by 18%, 47%, and 80%,

9

Models

Original model

Residual-Aware Attention Variants

MAE SMAPE GEI

SDI Moran’s I Variants

MAE

SMAPE

GEI

SDI

Moran’s I

A PREPRINT - JANUARY 22, 2025

DCRNN

8.092

0.458

1.28

0.2

0.182

DSTAGNN 8.564

0.425

1.383 0.308

0.542

STGCN

6.948

0.428

1.506 0.337

0.394

AGCRN

6.988

0.425

1.265 0.316

0.064

RAA block + Ds
+ loss with Moran’s I 8.911↑10% 0.555↑21% 1.148↓10% 0.183↓8% −0.135↓174%
+ loss with GEI

7.492↓7% 0.478↑4% 1.106↓13% 0.16↓20%

7.608↓5% 0.483↑5%

0.072↓64%

0.046↓74%

0.068↓62%

1.2↓6%

0.269↓12%
RAA block + Ds
+ loss with Moran’s I 8.509↓0% 0.448↑5% 2.862↑106% 0.281↓8%
+ loss with GEI

8.185↓4% 0.456↑7%

9.555↑11% 0.447↑5% 0.434↓68% 0.238↓22% −0.021↓103%

0.436↓19%
0.558↑2%

1.2↓13%

RAA block + Ds
7.329↑5% 0.538↑25% 1.075↓28% 0.235↓30%
+ loss with Moran’s I 7.885↑13% 0.506↑18% 1.692↑12% 0.106↓68%
+ loss with GEI

9.349↑34% 0.476↑11% 0.35↓76% 0.056↓83% −0.108↓127%

0.01↓97%
0.201↓48%

RAA block only
+ loss with Moran’s I 7.393↑5% 0.49↑15% 0.978↓22% 0.07↓77% −0.034↓153%
+ loss with GEI

7.039↓0% 0.465↑9% 0.975↓22% 0.007↓97%

8.419↑20% 0.49↑15% 0.373↓70% 0.084↓73%

0.019↓70%

0.04↓37%

Table 1: Comparison of Models with different Residual-Aware Attention versions

respectively. Among all 12 RAA experiments, 10 of them have reduced metrics for each fairness metric, and all
experiments have reduced SDI. This signifies the effectiveness of the RAA modules. If we take the average of the
percentage change for each RAA variant, we get a reduction of 40%, 37%, and 67%, respectively, for each of the
three variants. Thus, the variant with the RAA block and the GEI loss function has the best performance for reducing
fairness metrics. If we compare all four GNN models, the DCRNN and the AGCRN models with RAA blocks have
the most consistent performance. Their GEI, SDI, and Moran’s I all improved for all three model variations. The
AGCRN model’s overall fairness metric decrease percentages are also the highest compared to other models. These
improvements evidently showcase that reducing spatial disparities in model design can ultimately reduce demographic
disparities.

In addition, we observe a trend of accuracy-fairness trade-off. Among the 12 experiments, all of them have at least one
fairness metric improving while having error metrics decreasing. This makes sense since the objective of this project is
to reduce prediction error variances while sacrificing the accuracy performance. It is worth noting that even though this
is the case, our contribution allows much more fairness improvement amount compared to the accuracy loss in terms of
the percentage change. The average percentage increase for MAE and SMAPE are 7% and 12%, which are much lower
than the fairness percentage decrease mentioned above. It is possible to not sacrifice too much accuracy while greatly
improving the prediction equality among all regions. Furthermore, there are several cases when adding the RAA blocks
and the additional regularization terms in the loss function improves both accuracy and fairness. This phenomenon was
possible due to the Model Multiplicity or Under-Specification, meaning that the complex nature of the loss function
allows multiple objectives to be met during the training process D’Amour et al. (2022); Black et al. (2022).

5.6.2 Residual Spatial Distribution

To understand the effect of the RAA modules on the residual spatial distributions, we have plotted the average residuals at
each community area on the map, as shown in Figure 3. The red colors represent positive residuals, or under-prediction,
while the blue colors represent the opposite. Darker colors demonstrate larger residuals.

Comparing the spatial distribution of residuals between the original model and models with RAA modules, we observe
that the latter produces more equitable prediction results, as indicated by the less prominent residual clusters on the map.
Models with RAA blocks are effective in reducing errors concentrated in central city regions. For instance, in the case
of the STGCN model shown in Figure 3c, significant over-prediction occurs in central Chicago. However, models with
the RAA block and Moran’s I in the loss function display a much smoother residual distribution. Although the STGCN
model with GEI as a regularization term Dd still exhibits some clustering of large residuals in the central region, the
residual signs are more heterogeneous, indicating reduced spatial autocorrelation.

Furthermore, RAA blocks improve residual distribution throughout the city. For example, in the AGCRN models
shown in Figure 3b, the original model displays slight under-prediction in the southern part and northern tip of the city.
This issue is mitigated in models with RAA blocks and additional GEI regularization, resulting in a more equitable
distribution of residuals across different regions.

It is also worth noting that, although RAA blocks demonstrate some effectiveness in reducing disparities in the residual
spatial distribution, their effectiveness is model-dependent. There is a trade-off between residual clustering, variance,
and the imbalance between over- and under-predictions. It is challenging for a single model to improve all three aspects
simultaneously, which explains the varied performances of different models on the map and in terms of different fairness
metrics.

10

A PREPRINT - JANUARY 22, 2025

(a) DCRNN Residual Distribution

(b) DSTAGNN Residual Distribution

(c) STGCN Residual Distribution

(d) AGCRN Residual Distribution

Figure 3: Residual spatial distribution in Chicago.

11

DCRNN OriginalDCRNN RAA blockDCRNN RAA block + Moran's IDCRNN RAA block + GEI10.07.55.02.50.02.55.07.510.0Demand Prediction ResidualDSTAGNN OriginalDSTAGNN RAA blockDSTAGNN RAA block + Moran's IDSTAGNN RAA block + GEI10.07.55.02.50.02.55.07.510.0Demand Prediction ResidualSTGCN OriginalSTGCN RAA blockSTGCN RAA block + Moran's ISTGCN RAA block + GEI10.07.55.02.50.02.55.07.510.0Demand Prediction ResidualAGCRN OriginalAGCRN RAA blockAGCRN RAA block + Moran's IAGCRN RAA block + GEI10.07.55.02.50.02.55.07.510.0Demand Prediction ResidualA PREPRINT - JANUARY 22, 2025

5.6.3 Abaltion Study
An ablation study is a method used in machine learning to evaluate the impact of individual components on a model’s
performance. By systematically altering specific elements and observing changes in performance metrics, researchers
can identify which components are essential. We conducted 6 ablation cases in total, corresponding to:

• RAA block: adding RAA block to the architecture alone;
• RAA block + Ds: adding the RAA block to the architecture and adding the Ds regularization term in the loss

function;

• RAA block + Moran’s I: adding the RAA block to the architecture and adding the Moran’s I metric as the Dd

term in the loss function;

• RAA block + GEI: adding the RAA block to the architecture and adding the GEI metric as the Dd term in the

loss function;

• RAA block + Ds + Moran’s I: adding the RAA block to the architecture, adding the Ds term and the Moran’s

I metric as the Dd term to form the Equation 8;

• RAA block+ Ds + GEI : adding the RAA block to the architecture, adding the Ds term and the GEI metric as

the Dd term to form the Equation 8.

No. Model Variants
Original
1
RAA block
2
RAA block + Ds
3
RAA block + Moran’s I
4
RAA block + GEI
5
RAA block + Ds + Moran’s I
6
RAA block + Ds + GEI
7
Table 2: Ablation study of our designed modules using the STGCN model.

SMAPE GEI
1.506
0.402
1.854
0.842
0.525
1.461
0.350

SDI Moran’s I
0.337
0.154
0.140
0.151
0.044
0.015
0.056

MAE
6.948
7.830
7.257
10.465
8.028
7.924
9.349

0.394
-0.000
0.212
0.251
-0.136
0.012
-0.108

0.428
0.475
0.474
0.470
0.525
0.508
0.476

To illustrate the effect of model architecture design choices, we conducted an ablation study in the context of the
STGCN model, as shown in Table 2. The detailed steps are described in section 5.5. The ablation study validates each
strategy we have introduced.

First, the RAA block significantly improves fairness metrics compared to the original model, although it sacrifices
accuracy. Comparing Model 1 and Model 2 from Table 2, we observe reductions in GEI, SDI, and Moran’s I, indicating
reduced residual variances, correlations to demographics, and spatial autocorrelation. This supports the hypothesis that
using residuals to calculate the Attention map helps direct the model toward more equitable results. Moreover, both
spatial and demographic disparities could be mitigated using this method.

Second, adding the Ds term improves accuracy but trades off with fairness results. This is demonstrated by comparing
three pairs of models: Model 2 and Model 3, Model 4 and Model 6, and Model 5 and Model 7. Models with Ds
regularization show at least one lower accuracy metric compared to those without. The Ds term impacts error metrics
because it separately calculates the variance of positive and negative residuals, effectively weighting errors more heavily
in the loss function, causing the model to focus more on accuracy.

Lastly, adding Ds and Dd terms improves the corresponding fairness metrics. Comparing between Model 2 and Model
5, as well as Model 3 and Model 7, we see that introducing GEI in the loss function as a regularization term significantly
enhances the GEI performance of model predictions. On the other hand, comparing between Model 2 and Model 4 as
well as Model 3 and Model 6, we see that the Moran’s I metric as the Dd term is less effective in improving the output
Moran’s I metric, but is able to help with other fairness metrics. Thus, over-emphasizing any one metric can lead to
worse results in others. It is crucial to balance multiple objectives in the loss function to avoid such scenarios. In our
case, this means ensuring similar regularization weights for both accuracy and fairness terms.

5.6.4 Spatial Attention Distribution
To illustrate the influence of the Attention Mechanism in the RAA Block on the model, we plotted the attention score
and attention map of the last epoch (explained in section 3.3) and compared them with the final prediction residuals for
each region in Chicago, as shown in Fig 4.

We selected the results of four community areas predicted using the STGCN model with RAA block and the Ds
signed-aware residual variance term as regularization. The goal was to illustrate the characteristics of the attention maps

12

A PREPRINT - JANUARY 22, 2025

(a) Case Study 1: West Englewood. Attention map captures relationships with nearby areas.

(b) Case Study 2: North Lawndale. Attention map captures relationships with faraway areas in both north and south directions.

(c) Case Study 3: Lake View. Attention map captures relationships among under-prediction areas.

(d) Case Study 4: O’Hare. Attention map captures relationships between under- and over-prediction areas.

Figure 4: Attention Maps and Residuals in Chicago.

13

3020100102030Residual Attention Score0.0000.0050.0100.0150.0200.0250.030Residual Attention Weight42024Demand Prediction Residual3020100102030Residual Attention Score0.0000.0050.0100.0150.0200.0250.030Residual Attention Weight42024Demand Prediction Residual3020100102030Residual Attention Score0.0000.0050.0100.0150.0200.0250.030Residual Attention Weight42024Demand Prediction Residual3020100102030Residual Attention Score0.0000.0050.0100.0150.0200.0250.030Residual Attention Weight42024Demand Prediction ResidualA PREPRINT - JANUARY 22, 2025

for these community areas. For each case study, the focus community area is highlighted with a light green boundary
line. The map on the left demonstrates the attention scores, representing the relationship between the given community
area and the rest of the city. Regions shaded with darker red are associated with higher attention as learned from the
residuals, whereas darker blue indicates the opposite.

To further highlight the most important attention regions in the city corresponding to the given community area, the
middle map illustrates the attention weight calculated by applying the Softmax function to the attention scores. This
visualization allows us to understand how the model focuses on different regions and how this focus is influenced by the
residuals. The resulting attention maps provide insights into the spatial dependencies and the model’s adaptive learning
process.

By comparing the attention scores and weights with the final prediction residuals, we can assess the effectiveness of the
RAA Block in addressing spatial and demographic disparities. The attention mechanism helps the model to dynamically
adjust its focus, leading to more equitable prediction results across different regions. This approach not only enhances
the model’s accuracy but also ensures fairness in urban predictions, contributing to more balanced resource allocation
and policy-making.

The four community areas for case studies include:

Case Study 1: West Englewood.
In this scenario (Figure 4a), the attention related to the given community area
concentrates in New City, Chicago Lawn, and the Loop areas. Notably, the first two regions are adjacent to the target
West Englewood area. This demonstrates that the calculated attention weight prioritizes spatial proximity between
community areas. This focus on nearby areas helps ensure that predictions are influenced more by spatially relevant
information, potentially leading to more accurate and context-aware urban predictions.

Case Study 2: North Lawndale.
In this scenario (Figure 4b), the attentions corresponding to this community
area focus on Forest Glen, Avondale, and Riverdale areas, which are spatially far from the target community area,
North Lawndale. This demonstrates that the attention weight not only captures nearby entities but also emphasizes
similar entities far away. The model’s ability to highlight distant regions with comparable characteristics indicates
that the attention mechanism effectively recognizes and leverages similarities in urban features, regardless of spatial
distance.

Case Study 3: Lake View.
In this case (Figure 4c), the attentions focus on the Near West Side area, a busy
central region of the city. Both Lake View and the Near West Side are underestimated, as shown in the demand
prediction residual map. This illustrates that the attention weight is capable of linking regions with similar prediction
performances. By identifying and connecting areas with analogous underestimation patterns, the model can better
understand and correct systematic prediction biases. This aspect of the attention mechanism is particularly important
in urban planning, where equitable resource distribution can significantly impact the quality of life for residents in
different neighborhoods.

Case Study 4: O’Hare. In this case (Figure 4d), the attention also concentrates on the Near West Side area. However,
while the O’Hare area is over-predicted, as shown in the demand prediction residual map, the Near West Side exhibits
under-predictions. This reveals that the attention weight can connect regions with opposite behaviors, preventing the
model from overemphasizing similarities. This balance helps in mitigating biases by ensuring that areas with different
prediction errors are considered together, enhancing the model’s ability to correct over-predictions and under-predictions
effectively.

6 Discussion and conclusions

Previous urban prediction work prevalently built on ST-GNNs focuses solely on accuracy, neglecting social impacts.
By focusing on residuals as indicators of fairness, we effectively highlight disparities in traditional ST-GNN outputs.
This study addresses spatial and demographic disparities in urban prediction tasks by developing an RAA Block and
an equality-enhancing loss function. Our approach, integrated into existing ST-GNNs, dynamically adjusts spatial
relationships during training, mitigating spatial disparities.

Applied to urban prediction tasks in Chicago, our methodology demonstrates significant improvements both in fairness
metrics and error metrics. This shows that reducing spatial disparities can also help mitigate demographic disparities.
Moreover, our approach reduces the local segregation of residuals and errors. Spatial analysis of residual distributions
shows that models with RAA Blocks effectively reduced clustered prediction errors in central regions. Attention
maps indicate the model’s enhanced focus on relevant areas, improving prediction accuracy and fairness. Through
the comprehensive case study in Chicago, we demonstrate the effectiveness of our approach in mitigating prediction
disparities for future equitable urban city management.

14

A PREPRINT - JANUARY 22, 2025

However, the RAA Block’s effectiveness is model-dependent, and there is a trade-off between residual clustering,
variance, and the balance of over- and under-predictions. Future work should optimize these factors to enhance
performance. Although our approach does not rely on demographic data, incorporating such information when available
could provide a more comprehensive understanding of fairness in urban predictions.

7 Acknowledgement

ChatGPT was utilized to assist in polishing the wording and beautifying the code. No other uses were conducted. We
have thoroughly verified the accuracy, validity, and appropriateness of the content generated. No citations or literature
reviews were performed by the language model. We acknowledge the limitations of language models in the manuscript,
including potential bias, errors, and gaps in knowledge.

References

Lei Bai, Lina Yao, Can Li, Xianzhi Wang, and Can Wang. Adaptive graph convolutional recurrent network for traffic

forecasting. Advances in neural information processing systems, 33:17804–17815, 2020.

Emily Black, Manish Raghavan, and Solon Barocas. Model multiplicity: Opportunities, concerns, and solutions.
In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency, FAccT ’22, page
850–863, New York, NY, USA, June 2022. Association for Computing Machinery. ISBN 978-1-4503-9352-2. doi:
10.1145/3531146.3533149. URL https://dl.acm.org/doi/10.1145/3531146.3533149.

Simon Caton and Christian Haas. Fairness in Machine Learning: A Survey, October 2020. URL http://arxiv.org/

abs/2010.04053. arXiv:2010.04053 [cs, stat].

Austin Derrow-Pinion, Jennifer She, David Wong, Oliver Lange, Todd Hester, Luis Perez, Marc Nunkesser, Seongjae
Lee, Xueying Guo, Brett Wiltshire, Peter W. Battaglia, Vishal Gupta, Ang Li, Zhongwen Xu, Alvaro Sanchez-
Gonzalez, Yujia Li, and Petar Velickovic. Eta prediction with graph neural networks in google maps. In Proceedings
of the 30th ACM International Conference on Information & Knowledge Management, page 3767–3776, Virtual
Event Queensland Australia, October 2021. ACM. ISBN 978-1-4503-8446-9. doi: 10.1145/3459637.3481916. URL
https://dl.acm.org/doi/10.1145/3459637.3481916.

Yushun Dong, Ninghao Liu, Brian Jalaian, and Jundong Li. Edits: Modeling and mitigating data bias for graph neural
networks. In Proceedings of the ACM Web Conference 2022, page 1259–1269, April 2022. doi: 10.1145/3485447.
3512173. URL http://arxiv.org/abs/2108.05233. arXiv:2108.05233 [cs].

Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through awareness.
In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, ITCS ’12, page 214–226,
New York, NY, USA, January 2012. Association for Computing Machinery.
ISBN 978-1-4503-1115-1. doi:
10.1145/2090236.2090255. URL https://doi.org/10.1145/2090236.2090255.

Alexander D’Amour, Katherine Heller, Dan Moldovan, Ben Adlam, Babak Alipanahi, Alex Beutel, Christina Chen,
Jonathan Deaton, Jacob Eisenstein, Matthew D. Hoffman, Farhad Hormozdiari, Neil Houlsby, Shaobo Hou, Ghassen
Jerfel, Alan Karthikesalingam, Mario Lucic, Yian Ma, Cory McLean, Diana Mincu, Akinori Mitani, Andrea
Montanari, Zachary Nado, Vivek Natarajan, Christopher Nielson, Thomas F. Osborne, Rajiv Raman, Kim Ramasamy,
Rory Sayres, Jessica Schrouff, Martin Seneviratne, Shannon Sequeira, Harini Suresh, Victor Veitch, Max Vladymyrov,
Xuezhi Wang, Kellie Webster, Steve Yadlowsky, Taedong Yun, Xiaohua Zhai, and D. Sculley. Underspecification
presents challenges for credibility in modern machine learning. Journal of Machine Learning Research, 23(226):
1–61, 2022. ISSN 1533-7928.

Xiaomin Fang, Jizhou Huang, Fan Wang, Lingke Zeng, Haijin Liang, and Haifeng Wang. Constgat: Contextual spatial-
temporal graph attention network for travel time estimation at baidu maps. In Proceedings of the 26th ACM SIGKDD
International Conference on Knowledge Discovery & Data Mining, KDD ’20, page 2697–2705, New York, NY, USA,
August 2020. Association for Computing Machinery. ISBN 978-1-4503-7998-4. doi: 10.1145/3394486.3403320.
URL https://doi.org/10.1145/3394486.3403320.

Zheng Fang, Qingqing Long, Guojie Song, and Kunqing Xie. Spatial-temporal graph ode networks for traffic flow
forecasting. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages
364–373, 2021.

Hamed Farahmand, Yuanchang Xu, and Ali Mostafavi. A spatial–temporal graph deep learning model for urban
flood nowcasting leveraging heterogeneous community features. Scientific Reports, 13(1):6768, April 2023. ISSN
2045-2322. doi: 10.1038/s41598-023-32548-x.

Gillian Franklin, Rachel Stephens, Muhammad Piracha, Shmuel Tiosano, Frank Lehouillier, Ross Koppel, and Peter L
Elkin. The sociodemographic biases in machine learning algorithms: A biomedical informatics perspective. Life, 14
(6):652, 2024.

15

A PREPRINT - JANUARY 22, 2025

Kun Fu, Fanlin Meng, Jieping Ye, and Zheng Wang. Compacteta: A fast inference system for travel time prediction.
In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining,
KDD ’20, page 3337–3345, New York, NY, USA, August 2020. Association for Computing Machinery. ISBN
978-1-4503-7998-4. doi: 10.1145/3394486.3403386. URL https://doi.org/10.1145/3394486.3403386.
Xu Geng, Yaguang Li, Leye Wang, Lingyu Zhang, Qiang Yang, Jieping Ye, and Yan Liu. Spatiotemporal Multi-Graph
Convolution Network for Ride-Hailing Demand Forecasting. Proceedings of the AAAI Conference on Artificial
Intelligence, 33:3656–3663, 2019. ISSN 2159-5399. doi: 10.1609/aaai.v33i01.33013656.

Nina Grgic-Hlacˇa, Muhammad Bilal Zafar, Krishna P Gummadi, and Adrian Weller. The case for process fairness in

learning: Feature selection for fair decision making.

Xiaotong Guo, Hanyong Xu, Dingyi Zhuang, Yunhan Zheng, and Jinhua Zhao. Fairness-enhancing vehicle rebalancing
in the ride-hailing system. (arXiv:2401.00093), December 2023. doi: 10.48550/arXiv.2401.00093. URL http:
//arxiv.org/abs/2401.00093. arXiv:2401.00093 [cs].

Yong Han, Shukang Wang, Yibin Ren, Cheng Wang, Peng Gao, and Ge Chen. Predicting station-level short-term
passenger flow in a citywide metro network using spatiotemporal graph convolutional neural networks. ISPRS
International Journal of Geo-Information, 8(6), 2019. ISSN 22209964. doi: 10.3390/ijgi8060243.

Jizhou Huang, Zhengjie Huang, Xiaomin Fang, Shikun Feng, Xuyi Chen, Jiaxiang Liu, Haitao Yuan, and Haifeng
Wang. Dueta: Traffic congestion propagation pattern modeling via efficient graph learning for eta prediction at
baidu maps. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management,
page 3172–3181, October 2022. doi: 10.1145/3511808.3557091. URL http://arxiv.org/abs/2208.06979.
arXiv:2208.06979 [cs].

Guangyin Jin, Yan Cui, Liang Zeng, Hanbo Tang, Yanghe Feng, and Jincai Huang. Urban ride-hailing demand
prediction with multiple spatio-temporal information fusion network. Transportation Research Part C: Emerging
Technologies, 117:102665, August 2020. ISSN 0968-090X. doi: 10.1016/j.trc.2020.102665.

Guangyin Jin, Zhexu Xi, Hengyu Sha, Yanghe Feng, and Jincai Huang. Deep multi-view graph-based network for
citywide ride-hailing demand prediction. Neurocomputing, 510:79–94, October 2022. ISSN 0925-2312. doi:
10.1016/j.neucom.2022.09.010.

Guangyin Jin, Yuxuan Liang, Yuchen Fang, Zezhi Shao, Jincai Huang, Junbo Zhang, and Yu Zheng. Spatio-temporal
graph neural networks for predictive learning in urban computing: A survey. IEEE Transactions on Knowledge and
Data Engineering, page 1–20, 2023a. ISSN 1558-2191. doi: 10.1109/TKDE.2023.3333824.

Guangyin Jin, Lingbo Liu, Fuxian Li, and Jincai Huang. Spatio-temporal graph neural point process for traffic
congestion event prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1212):14268–14276,
June 2023b. ISSN 2374-3468. doi: 10.1609/aaai.v37i12.26669.

Nathan Kallus and Angela Zhou. Residual unfairness in fair machine learning from prejudiced data. In International

Conference on Machine Learning, pages 2439–2448. PMLR, 2018.

Jintao Ke, Hongyu Zheng, Hai Yang, and Xiqun (Michael) Chen. Short-term forecasting of passenger demand under
on-demand ride services: A spatio-temporal deep learning approach. Transportation Research Part C: Emerging
Technologies, 85:591–608, December 2017. ISSN 0968-090X. doi: 10.1016/j.trc.2017.10.016.

Xiangyuan Kong, Weiwei Xing, Xiang Wei, Peng Bao, Jian Zhang, and Wei Lu. STGAT: Spatial-Temporal Graph
Attention Networks for Traffic Flow Forecasting. IEEE Access, 8:134363–134372, 2020. ISSN 21693536. doi:
10.1109/ACCESS.2020.3011186.

Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. Counterfactual fairness. In Advances in Neural
Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.
cc/paper_files/paper/2017/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html.

Shiyong Lan, Yitong Ma, Weikang Huang, Wenwu Wang, Hongyu Yang, and Pyang Li. Dstagnn: Dynamic spatial-
temporal aware graph neural network for traffic flow forecasting. In International conference on machine learning,
pages 11906–11917. PMLR, 2022.

Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffusion convolutional recurrent neural network: Data-driven
traffic forecasting. 6th International Conference on Learning Representations, ICLR 2018 - Conference Track
Proceedings, pages 1–16, 2018.

Yuxuan Liang, Songyu Ke, Junbo Zhang, Xiuwen Yi, and Yu Zheng. Geoman: Multi-level attention networks
In Proceedings of the Twenty-Seventh International Joint Conference
for geo-sensory time series prediction.
on Artificial Intelligence, page 3428–3434, Stockholm, Sweden, July 2018. International Joint Conferences on
Artificial Intelligence Organization.
ISBN 978-0-9992411-2-7. doi: 10.24963/ijcai.2018/476. URL https:
//www.ijcai.org/proceedings/2018/476.

16

A PREPRINT - JANUARY 22, 2025

Todd Alexander Litman. Evaluating Transportation Equity. March 2023.

Xu Liu, Yutong Xia, Yuxuan Liang, Junfeng Hu, Yiwei Wang, Lei Bai, Chao Huang, Zhenguang Liu, Bryan Hooi,
and Roger Zimmermann. Largest: A benchmark dataset for large-scale traffic forecasting. In Advances in Neural
Information Processing Systems, 2023.

Yao Liu, Lina Yao, Binghao Li, Xianzhi Wang, and Claude Sammut. Social graph transformer networks for pedestrian
In Proceedings of the 31st ACM International Conference
trajectory prediction in complex social scenarios.
on Information & Knowledge Management, CIKM ’22, page 1339–1349, New York, NY, USA, October 2022.
Association for Computing Machinery. ISBN 978-1-4503-9236-5. doi: 10.1145/3511808.3557455. URL https:
//doi.org/10.1145/3511808.3557455.

Bin Lu, Xiaoying Gan, Haiming Jin, Luoyi Fu, Xinbing Wang, and Haisong Zhang. Make more connections: Urban
traffic flow forecasting with spatiotemporal adaptive gated graph convolution network. ACM Trans. Intell. Syst.
Technol., 13(2):28:1–28:25, January 2022. ISSN 2157-6904. doi: 10.1145/3488902.

Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A Survey on Bias and
Fairness in Machine Learning, January 2022. URL http://arxiv.org/abs/1908.09635. arXiv:1908.09635
[cs].

Abduallah Mohamed, Kun Qian, Mohamed Elhoseiny, and Christian Claudel. Social-stgcnn: A social spatio-temporal
(arXiv:2002.11927), March 2020. URL

graph convolutional neural network for human trajectory prediction.
http://arxiv.org/abs/2002.11927. arXiv:2002.11927 [cs].

Yusheng Peng, Gaofeng Zhang, Xiangyu Li, and Liping Zheng. Stirnet: A spatial-temporal interaction-aware recursive
network for human trajectory prediction. In 2021 IEEE/CVF International Conference on Computer Vision Workshops
(ICCVW), page 2285–2293, October 2021. doi: 10.1109/ICCVW54120.2021.00258. URL https://ieeexplore.
ieee.org/document/9607725.

Dana Pessach and Erez Shmueli. A Review on Fairness in Machine Learning. ACM Computing Surveys, 55(3):51:1–
51:44, February 2022. ISSN 0360-0300. doi: 10.1145/3494672. URL https://doi.org/10.1145/3494672.

Bogdan Ilie Sighencea, Ion Rares, Stanciu, and C˘at˘alin Daniel C˘aleanu. D-stgcn: Dynamic pedestrian trajectory
prediction using spatio-temporal graph convolutional networks. Electronics, 12(33):611, January 2023. ISSN
2079-9292. doi: 10.3390/electronics12030611.

Till Speicher, Hoda Heidari, Nina Grgic-Hlaca, Krishna P. Gummadi, Adish Singla, Adrian Weller, and Muhammad Bilal
Zafar. A unified approach to quantifying algorithmic unfairness: Measuring individual &group unfairness via
inequality indices. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery
& Data Mining, page 2239–2248, London United Kingdom, July 2018. ACM. ISBN 978-1-4503-5552-0. doi:
10.1145/3219819.3220046. URL https://dl.acm.org/doi/10.1145/3219819.3220046.

Mingjie Sun, Pengyuan Zhou, Hui Tian, Yong Liao, and Haiyong Xie. Spatial-temporal attention network for crime
prediction with adaptive graph learning. In Elias Pimenidis, Plamen Angelov, Chrisina Jayne, Antonios Papaleonidas,
and Mehmet Aydin, editors, Artificial Neural Networks and Machine Learning – ICANN 2022, page 656–669, Cham,
2022. Springer Nature Switzerland. ISBN 978-3-031-15931-2. doi: 10.1007/978-3-031-15931-2_54.

Ran Tian, Chu Wang, Jia Hu, and Zhongyu Ma. Mfstgn: a multi-scale spatial-temporal fusion graph network for
traffic prediction. Applied Intelligence, 53(19):22582–22601, October 2023. ISSN 1573-7497. doi: 10.1007/
s10489-023-04703-4.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia

Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.

Beibei Wang, Youfang Lin, Shengnan Guo, and Huaiyu Wan. Gsnet: Learning spatial-temporal correlations from
geographical and semantic aspects for traffic accident risk forecasting. Proceedings of the AAAI Conference on
Artificial Intelligence, 35(55):4402–4409, May 2021a. ISSN 2374-3468. doi: 10.1609/aaai.v35i5.16566.

Chenyu Wang, Zongyu Lin, Xiaochen Yang, Jiao Sun, Mingxuan Yue, and Cyrus Shahabi. Hagen: Homophily-aware
graph convolutional recurrent network for crime forecasting. Proceedings of the AAAI Conference on Artificial
Intelligence, 36(4):4193–4200, June 2022. ISSN 2374-3468, 2159-5399. doi: 10.1609/aaai.v36i4.20338.

Dongkun Wang, Jieyang Peng, Xiaoming Tao, and Yiping Duan. Boosting urban prediction tasks with domain-sharing

knowledge via meta-learning. Information Fusion, page 102324, 2024a.

Qingyi Wang, Shenhao Wang, Yunhan Zheng, Hongzhou Lin, Xiaohu Zhang, Jinhua Zhao, and Joan Walker. Deep
hybrid model with satellite imagery: How to combine demand modeling and computer vision for travel behavior
analysis? Transportation Research Part B: Methodological, 179:102869, 2024b.

17

A PREPRINT - JANUARY 22, 2025

Yuandong Wang, Hongzhi Yin, Hongxu Chen, Tianyu Wo, Jie Xu, and Kai Zheng. Origin-destination matrix prediction
via graph convolution: a new perspective of passenger demand modeling. In Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery & Data Mining, KDD ’19, page 1227–1235, New York, NY,
USA, July 2019. Association for Computing Machinery. ISBN 978-1-4503-6201-6. doi: 10.1145/3292500.3330877.
URL https://doi.org/10.1145/3292500.3330877.

Yuandong Wang, Hongzhi Yin, Tong Chen, Chunyang Liu, Ben Wang, Tianyu Wo, and Jie Xu. Gallat: A spatiotemporal
graph attention network for passenger demand prediction. In 2021 IEEE 37th International Conference on Data
Engineering (ICDE), page 2129–2134, April 2021b. doi: 10.1109/ICDE51399.2021.00212. URL https://
ieeexplore.ieee.org/document/9458919.

Zhaonan Wang, Renhe Jiang, Hao Xue, Flora D. Salim, Xuan Song, and Ryosuke Shibasaki. Event-aware multimodal
(arXiv:2112.08443), December 2021c. doi: 10.48550/arXiv.2112.08443. URL http:

mobility nowcasting.
//arxiv.org/abs/2112.08443. arXiv:2112.08443 [cs].

Yuankai Wu, Dingyi Zhuang, Aurelie Labbe, and Lijun Sun. Inductive graph neural networks for spatiotemporal kriging.

In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 4478–4485, 2021.

Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Liefeng Bo, Xiyue Zhang, and Tianyi Chen. Spatial-temporal
sequential hypergraph network for crime prediction with dynamic multiplex relation learning. In Proceedings of
the Thirtieth International Joint Conference on Artificial Intelligence, page 1631–1637, Montreal, Canada, August
ISBN 978-0-9992411-9-6. doi:
2021. International Joint Conferences on Artificial Intelligence Organization.
10.24963/ijcai.2021/225. URL https://www.ijcai.org/proceedings/2021/225.

An Yan and Bill Howe. Fairness-Aware Demand Prediction for New Mobility. Proceedings of the AAAI Conference
on Artificial Intelligence, 34(01):1079–1087, April 2020. ISSN 2374-3468. doi: 10.1609/aaai.v34i01.5458. URL
https://ojs.aaai.org/index.php/AAAI/article/view/5458. Number: 01.

Haiqiang Yang, Zihan Li, and Yashuai Qi. Predicting traffic propagation flow in urban road network with multi-graph
ISSN 2198-6053. doi:

convolutional network. Complex & Intelligent Systems, 10(1):23–35, February 2024.
10.1007/s40747-023-01099-z.

Jiexia Ye, Juanjuan Zhao, Kejiang Ye, and Chengzhong Xu. How to build a graph-based deep learning architecture in
traffic domain: A survey. IEEE Transactions on Intelligent Transportation Systems, 23(5):3904–3924, May 2022.
ISSN 1524-9050, 1558-0016. doi: 10.1109/TITS.2020.3043250. arXiv:2005.11691 [cs, eess].

Junchen Ye, Leilei Sun, Bowen Du, Yanjie Fu, and Hui Xiong. Coupled layer-wise graph convolution for transportation
demand prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 35(55):4617–4625, May 2021.
ISSN 2374-3468. doi: 10.1609/aaai.v35i5.16591.

Bing Yu, Haoteng Yin, and Zhanxing Zhu. Spatio-Temporal Graph Convolutional Networks : A Deep Learn-
ing Framework For Traffic Forecasting. ProceedLearningings of the Twenty-Seventh International Joint Con-
ference on Artificial Intelligence (IJCAI-18), pages 3634–3640, 2018. URL https://aaafoundation.org/
american-driving-survey-2014-2015/.

Le Yu, Bowen Du, Xiao Hu, Leilei Sun, Liangzhe Han, and Weifeng Lv. Deep spatio-temporal graph convolutional
network for traffic accident prediction. Neurocomputing, 423:135–147, January 2021. ISSN 0925-2312. doi:
10.1016/j.neucom.2020.09.043.

Xiaojian Zhang, Qian Ke, and Xilei Zhao. Enhancing fairness in ai-based travel demand forecasting models. arXiv

preprint arXiv:2303.01692, 2023a.

Xiaojian Zhang, Qian Ke, and Xilei Zhao. Enhancing Fairness in AI-based Travel Demand Forecasting Models, March

2023b. URL http://arxiv.org/abs/2303.01692. arXiv:2303.01692 [cs].

Yang Zhang and Tao Cheng. Graph deep learning model for network-based predictive hotspot mapping of sparse
spatio-temporal events. Computers, Environment and Urban Systems, 79:101403, January 2020. ISSN 0198-9715.
doi: 10.1016/j.compenvurbsys.2019.101403.

Yunhan Zheng, Shenhao Wang, and Jinhua Zhao. Equality of opportunity in travel behavior prediction with deep
neural networks and discrete choice models. Transportation Research Part C: Emerging Technologies, 132:103410,
November 2021. ISSN 0968090X. doi: 10.1016/j.trc.2021.103410. URL https://linkinghub.elsevier.com/
retrieve/pii/S0968090X21004058.

Yunhan Zheng, Qingyi Wang, Dingyi Zhuang, Shenhao Wang, and Jinhua Zhao. Fairness-enhancing deep learning for

ride-hailing demand prediction. arXiv preprint arXiv:2303.05698, 2023a.

Yunhan Zheng, Qingyi Wang, Dingyi Zhuang, Shenhao Wang, and Jinhua Zhao. Fairness-enhancing deep learning for
ride-hailing demand prediction, March 2023b. URL http://arxiv.org/abs/2303.05698. arXiv:2303.05698
[cs].

18

A PREPRINT - JANUARY 22, 2025

Hongye Zhou, Feng Zhang, Zhenhong Du, and Renyi Liu. Forecasting pm2.5 using hybrid graph convolution-based
model considering dynamic wind-field to offer the benefit of spatial interpretability. Environmental Pollution, 273:
116473, March 2021. ISSN 0269-7491. doi: 10.1016/j.envpol.2021.116473.

Yanpeng Zhou, Jinjie Wang, Jianli Ding, Bohua Liu, Nan Weng, and Hongzhi Xiao. Signet: A siamese graph
convolutional network for multi-class urban change detection. Remote Sensing, 15(99):2464, January 2023. ISSN
2072-4292. doi: 10.3390/rs15092464.

Dingyi Zhuang, Shenhao Wang, Haris Koutsopoulos, and Jinhua Zhao. Uncertainty quantification of sparse travel
demand prediction with spatial-temporal graph neural networks. In Proceedings of the 28th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining, pages 4639–4647, 2022.

Dingyi Zhuang, Qingyi Wang, Yunhan Zheng, Xiaotong Guo, Shenhao Wang, Haris N Koutsopoulos, and Jinhua Zhao.
Advancing transportation mode share analysis with built environment: Deep hybrid models with urban road network.
arXiv preprint arXiv:2405.14079, 2024.

19

