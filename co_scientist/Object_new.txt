**Toolset:** Analyze Patterns

**Tool:** Calculate Density

**Description:** The Calculate Density tool creates a density map from point or line features by spreading known quantities of some phenomenon (represented as attributes of the points or lines) across the map. The result is a layer of areas classified from least dense to most dense. Typical use cases include creating crime density maps, calculating hospital densities within a county, and identifying areas at high risk of forest fires.

**Parameters:**
- **Input Features:** The point or line features from which to calculate density. Type: Feature Set.
- **Output Name:** The name of the output layer to create on your portal. Type: String.
- **Count Field (Optional):** A field specifying the number of incidents at each location. Type: Field.
- **Cell Size (Optional):** This value is used to create a mesh of points where density values are calculated. Type: Double.
- **Cell Size Units (Optional):** The units of the cell size value. Type: String.
- **Radius (Optional):** A distance specifying how far to search to find point or line features when calculating density values. Type: Double.
- **Radius Units (Optional):** The units of the radius value. Type: String.
- **Time Step Interval (Optional):** Specifies the duration of the time step. Type: Time Unit.
- **Time Step Reference (Optional):** A date that specifies the reference time with which to align the time steps. Type: Date.

**Derived Output:**
- **Output Layer:** The output polygon layer with classified density values. Type: Feature Set.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set local variables
inputLayer = "https://MyPortal.esri.com/server/rest/services/Hosted/myPoints/FeatureServer/0"
outputName = "outImgServ"
inField = "Population"
searchDistance = "150000 Meters"
areaUnit = "Square Kilometers"
outCellSize = "10000 Meters"
inBarriers = "https://MyPortal.esri.com/server/rest/services/Hosted/myPoints/FeatureServer/1"

# Execute CalculateDensity
arcpy.ra.CalculateDensity(inputLayer, outputName, inField, searchDistance, areaUnit, outCellSize, inBarriers)
```
**Toolset:** Analyze Patterns

**Tool:** Find Hot Spots

**Description:** The Find Hot Spots tool identifies statistically significant spatial clustering of high values (hot spots) or low values (cold spots) using the Getis-Ord Gi* statistic. It is typically used to uncover patterns in data such as crime densities, traffic accident fatalities, or biodiversity.

**Parameters:**
- **Input Features:** The point or polygon feature layer for which hot spots will be calculated. Type: Feature Set.
- **Output Name:** The name of the output layer to create on your portal. Type: String.
- **Analysis Field (Optional):** A numeric field to be evaluated, such as crime rates or test scores. Type: Field.
- **Divide By Field (Optional):** A numeric field used to normalize data, such as population for per capita analysis. Type: Field.
- **Bounding Polygon Layer (Optional):** When specified, defines the area within which hot spots are calculated. Type: Feature Set.
- **Aggregate Polygon Layer (Optional):** Defines polygons over which points are aggregated and analyzed. Type: Feature Set.

**Derived Output:**
- **Output Layer:** The output hot spot layer. Type: Feature Set.

**Example ArcPy code:**
```python
import arcpy

# Set local variables
input_features = "https://sampleserver6.arcgisonline.com/arcgis/rest/services/SF311/FeatureServer/0"
output_name = "HotSpotsOF311Data"
bins = "500 Meters"
neighborhood = "1 Kilometers"
time_step = "1 Months"
data_store = "SPATIOTEMPORAL_DATA_STORE"

# Execute Find Hot Spots
arcpy.geoanalytics.FindHotSpots(
    inFeatures=input_features,
    outFS=output_name,
    bins=bins,
    neighborhood=neighborhood,
    timeStep=time_step,
    dataStore=data_store
)
```
**Toolset:** Analyze Patterns

**Tool:** Find Point Clusters

**Description:**  
The Find Point Clusters tool identifies clusters of point features amidst surrounding noise based on their spatial or spatiotemporal distribution. It is typically used to analyze spatial patterns in datasets where points represent events or occurrences, such as wildlife sightings or crime incidents.

**Parameters:**
- **inputPoints:** The point layer containing the features to be clustered. Type: Feature Layer.
- **outputName:** The name for the output layer containing the identified clusters. Type: String.
- **clusterMethod:** The method used for clustering, either DBSCAN or HDBSCAN. Type: String.
- **minimumPoints:** The minimum number of points required to form a cluster. Type: Integer.
- **searchDistance:** The distance within which points are considered part of the same cluster. Type: Linear Unit.
- **use_time (Optional):** Specifies whether time will be used to discover clusters with DBSCAN. Type: Boolean.
- **search_duration (Optional):** The time duration within which points must be found to form a cluster. Type: Time Unit.

**Derived Output:**
- **output:** The output point clusters. Type: Feature Set.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data/CountyData.gdb"

# Define local variables
inputPoints = "rat_sightings"
minimumPoints = 10
outputName = "RodentClusters"
searchDistance = "1 Kilometers"
clusterMethod = "DBSCAN"

# Execute Find Point Clusters
arcpy.gapro.FindPointClusters(
    inputPoints=inputPoints,
    outputName=outputName,
    clusterMethod=clusterMethod,
    minimumPoints=minimumPoints,
    searchDistance=searchDistance
)
```

Feel free to ask more about the Analyze Patterns toolset or explore other tools within ArcGIS Pro.
No information available.
**Toolset:** Analyze Patterns

**Tool:** Generalized Linear Regression

**Description:**  
The Generalized Linear Regression tool performs regression analysis to model a dependent variable based on its relationship with one or more explanatory variables. It supports continuous (OLS), binary (logistic), and count (Poisson) models, making it versatile for various applications such as predicting crime rates, analyzing demographic impacts on public transportation usage, and forecasting emergency response demands.

**Parameters:**
- **Input Features:** The feature class containing the dependent and explanatory variables.  
  *Type:* Feature Layer.
- **Dependent Variable:** The numeric field containing the observed values to be modeled.  
  *Type:* Field.
- **Model Type:** Specifies the type of data to be modeled: Continuous (Gaussian), Binary (Logistic), or Count (Poisson).  
  *Type:* String.
- **Explanatory Variable(s):** A list of fields representing independent explanatory variables in the regression model.  
  *Type:* Field.
- **Output Features:** The new feature class containing the dependent variable estimates.  
  *Type:* Feature Class.

**Derived Output:**
- **Output Predicted Features:** The output feature class with the dependent variable estimates for each prediction location.  
  *Type:* Feature Class.
- **Coefficient Table:** An output table containing the coefficients from the model fit.  
  *Type:* Table.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = r"c:\data\project_data.gdb"

# Run Generalized Linear Regression
arcpy.stats.GeneralizedLinearRegression(
    in_features="crime_counts",
    dependent_variable="total_crimes",
    model_type="COUNT",
    out_features="predicted_features",
    explanatory_variables=["YRBLT", "TOTPOP", "AVGHINC"],
    prediction_locations="CBD",
    dependent_variable_mapping=[["No Arrest", "Arrest"]],
    output_predicted_features="predicted_features"
)
```
No information available.
**Toolset: Find Locations**

**Tool: Detect Incidents**

**Description:**  
The Detect Incidents tool creates a layer that identifies features meeting a specified condition. It is typically used to detect events or changes in data that meet certain criteria, such as identifying locations where a specific threshold is exceeded.

**Parameters:**
- **inFeatures**: The input features to analyze. Type: Feature Layer.
- **outFS**: The output feature service name where the detected incidents will be stored. Type: String.
- **trackIdentifier**: A field used to identify distinct tracks or sequences of features. Type: Field.
- **start_condition**: An expression that defines the condition to start an incident. Type: String.

**Derived Output:**
- **output**: The output features that meet a given condition. Type: Record Set.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set local variables
inFeatures = "https://sampleserver6.arcgisonline.com/arcgis/rest/services/Hurricanes/MapServer/0"
outFS = "HurricaneTracks_Incidents"
trackIdentifier = "STAGE"
start_condition = "$feature['WINDSPEED'] > 100"

# Execute Detect Incidents
arcpy.geoanalytics.DetectIncidents(inFeatures, outFS, trackIdentifier, start_condition)
```
**Toolset:** Find Locations

**Tool:** Find Dwell Locations

**Description:** The Find Dwell Locations tool identifies areas where moving objects have stopped or dwelled using specified time and distance thresholds. It is typically used to analyze movement data to detect stay points or idle periods, such as tracking vehicles or animals to understand their behavior patterns.

**Parameters:**
- **Input Features:** The point tracks in which dwells will be found. The input must be a time-enabled layer with features that represent instants in time. Type: Feature Layer.
- **Output Dataset:** The output feature class with the resulting dwells. Type: Feature Class.
- **Track Fields:** One or more fields that will be used to identify unique tracks. Type: Field.
- **Distance Method:** Specifies how the distances between dwell features will be calculated. Options include Geodesic and Planar. Type: String.
- **Distance Tolerance:** The maximum distance between points to be considered a single dwell location. Type: Linear Unit.
- **Time Tolerance:** The minimum time duration to be considered a single dwell location. Type: Time.

**Derived Output:**
- **Dwell location:** Features representing when a track has been stationary given specified time and distance parameters. This output can be represented as points, convex hulls, or mean centers. Type: Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data/MovementData.gdb"

# Define the input parameters
input_features = "TimeEnabledPoints"
output_dataset = "DwellLocations"
track_fields = ["TrackID"]
distance_method = "Planar"
distance_tolerance = "100 Meters"
time_tolerance = "2 Hours"

# Run the Find Dwell Locations tool
arcpy.gapro.FindDwellLocations(
    input_features=input_features,
    output_dataset=output_dataset,
    track_fields=track_fields,
    distance_method=distance_method,
    distance_tolerance=distance_tolerance,
    time_tolerance=time_tolerance
)
```
**Toolset:** Find Locations

**Tool:** Find Similar Locations

**Description:**  
The Find Similar Locations tool identifies candidate features that are most similar or dissimilar to one or more input features based on feature attributes. It is typically used to find locations that share similar characteristics with a reference location, such as identifying stores similar to a top-performing store.

**Parameters:**
- **referenceStore:** The input feature or features to which similarity is measured. Type: *String*.
- **candidateStores:** The features among which the most similar ones will be found. Type: *String*.
- **analysisFields:** A list of fields used to determine similarity. Type: *List*.
- **outputName:** The name of the output feature class. Type: *String*.
- **dataStore:** Specifies the ArcGIS Data Store where the output will be stored. Type: *String*.

**Derived Output:**
- **output:** Features from the input and all the solution-matching features found. Type: *Record Set*.

**Example ArcPy code:**
```python
import arcpy

# Set local variables
referenceStore = "TopPerformer"
candidateStores = "AllStores"
analysisFields = ["SickDays", "TotalCustomers", "AvgPurchaseAmount"]
outputName = "BestStores_10"

# Execute Find Similar Locations
arcpy.gapro.FindSimilarLocations(
    referenceStore=referenceStore,
    candidateStores=candidateStores,
    outputName=outputName,
    analysisFields=analysisFields,
    matchMethod="MOST_SIMILAR",
    matchType="ATTRIBUTE_VALUES",
    numberOfResults=10
)
```

Feel free to ask more about the Find Locations toolset or explore other tools within ArcGIS Pro.
**Toolset:** Manage Data

**Tool:** Calculate Field

**Description:**  
The Calculate Field tool is used to compute values for a specified field in a feature class, feature layer, or raster. It is typically used to update or populate fields with calculated values based on expressions, which can be simple or complex, using Python, Arcade, SQL, or VBScript.

**Parameters:**
- **Input Layer:** The input features that will have a field calculated.  
  *Type:* Record Set.
- **Output Name:** The name of the output feature service.  
  *Type:* String.
- **Field Name:** The name of the field that will have values calculated. This can be an existing field or a new field.  
  *Type:* String.
- **Field Type:** Specifies the field type for the calculated field.  
  *Type:* String (options include String, Integer, Double, Date).
- **Expression:** Calculates values in the field. Expressions are written in Arcade and can include operators like [+ - * /].  
  *Type:* String.

**Derived Output:**
- **Output Table:** The updated table with calculated fields.  
  *Type:* Table View; Raster Layer; Mosaic Layer.

**Example ArcPy code:**
```python
import arcpy

# Define the input parameters
input_layer = "path/to/your/input/layer"
field_name = "NewField"
expression = "!existing_field! * 2"  # Example expression using Python syntax

# Execute the Calculate Field tool
arcpy.management.CalculateField(
    in_table=input_layer,
    field=field_name,
    expression=expression,
    expression_type="PYTHON3"
)
```
**Toolset:** Manage Data

**Tool:** Clip Layer

**Description:** The Clip Layer tool is used to cut out a piece of a feature class using one or more features from another feature class as a cookie cutter. This is particularly useful for creating a feature class that contains a geographic subset of the features from another, larger feature class.

**Parameters:**
- **input_layer:** The dataset containing the point, line, or polygon features to be clipped. Type: Feature Layer.
- **clip_layer:** The dataset containing the polygon features used to clip the input features. Type: Feature Layer.
- **out_feature_class:** The output feature class with clipped features. Type: Feature Class.

**Derived Output:**
- **Output Feature Class:** The clipped output. Type: Feature Set.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "C:/data/USA.gdb"

# Define local variables
clipFeatures = "USA_Rivers"
studyArea = "Nebraska_Boundary"
out = "NebraskaRivers"

# Execute Clip Layer
arcpy.gapro.ClipLayer(clipFeatures, studyArea, out)
```
**Toolset:** Manage Data

**Tool:** Dissolve Boundaries

**Description:** The Dissolve Boundaries tool merges polygons that overlap or share a common boundary into a single polygon. It is typically used to simplify data by removing unnecessary boundaries, such as merging adjacent counties into state boundaries based on a shared attribute like `State_Name`.

**Parameters:**
- **Input Layer:** The layer containing polygon features that will be dissolved or combined. Type: Feature Set.
- **Output Name:** The name of the output layer to create on your portal. Type: String.
- **Dissolve Fields (Optional):** One or more fields from the input layer that control which polygons are merged. Type: Field.
- **Summary Fields (Optional):** A list of field names and statistical summary types to calculate for all points within each polygon. Supported statistics include SUM, MIN, MAX, MEAN, and STDDEV. Type: Value Table.

**Derived Output:**
- **Output:** The output polygon layer with dissolved boundaries. Type: Feature Set.

**Example ArcPy code:**
```python
import arcpy

# Set local variables
inputLayer = "https://sampleserver6.arcgisonline.com/arcgis/rest/services/USA_counties/FeatureServer/0"
outputName = "USA_State_Boundaries"
statistics = [["population", "SUM"]]
dataStore = "RELATIONAL_DATA_STORE"

# Execute DissolveBoundaries using "STATE" as the Dissolve Field
arcpy.geoanalytics.DissolveBoundaries(
    inputLayer=inputLayer,
    outputName=outputName,
    dissolveType="SINGLE_PART",
    dissolveFields="STATE",
    summaryFields=statistics,
    dataStore=dataStore
)
```
**Toolset:** Manage Data

**Tool:** Overlay Layers

**Description:** The Overlay Layers tool in ArcGIS Pro overlays the geometries from multiple layers into a single layer. It can be used to combine, erase, modify, or update spatial features, answering geographic questions such as "What is on top of what?" Typical use cases include determining intersecting areas or removing certain features from a dataset.

**Parameters:**
- **Input Layer:** The point, line, or polygon features that will be overlaid with the overlay layer. Type: Feature Layer.
- **Overlay Layer:** The features that will be overlaid with the input layer features. Type: Feature Layer.
- **Out Feature Class:** A new feature class with overlaid features. Type: Feature Class.
- **Overlay Type:** Specifies the type of overlay to be performed. Options include INTERSECT, ERASE, UNION, IDENTITY, and SYMMETRICAL_DIFFERENCE. Type: String.
- **Include Overlaps (Optional):** Specifies whether one or both of the input layers have overlapping features. Type: Boolean.
- **Data Store (Optional):** Specifies the ArcGIS Data Store where the output will be stored. Options include SPATIOTEMPORAL_DATA_STORE and RELATIONAL_DATA_STORE. Type: String.

**Derived Output:**
- **Output:** The overlay of multiple layers into a single layer. Type: Feature Set.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "c:/data/data.gdb"

# Define local variables
inFeatures = "areasOfInterest"
overlayFeatures = "commercial"
out = "DevelopmentSites"
overlayType = "ERASE"

# Execute Overlay Layers
arcpy.gapro.OverlayLayers(inFeatures, overlayFeatures, out, overlayType)
```
**Toolset:** Summarize Data

**Tool:** Aggregate Points

**Description:**  
The Aggregate Points tool aggregates point features into polygon features or bins, returning a polygon with a count of points and optional statistics at locations where points exist. It is typically used to summarize point data within specified boundaries, such as aggregating sales data within district boundaries.

**Parameters:**
- **Input Layer:** The point features to be aggregated.  
  *Type:* Feature Layer.
- **Output Feature Class:** The feature class that will contain the aggregated polygons.  
  *Type:* Feature Class.
- **Aggregation Distance:** The distance within which points will be clustered.  
  *Type:* Linear Unit.

**Derived Output:**
- **Output Table:** A one-to-many relationship table linking aggregated polygons to their source point features.  
  *Type:* Table.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set local variables
in_point_features = "C:/data/cartography.gdb/crime/robberies"
out_feature_class = "C:/data/cartography.gdb/crime/clustered_robberies"
aggregation_distance = "100 meters"

# Execute Aggregate Points
arcpy.cartography.AggregatePoints(in_point_features, out_feature_class, aggregation_distance)
```
**Toolset:** Summarize Data

**Tool:** Describe Dataset

**Description:** The Describe Dataset tool summarizes features into calculated field statistics, sample features, and extent boundaries. It is typically used to create a sample of a dataset, preview features, and calculate summary statistics for datasets with time or geometry.

**Parameters:**
- **input_layer:** The point, line, polygon, or tabular features to be described. Type: Table View.
- **output:** A new table with the summary information. Type: Table.
- **sample_features (Optional):** The number of features that will be included in the output sample layer. No sample is returned if you select 0 features or don't provide a number. By default, no sample layer is returned. Type: Long.
- **sample_layer (Optional):** A new feature class with a sample of the input data. Type: Table; Feature Class.
- **extent_layer (Optional):** A new feature class with the spatial and temporal extent of the input data. Type: Feature Class.

**Derived Output:**
- **output:** The output layer containing the summarized statistic calculations. Type: Record Set.
- **extent_layer:** When the create_extent_layer parameter is selected, the tool will output a layer containing a single polygon representing the extent of your dataset. Type: Feature Set.
- **sample_layer:** When the sample_features parameter specifies a value greater than zero, the tool will output a layer containing the specified number of sample features from your dataset. Type: Feature Set.
- **output_json:** This parameter is not used. A JSON string containing all of the summary information calculated in analysis is included in the tool's messages. Type: String.

**Example ArcPy code:**
```python
import arcpy

# Set local variables
inputDataset = "WaterSample"
output = "WSample_summary"
sample = "WSample_sample2500"

# Run Describe Dataset
arcpy.gapro.DescribeDataset(inputDataset, output, 2500, sample)
```
**Toolset: Summarize Data**

**Tool: Join Features**

**Description:**  
The Join Features tool in ArcGIS Pro is used to join attributes from one layer to another based on spatial, temporal, or attribute relationships, or a combination of those relationships. This tool is typically used to analyze spatial relationships between datasets, such as determining how many features in one layer are within a certain distance of features in another layer.

**Parameters:**
- **Target Layer**: Contains the target features. The attributes from the target features and the attributes from the joined features will be transferred to the output.  
  *Type: Table View*.
- **Join Layer**: Contains the join features. The attributes from the join features will be joined to the attributes of the target features. The join operation affects how the aggregation of joined attributes is handled. Type: Table View.
- **Output Dataset**: The new feature class containing the target layer features with joined features. Type: Feature Class; Table.
- **Join Operation**: Specifies how joins between the Target Layer values and the Join Layer values will be handled in the output if multiple join features have the same spatial relationship with a single target feature. Options include:
  - **Join one to one**: Aggregates attributes from multiple join features.
  - **Join one to many**: The output feature class will contain multiple copies of the target feature with attributes from each join feature. Type: String.
- **Spatial Relationship (Optional)**: Specifies the criteria for spatially joining features. Options include:
  - **Intersects**: Default option, matches features that intersect a target feature.
  - **Equals**: Matches features that are the same geometry as a target feature.
  - **Planar Near**: Matches features within a specified distance. Type: String.

**Derived Output:**
- **Output Layer or View**: The updated input dataset. Type: Table View; Raster Layer; Mosaic Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/city.gdb"

# Define local variables
target_layer = "TargetLayer"
join_layer = "JoinLayer"
output_dataset = "OutputFeatureClass"
join_operation = "JOIN_ONE_TO_ONE"
spatial_relationship = "INTERSECTS"

# Run Join Features
arcpy.analysis.JoinFeatures(
    target_layer,
    join_layer,
    output_dataset,
    join_operation,
    spatial_relationship
)

print("Join Features tool executed successfully.")
```
**Toolset:** Summarize Data

**Tool:** Reconstruct Tracks

**Description:** The Reconstruct Tracks tool creates line or polygon tracks from time-enabled input data. It is typically used to analyze movement patterns by reconstructing paths from point or polygon data that represent moments in time.

**Parameters:**
- **input_layer:** The points or polygons to be reconstructed into tracks. The input must be a time-enabled layer that represents an instant in time. Type: Feature Set.
- **output_name:** The name of the output feature service. Type: String.
- **track_fields:** One or more fields that will be used to identify unique tracks. Type: Field.
- **method:** Specifies the criteria that will be used to reconstruct tracks. Options include GEODESIC and PLANAR. Type: String.
- **buffer_type:** Specifies how the buffer distance will be defined. Options include FIELD and EXPRESSION. Type: String.
- **buffer_field (Optional):** The field that will be used to buffer the input features. Type: Field.
- **buffer_expression (Optional):** The expression that will be used to buffer input features. Type: Calculated Expression.

**Derived Output:**
- **Output Feature Class:** The output line or polygon tracks. Type: Feature Set.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set local variables
inFeatures = "https://sampleserver6.arcgisonline.com/arcgis/rest/services/Hurricanes/MapServer/0"
outFS = "HurricaneTracks"
trackIdentifier = "EVENTID"
bufferExpression = "WINDSPEED * 100"
statistics = [["PRESSURE", "MEAN"]]

# Run Reconstruct Tracks
arcpy.geoanalytics.ReconstructTracks(
    input_layer=inFeatures,
    output_name=outFS,
    track_fields=trackIdentifier,
    method="GEODESIC",
    buffer_type="EXPRESSION",
    buffer_expression=bufferExpression,
    summary_fields=statistics
)
```
**Toolset:** Summarize Data

**Tool:** Summarize Attributes

**Description:**  
The Summarize Attributes tool calculates summary statistics for fields in a feature class. It is typically used for tabular analysis to derive statistical insights from attribute data, such as counts, sums, averages, and other descriptive statistics.

**Parameters:**
- **inFeatures:** The input feature class containing the data to be summarized. Type: Feature Set.
- **summaryFields:** Fields by which to summarize the data. Type: List of Strings.
- **summaryStatistics:** A list of statistical operations to perform on the fields, such as COUNT, SUM, MIN, MAX, etc. Type: List of Lists.
- **outFS:** The name of the output feature service containing the summarized data. Type: String.
- **dataStore (Optional):** Specifies the ArcGIS Data Store where the output will be stored. Type: String.

**Derived Output:**
- **output:** The output table with summarized attributes. Type: Record Set.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/CityData.gdb"

# Set local variables
inFeatures = "ChicagoCrimes"
summaryFields = ["Year", "Beat"]
summaryStatistics = [["Arrest", "COUNT"], ["District", "COUNT"]]
outFS = 'SummarizeCrimes'
dataStore = "SPATIOTEMPORAL_DATA_STORE"

# Execute SummarizeAttributes
arcpy.geoanalytics.SummarizeAttributes(inFeatures, outFS, summaryFields, summaryStatistics, dataStore)
```
**Toolset:** Summarize Data

**Tool:** Summarize Center And Dispersion

**Description:**  
The Summarize Center And Dispersion tool identifies central features and directional distributions, calculating mean and median locations from the input data. It is typically used to analyze spatial patterns and trends, such as the movement of fire occurrences or the spread of diseases over time.

**Parameters:**
- **inFeatures:** The input feature class containing the data to be analyzed. Type: Feature Class.
- **outMeanCenter:** The output feature class for the mean center of the input data. Type: Feature Class.
- **outEllipse:** The output feature class for the standard deviational ellipse of the input data. Type: Feature Class.
- **ellipse_size (Optional):** Specifies the size of output ellipses in standard deviations (e.g., 1_STANDARD_DEVIATION, 2_STANDARD_DEVIATIONS, 3_STANDARD_DEVIATIONS). Type: String.
- **weight_field (Optional):** A numeric field used to weight locations according to their relative importance. Type: Field.
- **group_by_field (Optional):** The field used to group similar features for analysis. Type: Field.

**Derived Output:**
- **Mean Center:** The calculated mean center location of the input features. Type: Feature Class.
- **Standard Deviational Ellipse:** The calculated ellipse representing the dispersion of the input features. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set local variables
inFeatures = r"c:\data\MyBigDataConnection.bdc\fire_incidents"
outMeanCenter = r"c:\data\FireIncidents.gdb\fires_meancenter"
outEllipse = r"c:\data\FireIncidents.gdb\fires_ellipse"

# Run SummarizeCenterAndDispersion
arcpy.gapro.SummarizeCenterAndDispersion(
    inFeatures, 
    "", 
    outMeanCenter, 
    "", 
    outEllipse, 
    "2_STANDARD_DEVIATIONS"
)
```
**Toolset:** Summarize Data

**Tool:** Summarize Within

**Description:** The Summarize Within tool overlays a polygon layer with another layer to summarize the number of points, length of lines, or area of polygons within each polygon. It calculates attribute field statistics for those features within the polygons. Typical use cases include calculating total acreage of land-use types within watershed boundaries or summarizing the average value of vacant parcels within city boundaries.

**Parameters:**
- **Input Polygons:** The polygons that will be used to summarize the features, or portions of features, in the input summary layer. Type: Feature Layer.
- **Input Summary Features:** The point, line, or polygon features that will be summarized for each polygon in the input polygons. Type: Feature Layer.
- **Output Feature Class:** The output polygon feature class containing the same geometries and attributes as the input polygons, with additional attributes for the number of points, length of lines, and area of polygons inside each input polygon and statistics about those features. Type: Feature Class.
- **Keep all input polygons (Optional):** Specifies whether all input polygons or only those intersecting or containing at least one input summary feature will be copied to the output feature class. Type: Boolean.
- **Summary Fields (Optional):** A list of attribute field names from the input summary features, as well as statistical summary types that will be calculated. Type: List.

**Derived Output:**
- **Output Feature Class:** The output polygon feature class containing summarized data. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set local variables
input_polygons = "Watershed_Boundaries"
input_summary_features = "Land_Use_Boundaries"
output_feature_class = "LandUse_Summary"

# Execute Summarize Within
arcpy.analysis.SummarizeWithin(
    in_polygons=input_polygons,
    in_sum_features=input_summary_features,
    out_feature_class=output_feature_class,
    keep_all_polygons="KEEP_ALL",
    summary_fields=[["LandUseType", "SUM"]]
)
```
**Toolset:** Use Proximity

**Tool:** Create Buffers

**Description:** The Create Buffers tool generates polygons that cover a specified distance from point, line, or polygon features. It is typically used to identify areas within a certain proximity to features, such as determining zones of influence or areas affected by a particular feature.

**Parameters:**
- **Input Layer:** The point, polyline, or polygon features that will be buffered. Type: Feature Layer.
- **Output Feature Class:** The new feature class of buffered results. Type: Feature Class.
- **Method:** Specifies the method used to create the buffers. Options include Geodesic (default) and Planar. Type: String.
- **Distance:** The buffer distance specified as a numeric value with units (e.g., "300 Meters"). Type: String.
- **Dissolve Type:** Specifies how overlapping buffers are handled. Options include None, All, and Fields. Type: String.
- **End Type:** The shape of the buffer at the end of line input features, either Round or Flat. Type: String.

**Derived Output:**
- **Output Buffers Layer:** The resulting layer containing the buffer polygons. Type: Feature Set.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/DamageSurvey.gdb"

# Define input and output parameters
inFeatures = "DamageAssessment"
outFeatureClass = "DangerousAreas"

# Execute Create Buffers
arcpy.gapro.CreateBuffers(
    inFeatures=inFeatures,
    out_feature_class=outFeatureClass,
    method="GEODESIC",
    distance="300 Meters",
    dissolve_type="ALL",
    end_type="ROUND"
)
```
**Toolset:** Use Proximity

**Tool:** Group By Proximity

**Description:** The Group By Proximity tool groups features that are within spatial or spatiotemporal proximity to each other. Typical use cases include identifying connected roads, clustering crime incidents that occur close in time and space, and grouping overlapping polygons.

**Parameters:**
- **inFeatures:** The input features to be grouped. Type: Feature Set.
- **outname:** The name for the output feature class. Type: String.
- **overlayType:** Specifies the spatial relationship used for grouping. Options include TOUCHES, INTERSECTS, NEAR_GEODESIC, and NEAR_PLANAR. Type: String.
- **dataStore (Optional):** Specifies where the output will be stored. Options include SPATIOTEMPORAL_DATA_STORE and RELATIONAL_DATA_STORE. Type: String.
- **temporal_relationship (Optional):** Specifies the time criteria for grouping features. Options include INTERSECTS, NEAR, and NONE. Type: String.
- **temporal_near_distance (Optional):** The temporal distance for grouping near features. Type: Time Unit.
- **attribute_relationship (Optional):** An ArcGIS Arcade expression for grouping features by attribute. Type: String.

**Derived Output:**
- **output:** A new feature class with grouped features represented by a new field named `group_id`. Type: Feature Set.

**Example ArcPy code:**
```python
import arcpy

# Set local variables
inFeatures = "C:/myData/cities.gdb/roads"
outname = "groupedRoads"
overlayType = "TOUCHES"

# Run Group By Proximity
result = arcpy.gapro.GroupByProximity(inFeatures, outname, overlayType)
```
**Toolset:** Use Proximity

**Tool:** Snap Tracks

**Description:** The Snap Tracks tool is designed to snap input track points to lines. It is typically used for time-enabled point data that represents an instant in time, requiring traversable lines with fields indicating the from and to nodes for analysis.

**Parameters:**
- **tracksLayer:** The input point layer containing time-enabled observations. Type: Feature Layer.
- **lineLayer:** The input line layer containing connectivity information. Type: Feature Layer.
- **trackIdentifier:** A field that uniquely identifies each track. Type: String.
- **searchDistance:** The maximum distance within which tracks will be snapped to lines. Type: Linear Unit.
- **connectivityFieldMatching:** Specifies the fields used to match connectivity between lines. Type: String.
- **directionValueMatching:** Specifies the direction values for matching. Type: String.

**Derived Output:**
- **out:** The output dataset containing snapped tracks. Type: Feature Set.

**Example ArcPy code:**
```python
import arcpy

# Set local variables
tracksLayer = "https://sampleserver.arcgisonline.com/arcgis/rest/services/DeliveryTrucks/MapServer/0"
lineLayer = "https://sampleserver.arcgisonline.com/arcgis/rest/services/CityStreets/MapServer/0"
trackIdentifier = "vehicle_id"
out = "trucks_snapped_to_streets"
searchDistance = "30 Feet"
connectivityFieldMatching = "unique_ID from_node to_node"
directionValueMatching = "dir_travel F T B #"

# Run Snap Tracks
arcpy.gapro.SnapTracks(tracksLayer, lineLayer, out, trackIdentifier, searchDistance, connectivityFieldMatching, None, "GEODESIC", directionValueMatching)
```

Feel free to ask more about the Use Proximity toolset or other tools in ArcGIS Pro.
**Toolset:** Use Proximity

**Tool:** Trace Proximity Events

**Description:** The Trace Proximity Events tool identifies events that are near each other in both space and time. It is typically used for analyzing time-enabled point data to determine spatial and temporal proximity among events.

**Parameters:**
- **Input Points:** The time-enabled point feature class used to trace proximity events. Type: Feature Layer.
- **Entity ID Field:** The text field representing unique IDs for each entity. Type: Field.
- **Distance Method:** Specifies the distance type used with the Spatial Search Distance parameter. Options include Planar and Geodesic. Type: String.
- **Spatial Search Distance (Optional):** The maximum distance between two points to be considered in proximity. Type: Linear Unit.
- **Temporal Search Distance (Optional):** The maximum duration between two points to be considered in proximity. Type: Time Unit.
- **Define Entities of Interest Using (Optional):** Specifies the entities of interest. Options include Entities of Interest IDs and Selected features in a specified entity of interest layer. Type: String.
- **Entities of Interest IDs:** The entity names and start times for the entities of interest. Type: Value Table.
- **Entities of Interest Layer:** The layer or table containing the entities of interest. Type: Feature Layer.

**Derived Output:**
- **Output Proximity Events:** The output feature class containing the trace proximity events. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/path/to/your/workspace"

# Define parameters
input_points = "TimeEnabledPoints"
entity_id_field = "EntityID"
distance_method = "Planar"
spatial_search_distance = "100 Meters"
temporal_search_distance = "1 Days"
entities_of_interest = "EntitiesLayer"

# Run the Trace Proximity Events tool
arcpy.geoanalytics.TraceProximityEvents(
    input_points=input_points,
    entity_id_field=entity_id_field,
    distance_method=distance_method,
    spatial_search_distance=spatial_search_distance,
    temporal_search_distance=temporal_search_distance,
    entities_of_interest=entities_of_interest
)
```
**Toolset:** Projections and Transformations

**Tool:** Batch Project

**Description:** The Batch Project tool changes the coordinate system of a set of input feature classes or feature datasets to a common coordinate system. It is typically used when multiple datasets need to be reprojected to the same spatial reference for consistency in analysis or mapping.

**Parameters:**
- **input_features**: The feature classes or datasets to be reprojected. Type: List of Feature Classes.
- **out_workspace**: The workspace where the output feature classes will be stored. Type: Workspace.
- **out_cs**: The output coordinate system. If left empty, the coordinate system of the template dataset will be used. Type: Coordinate System.
- **template**: A template dataset that defines the output coordinate system if `out_cs` is not specified. Type: Feature Class.
- **transformation**: The geographic transformation to be applied if necessary. Type: String.

**Derived Output:**
- **out_features**: The reprojected feature classes stored in the specified output workspace. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set workspace environment
arcpy.env.workspace = "C:/data/wgs1972.gdb"

# Input feature classes
input_features = ["cities", "counties", "blocks", "crime"]

# Output workspace
out_workspace = "C:/data/output.gdb"

# Output coordinate system - leave it empty to use template's coordinate system
out_cs = ''

# Template dataset - it has GCS_WGS_1984 coordinate system
template = "C:/data/wgs1984.gdb/stateparks"

# Geographic transformation
transformation = "WGS_1972_To_WGS_1984_1"

# Run Batch Project tool
arcpy.management.BatchProject(input_features, out_workspace, out_cs, template, transformation)
```

Feel free to ask if you need further clarification or have additional questions about using the Batch Project tool in ArcGIS Pro.
**Toolset:** Projections and Transformations

**Tool:** Convert Coordinate Notation

**Description:** The Convert Coordinate Notation tool is used to convert coordinate notations contained in one or two fields from one notation format to another. This tool is typically used in scenarios where geographic data needs to be transformed into a different coordinate format for analysis or visualization purposes.

**Parameters:**
- **Input Table:** The table containing the coordinates to be converted. Type: Table.
- **Output Points:** The output feature class that will contain the converted coordinates. Type: Feature Class.
- **X Field:** The field containing the x-coordinate or longitude. Type: Field.
- **Y Field:** The field containing the y-coordinate or latitude. Type: Field.
- **Input Coordinate Format:** The format of the input coordinates (e.g., DD_2, DDM_2, DMS_2). Type: String.
- **Output Coordinate Format:** The format to which the coordinates will be converted (e.g., MGRS, GARS). Type: String.
- **ID Field (Optional):** A field containing unique identifiers for the input records. Type: Field.
- **Spatial Reference (Optional):** The spatial reference of the input data. If not specified, defaults to GCS_WGS_1984. Type: Spatial Reference.

**Derived Output:**
- **Output Feature Class:** The feature class containing the converted coordinates. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = r"c:\data\mtf.gdb"

# Define input parameters
input_table = 'rit_up_DD'
output_points = 'ritLOC'
x_field = 'LON'
y_field = 'LAT'
input_format = 'DD_2'
output_format = 'GARS'
id_field = 'CITY_NAME'
spatial_ref = arcpy.SpatialReference('WGS 1984')

# Execute Convert Coordinate Notation
try:
    arcpy.management.ConvertCoordinateNotation(
        input_table, output_points, x_field, y_field, input_format, output_format, id_field, spatial_ref
    )
    print(arcpy.GetMessages(0))
except arcpy.ExecuteError:
    print(arcpy.GetMessages(2))
except Exception as ex:
    print(ex.args[0])
```
**Toolset:** Projections and Transformations

**Tool:** Create Custom Geographic Transformation

**Description:** The Create Custom Geographic Transformation tool is used to define a transformation for converting data between two geographic coordinate systems or datums. This transformation can be applied in any tool requiring a geographic transformation parameter.

**Parameters:**
- **Geographic Transformation Name:** The name of the custom transformation definition. Type: String.
- **Input Geographic Coordinate System:** The starting geographic coordinate system. Must be a geographic coordinate system; a projected coordinate system is invalid. Type: Coordinate System.
- **Output Geographic Coordinate System:** The final geographic coordinate system. Must be a geographic coordinate system; a projected coordinate system is invalid. Type: Coordinate System.
- **Custom Geographic Transformation:** The custom transformation method to be used. Type: String.
- **Extent (Optional):** The geographic area where the transformation is applicable. Type: Extent.

**Derived Output:**
- **out_transformation:** The output transformation. Type: Value Table.

**Example ArcPy code:**
```python
import arcpy

# Set the name for the custom geographic transformation
geoTransfmName = "cgt_geocentric2"

# Create spatial reference objects for the input and output geographic coordinate systems
inGCS = arcpy.SpatialReference("Tokyo")
outGCS = arcpy.SpatialReference("WGS 1984")

# Define the custom geographic transformation method
customGeoTransfm = "GEOGTRAN[METHOD['Geocentric_Translation'],PARAMETER['X_Axis_Translation',''],PARAMETER['Y_Axis_Translation',''],PARAMETER['Z_Axis_Translation','']]"

# Create the custom geographic transformation
arcpy.management.CreateCustomGeoTransformation(geoTransfmName, inGCS, outGCS, customGeoTransfm)
```
**Toolset:** Projections and Transformations

**Tool:** Create Custom Vertical Transformation

**Description:**  
The Create Custom Vertical Transformation tool is used to define a transformation for converting data between two vertical coordinate systems or datums. This transformation can be utilized by any tool requiring a vertical transformation, facilitating accurate data conversion across different vertical systems.

**Parameters:**
- **Vertical Transformation Name:** The name of the custom transformation definition.  
  *Type:* String.
  
- **Source Vertical Coordinate System:** The starting vertical coordinate system. Provide a well-known ID (WKID) or use the Select Coordinate System button to select a coordinate system.  
  *Type:* String.
  
- **Target Vertical Coordinate System:** The final vertical coordinate system. Provide a WKID or use the Select Coordinate System button to select a coordinate system.  
  *Type:* String.
  
- **Interpolation Geographic Coordinate System (Optional):** The geographic coordinate system used for interpolation if required by the transformation method.  
  *Type:* Coordinate System.
  
- **Vertical Transformation Method (Optional):** The method used to transform data from the input vertical coordinate system to the output vertical coordinate system.  
  *Type:* String.

**Derived Output:**
- **out_transformation:** The output transformation.  
  *Type:* Value Table.

**Example ArcPy code:**
```python
import arcpy

# Define the vertical transformation parameters
vt_name = "NAD_1983_2011_ellipsoid_to_GEOID18b"
source_vt_coor_system = 'VERTCS["NAD_1983_2011",DATUM["D_NAD_1983_2011",SPHEROID["GRS_1980",6378137.0,298.257222101]],PARAMETER["Vertical_Shift",0.0],PARAMETER["Direction",1.0],UNIT["Meter",1.0]]'
target_vt_coor_system = 'VERTCS["GEOID18b",DATUM["D_GEOID18b",SPHEROID["GRS_1980",6378137.0,298.257222101]],PARAMETER["Vertical_Shift",0.0],PARAMETER["Direction",1.0],UNIT["Meter",1.0]]'

# Create the custom vertical transformation
arcpy.management.CreateCustomVerticalTransformation(
    vt_name=vt_name,
    source_vt_coor_system=source_vt_coor_system,
    target_vt_coor_system=target_vt_coor_system
)

# Print success message
print("Custom vertical transformation created successfully.")
```
No information available.
**Toolset:** Projections and Transformations

**Tool:** Define Projection

**Description:**  
The Define Projection tool is used to overwrite the coordinate system information (map projection and datum) stored with a dataset. It is particularly useful for datasets that have an unknown or incorrect coordinate system defined.

**Parameters:**
- **Input Dataset or Feature Class**: The dataset or feature class for which the coordinate system information is to be defined. Type: *Feature Layer*.
- **Coordinate System**: The coordinate system to be assigned to the input dataset. Type: *Spatial Reference*.

**Derived Output:**
- **Output Dataset**: The dataset with the newly defined coordinate system. Type: Dataset.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "C:/data"

try:
    # Set local variables
    in_dataset = "citylimit_unk.shp"
    coordinate_system = arcpy.SpatialReference("NAD 1983 StatePlane California V FIPS 0405 (US Feet)")

    # Define the projection
    arcpy.management.DefineProjection(in_dataset, coordinate_system)

    # Print the success message
    print(arcpy.GetMessages(0))

except arcpy.ExecuteError:
    # Print geoprocessing message
    print(arcpy.GetMessages(2))

except Exception as ex:
    # Print the exception message
    print(ex.args[0])
```
**Toolset:** Projections and Transformations

**Tool:** Project

**Description:** The Project tool in ArcGIS Pro is used to transform spatial data from one coordinate system to another. It is typically used when you need to convert datasets to a common coordinate system for analysis or visualization.

**Parameters:**
- **Input Dataset or Feature Class:** The input feature classes or datasets whose coordinates are to be converted. Type: Feature Layer; Feature Dataset.
- **Output Dataset or Feature Class:** The location of the new output feature class or dataset. Type: Feature Dataset; Workspace.
- **Output Coordinate System:** The coordinate system to be used for the output. Type: Coordinate System.
- **Transformation (Optional):** The name of the geographic transformation to be applied to convert data between two geographic coordinate systems (datums). Type: String.

**Derived Output:**
- **Updated Output Workspace:** The location of each new output feature class or feature dataset. Type: Workspace; Feature Dataset.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/Redlands.gdb"
arcpy.env.overwriteOutput = True

# Define input and output parameters
input_features = "Redlands.shp"
output_feature_class = "Redlands_Project.shp"
out_coordinate_system = arcpy.SpatialReference('NAD 1983 StatePlane California V FIPS 0405 (US Feet)')

# Run the Project tool
arcpy.management.Project(input_features, output_feature_class, out_coordinate_system)

# Print messages
print(arcpy.GetMessages())
```
**Toolset:** Projections and Transformations

**Tool:** Project LAS

**Description:** The Project LAS tool is used to reproject .las or .zlas files from one coordinate system to another. This tool is typically used to ensure that lidar data aligns with a specific spatial reference system for analysis and visualization purposes.

**Parameters:**
- **in_las_dataset:** The input .las or .zlas files that will be projected. A LAS dataset can also be provided to process all of the .las and .zlas files it references. Type: LAS Dataset Layer.
- **target_folder:** The existing folder where the output .las files will be written. Type: Folder.
- **coordinate_system:** The coordinate system of the output LAS format files. Valid values are a Spatial Reference object, a file with a .prj extension, or a string representation of a coordinate system. Type: Coordinate System.
- **geographic_transform:** (Optional) This method can be used for converting data between two geographic coordinate systems or datums. Type: String.
- **compression:** (Optional) Specifies the compression method for the output files. Type: String.
- **las_options:** (Optional) Options for processing the LAS files, such as rearranging points or computing statistics. Type: String.
- **name_modifier:** (Optional) Modifies the output file names by adding characters to the beginning and end of their existing file names. Type: String.
- **out_las_dataset:** (Optional) The LAS dataset that will reference the newly created .las or .zlas files. Type: Value Table.

**Derived Output:**
- **out_folder:** The folder containing the projected .las or .zlas files. Type: Folder.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data"

# Define the input LAS dataset and output parameters
in_las_dataset = "British_Tiled.lasd"
target_folder = r"Projected/BNG_Newlyn"
coordinate_system = arcpy.SpatialReference(27700, 5701)  # British National Grid/Newlyn VCS
geographic_transform = "'~WGS_1984_To_WGS_1984_EGM2008_1x1_Height + ~ETRS_1989_To_WGS_1984 + ETRS89_To_Newlyn_Height_2_OSGM15 + ~OSGB_1936_To_ETRS_1989_1'"
compression = "ZLAS"
las_options = ['REARRANGE', 'COMPUTE_STATISTICS', 'REMOVE_VLR']
name_modifier = "Projected__BNG_Newlyn"

# Run the Project LAS tool
arcpy.management.ProjectLAS(
    in_las_dataset=in_las_dataset,
    target_folder=target_folder,
    coordinate_system=coordinate_system,
    geographic_transform=geographic_transform,
    compression=compression,
    las_options=las_options,
    name_modifier=name_modifier
)
```
**Toolset:** Raster

**Tool:** Convert Feature to Raster

**Description:** Converts features such as points, lines, or polygons into a raster dataset. This tool is typically used for spatial analysis where raster data is required, such as in environmental modeling or land use planning.

**Parameters:**
- **Input Features:** The input feature layer to be converted. Type: Feature Set.
- **Value Field:** The field used to assign values to the output raster. Type: Field.
- **Output Name:** The name of the output raster service. Type: String.
- **Output Cell Size:** The cell size and unit for the output raster. Units can be Kilometers, Meters, Statute Miles, International Feet, US Survey Miles, and US Survey Feet. Type: Linear Unit.

**Derived Output:**
- **Output Raster:** The resulting raster layer from the conversion process. Type: Raster Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define local variables
inputFeatures = "roads.shp"
valueField = "CLASS"
outputName = "c:/output/roadsgrid"
outputCellSize = 25

# Execute ConvertFeatureToRaster
arcpy.ra.ConvertFeatureToRaster(inputFeatures, valueField, outputName, outputCellSize)
```
**Toolset:** Raster

**Tool:** Convert Raster to Feature

**Description:**  
The "Convert Raster to Feature" tool transforms a raster dataset into a feature dataset, which can be in the form of points, lines, or polygons. This tool is typically used in scenarios where spatial analysis requires vector data representation of raster data, such as when performing spatial queries or overlay operations in a GIS environment.

**Parameters:**
- **Input Raster Layer**: The input raster layer to be converted.  
  *Type: Raster Layer*.
- **Field:** A field that specifies the conversion value. It can be any integer or text value. A field containing floating-point values can only be used if the output is to a point dataset. The default is the Value field, which contains the value in each raster cell. Type: Field.
- **Output Type:** Specifies the output type. Options include:
  - **Point:** The raster will be converted to point features.
  - **Line:** The raster will be converted to line features.
  - **Polygon:** The raster will be converted to polygon features. Type: String.
- **Simplify Lines or Polygons (Optional):** Specifies whether lines or polygons will be simplified (smoothed). The smoothing is done in such a way that the line contains a minimum number of vertices while remaining as close as possible to the original shape. Options include:
  - **Checked:** The line or polygon features will be smoothed to produce a more generalized result. This is the default.
  - **Unchecked:** The line or polygon features will not be smoothed.
- **Create Multipart Features (Optional):** Specifies whether the output polygons will consist of single-part or multipart features.
  - **Checked:** Multipart features will be created based on the same value.
  - **Unchecked:** Individual (single-part) features will be created.

**Derived Output:**
- **Output Feature Class:** The output feature class that will contain the converted point, line, or polygon features. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data"

# Define input and output parameters
input_raster = "input_raster.tif"
output_feature_class = "C:/output/converted_features.shp"
field = "Value"
output_type = "Polygon"  # Options: "Point", "Line", "Polygon"
simplify = "SIMPLIFY"  # Options: "SIMPLIFY" or "NO_SIMPLIFY"
create_multipart = "SINGLE_OUTER_PART"  # Options: "SINGLE_OUTER_PART" or "NO_MULTIPART"

# Run the Convert Raster to Feature tool
arcpy.conversion.RasterToPolygon(
    in_raster=input_raster,
    out_polygon_features="C:/output/converted_features.shp",
    simplify=simplify,
    raster_field="VALUE",
    create_multipart=create_multipart
)
```
No information available.
**Toolset: Raster**

**Tool: Math**

**Description:**  
The Math toolset in ArcGIS Pro is designed to perform a variety of mathematical operations on raster data. These operations are categorized into arithmetic, power, exponential, logarithmic, sign conversion, and type conversion functions. The toolset is typically used for tasks such as performing basic mathematical operations (addition, subtraction, multiplication, division), exponentiation, logarithmic calculations, and conversions between integer and floating-point data types.

**Parameters:**
- **Input Raster or Constant Value 1**: The first input raster or a constant value. Type: Raster Layer or Constant.
- **Input Raster or Constant Value 2**: The second input raster or constant value for operations like Plus, Minus, Times, Divide, and Mod. Type: Raster Layer or Constant Value.

**Derived Output:**
- **Output Raster**: The result of the mathematical operation applied to the input raster(s). Type: Raster Dataset.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set local variables
inRaster1 = "elevation"
inRaster2 = "landuse"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute Divide
outDivide = Divide(inRaster1, inRaster2)

# Save the output
outDivide.save("C:/output/outdivide")
```
**Toolset:** Raster

**Tool:** Reclass

**Description:**  
The Reclass tool in ArcGIS Pro is used to reclassify or change the values in a raster. It is typically used to replace values based on new information, group certain values, reclassify values to a common scale, or set specific values to NoData.

**Parameters:**
- **Input raster:** The raster to be reclassified.  
  *Type:* Raster Layer.
- **Reclass field:** The field denoting the values that will be reclassified.  
  *Type:* Field.
- **Reclassification:** A remap table that defines how the values will be reclassified.  
  *Type:* Remap Table.

**Derived Output:**
- **Output raster:** The reclassified raster. The output will always be of integer type.  
  *Type:* Raster.

**Example ArcPy code:**
```python
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "landuse"
reclassField = "LANDUSE"
remap = RemapValue([["Brush/transitional", 0], ["Water", 1], ["Barren land", 2]])

# Execute Reclassify
outReclassify = Reclassify(inRaster, reclassField, remap, "NODATA")

# Save the output
outReclassify.save("C:/sapyexamples/output/outreclass02")
```
No information available.
**Toolset:** Relationship Classes

**Tool:** Create Relationship Class

**Description:**  
The Create Relationship Class tool in ArcGIS Pro is used to establish associations between fields or features in an origin table and a destination table within a geodatabase. It is typically used to define relationships that can be simple one-to-one or complex one-to-many, ensuring data integrity and facilitating data management workflows.

**Parameters:**
- **Origin Table:** The table or feature class associated with the destination table.  
  *Type:* Table/Feature Class.
  
- **Destination Table:** The table associated with the origin table.  
  *Type:* Table/Feature Class.
  
- **Output Relationship Class:** The name of the relationship class to be created.  
  *Type:* String.
  
- **Relationship Type:** Specifies the type of relationship (Simple or Composite) between the origin and destination tables.  
  *Type:* String.
  
- **Forward Path Label:** A unique name for navigating from the origin table to the destination table.  
  *Type:* String.
  
- **Backward Path Label:** A unique name for navigating from the destination table to the origin table.  
  *Type:* String.
  
- **Message Direction:** Specifies the direction of message passing between tables (Forward, Backward, None).  
  *Type:* String.
  
- **Cardinality:** Defines the relationship cardinality (One to one, One to many, Many to many).  
  *Type:* String.
  
- **Relationship class is attributed:** Indicates if the relationship class will have attributes.  
  *Type:* Boolean.
  
- **Origin Primary Key:** The field in the origin table linking to the foreign key in the destination table.  
  *Type:* String.
  
- **Origin Foreign Key:** The field in the destination table linking to the primary key in the origin table.  
  *Type:* String.

**Derived Output:**
- **Output Relationship Class:** The created relationship class with specified rules and attributes.  
  *Type:* Relationship Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define parameters
origin_table = "Montgomery.gdb/Parcels"
destination_table = "Montgomery.gdb/owners"
output_relationship_class = "Montgomery.gdb/parcelowners_RelClass"
relationship_type = "SIMPLE"
forward_path_label = "Owns"
backward_path_label = "Is Owned By"
message_direction = "BACKWARD"
cardinality = "ONE_TO_MANY"
origin_primary_key = "PROPERTY_ID"
origin_foreign_key = "PROPERTY_ID"

# Create relationship class
arcpy.management.CreateRelationshipClass(
    origin_table,
    destination_table,
    output_relationship_class,
    relationship_type,
    forward_path_label,
    backward_path_label,
    message_direction,
    cardinality,
    "NONE",  # No attributes
    origin_primary_key,
    origin_foreign_key
)
```
**Toolset:** Relationship Classes

**Tool:** Table To Relationship Class

**Description:** The Table To Relationship Class tool in ArcGIS Pro creates an attributed relationship class from existing origin, destination, and relationship tables. It is typically used to establish many-to-many relationships or relationships that include attributes, allowing for complex associations between data entities in a geodatabase.

**Parameters:**
- **Relationship Table:** An existing table containing attributes that will be added to the relationship class. Type: Table.
- **Attribute Fields:** The names of the fields present in the Relationship Table containing the attribute values that will be added to the intermediate table in the attributed relationship class. Type: Field.
- **Origin Primary Key:** The field in the origin table that will be used to create the relationship. Type: String.
- **Origin Foreign Key:** The name of the field in the relationship table that refers to the primary key field in the origin table or feature class. Type: String.
- **Destination Primary Key:** The field in the destination table that will be used to create the relationship. Type: String.
- **Destination Foreign Key:** The field in the relationship table that refers to the primary key field in the destination table or feature class. Type: String.

**Derived Output:**
- **Output Relationship Class:** The newly created attributed relationship class. Type: Relationship Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/Montgomery.gdb"

# Define parameters
relationship_table = "owners"
origin_table = "Parcels"
output_relationship_class = "ownersParcels_RelClass"
relationship_type = "SIMPLE"
forward_label = "Owns"
backward_label = "Is Owned By"
message_direction = "BACKWARD"
cardinality = "MANY_TO_MANY"
attribute_fields = ["OWNER_PERCENT", "DEED_DATE"]
origin_primary_key = "OBJECTID"
origin_foreign_key = "owner_id"
destination_primary_key = "OBJECTID"
destination_foreign_key = "parcel_id"

# Execute TableToRelationshipClass
arcpy.management.TableToRelationshipClass(
    relationship_table,
    origin_table,
    output_relationship_class,
    relationship_type,
    forward_label,
    backward_label,
    message_direction,
    cardinality,
    relationship_table,
    attribute_fields,
    origin_primary_key,
    origin_foreign_key,
    destination_primary_key,
    destination_foreign_key
)
```
**Toolset:** Relationship Classes

**Tool:** Add Rule To Relationship Class

**Description:**  
The "Add Rule To Relationship Class" tool is used to add a rule to an existing relationship class in a geodatabase. This tool is typically used to define or restrict the types of relationships that can exist between objects in the origin and destination classes, ensuring data integrity and enforcing business rules.

**Parameters:**
- **Input Relationship Class:** The relationship class to which a rule will be added.  
  *Type:* Relationship Class.
- **Origin Subtype (Optional):** Specifies the subtype of the origin class. If the origin class has subtypes, choose the subtype to which you want to associate a relationship class rule. If the origin class has no subtypes, the relationship rule will apply to all features.  
  *Type:* String.
- **Origin Minimum (Optional):** Specifies the minimum range cardinality for the origin class if the relationship class is many-to-many.  
  *Type:* Long.
- **Origin Maximum (Optional):** Specifies the maximum range cardinality for the origin class if the relationship class is many-to-many or one-to-many.  
  *Type:* Long.
- **Destination Subtype (Optional):** Specifies the subtype of the destination class. If the destination class has subtypes, choose the subtype to which you want to associate a relationship class rule. If the destination class has no subtypes, the relationship rule will apply to all features.  
  *Type:* String.
- **Destination Minimum (Optional):** Specifies the minimum range cardinality for the destination class if the relationship class is many-to-many or one-to-many.  
  *Type:* Long.
- **Destination Maximum (Optional):** Specifies the maximum range cardinality for the destination class if the relationship class is many-to-many or one-to-many.  
  *Type:* Long.

**Derived Output:**
- **out_rel_class:** The updated relationship class with the relationship rule added.  
  *Type:* Relationship Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define the parameters for the Add Rule To Relationship Class tool
input_relationship_class = "C:\\MyProject\\sdeConn.sde\\progdb.user1.ParcelsToBuildings"
origin_subtype = "Residential"
origin_minimum = 0
origin_maximum = 1
destination_subtype = "House"
destination_minimum = 1
destination_maximum = 3

# Execute the Add Rule To Relationship Class tool
arcpy.management.AddRuleToRelationshipClass(
    input_relationship_class,
    origin_subtype,
    origin_minimum,
    origin_maximum,
    destination_subtype,
    destination_minimum,
    destination_maximum
)
```
**Toolset:** Relationship Classes

**Tool:** Remove Rule From Relationship Class

**Description:** The "Remove Rule From Relationship Class" tool is used to delete a specific rule from a relationship class within a geodatabase. This tool is typically used to manage and update the rules that define how objects in a geodatabase relate to each other, ensuring that the relationships are current and accurate.

**Parameters:**
- **Input Relationship Class:** The relationship class from which the rule will be removed.  
  *Type:* Relationship Class.
- **Origin Subtype (Optional):** Specifies the subtype of the origin class associated with the rule to be deleted, if subtypes exist.  
  *Type:* String.
- **Destination Subtype (Optional):** Specifies the subtype of the destination class associated with the rule to be deleted, if subtypes exist.  
  *Type:* String.
- **Remove All (Optional):** Determines whether all relationship rules will be removed from the relationship class.  
  *Type:* Boolean.

**Derived Output:**
- **Updated Relationship Class:** The relationship class after the rule has been removed.  
  *Type:* Relationship Class.

**Example ArcPy code:**
```python
import arcpy

# Define the input parameters
input_relationship_class = "C:\\MyProject\\sdeConn.sde\\progdb.user1.ParcelsToBuildings"
origin_subtype = "Residential"
destination_subtype = "House"

# Execute the Remove Rule From Relationship Class tool
arcpy.management.RemoveRuleFromRelationshipClass(
    in_rel_class=input_relationship_class,
    origin_subtype=origin_subtype,
    destination_subtype=destination_subtype
)
```
**Toolset:** Relationship Classes

**Tool:** Migrate Relationship Class

**Description:** The Migrate Relationship Class tool in ArcGIS Pro is used to convert an existing relationship class that is based on ObjectID to one that uses GlobalID. This conversion is necessary to meet runtime geodatabase requirements, ensuring compatibility with versioned and nonversioned data.

**Parameters:**
- **Input Relationship Class:** An object ID-based relationship class that will be migrated to a global ID-based relationship class. The origin and destination feature classes or tables must have an existing GlobalID field.  
  *Type:* Relationship Class

**Derived Output:**
- **Migrated Relationship Class:** The updated relationship class after migration.  
  *Type:* Relationship Class

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
workspace = r'C:\Data\Relationships.gdb'

# Define the input relationship class
in_relationship_class = workspace + r'\YourRelationshipClass'

# Execute the Migrate Relationship Class tool
arcpy.management.MigrateRelationshipClass(in_relationship_class)

# Print messages
print(arcpy.GetMessages())
```
**Toolset:** Relationship Classes

**Tool:** Set Relationship Class Split Policy

**Description:** The Set Relationship Class Split Policy tool is used to define the split policy for a relationship class, which determines how related records are handled when a feature in the origin feature class is split during editing. Typical use cases include managing how data is duplicated or preserved in geodatabase relationships when features are split.

**Parameters:**
- **Input Relationship Class:** The relationship class on which the split policy will be set. The origin feature class must be a polyline or polygon feature class, and the destination must be a nonspatial table. Type: Relationship Class.
- **Relationship Class Split Policy:** Specifies the split policy to apply to the relationship class. Options include:
  - **Default (composite):** Preserves relationships on the largest resulting feature for composite relationship classes.
  - **Default (simple):** Preserves relationships on the largest resulting feature for simple relationship classes.
  - **Duplicate related objects:** Generates copies of related objects for both resulting parts. Requires the relationship class to be Global ID based. Type: String.

**Derived Output:**
- **Output Relationship Class:** The updated relationship class with the split policy set. Type: Relationship Class.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/MyProject/sdeConn.sde"

# Define the input relationship class and split policy
input_rel_class = "progdb.user1.ParcelsToBuildings"
split_policy = "DUPLICATE_RELATED_OBJECTS"

# Execute the Set Relationship Class Split Policy tool
arcpy.management.SetRelationshipClassSplitPolicy(input_rel_class, split_policy)
```
**Toolset:** Sampling

**Tool:** Create Fishnet

**Description:** The Create Fishnet tool generates a feature class consisting of a grid of rectangular cells. It is typically used to create a spatial grid for analysis, such as overlaying with other datasets to aggregate or sample data.

**Parameters:**
- **Output Feature Class:** The feature class that will contain the fishnet of rectangular cells. Type: Feature Class.
- **Fishnet Origin Coordinate:** The starting point of the fishnet. Type: Point.
- **Y-Axis Coordinate:** The y-axis coordinate used to orient the fishnet, determining its rotation. Type: Point.
- **Cell Size Width:** The width of each cell in the fishnet. If set to zero, it will be calculated based on the number of rows. Type: Double.
- **Cell Size Height:** The height of each cell in the fishnet. If set to zero, it will be calculated based on the number of columns. Type: Double.
- **Number of Rows:** The number of rows in the fishnet. If set to zero, it will be calculated based on the cell size width. Type: Long.
- **Number of Columns:** The number of columns in the fishnet. If set to zero, it will be calculated based on the cell size height. Type: Long.

**Derived Output:**
- **Output Feature Class:** The resulting feature class containing the fishnet grid. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define parameters
output_feature_class = "fishnet_output.shp"
origin_coordinate = "0 0"
y_axis_coordinate = "0 10"
cell_width = 110
cell_height = 63
num_rows = 0
num_columns = 0

# Create fishnet
arcpy.management.CreateFishnet(
    out_feature_class=output_feature_class,
    origin_coord=origin_coordinate,
    y_axis_coord=y_axis_coordinate,
    cell_width=cell_width,
    cell_height=cell_height,
    number_rows=num_rows,
    number_columns=num_columns
)
```

Feel free to ask if you need further details on using the Create Fishnet tool or any other ArcGIS Pro functionalities.
**Toolset:** Sampling

**Tool:** Create Random Points

**Description:** The Create Random Points tool generates a specified number of random point features within a defined extent. These points can be used as sampling locations for various analyses, such as environmental studies or spatial data collection.

**Parameters:**
- **out_path**: The workspace or folder where the output feature class will be stored. Type: *Workspace*.
- **out_name**: The name of the output feature class. Type: *String*.
- **constraining_feature_class**: A feature class that constrains where random points can be placed. Type: *Feature Class*.
- **constraining_extent**: The extent within which random points will be generated. Type: *Extent*.
- **number_of_points**: The total number of random points to be created. Type: *Long*.
- **minimum_allowed_distance**: The shortest distance allowed between any two randomly placed points. Type: *Linear Unit*.
- **create_multipoint_output**: Determines if the output feature class will be a multipart or single-part feature. Type: *Boolean*.
- **multipoint_size**: If create_multipoint_output is set to MULTIPOINT, specify the number of random points to be placed in each multipoint geometry. Type: *Long*.

**Derived Output:**
- **out_feature_class**: The output random points feature class. Type: *Feature Class*.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define parameters
out_path = "C:/data/project"
out_name = "samplepoints"
constraining_feature_class = "C:/data/studyarea.shp"
number_of_points = 500
create_multipoint_output = "POINT"

# Execute CreateRandomPoints
arcpy.management.CreateRandomPoints(out_path, out_name, constraining_feature_class, "", number_of_points, "", create_multipoint_output)
```
**Toolset:** Sampling

**Tool:** Create Spatial Sampling Locations

**Description:**  
The "Create Spatial Sampling Locations" tool generates sample locations within a continuous study area using various sampling designs such as simple random, stratified, systematic (gridded), or cluster sampling. This tool is typically used for environmental studies, resource management, and other applications requiring spatially distributed sample points.

**Parameters:**
- **inputStudyArea:** The study area where sampling locations will be generated. Type: Feature Layer.
- **outputFeatures:** The output feature class that will contain the generated sample locations. Type: Feature Class.
- **samplingMethod:** The method used for sampling, such as "RANDOM" for simple random sampling or "STRAT_POLY" for stratified by polygons. Type: String.
- **strataCountMethod:** Method to determine the number of samples per stratum, such as "EQUAL" or "PROP_AREA". Type: String.
- **numSamplesPerStrata:** The number of samples to create per stratum. Type: Long.
- **minDistance:** The minimum distance allowed between any two sample points. Type: Linear Unit.

**Derived Output:**
- **outputFeatures:** The feature class containing the generated sample locations. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Allow overwriting output
arcpy.env.overwriteOutput = True

# Define the study area and output features
inputStudyArea = "C:/samplingdata/inputs.gdb/study_area_polygons"
outputFeatures = "C:/samplingdata/outputs.gdb/out_samples_SRS"

# Define the sampling method and number of samples
samplingMethod = "RANDOM"
numSamples = 50

# Define the minimum distance between any two points
minDistance = "15 NauticalMilesInt"

# Run tool
try:
    arcpy.management.CreateSpatialSamplingLocations(
        inputStudyArea, 
        outputFeatures, 
        samplingMethod, 
        "", 
        "", 
        "", 
        "", 
        "", 
        numSamples, 
        "", 
        "", 
        "", 
        minDistance
    )
except arcpy.ExecuteError:
    # If an error occurred when running the tool, print the error message
    print(arcpy.GetMessages())
```
**Toolset:** Sampling

**Tool:** Create Spatially Balanced Points

**Description:** The Create Spatially Balanced Points tool generates a set of sample points based on inclusion probabilities, resulting in a spatially balanced sample design. This tool is typically used for designing a monitoring network by suggesting locations to take samples, with a preference for particular locations defined using an inclusion probability raster.

**Parameters:**
- **Input Inclusion Probability Raster:** Defines the inclusion probabilities for each location in the area of interest. The location values must range from 0 (low inclusion probability) to 1 (high inclusion probability). Type: Raster Layer; Mosaic Layer.
- **Number of Output Points:** The number of sample locations that will be created. Type: Long.
- **Output Point Feature Class:** The output feature class containing the selected sample locations and their inclusion probabilities. Type: Feature Class.

**Derived Output:**
- **Output Point Feature Class:** The output feature class containing the selected sample locations and their inclusion probabilities. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/gapyexamples/data"

# Set local variables
inProb = "ca_prob"
numberPoints = 10
outPoints = "C:/gapyexamples/output/csbp"

# Execute CreateSpatiallyBalancedPoints
arcpy.management.CreateSpatiallyBalancedPoints(inProb, numberPoints, outPoints)
```
**Toolset:** Sampling

**Tool:** Generate Points Along Lines

**Description:** The Generate Points Along Lines tool creates point features along lines or polygons. It is typically used to place points at regular intervals or specific distances along linear features, which can be useful for sampling or analysis purposes.

**Parameters:**
- **in_features:** The input line features along which points will be generated. Type: Feature Layer.
- **out_feature_class:** The output feature class containing the generated points. Type: Feature Class.
- **Point_Placement:** Specifies the method used to place the output points. Options include 'DISTANCE', 'PERCENTAGE', and 'DISTANCE_FIELD'. Type: String.
- **Distance (Optional):** The interval distance at which points will be placed along the line. Type: Linear Unit.
- **Percentage (Optional):** The percentage of the line's length at which points will be placed. Type: Double.
- **Distance_Field (Optional):** A field from the input features that specifies distances for point placement. Type: Field.
- **Include_End_Points (Optional):** Specifies whether points will be generated at the start and end of the input line. Options are 'END_POINTS' or 'NO_END_POINTS'. Type: Boolean.

**Derived Output:**
- **out_feature_class:** The output feature class containing the generated points. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data/base.gdb'

# Set local variables
in_features = 'rivers'
out_fc_1 = 'distance_intervals'
out_fc_2 = 'percentage_intervals'

# Run GeneratePointsAlongLines by distance
arcpy.management.GeneratePointsAlongLines(in_features, out_fc_1, 'DISTANCE', Distance='500 meters')

# Run GeneratePointsAlongLines by percentage
arcpy.management.GeneratePointsAlongLines(in_features, out_fc_2, 'PERCENTAGE', Percentage=10, Include_End_Points='END_POINTS')

# Run GeneratePointsAlongLines by distance field
arcpy.management.GeneratePointsAlongLines(in_features, out_fc_2, 'DISTANCE_FIELD', Distance_Field='distance')
```
No information available.
**Toolset:** Sampling

**Tool:** Generate Tessellation

**Description:** The Generate Tessellation tool creates a tessellated grid of regular polygon features to cover a given extent. This grid can consist of triangles, squares, diamonds, hexagons, H3 hexagons, or transverse hexagons, and is typically used for aggregating other spatial data.

**Parameters:**
- **Output Feature Class:** The feature class that will contain the tessellated grid. Type: Feature Class.
- **Geometry Type:** Specifies the shape of the tessellation, such as triangles, squares, or hexagons. Type: String.
- **Extent:** The spatial extent within which the tessellation will be generated. Type: Extent.
- **Cell Size:** The size of each cell in the tessellation. Type: Double.

**Derived Output:**
- **Tessellated Grid:** The output grid of polygon features covering the specified extent. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define parameters
output_feature_class = "C:/data/tessellation.gdb/tessellated_grid"
geometry_type = "HEXAGON"
extent = arcpy.Extent(0, 0, 10000, 10000)
cell_size = 1000

# Execute Generate Tessellation
arcpy.management.GenerateTessellation(output_feature_class, geometry_type, extent, cell_size)
```
**Toolset:** Sampling

**Tool:** Generate Transects Along Lines

**Description:** The Generate Transects Along Lines tool creates perpendicular transect lines at regular intervals along specified line features. It is typically used for environmental sampling, such as measuring cross-sections of rivers or roads.

**Parameters:**
- **in_features:** The line features along which perpendicular transect lines will be generated. *Type: Feature Layer*.
- **out_feature_class:** The output perpendicular transect lines generated along the input features. *Type: Feature Class*.
- **interval:** The interval from the beginning of the feature at which transects will be generated. *Type: Linear Unit*.
- **transect_length:** The length or width of the transect line. Each transect will be placed such that half its length falls on one side of the line, and half on the other. *Type: Linear Unit*.
- **include_ends (Optional):** Specifies whether transects will be generated at the start and end of the input line. *Type: Boolean*.

**Derived Output:**
- **out_feature_class:** The output feature class containing the generated transect lines. *Type: Feature Class*.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data/base.gdb'

# Set local variables
in_features = 'rivers'
out_feature_class = 'river_sample_transects'
interval = '100 Meters'
transect_length = '200 Meters'  # Double the distance to specify the transect length
include_ends = 'NO_END_POINTS'

# Execute GenerateTransectsAlongLines
arcpy.management.GenerateTransectsAlongLines(in_features, out_feature_class, interval, transect_length, include_ends)
```
**Toolset:** Subtypes

**Tool:** Add Subtype

**Description:**  
The Add Subtype tool is used to add a new subtype to the subtypes in the input table or feature class. Subtypes allow for logical grouping of features or objects based on an attribute value, facilitating consistent attribute assignment and behavior across subsets.

**Parameters:**  
- **Input Table:** The feature class or table containing the subtype definition to be updated.  
  *Type:* Table View.  
- **Subtype Code:** A unique integer value for the subtype to be added.  
  *Type:* Long.  
- **Subtype Name:** A name (also known as description) of the subtype code.  
  *Type:* String.

**Derived Output:**  
- **Updated Input Table:** The updated table or feature class.  
  *Type:* Table View.

**Example ArcPy code:**  
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data/Montgomery.gdb"

# Define the input feature class
inFeatures = "water/fittings"

# Set the subtype field
arcpy.management.SetSubtypeField(inFeatures, "TYPECODE")

# Define subtype codes and descriptions
stypeDict = {
    "0": "Unknown",
    "1": "Bend",
    "2": "Cap",
    "3": "Cross",
    "4": "Coupling",
    "5": "Expansion joint",
    "6": "Offset",
    "7": "Plug",
    "8": "Reducer",
    "9": "Saddle",
    "10": "Sleeve",
    "11": "Tap",
    "12": "Tee",
    "13": "Weld",
    "14": "Riser"
}

# Add subtypes using a loop
for code, description in stypeDict.items():
    arcpy.management.AddSubtype(inFeatures, code, description)
```
**Toolset:** Subtypes

**Tool:** Remove Subtype

**Description:** The "Remove Subtype" tool is used to remove a subtype from a feature class or table using its code. This is typically used when managing data in a geodatabase to ensure that only relevant subtypes are maintained.

**Parameters:**
- **Input Table:** The feature class or table containing the subtype definition.  
  *Type:* Table View.
- **Subtype Code:** The subtype code to remove from the input table or feature class.  
  *Type:* String.

**Derived Output:**
- **Updated Input Table:** The updated table or feature class after the subtype has been removed.  
  *Type:* Table View.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data/Montgomery.gdb"

# Define the input feature class and the subtype codes to remove
inFeatures = "water/fittings"
stypeList = ["5", "6", "7"]

# Remove the specified subtypes
arcpy.management.RemoveSubtype(inFeatures, stypeList)
```

Feel free to ask if you need further clarification on using subtypes in ArcGIS Pro or any other related topic.
**Toolset:** Subtypes

**Tool:** Set Default Subtype

**Description:**  
The Set Default Subtype tool is used to set the default value or code for a subtype within an input table or feature class. This tool is typically used in workflows where subtypes are defined to categorize data, ensuring that a default subtype is automatically applied when new features are created.

**Parameters:**
- **Input Table:** The input table or feature class whose subtype default value will be set.  
  *Type:* Table View.
- **Subtype Code:** The unique default value for a subtype.  
  *Type:* Long.

**Derived Output:**
- **Updated Input Table:** The updated table or feature class with the default subtype set.  
  *Type:* Table View.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data/Montgomery.gdb"

# Define the input feature class and the default subtype code
in_table = "water/fittings"
subtype_code = 5

# Set the default subtype
arcpy.management.SetDefaultSubtype(in_table, subtype_code)
```
**Toolset:** Subtypes

**Tool:** Set Subtype Field

**Description:** The Set Subtype Field tool defines the field in the input table or feature class that stores the subtype codes. It is typically used to organize data into logical groupings based on attribute values, facilitating efficient data management and analysis.

**Parameters:**
- **Input Table:** The input table or feature class that contains the field to set as a subtype field. Type: Table View.
- **Field Name (Optional):** The integer field that will store the subtype codes. Type: Field.
- **Clear Value (Optional):** Specifies whether to clear the subtype field. Type: Boolean. Options are:
  - **Checked:** The subtype field will be cleared (set to null).
  - **Unchecked:** The subtype field will not be cleared (default).

**Derived Output:**
- **Updated Input Table:** The updated table or feature class. Type: Table View.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data/Montgomery.gdb"

# Define the feature class and field to store subtype codes
inFeatures = "water/fittings"
field = "TYPECODE"

# Set the subtype field
arcpy.management.SetSubtypeField(inFeatures, field)
```
**Toolset: Table**

**Tool: Analyze**

**Description:**  
The Analyze tool is used to update database statistics for business tables, feature tables, and delta tables, as well as the statistics of those tables' indexes. This is essential for optimizing query performance in enterprise geodatabases, particularly for databases like Oracle, SQL Server, and PostgreSQL.

**Parameters:**
- **Input Dataset**: The table or feature class to be analyzed. Type: Layer; Table View; Dataset.
- **Components to Analyze**: Specifies the component type that will be analyzed. Options include:
  - **BUSINESS**: Updates business rules statistics.
  - **FEATURE**: Updates feature statistics.
  - **RASTER**: Updates statistics on raster tables.
  - **ADDS**: Updates statistics on added datasets.
  - **DELETES**: Updates statistics on deleted datasets. Type: String.

**Derived Output:**
- **out_dataset**: The geodatabase input dataset with updated statistics. Type: Layer; Table View; Dataset.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
# Description: Gathers statistics for the indexes on the business table of the input dataset

# Import system modules
import arcpy

# Set local variables
in_dataset = "c:/Connections/ninefour@gdb.sde/GDB.ctgPrimaryFeature"
components = "BUSINESS"

# Run Analyze
arcpy.management.Analyze(in_dataset, components)
```
**Toolset:** Table

**Tool:** Copy Rows

**Description:** The Copy Rows tool is used to copy the rows of a table, table view, feature class, feature layer, delimited file, or raster with an attribute table to a new geodatabase or dBASE table or a delimited file. It is typically used for data conversion and management tasks where the geometry of features is not required, only the attribute information.

**Parameters:**
- **in_rows:** The input rows to be copied to a new table. Type: Table View; Raster Layer.
- **out_table:** The table that will be created and to which rows from the input will be copied. If the output table is in a folder, include an extension such as .csv, .txt, or .dbf to make the table the specified format. If the output table is in a geodatabase, do not specify an extension. Type: Table.
- **config_keyword (Optional):** The default storage parameters for an enterprise geodatabase. Type: String.

**Derived Output:**
- No specific derived outputs are listed for this tool.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "C:/data"

# Define input and output tables
in_rows = "vegtable.dbf"
out_table = "C:/output/output.gdb/vegtable"

# Execute the CopyRows tool
arcpy.management.CopyRows(in_rows, out_table)
```
No information available.
**Toolset:** Table

**Tool:** Create Unregistered Table

**Description:** The Create Unregistered Table tool is used to create an empty table in an enterprise database, enterprise geodatabase, GeoPackage, or SQLite database. The table created is not registered with the geodatabase, which means it does not participate in geodatabase functionality until registered. This tool is typically used when a user needs to create a table structure without immediately integrating it into the geodatabase system.

**Parameters:**
- **out_path:** The enterprise database or enterprise geodatabase where the table will be created. Type: Workspace.
- **out_name:** The name of the table that will be created. Type: String.
- **template (Optional):** An existing dataset or list of datasets with fields and attribute schema that will be used to define the fields in the output table. Type: Table View.
- **config_keyword (Optional):** Specifies the default storage parameters (configurations) for geodatabases in a relational database management system (RDBMS). This setting is applicable only when using enterprise geodatabase tables. Type: String.

**Derived Output:**
- **out_table:** The output unregistered table. Type: Table.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define the parameters
out_path = r'Database Connections\Connection to Organization.sde'
out_name = 'New_Table'

# Execute the Create Unregistered Table tool
arcpy.management.CreateUnRegisteredTable(out_path, out_name)
```
**Toolset:** Table

**Tool:** Delete Rows

**Description:** The Delete Rows tool removes all or a selected subset of rows from the input dataset. It is typically used to clean up data by removing unwanted records from tables or feature classes.

**Parameters:**
- **Input Rows:** The feature class, layer, table, or table view whose rows will be deleted. Type: Table View.

**Derived Output:**
- **Updated Input With Rows Removed:** The updated input with the specified rows deleted. Type: Table View.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "C:/data"

# Define the input table
in_rows = "accident.dbf"

# Use the DeleteRows tool to delete rows
arcpy.management.DeleteRows(in_rows)
```
**Toolset:** Table

**Tool:** Get Count

**Description:** The Get Count tool returns the total number of rows for a table. It is typically used to determine the number of records in a dataset, especially when working with selected records or within a specified extent.

**Parameters:**
- **Input Rows:** The input table view or raster layer. If a selection is defined on the input, the count of the selected rows will be returned.  
  **Type:** Table View; Raster Layer.

**Derived Output:**
- **Row Count:** The total number of rows for the input.  
  **Type:** Long.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "C:/data/data.gdb"

# Use the Get Count tool to determine the number of features in a feature class
result = arcpy.management.GetCount("roads")

# Convert the result to an integer and print it
count = int(result[0])
print(f'roads has {count} records')
```

This script sets up the environment, runs the Get Count tool on a feature class named "roads," and prints the number of records found.
**Toolset:** Table

**Tool:** Pivot Table

**Description:** The Pivot Table tool in ArcGIS Pro creates a table from the input table by reducing redundancy in records and flattening one-to-many relationships. It is typically used to transform data so that each unique combination of specified fields results in a single record, with additional fields created for each unique value in the pivot field.

**Parameters:**
- **Input Table:** The table containing the records that will be pivoted. Type: Table View.
- **Input Fields:** The fields that define the records that will be included in the output table. Type: Field.
- **Pivot Field:** The field whose record values will be used to generate the field names in the output table. Type: Field.
- **Value Field:** The field whose values will populate the pivoted fields in the output table. Type: Field.
- **Output Table:** The table that will be created containing the pivoted records. Type: Table.

**Derived Output:**
- **Output Table:** The table that will be created containing the pivoted records. Type: Table.

**Example ArcPy code:**
```python
import arcpy

# Set workspace
arcpy.env.workspace = "C:/data"

# Define local variables
in_table = "attributes.dbf"
fields = "OwnerID"
pivot_field = "AttrTagNam"
value_field = "AttrValueS"
out_table = "C:/output/attribPivoted.dbf"

# Execute PivotTable
arcpy.management.PivotTable(in_table, fields, pivot_field, value_field, out_table)
```
**Toolset:** Table

**Tool:** Transpose Fields

**Description:** The Transpose Fields tool in ArcGIS Pro is used to convert data stored in columns into rows within a table or feature class. This is particularly useful for tables or feature classes that store time-related data in field names, allowing for the creation of time stamps that can be animated through time.

**Parameters:**
- **Input Feature Class or Table:** The input feature class or table for which time stamps will be created. Type: Table View.
- **Fields to Transpose:** The columns from the input table and the corresponding time values. Multiple strings can be entered, formatted as "Field_Name Time". Type: String.
- **Output Feature Class or Table:** The output feature class or table. The output must be a geodatabase feature class. Type: Table.
- **Time Field Name:** The name of the time field that will be created to store time values. Type: String.
- **Value Field Name:** The name of the field that will be created to store the corresponding values of the transposed fields. Type: String.
- **Attribute Fields (Optional):** Additional attribute fields from the input table that will be included in the output table. Type: Field.

**Derived Output:**
- **Output Feature Class or Table:** The output feature class or table containing the transposed data. Type: Table.

**Example ArcPy code:**
```python
import arcpy

# Set workspace
arcpy.env.workspace = "C:/Data/TemporalData.gdb"

# Define input parameters
inTable = "Input"
fieldsToTranspose = "Field1 newField1;Field2 newField2;Field3 newField3"
outTable = "Output_Time"
timeFieldName = "Time"
valueFieldName = "Value"
attrFields = "Shape;Type"

# Run TransposeFields tool
arcpy.management.TransposeFields(inTable, fieldsToTranspose, outTable, timeFieldName, valueFieldName, attrFields)
```
**Toolset:** Table

**Tool:** Truncate Table

**Description:** The Truncate Table tool removes all rows from a database table or feature class using truncate procedures in the database. It is typically used in workflows where all rows need to be removed without the need for transaction backups, such as nightly data reloads.

**Parameters:**
- **Input Table:** The input database table or feature class that will be truncated. Type: Table View.

**Derived Output:**
- **Truncated Table:** The truncated table. Type: Table View.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/work/vancouver.gdb"

# Get a list of all the tables
tableList = arcpy.ListTables()

# Loop through the list and run truncate
for table in tableList:
    arcpy.management.TruncateTable(table)
```
**Toolset:** Tile Cache

**Tool:** Export Tile Cache

**Description:** The Export Tile Cache tool is used to export tiles from an existing tile cache to a new tile cache or a tile package. This is typically used for sharing tile caches as tile packages on ArcGIS Online or for publishing as tiled map services.

**Parameters:**
- **Input Tile Cache:** The existing tile cache to be exported. *Type: Raster Layer*.
- **Output Location:** The folder where the exported cache will be stored. *Type: Folder*.
- **Output Tile Cache Name:** The name for the new tile cache or tile package. *Type: String*.
- **Export Cache As:** Specifies the type of cache to export, such as a tile package. *Type: String*.
- **Scales:** A list of scale levels at which tiles will be exported. *Type: Double*.
- **Area of Interest:** An optional parameter to spatially constrain where tiles will be exported. *Type: Feature Set*.

**Derived Output:**
- **Output Cache Path:** The folder into which the cache has been exported. *Type: String*.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define parameters
cacheSource = "C:/Data/CacheDatasets/Source"
cacheTarget = "C:/Data/CacheDatasets"
cacheName = "Target"
cacheType = "TILE_PACKAGE"
storageFormat = "COMPACT"
scales = "4000;2000;1000"
areaofinterest = "#"

# Execute ExportTileCache
arcpy.management.ExportTileCache(
    cacheSource, 
    cacheTarget, 
    cacheName, 
    cacheType, 
    storageFormat, 
    scales, 
    areaofinterest
)
```
**Toolset:** Tile Cache

**Tool:** Generate Tile Cache Tiling Scheme

**Description:** Generates an XML tiling scheme file that defines the scale levels, tile dimensions, and other properties for a tile cache. This tool is typically used to create a tiling scheme for managing tile caches in ArcGIS Pro, which can then be used in the Manage Tile Cache tool to create cache tiles.

**Parameters:**
- **Input Data Source:** The source to be used to generate the tiling scheme. It can be a raster dataset, a mosaic dataset, or a map.  
  **Type:** Raster Layer; Mosaic Layer; Map.
  
- **Output Tiling Scheme:** The path and file name for the output tiling scheme to be created.  
  **Type:** File.
  
- **Generation Method:** Choose to use a new or predefined tiling scheme.  
  **Type:** String.
  
- **Number of Scales:** The number of scale levels to be created in the tiling scheme.  
  **Type:** Long.
  
- **Predefined Tiling Scheme (Optional):** Path to a predefined tiling scheme file (usually named conf.xml). This parameter is enabled only when the Predefined option is chosen as the tiling scheme generation method.  
  **Type:** File.
  
- **Scales (Optional):** Scale levels to be included in the tiling scheme.  
  **Type:** String.

**Derived Output:**
- **Output Tiling Scheme:** The generated tiling scheme file.  
  **Type:** File.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define parameters
mdname = "C:/Workspace/Cache.gdb/md"
outScheme = "C:/Workspace/Schemes/Tilingscheme.xml"
method = "NEW"
numscales = "5"
predefScheme = "#"
scales = "#"
scaleType = "SCALE"
tileOrigin = "-20037700 30198300"
dpi = "96"
tileSize = "256 x 256"
tileFormat = "MIXED"
compQuality = "75"
storageFormat = "COMPACT"

# Execute the tool
arcpy.management.GenerateTileCacheTilingScheme(
    mdname, outScheme, method, numscales, predefScheme, scales, scaleType, tileOrigin, dpi, tileSize, compQuality, storageFormat
)
```
**Toolset:** Tile Cache

**Tool:** Import Tile Cache

**Description:** The Import Tile Cache tool is used to import tiles from an existing tile cache or a tile package into another tile cache. This tool is typically used to transfer or update tile caches while ensuring that the target cache has the same tiling scheme, spatial reference, and storage format as the source.

**Parameters:**
- **Target Tile Cache:** An existing tile cache to which the tiles will be imported.  
  *Type:* Raster Layer.
- **Source Tile Cache:** An existing tile cache or a tile package from which the tiles are imported.  
  *Type:* Raster Layer; File.
- **Scales:** (Optional) A list of scale levels at which tiles will be imported.  
  *Type:* Double.
- **Area of Interest:** (Optional) An area of interest that spatially constrains where tiles are imported into the cache. Useful for importing tiles for irregularly shaped areas.  
  *Type:* Feature Set.
- **Overwrite Tiles:** (Optional) Determines whether the images in the destination cache will be merged with the tiles from the originating cache or overwritten by them.  
  *Type:* Boolean.

**Derived Output:**
- **Updated Target Tile Cache:** The updated tile cache.  
  *Type:* Raster Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define the parameters for the ImportTileCache tool
cacheTarget = "C:/Data/CacheDatasets/Target"
cacheSource = "C:/Data/CacheDatasets/Source"
scales = "4000;2000;1000"
area_of_interest = "#"  # No specific area of interest
overwrite = "MERGE"  # Merge tiles by default

# Execute the ImportTileCache tool
arcpy.management.ImportTileCache(
    in_cache_target=cacheTarget,
    in_cache_source=cacheSource,
    scales=scales,
    area_of_interest=area_of_interest,
    overwrite=overwrite
)
```

Feel free to ask if you need further clarification on any of these points or if you have other questions about ArcGIS Pro tools.
**Toolset:** Tile Cache

**Tool:** Manage Tile Cache

**Description:**  
The Manage Tile Cache tool is used to create and update tiles in an existing tile cache. It is typically used to generate new tiles, replace missing tiles, overwrite outdated tiles, and delete tiles in web tile layer caches, map image layers, and cached map or image services.

**Parameters:**
- **Input Service:** The web tile layer, web imagery layer, or map image layer whose cache tiles will be updated.  
  *Type:* Image Service; Map Server.
- **Scales:** A list of scale levels at which tiles will be created.  
  *Type:* Double.
- **Update Mode:** Specifies the mode that will be used to update the cache. Options include Recreate Empty Tiles, Recreate All Tiles, and Delete Tiles.  
  *Type:* String.
- **Cache Location:** The folder in which the cache dataset will be created, or the path to an existing tile cache.  
  *Type:* Folder; Raster Layer.
- **Manage Mode:** Specifies the mode that will be used to manage the cache, such as Recreate all tiles, Recreate empty tiles, or Delete tiles.  
  *Type:* String.
- **Cache Name (Optional):** The name of the cache dataset that will be created in the cache location.  
  *Type:* String.
- **Input Data Source (Optional):** A raster dataset, mosaic dataset, or map file.  
  *Type:* Mosaic Layer; Raster Layer; Map.
- **Input Tiling Scheme (Optional):** Specifies the tiling scheme that will be used.  
  *Type:* String.
- **Import Tiling Scheme (Optional):** The path to an existing scheme file (.xml) or to a tiling scheme imported from an existing image service or map service.  
  *Type:* Image Service; Map Server; File.

**Derived Output:**
- **out_cache_location:** The cache dataset to create in the output cache location.  
  *Type:* Raster Dataset.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define parameters
folder = "C:/Workspace/CacheDatasets/Manage"
mode = "RECREATE_ALL_TILES"
cacheName = "Test"
dataSource = "C:/Workspace/Cache.gdb/md"
method = "IMPORT_SCHEME"
tilingScheme = "C:/Workspace/Schemes/Tilingscheme.xml"
scales = "16000;8000;4000;2000;1000"
areaofinterest = "#"
maxcellsize = "#"
mincachedscale = "8000"
maxcachedscale = "2000"
ready_to_serve_format = "NON_READY_TO_SERVE_FORMAT"

# Execute ManageTileCache
arcpy.management.ManageTileCache(
    folder, mode, cacheName, dataSource, method, tilingScheme, scales,
    areaofinterest, maxcellsize, mincachedscale, maxcachedscale, ready_to_serve_format
)
```
No information available.
**Toolset:** Cartography

**Tool:** Convert To Graphics

**Description:** The Convert To Graphics tool in ArcGIS Pro is used to convert a feature layer's symbolized features into graphic elements within a graphics layer. This tool is typically utilized to convert a subset of features to graphics, allowing for precise control over their appearance and placement in a map layout.

**Parameters:**
- **Input Features:** The layer to convert to graphics. Type: Feature Layer.
- **Output Graphics Layer:** The graphics layer containing the converted graphic elements. Type: Graphics Layer.
- **Exclude converted features from drawing (Optional):** Specifies whether the converted features will be excluded using a query. Checked—The features will be excluded. This is the default. Unchecked—The features will not be excluded; they will be preserved. Type: Boolean.

**Derived Output:**
- **Updated layer:** The updated input layer. The layer will contain the update of the exclusion set if the Exclude converted features from drawing parameter is checked. Type: Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = r"C:/data/input"

# Convert a feature layer to a graphics layer
arcpy.conversion.FeaturesToGraphics(
    in_layer="pointFeatures",
    out_layer="pointGraphics",
    exclude_features="KEEP_FEATURES"
)
```
No information available.
`No information available.`
`No information available.`
No information available.
`No information available.`
`No information available.`
`No information available.`
**Toolset:** Cartography

**Tool:** Set Representation Control Point At Intersect

**Description:** This tool creates control points at vertices shared by one or more line or polygon features. It is typically used in cartographic refinement to enhance the representation of features by adding control points at intersections.

**Parameters:**
- **in_line_or_polygon_features:** The line or polygon feature layer. Type: Feature Layer.
- **in_features (Optional):** The line or polygon feature layer with features coincident to the input features. Type: Feature Layer.

**Derived Output:**
- **out_representations:** The updated input features. Type: Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"
arcpy.env.cartographicPartitions = "partitions.lyrx"

# Set local variables
in_line_or_polygon_features = "parcels.lyrx"
in_features = "roads.lyrx"

# Execute Set Representation Control Point At Intersect
arcpy.cartography.SetControlPointAtIntersect(in_line_or_polygon_features, in_features)
```
No information available.
`No information available.`
**Toolset:** Cartography

**Tool:** Apply Building Offsets

**Description:** The Apply Building Offsets tool aligns, moves, and hides building features or calculates offset values for bridge features based on product specification rules defined in an XML file. It is typically used in cartographic production to ensure that building symbols are displayed correctly according to specific mapping standards.

**Parameters:**
- **in_map:** The map that contains the layers with proper symbology. This can be a map in the application or an .mapx file on disk. **Type:** Map.
- **rule_file:** An XML file containing the offset rules that define how features will be aligned and refined in case of any conflict. **Type:** File.

**Derived Output:**
- **updated_map:** The updated map with modified building features and symbology. **Type:** Map.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Check Out Extensions
arcpy.CheckOutExtension('Foundation')

# Setting Local Variables
in_map = r'C:\Data\MGCP_TRD_4_4.mapx'
rule_file = r'C:\Data\MTM50_TRD_4_4_BuildingOffsets.xml'

# Calling the Apply Building Offsets tool
arcpy.topographic.ApplyBuildingOffsets(in_map, rule_file)

# Getting all messages, warnings, and errors from the tool run
messages = arcpy.GetMessages(0)
warnings = arcpy.GetMessages(1)
errors = arcpy.GetMessages(2)

# Print the results back to the user
arcpy.AddMessage('Tool Messages: {}\nTool Warnings: {}\nTool Errors{}\n'.format(messages, warnings, errors))

# Check In Extensions
arcpy.CheckInExtension('Foundation')
```
**Toolset:** Cartography

**Tool:** Apply Masks From Rules

**Description:** The "Apply Masks From Rules" tool in ArcGIS Pro is used to apply symbol layer masking to feature layers in a map. This is based on an XML rule file and mask features that were created by the "Make Masks From Rules" tool. It is typically used in cartographic workflows to ensure that map features are displayed correctly by applying predefined masking rules.

**Parameters:**
- **Input Map:** The map containing symbolized features, such as a map in a project or a MAPX file on disk.  
  *Type:* Map.
- **Rule File:** The XML file containing rules that define how features should be masked based on colors and symbol parts.  
  *Type:* File.
- **Mask Feature Dataset:** The feature dataset containing the masking polygon feature classes created by the "Make Masks From Rules" tool.  
  *Type:* Feature Dataset.

**Derived Output:**
- **Updated Map:** The output map with updated masks applied according to the rules specified.  
  *Type:* Map.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Check Out Extensions
arcpy.CheckOutExtension('Foundation')

# Setting the environment
arcpy.env.overwriteOutput = True

# Setting Local Variables
in_map = r'C:\Data\NewZealandHistoricBuildings.mapx'
rule_file = r'C:\Data\NewZealandHistoricBuildingAnno_Masking_Rules.xml'
in_feature_dataset = r'C:\Data\Label_your_map.gdb\Masks'

# Calling the Apply Masks From Rules to apply masks created in the Make Masks From Rules tool
arcpy.topographic.ApplyMasksFromRules(in_map, rule_file, in_feature_dataset)

# Getting all messages, warnings, and errors from the tool run and printing the results back to the user
messages = arcpy.GetMessages(0)
warnings = arcpy.GetMessages(1)
errors = arcpy.GetMessages(2)
arcpy.AddMessage('Tool Messages: {}\nTool Warnings: {}\nTool Errors{}\n'.format(messages, warnings, errors))

# Check In Extensions
arcpy.CheckInExtension('Foundation')
```
**Toolset: Cartography**

**Tool: Apply Visual Specification To Map**

**Description:**  
The "Apply Visual Specification To Map" tool applies symbols and Arcade expressions to layers in a map based on the symbols and rules defined in a visual specification database. It is typically used to convert existing Visual Specification rules to Arcade expressions for map and layout template creation in ArcGIS Pro.

**Parameters:**
- **Input Map**: The map containing layers to which symbols and Arcade expressions will be applied.  
  **Type**: Map.
- **Visual Specification Workspace**: The database containing the visual specification rules. Type: Workspace.
- **Visual Specification**: The specification rules that will be converted to Arcade and applied to the map layers. Type: String.
- **Input Style File (Optional)**: The style file (.stylx) that contains the symbols defined in the visual specification rules. Type: String.

**Derived Output:**
- **Updated Map**: The updated map. Type: Map.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Check Out Extensions
arcpy.CheckOutExtension('Foundation')

# Setting the environment
arcpy.env.overwriteOutput = True

# Setting Local Variables
in_map = r'C:\Data\TM50.mapx'
vs_workspace = r'C:\Data\TDS_6_1_TM_Visual_Specification.gdb'
specification = "TDS_50K :: 50K TM Visual Specification for TDS 6.1"
in_style_file = r'C:\Data\TM.stylx'

# Calling the Apply Visual Specification To Map to convert existing Visual Specification rules to Arcade
arcpy.topographic.ApplyVisualSpecificationToMap(in_map, vs_workspace, specification, in_style_file)

# Getting all messages, warnings, and errors from the tool run and printing the results back to the user
messages = arcpy.GetMessages(0)
warnings = arcpy.GetMessages(1)
errors = arcpy.GetMessages(2)
arcpy.AddMessage('Tool Messages: {}\nTool Warnings: {}\nTool Errors{}\n'.format(messages, warnings, errors))

# Check In Extensions
arcpy.CheckInExtension('Foundation')
```
**Toolset:** Cartography

**Tool:** Calculate Bridge Offsets

**Description:** The Calculate Bridge Offsets tool is designed to compute the necessary offsets for accurately displaying bridge features on a map. It is typically used in topographic mapping to ensure that bridges are symbolized correctly, taking into account their interaction with overpassing features such as roads.

**Parameters:**
- **Input Bridge Features:** The feature layer containing bridge features for which symbol offsets will be updated. Type: Layer.
- **Overpassing Features:** The feature layer containing features that overpass the bridges. Type: Layer.
- **Reference Scale:** The scale at which symbols appear at their intended size. Type: Long.
- **Search Distance (Optional):** The distance, in map units, by which point bridge features are buffered when identifying overpassing features. Default is 0 meters. Type: Linear Unit.
- **Expand to Markers (Optional):** Specifies whether marker layers on overpassing symbols will be included when analyzing widths. Type: Boolean.
- **Offset (Optional):** An offset added to the bridge width. Default is 0 points. Type: Linear Unit.
- **Minimum Length (Optional):** The minimum length of a line bridge. Default is 1.35 millimeters. Type: Linear Unit.
- **Bridge Subtype (Optional):** The subtype of the feature class from the Input Bridge Features parameter that will be modified. Type: String.
- **Overpassing Subtype (Optional):** The subtype of the feature class in the Overpassing Features parameter used in this operation. Type: String.

**Derived Output:**
- **Updated Bridge Features:** Bridge features that have been offset based on the Overpassing Features. Type: Layer.

**Example ArcPy code:**
```python
import arcpy

# Check Out Extensions
arcpy.CheckOutExtension('Foundation')

# Set the Cartographic Environment
arcpy.env.cartographicCoordinateSystem = 'GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]'
arcpy.env.referenceScale = 10000

# Setting Local Variables
in_bridge_features = r'C:\Data\Layers\BridgeL.lyrx'
in_overpassing_features = r'C:\Data\Layers\RoadL.lyrx'
reference_scale = 1000

# Execute Calculate Bridge Offsets
arcpy.topographic.CalculateBridgeOffsets(in_bridge_features, in_overpassing_features, reference_scale)

# Check In Extensions
arcpy.CheckInExtension('Foundation')
```
**Toolset:** Cartography

**Tool:** Make Masks From Rules

**Description:** The Make Masks From Rules tool creates polygon masks for features based on color rules defined in an XML file. It is typically used to enhance cartographic display by obscuring conflicting feature symbology.

**Parameters:**
- **Input Map:** The map containing symbolized features, such as a map in a project or a MAPX file on disk. Type: Map.
- **Rule File:** The XML file containing rules that define how features should be masked based on colors and symbol parts. Type: File.
- **Output Feature Dataset:** The feature dataset containing the masking polygon feature classes created by the tool. Type: Feature Dataset.

**Derived Output:**
- **Updated Map:** Output map with updated masks. Type: Map.

**Example ArcPy code:**
```python
import arcpy

# Check Out Extensions
arcpy.CheckOutExtension('Foundation')

# Setting the environment
arcpy.env.overwriteOutput = True

# Setting Local Variables
in_map = r'C:\Data\NewZealandHistoricBuildings.mapx'
rule_file = r'C:\Data\NewZealandHistoricBuildingAnno_Masking_Rules.xml'
out_feature_dataset = r'C:\Data\Label_your_map.gdb\Masks'

# Calling the Make Masks From Rules to create mask features for the annotation features defined in the rule_file
arcpy.topographic.MakeMasksFromRules(in_map, rule_file, out_feature_dataset)

# Check In Extension
arcpy.CheckInExtension('Foundation')
```
**Toolset:** Cartography

**Tool:** Thin Spot Heights

**Description:** The Thin Spot Heights tool generalizes spot heights for a specified area of interest (AOI) to meet cartographic product specifications. It is typically used to refine elevation data for topographic maps, ensuring that only the most significant spot heights are displayed, thereby enhancing map readability and aesthetic quality.

**Parameters:**
- **Input Elevation Features:** The elevation features to be thinned. Type: Feature Layer.
- **Area of Interest (AOI):** The feature layer defining the area within which spot heights will be thinned. Type: Feature Layer.
- **Contour Height Field:** The field in the input contours that contains elevation values. Type: Field.
- **Visibility Field:** The field indicating whether a spot height is visible. Type: Field.
- **Text Field:** The field containing text labels for spot heights. Type: Field.
- **Search Distance:** The distance within which spot heights are evaluated for thinning. Type: Linear Unit.
- **Input Contour Features:** The contour features used to assist in thinning spot heights. Type: Feature Layer.
- **Hierarchy Field:** The field used to determine the importance of spot heights. Type: Field.
- **Spot Height Subtype:** The subtype of spot heights to be processed. Type: String.

**Derived Output:**
- **Updated Features:** The input features that have been thinned based on input criteria. Type: Feature Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy
import os

# Check Out Extensions
arcpy.CheckOutExtension('Foundation')

# Setting the environment
arcpy.env.overwriteOutput = True

# Setting Local Variables
input_database = r'C:\Data\MGCP_TRD_4_4.gdb'
input_elevation_features = os.path.join(input_database, r'MGCP_Delta\ElevP')
input_contour_features = os.path.join(input_database, r'MGCP_Delta\ContourL')
area_of_interest = r'C:\Data\MapIndex.gdb\MapIndex\TM50_Index'

# Make a feature layer from the Area of Interest features
arcpy.management.MakeFeatureLayer(area_of_interest, 'AOI_Index')

# Select a single feature based on the NRN field
arcpy.management.SelectLayerByAttribute('AOI_Index', 'NEW_SELECTION', "NRN = 'V795X16573'")

# Execute Thin Spot Heights
arcpy.topographic.ThinSpotHeights(
    input_elevation_features,
    "AOI_Index",
    "ZVH",
    "IS_VISIBLE",
    "TXT",
    "1300 Meters",
    None,
    input_contour_features,
    "HQC",
    "5;6;22"
)

# Check In Extensions
arcpy.CheckInExtension('Foundation')
```
**Toolset:** Cartography

**Tool:** Generate Contiguous Cartogram

**Description:** The Generate Contiguous Cartogram tool creates a cartogram by distorting the area of polygons to be proportional to each other based on a numeric field, while preserving shared boundaries. This tool is typically used for visualizing data in a way that emphasizes the relative importance of different areas, such as population density or economic activity.

**Parameters:**
- **in_features:** The input polygon features that will be used to generate the cartogram. **Type:** Feature Layer.
- **field_name:** The numeric field containing the values that will determine the area of the polygon features in the output cartogram. Features with a negative value or a value of 0 will be omitted from the output. **Type:** Field.
- **out_features:** The output polygons with the cartogram transformation applied. **Type:** Feature Layer.
- **method (Optional):** Specifies the method used to transform the input and create the cartogram. Options include:
  - **FLOW-BASED:** An evolution of the diffusion method that is often faster but may increase distortion. This is the default.
  - **DIFFUSION:** A method that may introduce less distortion but takes longer to complete. **Type:** String.

**Derived Output:**
- **out_features:** The output polygons with the cartogram transformation applied. **Type:** Feature Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/admin.gdb"

# Set Local Variables
in_features = "countries"
value_field = "population"
out_cartogram = "countries_cartogram_population"
algorithm = "DIFFUSION"

# Execute Generate Contiguous Cartogram
arcpy.cartography.GenerateContiguousCartogram(
    in_features, 
    value_field, 
    out_cartogram, 
    algorithm
)
```
**Toolset:** Cartography

**Tool:** Apply Maritime Symbology

**Description:**  
The "Apply Maritime Symbology" tool is used to apply maritime paper chart symbols to layers based on a CXML format file that contains symbology rules. It is typically used in maritime chart production to ensure that the symbology of chart features aligns with the standards defined in the CXML file.

**Parameters:**
- **target_features**: The input point, line, or polygon features to which the symbology will be applied.  
  **Type:** Feature Class; Feature Layer.

- **cxml_file**: The .cxml file that contains rules for applying symbology.  
  **Type:** File.

**Derived Output:**
- **updated_features**: The updated target features with applied symbology.  
  **Type:** Feature Class; Feature Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import os
import arcpy

# Set the workspace
arcpy.env.workspace = r"C:\ChartSchema.gdb"

# Use the ListDatasets function to return a list of feature datasets then list of feature classes
datasets = arcpy.ListDatasets(feature_type='feature')
featureclasses = arcpy.ListFeatureClasses(feature_dataset='Nautical')

# Use the list of feature classes for Apply Maritime Symbology tool
arcpy.maritime.ApplyMaritimeSymbology(
    target_features=featureclasses,
    cxml_file=r'C:\ProductFiles\ArcGIS Maritime\Product Files\3.1\Charting\INT1.cxml'
)
```
**Toolset:** Cartography

**Tool:** Generate Cartographic Limits

**Description:** The Generate Cartographic Limits tool converts polygon features to polylines and removes all segments that are coincident with specified erase features. This tool is typically used in cartographic workflows to create clean feature outlines for map production, particularly in nautical charting.

**Parameters:**
- **input_polygons:** The polygon features that will be converted to polylines to create feature outlines where they are not coincident with the erase features.  
  **Type:** Feature Class; Feature Layer.
- **erase_features:** A list of polyline features that will be used to identify and remove coincident features from the input polygons.  
  **Type:** Feature Layer.
- **target_feature_class:** The feature class that will contain the resulting cartographic limit features.  
  **Type:** Feature Layer.

**Derived Output:**
- **updated_target_feature_class:** The polyline features derived from the input polygons that are not coincident with the erase features.  
  **Type:** Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = r"C:\ChartSchema.gdb"

# Define tool variables
DepthsA = "Nautical\\DepthsA"
CoastlineL = "Nautical\\CoastlineL"
CoastlineA = "Nautical\\CoastlineA"
neatline = "GRD_Grids\\SEG_GRD_Grids"
DepthsA_L = "CartographicFeatures\\DepthsA_L"

# Make a feature layer for DepthsA to only process features that are in FCSubtypes 5, 10, and 15
arcpy.management.MakeFeatureLayer(DepthsA, "depthsa_lyr", "FCSubtype IN (5, 10, 15)")

# Run the Generate Cartographic Limits tool
arcpy.maritime.GenerateCartographicLimits("depthsa_lyr", [CoastlineL, CoastlineA, neatline], DepthsA_L)
```

Feel free to ask if you need further clarification on any of these points or if you have additional questions about using this tool in ArcGIS Pro.
**Toolset:** Cartography

**Tool:** Generate Light Sector

**Description:** The Generate Light Sector tool creates navigational light sector lines and arcs based on attributes in a specified point feature class. It is typically used in nautical charting to depict the visibility range and angles of navigational lights.

**Parameters:**
- **Input Features:** The point feature class containing the AidsToNavigationP features with LIGHTS subtype. Type: Feature Layer.
- **Sector Line Length:** Specifies the length of the sector lines. Can be a numeric value or a field name. Type: Double; Field.
- **Sector Arc Radius:** Specifies the radius for the sector arcs. Can be a numeric value or a field name. Type: Double; Field.
- **Sector Unit:** Specifies the unit of measurement for the sector arcs. Options include CENTIMETERS, DECIMAL_DEGREES, DECIMETERS, FEET, INCHES, KILOMETERS, METERS, MILLIMETERS, NAUTICAL_MILES, POINTS, YARDS. Type: String.
- **Coordinate System:** The coordinate system for the output features. Default is the current map coordinate system. Type: Long.

**Derived Output:**
- **Output Feature Class:** The feature class where the light sector features will be written. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Define the spatial reference
sr = arcpy.SpatialReference(r"C:\Users\name\Documents\ArcGIS\Projects\GLS\CustomProjectionFile.prj")

# Run Generate Light Sector tool
arcpy.maritime.GenerateLightSector(
    in_features=r'C:\Users\name\Documents\ArcGIS\Projects\GLS\LightSector.gdb\Nautical\AidsToNavigationP',
    sector_line_length=35,
    sector_arc_radius=10,
    sector_unit='Millimeters',
    coordinate_system=sr
)
```

Feel free to ask more about ArcGIS Pro tools or explore other functionalities within the Cartography toolset.
**Toolset:** Cartography

**Tool:** Transfer Quality Of Position

**Description:** Transfers the Quality of Position (QUAPOS) attribution from S-57 edge primitives to features in CoastlineL, NaturalFeaturesL, and DepthsL. This tool is typically used to ensure that features have the necessary attribution for proper symbolization in maritime charts.

**Parameters:**
- **Input Geodatabase:** The input geodatabase containing the chart data in the maritime chart schema. **Type:** Workspace.
- **Unverified Features Only (Optional):** Specifies whether only features marked as unverified will be processed. **Type:** Boolean. Options are:
  - **Checked:** Only features marked as unverified will be processed.
  - **Unchecked:** All features will be processed (default).

**Derived Output:**
- **Output Geodatabase:** The updated workspace. **Type:** Workspace.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the input geodatabase
input_geodatabase = r"C:\Data\Chart.gdb"

# Specify whether to process only unverified features
unverified_features_only = "ALL_FEATURES"  # or "UNVERIFIED_FEATURES"

# Run the Transfer Quality Of Position tool
arcpy.maritime.TransferQualityOfPosition(input_geodatabase, unverified_features_only)
```

Feel free to ask if you need more details on using this tool or have other questions about ArcGIS Pro.
No information available.
**Toolset:** Cartography

**Tool:** Create Underpass

**Description:** The Create Underpass tool generates bridge parapets and polygon masks at line intersections to visually indicate underpasses. It is typically used in cartographic workflows to symbolize features where one line feature passes below another.

**Parameters:**
- **Input Above Features:** The input line feature layer containing lines that intersect and will be symbolized as passing above lines in the Input Below Features parameter. Type: Layer.
- **Input Below Features:** The input line feature layer containing lines that intersect and will be symbolized as passing below lines in the Input Above Features parameter. Type: Layer.
- **Margin Along:** The length of the mask polygons along the Input Above Features, extending beyond the width of the stroke symbol of the Input Below Features. Type: Linear Unit.
- **Margin Across:** The width of the mask polygons across the Input Above Features, extending beyond the width of the stroke symbol of the Input Above Features. Type: Linear Unit.
- **Output Overpass Feature Class:** The output feature class created to store polygons that mask the Input Below Features. Type: Feature Class.
- **Output Mask Relationship Class:** The output relationship class created to store links between overpass mask polygons and the lines of the Input Below Features. Type: Relationship Class.
- **Expression (Optional):** An SQL expression used to select a subset of features from the Input Above Features. Type: SQL Expression.
- **Output Decoration Feature Class (Optional):** The output line feature class created to store parapet features. Type: Feature Class.
- **Wing Type (Optional):** Specifies the wing style for the parapet features. Options include ANGLED, PARALLEL, and NONE. Type: String.
- **Wing Tick Length (Optional):** The length of the parapet wings in page units. Type: Linear Unit.

**Derived Output:**
- **Output Overpass Feature Class:** Stores polygons to mask the Input Below Features. Type: Feature Class.
- **Output Mask Relationship Class:** Stores links between mask polygons and lines of the Input Below Features. Type: Relationship Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"
arcpy.env.referenceScale = "50000"

# Set local variables
in_above_features = "roads.lyr"
in_below_features = "railroads.lyr"
margin_along = "2 Points"
margin_across = "1 Points"
out_overpass_feature_class = "cartography.gdb/transportation/under_mask_fc"
out_mask_relationship_class = "cartography.gdb/transportation/under_mask_rc"
where_clause = "'RelationshipToSurface' = 3"
out_decoration_feature_class = "cartography.gdb/transportation/tunnel"
wing_type = "PARALLEL"
wing_tick_length = "1 Points"

# Execute Create Underpass
arcpy.cartography.CreateUnderpass(
    in_above_features, 
    in_below_features, 
    margin_along, 
    margin_across, 
    out_overpass_feature_class, 
    out_mask_relationship_class, 
    where_clause, 
    out_decoration_feature_class, 
    wing_type, 
    wing_tick_length
)
```
No information available.
**Toolset:** Cartography

**Tool:** Generate Hachures For Defined Slopes

**Description:** This tool generates multipart polygons representing the slope between the lines of an upper and lower slope. It is typically used in cartographic applications to visualize terrain features through hachures, which are lines or polygons that indicate slope direction and steepness.

**Parameters:**
- **upper_lines:** The feature class representing the upper edges of the slope. Type: Feature Layer.
- **lower_lines:** The feature class representing the lower edges of the slope. Type: Feature Layer.
- **output_feature_class:** The name of the output feature class that will store the generated hachures. Type: String.
- **output_type:** Specifies the type of output geometry, such as "POLYGON_TRIANGLES". Type: String.
- **fully_connected:** Determines if the hachures are fully connected or not. Options include "CONNECTED" or "NOT_CONNECTED". Type: String.
- **search_distance:** The distance to search for connecting hachures. Type: Linear Unit.
- **interval:** The interval at which hachures are generated. Type: Linear Unit.
- **minimum_length:** The minimum length of hachures to be generated. Type: Linear Unit.
- **alternate_hachures:** Specifies the pattern of hachures, such as "UNIFORM_HACHURES". Type: String.
- **perpendicular:** Boolean indicating if hachures should be oriented perpendicularly to the upper line. Type: Boolean.
- **polygon_base_width:** The width of the base of triangular polygon hachures, applicable when output_type is set to polygon_triangles. Type: Linear Unit.

**Derived Output:**
- **output_feature_class:** Contains the generated hachures representing the slope between the defined upper and lower lines. Type: Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/Data/Hachures.gdb"

# Set local variables
upper_lines = "UpperEdges"
lower_lines = "LowerEdges"
output_type = "POLYGON_TRIANGLES"
output_feature_class = "Hachures_output"
fully_connected = "NOT_CONNECTED"
search_distance = "20 Meters"
interval = "10 Meters"
minimum_length = "0 Meters"
alternate_hachures = "UNIFORM_HACHURES"
perpendicular = False
polygon_base_width = "5 Meters"

# Execute Generate Hachures For Defined Slopes
arcpy.cartography.GenerateHachuresForDefinedSlopes(
    upper_lines, lower_lines, output_feature_class, output_type,
    fully_connected, search_distance, interval, minimum_length,
    alternate_hachures, perpendicular, polygon_base_width
)
```

Feel free to ask more about ArcGIS Pro tools or explore other functionalities within the Cartography toolset.
**Toolset:** Cartography

**Tool:** Set Control Point At Intersect

**Description:** Creates a control point at vertices that are shared by one or more line or polygon features. This tool is commonly used to synchronize boundary symbology on adjacent polygons.

**Parameters:**
- **in_line_or_polygon_features:** The line or polygon feature layer. Type: Feature Layer.
- **in_features (Optional):** The line or polygon feature layer with features coincident to the input features. Type: Feature Layer.

**Derived Output:**
- **out_representations:** The updated input features. Type: Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"
arcpy.env.cartographicPartitions = "partitions.lyrx"

# Set local variables
in_line_or_polygon_features = "parcels.lyrx"
in_features = "roads.lyrx"

# Execute Set Control Point At Intersect
arcpy.cartography.SetControlPointAtIntersect(in_line_or_polygon_features, in_features)
```
**Toolset:** Cartography

**Tool:** Set Control Point By Angle

**Description:** This tool places control points at vertices along a line or polygon outline where the angle created by a change in line direction is less than or equal to a specified maximum angle. It is typically used to improve dash placement along lines or polygon outlines by setting control points at prominent angles.

**Parameters:**
- **Input Features:** The feature layer containing line or polygon features. Type: Feature Layer.
- **Maximum Angle (decimal degrees):** The angle used to determine whether a vertex along a line or polygon outline will be set as a control point. The angle value must be greater than zero and less than 180 decimal degrees. Type: Double.

**Derived Output:**
- **Updated Input Features:** The updated input features. Type: Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "C:/data"

# Define the input feature layer and maximum angle
in_features = "trails.lyrx"
maximum_angle = 135

# Execute the Set Control Point By Angle tool
arcpy.cartography.SetControlPointByAngle(in_features, maximum_angle)
```
No information available.
**Toolset:** Data Management

**Tool:** Copy

**Description:** The Copy tool in ArcGIS Pro is used to duplicate features from an input feature class or layer to a new feature class. It is typically used for data conversion, allowing users to read various feature formats and write them to a shapefile or geodatabase.

**Parameters:**
- **Input Features:** The features to be copied. Type: Feature Layer.
- **Output Feature Class:** The feature class which will be created and to which the features will be copied. Type: Feature Class.
- **Configuration Keyword (Optional):** Geodatabase configuration keyword to be applied if the output is a geodatabase. Type: String.
- **Output Spatial Grid 1 (Optional):** Deprecated parameter. Any value entered is ignored. Type: Double.
- **Output Spatial Grid 2 (Optional):** Deprecated parameter. Any value entered is ignored. Type: Double.
- **Output Spatial Grid 3 (Optional):** Deprecated parameter. Any value entered is ignored. Type: Double.

**Derived Output:**
- **Output Feature Class:** The newly created feature class containing the copied features. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "C:/data"

# Define the input and output parameters
in_features = "majorrds.shp"
out_feature_class = "C:/output/majorrdsCopy.shp"

# Execute the Copy tool
arcpy.management.CopyFeatures(in_features, out_feature_class)
```

Feel free to ask if you need more details on using the Copy tool or any other ArcGIS Pro functionalities.
**Toolset:** Data Management

**Tool:** Create AI Service Connection File

**Description:** This tool generates and stores secure connection files for accessing hosted AI services in ArcGIS Pro. It eliminates the need to manually enter access credentials and configuration settings each time you interact with AI services, ensuring a faster, more secure connection process while reducing the risk of configuration errors.

**Parameters:**
- **Connection File Location:** The folder path where the connection file will be created. Type: Folder.
- **Connection File Name:** The name of the AI service connection file. Type: String.
- **Service Provider (Optional):** Specifies the cloud service provider that will be used. Options include AWS, Anthropic, Azure, Hugging Face, OpenAI, Google, and Others. Type: String.
- **Connection Parameters (Optional):** The connection parameters that will be added to the output connection file. Type: Value Table.
- **Secret Parameter Key (Optional):** The key whose value contains sensitive information, such as API keys or authentication tokens. Type: String.
- **Secret Parameter Value (Optional):** The secret access key string to authenticate the connection. Type: String.

**Derived Output:**
- **out_connection_file:** The path to the output connection file. Type: File.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set local variables
out_folder_path = r"C:\Path\To\Folder"
out_name = "ConnectionFile.ais"
service_provider = "AWS"
connection_parameters = "param1=value1;param2=value2"
secret_param_key = "api_key"
secret_param_value = "your_secret_value"

# Run Create AI Service Connection File
arcpy.management.CreateAIServiceConnection(
    out_folder_path=out_folder_path,
    out_name=out_name,
    service_provider=service_provider,
    connection_parameters=connection_parameters,
    secret_param_key=secret_param_key,
    secret_param_value=secret_param_value
)
```
**Toolset:** Data Management

**Tool:** Create Database View

**Description:** The Create Database View tool is used to create a view in a database based on an SQL expression. This tool is typically used to define a subset of data from one or more tables, which can improve performance by reducing the volume of data transferred from the database to the client.

**Parameters:**
- **Input Workspace:** The database that contains the tables or feature classes used to construct the view. This is also where the view will be created. Type: Workspace.
- **View Name:** The name of the view that will be created in the database. Type: String.
- **View Definition:** An SQL statement that will be used to construct the view. Type: String.

**Derived Output:**
- **Output Layer:** The output database view. Type: Table.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define the parameters
input_database = "c:/Connections/city_data.sde"
view_name = "trees"
view_definition = "select objectid, owner, parcel from inventory where type = 'trees'"

# Create the database view
arcpy.management.CreateDatabaseView(input_database, view_name, view_definition)
```
**Toolset: Data Management**

**Tool: Delete**

**Description:**  
The Delete tool in ArcGIS Pro is used to permanently remove data. It can delete all types of geographic data supported by ArcGIS, including feature classes, tables, shapefiles, rasters, annotation or dimension feature classes, toolboxes, and workspaces (folders and geodatabases). If a workspace is specified for deletion, all contained items will also be deleted.

**Parameters:**
- **Input Data Element**: The input data that will be deleted. Type: Data Element; Graph; Layer; Table View; Utility Network.
- **Data type (Optional)**: Specifies the type of data on disk to be deleted. This parameter is necessary in the event of a name conflict between data types. Type: String.

**Derived Output:**
- **Delete Succeeded**: Returns whether the tool succeeded. Type: Boolean.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "C:/data"

# Set local variables
in_data = "majorrds.shp"
out_data = "majorrdsCopy.shp"

# Run Copy to create a copy of the input data
arcpy.management.Copy(in_data, out_data)

# Run Delete to remove the copied data
arcpy.management.Delete(out_data)
```
**Toolset:** Data Management

**Tool:** Delete Identical

**Description:** The Delete Identical tool is used to remove records from a feature class or table that have identical values in a specified set of fields. It is typically used to clean datasets by eliminating duplicate records, which can be identified by comparing values across multiple fields, including geometry if specified.

**Parameters:**
- **Input Dataset:** The table or feature class from which identical records will be deleted.  
  *Type:* Table View.
- **Fields:** The field or fields whose values will be compared to find identical records.  
  *Type:* Field.
- **XY Tolerance (Optional):** The x,y tolerance applied to each vertex when evaluating identical vertices in another feature.  
  *Type:* Linear Unit.
- **Z Tolerance (Optional):** The z-tolerance applied to each vertex when evaluating identical vertices in another feature.  
  *Type:* Double.
- **Output Duplicate IDs Mapping Table (Optional):** An optional output table that includes the object ID values of all records from the input that have a duplicate, matched with the object ID values of the representative record that was retained.  
  *Type:* Table View.

**Derived Output:**
- **Updated Input Dataset:** The updated input dataset after identical records have been deleted.  
  *Type:* Table View.

**Example ArcPy code:**
```python
import arcpy

# Set workspace environment
arcpy.env.workspace = "C:/data/sbfire.gdb"

# Set input feature class
in_dataset = "fireincidents"

# Set the fields on which the identical records are found
fields = ["Shape", "INTENSITY"]

# Set the XY tolerance within which identical records will be deleted
xy_tol = "0.02 Miles"

# Set the Z tolerance to default
z_tol = ""

# Run Delete Identical
arcpy.management.DeleteIdentical(in_dataset, fields, xy_tol, z_tol)
```
**Toolset:** Data Management

**Tool:** Delete Multiple

**Description:** The "Delete Multiple" tool in ArcGIS Pro is used to permanently delete multiple data items of the same or different data types. It supports all types of geographic data, as well as toolboxes and workspaces (folders and geodatabases). If a specified item is a workspace, all contained items will also be deleted.

**Parameters:**
- **in_data**: A list of data items to be deleted. Each item in the list is a pair consisting of the path to the data and its type (e.g., 'FeatureClass', 'FeatureDataset'). Type: Value Table.

**Derived Output:**
- **out_results**: Indicates whether the delete operation was successful. Type: Boolean.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = r"C:\dataToDelete"

# Define the data items to delete
data_to_delete = [
    [r'C:\dataToDelete\convertlabels.gdb\points', 'FeatureClass'],
    [r'C:\dataToDelete\deleteMultiple.gdb\issue7725', 'FeatureDataset']
]

# Execute the DeleteMultiple tool
arcpy.management.DeleteMultiple(in_data=data_to_delete)
```
**Toolset:** Data Management

**Tool:** Rename

**Description:** The Rename tool changes the name of a dataset, which can include feature datasets, rasters, tables, and shapefiles. It is important to note that this tool does not rename layers, as layers are references to datasets, nor does it rename fields within a dataset.

**Parameters:**
- **Input Data Element:** The input data to be renamed. Type: Data Element.
- **Output Data Element:** The name of the output data. Type: Data Element.
- **Data Type (Optional):** Specifies the type of data to be renamed, necessary in case of a name conflict between different data types. Type: String.

**Derived Output:**
- No derived outputs are specified for this tool.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/workspace/test.gdb"

# Define local variables
in_data = "test"
out_data = "testFC"
data_type = "FeatureClass"

# Execute Rename
arcpy.management.Rename(in_data, out_data, data_type)
```

Feel free to ask if you need more details on using the Rename tool or any other ArcGIS Pro functionalities.
**Toolset:** Data Management

**Tool:** Sort

**Description:** The Sort tool in ArcGIS Pro reorders records in a feature class or table in ascending or descending order based on one or multiple fields. The reordered result is written to a new dataset. This tool is typically used to organize data for better analysis and visualization.

**Parameters:**
- **in_dataset:** The input dataset with the records that will be reordered based on the field values in the sort field or fields.  
  **Type:** Table View.
- **out_dataset:** The output feature class or table.  
  **Type:** Feature Class; Table.
- **sort_field:** The field or fields whose values will be used to reorder the input records and the direction the records will be sorted.  
  **Type:** Value Table.
- **spatial_sort_method (Optional):** Specifies how features will be spatially sorted. This is only enabled when the Shape field is designated as one of the sort fields. Options include Upper right, Upper left, Lower right, Lower left, and Peano curve.  
  **Type:** String.

**Derived Output:**
- **out_dataset:** The output feature class or table containing the sorted records.  
  **Type:** Feature Class; Table.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the input and output datasets
in_dataset = "C:/data/input.gdb/feature_class"
out_dataset = "C:/data/output.gdb/sorted_feature_class"

# Define the sort fields and order
sort_fields = [["FieldName1", "ASCENDING"], ["FieldName2", "DESCENDING"]]

# Execute the Sort tool
arcpy.management.Sort(in_dataset, out_dataset, sort_fields)
```

Feel free to ask if you need more details on using the Sort tool or any other ArcGIS Pro functionalities.
**Toolset: Data Management**

**Tool: Transfer Files**

**Description:**  
The Transfer Files tool is used to transfer files between a file system and a cloud storage workspace. It is typically used for managing hosted image products in the cloud. This tool does not support file transfers to or from geodatabases.

**Parameters:**
- **Input Paths**: The list of input files or folders that will be copied to the output folder. The path can be a file system path or cloud storage path where the .acs file can be used.  
  **Type**: Raster Dataset; File; Folder.
  
- **Output Folder**: The output folder path where the files will be copied.  
  Type: Folder.
  
- **Filters (Optional)**: A file pattern filter that will limit the number of files that need to be copied, such as `.tif`, `.crf`, and similar image file types.  
  Type: String.

**Derived Output:**
- **Output Folder**: The output raster dataset.  
  Type: Folder.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the input folder and output folder paths
input_folder = "c:\\test\\uploaddata"
output_folder = "c:\\cloudconnection\\s3cloudstore.acs\\s3folder"
file_filter = "*.tif"  # Optional filter for specific file types

# Execute the TransferFiles tool
arcpy.management.TransferFiles(input_folder, output_folder, file_filter)
```
**Toolset:** Data Management

**Tool:** Upload File To Portal

**Description:** This tool uploads a file to the active portal, which can be ArcGIS Online or ArcGIS Enterprise. It supports various file types such as maps, layers, layouts, PDFs, presentations, reports, and styles, with a file size limit of 500 GB. It is typically used to share content with an organization or the public.

**Parameters:**
- **Input File:** The file that will be uploaded to the active portal. Supported file types include layer (.lyrx), layout (.pagx), map (.mapx), PDF (.pdf), presentation (.prsx), report (.rptx), and report template (.rptt). Type: File.
- **Title (Optional):** The title for the uploaded file. If not specified, the file name is used. Type: String.
- **Folder (Optional):** The folder in the portal where the file will be stored. By default, it is stored at the root level. Type: String.
- **Summary (Optional):** A brief summary of the file. Type: String.
- **Tags (Optional):** Tags to help categorize and search for the file. Type: String.
- **Sharing Level (Optional):** The level of sharing for the file, such as 'PRIVATE', 'ORGANIZATION', or 'EVERYONE'. Type: String.
- **Groups (Optional):** The groups with which the item will be shared. Type: String.

**Derived Output:**
- **file_item_id:** The portal item ID of the file. Type: String.
- **file_item_url:** The item URL of the file uploaded to the portal. Type: String.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define the input file and other parameters
input_file = r"C:\path\to\your\file.lyrx"
title = "MyFile"
folder = ""
summary = "My Summary"
tags = "tag1, tag2"
sharing_level = "EVERYONE"
groups = "MYGROUP"

# Upload the file to the portal
arcpy.management.UploadFileToPortal(input_file, title, folder, summary, tags, sharing_level, groups)
```
**Toolset: Overlay**

**Tool: Apportion Polygon**

**Description:**  
The Apportion Polygon tool summarizes the attributes of an input polygon layer based on the spatial overlay of a target polygon layer. It assigns the summarized attributes to the target polygons, which have summed numeric attributes derived from the input polygons that each target overlaps. This process is typically used for estimating attributes like population based on overlapping areas.

**Parameters:**
- **Input Polygons**: The polygon features that will be apportioned. Type: Feature Layer.
- **Target Polygons**: The polygon features that will receive the apportioned attributes. Type: Feature Layer.
- **Apportion Fields**: The fields from the input polygons to be apportioned to the target polygons. Type: Value Table.
- **Estimation Features (Optional)**: Features used to estimate the proportion of attributes transferred, instead of using area. Type: Feature Layer.
- **Maintain Target Geometry**: Determines whether to include the target geometry or the intersection of input and target geometries in the output. Type: Boolean.

**Derived Output:**
- **Output Feature Class**: The resulting feature class with apportioned attributes. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the input parameters
input_polygons = "InputPolygonLayer"
target_polygons = "TargetPolygonLayer"
apportion_fields = [["Population", "SUM"], ["Area", "MEAN"]]
estimation_features = "EstimationFeatureLayer"  # Optional
maintain_target_geometry = True

# Run the Apportion Polygon tool
arcpy.analysis.ApportionPolygon(
    in_polygons=input_polygons,
    target_polygons=target_polygons,
    apportion_fields=apportion_fields,
    estimation_features=estimation_features,
    maintain_target_geometry=maintain_target_geometry
)
```

Feel free to ask if you need further clarification or have additional questions about using the Apportion Polygon tool in ArcGIS Pro.
**Toolset:** Overlay

**Tool:** Count Overlapping Features

**Description:** The "Count Overlapping Features" tool generates planarized overlapping features from the input features and writes the count of overlapping features to the output features. It is typically used to analyze spatial relationships where multiple features overlap, such as determining the number of overlapping service areas or land parcels.

**Parameters:**
- **in_features:** The input feature classes or layers. These can be point, multipoint, line, or polygon features. If multiple inputs are provided, they must all be the same geometry type. Type: Feature Layer.
- **out_feature_class:** The output feature class containing the overlap count. Type: Feature Class.
- **min_overlap_count (Optional):** Limits the output to only locations that meet or exceed the specified number of overlaps. The default value is 1. Type: Long.
- **out_overlap_table (Optional):** The output table containing records for each individual overlapping geometry. Type: Table.

**Derived Output:**
- **out_feature_class:** The output feature class containing the overlap count. Type: Feature Class.
- **out_overlap_table (Optional):** The output table containing records for each individual overlapping geometry. Type: Table.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = r"C:\data\data.gdb"

# Define input feature classes
provider_a = 'Provider_A_ServiceArea'
provider_b = 'Provider_B_ServiceArea'
provider_c = 'Provider_C_ServiceArea'
in_fcs = [provider_a, provider_b, provider_c]

# Define output feature class and table
out_fc = 'CellularProviders_Count'
out_tbl = 'CellularProviders_Count_Tbl'

# Execute Count Overlapping Features
arcpy.analysis.CountOverlappingFeatures(in_fcs, out_fc, 3, out_tbl)
```
**Toolset:** Overlay

**Tool:** Erase

**Description:** The Erase tool in ArcGIS Pro creates a feature class by overlaying the input features with the erase features. It removes those portions of the input features that overlap with the erase features, effectively excluding areas from the input dataset.

**Parameters:**
- **Input Features:** The point, line, or polygon features that will be overlaid with the erase features.  
  *Type:* Feature Layer.
- **Erase Features:** The features that will be used to erase coincident features in the input.  
  *Type:* Feature Layer.
- **Output Feature Class:** The feature class that will contain only those input features that do not overlap with the erase features.  
  *Type:* Feature Class.

**Derived Output:**
- **Output Feature Class:** Contains the input features that do not overlap with the erase features.  
  *Type:* Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/Habitat_Analysis.gdb"

# Define local variables
input_features = "suitable_vegetation"
erase_features = "major_roads"
output_feature_class = "suitable_vegetation_minus_roads"

# Execute Erase
arcpy.analysis.Erase(input_features, erase_features, output_feature_class)
```
**Toolset:** Overlay

**Tool:** Identity

**Description:** The Identity tool in ArcGIS Pro performs a geometric intersection of the input features and identity features. It outputs features or portions of features that overlap in both the input layer and the overlay layer. This tool is typically used to combine attributes from two datasets where they spatially intersect.

**Parameters:**
- **Input Features:** The point, line, or polygon features that will be overlaid with the identity features. Type: Feature Layer.
- **Identity Features:** The features that will be overlaid with the input features. Type: Feature Layer.
- **Output Feature Class:** The name of the output feature class that will contain the overlaid features. Type: Feature Class.

**Derived Output:**
- **Output Feature Class:** The resulting feature class containing the overlaid features. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data/data.gdb"

# Set local parameters
inFeatures = "wells"
idFeatures = "counties"
outFeatures = "wells_w_county_info"

# Process: Use the Identity function
arcpy.analysis.Identity(inFeatures, idFeatures, outFeatures)
```
**Toolset:** Overlay

**Tool:** Intersect

**Description:** The Intersect tool computes the geometric intersection of multiple feature classes or layers. It retains the features or portions of features that are common to all inputs, effectively identifying spatial relationships between them. This tool is typically used to find overlapping areas or features, such as determining which land parcels fall within a flood zone.

**Parameters:**
- **Input Features:** The point, line, or polygon features to be intersected. Type: Feature Set.
- **Output Feature Class:** The name of the output feature class that will store the intersected features. Type: String.
- **Join Attributes (Optional):** Specifies which attributes from the input features will be transferred to the output feature class. Options include ALL, NO_FID, and ONLY_FID. Type: String.
- **Cluster Tolerance (Optional):** The minimum distance separating all feature coordinates. Type: Linear Unit.
- **Output Type (Optional):** Specifies the type of intersections that will be returned (e.g., INPUT, LINE, POINT). Type: String.

**Derived Output:**
- **Output Feature Class:** The feature class containing the intersected features. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data"

# Define input feature classes
input_features = ["roads.shp", "landuse.shp"]

# Define the output feature class
output_feature_class = "C:/data/intersect_output.shp"

# Run the Intersect tool
arcpy.analysis.Intersect(input_features, output_feature_class, "ALL", "", "INPUT")
```
**Toolset:** Overlay

**Tool:** Remove Overlap (multiple)

**Description:** The Remove Overlap (multiple) tool is used to eliminate overlapping areas between multiple polygon layers, creating distinct trade area layers. This tool is typically used in scenarios where clear delineation between overlapping spatial features is required, such as in trade area analysis.

**Parameters:**
- **in_features:** The input features containing the overlapping polygons.  
  *Type:* Value Table.
- **out_feature_class:** The feature class containing the new polygon features with overlaps removed.  
  *Type:* Feature Class.
- **method (Optional):** Specifies how the overlap between polygons will be removed. Options include:
  - **CENTER_LINE:** Creates a border that evenly distributes the overlapping area between polygons. This is the default method.
  - **THIESSEN:** Uses straight lines to divide the area of intersection, creating nonoverlapping trade areas.
  - **GRID:** Uses a grid of parallel lines to define a natural division between polygons.  
  *Type:* String.
- **join_attributes (Optional):** Specifies the attributes of the input layers that will be transferred to the output. Options include:
  - **ALL:** All attributes from the input features will be transferred to the output feature class. This is the default.
  - **NO_FID:** All attributes except the FID field will be transferred.
  - **ONLY_FID:** Only the FID field will be transferred.  
  *Type:* String.

**Derived Output:**
- **out_feature_class:** The feature class containing the new polygon features with overlaps removed.  
  *Type:* Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the input features and output feature class
in_features = "Ring_Trade_Areas"
out_feature_class = r"C:\Temp\MyProject.gdb\Ring_Trade_Areas_RemoveOverlapMultiple"

# Execute the Remove Overlap (multiple) tool
arcpy.analysis.RemoveOverlapMultiple(
    in_features=in_features,
    out_feature_class=out_feature_class,
    method="THIESSEN",
    join_attributes="ALL"
)
```
**Toolset:** Overlay

**Tool:** Spatial Join

**Description:**  
The Spatial Join tool in ArcGIS Pro joins the attributes of two layers based on the spatial relationship of the features in the layers. It is typically used to append the attributes of one layer to another, similar to joining two tables by matching attribute values in a field. Common use cases include finding the nearest feature, determining what is inside a polygon, or identifying intersecting features.

**Parameters:**
- **Target Features:** The layer to which you want to join data.  
  *Type:* Feature Layer.
- **Join Features:** The layer whose attributes will be joined to the target features.  
  *Type:* Feature Layer.
- **Output Feature Class:** The new feature class that will contain the target features with the joined attributes.  
  *Type:* Feature Class.
- **Join Operation:** Specifies how joins between the target and join features will be handled if multiple join features have the same spatial relationship with a single target feature. Options include "Join one to one" or "Join one to many."  
  *Type:* String.
- **Match Option:** Determines the spatial relationship between the features to be joined, such as "Intersect," "Within," "Contains," or "Closest."  
  *Type:* String.

**Derived Output:**
- **Output Feature Class:** The resulting feature class containing the target features with attributes from the join features.  
  *Type:* Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/path/to/your/geodatabase.gdb"

# Define parameters
target_features = "Tourist_Attractions"
join_features = "Rail_Stations"
output_feature_class = "Tourist_Attractions_Join"
join_operation = "JOIN_ONE_TO_ONE"
match_option = "CLOSEST"

# Execute Spatial Join
arcpy.analysis.SpatialJoin(target_features, join_features, output_feature_class, join_operation, match_option)
```
**Toolset:** Overlay

**Tool:** Symmetrical Difference

**Description:** The Symmetrical Difference tool in ArcGIS Pro is used to create a new feature class containing features or portions of features from the input layer and the overlay layer that do not overlap. This tool is typically used in spatial analysis to identify areas that are unique to each dataset, excluding any shared areas.

**Parameters:**
- **Input Layer:** The point, line, or polygon features that will be overlaid with the overlay layer. Type: Feature Layer.
- **Overlay Layer:** The features that will be overlaid with the input layer features. Type: Feature Layer.
- **Output Feature Class:** A new feature class with overlaid features. Type: Feature Class.
- **Cluster Tolerance (Optional):** The minimum distance separating all feature coordinates (nodes and vertices) as well as the distance a coordinate can move in x or y (or both). Type: Linear Unit.

**Derived Output:**
- **Output Feature Class:** The overlay of multiple layers into a single layer. Type: Feature Set.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set local variables
inFeatures = "climate.shp"
updateFeatures = "elevlt250.shp"
outFeatureClass = "C:/output/symdiff.shp"
clusterTolerance = 0.001

# Run Symmetrical Difference
arcpy.analysis.SymDiff(inFeatures, updateFeatures, outFeatureClass, "ALL", clusterTolerance)
```

Feel free to ask if you need further clarification on using the Symmetrical Difference tool or any other ArcGIS Pro functionalities.
**Toolset:** Overlay

**Tool:** Union

**Description:**  
The Union tool computes a geometric union of input polygon feature classes or layers. It combines all features and their attributes into a single output feature class, representing the union of all inputs. This tool is typically used to analyze spatial relationships by merging multiple datasets to identify overlapping areas and aggregate attributes.

**Parameters:**
- **Input Features:** The polygon feature classes or layers to be combined.  
  *Type:* Feature Layer
- **Output Feature Class:** The name of the new feature class that will contain the unioned features.  
  *Type:* Feature Class
- **Join Attributes:** Specifies which attributes from the input features will be transferred to the output feature class. Options include ALL, NO_FID, or ONLY_FID.  
  *Type:* String
- **Cluster Tolerance (Optional):** The minimum distance separating all feature coordinates.  
  *Type:* Linear Unit
- **Gaps (Optional):** Specifies whether a feature will be created for areas in the output that are completely enclosed by polygons.  
  *Type:* Boolean

**Derived Output:**
- **Output Feature Class:** Contains polygons representing the geometric union of all input features, along with their attributes.  
  *Type:* Feature Class

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data/data.gdb"

# Define input feature classes
inFeatures = ["well_buff50", "stream_buff200", "waterbody_buff500"]

# Define output feature class
outFeatures = "water_buffers"

# Run Union tool
arcpy.analysis.Union(inFeatures, outFeatures, "NO_FID", 0.0003)
```
**Toolset: Overlay**

**Tool: Update**

**Description:**  
The Update tool computes the geometric intersection of the input features and update features. It updates the attributes and geometry of the input features with those of the update features in the output feature class. This tool is typically used to modify existing spatial features by overlaying them with new data, allowing for the integration of updated information into existing datasets.

**Parameters:**
- **in_features**: The input feature class or layer. The geometry type must be polygon.  
  Type: Feature Layer.
  
- **update_features**: The features that will be used to update the input features. The geometry type must be polygon. Type: Feature Layer.

- **out_feature_class**: The feature class that will contain the results. Type: Feature Class.

- **keep_borders** (Optional): Specifies whether the boundary of the update polygon features will be kept. Options are:
  - **BORDERS**: The outside border of the `update_features` parameter value will be kept in the `out_feature_class` parameter value. This is the default.
  - **NO_BORDERS**: The outside border of the `update_features` parameter value will not be kept after it is inserted into the `in_features`. Item values of the `update_features` parameter value take precedence over `in_features` parameter value attributes. Type: Boolean.

- **cluster_tolerance (Optional)**: The minimum distance separating all feature coordinates (nodes and vertices) as well as the distance a coordinate can move in x or y (or both). Caution: Changing this parameter's value may cause failure or unexpected results. It is recommended that you do not modify this parameter. By default, the input feature class's spatial reference x,y tolerance property is used. Type: Linear Unit.

**Derived Output:**
- `out_feature_class`: The feature class that will contain the results. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "c:/data/city.gdb"

# Set local parameters
inFeatures = "lots"
updateFeatures = "cutzones"
outFeatures = "futurecut"

# Process: Update
arcpy.analysis.Update(in_features=inFeatures, update_features=updateFeatures, out_feature_class=outFeatures, keep_borders="NO_BORDERS")
```
**Toolset:** Pairwise Overlay

**Tool:** Pairwise Buffer

**Description:** The Pairwise Buffer tool creates buffer polygons around input features to a specified distance using a parallel processing approach. This tool is typically used to find features within a certain distance of other features, such as identifying areas within a specific radius of campgrounds.

**Parameters:**
- **Input Features:** The features around which buffers will be created. Type: Feature Layer.
- **Output Feature Class:** The name and location of the output feature class that will contain the buffer polygons. Type: Feature Class.
- **Distance [value or field]:** The distance around the input features to create the buffer. This can be a fixed value or a field from the input features. Type: Linear Unit.

**Derived Output:**
- **Output Feature Class:** The resulting feature class containing the buffer polygons. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/YourGeodatabase.gdb"

# Define input and output parameters
input_features = "CommercialCampgrounds"
output_feature_class = "Campground_Buffers"
buffer_distance = "1.5 Kilometers"

# Run Pairwise Buffer
arcpy.analysis.PairwiseBuffer(input_features, output_feature_class, buffer_distance)
```
**Toolset:** Pairwise Overlay

**Tool:** Pairwise Clip

**Description:** The Pairwise Clip tool is used to cut out a piece of one feature class using one or more of the features in another feature class. This is particularly useful for creating a new feature class that contains a geographic subset of the features in another, larger feature class.

**Parameters:**
- **Input Features:** The features to be clipped. Type: Feature Layer.
- **Clip Features:** The features used to clip the input features. Type: Feature Layer.
- **Output Feature Class:** The feature class that will contain the clipped features. Type: Feature Class.

**Derived Output:**
- **Output Feature Class:** The resulting feature class containing the clipped features. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define local variables
in_features = "C:/data/input_features.shp"
clip_features = "C:/data/clip_features.shp"
out_feature_class = "C:/output/clipped_features.shp"

# Execute Pairwise Clip
arcpy.analysis.PairwiseClip(in_features, clip_features, out_feature_class)
```
**Toolset:** Pairwise Overlay

**Tool:** Pairwise Dissolve

**Description:**  
The Pairwise Dissolve tool aggregates features based on specified attributes using a parallel processing approach. It is typically used to simplify data by merging features that share common attributes, enhancing performance when working with large datasets.

**Parameters:**
- **Input Features:** The layer containing the features to be dissolved.  
  *Type:* Feature Set.
- **Output Feature Class:** The name of the output feature class where the dissolved features will be stored.  
  *Type:* String.
- **Dissolve Fields:** One or more fields from the input layer that control which features are merged.  
  *Type:* Field.
- **Statistics Fields:** Fields on which statistical calculations will be performed during the dissolve process.  
  *Type:* Value Table.
- **Multi-part:** Specifies whether multipart features will be created.  
  *Type:* Boolean.
- **Concatenation Separator:** A character or characters used to concatenate values when the CONCATENATION option is used for statistics fields.  
  *Type:* String.

**Derived Output:**
- **Output Feature Class:** The dissolved features stored in the specified output feature class.  
  *Type:* Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/Portland.gdb/Taxlots"

# Set local variables
inFeatures = "taxlots"
outFeatureClass = "C:/output/output.gdb/taxlots_dissolved"
dissolveFields = ["LANDUSE", "TAXCODE"]

# Execute Pairwise Dissolve
arcpy.analysis.PairwiseDissolve(inFeatures, outFeatureClass, dissolveFields, "", "SINGLE_PART")
```
**Toolset:** Pairwise Overlay

**Tool: Pairwise Erase**

**Description:**  
The Pairwise Erase tool computes a pairwise intersection of the input and erase features. It is designed to efficiently handle large datasets with densely packed features by only copying those portions of the input features that fall outside the erase features to the output feature class. This tool is particularly useful when you need to remove overlapping areas from a dataset, such as erasing areas within a buffer zone from a larger feature class.

**Parameters:**
- **Input Features**: The input feature class or layer. Type: *Feature Layer*.
- **Erase Features**: The features that will be used to erase coincident features in the input. Type: *Feature Layer*.
- **Output Feature Class**: The output feature class. Type: *Feature Class*.
- **XY Tolerance (Optional)**: The minimum distance separating all feature coordinates (nodes and vertices) as well as the distance a coordinate can move in x or y (or both). It is recommended not to modify this parameter as it may cause failure or unexpected results. By default, the input feature class's spatial reference x,y tolerance property is used. Type: *Linear Unit*.

**Derived Output:**
- **Output Feature Class**: The output feature class containing only those portions of the input features that fall outside the erase features. Type: *Feature Class*.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data/gdb'
arcpy.env.overwriteOutput = True

# Set local variables
in_features = "redlands.gdb/rdls"
erase_features = "redlands.gdb/erase_area"
out_feature_class = "redlands.gdb/rdls_erased"

# Execute Pairwise Erase
arcpy.analysis.PairwiseErase(in_features, erase_features, out_feature_class)
```
**Toolset:** Pairwise Overlay

**Tool: Pairwise Integrate**

**Description:**  
The Pairwise Integrate tool analyzes the coordinate locations of feature vertices among features in one or more feature classes. It identifies vertices that fall within a specified distance of one another, assuming they represent the same location, and assigns them a common coordinate value. Additionally, it adds vertices where feature vertices are within the x,y tolerance of an edge and where line segments intersect.

**Parameters:**
- **in_features**: The input feature class or feature layer to be integrated. Type: Feature Layer.
- **cluster_tolerance (Optional)**: The distance that determines the range in which feature vertices are made coincident. It is recommended not to modify this parameter as it has been removed from view on the tool dialog box. By default, the input feature class's x,y tolerance property is used. Type: Linear Unit.

**Derived Output:**
- **out_feature_class**: The output feature class with updated input features. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/Habitat_Analysis.gdb"

# Set local variables
inFeatures = "vegtype"
integrateFeatures = "C:/output/output.gdb/vegtype"

# Run CopyFeatures (since PairwiseIntegrate modifies the original data, this ensures the original is preserved)
arcpy.management.CopyFeatures(inFeatures, integrateFeatures)

# Run PairwiseIntegrate
arcpy.analysis.PairwiseIntegrate(integrateFeatures)
```
**Toolset:** Pairwise Overlay

**Tool:** Pairwise Intersect

**Description:** The Pairwise Intersect tool computes the intersection between features in two feature layers or feature classes using a pairwise comparison technique. It writes the overlapping features or portions of features to the output feature class, making it useful for analyses where only two input feature layers are involved.

**Parameters:**
- **Input Features:** The first set of features to be intersected. Type: Feature Layer.
- **Intersect Features:** The second set of features to be intersected with the input features. Type: Feature Layer.
- **Output Feature Class:** The feature class where the intersected features will be stored. Type: Feature Class.

**Derived Output:**
- **Output Feature Class:** Contains the intersected features from the input and intersect feature layers. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data/data.gdb"

# Define input feature layers
inFeatures = ["vegetation", "streams"]

# Define output feature class
intersectOutput = "streams_in_vegtype"

# Run Pairwise Intersect
arcpy.analysis.PairwiseIntersect(inFeatures, intersectOutput)
```
**Toolset:** Proximity

**Tool:** Buffer

**Description:** The Buffer tool in ArcGIS Pro creates buffer polygons around input features to a specified distance. It is typically used to determine areas within a certain distance from a feature, such as identifying all locations within 1 mile of a school.

**Parameters:**
- **in_features:** The input point, line, or polygon features that will be buffered. **Type:** Feature Layer.
- **out_feature_class:** The feature class containing the output buffers. **Type:** Feature Class.
- **buffer_distance_or_field:** The distance around the input features that will be buffered. This can be a fixed value or a field containing numeric values. **Type:** Linear Unit or Field.

**Derived Output:**
- **output:** The output buffers layer. **Type:** Feature Set.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define input and output parameters
in_features = "fire_stations"
out_feature_class = "fire_buffer"
buffer_distance = "1000 METERS"

# Execute Buffer
arcpy.analysis.Buffer(in_features, out_feature_class, buffer_distance)
```

This script sets up the environment, specifies the input features, output feature class, and buffer distance, and then executes the Buffer tool using the `arcpy.analysis.Buffer` function.
**Toolset:** Proximity

**Tool:** Create Thiessen Polygons

**Description:** The Create Thiessen Polygons tool generates Thiessen (or Voronoi) polygons from point features. Each polygon contains a single point input feature, ensuring that any location within a polygon is closer to its associated point than to any other point feature. This tool is typically used to divide a space into regions based on proximity to a set of points.

**Parameters:**
- **Input Features:** The point input features from which Thiessen polygons will be generated.  
  *Type:* Feature Layer.
- **Output Feature Class:** The output feature class containing the generated Thiessen polygons.  
  *Type:* Feature Class.
- **Output Fields (Optional):** Specifies which fields from the input features will be transferred to the output feature class. Options include:
  - **ONLY_FID:** Only the FID field from the input features will be transferred.
  - **ALL:** All fields from the input features will be transferred.  
  *Type:* String.

**Derived Output:**
- **Output Feature Class:** The feature class containing the Thiessen polygons generated from the point input features.  
  *Type:* Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/data.gdb"

# Set local variables
inFeatures = "schools"
outFeatureClass = "c:/output/output.gdb/thiessen1"
outFields = "ALL"

# Run CreateThiessenPolygons
arcpy.analysis.CreateThiessenPolygons(inFeatures, outFeatureClass, outFields)
```
**Toolset:** Proximity

**Tool:** Generate Near Table

**Description:** The Generate Near Table tool calculates distances and other proximity information between features in one or more feature classes or layers. Unlike the Near tool, which modifies the input, Generate Near Table writes results to a new stand-alone table and supports finding more than one near feature.

**Parameters:**
- **Input Features:** The input features, which can be point, polyline, polygon, or multipoint type. Type: Feature Layer.
- **Near Features:** One or more feature layers or feature classes containing near feature candidates. The near features can be point, polyline, polygon, or multipoint. Type: Feature Layer.
- **Out Table:** The table where the results will be written. Type: Table.
- **Search Radius (Optional):** The radius within which to search for near features. Type: Linear Unit.
- **Location (Optional):** Specifies whether the location of the near feature will be added to the output table. Type: Boolean.
- **Angle (Optional):** Specifies whether the angle to the near feature will be added to the output table. Type: Boolean.
- **Closest (Optional):** Specifies whether to find only the closest feature or all features within the search radius. Type: String.
- **Closest Count (Optional):** The number of closest features to find. Type: Long.

**Derived Output:**
- **Out Table:** A new table containing the proximity information. Type: Table.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "C:/data/input/gnt.gdb"

# Define parameters
in_features = "campsites"
near_features = ["parks", "trails"]
out_table = "near_parks_trails"
search_radius = '1500 Meters'
location = 'NO_LOCATION'
angle = 'NO_ANGLE'
closest = 'ALL'
closest_count = 3

# Execute Generate Near Table
arcpy.analysis.GenerateNearTable(in_features, near_features, out_table, search_radius, location, angle, closest, closest_count)
```
**Toolset:** Proximity

**Tool:** Generate Origin-Destination Links

**Description:** The Generate Origin-Destination Links tool creates connecting lines from origin features to destination features, often referred to as spider diagrams. This tool is typically used to visualize and analyze spatial relationships between two sets of features, such as fire stations and response points.

**Parameters:**
- **Origin Features:** The input features from which links will be generated. Type: Feature Layer.
- **Destination Features:** The destination features to which links will be generated. Type: Feature Layer.
- **Output Feature Class:** The output polyline feature class that will contain the output links. Type: Feature Class.
- **Origin Group Field (Optional):** A field used to group origin features. Type: Field.
- **Destination Group Field (Optional):** A field used to group destination features. Type: Field.
- **Line Type (Optional):** Specifies the type of line to be generated (e.g., PLANAR). Type: String.
- **Number of Nearest (Optional):** The number of nearest destination features to connect to each origin. Type: Integer.
- **Search Distance (Optional):** The maximum distance to search for destination features. Type: Double.
- **Distance Unit (Optional):** The unit of measurement for the search distance (e.g., MILES). Type: String.
- **Aggregate Links (Optional):** Specifies whether overlapping links should be aggregated. Type: String.
- **Sum Fields (Optional):** Fields to sum for each link. Type: String.

**Derived Output:**
- **Output Origin-Destination Lines:** Provides access to the lines connecting the origins to the destinations, including travel time and distance. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set workspace environment
arcpy.env.workspace = "C:/data/input/genODLinks.gdb"

# Define parameters
origin_features = "Station_100"
destination_features = "City_FireResponses"
out_feature_class = "Station_100_OD_Links"
origin_group_field = 'STA_NUM'
destination_group_field = 'District'
line_type = 'PLANAR'
num_nearest = 10
search_distance = 25
distance_unit = 'MILES'
aggregate_links = 'AGGREGATE_OVERLAPPING'
sum_fields = 'TimeSpentOnCall SUM'

# Execute the tool
arcpy.analysis.GenerateOriginDestinationLinks(
    origin_features, 
    destination_features, 
    out_feature_class, 
    origin_group_field, 
    destination_group_field, 
    line_type, 
    num_nearest, 
    search_distance, 
    distance_unit, 
    aggregate_links, 
    sum_fields
)
```
No information available.
**Toolset:** Proximity

**Tool:** Multiple Ring Buffer

**Description:** The Multiple Ring Buffer tool creates a set of concentric circles around a point feature, given a specified number of rings and distance between rings, or a minimum and maximum distance from the center. It is typically used for spatial analysis to visualize areas at varying distances from a central point.

**Parameters:**
- **Input Features (Center Points):** The point feature set that identifies the center of the range ring. The input must have at least one point. Type: Feature Set.
- **Output Feature Class (Rings):** The feature class containing the output ring features. Type: Feature Class.
- **Range Ring Type:** Specifies the method to create the range rings. Options include "Interval" for generating rings based on the number of rings and distance between them, or "Minimum and maximum" for generating rings based on specified minimum and maximum distances. Type: String.
- **Output Feature Class (Radials) (Optional):** The feature class containing the output radial features. Type: Feature Class.
- **Number of Rings:** The number of rings to create. Type: Integer.
- **Distance Between Rings:** The distance between each ring. Type: Double.
- **Minimum Distance:** The minimum distance from the center point. Type: Double.
- **Maximum Distance:** The maximum distance from the center point. Type: Double.

**Derived Output:**
- **Output Feature Class (Rings):** The feature class containing the output ring features. Type: Feature Class.
- **Output Feature Class (Radials) (Optional):** The feature class containing the output radial features. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/Data/FeatureTest/FeatureTest.gdb"

# Define input parameters
input_features = "Points_MultipleRingBuffer"
output_rings = "Rings"
output_radials = "Radials"
ring_type = "INTERVAL"
number_of_rings = 3
distance_between_rings = "1000 Meters"

# Execute Multiple Ring Buffer
arcpy.analysis.MultipleRingBuffer(
    input_features, 
    output_rings, 
    number_of_rings, 
    distance_between_rings, 
    ring_type, 
    output_radials
)
```
No information available.
No information available.
**Toolset:** Statistics

**Tool:** Enrich

**Description:** The Enrich tool in ArcGIS Pro adds demographic and landscape facts to your data by appending new attribute fields to existing features. It is typically used to enhance geographic data with additional information about the surrounding area, such as population statistics or consumer behavior, for analysis and reporting purposes.

**Parameters:**
- **Input Features:** The features to be enriched. *Type: Feature Layer.*
- **Output Feature Class:** A new layer containing both the input attributes and user-selected attributes. *Type: Feature Class.*
- **Country:** The country whose data collections and variables are used to enrich the input. *Type: String.*
- **Data Collection:** The collection of data used to enrich the input. *Type: String.*
- **Variables (Optional):** The specific variables used to enrich the input. *Type: String.*
- **Define areas to enrich (Optional):** Specifies the area that will be enriched. *Type: String.*
- **Distance or time (Optional):** The distance or size of an area to enrich. *Type: Double.*
- **Unit (Optional):** The units associated with the distance or time parameter. *Type: String.*

**Derived Output:**
- **Output Feature Class:** The enriched feature class with additional attributes. *Type: Feature Class.*

**Example ArcPy code:**
```python
import arcpy

# Set the Business Analyst data source environment
arcpy.env.baDataSource = "ONLINE;US;"

# Use the Enrich tool to add demographic data
arcpy.analysis.Enrich(
    in_features="City",
    out_feature_class=r"C:\temp\Data.gdb\City_Enrich",
    variables="populationtotals.totpop_cy",
    buffer_type=None,
    distance=1,
    unit=None
)
```
**Toolset:** Statistics

**Tool:** Frequency

**Description:** The Frequency tool reads a table and a set of fields to create a new table containing unique field values and the number of occurrences of each unique field value. It is typically used to summarize data by counting occurrences of specific attribute combinations.

**Parameters:**
- **Input Table:** The table containing the field(s) that will be used to calculate frequency statistics. *Type: Table View; Raster Layer*.
- **Output Table:** The output table that will store the frequency statistics. *Type: Table*.
- **Frequency Field(s):** The field(s) used to calculate frequency statistics. Each unique combination of field values will be included as a new row in the output table. *Type: Field*.
- **Summary Field(s) (Optional):** The attribute field(s) to sum and add to the output table. Values will be summed for each unique combination of frequency fields. Null values are excluded from this calculation. *Type: Field*.

**Derived Output:**
- **Output Table:** Contains the frequency for each unique combination of the specified frequency field(s) and, if applicable, summarized values from the summary fields. *Type: Table*.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/Portland.gdb/Taxlots"

# Set local variables
inTable = "taxlots"
outTable = "C:/output/output.gdb/tax_frequency"
frequencyFields = ["YEARBUILT", "COUNTY"]
summaryFields = ["LANDVAL", "BLDGVAL", "TOTALVAL"]

# Execute Frequency
arcpy.analysis.Frequency(inTable, outTable, frequencyFields, summaryFields)
```
**Toolset:** Statistics

**Tool:** Summary Statistics

**Description:**  
The Summary Statistics tool calculates summary statistics for fields in a table, such as sum, mean, minimum, maximum, and more. It is typically used to analyze and summarize data attributes in a feature class or table.

**Parameters:**
- **Input Layer:** The point, polyline, or polygon layer to be summarized.  
  *Type:* Table View.
- **Output Table:** A new table with the summarized attributes.  
  *Type:* Table.
- **Fields:** A field or fields used to summarize similar features. For example, fields with values like 'commercial' and 'residential' can be summarized separately.  
  *Type:* Field.
- **Summary Fields (Optional):** The statistics that will be calculated on specified fields.  
  *Type:* Value Table.
- **Time step interval (Optional):** Specifies the duration of the time step, applicable if the input points are time-enabled.  
  *Type:* Time Unit.

**Derived Output:**
- **Output Table:** Contains the summarized attributes based on the specified fields and statistics.  
  *Type:* Table.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/f.gdb"

# Set local variables
input_layer = "intable"
output_table = "sumstats"
fields = ["PropertyType"]
summary_fields = [["Field1", "Sum"], ["Field2", "Mean"]]

# Run Summary Statistics
arcpy.analysis.Statistics(input_layer, output_table, summary_fields, fields)
```
**Toolset:** Statistics

**Tool:** Summarize Nearby

**Description:** The Summarize Nearby tool identifies features within a specified distance from features in the input layer and calculates statistics for these nearby features. It is typically used to assess accessibility or proximity, such as calculating the population within a drive-time radius of a new store location.

**Parameters:**
- **Input Nearby Layer:** Point, line, or polygon features from which distances will be measured to features in the input summary layer. Type: Feature Set.
- **Input Summary Features:** Point, line, or polygon features that will be summarized for each feature in the input nearby layer. Type: Feature Set.
- **Output Name:** The name of the output layer to create on your portal. Type: String.
- **Distance Measurement:** Defines the type of distance measurement: straight-line, drive-time, or drive distance. Type: String.
- **Distances:** A list of double values specifying multiple distances for buffering. Type: List of Double.
- **Units:** Units for distance measurement, such as kilometers or miles. Type: String.
- **Time of Day:** Specifies the time of day for travel mode calculations. Type: String.
- **Time Zone for Time of Day:** Time zone for the specified time of day. Type: String.
- **Return Boundaries:** Option to return the boundaries of the summarized areas. Type: Boolean.
- **Summary Fields:** A list of field names and statistical summary types to calculate for nearby features. Type: Value Table.
- **Group By Field:** Field from the input summary features to calculate statistics separately for each unique attribute value. Type: Field.
- **Add Minority and Majority Attributes:** Option to add fields for minority and majority attribute values. Type: Boolean.
- **Add Percentages:** Option to add percentage fields for each unique group value. Type: Boolean.

**Derived Output:**
- **Output Feature Service:** The output summarized layer. Type: Feature Set.
- **Output Group Table:** If a group by field is provided, outputs a table with calculated statistics for each unique group. Type: Record Set.

**Example ArcPy code:**
```python
import arcpy

# Set local variables
sumNearbyLayer = "InputNearbyLayer"
summaryLayer = "InputSummaryFeatures"
outputName = "SummarizedOutput"
nearType = "STRAIGHTLINE"
distances = [5, 10]  # Distances in kilometers
units = "KILOMETERS"
summaryFields = [["Population", "SUM"], ["Area", "MEAN"]]
groupByField = "Crime_type"
minorityMajority = "ADD_MIN_MAJ"
percentShape = "ADD_PERCENT"

# Execute Summarize Nearby
arcpy.sfa.SummarizeNearby(
    sumNearbyLayer=sumNearbyLayer,
    summaryLayer=summaryLayer,
    outputName=outputName,
    nearType=nearType,
    distances=distances,
    units=units,
    summaryFields=summaryFields,
    groupByField=groupByField,
    minorityMajority=minorityMajority,
    percentShape=percentShape
)
```
**Toolset:** Statistics

**Tool:** Summarize Within

**Description:** The Summarize Within tool overlays a polygon layer with another layer to summarize the number of points, length of the lines, or area of the polygons within each polygon. It calculates attribute field statistics for those features within the polygons. Typical use cases include calculating total acreage of land-use types within watersheds or summarizing the average value of vacant parcels within city boundaries.

**Parameters:**
- **Input Polygons:** The polygons used to summarize the features in the input summary layer. Type: Feature Layer.
- **Input Summary Features:** The point, line, or polygon features to be summarized for each polygon in the input polygons. Type: Feature Layer.
- **Output Feature Class:** The output polygon feature class containing the same geometries and attributes as the input polygons, with additional attributes for the number of points, length of lines, and area of polygons inside each input polygon. Type: Feature Class.
- **Keep all input polygons (Optional):** Specifies whether all input polygons or only those intersecting or containing at least one input summary feature will be copied to the output feature class. Type: Boolean.
- **Summary Fields (Optional):** A list of attribute field names from the input summary features, along with statistical summary types. Type: List.

**Derived Output:**
- **Output Feature Class:** The summarized polygon feature class with additional attributes for summarized statistics. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set the input parameters
input_polygons = "Campground_Buffers"
input_summary_features = "Nassella_Tussock_Range"
output_feature_class = "Tussock_Within_Buffers"

# Execute the Summarize Within tool
arcpy.analysis.SummarizeWithin(
    in_polygons=input_polygons,
    in_sum_features=input_summary_features,
    out_feature_class=output_feature_class,
    keep_all_polygons="KEEP_ALL",
    sum_fields=[["Area", "SUM"]]
)
```
No information available.
**Toolset:** 3D Objects

**Tool:** Add 3D Formats To Multipatch

**Description:**  
The "Add 3D Formats To Multipatch" tool converts a multipatch feature class into a 3D object feature layer by associating it with one or more 3D model formats. This enhances the multipatch features by optimizing texture storage and supporting additional visualization effects, making it suitable for advanced 3D modeling and rendering tasks.

**Parameters:**
- **Input Features:**  
  The multipatch feature class to be converted into a 3D object feature layer.  
  *Type:* Feature Layer.

- **3D Formats to Add (Optional):**  
  Specifies the 3D formats to associate with the multipatch features. Each feature will be stored in each selected format. Available formats include COLLADA (.dae), Autodesk Drawing (.dwg), Autodesk FilmBox (.fbx), Khronos Group glTF binary (.glb), Khronos Group glTF json (.gltf), Industry Foundation Classes (.ifc), Wavefront (.obj), Universal Scene Description (.usdc), and Compressed Universal Scene Description (.usdz).  
  *Type:* String.

**Derived Output:**
- **Updated Input Features:**  
  The updated input features with the added 3D formats.  
  *Type:* Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = 'C:/data/city_models.gdb'

# Use the Add3DFormats tool
arcpy.management.Add3DFormats(
    in_features='Downtown_Buildings',
    formats=['FMT3D_DAE', 'FMT3D_OBJ']
)
```
**Toolset:** 3D Objects

**Tool:** Export 3D Objects

**Description:** This tool exports 3D object features to one or more 3D model file formats. It is typically used to prepare 3D models for use in other software that does not support the 3D object feature layer, ensuring compatibility by selecting the most widely supported format version.

**Parameters:**
- **Input Features:** The 3D object feature layer that will be exported. Type: Feature Layer.
- **Target Folder:** The existing directory that will contain the output 3D models. Type: Folder.
- **3D Formats To Export:** Specifies the 3D formats that will be exported, such as COLLADA (.dae), Autodesk Drawing (.dwg), Autodesk (.fbx), Khronos Group glTF binary (.glb), Khronos Group glTF json (.gltf), Industry Foundation Classes (.ifc), Wavefront (.obj), Universal Scene Description (.usdc), and Compressed Universal Scene Description (.usdz). Type: String.
- **Output Folder Name Field (Optional):** The text field in the input feature's attribute table that contains the name to be used for each output folder. If no name field is provided, the output folder will use default naming. Type: String.

**Derived Output:**
- No specific derived outputs are mentioned in the provided information.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = 'C:/project_directory'

# Export the feature class or layer to model files on disk
arcpy.management.Export3DObjects(
    "city_models.gdb/Downtown_Buildings",  # Input Features
    "exported_models",                     # Target Folder
    ["FMT3D_IFC"]                          # 3D Formats To Export
)
```
No information available.
No information available.
**Toolset:** Attribute Rules

**Tool:** Add Attribute Rule

**Description:**  
The "Add Attribute Rule" tool is used to add custom rules to a dataset, enhancing the editing experience and enforcing data integrity. These rules can automatically populate attribute values or constrain permissible feature configurations during feature editing.

**Parameters:**
- **Input Table:** The table or feature class to which the new rule will be applied.  
  *Type:* Table View.
- **Name:** A unique name for the new rule.  
  *Type:* String.
- **Type:** Specifies the type of attribute rule to be added. Options include Calculation, Constraint, and Validation.  
  *Type:* String.
- **Script Expression:** The Arcade expression that defines the rule.  
  *Type:* Calculator Expression.
- **Is Editable (Optional):** Specifies whether the attribute value can be edited.  
  *Type:* Boolean.
- **Triggering Events (Optional):** Specifies the editing events that will trigger the attribute rule.  
  *Type:* String.

**Derived Output:**
- No specific derived outputs are listed for this tool.

**Example ArcPy code:**
```python
import arcpy

# Define the parameters for the Add Attribute Rule tool
input_table = "C:\\MyProject\\MyDatabase.sde\\myGDB.USER1.FacilitySite"
rule_name = "NewRule"
rule_type = "CALCULATION"
script_expression = "return $feature.Field1 + $feature.Field2"
is_editable = True
triggering_events = "INSERT;UPDATE"

# Execute the Add Attribute Rule tool
arcpy.management.AddAttributeRule(
    in_table=input_table,
    name=rule_name,
    type=rule_type,
    script_expression=script_expression,
    is_editable=is_editable,
    triggering_events=triggering_events
)
```

Feel free to ask if you need more details on using attribute rules or any other ArcGIS Pro functionalities.
**Toolset:** Attribute Rules

**Tool:** Alter Attribute Rule

**Description:** The Alter Attribute Rule tool is used to modify the properties of an existing attribute rule within a dataset. This tool is typically used to update rule descriptions, error messages, or tags associated with attribute rules in geodatabases.

**Parameters:**
- **Input Table:** The table containing the attribute rule that will be altered. Type: Table View.
- **Rule Name:** The name of the attribute rule that will be altered. Type: String.
- **Description (Optional):** The description of the attribute rule. Type: String.
- **Error Number (Optional):** The error number of the attribute rule. Type: String.
- **Error Message (Optional):** The error message of the attribute rule. Type: String.
- **Tags (Optional):** The tags for the attribute rule. Type: String.
- **Triggering Events (Optional):** Specifies the editing events that will trigger the attribute rule. Type: String.
- **Script Expression (Optional):** An ArcGIS Arcade expression that defines the rule. Type: Calculator Expression.
- **Exclude From Client Evaluation (Optional):** Specifies whether the application will evaluate the rule locally before applying the edits. Type: Boolean.
- **Triggering Fields (Optional):** A list of fields that will trigger an attribute rule to run during an update trigger. Type: Field.
- **Subtype (Optional):** The subtype or subtypes to which the rule will be applied. Type: String.

**Derived Output:**
- **Updated Table:** The input table with the updated attribute rule properties. Type: Table View; Raster Layer; Mosaic Layer.

**Example ArcPy code:**
```python
import arcpy

# Alter the properties of a constraint attribute rule named constraintRuleOP
arcpy.management.AlterAttributeRule(
    "C:\\MyProject\\sdeConn.sde\\progdb.user1.GasPipes",
    "constraintRuleOP",
    "Operating pressure cannot exceed 300",
    "999",
    "Invalid operating pressure value",
    "Pipeline;OP;ExceededValue"
)
```
**Toolset:** Attribute Rules

**Tool:** Delete Attribute Rule

**Description:** The Delete Attribute Rule tool is used to remove one or more attribute rules from a dataset. This tool is typically used to manage and update geodatabase datasets by removing outdated or unnecessary rules.

**Parameters:**
- **Input Table:** The table or feature class containing the attribute rules that will be deleted.  
  *Type:* Table View.
- **Rule Names:** The names of the rules that will be deleted from the dataset.  
  *Type:* String.
- **Type (Optional):** Specifies the type of attribute rules that will be deleted. Options include:
  - Calculation: Calculation rules will be deleted.
  - Constraint: Constraint rules will be deleted.
  - Validation: Validation rules will be deleted.  
  *Type:* String.

**Derived Output:**
- **Attribute Rules Deleted:** The updated input table with one or more attribute rules deleted.  
  *Type:* Table View; Raster Layer; Mosaic Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define the path to the feature class and the rules to delete
feature_class = "C:\\MyProject\\MyDatabase.sde\\pro.USER1.campusData"
rule_names = "Rule A;Rule B"
rule_type = "CALCULATION"

# Execute the Delete Attribute Rule tool
arcpy.management.DeleteAttributeRule(feature_class, rule_names, rule_type)
```

Feel free to ask if you need further assistance or have questions about other tools or functionalities in ArcGIS Pro.
**Toolset:** Attribute Rules

**Tool:** Disable Attribute Rules

**Description:** The "Disable Attribute Rules" tool is used to disable one or more attribute rules for a dataset. This is particularly useful when loading large amounts of data, as it can help avoid potential performance issues by temporarily suspending rule enforcement.

**Parameters:**
- **Input Table:** The table or feature class that contains the attribute rule to be disabled.  
  *Type:* Table View.
- **Rule Names:** The names of the rules to disable for the dataset.  
  *Type:* String.
- **Type (Optional):** Specifies the type of attribute rules to disable. Options include:
  - Calculation — Disable a calculation rule.
  - Constraint — Disable a constraint rule.
  - Validation — Disable a validation rule.  
  *Type:* String.

**Derived Output:**
- **out_table:** The updated input table with one or more attribute rules disabled.  
  *Type:* Table View; Raster Layer; Mosaic Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define the input feature class and the rules to disable
input_table = "C:\\MyProject\\MyDatabase.sde\\pro.USER1.campusData"
rule_names = "Rule A;Rule B"
rule_type = "CALCULATION"  # Optional parameter

# Disable the specified attribute rules
arcpy.management.DisableAttributeRules(input_table, rule_names, rule_type)
```

Feel free to ask if you need further clarification on using attribute rules or any other ArcGIS Pro functionalities.
**Toolset:** Attribute Rules

**Tool:** Enable Attribute Rules

**Description:** The "Enable Attribute Rules" tool is used to re-enable one or more attribute rules in a dataset that were previously disabled. This is typically used to enforce rules that were temporarily turned off, such as during bulk data loading operations.

**Parameters:**
- **Input Table:** The table or feature class containing the attribute rule to be enabled.  
  *Type:* Table View.
- **Rule Names:** The names of the rules to enable for the dataset.  
  *Type:* String.
- **Type (Optional):** Specifies the type of attribute rules to enable. Options include:
  - Calculation — Enable a calculation rule.
  - Constraint — Enable a constraint rule.
  - Validation — Enable a validation rule.  
  *Type:* String.

**Derived Output:**
- **Output Feature Class:** The updated input table with the attribute rule enabled.  
  *Type:* Table View; Raster Layer; Mosaic Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define the path to the feature class
feature_class = "C:\\MyProject\\MyDatabase.sde\\pro.USER1.campusData"

# Enable specific attribute rules by name
rule_names = "Rule A;Rule B"
rule_type = "CALCULATION"

# Execute the Enable Attribute Rules tool
arcpy.management.EnableAttributeRules(feature_class, rule_names, rule_type)
```

Feel free to ask if you need further clarification on using attribute rules or any other ArcGIS Pro functionalities.
**Toolset:** Attribute Rules

**Tool:** Evaluate Rules

**Description:** The Evaluate Rules tool in ArcGIS Pro is used to assess geodatabase attribute rules and functionality. It evaluates both calculation and validation rules within a specified workspace, ensuring data integrity and quality by identifying errors or rule violations.

**Parameters:**
- **Input Workspace:** The geodatabase or feature service URL where the rules will be evaluated. Type: Workspace.
- **Evaluation Types:** Specifies the types of rules to evaluate, such as calculation or validation rules. Type: String.
- **Extent (Optional):** Defines the spatial extent for evaluation. If a selection exists, only features within this extent are evaluated. Type: Extent.

**Derived Output:**
- **Evaluation Result:** The result of the evaluation process, detailing any errors or rule violations. Type: AttributeRuleEvaluationResult.

**Example ArcPy code:**
```python
import arcpy

# Define the input workspace and evaluation parameters
input_workspace = "C:/path/to/your/geodatabase.gdb"
evaluation_types = "Validation"

# Execute the Evaluate Rules tool
arcpy.management.EvaluateRules(
    in_workspace=input_workspace,
    evaluation_types=evaluation_types
)
```

This script sets up the necessary environment to run the Evaluate Rules tool, specifying the workspace and the type of evaluation to perform. Feel free to ask more about attribute rules or any other ArcGIS Pro functionalities.
**Toolset:** Attribute Rules

**Tool:** Export Attribute Rules

**Description:**  
The Export Attribute Rules tool is used to export attribute rules from a dataset to a comma-separated values file (.csv). This tool is typically used to transfer attribute rules between existing datasets or to create a backup of the rules for documentation or further analysis.

**Parameters:**
- **in_table:** The table or feature class from which the attribute rules will be exported.  
  *Type:* Table View.
- **out_csv_file:** The folder location and name of the .csv file that will be created.  
  *Type:* File.

**Derived Output:**
- **out_csv_file:** The .csv file containing the exported attribute rules.  
  *Type:* File.

**Example ArcPy code:**
```python
import arcpy

# Define the input feature class and output CSV file path
input_table = "C:\\MyProject\\MyDatabase.sde\\pro.USER1.GasPipes"
output_csv = "C:\\MyProject\\ExpAttrRulesFrBuilding.csv"

# Execute the Export Attribute Rules tool
arcpy.management.ExportAttributeRules(input_table, output_csv)
```
**Toolset:** Attribute Rules

**Tool:** Import Attribute Rules

**Description:** The Import Attribute Rules tool is used to import attribute rules from comma-separated value files (.csv) into a specified dataset. This tool is typically used to transfer attribute rules between datasets or to apply predefined rules to a dataset to automate data management tasks.

**Parameters:**
- **Target Table:** The table or feature class to which the attribute rules will be applied. The dataset must have all the features specified in the rule definition. Type: Table View.
- **Input File:** The .csv files containing the rules to import. Type: File.

**Derived Output:**
- **Attribute Rules Imported:** The updated input dataset with the imported attribute rules. Type: Table View; Raster Layer; Mosaic Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define the target table and the CSV files containing the attribute rules
target_table = "C:\\MyProject\\MyDatabase.sde\\pro.USER1.Building"
csv_files = ["C:\\MyProject\\expAttrRules.csv", "C:\\MyProject\\expAttrRules_II.csv"]

# Import the attribute rules from the CSV files into the target table
arcpy.management.ImportAttributeRules(target_table, csv_files)
```

This script imports attribute rules from specified CSV files into a feature class named "Building" within a geodatabase.
**Toolset:** Attribute Rules

**Tool: Reorder Attribute Rule**

**Description:**  
The "Reorder Attribute Rule" tool is used to change the evaluation order of an attribute rule within a geodatabase. This is important because the sequence in which rules are evaluated can affect the outcome, especially when there are dependencies on calculated fields.

**Parameters:**
- **Input Table**: The table that contains the attribute rule with the evaluation order that will be updated.  
  *Type: Table View*.
- **Calculation Rule Name**: The name of the calculation rule that will have its evaluation order updated. Type: *String*.
- **Evaluation Order**: The new evaluation order for the rule. For example, if there are five rules and a particular rule is in position 5 (the fifth order position, to be evaluated last) but you want it to be evaluated in position 2 (to be evaluated second), enter 2 for the value. The evaluation order for the rules after position 2 will be reassigned (that is, position 2 becomes position 3, position 3 becomes position 4, and position 4 becomes position 5). Type: Long.

**Derived Output:**
- **Updated Table**: The input table with its attribute rule evaluation order updated. Type: Table View.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Define the input parameters
in_table = "C:\\MyProject\\sdeConn.sde\\progdb.user1.GasPipes"
calculation_rule_name = "calculateRuleLabel"
evaluation_order = 1

# Reorder the attribute rule
arcpy.management.ReorderAttributeRule(in_table, calculation_rule_name, evaluation_order)
```
**Toolset:** Visibility

**Tool:** Linear Line Of Sight

**Description:** The Linear Line Of Sight tool creates lines of sight between observers and targets, showing the surface visibility between these locations. It is typically used for locating observation posts or testing the siting of radio antennas.

**Parameters:**
- **Input Surface:** The elevation surface layer used for calculations. Type: Feature Layer.
- **Observer Points:** Locations of observers, which can be manually entered or selected from a map. Type: Feature Layer.
- **Target Points:** Locations of targets, which can be manually entered or selected from a map. Type: Feature Layer.
- **Height Above Surface (Observer):** The height added to the observer's surface elevation. Default is 2 meters. Type: Double.
- **Height Above Surface (Target):** The height added to the target's surface elevation. Default is 0 meters. Type: Double.
- **Add Profile Graph:** Option to add a profile graph showing terrain between observer and target. Type: Boolean.

**Derived Output:**
- **Output Linear Line of Sight:** A feature dataset containing lines of sight between observer and target points. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = r"C:/Data.gdb"

# Define input parameters
input_surface = "n36.dt2"
observer_points = "Test_Observers"
target_points = "Test_Targets"

# Execute Linear Line Of Sight
arcpy.defense.LinearLineOfSight(
    observer_points, 
    target_points, 
    input_surface, 
    "LineOfSight", 
    "SightLines", 
    observer_points, 
    target_points, 
    None, 
    2, 
    0, 
    "NO_PROFILE_GRAPH"
)
```
No information available.
**Toolset:** Visibility

**Tool:** Radial Line Of Sight And Range

**Description:** The Radial Line Of Sight And Range tool identifies areas visible to one or more observer locations within a specified distance and viewing angle. It is typically used for visibility analysis in scenarios such as siting antennas or determining observation posts.

**Parameters:**
- **Observer Features:** The input feature class that identifies the observer locations. Type: Feature Layer.
- **Input Surface:** The input surface raster for visibility calculation. Type: Raster Layer.
- **Output Viewshed Feature Class:** The output polygon feature class showing visible and nonvisible areas. Type: Feature Class.
- **Output Field Of View Feature Class:** The output polygon feature class containing the field of view range fan. Type: Feature Class.
- **Output Range Radius Feature Class:** The output polygon feature class containing the viewing sector created by the range radius, start angle, and end angle. Type: Feature Class.
- **Observer Height Offset (Optional):** The height added to the surface elevation of the observer. Default is 2. Type: Double.
- **Inner Radius (Optional):** The minimum distance from observers to consider for analysis in meters. Default is 1000. Type: Double.
- **Outer Radius (Optional):** The maximum distance from observers to consider for analysis in meters. Default is 3000. Type: Double.
- **Horizontal Start Angle (Optional):** The left bearing limit in degrees. Default is 0. Type: Double.
- **Horizontal End Angle (Optional):** The right bearing limit in degrees. Default is 360. Type: Double.

**Derived Output:**
- **Output Viewshed Feature Class:** Shows visible and nonvisible areas. Type: Feature Class.
- **Output Field Of View Feature Class:** Contains the field of view range fan. Type: Feature Class.
- **Output Range Radius Feature Class:** Contains the viewing sector created by the range radius, start angle, and end angle. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = r"C:/Data.gdb"

# Define input parameters
observer_features = "LLOS_Tar"
input_surface = "n36.dt2"
output_viewshed = "Viewshed"
output_fov = "FieldOfView"
output_range = "Range"
observer_height_offset = 2
inner_radius = 1000
outer_radius = 3000
horizontal_start_angle = 0
horizontal_end_angle = 360

# Execute Radial Line Of Sight And Range
arcpy.defense.RadialLineOfSightAndRange(
    observer_features,
    input_surface,
    output_viewshed,
    output_fov,
    output_range,
    observer_height_offset,
    inner_radius,
    outer_radius,
    horizontal_start_angle,
    horizontal_end_angle
)
```
**Toolset:** Visibility

**Tool:** Find Highest Or Lowest Point

**Description:** This tool identifies the highest or lowest point on an input surface within a specified area. It is typically used for tasks such as determining potential obstructions at an airport or finding the highest peak in a park.

**Parameters:**
- **Input Surface:** The input elevation raster surface.  
  *Type:* Raster Layer; Mosaic Dataset; Mosaic Layer.
- **Output Feature Class:** The feature class that will contain the output highest or lowest point.  
  *Type:* Feature Class.
- **Highest or Lowest Point:** Specifies whether to find the highest or lowest points. Options are "Highest" (default) or "Lowest".  
  *Type:* String.
- **Input Area (Optional):** The input polygon feature class within which the highest or lowest point will be found.  
  *Type:* Feature Set.

**Derived Output:**
- **Output Feature Class:** Contains the highest or lowest point(s) found.  
  *Type:* Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = r"C:/Data.gdb"
arcpy.env.overwriteOutput = True

# Define inputs
input_surface = "n36.dt2"
output_feature_class = "FindHighestPoint"
operation_type = "HIGHEST"
input_area = "AOI"  # Optional

# Execute the FindHighestLowestPoint tool
arcpy.defense.FindHighestLowestPoint(
    in_surface=input_surface,
    out_feature_class=output_feature_class,
    high_low_operation_type=operation_type,
    in_feature=input_area
)
```
**Toolset:** Visibility

**Tool:** Find Local Peaks Or Valleys

**Description:** The "Find Local Peaks Or Valleys" tool identifies local peaks or valleys within a specified area on an elevation surface. It is typically used in terrain analysis to locate high points (peaks) or low points (valleys) for applications such as site selection, landscape analysis, or environmental studies.

**Parameters:**
- **Input Surface:** The input elevation raster surface. *Type: Raster Layer; Mosaic Dataset; Mosaic Layer.*
- **Output Feature Class:** The output point feature class containing the local peaks or valleys. *Type: Feature Class.*
- **Peaks or Valleys:** Specifies the type of operation the tool will perform. Options are "Local peaks" or "Local valleys." *Type: String.*
- **Number of Peaks or Valleys:** The number of peaks or valleys to find. *Type: Long.*
- **Input Area (Optional):** The input polygon feature class in which the local peaks or valleys will be found. *Type: Feature Set.*

**Derived Output:**
- **Output Feature Class:** Contains the local peaks or valleys with an elevation field indicating their elevation values. *Type: Feature Class.*

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = r"C:/Data.gdb"

# Define input parameters
input_surface = "n36.dt2"
output_feature_class = "n36_FindLocalPeaksValleys"
peak_valley_op_type = "PEAKS"
num_peaks_valleys = 10
input_area = "SelectedAOI"  # Optional

# Execute the Find Local Peaks Or Valleys tool
arcpy.defense.FindLocalPeaksValleys(
    in_surface=input_surface,
    out_feature_class=output_feature_class,
    peak_valley_op_type=peak_valley_op_type,
    num_peaks_valleys=num_peaks_valleys,
    in_feature=input_area
)
```
**Toolset:** Visibility

**Tool:** Construct Sight Lines

**Description:** The Construct Sight Lines tool creates line features that represent sight lines from one or more observer points to features in a target feature class. It is typically used to determine visibility between observers and targets, with applications in urban planning, military operations, and environmental studies.

**Parameters:**
- **Observer Features:** The input feature class containing observer points. Type: Feature Layer.
- **Target Features:** The input feature class containing target points or lines. Type: Feature Layer.
- **Output Sight Line Features:** The output feature class that will contain the sight lines. Type: Feature Class.
- **Observer Height Field (Optional):** The field containing the height of the observer points. Type: String.
- **Target Height Field (Optional):** The field containing the height of the target points. Type: String.
- **Join Field (Optional):** The field used to match observers to specific targets. Type: String.
- **Sampling Distance (Optional):** The distance between samples when the target is a line or polygon feature class. Type: Double.
- **Output the Direction (Optional):** Specifies whether to add direction attributes to the output sight lines. Type: Boolean.
- **Sampling Method (Optional):** Specifies how the sampling distance will be used to establish sight lines along the target feature. Type: String.

**Derived Output:**
- **Output Sight Line Features:** The feature class containing the constructed sight lines with visibility attributes. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Define input and output parameters
observer_features = 'observer_pts.shp'
target_features = 'target.shp'
output_sight_lines = 'sightlines.shp'
observer_height_field = 'Height'
target_height_field = 'Height'
join_field = None
sampling_distance = 1.0
output_direction = 'OUTPUT_THE_DIRECTION'
sampling_method = '2D_DISTANCE'

# Execute Construct Sight Lines
arcpy.ddd.ConstructSightLines(
    observer_features,
    target_features,
    output_sight_lines,
    observer_height_field,
    target_height_field,
    join_field,
    sampling_distance,
    output_direction,
    sampling_method
)
```
**Toolset:** Visibility

**Tool:** Geodesic Viewshed

**Description:**  
The Geodesic Viewshed tool determines surface locations visible to a set of point or polyline observers using geodesic methods. It transforms the elevation surface into a geocentric 3D coordinate system and runs 3D sight lines to each transformed cell center, providing more accurate visibility analysis by considering earth curvature and refractivity.

**Parameters:**
- **Input Observer Features:** The input observer points.  
  *Type:* Feature Set.
- **Input Surface:** The input elevation raster surface.  
  *Type:* Raster Layer; Mosaic Dataset; Mosaic Layer.
- **Radius Of Observer (meters) (Optional):** The radius of the analysis area from the observer.  
  *Type:* Double.
- **Observer Height Above Surface (meters) (Optional):** The height added to the surface elevation of the observer. The default is 2.  
  *Type:* Double.

**Derived Output:**
- **Output Visibility:** The output polygon feature class showing visible and nonvisible surface areas.  
  *Type:* Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set local variables
inObserverFeatures = "observers.shp"
inSurface = "elevation"
outVisibility = "C:/output/outVisibility"

# Execute Geodesic Viewshed
arcpy.ddd.GeodesicViewshed(inObserverFeatures, inSurface, outVisibility, radius=5000, observer_height_above_surface=2)
```
No information available.
**Toolset:** Visibility

**Tool:** Line Of Sight

**Description:** The Line Of Sight tool in ArcGIS Pro calculates intervisibility between the first and last vertex of each line feature in 3D space, considering obstructions from a surface or multipatch feature class. It is typically used to determine visibility between observation points and targets, such as for siting observation posts or radio antennas.

**Parameters:**
- **Sight Lines:** The 3D sight lines whose visibility will be determined. Type: Feature Layer.
- **Obstructions:** The mesh and surface datasets that provide potential obstructions for sight lines. Type: Feature Layer; TIN Layer; Raster Layer; Mosaic Layer; Scene Layer; File.
- **Visible Field Name (Optional):** The name of the field that will store the visibility results. Type: String.

**Derived Output:**
- **Output Feature Class:** The updated 3D sight lines. Type: Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define input parameters
sight_lines = "sightlines.shp"
obstructions = ["3dbuildings.shp", "topo_tin"]
visible_field = "Visibility"

# Execute Line Of Sight tool
arcpy.ddd.Intervisibility(sight_lines, obstructions, visible_field)
```
**Toolset:** Visibility

**Tool:** Observer Points

**Description:** The Observer Points tool identifies which observer points are visible from each raster surface location. It is typically used in scenarios such as determining the visibility of fire lookout towers or assessing which areas can be seen from specific observation points.

**Parameters:**
- **Input raster:** The input surface raster. Type: Raster Layer.
- **Input point or polyline observer features:** The feature class that identifies the observer locations. The input can be point or polyline features. Type: Feature Layer.
- **Output raster:** The output raster that records visibility information. Type: Raster Dataset.
- **Output above ground level raster (Optional):** The output above-ground-level (AGL) raster where each cell value is the minimum height needed to make it visible by at least one observer. Type: Raster Dataset.
- **Analysis type (Optional):** The visibility analysis type, either "Frequency" or "Observers". Type: String.
- **Use NoData for non-visible cells (Optional):** Specifies whether NoData is assigned to nonvisible cells. Type: Boolean.
- **Z factor (Optional):** Adjusts the units of measure for the z-units when they differ from the x,y units of the input surface. Type: Double.
- **Use earth curvature corrections (Optional):** Specifies whether correction for the earth's curvature will be applied. Type: Boolean.
- **Refractivity coefficient (Optional):** The coefficient of the refraction of visible light in air. Default is 0.13. Type: Double.

**Derived Output:**
- **Output raster:** Identifies which observer points are visible from each raster surface location. Type: Raster Dataset.
- **Output above ground level raster (Optional):** Records the minimum height needed to make a cell visible by at least one observer. Type: Raster Dataset.

**Example ArcPy code:**
```python
import arcpy
from arcpy import env

# Set environment settings
env.workspace = "C:/data"

# Set local variables
inRaster = "elevation"
inObsPoints = "observers.shp"
outRaster = "C:/output/outobspnt01"
zFactor = 1
useEarthCurv = "CURVED_EARTH"
refractionVal = 0.13

# Execute ObserverPoints
arcpy.ddd.ObserverPoints(inRaster, inObsPoints, outRaster, zFactor, useEarthCurv, refractionVal)
```
**Toolset:** Visibility

**Tool:** Skyline

**Description:**  
The Skyline tool generates a 3D polyline representation of the line separating the sky from the surface and features surrounding each observer point. It is typically used to analyze the horizon from a viewpoint, creating a skyline that can be used for further analysis, such as shadow volume generation.

**Parameters:**
- **in_observer_point_features:** The input features containing one or more observer points. Type: Feature Layer.
- **in_line_features:** The line features that represent the skyline. Type: Feature Layer.
- **base_visibility_angle (Optional):** The baseline vertical angle used to calculate the percentage of visible sky. Zero is the horizon, 90 is straight up, and -90 is straight down. Default is 0. Type: Double.
- **additional_fields (Optional):** Specifies whether additional fields will be included in the angles table. Type: Boolean.
- **out_angles_table (Optional):** The table created for outputting the horizontal and vertical angles from the observer point to each of the vertices on the skyline. Type: Table.
- **out_graph (Optional):** This parameter is not supported. Type: Graph.
- **out_image_file (Optional):** The image of the polar chart depicting the radial view of the visible skyline. Can be created in PNG, JPG, JPEG, or SVG format. Type: File.

**Derived Output:**
- **out_visibility_ratio:** The average percentage of visible sky for all observers, expressed as a value from 0 to 1. Type: Double.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Set Local Variables
in_observer_point_features = "observers.shp"
in_line_features = "skyline_outline.shp"
base_visibility_angle = 0
additional_fields = "ADDITIONAL_FIELDS"
out_angles_table = arcpy.CreateUniqueName("angles_table.dbf")

# Execute SkylineGraph
arcpy.ddd.SkylineGraph(
    in_observer_point_features,
    in_line_features,
    base_visibility_angle,
    additional_fields,
    out_angles_table
)
```
**Toolset:** Visibility

**Tool:** Skyline Barrier

**Description:** The Skyline Barrier tool generates a multipatch feature class representing a skyline barrier or shadow volume. It is typically used to determine whether features, such as buildings, violate the barrier by protruding through it or to assess if a proposed building will alter the skyline.

**Parameters:**
- **Input Observer Point Features:** The point feature class containing the observer points. Type: Feature Layer.
- **Input Features:** The input line feature class representing the skylines or the input multipatch feature class representing the silhouettes. Type: Feature Layer.
- **Output Feature Class:** The output feature class into which the skyline barrier or shadow volume will be stored. Type: Feature Layer.
- **Minimum Radius:** The horizontal distance from the observer point to the beginning of the shadow volume. Type: Linear Unit; Field.
- **Maximum Radius:** The horizontal distance from the observer point to the end of the shadow volume. Type: Linear Unit; Field.
- **Closed (Optional):** Specifies whether a skirt and base will be added to form a closed solid. Type: Boolean.
- **Base Elevation (Optional):** The elevation of the base of the closed multipatch. Type: Linear Unit; Field.
- **Project to Plane (Optional):** Specifies whether the barrier should be projected onto a vertical plane. Type: Boolean.

**Derived Output:**
- **Output Feature Class:** Contains the skyline barrier or shadow volume. Type: Feature Layer.

**Example ArcPy code:**
```python
# Import system modules
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Set Local Variables
inPts = 'observers.shp'
inLine = 'skyline.shp'
outFC = 'output_barriers.shp'
minRadius = '0 METERS'
maxRadius = '200 METERS'

# Execute SkylineBarrier
arcpy.ddd.SkylineBarrier(inPts, inLine, outFC, minRadius, maxRadius, 'CLOSED')
```

Feel free to ask if you need more details on using the Skyline Barrier tool or any other ArcGIS Pro functionalities.
**Toolset:** Visibility

**Tool:** Skyline Graph

**Description:** The Skyline Graph tool calculates the sky visibility ratio and generates an optional table and a polar graph. It is typically used to assess how open or closed a physical site is by analyzing the percentage of visible sky from a given observer point.

**Parameters:**
- **in_pts**: The input features containing one or more observer points. Type: Feature Layer.
- **in_line_features**: The line features that represent the skyline. Type: Feature Layer.
- **base_visibility_angle**: (Optional) The baseline vertical angle used to calculate the percentage of visible sky. Zero is the horizon, 90 is straight up, and -90 is straight down. The default is 0. Type: Double.
- **additional_fields**: (Optional) Specifies whether additional fields will be included in the angles table. Options are NO_ADDITIONAL_FIELDS (default) or ADDITIONAL_FIELDS. Type: Boolean.
- **out_angles_table**: (Optional) The table created for outputting the horizontal and vertical angles from the observer point to each of the vertices on the skyline. Type: Table.
- **out_graph**: (Optional) This parameter is not supported. Type: Graph.
- **out_image_file**: (Optional) The image of the polar chart depicting the radial view of the visible skyline. The image can be created in PNG, JPG, JPEG, or SVG format. Type: File.

**Derived Output:**
- **out_visibility_ratio**: The average percentage of visible sky for all observers, expressed as a value from 0 to 1, where 0.8 represents 80 percent visibility of the skyline. Type: Double.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Set Local Variables
inPts = "observers.shp"
inLines = "skyline_outline.shp"
baseVisibility = 25

# Ensure output table has unique name
outTable = arcpy.CreateUniqueName("angles_table.dbf")

# Execute SkylineGraph
arcpy.ddd.SkylineGraph(inPts, inLines, baseVisibility, "ADDITIONAL_FIELDS", outTable)
```
No information available.
No information available.
**Toolset:** Visibility

**Tool:** Viewshed

**Description:** The Viewshed tool identifies areas visible from one or more observer locations on a surface. It is typically used for visibility analysis in applications such as determining line-of-sight for surveillance, planning, and environmental studies.

**Parameters:**
- **Input Observer Features:** The input observer points. *Type:* Feature Set.
- **Input Surface:** The input elevation raster surface. *Type:* Raster Layer; Mosaic Dataset; Mosaic Layer.
- **Radius Of Observer (meters) (Optional):** The radius of the analysis area from the observer. *Type:* Double.
- **Observer Height Above Surface (meters) (Optional):** The height added to the surface elevation of the observer. The default is 2. *Type:* Double.

**Derived Output:**
- **Output Visibility:** The output polygon feature class showing visible and nonvisible surface areas. *Type:* Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set local variables
inRaster = "elevation"
inObserverFeatures = "observers.shp"
outViewshed = "C:/output/outvwshd02"
zFactor = 2
useEarthCurvature = "CURVED_EARTH"
refractivityCoefficient = 0.15

# Execute Viewshed
arcpy.ddd.Viewshed(inRaster, inObserverFeatures, outViewshed, zFactor, useEarthCurvature, refractivityCoefficient)
```
**Toolset:** Visibility

**Tool:** Visibility

**Description:** The Visibility tool in ArcGIS Pro is used to determine areas visible to one or more observer locations. It creates a viewshed by analyzing the visibility from specified observer points, considering factors such as earth curvature and refractivity if supported by the input surface.

**Parameters:**
- **Input Observer Features:** The input observer points. *Type:* Feature Set.
- **Input Surface:** The input elevation raster surface. *Type:* Raster Layer; Mosaic Dataset; Mosaic Layer.
- **Output Visibility:** The output polygon feature class showing visible and nonvisible surface areas. *Type:* Feature Class.
- **Radius Of Observer (meters) (Optional):** The radius of the analysis area from the observer. *Type:* Double.
- **Observer Height Above Surface (meters) (Optional):** The height added to the surface elevation of the observer. The default is 2. *Type:* Double.

**Derived Output:**
- **Output Feature Class:** The updated 3D sight lines. *Type:* Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = r"C:\Data.gdb"

# Define input parameters
in_observer_features = "Observers.shp"
in_surface = "Elevation_Dataset"
out_feature_class = "Visibility_Output"

# Execute the Visibility tool
arcpy.defense.RadialLineOfSight(
    in_observer_features,
    in_surface,
    out_feature_class,
    radius=5000,  # Optional parameter
    observer_height_above_surface=2  # Optional parameter
)
```
No information available.
**Toolset:** Airports

**Tool:** Analyze LAS Runway Obstacles

**Description:** Analyzes lidar data and obstruction identification surfaces (OIS) to determine if lidar points are penetrating these surfaces, which is crucial for ensuring flight safety by identifying potential obstacles on or near runways.

**Parameters:**
- **Input Obstruction Identification Surface Feature Class:** The input multipatch feature class containing the OIS. Type: Feature Layer.
- **Input LAS Obstacle Data:** The input LAS dataset containing potential obstacles. Type: LAS Dataset.
- **Output Folder for LIDAR Data:** The folder where the output LIDAR data will be stored. Type: Folder.
- **Output LIDAR Dataset:** The output LAS dataset that will be generated. Type: LAS Dataset.
- **Vertical Clearance (Optional):** The vertical clearance value to be used in the analysis. Type: Double.
- **Vertical Clearance Unit (Optional):** The unit of measure for the vertical clearance. Type: String.

**Derived Output:**
- **Output LAS Dataset:** The LAS dataset that contains the analyzed obstacles. Type: LAS Dataset.

**Example ArcPy code:**
```python
import arcpy

# Check out necessary extensions
arcpy.CheckOutExtension("Airports")
arcpy.CheckOutExtension("3D")

# Define input and output parameters
inOISFeatures = r"C:\data\ois.gdb\ObstructionIdSurface"
inLASObstacles = r"C:\data\PotentialObstacles.lasd"
outObstacleFolder = r"C:\data\LasObstacles"
outObstacleDataset = r"C:\data\LasObstacles\LasObstacles.lasd"

# Execute the Analyze LAS Runway Obstacles tool
arcpy.aviation.AnalyzeLASRunwayObstacles(
    inOISFeatures, 
    inLASObstacles, 
    None, 
    outObstacleFolder, 
    outObstacleDataset, 
    10,  # Example vertical clearance
    "METERS"  # Example unit
)

# Check in extensions
arcpy.CheckInExtension("3D")
arcpy.CheckInExtension("Airports")
```

Feel free to ask if you need more details on any specific aspect of this tool or its usage.
**Toolset:** Airports

**Tool:** Analyze Runway Obstacles

**Description:** The Analyze Runway Obstacles tool examines obstacle data and obstruction identification surfaces (OIS) to determine if obstacles penetrate the OIS, which can be classified as flight hazards.

**Parameters:**
- **Input OIS Features:** The multipatch feature class containing the OIS. Type: Feature Layer.
- **Input Obstacle Features:** The feature class containing obstacles, which can be point, line, or polygon features. Must be z-enabled with a projected coordinate system. Type: Feature Layer.
- **Obstacle Height:** Specifies the height of the obstacle features, either as a field in the feature class or using the keyword FEATURE_GEOMETRY for z-coordinate values. Type: String.
- **Unit (Optional):** Specifies the unit of measure for obstacle height. Options include Feet, Meters, etc. Type: String.

**Derived Output:**
- **Output Obstacle Feature Class:** A new feature class describing how each input obstacle interacts with the OIS approach surface. Type: Feature Layer.

**Example ArcPy code:**
```python
import arcpy

# Check out the necessary extension
arcpy.CheckOutExtension("Airports")

# Set local variables
inOISFeatures = r"C:\data\ois.gdb\ObstructionIdSurface_MP"
inObstacleFeatures = r"C:\data\ois.gdb\VerticalStructurePoint"
outObstacleFeatureClass = r"C:\data\ois.gdb\DOF_Hazards"
obstacleHeight = "Elev_Val"
unit = "Feet"

# Execute Analyze Runway Obstacles
arcpy.aviation.AnalyzeRunwayObstacles(
    inOISFeatures=inOISFeatures,
    inObstacleFeatures=inObstacleFeatures,
    outObstacleFeatureClass=outObstacleFeatureClass,
    obstacleHeight=obstacleHeight,
    unit=unit
)

# Check in the extension
arcpy.CheckInExtension("Airports")
```

Feel free to ask more about ArcGIS Pro tools or any other Esri products.
No information available.
No information available.
**Toolset:** Area and Volume

**Tool:** Cut Fill

**Description:**  
The Cut Fill tool calculates the volume change between two surfaces, typically used for cut-and-fill operations. It identifies regions of surface material removal, addition, and areas where the surface has not changed, making it useful for applications such as construction site leveling and erosion studies.

**Parameters:**
- **Before_Raster:** The raster representing the initial surface. Type: Raster Dataset.
- **After_Raster:** The raster representing the modified surface. Type: Raster Dataset.
- **OutRas:** The output raster that will display the areas and volumes of change. Type: Raster Dataset.
- **z_factor (Optional):** Adjusts the units of measure for the z-units when they differ from the x,y units of the input surface. Type: Double.

**Derived Output:**
- **Output Raster:** Displays the areas and volumes of surface materials modified by removal or addition. Positive values indicate material removal (cut), and negative values indicate material addition (fill). Type: Raster Dataset.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define local variables
before_raster = "elevation01"
after_raster = "elevation02"
output_raster = "C:/output/outcutfill01"
z_factor = 1  # Optional, adjust if necessary

# Execute CutFill
arcpy.ddd.CutFill(before_raster, after_raster, output_raster, z_factor)
```

Feel free to ask more about the Cut Fill tool or explore other tools in the ArcGIS Pro suite.
**Toolset:** Area and Volume

**Tool:** Difference 3D

**Description:** The Difference 3D tool is used to eliminate portions of multipatch features in a target feature class that overlap with enclosed volumes of multipatch features in the subtraction feature class. This tool is typically used to analyze and modify 3D spatial data by removing overlapping sections.

**Parameters:**
- **in_features_minuend:** The multipatch features that will have features removed by the subtrahend features. Type: Feature Layer.
- **in_features_subtrahend:** The multipatch features that will be subtracted from the input. Type: Feature Layer.
- **out_feature_class:** The output multipatch feature class that will contain the resulting features. Type: Feature Class.
- **out_table (Optional):** A table that stores information about the relationship between the input features and the difference output. The following fields will be created in this table: Output_ID, Minuend_ID, Subtrahend. Type: Table.

**Derived Output:**
- **out_feature_class:** The output multipatch feature class that will contain the resulting features. Type: Feature Class.
- **out_table (Optional):** A table that stores information about the relationship between the input features and the difference output. Type: Table.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Set Local Variables
in_features_minuend = 'buildings.shp'
in_features_subtrahend = 'bldg_extensions.shp'
out_feature_class = arcpy.CreateUniqueName('bldgs_without_extensions.shp')

# Run Difference3D
arcpy.ddd.Difference3D(in_features_minuend, in_features_subtrahend, out_feature_class)
```
**Toolset:** Area and Volume

**Tool:** Extrude Between

**Description:** The "Extrude Between" tool creates 3D features by extruding each input feature between two triangulated irregular network (TIN) datasets. It is typically used to generate volumetric representations of features that exist between two surfaces, such as geological layers or architectural elements.

**Parameters:**
- **in_tin1:** The first input TIN. Type: TIN Layer.
- **in_tin2:** The second input TIN. Type: TIN Layer.
- **in_feature_class:** The features that will be extruded between the TINs. Type: Feature Layer.
- **out_feature_class:** The output that will store the extruded features. Type: Feature Class.

**Derived Output:**
- **out_feature_class:** The output features that will be updated. Type: Feature Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set Local Variables
inTIN1 = "ceiling"
inTIN2 = "floor"
inPoly = "study_area.shp"

# Ensure output has a unique name
outMP = arcpy.CreateUniqueName("extrusion.shp")

# Execute ExtrudeBetween
arcpy.ddd.ExtrudeBetween(inTIN1, inTIN2, inPoly, outMP)
```
**Toolset:** Area and Volume

**Tool:** Minimum Bounding Volume

**Description:** The Minimum Bounding Volume tool creates multipatch features that represent the volume of space occupied by a set of 3D features. It is typically used to analyze and visualize the spatial extent of 3D data, such as determining the smallest volume that can enclose a group of 3D features.

**Parameters:**
- **in_features:** The LAS dataset or 3D features whose minimum bounding volume will be evaluated. Type: LAS Dataset Layer; Feature Layer.
- **z_value:** The source of z-values for the input data. Type: Field.
- **out_feature_class:** The feature class that will be produced. Type: Feature Class.
- **geometry_type (Optional):** Specifies the method to determine the geometry of the minimum bounding volume. Options include Convex hull, Sphere, Envelope, and Concave hull. Type: String.
- **group (Optional):** Specifies how the input features will be grouped; each group will be enclosed with one output multipatch. Options include None, All, and List. Type: String.
- **group_field (Optional):** The field or fields in the input features that will be used to group features when List is specified as group_option. Type: Field.
- **mbv_fields (Optional):** Specifies whether geometric attributes will be added to the output multipatch feature class. Options include NO_MBV_FIELDS and MBV_FIELDS. Type: Boolean.

**Derived Output:**
- **output_feature_class:** The output features that will be updated. Type: Feature Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Define input parameters
in_features = 'tree_canopy.shp'
z_value = 'Shape.Z'
out_feature_class = 'canopy_volume.shp'
geometry_type = 'CONCAVE_HULL'
group = 'List'
group_field = 'Season'
mbv_fields = 'MBV_FIELDS'

# Execute MinimumBoundingVolume
arcpy.ddd.MinimumBoundingVolume(
    in_features, z_value, out_feature_class, geometry_type, group, group_field, mbv_fields
)
```

Feel free to ask if you need more details on using this tool or have other questions about ArcGIS Pro!
```markdown
**Toolset:** Area and Volume

**Tool:** Polygon Volume

**Description:**  
The Polygon Volume tool calculates the volumetric and surface area between polygons of an input feature class and a TIN surface. It is typically used to determine the volume and surface area between a polygon of a constant height and a surface, which is useful in applications such as earthwork calculations and analyzing changes between surfaces.

**Parameters:**
- **Input TIN**: The input TIN. Type: TIN Layer.
- **Input Feature Class**: The input polygon feature class. Type: Feature Layer.
- **Height Field**: The name of the field containing polygon reference plane heights. Type: String.
- **Reference Plane (Optional)**: The keyword used to indicate whether volume and surface area are calculated ABOVE the reference plane height of the polygons, or BELOW. The default is BELOW. Type: String.
- **Volume Field (Optional)**: The name of the output field used to store the volume result. The default is Volume. Type: String.
- **Surface Area Field (Optional)**: The name of the output field used to store the surface area result. The default is SArea. Type: String.

**Derived Output:**
- **Output Feature Class**: The output features that will be updated. Type: Feature Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy
from arcpy import env

# Set environment settings
env.workspace = "C:/data"

# Set Local Variables
inSurface = "sample.gdb/featuredataset/terrain"
inPoly = "floodplain_100.shp"
zField = "Height"
refPlane = "BELOW"
volFld = "Volume"
sAreaFld = "SArea"

# Execute PolygonVolume
arcpy.ddd.PolygonVolume(inSurface, inPoly, zField, refPlane, volFld, sAreaFld)
```
**Toolset:** Area and Volume

**Tool:** Surface Difference

**Description:** The Surface Difference tool calculates the displacement between two surfaces to determine where one surface is above, below, or the same as the other surface. It is typically used to analyze changes in elevation or volume between two surfaces, such as in environmental studies or construction projects.

**Parameters:**
- **Input Surface:** The triangulated surface whose relative displacement is being evaluated from the reference surface.  
  *Type:* LAS Dataset Layer; Terrain Layer; TIN Layer.
- **Reference Surface:** The triangulated surface that will be used as the baseline for determining the relative displacement of the input surface.  
  *Type:* LAS Dataset Layer; Terrain Layer; TIN Layer.
- **Output Feature Class:** The output feature class containing contiguous triangles and triangle parts that have the same classification grouped into polygons. The volume enclosed by each region of difference is listed in the attribute table.  
  *Type:* Feature Class.
- **Analysis Resolution (Optional):** The resolution that will be used to generate the input surface. For a terrain dataset, this corresponds to its pyramid-level definitions, where the default of 0 represents full resolution.  
  *Type:* Double.
- **Reference Analysis Resolution (Optional):** The resolution that will be used to generate the reference surface. Similar to the Analysis Resolution for the input surface.  
  *Type:* Double.

**Derived Output:**
- **Output Feature Class:** Contains polygons representing regions where the input surface is above, below, or the same as the reference surface. The attribute table includes fields for volume, surface area, and a code indicating the spatial relationship.  
  *Type:* Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set Local Variables
inSurface = "flood_tin"
inReference = "elev_tin"

# Ensure output name is unique
outPoly = arcpy.CreateUniqueName("difference.shp")

# Execute SurfaceDifference
arcpy.ddd.SurfaceDifference(inSurface, inReference, outPoly)
```
**Toolset:** Area and Volume

**Tool:** Surface Volume

**Description:** The Surface Volume tool calculates the area and volume of the region between a surface and a reference plane. It is typically used for analyzing the volumetric space above or below a specified plane in relation to a surface, such as terrain or elevation models.

**Parameters:**
- **in_surface:** The raster, TIN, or terrain surface that will be processed. *Type: Mosaic Layer; Raster Layer; Terrain Layer; TIN Layer.*
- **out_text_file (Optional):** A comma-delimited ASCII text file containing the area and volume calculations. If the file already exists, the new results will be appended to the file. *Type: File.*
- **reference_plane (Optional):** The direction from the reference plane for which to calculate the results. Options are ABOVE or BELOW. *Type: String.*
- **base_z (Optional):** The Z value of the plane that will be used to calculate area and volume. *Type: Double.*
- **z_factor (Optional):** The factor by which z-values will be multiplied, typically used to convert z linear units to match x,y linear units. *Type: Double.*
- **pyramid_level_resolution (Optional):** The z-tolerance or window-size resolution of the terrain pyramid level that will be used. *Type: Double.*

**Derived Output:**
- **Output:** The tool does not specify derived outputs in the provided documentation.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set Local Variables
inSurface = "elevation_tin"

# Execute SurfaceVolume
result = arcpy.ddd.SurfaceVolume(
    in_surface=inSurface,
    out_text_file="surf_vol.txt",
    reference_plane="ABOVE",
    base_z=300,
    z_factor=3.24,
    pyramid_level_resolution=5
)

# Print the result messages
print(result.getMessages())
```
**Toolset:** Point Cloud

**Tool:** Colorize LAS

**Description:** The Colorize LAS tool applies colors and near-infrared values from orthographic imagery to LAS points. This tool is typically used to enhance the visual representation of point cloud data by superimposing true imagery onto LAS points, which aids in data classification, feature digitization, and 3D distance measurements.

**Parameters:**
- **Input LAS Dataset:** The LAS dataset to be colorized. Type: LAS Dataset Layer.
- **Input Raster:** The orthographic imagery used to apply colors to the LAS points. Type: Raster Layer.
- **RGB Bands:** Specifies the bands from the input raster that correspond to the red, green, and blue channels. Type: String.
- **Output LAS Dataset:** The location where the colorized LAS dataset will be stored. Type: LAS Dataset Layer.
- **Rearrange Points:** Specifies whether to rearrange the LAS points for optimized spatial operations. Type: Boolean.
- **Compute Statistics:** Specifies whether statistics will be computed for the LAS files. Type: Boolean.

**Derived Output:**
- **Colorized LAS Dataset:** The LAS dataset with applied color values. Type: LAS Dataset Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment
arcpy.env.workspace = 'C:/data'

# Define parameters
input_las_dataset = '2014_lidar_survey.lasd'
input_raster = '2014_CIR.tif'
rgb_bands = 'RED Band_1; GREEN Band_2; BLUE Band_3'
output_las_dataset = 'las/rgb'
rearrange_points = True
compute_statistics = True

# Execute Colorize LAS
arcpy.ddd.ColorizeLas(
    input_las_dataset,
    input_raster,
    rgb_bands,
    output_las_dataset,
    rearrange_points,
    compute_statistics
)
```
**Toolset:** Point Cloud

**Tool:** Extract LAS

**Description:** Extract LAS creates LAS files from point cloud data in a LAS dataset or point cloud scene layer. It is typically used to clip and filter point cloud data, rearranging the points to optimize spatial queries and improve performance in visualization and data processing.

**Parameters:**
- **Input LAS Dataset:** The input `.las` or `.zlas` files that will be projected. A LAS dataset can also be provided to process all of the `.las` and `.zlas` files it references. Type: LAS Dataset Layer.
- **Target Folder:** The existing folder where the output `.las` files will be written. Type: Folder.
- **Output Coordinate System:** The coordinate system of the output LAS format files. Type: Coordinate System.
- **Geographic Transformation (Optional):** This method can be used for converting data between two geographic coordinate systems or datums. Type: String.
- **Compression (Optional):** Specifies whether the output file will be written using the compressed ZLAS format or the uncompressed LAS format. Type: String.

**Derived Output:**
- **Output Folder:** The folder that the output LAS files will be written out to. Type: Folder.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define input and output parameters
input_las_dataset = "input.lasd"
target_folder = "C:/output"
output_coordinate_system = arcpy.SpatialReference(4326)  # WGS 1984
geographic_transformation = "WGS_1984_(ITRF00)_To_NAD_1983"
compression = "ZLAS"

# Execute Extract LAS
arcpy.management.ExtractLas(input_las_dataset, target_folder, output_coordinate_system, geographic_transformation, compression)
```

Feel free to ask if you need further details or have another topic in mind to discuss!
**Toolset:** Point Cloud

**Tool:** Extract Objects From Point Cloud

**Description:** Extracts distinct objects from a classified point cloud into point, polygon, or multipatch features. This tool is typically used to identify and extract features such as buildings or vegetation from a point cloud dataset, which can then be used for further analysis or visualization.

**Parameters:**
- **Input Integrated Mesh:** The integrated mesh I3S service or scene layer package that will be processed. Type: Scene Layer; File.
- **Input Point Cloud:** The LAS dataset, I3S point cloud, or point cloud scene layer package with classified points that will be used to extract features from the integrated mesh. Type: LAS Dataset Layer; Scene Layer; File.
- **Output Multipatch Features:** The output multipatch features that represent the objects detected from the integrated mesh. Type: Feature Class.
- **Class Codes To Extract:** The class code values from the point cloud that will be used to identify the objects in the integrated mesh. Each code will have a default group ID of the same value. Type: Value Table.
- **Point Distance Threshold:** The maximum distance between the centers of the subdivided mesh triangles and the points representing a given object. Type: Linear Unit.
- **Maximum Triangle Area (Optional):** The maximum area for subdividing mesh triangles to support cases where multiple objects may be present in a given triangle. Type: Linear Unit.

**Derived Output:**
- **Output Multipatch Features:** The output multipatch features that will contain the objects detected from the input point cloud. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data"

# Define the input parameters
input_mesh = "IntegratedMesh.i3s"
input_point_cloud = "ClassifiedPointCloud.lasd"
output_features = "ExtractedObjects.gdb/MultipatchFeatures"
class_codes = "1;2;3"  # Example class codes
point_distance_threshold = "10 Meters"
max_triangle_area = "50 Square Meters"

# Execute the tool
arcpy.ddd.ExtractObjectsFromPointCloud(
    input_mesh,
    input_point_cloud,
    output_features,
    class_codes,
    point_distance_threshold,
    max_triangle_area
)
```

Feel free to ask if you need further clarification or have additional questions about using this tool in ArcGIS Pro.
**Toolset:** Point Cloud

**Tool: Thin LAS**

**Description:**  
The Thin LAS tool is used to create new LAS files that contain a subset of LAS points from the input LAS dataset. This tool is typically used to reduce the density of point cloud data, which can help in optimizing performance for visualization and analysis by retaining only the necessary points.

**Parameters:**
- **Input LAS Dataset**: The LAS dataset that will be processed. Type: LAS Dataset Layer.
- **Target Folder**: The folder where the output LAS files will be stored. Type: Folder.
- **Thinning Dimension**: Determines the type of thinning, either 2D or 3D. Type: String.
- **XY Resolution**: The size of each side of the thinning tile along the x and y dimensions. Type: Linear Unit.
- **Z Resolution** (Optional): The size of each side of the thinning tile along the z dimension. Type: Linear Unit.
- **Point Selection Method**: Method used to select a LAS point in each analysis window. Options include Closest to mean, Minimum, and Maximum. Type: String.
- **Class Codes Weights**: Optional weights for class codes to influence point selection. Type: String.
- **Name Suffix**: Optional suffix for naming output LAS files. Type: String.
- **Out LAS Dataset** (Optional): The name of the output LAS dataset. Type: LAS Dataset.
- **Preserved Class Codes** (Optional): Class codes to preserve during thinning. Type: String.
- **Preserved Flags** (Optional): Flags to preserve during thinning. Type: String.
- **Preserved Returns** (Optional): Return types to preserve during thinning. Type: String.
- **Excluded Class Codes**: Class codes to exclude during thinning. Type: String.
- **Excluded Flags**: Flags to exclude during thinning. Type: String.
- **Excluded Returns**: Returns to exclude during thinning. Type: String.
- **Compression**: Specifies if the output .las file will be compressed. Type: Boolean.
- **Remove VLR**: Specifies whether to remove variable length records from the output LAS data. Type: Boolean.
- **Rearrange Points**: Indicates if LAS points will be stored in spatially organized clusters. Type: Boolean.
- **Compute Stats**: Specifies whether statistics will be computed for the .las files. Type: Boolean.

Derived Output:
- **Output Folder**: The folder containing the output LAS files. Type: Folder.

Example ArcPy code (include all the necessary imports and context to successfully run the code):
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Set local variables
in_las_dataset = 'photogrammetric_cloud.lasd'
target_folder = 'thinned'
thinning_dimension = '3D'
xy_resolution = '20 Centimeters'
z_resolution = '15 Centimeters'
point_selection_method = 'Z_AVERAGE'
excluded_flags = 'WITHHELD'
rearrange_points = 'REARRANGE_POINTS'

# Execute ThinLas
arcpy.ddd.ThinLas(
    in_las_dataset,
    target_folder,
    thinning_dimension,
    xy_resolution,
    z_resolution,
    point_selection_method,
    excluded_flags=excluded_flags,
    rearrange_points=rearrange_points
)
```
**Toolset:** Point Cloud

**Tool:** Tile LAS

**Description:** The Tile LAS tool creates a set of nonoverlapping LAS files by dividing the horizontal extents of the input LAS dataset into a regular grid. This tool is typically used to manage large LAS datasets by subdividing them into smaller, more manageable files, which can improve performance in visualization and data processing tasks.

**Parameters:**
- **Input LAS Dataset:** The input .las or .zlas files that will be tiled. Type: LAS Dataset.
- **Tile Width:** The width of each tile. This parameter is optional and is disabled when the tile_feature parameter is specified. Type: Linear Unit.
- **Tile Height:** The height of each tile. This parameter is optional and is disabled when the tile_feature parameter is specified. Type: Linear Unit.
- **Tile Origin:** The coordinates of the origin of the tiling grid. The default values are obtained from the lower left corner of the input LAS dataset. Type: Double.

**Derived Output:**
- **Out Folder:** The folder where the output LAS files will be written. Type: Folder.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Define input parameters
input_las_dataset = 'Denver_2'
output_folder = 'C:/output'
basename = '2014_'
output_las_dataset = 'Denver_2014.lasd'

# Execute TileLas
arcpy.ddd.TileLas(
    input_las_dataset,
    output_folder,
    basename=basename,
    out_las_dataset=output_las_dataset,
    las_version='1.4',
    point_format=6,
    compression='ZLAS Compression',
    las_options=['Rearrange points'],
    naming_method='ROW_COLUMN',
    file_size=300
)
```

Feel free to ask if you need more details on using the Tile LAS tool or any other ArcGIS Pro functionalities.
**Toolset:** Point Cloud

**Tool:** Change LAS Class Codes

**Description:** The "Change LAS Class Codes" tool is used to modify the classification codes for LAS files referenced by a LAS dataset. This tool reclassifies one set of classification codes into another, which is particularly useful for updating the classification of LAS files generated before the introduction of classification standards in the LAS 1.1 specification.

**Parameters:**
- **Input LAS Dataset:** The LAS dataset that will be processed. Type: LAS Dataset Layer.
- **Reclassification List:** A list of old and new classification codes to be applied. Type: List of values.
- **Compute Statistics (Optional):** Specifies whether statistics will be computed for the .las files referenced by the LAS dataset. Type: Boolean.

**Derived Output:**
- **Derived LAS Dataset:** The reclassified LAS dataset. Type: LAS Dataset Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = 'C:/data'

# Define the input LAS dataset and reclassification list
lasd = 'test.lasd'
reclassList = [[5, 2], [3, 1], [4, 6]]

# Execute the Change LAS Class Codes tool
arcpy.ddd.ChangeLasClassCodes(lasd, reclassList, 'COMPUTE_STATS')
```
**Toolset:** Point Cloud

**Tool:** Classify LAS Building

**Description:** The Classify LAS Building tool is used to classify building rooftop points in LAS format point cloud data, typically derived from aerial lidar. It identifies and assigns a class code to points that represent building rooftops, which is essential for creating accurate building models and further analysis.

**Parameters:**
- **Input LAS Dataset:** The LAS dataset that will be classified. Type: LAS Dataset Layer.
- **Minimum Rooftop Height (Optional):** The height from the ground that defines the lowest point from which rooftop points will be identified. Type: Linear Unit.
- **Minimum Area:** The smallest area of the building rooftop. Type: Areal Unit.
- **Compute statistics (Optional):** Specifies whether statistics will be computed for the .las files referenced by the LAS dataset. Type: Boolean.

**Derived Output:**
- **out_las_dataset:** The LAS dataset that is classified for building rooftops. Type: LAS Dataset Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = 'C:/data'

# Define the input LAS dataset
input_las_dataset = 'Highland.lasd'

# Execute the Classify LAS Building tool
arcpy.ddd.ClassifyLasBuilding(
    input_las_dataset,
    minHeight='9 feet',
    minArea='30 Square Feet',
    compute_stats=True
)
```
No information available.
**Toolset:** Point Cloud

**Tool:** Classify LAS Ground

**Description:**  
The Classify LAS Ground tool is used to automatically identify and classify ground points in lidar and photogrammetric point clouds. This tool is typically used to prepare data for further analysis, such as generating digital elevation models (DEMs) or refining classifications for features like buildings and vegetation.

**Parameters:**
- **Input LAS Dataset:** The LAS dataset that will be processed.  
  *Type:* LAS Dataset Layer.
- **Ground Detection Method:** Specifies the method used to detect ground points, with options like Standard, Conservative, and Aggressive.  
  *Type:* String.
- **Reuse Existing Ground:** Determines whether existing ground points should be reused or reclassified.  
  *Type:* Boolean.
- **Noise Handling:** Specifies how noise points are handled during classification.  
  *Type:* String.

**Derived Output:**
- **Output LAS Dataset:** The LAS dataset with classified ground points.  
  *Type:* LAS Dataset Layer.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data"

# Define the input LAS dataset
input_las_dataset = "Tuborg_Havn.lasd"

# Run the Classify LAS Ground tool
arcpy.ddd.ClassifyLasGround(
    input_las_dataset,
    ground_detection_method="Standard",
    reuse_existing_ground=True,
    noise_handling="Leave Alone"
)
```
No information available.
No information available.
No information available.
**Toolset:** Point Cloud

**Tool:** Convert LAS

**Description:**  
The Convert LAS tool is used to convert `.las`, `.zlas`, and `.laz` files between different LAS compression methods, file versions, and point record formats. It is typically used to ensure compatibility with various applications and optimize file storage and performance.

**Parameters:**
- **in_las**: The input LAS file to be converted. Type: LAS File.
- **out_las_dataset**: The LAS dataset that will reference the newly created LAS files. Type: LAS Dataset.
- **compression**: Specifies whether the output LAS file will be in a compressed format or the standard LAS format. Type: String.
- **define_coordinate_system**: Specifies how the coordinate system of each input file will be defined. Type: String.
- **in_coordinate_system**: The coordinate system that will be used to define the spatial reference of some or all input files. Type: Coordinate System.

**Derived Output:**
- **out_folder**: The folder containing the projected LAS files. Type: Folder.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = "C:/data"

# Convert LAS files
arcpy.conversion.ConvertLas(
    in_las='2014_survey.zlas',
    out_las_dataset='2014_unclassified_collection',
    compression='NO_COMPRESSION',
    define_coordinate_system='ALL_FILES',
    in_coordinate_system='WGS 1984'
)
```
**Toolset:** Point Cloud

**Tool: LAS Dataset To Raster**

**Description:**  
The LAS Dataset To Raster tool is used to create a raster from elevation, intensity, or RGB values stored in the lidar points referenced by a LAS dataset. It is typically used to generate digital terrain models (DTM) or digital surface models (DSM) from point cloud data.

**Parameters:**
- **Input LAS Dataset**: The LAS dataset that will be processed. Type: LAS Dataset Layer.
- **Output Raster**: The location and name of the output raster dataset. The output can be created in most writable raster formats, such as TIFF, CRF, or IMG. Type: Raster Dataset.
- **Cellsize**: The cell size of the output raster dataset. Type: Double.
- **Interpolation Method (Optional)**: Specifies the method that will be used to interpolate the output raster dataset from the point cloud. Options include:
  - **TRIANGULATION**: Triangulated irregular network (TIN) linear interpolation, suitable for irregularly distributed sparse points.
  - **NATURAL_NEIGHBOR**: Generates a smoother surface, more computationally intensive.
  - **IDW**: Inverse distance weighted average method, used for regularly distributed dense points.

**Derived Output:**
- **out_raster**: The output raster dataset. Type: Raster Dataset.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Set local variables
inLasDataset = 'baltimore.lasd'
outRaster = 'baltimore.tif'
interpolationType = 'ELEVATION'
interpolationMethod = 'TRIANGULATION LINEAR WINDOW_SIZE 10'
valueField = 'FLOAT'
cellSize = 10
zFactor = 3.28

# Execute LasDatasetToRaster
arcpy.conversion.LasDatasetToRaster(
    in_las_dataset=inLas,
    out_raster=outRaster,
    value_field=interpolationType,
    interpolation_type=interpolationMethod,
    cell_size=10,
    z_factor=3.28
)

# Print messages
print(arcpy.GetMessages())
```
**Toolset:** Point Cloud

**Tool:** Mesh To LAS

**Description:** Converts an integrated mesh into a LAS format point cloud. This tool is typically used to create point cloud data from an integrated mesh, which can then be used for further analysis or visualization in applications that support LAS format.

**Parameters:**
- **in_mesh:** The integrated mesh scene layer package or I3S service that will be exported to the LAS format point cloud. **Type:** Scene Layer; File.
- **target_folder:** The folder where the output LAS format files created from the integrated mesh will be stored. **Type:** Folder.
- **method (Optional):** Specifies the method used to create the point cloud from the integrated mesh. Options include `SAMPLE_POINTS_FROM_FACES` (default) and `USE_TRIANGLE_VERTICES`. **Type:** String.
- **maximum_triangle_area (Optional):** Controls the density of points by defining the maximum area of each triangle that contributes points. **Type:** Areal Unit.
- **extent (Optional):** The extent of the integrated mesh that will be exported to the point cloud. **Type:** Extent.
- **boundary (Optional):** The polygon features defining the area that will be clipped. **Type:** Feature Layer.
- **rearrange_points (Optional):** Specifies whether points will be rearranged to optimize performance. **Type:** Boolean.
- **compute_stats (Optional):** Specifies whether statistics will be computed for the LAS files. **Type:** Boolean.
- **out_las_dataset (Optional):** The output LAS dataset that will reference the LAS format files created by the conversion process. **Type:** LAS Dataset.
- **compression (Optional):** Specifies whether the output .las file will be in a compressed format or the standard LAS format. Options include `NO_COMPRESSION` (default) and `ZLAS`. **Type:** String.

**Derived Output:**
- **out_folder:** The output folder where the LAS format files created from the integrated mesh will be stored. **Type:** Folder.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = 'C:/data'

# Execute the MeshToLas tool
arcpy.conversion.MeshToLas(
    in_mesh='Redlands.slpk',
    target_folder='Redlands_Point_Cloud',
    method='SAMPLE_POINTS_FROM_FACES',
    maximum_triangle_area='0.5 Square Meters',
    compression='ZLAS'
)
```
No information available.
**Toolset:** Terrain Dataset

**Tool:** Add Feature Class To Terrain

**Description:** The "Add Feature Class To Terrain" tool is used to incorporate one or more feature classes into an existing terrain dataset. This tool is typically used to enhance terrain datasets by adding new data sources, such as mass points or breaklines, which contribute to the terrain's surface representation.

**Parameters:**
- **Input Terrain:** The terrain dataset to which feature classes will be added. Type: Terrain Layer.
- **Input Feature Class:** Identifies the features being added to the terrain. Each feature must reside in the same feature dataset as the terrain and have its role defined through properties such as height field and type. Type: String.
- **Height Field:** The field containing the feature's height information. Type: Any numeric field or geometry field for z-enabled features.
- **Type:** Surface feature type that defines how the features contribute to the terrain, such as mass points or breaklines. Type: String.
- **Group:** Defines the group of each contributing feature. Type: String.
- **Embed Name:** Name of the embedded feature class, applicable if the feature is being embedded. Type: String.
- **Embed Fields:** Specifies BLOB field attributes to be retained in the embedded feature class. Type: String.
- **Anchor:** Specifies whether the point feature class will be anchored through all terrain pyramid levels. Type: Boolean.

**Derived Output:**
- **Updated Terrain:** The updated terrain dataset after adding the feature classes. Type: Terrain Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment workspace
arcpy.env.workspace = "C:/data"

# Define the terrain dataset and feature class data
terrain = "sample.gdb/featuredataset/terrain"
terrain_data = ["terrain.gdb/terrainFDS/points2", "SHAPE", "masspoints", 2, 0, 10, "true", "false", "points_embed", "<None>", "false"]

# Execute AddFeatureClassToTerrain
arcpy.ddd.AddFeatureClassToTerrain(terrain, terrain_data)

# Optionally, build the terrain to update it
arcpy.ddd.BuildTerrain(terrain, "NO_UPDATE_EXTENT")
```
**Toolset:** Terrain Dataset

**Tool:** Add Terrain Pyramid Level

**Description:** The Add Terrain Pyramid Level tool is used to add one or more pyramid levels to an existing terrain dataset. This tool is typically used to define the z-tolerance or window size and reference scale for each pyramid level, enhancing the terrain dataset's scalability and performance at different map scales.

**Parameters:**
- **Input Terrain:** The terrain dataset that will be processed. Type: Terrain Layer.
- **Pyramid Type (Optional):** The pyramid type used by the terrain dataset. This parameter is not used in ArcGIS 9.3 and beyond, as its purpose is to ensure backward compatibility with scripts and models written using ArcGIS 9.2. Type: String.
- **Pyramid Levels Definition:** The z-tolerance or window size and its associated reference scale for each pyramid level being added to the terrain. Each pyramid level is entered as a space-delimited pair of the pyramid level resolution and reference scale (e.g., "20 24000" for a window size of 20 and reference scale of 1:24000). Type: String.

**Derived Output:**
- **Updated Input Terrain:** The updated terrain. Type: Terrain Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define the terrain dataset
inTerrain = "sample.gdb/featuredataset/terrain"

# Define pyramid levels as space-delimited pairs
pyramid_levels = ["20 24000", "1.5 10000"]

# Execute AddTerrainPyramidLevel
arcpy.ddd.AddTerrainPyramidLevel(inTerrain, "", pyramid_levels)

# Print completion message
arcpy.AddMessage("Terrain pyramid levels added successfully.")
```
**Toolset:** Terrain Dataset

**Tool:** Append Terrain Points

**Description:** The "Append Terrain Points" tool is used to add points or multipoints to a point feature that is referenced by a terrain dataset. This operation will invalidate the terrain dataset, necessitating a subsequent run of the "Build Terrain" tool to reprocess the terrain for analysis and display purposes. It is particularly useful for updating terrain datasets with new or additional point data.

**Parameters:**
- **Input Terrain:** The terrain dataset that will be processed. Type: Terrain Layer.
- **Input Terrain Data Source:** The feature class that contributes to the terrain dataset into which the points or multipoints will be added. Type: String.
- **Input Points:** The feature class of points or multipoints to add as an additional data source for the terrain dataset. Type: Feature Layer.
- **Area of Interest (Optional):** Specify a polygon feature class or extent values to define the area where point features will be added. This parameter is empty by default, which results in all the points from the input feature class being loaded to the terrain feature. Type: Extent; Feature Layer.

**Derived Output:**
- **Updated Input Terrain:** The updated terrain. Type: Terrain Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Set local variables
in_terrain = 'sample.gdb/featuredataset/terrain'
terrain_feature_class = 'existing_points'
in_point_features = 'new_points.shp'
polygon_features_or_extent = None  # Optional

# Execute AppendTerrainPoints
arcpy.ddd.AppendTerrainPoints(
    in_terrain,
    terrain_feature_class='existing_points',
    in_point_features='new_points.shp',
    polygon_features_or_extent=None
)
```
**Toolset:** Terrain Dataset

**Tool:** Build Terrain

**Description:** The Build Terrain tool is used to make a terrain dataset functional after it has been initially defined. It is typically used for analyzing and displaying terrain datasets, especially after modifications to the features or pyramid definitions within the dataset.

**Parameters:**
- **Input Terrain:** The terrain dataset that will be processed. *Type:* Terrain Layer.
- **Update Extent (Optional):** Recalculates the data extent of a window-size-based terrain dataset when the data area has been reduced through editing. *Type:* String.

**Derived Output:**
- **Updated Input Terrain:** The updated terrain. *Type:* Terrain Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Define the terrain dataset
terrain = 'test.gdb/featuredataset/terrain'

# Execute BuildTerrain
arcpy.ddd.BuildTerrain(terrain, "NO_UPDATE_EXTENT")

# Print messages
print(arcpy.GetMessages())
```

Feel free to ask more about terrain datasets or other tools in ArcGIS Pro.
**Toolset:** Terrain Dataset

**Tool:** Change Terrain Reference Scale

**Description:** This tool modifies the reference scale associated with a terrain pyramid level. It is typically used to optimize draw speed performance or adjust the densification of data points within a pyramid's display scale range.

**Parameters:**
- **Input Terrain:** The terrain dataset that will be processed. Type: Terrain Layer.
- **Old Reference Scale:** The reference scale of an existing pyramid level. Type: Long.
- **New Reference Scale:** The new reference scale for the pyramid level. Type: Long.

**Derived Output:**
- **Updated Input Terrain:** The updated terrain. Type: Terrain Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define variables
inTerrain = "terrain.gdb/terrainFDS/terrain1"
old_refscale = 1000
new_refscale = 2000

# Execute ChangeTerrainReferenceScale
arcpy.ddd.ChangeTerrainReferenceScale(inTerrain, old_refscale, new_refscale)
```

Feel free to ask more about terrain datasets or other ArcGIS Pro tools.
**Toolset:** Terrain Dataset

**Tool:** Change Terrain Resolution Bounds

**Description:** The "Change Terrain Resolution Bounds" tool modifies the pyramid levels at which a feature class is enforced within a terrain dataset. This is typically used to optimize display performance by adjusting the resolution bounds for terrain features.

**Parameters:**
- **in_terrain:** The terrain dataset that will be processed. Type: Terrain Layer.
- **feature_class:** The feature class referenced by the terrain that will have its pyramid-level resolutions modified. Type: String.
- **lower_pyramid_resolution (Optional):** The new lower pyramid-level resolution for the chosen feature class. Type: Double.
- **upper_pyramid_resolution (Optional):** The new upper pyramid-level resolution for the chosen feature class. Type: Double.
- **overview (Optional):** Specifies whether the feature class will contribute to the overview of the terrain dataset. Type: Boolean.

**Derived Output:**
- **derived_out_terrain:** The updated terrain. Type: Terrain Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define input parameters
in_terrain = "sample.gdb/featuredataset/terrain"
feature_class = "breaklines"
lower_pyramid_resolution = 2.5
upper_pyramid_resolution = 7.5

# Execute ChangeTerrainResolutionBounds
arcpy.ddd.ChangeTerrainResolutionBounds(
    in_terrain,
    feature_class,
    lower_pyramid_resolution,
    upper_pyramid_resolution
)
```
**Toolset:** Terrain Dataset

**Tool:** Create Terrain

**Description:**  
The Create Terrain tool is used to create a terrain dataset from various data sources such as TINs, lidar, and other survey data. It is particularly useful for managing large datasets and improving display performance and analysis speed by leveraging the scalability of terrain datasets.

**Parameters:**
- **Input Feature Dataset:** The feature dataset where the terrain dataset will be created. Type: Feature Dataset.
- **Output Terrain:** The name for the new terrain dataset. Type: String.
- **Average Point Spacing:** The average spacing of points used to build the terrain dataset. Type: Double.
- **Maximum Overview Size (Optional):** The upper limit of the number of measurement points sampled to create the overview. Type: Long.
- **Pyramid Type:** The method used to create and organize the terrain data, either Window Size or Z Tolerance. Type: String.
- **Window Size Method (Optional):** The method used if Window Size is chosen, default is Minimum Z. Type: String.
- **Secondary Thinning Method (Optional):** The method for secondary thinning, default is None. Type: String.
- **Secondary Thinning Threshold (Optional):** The threshold for secondary thinning, default is 1. Type: Double.

**Derived Output:**
- **Derived Output Terrain:** The newly created terrain dataset. Type: Terrain.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set local variables
tin = arcpy.GetParameterAsText(0)  # TIN used to create terrain
gdbLocation = arcpy.GetParameterAsText(1)  # Folder that will store terrain GDB
gdbName = arcpy.GetParameterAsText(2)  # Name of terrain GDB
fdName = arcpy.GetParameterAsText(3)  # Name of feature dataset
terrainName = arcpy.GetParameterAsText(4)  # Name of terrain

try:
    # Create the file gdb that will store the feature dataset
    arcpy.management.CreateFileGDB(gdbLocation, gdbName)
    gdb = '{0}/{1}'.format(gdbLocation, gdbName)
    
    # Obtain spatial reference from TIN
    SR = arcpy.Describe(tin).spatialReference
    
    # Create the feature dataset that will store the terrain
    arcpy.management.CreateFeatureDataset(gdb, fdName, SR)
    fd = '{0}/{1}'.format(gdb, fdName)
    
    # Create the terrain dataset
    arcpy.ddd.CreateTerrain(fd, terrainName, 10, 50000, "", "WINDOWSIZE", "ZMEAN", "NONE", 1)
    
    arcpy.AddMessage("Terrain dataset created successfully.")
except arcpy.ExecuteError:
    print(arcpy.GetMessages())
except Exception as err:
    print(err)
```
**Toolset: Terrain Dataset**

**Tool: Delete Terrain Points**

**Description:**  
The "Delete Terrain Points" tool is used to remove points within a specified area of interest from one or more features that participate in a terrain dataset. This is typically used to eliminate unwanted points, such as outliers, from a terrain dataset. It is important to note that deleting points from an embedded feature class will invalidate the terrain, necessitating the use of the Build Terrain tool afterward to rebuild the terrain.

**Parameters:**
- **Input Terrain**: The terrain dataset that will be processed.  
  *Type: Terrain Layer*.
- **Input Terrain Data Source**: One or more feature classes from which points will be removed.  
  Type: *String*.
- **Area of Interest**: Specifies the area from which points will be removed. A polygon feature class or an extent can be used. If extent values are desired, use an `arcpy.Extent` object.  
  Type: *Feature Layer; Extent*.

**Derived Output:**
- **Updated Input Terrain**: The updated terrain after points have been deleted.  
  *Type: Terrain Layer*.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set local variables
in_terrain = "sample.gdb/featuredataset/terrain"
data_source = "mass_pts_embed"
polygon_features_or_extent = "1379938 235633 1382756 237681"

# Execute DeleteTerrainPoints
arcpy.ddd.DeleteTerrainPoints(in_terrain, data_source, polygon_features_or_extent)
```
**Toolset: Terrain Dataset**

**Tool: Remove Feature Class From Terrain**

**Description:**  
The "Remove Feature Class From Terrain" tool is used to remove a reference to a feature class that is part of a terrain dataset. This tool is typically used when a feature class is no longer needed in the terrain dataset, and it will delete any embedded features that are referenced by the terrain dataset. If the removed features were referenced as a masspoints surface type, the terrain may need to be rebuilt using the Build Terrain tool.

**Parameters:**
- **Input Terrain**: The terrain dataset that will be processed. Type: *Terrain Layer*.
- **Input Feature Class**: The feature class to be removed. Type: *String*.

**Derived Output:**
- **Updated Input Terrain**: The updated terrain. Type: Terrain Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
# Import system modules
import arcpy
from arcpy import env

# Set environment settings
env.workspace = "C:/data"

# Set Local Variables
inTerrain = "sample.gdb/featuredataset/terrain"
remFC = "points_1995"

# Execute RemoveFeatureClassFromTerrain
arcpy.ddd.RemoveFeatureClassFromTerrain(inTerrain, remFC)
```
**Toolset:** Terrain Dataset

**Tool:** Remove Terrain Pyramid Level

**Description:** This tool is used to remove a specific pyramid level from a terrain dataset. It is typically used when a particular level of detail is no longer needed, except for level 0, which represents the full resolution pyramid and cannot be removed.

**Parameters:**
- **Input Terrain:** The terrain dataset that will be processed.  
  *Type:* Terrain Layer.
- **Pyramid Level Resolution:** The pyramid level to be removed, specified by its resolution.  
  *Type:* Double.

**Derived Output:**
- **Updated Input Terrain:** The updated terrain after the pyramid level has been removed.  
  *Type:* Terrain Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = "C:/data"

# Define the input terrain and the pyramid level resolution to remove
in_terrain = "sample.gdb/featuredataset/terrain"
pyramid_level_resolution = 10

# Execute the RemoveTerrainPyramidLevel tool
arcpy.ddd.RemoveTerrainPyramidLevel(in_terrain, pyramid_level_resolution)
```
**Toolset:** Terrain Dataset

**Tool:** Replace Terrain Points

**Description:** The Replace Terrain Points tool is used to replace points referenced by a terrain dataset with points from a specified feature class. This is typically used when updating or modifying the terrain dataset with new or corrected point data.

**Parameters:**
- **Input Terrain:** The terrain dataset that will be processed.  
  **Type:** Terrain Layer.
- **Input Terrain Data Source:** The name of the terrain point feature class that will have some or all of its points replaced.  
  **Type:** String.
- **Input Points:** The point or multipoint features that will replace the terrain point features.  
  **Type:** Feature Layer.
- **Area of Interest (Optional):** An optional area of interest can be used to define the extent of the area in which the terrain points would be replaced.  
  **Type:** Feature Layer; Extent.

**Derived Output:**
- **Updated Input Terrain:** The updated input terrain.  
  **Type:** Terrain Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set Local Variables
InTerrain = "sample.gdb/featuredataset/terrain"
TerrainFCl = "points_old"
InPoints = "sample.gdb/featuredataset/terrain/pts_new"

# Execute ReplaceTerrainPoints
arcpy.ddd.ReplaceTerrainPoints(InTerrain, TerrainFCl, InPoints)
```
**Toolset:** Terrain Dataset

**Tool:** Terrain To Points

**Description:** Converts a terrain dataset into a new point or multipoint feature class. This tool is typically used to extract point data from a terrain dataset for further analysis or visualization.

**Parameters:**
- **in_terrain:** The terrain dataset that will be processed. Type: Terrain Layer.
- **out_feature_class:** The feature class that will be produced. Type: Feature Class.
- **pyramid_level_resolution (Optional):** The z-tolerance or window-size resolution of the terrain pyramid level that will be used. The default is 0, or full resolution. Type: Double.
- **source_embedded_feature_class (Optional):** The name of the terrain dataset's embedded points to be exported. If specified, only these points will be written to the output. Otherwise, all points from all data sources in the terrain will be exported. Type: String.
- **out_geometry_type (Optional):** The geometry of the output feature class. Options are MULTIPOINT (default) or POINT. Type: String.

**Derived Output:**
- **out_feature_class:** The feature class that will be produced. Type: Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set Local Variables
terrain = "sample.gdb/featuredataset/terrain"
out_feature_class = arcpy.CreateUniqueName("terrain_points", "sample.gdb")
out_geometry_type = "POINT"

# Execute TerrainToPoints
arcpy.ddd.TerrainToPoints(
    in_terrain=terrain,
    out_feature_class=out_feature_class,
    pyramid_level_resolution=6,
    source_embedded_feature_class="<NONE>",
    out_geometry_type=out_geometry_type
)
```
**Toolset:** Terrain Dataset

**Tool:** Terrain To Raster

**Description:** The Terrain To Raster tool interpolates a raster using z-values from a terrain dataset. It is typically used to convert terrain datasets into raster formats for analysis and visualization purposes.

**Parameters:**
- **Input Terrain:** The terrain dataset that will be processed. Type: Terrain Layer.
- **Output Raster:** The location and name of the output raster. Type: Raster Dataset.
- **Data Type (Optional):** Specifies the type of numeric values stored in the output raster. Options include Floating Point (32-bit) and Integer. Type: String.
- **Method (Optional):** The interpolation method used to calculate cell values. Options include Linear and Natural Neighbors. Type: String.
- **Sampling Distance (Optional):** Defines the cell size of the output raster. Options include Observations and Cell Size. Type: String.
- **Pyramid Level Resolution (Optional):** The z-tolerance or window-size resolution of the terrain pyramid level used. Type: Double.
- **Sampling Value:** The value corresponding to the Sampling Distance for specifying the output raster's cell size. Type: Double.

**Derived Output:**
- **Output Raster:** The resulting raster dataset from the interpolation process. Type: Raster Dataset.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set local variables
terrain = "sample.gdb/featuredataset/terrain"
outRas = arcpy.CreateUniqueName("terrain_level.img")
bitType = "INT"
method = "LINEAR"
sampling = "CELLSIZE 10"
pyrLvl = 2.5

# Execute TerrainToRaster
arcpy.ddd.TerrainToRaster(terrain, outRas, bitType, method, sampling, pyrLvl)
```
**Toolset:** Terrain Dataset

**Tool:** Terrain To TIN

**Description:** Converts a terrain dataset into a triangulated irregular network (TIN) dataset. This tool is typically used to create a TIN surface from terrain data for detailed surface analysis and visualization.

**Parameters:**
- **Input Terrain:** The terrain dataset that will be processed. Type: Terrain Layer.
- **Output TIN:** The TIN dataset that will be generated. Type: TIN.
- **Pyramid Level Resolution (Optional):** The z-tolerance or window-size resolution of the terrain pyramid level that will be used. The default is 0, or full resolution. Type: Double.
- **Maximum Number of Nodes (Optional):** The maximum number of nodes permitted in the output TIN. The tool will return an error if the analysis extent and pyramid level would produce a TIN that exceeds this size. The default is 5 million. Type: Long.
- **Clip to Extent (Optional):** Specifies whether the resulting TIN will be clipped against the analysis extent. Type: Boolean.

**Derived Output:**
- **Output TIN:** The TIN dataset that will be generated. Type: TIN.

**Example ArcPy code:**
```python
import arcpy
from arcpy import env

# Set environment settings
env.workspace = "C:/data"

# Set Local Variables
inTerrain = "sample.gdb/featuredataset/terrain"
pyrRes = 6
maxNodes = 5000000
clipExtent = False

# Ensure output name is unique
outTIN = arcpy.CreateUniqueName("tin")

# Execute TerrainToTin
arcpy.ddd.TerrainToTin(inTerrain, outTIN, pyrRes, maxNodes, clipExtent)
```
**Toolset:** TIN Dataset

**Tool:** Create TIN

**Description:** The Create TIN tool in ArcGIS Pro is used to create a triangulated irregular network (TIN) dataset. This tool is typically used to model surfaces using measurements from point, line, and polygon features, which can include elevation data. It is essential for creating detailed surface models for analysis and visualization in both 2D and 3D environments.

**Parameters:**
- **Output TIN:** The TIN dataset that will be generated. Type: TIN.
- **Coordinate System (Optional):** The spatial reference of the output TIN. It is recommended to use a projected coordinate system to ensure accurate Delaunay triangulation. Type: Coordinate System.
- **Input Feature Class (Optional):** The input features and their related properties that define how they will be added to the TIN. Type: Input Features.
  - **Height Field:** The field from the input's attribute table that provides the elevation for its features. Type: Field.
  - **Tag Field:** A numeric attribute assigned to the TIN's data elements using values from an integer field in the input feature's attribute table. Type: Field.
  - **Type:** The input feature's role in defining the TIN surface, such as mass points or breaklines. Type: String.

**Derived Output:**
- **Output TIN:** The TIN dataset that is created. Type: TIN.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define local variables
out_tin = "C:/output/myTIN"
coordinate_system = arcpy.SpatialReference(4326)  # WGS 84
input_features = "C:/data/elevation_points.shp"
height_field = "Elevation"
tag_field = "LanduseCode"
feature_type = "masspoints"

# Execute CreateTin
arcpy.ddd.CreateTin(out_tin, coordinate_system, 
                    "{0} {1} {2}".format(input_features, height_field, feature_type), 
                    "Delaunay")
```
**Toolset:** TIN Dataset

**Tool: Copy TIN**

**Description:**  
The "Copy TIN" tool creates a duplicate of a triangulated irregular network (TIN) dataset. It is typically used to maintain an archival copy of a TIN dataset before it undergoes modifications. This tool is also useful for creating backward-compatible TIN datasets for use in older versions of ArcGIS.

**Parameters:**
- **Input TIN:** The TIN that will be copied.  
  *Type:* TIN Layer.
- **Output TIN:** The TIN dataset that will be generated. Type: TIN.
- **Version (Optional):** Specifies the version of the output TIN. Options include:
  - **Current:** Supports constrained Delaunay triangulation, enhanced spatial reference information, and storage of node source and edge tag values. The resulting TIN will not be backward compatible with versions of ArcGIS prior to 10.0. This is the default.
  - **Pre 10.0:** The TIN will be backward compatible with versions of ArcGIS prior to 10.0, which only supports conforming Delaunay triangulation.  
  *Type:* String.

**Derived Output:**
- **Output TIN:** The TIN dataset that will be generated. Type: TIN.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/TINs"

# Set local variables
in_tin = "elevation"
out_tin = "elevation_copy"
version = "CURRENT"  # or "PRE_10.0" for backward compatibility

# Execute Copy TIN
arcpy.ddd.CopyTin(in_tin, out_tin, version)
```
**Toolset:** TIN Dataset

**Tool:** Decimate TIN Nodes

**Description:** The Decimate TIN Nodes tool creates a triangulated irregular network (TIN) dataset using a subset of nodes from a source TIN. It is typically used to thin oversampled data, improving the drawing experience and performance.

**Parameters:**
- **Input TIN:** The TIN dataset that will be processed. Type: TIN Layer.
- **Output TIN:** The TIN dataset that will be generated. Type: TIN.
- **Decimation Method:** Specifies the thinning method used for selecting a subset of nodes from the input TIN. Options include:
  - *Z Tolerance* — Maintains vertical accuracy within the specified Z tolerance.
  - *Count* — Reduces nodes to a specified maximum number. Type: String.
- **Copy Breaklines (Optional):** Indicates whether breaklines from the input TIN are copied to the output. Type: Boolean.
- **Z Tolerance (Optional):** The maximum deviation from the source TIN's Z-value allowed in the output TIN. Type: Double.
- **Maximum Number of Nodes (Optional):** The maximum number of nodes that can be stored in the output TIN. Type: Long.

**Derived Output:**
- **Output TIN:** The TIN dataset that is generated after decimation. Type: TIN.

**Example ArcPy code:**
```python
import arcpy
from arcpy import env

# Set environment settings
env.workspace = "C:/data"

# Set Local Variables
inTin = "elevation"
method = "COUNT 5000"
copyBrk = "BREAKLINES"

# Ensure output name is unique
outTin = arcpy.CreateUniqueName("simple_elev")

# Execute DecimateTinNodes
arcpy.ddd.DecimateTinNodes(inTin, outTin, method, copyBrk)
```
**Toolset:** TIN Dataset

**Tool:** Delineate TIN Data Area

**Description:**  
The "Delineate TIN Data Area" tool is used to redefine the data area, or interpolation zone, of a triangulated irregular network (TIN) based on its triangle edge length. This tool is typically used to eliminate long connections between points in a TIN, which are not valid for accurate surface modeling.

**Parameters:**
- **Input TIN:** The TIN dataset generated from the Create TIN tool.  
  *Type: TIN Layer.*
- **Maximum Edge Length:** The maximum allowable length for triangle edges in the TIN. Connections between points are removed based on this parameter. For irregularly spaced points, a recommended value is two times the square root of the average point spacing.  
  *Type: Double.*
- **Method (Optional):** Specifies the method for classifying TIN triangles by edge length. Options include "PERIMETER_ONLY" and "ALL".  
  *Type: String.*

**Derived Output:**
- **Derived Output TIN:** The updated TIN with redefined data area.  
  *Type: TIN Layer.*

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Local variables
input_tin = "elevation"
max_edge_length = 10
method = "PERIMETER_ONLY"

# Execute DelineateTinDataArea
arcpy.ddd.DelineateTinDataArea(input_tin, max_edge_length, method)
```
**Toolset:** TIN Dataset

**Tool:** Edit TIN

**Description:** The Edit TIN tool is used to modify the surface of an existing triangulated irregular network (TIN) by loading data from one or more input features. This tool is typically used to update TIN surfaces with new data, such as changes in elevation or the addition of new features like roads or excavation sites.

**Parameters:**
- **Input TIN:** The TIN dataset that will be processed. Type: TIN Layer.
- **Surface Feature Definition:** The input features and their related properties that define how they will be added to the TIN. Type: Input Features.
  - **Height Field:** The field from the input's attribute table that provides the elevation for its features. Type: Field.
  - **Tag Field:** A numeric attribute assigned to the TIN's data elements using values from an integer field in the input feature's attribute table. Type: Field.
  - **Type:** The input feature's role in defining the TIN surface, such as mass points or breaklines. Type: String.
- **Constrained Delaunay (Optional):** Specifies the triangulation technique used along the breaklines of the TIN. Type: Boolean.

**Derived Output:**
- **Derived Output TIN:** The updated TIN. Type: TIN Layer.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data/LAS"

# Set Local Variables
copyTin = "elev_copy"
inFCs = [["Clip_Polygon.shp", "<None>", "<None>", "hardclip", False], 
         ["new_points.shp", "Shape", "<None>", "masspoints", True]]

# Execute EditTin
arcpy.ddd.EditTin(copyTin, inFCs, "Delaunay")
```
**Toolset:** TIN Dataset

**Tool:** LandXML To TIN

**Description:** This tool imports one or more triangulated irregular network (TIN) surfaces from a LandXML file to output Esri TINs. It is typically used for converting TIN data stored in LandXML format into a format that can be utilized within ArcGIS Pro for further analysis and visualization.

**Parameters:**
- **Input:** The input LandXML file.  
  *Type:* File.
- **Output TIN Folder:** The folder where the output TINs will be created.  
  *Type:* Folder.
- **Output TIN Base Name:** The basename of the resulting TIN. When several TINs are exported from the LandXML file, this name is used to define a unique name for each output TIN.  
  *Type:* String.
- **TINs to Import (Optional):** The one or more LandXML TIN surfaces that will be exported to an Esri TIN.  
  *Type:* String.

**Derived Output:**
- **Updated Output TIN Folder:** The folder containing the output TINs.  
  *Type:* Folder.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define local variables
in_landxml_path = "surfaces.xml"
out_tin_folder = "TINs"
tin_basename = "Madagascar_"
tinnames = "1;2"  # Optional: Specify TINs to import

# Execute LandXMLToTin
arcpy.ddd.LandXMLToTin(in_landxml_path, out_tin_folder, tin_basename, tinnames)
```
**Toolset:** TIN Dataset

**Tool:** TIN Domain

**Description:** The TIN Domain tool creates a line or polygon feature class representing the interpolation zone of a triangulated irregular network (TIN) dataset. It is typically used to generate a convex hull around a set of points, defining the boundary of the TIN's interpolation area.

**Parameters:**
- **Input TIN:** The TIN dataset that will be processed.  
  *Type:* TIN Layer.
- **Output Feature Class:** The feature class that will be produced.  
  *Type:* Feature Class.
- **Output Feature Class Type:** The geometry of the output feature class. Options include:
  - **Line:** The output will be a z-enabled line feature class.
  - **Polygon:** The output will be a z-enabled polygon feature class.  
  *Type:* String.

**Derived Output:**
- **Output Feature Class:** The feature class representing the interpolation zone of the TIN.  
  *Type:* Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace environment
arcpy.env.workspace = 'C:/data'

# Define the input TIN and output feature class
input_tin = 'tin'
output_feature_class = 'tin_domain.shp'

# Execute the TinDomain tool
arcpy.ddd.TinDomain(input_tin, output_feature_class, out_geometry_type='POLYGON')
```
**Toolset:** TIN Dataset

**Tool:** TIN Edge

**Description:** The TIN Edge tool creates 3D line features using the triangle edges of a triangulated irregular network (TIN) dataset. It is typically used to extract specific types of triangle edges, such as regular, soft, or hard edges, for further analysis or visualization.

**Parameters:**
- **Input TIN:** The TIN dataset that will be processed. *Type:* TIN Layer.
- **Output Feature Class:** The feature class that will be produced. *Type:* Feature Class.
- **Edge Type (Optional):** Specifies the type of triangle edge to export. Options include:
  - **Data Area:** Edges representing the interpolation zone. This is the default.
  - **Soft Breaklines:** Edges representing gradual breaks in slope.
  - **Hard Breaklines:** Edges representing distinct breaks in slope.
  - **Enforced Edges:** Edges not introduced by the TIN's triangulation.
  - **Regular Edges:** Edges created by the TIN's triangulation.
  - **Excluded Edges:** Edges excluded from the interpolation zone.
  - **All Edges:** All edges, including those excluded from the interpolation zone. *Type:* String.

**Derived Output:**
- **Output Feature Class:** The feature class containing the 3D line features created from the TIN edges. *Type:* Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = 'C:/data'

# Define input and output parameters
input_tin = 'tin'
output_feature_class = 'tin_edge.shp'
edge_type = 'ENFORCED'  # Optional parameter

# Execute the TinEdge tool
arcpy.ddd.TinEdge(input_tin, output_feature_class, edge_type)
```

Feel free to ask more about TIN datasets or explore other tools within ArcGIS Pro.
**Toolset:** TIN Dataset

**Tool:** TIN Line

**Description:** The TIN Line tool exports breaklines from a triangulated irregular network (TIN) dataset to a 3D line feature class. It is typically used to represent linear features such as ridges or streams within a TIN surface model.

**Parameters:**
- **Input TIN:** The TIN dataset that will be processed. Type: TIN Layer.
- **Output Feature Class:** The feature class that will be produced. Type: Feature Class.
- **Code Field (Optional):** The name of the field in the output feature class that defines the breakline type. The default field name is Code. Type: String.

**Derived Output:**
- **Output Feature Class:** The feature class containing the exported breaklines. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set the workspace
arcpy.env.workspace = 'C:/data'

# Define input and output parameters
input_tin = 'tin'
output_feature_class = 'tin_line.shp'
code_field = 'BreakType'  # Optional parameter

# Execute the TinLine tool
arcpy.ddd.TinLine(input_tin, output_feature_class, code_field)
```
**Toolset:** TIN Dataset

**Tool:** TIN Node

**Description:** The TIN Node tool exports the nodes of a triangulated irregular network (TIN) dataset to a point feature class. It is typically used to convert TIN nodes into a format that can be further analyzed or visualized as point features.

**Parameters:**
- **Input TIN:** The TIN dataset that will be processed. Type: TIN Layer.
- **Output Feature Class:** The feature class that will be produced. Type: Feature Class.
- **Spot Field (Optional):** The name of the elevation attribute field of the output feature class. If a name is given, the feature class will be 2D; otherwise, it will be 3D. No name is provided by default, which results in the creation of 3D point features. Type: String.
- **Tag Value Field (Optional):** The name of the field storing the tag attribute in the output feature class. By default, no tag value field is created. Type: String.

**Derived Output:**
- **Output Feature Class:** The feature class that will be produced, containing the exported nodes. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = 'C:/data'

# Define input TIN and output feature class
input_tin = 'tin'
output_feature_class = 'elevation_node.shp'

# Execute TinNode tool
arcpy.ddd.TinNode(input_tin, output_feature_class, spot_field='Elevation')
```
**Toolset:** TIN Dataset

**Tool:** TIN Polygon Tag

**Description:** The TIN Polygon Tag tool creates polygon features using tag values in a triangulated irregular network (TIN) dataset. It is typically used to assign integer values as tags to triangles within a TIN, which can represent user-defined criteria such as land cover codes.

**Parameters:**
- **in_tin:** The TIN dataset that will be processed. Type: TIN Layer.
- **out_feature_class:** The feature class that will be produced. Type: Feature Class.
- **tag_field (Optional):** The name of the field storing the tag attribute in the output feature class. The default field name is Tag_Value. Type: String.

**Derived Output:**
- **Output Feature Class:** The feature class containing the polygon features with tag values. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Define local variables
tag_field = "LanduseCode"

# Create list of TINs
TINList = arcpy.ListDatasets("*", "Tin")

# Verify the presence of TINs in the list
if TINList:
    # Iterate through the list of TINs
    for dataset in TINList:
        # Define the name of the output file
        Output = dataset + "_polytag.shp"
        
        # Execute TinPolygonTag
        arcpy.ddd.TinPolygonTag(dataset, Output, tag_field)
        print("Finished processing:", dataset)
else:
    print("No TIN files reside in", arcpy.env.workspace)
```

Feel free to ask more about TIN datasets or explore other tools within ArcGIS Pro.
No information available.
**Toolset:** TIN Dataset

**Tool:** TIN Triangle

**Description:** The TIN Triangle tool exports triangle faces from a TIN dataset to polygon features. It provides slope, aspect, and optional attributes such as hillshade and tag values for each triangle. This tool is typically used for analyzing and visualizing terrain surfaces in 3D.

**Parameters:**
- **in_tin:** The TIN dataset that will be processed. Type: TIN Layer.
- **out_feature_class:** The feature class that will be produced. Type: Feature Class.
- **units (Optional):** The units of measure to be used in calculating slope. Options are PERCENT (default) or DEGREE. Type: String.
- **z_factor (Optional):** The factor by which z-values will be multiplied, typically used to convert z linear units to match x,y linear units. Default is 1. Type: Double.
- **hillshade (Optional):** Specifies the azimuth and altitude angles of the light source for hillshade effect. Format: "HILLSHADE <azimuth>, <angle>". Type: String.
- **tag_field (Optional):** The field name in the output feature that will store the triangle tag value. Type: String.

**Derived Output:**
- **out_feature_class:** The feature class containing the exported triangle faces with attributes. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Execute TinTriangle tool
arcpy.ddd.TinTriangle(
    in_tin="tin",
    out_feature_class="tin_triangle.shp",
    units="DEGREE",
    z_factor=1,
    hillshade="HILLSHADE 310,45",
    tag_field="tag"
)
```
**Toolset:** Triangulated Surface

**Tool:** Surface Aspect

**Description:** The Surface Aspect tool creates polygon features that represent aspect measurements derived from a TIN, terrain, or LAS dataset surface. It is typically used to determine the compass direction that the downhill slope faces, which is useful in applications such as identifying suitable locations for ski runs or analyzing solar illumination.

**Parameters:**
- **Input Surface:** The input TIN, terrain, or LAS dataset from which aspect will be derived. Type: Dataset.
- **Output Feature Class:** The output polygon feature class that will store the aspect information. Type: Feature Class.

**Derived Output:**
- **Output Feature Class:** Contains polygon features representing the aspect of the input surface. Type: Feature Layer.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
# Import system modules
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# List all TINs in workspace
listTINs = arcpy.ListDatasets("", "TIN")

# Determine whether the list contains any TINs
if len(listTINs) > 0:
    for dataset in listTINs:
        print(dataset)
        # Set Local Variables
        aspect = arcpy.CreateUniqueName("Aspect.shp")
        
        # Execute SurfaceAspect
        arcpy.ddd.SurfaceAspect(dataset, aspect)
        print("Completed aspect calculation for " + dataset)
else:
    print("There are no TINs in the " + arcpy.env.workspace + " directory.")
```
**Toolset:** Triangulated Surface

**Tool:** Surface Contour

**Description:** The Surface Contour tool generates contour lines from a terrain, TIN, or LAS dataset surface. These contours are typically used for visualizing elevation changes and are essential in topographic mapping and analysis.

**Parameters:**
- **Input Surface:** The TIN, terrain, or LAS dataset surface to be processed.  
  *Type:* LAS Dataset Layer; Terrain Layer; TIN Layer.
- **Output Feature Class:** The feature class that will be produced, containing the contour lines.  
  *Type:* Feature Class.
- **Contour Interval:** The interval between the contours, determining the vertical distance between contour lines.  
  *Type:* Double.
- **Base Contour (Optional):** The starting Z value from which the contour interval is added or subtracted to delineate contours.  
  *Type:* Double.
- **Contour Field (Optional):** The field that stores the contour value associated with each line in the output feature class.  
  *Type:* String.
- **Contour Field Precision (Optional):** Specifies the precision of the contour field, with zero indicating an integer and numbers 1–9 indicating decimal places.  
  *Type:* Long.
- **Index Interval (Optional):** Adds an integer field to the attribute table to differentiate index contours from regular contours.  
  *Type:* Integer.

**Derived Output:**
- **Output Feature Class:** A 2D polyline feature class with contour heights assigned as attributes.  
  *Type:* Feature Class.

**Example ArcPy code (include all the necessary imports and context to successfully run the code):**
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set local variables
inSurface = "sample.gdb/featuredataset/terrain"
outContour = arcpy.CreateUniqueName("contour.shp")

# Execute SurfaceContour
arcpy.ddd.SurfaceContour(inSurface, outContour, 10)
```
```
Toolset: Triangulated Surface

Tool: Surface Slope

Description: The Surface Slope tool creates polygon features that represent ranges of slope values for triangulated surfaces such as TIN, terrain, or LAS datasets. It is used to analyze the steepness of terrain, which is crucial for applications like identifying areas prone to landslides or determining suitable locations for construction.

Parameters:
- in_surface: The TIN, terrain, or LAS dataset whose slope measurements will be written to the output polygon feature. Type: LAS Dataset Layer; Terrain.
- out_feature_class: The output feature class that will contain the slope polygons. Type: Feature Layer.
- units (Optional): Specifies the measurement units for the slope. Options include PERCENT (slope as a percentage) or DEGREE (default). Type: String.
- class_breaks_table (Optional): A table to group the output features. The first column indicates the break point, and the second provides the classification code. Type: Table.
- slope_field (Optional): The field containing slope values. Type: String.
- z_factor (Optional): The number by which z-values will be multiplied to convert z linear units to match x,y linear units. The default is 1. Type: Double.
- pyramid_level_resolution (Optional): The z-tolerance or window-size resolution of the terrain pyramid level that will be used. The default is 0, or full resolution. Type: Double.

Derived Output:
- output_feature_class: The updated input features. Type: Feature Layer.

Example ArcPy code (include all the necessary imports and context to successfully run the code):
```python
import arcpy

# Set environment settings
arcpy.env.workspace = "C:/data"

# Set local variables
in_surface = "sample.gdb/featuredataset/terrain"
out_feature_class = "C:/output/slope.shp"
units = "PERCENT"
z_factor = 1

# Execute Surface Slope
arcpy.ddd.SurfaceSlope(in_surface, out_feature_class, units, z_factor)
```
**Toolset:** Triangulated Surface

**Tool:** Locate Outliers

**Description:** The Locate Outliers tool identifies anomalous elevation measurements from terrain, TIN, or LAS datasets that exceed a defined range of elevation values or have slope characteristics inconsistent with the surrounding surface. It is typically used to find and analyze suspicious measurement points that may be in error.

**Parameters:**
- **in_surface:** The terrain, TIN, or LAS dataset that will be analyzed. Type: LAS Dataset Layer; Terrain Layer; TIN Layer.
- **out_feature_class:** The feature class that will be produced. Type: Feature Class.
- **apply_hard_limit (Optional):** Specifies use of absolute z minimum and maximum to find outliers. Type: Boolean.
- **absolute_z_min (Optional):** If hard limits are applied, any point with an elevation below this value will be considered an outlier. Default is 0. Type: Double.
- **absolute_z_max (Optional):** If hard limits are applied, any point with an elevation above this value will be considered an outlier. Default is 0. Type: Double.
- **apply_comparison_filter (Optional):** Specifies use of comparison parameters (Z Tolerance, Slope Tolerance, Exceed Tolerance Ratio) in assessing points. Type: Boolean.
- **z_tolerance (Optional):** Compares z-values of neighboring points if the comparison filter is applied. Default is 0. Type: Double.
- **slope_tolerance (Optional):** The threshold of slope variance between consecutive points used to identify outlier points. Default is 150. Type: Double.
- **exceed_tolerance_ratio (Optional):** Defines the criteria for determining each outlier point as a function of the ratio of points in its natural neighborhood that must exceed the specified comparison filters. Default is 0.5. Type: Double.
- **outlier_cap (Optional):** The maximum number of outlier points that can be written to the output. Default is 2,500. Type: Long.

**Derived Output:**
- **out_feature_class:** The feature class containing the identified outlier points. Type: Feature Class.

**Example ArcPy code:**
```python
import arcpy

# Set local variables
in_surface = "C:/data/terrain.tin"
out_feature_class = "C:/data/outliers.shp"
apply_hard_limit = "APPLY_HARD_LIMIT"
absolute_z_min = -15
absolute_z_max = 680
apply_comparison_filter = "APPLY_COMPARISON_FILTER"
z_tolerance = 0
slope_tolerance = 150
exceed_tolerance_ratio = 0.5
outlier_cap = 2500

# Execute Locate Outliers
arcpy.ddd.LocateOutliers(
    in_surface,
    out_feature_class,
    apply_hard_limit,
    absolute_z_min,
    absolute_z_max,
    apply_comparison_filter,
    z_tolerance,
    slope_tolerance,
    exceed_tolerance_ratio,
    outlier_cap
)
```

Feel free to ask if you need further clarification or have additional questions about using this tool in ArcGIS Pro.
