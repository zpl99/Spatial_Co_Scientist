# Name:        Interpreting Geo-analytical Questions as concept transformations
# Purpose:     Python script for identifying placenames, entities, and concepts in each geo-analytical question,
#              then extracting concept transformations from parser trees generated by a Antlr4 grammar-GenAnQu.g4.

import json
import re
import numpy
# [X] import nlp packages for placename and entities recognition
from spacy.lang.en import English
import en_core_web_sm
from spacy.matcher import PhraseMatcher
import nltk
import nltk.tokenize as nt
from allennlp.predictors.predictor import Predictor  # For using ELMo-based NER & Fine Grained NER
from word2number import w2n
# [X] import antlr4 grammar
from antlr4 import *
from Grammar.GeoAnQuLexer import GeoAnQuLexer
from Grammar.GeoAnQuParser import GeoAnQuParser
from antlr4.tree.Trees import Trees
# from antlr4.error.ErrorListener import ErrorListener


# [X]  customized a list of stopwords
class CustomEnglishDefaults(English.Defaults):
    # stop_words = set(["is", "are", "was", "were", "do", "does", "did", "have", "had", "the"])
    stop_words = {"do", "did", "does", "a", "an", "the", "their", 'his', 'her', 'my'}


class CustomEnglish(English):
    lang = "custom_en"
    Defaults = CustomEnglishDefaults


# [X] Raise exception for errors in parsing questions, such as token recognition error.
# class MyErrorListener(ErrorListener):
#     def __init__(self):
#         super(MyErrorListener, self).__init__()
#
#     def syntaxError(self, recognizer, offendingSymbol, line, column, msg, e):
#         raise Exception()
#
#     def reportAmbiguity(self, recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs):
#         raise Exception()
#
#     def reportAttemptingFullContext(self, recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs):
#         raise Exception()
#
#     def reportContextSensitivity(self, recognizer, dfa, startIndex, stopIndex, prediction, configs):
#         raise Exception()


class BracketMatch:
    def __init__(self, refstr, parent=None, start=-1, end=-1):
        self.parent = parent
        self.start = start
        self.end = end
        self.refstr = refstr
        self.nested_matches = []

    def __str__(self):
        cur_index = self.start + 1
        result = ""
        if self.start == -1 or self.end == -1:
            return ""
        for child_match in self.nested_matches:
            if child_match.start != -1 and child_match.end != -1:
                result += self.refstr[cur_index:child_match.start]
                cur_index = child_match.end + 1
            else:
                continue
        result += self.refstr[cur_index:self.end]
        return result


def is_left_inside(string, list):
    cur_list = []
    for l in list:
        if l.lower().strip().startswith(string):
            cur_list.append(l)
    return cur_list


# [X] Convert numeric words into digit numbers
# Input sentence(string): 'What is average network distance for three thousand and five people to
# two hundred and twelve closest primary schools'.
# Output sentence(string): 'What is average network distance for 3005 people to 212 closest primary schools'.
# except for 'five star hotels'
def word2num(sentence):
    try:
        if 'five star' not in sentence:
            cur_doc = nlp(sentence)
            numWords = ''
            numDig = ''
            for cur_i in range(0, len(cur_doc)):
                if cur_doc[cur_i].pos_ == 'NUM':
                    numWords = numWords + ' ' + cur_doc[cur_i].text
                    cur_i += 1
                elif cur_doc[cur_i].text == 'and' and cur_doc[cur_i - 1].pos_ == 'NUM':
                    numWords = numWords + ' and'
                    cur_i += 1
                elif numWords and not cur_doc[cur_i].pos_ == 'NUM':
                    numDig = w2n.word_to_num(numWords.strip())
                    # print(numWords)
                    # print(numDig)
                    sentence = sentence.replace(numWords.strip(), str(numDig))
                    numWords = ''
    except:
        return sentence

    return sentence


# [X] Identify Place names(e.g., ) in questions
# input string sentence:
# 'What buildings are within 1 minute of driving time from a fire station for
# Multifunctional Urban Area in Fort Worth in US
# output tuple:
# (['Multifunctional Urban Area', 'Fort Worth', 'US'],
# 'What buildings are within 1 minute of driving time from a fire station
# for each PlaceName0 in PlaceName1 in PlaceName3')
def place_ner(sentence):
    # predictorELMo = Predictor.from_path(
    #     "https://storage.googleapis.com/allennlp-public-models/ner-model-2020.02.10.tar.gz")
    pred = predictorELMo.predict(sentence)

    PlaceName = []
    loc = 0
    for i in range(0, len(pred['tags'])):
        if pred['tags'][i] == 'U-LOC' or pred['tags'][i] == 'U-PER':  # place name is a single word, such as Utrecht
            if not pred['words'][i] == 'PC4':
                PlaceName.append(pred['words'][i])
                sentence = sentence.replace(pred['words'][i], 'PlaceName' + str(loc))
                loc += 1
        elif pred['tags'][i] == 'B-LOC':  # When place name is a phrase, such as Happy Valley
            place = pred['words'][i]
        elif pred['tags'][i] == 'I-LOC' or pred['tags'][i] == 'L-LOC':
            place = place + ' ' + pred['words'][i]
            if i + 1 == len(pred['tags']):
                PlaceName.append(place)
                sentence = sentence.replace(place, 'PlaceName' + str(loc))
                place = ''
            elif pred['tags'][i + 1] == 'O':  # 'O' not a place name
                PlaceName.append(place)
                sentence = sentence.replace(place, 'PlaceName' + str(loc))
                loc += 1
                place = ''

    # Solve place name + place type, such as PlaceName0 area(PC4 area) -> PlaceName0(PC4 area)...
    cur_words = sentence.strip().split(' ')
    for i in range(0, len(cur_words)):
        if cur_words[i].startswith('PlaceName'):
            if i + 1 < len(cur_words):
                if cur_words[
                    i + 1] in pt_set:  # PlaceName0(Happy Valley) ski resort -> PlaceName0(Happy Valley ski resort)
                    cur_index = int(cur_words[i][9:])  # PlaceName0 -> 0
                    PlaceName[cur_index] = PlaceName[cur_index] + ' ' + cur_words[i + 1]
                    sentence = sentence.replace(' '.join(cur_words[i:i + 2]), cur_words[i])
                elif not len(is_left_inside(cur_words[i + 1],
                                            pt_set)) == 0:  # PlaceName0 ski resort(Happy Valley ski resort) -> PlaceName0
                    if i + 2 < len(cur_words):
                        cur_pt = cur_words[i + 1] + ' ' + cur_words[i + 2]
                        if cur_pt in is_left_inside(cur_words[i + 1], pt_set):
                            cur_index = int(cur_words[i][9:])  # PlaceName0 -> 0
                            PlaceName[cur_index] = PlaceName[cur_index] + ' ' + cur_pt
                            sentence = sentence.replace(' ' + cur_pt, '')
                        elif i + 3 < len(cur_words):
                            cur_pt = ' '.join(cur_words[i+1:i+4])
                            if cur_pt in is_left_inside(cur_words[i + 1], pt_set):
                                cur_index = int(cur_words[i][9:])
                                PlaceName[cur_index] = PlaceName[cur_index] + ' ' + cur_pt
                                sentence = sentence.replace(' ' + cur_pt, '')


    # print(sentence)
    print(PlaceName)
    return PlaceName, sentence


# [X] Identify Date, Time, Quantity, Percent
# input string sentence:
# 'What buildings are within 1 minute, 2 minutes and 3 minutes of driving time from 3 fire stations that are
# within 60 meters of rivers and located at areas that has slope larger than 10 percent for each PlaceName1 in
# PlaceName2 between 1990 and 2000'
# output tuple:
# ({'Time': [1 minute, 2 minutes, 3 minutes], 'Quantity': [60 meters],
# 'Percent': [larger than 10 percent], 'Date': [between 1990 and 2000]},
# 'What buildings are within ETime0, ETime1, and ETime2 of driving time from 3 fire stations that are within
# EQuantity0 of rivers and located at areas that has slope EPercent1 for each PlaceName0 in PlaceName1 EDate0')
def entity_ner(sentence):
    entities = []
    enti_dict = {}
    Date = []
    Time = []
    Quantity = []
    Percent = []

    cur_sen = ''
    if 'each' in sentence:  # {'Quantity': [each 50 square km]} -> {'Quantity': [50 square km]}
        cur_sen = sentence.replace(' each', '')
    else:
        cur_sen = sentence

    cur_doc = nlp(cur_sen)
    # entities = [(i.text, i.label_) for i in cur_doc.ents]
    # e.g., tuple entities = [(1 minute, 'TIME'), (between 1990 and 2000, 'DATE')]
    # remove compareR from entities. [('larger than 15 percent', 'PERCENT')] -> [('15 percent', 'PERCENT')]
    for i in cur_doc.ents:
        compBool = [word in i.text for word in compR]
        if True in compBool:
            tin = compBool.index(True)
            en_text = i.text.replace(compR[tin]+' ','')
            entities.append((en_text, i.label_))
        else:
            entities.append((i.text, i.label_))

    # print(sentence)
    # print(entities)

    D_loc = 0
    T_loc = 0
    Q_loc = 0
    P_loc = 0

    for i in range(0, len(entities)):
        if entities[i][1] == 'TIME':
            Time.append(entities[i][0])
            sentence = sentence.replace(entities[i][0], 'ETime' + str(T_loc))
            T_loc += 1
        elif entities[i][1] == 'QUANTITY':
            Quantity.append(entities[i][0])
            sentence = sentence.replace(entities[i][0], 'EQuantity' + str(Q_loc))
            Q_loc += 1
        elif entities[i][1] == 'PERCENT':
            Percent.append(entities[i][0])
            sentence = sentence.replace(entities[i][0], 'EPercent' + str(P_loc))
            P_loc += 1
        elif entities[i][1] == 'DATE' and not entities[i][0] == 'annual' and not entities[i][0] == 'monthly' \
                and not entities[i][0].startswith('PlaceName'):
            Date.append(entities[i][0])
            sentence = sentence.replace(entities[i][0], 'EDate' + str(D_loc))
            D_loc += 1

    cur_w = sentence.strip().split(' ')
    cur_quan = ''
    for w in cur_w:
        if w.startswith('meter') or w.startswith('millimeter'):
            cur_quan = cur_w[cur_w.index(w) - 1] + ' ' + w
            Quantity.append(cur_quan)
            sentence = sentence.replace(cur_quan, 'EQuantity' + str(Q_loc))
            Q_loc += 1
        elif w.isnumeric() and cur_w.index(w) < len(cur_w) - 3 and cur_w[cur_w.index(w) + 1] == 'per' and cur_w[
            cur_w.index(w) + 2] == 'square' and cur_w[cur_w.index(w) + 3].startswith(
            'kilometer'):  # 300 per square kilometer
            cur_quan = w + ' per square ' + cur_w[cur_w.index(w) + 3]
            Quantity.append(cur_quan)
            sentence = sentence.replace(cur_quan, 'EQuantity' + str(Q_loc))
            Q_loc += 1
        elif w == 'per' and cur_w.index(w) < len(cur_w) - 3 and cur_w[cur_w.index(w) - 1].isnumeric() and cur_w[
            cur_w.index(w) + 1].isnumeric():  # 500 per 1000000 people
            cur_quan = ' '.join(cur_w[cur_w.index(w) - 1: cur_w.index(w) + 3])
            Quantity.append(cur_quan)
            sentence = sentence.replace(cur_quan, 'EQuantity' + str(Q_loc))
            Q_loc += 1
        elif w.isnumeric() and cur_w[int(cur_w.index(w) - 1)] == 'over' and cur_w[
            int(cur_w.index(w) - 2)] in humanWords:
            Date.append('over ' + w)
            sentence = sentence.replace('over ' + w, 'EDate' + str(D_loc))
            D_loc += 1
        elif w.isnumeric() and cur_w[int(cur_w.index(w) - 1)] == 'than' and cur_w[
            int(cur_w.index(w) - 3)] in humanWords:
            cur_date = ' '.join(cur_w[cur_w.index(w) - 2: cur_w.index(w) + 1])
            Date.append(cur_date)
            sentence = sentence.replace(cur_date, 'EDate' + str(D_loc))
            D_loc += 1

    cur_words = sentence.strip().split(' ')
    if not len(Time) == 0:
        enti_dict['time'] = Time
    if not len(Quantity) == 0:
        for w in cur_words:
            if w.startswith('EQuantity'):
                i = cur_words.index(w)
                if cur_words[i - 1] == 'by' and cur_words[
                    i - 2].isnumeric():  # 2 by Quantity0(2 km) grid cell -> Quantity0 grid cell
                    Quantity[int(w[9])] = ' '.join(cur_words[i - 2:i]) + ' ' + Quantity[int(w[9])]
                    sentence = sentence.replace(' '.join(cur_words[i - 2:i]) + ' ' + w, w)
                    enti_dict['quantity'] = Quantity
                elif cur_words[i - 1] == 'from':  # from Quantity0(60 to 600 meters) -> Quantity0
                    Quantity[int(w[9])] = 'from ' + Quantity[int(w[9])]
                    sentence = sentence.replace('from ' + w, w)
                    enti_dict['quantity'] = Quantity
                elif cur_words[i - 1] == 'to' and cur_words[i - 2].isnumeric() and cur_words[
                    i - 3] == 'from':  # from 300 to Quantity0(900 meters) -> Quantity0
                    Quantity[int(w[9])] = ' '.join(cur_words[i - 3:i]) + ' ' + Quantity[int(w[9])]
                    sentence = sentence.replace(' '.join(cur_words[i - 3:i]) + ' ' + w, w)
                    enti_dict['quantity'] = Quantity
                elif cur_words[i - 1] == 'and' and cur_words[i - 2].isnumeric() and cur_words[
                    i - 3] == 'between':  # between 700 and Quantity0(2000 meters) -> Quantity0
                    Quantity[int(w[9])] = ' '.join(cur_words[i - 3:i]) + ' ' + Quantity[int(w[9])]
                    sentence = sentence.replace(' '.join(cur_words[i - 3:i]) + ' ' + w, w)
                    enti_dict['quantity'] = Quantity
                elif cur_words[i+1] == 'per' and cur_words[i+2] == 'second':
                    Quantity[int(w[9])] = Quantity[int(w[9])] + ' ' + ' '.join(cur_words[i+1:i+3])
                else:
                    enti_dict['quantity'] = Quantity
    if not len(Percent) == 0:
        enti_dict['percent'] = Percent
    if not len(Date) == 0:
        for w in cur_words:
            if w.startswith('EDate'):
                i = cur_words.index(w)
                if cur_words[i - 2].isnumeric() and cur_words[i - 1] == 'to':  # from 2000 to Date0 -> Date0
                    Date[int(w[5])] = ' '.join(cur_words[i - 3:i]) + ' ' + Date[int(w[5])]
                    sentence = sentence.replace(' '.join(cur_words[i - 3:i]) + ' ' + w, w)
                    enti_dict['date'] = Date
                elif i + 2 < len(cur_words) and cur_words[i + 2].isnumeric() and cur_words[
                    i + 1] == 'to':  # from Date0 to 1994
                    Date[int(w[5])] = cur_words[i - 1] + ' ' + Date[int(w[5])] + ' ' + ' '.join(cur_words[i + 1:i + 3])
                    sentence = sentence.replace(cur_words[i - 1] + ' ' + w + ' ' + ' '.join(cur_words[i + 1:i + 3]), w)
                    enti_dict['date'] = Date
                elif cur_words[i - 1] == 'from' and i + 1 == len(cur_words):  # from Date0 (1997 to 2004)
                    Date[int(w[5])] = 'from ' + Date[int(w[5])]
                    sentence = sentence.replace('from ' + w, w)
                    enti_dict['date'] = Date
                elif cur_words[i - 1] == 'from' and i + 1 < len(cur_words) and not cur_words[
                                                                                       i + 1] == 'to':  # from Date0 (1997 to 2004) in Utrecht
                    Date[int(w[5])] = 'from ' + Date[int(w[5])]
                    sentence = sentence.replace('from ' + w, w)
                    enti_dict['date'] = Date
                elif cur_words[i - 1] == 'from' and cur_words[i + 1] == 'to' and cur_words[i + 2].startswith(
                        'Date') and i + 2 < len(cur_words):  # from date0 to date1 -> date0
                    Date[int(w[5])] = 'from ' + Date[int(w[5])] + ' to ' + Date[int(cur_words[i + 2][5])]
                    Date.remove(Date[int(cur_words[i + 2][5])])
                    sentence = sentence.replace('from ' + w + ' to ' + cur_words[i + 2], w)
                    enti_dict['date'] = Date
                elif cur_words[i - 1] == 'over':  # over 65 years
                    Date[int(w[5])] = 'over ' + Date[int(w[5])]
                    sentence = sentence.replace('over ' + w, w)
                    enti_dict['date'] = Date
                else:
                    enti_dict['date'] = Date

    print(enti_dict)

    return enti_dict, sentence


# Read Core concepts.txt into a dictionary.
def load_ccdict(filePath):
    coreCon = {}
    text = []
    tag = []
    meaLevel = []  # measurement level
    with open(filePath, encoding="utf-8") as coreConcepts:
        for line in coreConcepts:
            cur = line.strip().split('\t')
            text.append(cur[0].lower())
            tag.append(cur[1].lower())
            if len(cur) == 3:
                meaLevel.append(cur[2].lower())
            else:
                meaLevel.append('NULL')
    coreCon['text'] = text
    coreCon['tag'] = tag
    coreCon['measureLevel'] = meaLevel

    return coreCon


# [X] Clean noun_phrases after noun chunks recognition, remove superlatives and comparatives, placenames, entities...
def noun_phrases_correct(noun_phrases_list):
    noun_phrases_CleanList = []

    for cur_noun in noun_phrases_list:
        if cur_noun in cn:
            noun_phrases_CleanList.append(cur_noun)
            # print('noun_phrases_CleanList:', noun_phrases_CleanList)
        else:
            cur_p = nt.sent_tokenize(cur_noun)
            tokenized_sen = [nt.word_tokenize(p) for p in cur_p]  # [['nearest', 'supermarket']]
            cur_pos = [nltk.pos_tag(cur_sen) for cur_sen in tokenized_sen][
                0]  # [('nearest', 'JJS'), ('supermarket', 'NN')]
            for e in cur_pos:
                pos.append(e)
            res = [sub[0] for sub in cur_pos if
                   ('JJS' in sub[1] and not sub[0] == 'west') or 'JJR' in sub[1] or 'RBS' in sub[1] or 'RBR' in sub[
                       1]]  # ['longest', 'more', 'most']

            if 'most' in res or 'more' in res :  # most intense, also remove intense; more than, also remove than
                mostIndex = [cur_pos.index(sub) for sub in cur_pos if sub[0] == 'most' or sub[0] == 'more']
                nextIndex = mostIndex[0] + 1
                if cur_pos[nextIndex][1] == 'JJ' or cur_pos[nextIndex][0] == 'than':
                    res.append(cur_pos[nextIndex][0])

            nounStr_Clean = [ele for ele in tokenized_sen[0] if ele not in res and ele.lower() not in removeWords
                             and not ele.startswith('placename') and not ele.startswith('edate') and not
                             ele.startswith('equantity') and not ele.startswith('etime') and not ele.startswith('epercent')
                             and not ele.startswith('outside') and not ele.isnumeric() and not ele == ',' or ele == '911' ]
            # print('nounStr_Clean:', nounStr_Clean)

            cur_noun_Clean = ' '.join(text for text in nounStr_Clean).strip()
            # print('cur_noun_Clean:', cur_noun_Clean)

            # [X] remove 'areas' in 'what areas', 'many' in 'how many'...'how many buildings'->'buildings'
            if cur_noun_Clean.startswith('areas'):
                cur_noun_Clean = cur_noun_Clean.replace('areas', '')
            # if cur_noun_Clean.startswith('area'):
            #     cur_noun_Clean = cur_noun_Clean.replace('area', '')
            if cur_noun_Clean.startswith('many'):
                cur_noun_Clean = cur_noun_Clean.replace('many', '')
            if cur_noun_Clean.startswith('much'):
                cur_noun_Clean = cur_noun_Clean.replace('much', '')

            if cur_noun_Clean:
                noun_phrases_CleanList.append(cur_noun_Clean.strip())

    return noun_phrases_CleanList


# [X] Identify Core concepts: field, object, event, network, contentAmount, coverageAmount, conProportion, proportion
# input string sentence: What is number of crime cases for each police district in PlaceName0 in Date0
# output string sentence: what is conamount0 era of event0 for each object0 in placename0 in date0
# output tuple: {'Object': ['police district'], 'Event': ['crime cases'], 'ConAmount': ['number']}
def core_concept_match(sentence):
    # [X] Noun chunks recognition, and remove Entity tags from detected noun chunks
    # cur_que = pre_cc_ner(sentence)
    cur_sen = sentence
    cur_doc = nlp(cur_sen)
    cur_matches = matcher(cur_doc)
    match_phrases = [cur_doc[start: end].text for mat_id, start, end in cur_matches]
    for cur_ph in match_phrases:
        cur_sen = cur_sen.replace(cur_ph + ' ', '')
    cur_doc2 = nlp(cur_sen)
    noun_list = [noun.text for noun in cur_doc2.noun_chunks]
    if not len(match_phrases) == 0:
        for cur_phr in match_phrases:
            noun_list.append(cur_phr)
    print('noun_list:', noun_list)

    noun_list_Clean = noun_phrases_correct(noun_list)
    print('noun_list_Clean:',noun_list_Clean)

    # [X] Identify core concepts from noun chunks
    coreConcept_dect = {}
    field = []
    object = []
    objectQuality = []
    event = []
    eventQuality = []
    network = []
    quality = []
    conAmount = []
    objConAmount = []
    eveConAmount = []
    covAmount = []
    conConPro = []
    objConobjConPro = []
    eveConobjConPro = []
    conCovPro = []
    objConobjCovPro = []
    eveConobjCovPro = []
    covPro = []
    proportion = []

    fie_loc = 0
    obj_loc = 0
    objQ_loc = 0
    eve_loc = 0
    eveQ_loc = 0
    net_loc = 0
    qua_loc = 0
    conA_loc = 0
    objConA_loc = 0
    eveConA_loc = 0
    covA_loc = 0
    objConobjConP_loc = 0
    eveconobjconP_loc = 0
    conconP_loc = 0
    objConobjCovP_loc = 0
    eveConobjCovP_loc = 0
    concovP_loc = 0
    covpro_loc = 0
    pro_loc = 0

    for cur_noun in noun_list_Clean:
        cur_w = cur_noun.split(' ')
        # print('cur_w:', cur_w)
        if cur_noun in coreCon_dict['text'] and not cur_noun == 'population':
            cur_index = coreCon_dict['text'].index(cur_noun)
            if coreCon_dict['tag'][cur_index] == 'field':
                field.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'field' + str(fie_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                fie_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'object':
                object.append(cur_noun)
                sentence = sentence.replace(cur_noun, 'object' + str(obj_loc))
                obj_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'object quality':
                objectQuality.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'objectquality' + str(objQ_loc) + ' ' +
                                            coreCon_dict['measureLevel'][
                                                cur_index])
                objQ_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'event':
                event.append(cur_noun)
                sentence = sentence.replace(cur_noun, 'event' + str(eve_loc))
                eve_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'event quality':
                eventQuality.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'eventquality' + str(eveQ_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                eveQ_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'network':
                cur_ns = cur_noun.split(' ')[0]
                cur_i = [x for x, y in enumerate(pos) if y[0] == cur_ns]
                if len(cur_i) >= 1 and (pos[cur_i[0] - 1][1] == 'JJS' or pos[cur_i[0] - 1][1] == 'RBS'):
                    cur_np = pos[cur_i[0] - 1][0] + ' ' + cur_noun
                    network.append(cur_np)
                    sentence = sentence.lower().replace(cur_np, 'network' + str(net_loc))
                    net_loc += 1
                else:
                    network.append(cur_noun)
                    sentence = sentence.lower().replace(cur_noun, 'network' + str(net_loc))
                    net_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'quality':
                quality.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'quality' + str(qua_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                qua_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'covamount':
                covAmount.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'covamount' + str(covA_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                covA_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'conamount':
                conAmount.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'conamount' + str(conA_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                conA_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'object conamount':
                objConAmount.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'objconamount' + str(objConA_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                objConA_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'event conamount':
                eveConAmount.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'eveconamount' + str(eveConA_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                eveConA_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'objconobjconpro':
                objConobjConPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'objconobjconpro' + str(conconP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                objConobjConP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'eveconobjconpro':
                eveConobjConPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'eveconobjconpro' + str(conconP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                eveconobjconP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'conconpro':
                conConPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'conconpro' + str(conconP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                conconP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'objconobjcovpro':
                objConobjCovPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'objconobjcovpro' + str(concovP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                objConobjCovP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'eveconobjcovpro':
                eveConobjCovPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'eveconobjcovpro' + str(concovP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                eveConobjCovP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'concovpro':
                conCovPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'concovpro' + str(concovP_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                concovP_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'covpro':
                covPro.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'covpro' + str(covpro_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                covpro_loc += 1
            elif coreCon_dict['tag'][cur_index] == 'proportion':
                proportion.append(cur_noun)
                sentence = sentence.replace(cur_noun,
                                            'proportion' + str(pro_loc) + ' ' + coreCon_dict['measureLevel'][
                                                cur_index])
                pro_loc += 1
        elif cur_w[0] == 'average' or cur_w[0] == 'median' or cur_w[0] == 'total':  # average Euclidean distance
            cur_r = ' '.join(cur_w[1:])  # 'Euclidean' 'distance' -> 'Euclidean distance'
            if cur_r in coreCon_dict['text']:
                cur_in = coreCon_dict['text'].index(cur_r)
                if coreCon_dict['tag'][cur_in] == 'field':
                    field.append(cur_r)
                    sentence = sentence.replace(cur_r,
                                                'field' + str(fie_loc) + ' ' + coreCon_dict['measureLevel'][cur_in])
                    fie_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'object':
                    object.append(cur_r)
                    sentence = sentence.replace(cur_r, 'object' + str(obj_loc))
                    obj_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'object quality':
                    objectQuality.append(cur_r)
                    sentence = sentence.replace(cur_r,
                                                'objectquality' + str(objQ_loc) + ' ' + coreCon_dict['measureLevel'][
                                                    cur_in])
                    objQ_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'event':
                    event.append(cur_r)
                    sentence = sentence.replace(cur_r, 'event' + str(eve_loc))
                    eve_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'event quality':
                    eventQuality.append(cur_r)
                    sentence = sentence.replace(cur_r,
                                                'eventquality' + str(eveQ_loc) + ' ' + coreCon_dict['measureLevel'][
                                                    cur_in])
                    eveQ_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'network':
                    network.append(cur_r)
                    sentence = sentence.lower().replace(cur_r, 'network' + str(net_loc))
                    net_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'quality':
                    quality.append(cur_r)
                    sentence = sentence.replace(cur_r,
                                                'quality' + str(qua_loc) + ' ' + coreCon_dict['measureLevel'][cur_in])
                    qua_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'covamount':
                    covAmount.append(cur_r)
                    sentence = sentence.replace(cur_r, 'covamount' + str(covA_loc) + ' ' + coreCon_dict['measureLevel'][
                        cur_in])
                    covA_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'conamount':
                    conAmount.append(cur_r)
                    sentence = sentence.replace(cur_r, 'conamount' + str(conA_loc) + ' ' + coreCon_dict['measureLevel'][
                        cur_in])
                    conA_loc += 1
                elif coreCon_dict['tag'][cur_in] == 'object conamount':
                    objConAmount.append(cur_r)
                    sentence = sentence.replace(cur_r,
                                                'objconamount' + str(objConA_loc) + ' ' + coreCon_dict['measureLevel'][
                                                    cur_in])
                    objConA_loc += 1
        # elif cur_w[len(cur_w) - 1] == 'count' or cur_w[len(cur_w) - 1] == 'counts' or cur_w[
        #     len(cur_w) - 1] == 'totals' or cur_w[len(cur_w) - 1] == 'total':  # house totals -> Object ConAmount
        #     conAmount.append(cur_w[len(cur_w) - 1])
        #     sentence = sentence.replace(cur_w[len(cur_w) - 1], 'conamount' + str(conA_loc) + ' era')
        #     conA_loc += 1
        #     cur_r = ' '.join(cur_w[0:len(cur_w) - 1])
        #     if cur_r in coreCon_dict['text']:
        #         cur_in = coreCon_dict['text'].index(cur_r)
        #         if coreCon_dict['tag'][cur_in] == 'object':
        #             object.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'object' + str(obj_loc))
        #             obj_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'event':
        #             event.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'event' + str(eve_loc))
        #             eve_loc += 1
        # elif cur_w[len(cur_w) - 1] == 'density':  # household density, tree density
        #     covPro.append('density')
        #     sentence = sentence.replace('density', 'covpro' + str(covpro_loc) + ' ira')
        #     covpro_loc += 1
        #     cur_r = ' '.join(cur_w[0:len(cur_w) - 1])
        #     if cur_r in coreCon_dict['text']:
        #         cur_in = coreCon_dict['text'].index(cur_r)
        #         if coreCon_dict['tag'][cur_in] == 'object':
        #             object.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'object' + str(obj_loc))
        #             obj_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'event':
        #             event.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'event' + str(eve_loc))
        #             eve_loc += 1
        # elif cur_w[len(cur_w) - 2:len(cur_w)] == ['mortality', 'rate']:
        #     ConConPro.append('mortality rate')
        #     sentence = sentence.replace('mortality rate', 'objconobjconpro' + str(conconP_loc) + ' ira')
        #     conconP_loc += 1
        #     cur_r = ' '.join(cur_w[0:len(cur_w) - 2])
        #     if cur_r in coreCon_dict['text']:
        #         cur_in = coreCon_dict['text'].index(cur_r)
        #         if coreCon_dict['tag'][cur_in] == 'object':
        #             Object.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'object' + str(obj_loc))
        #             obj_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'event':
        #             Event.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'event' + str(eve_loc))
        #             eve_loc += 1
        # elif cur_w[len(cur_w) - 1] == 'rate':
        #     ConConPro.append('rate')
        #     sentence = sentence.replace('rate', 'conconpro' + str(conconP_loc) + ' ira')
        #     conconP_loc += 1
        #     cur_r = ' '.join(cur_w[0:len(cur_w) - 1])
        #     if cur_r in coreCon_dict['text']:
        #         cur_in = coreCon_dict['text'].index(cur_r)
        #         if coreCon_dict['tag'][cur_in] == 'object':
        #             Object.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'object' + str(obj_loc))
        #             obj_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'object quality':
        #             ObjectQuality.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'objectquality' + str(objQ_loc) + ' ' + coreCon_dict['measureLevel'][cur_in])
        #             objQ_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'event':
        #             Event.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'event' + str(eve_loc))
        #             eve_loc += 1
        #         elif coreCon_dict['tag'][cur_in] == 'event quality':
        #             EventQuality.append(cur_r)
        #             sentence = sentence.replace(cur_r, 'eventquality' + str(eveQ_loc) + ' ' + coreCon_dict['measureLevel'][cur_in])

    if 'population' in sentence:
        objConAmount.append('population')
        sentence = sentence.replace('population', 'objconamount' + str(objConA_loc) + ' ' + 'era')
        objConA_loc += 1

    # [X] 'local road' is network in 'What is the potential accessibility by local road for each 2 by 2 km grid cell
    # in Finland'; 'roads' is object in 'Which roads are intersected with forest areas in UK'
    for cur_noun in noun_list_Clean:
        if cur_noun in networkSet:
            if 'network' in sentence or 'access' in cur_sen or 'connectivity' in cur_sen:
                network.append(cur_noun)
                sentence = sentence.lower().replace(cur_noun, 'network' + str(net_loc))
                net_loc += 1
            else:
                object.append(cur_noun)
                sentence = sentence.replace(cur_noun, 'object' + str(obj_loc))
                obj_loc += 1

    # cur_words = sentence.split(' ')
    # for w in cur_words:  # has 4 object -> has 4 objconAmount
    #     ind = cur_words.index(w)
    #     if w.startswith('object') and not w.startswith('objectquality') and 'network0' not in cur_words and (
    #             cur_words[ind - 2] in amsign or cur_words[ind - 1] in amsign) and not cur_words[ind - 1] == 'from':
    #         objConAmount.append(object[int(w[-1])])
    #         sentence = sentence.replace(w, 'objconamount' + str(len(objConAmount) - 1) + ' era')
    #     elif w.startswith('event') and not w.startswith('eventquality') and 'network0' not in cur_words and (
    #             cur_words[ind - 2] in amsign or cur_words[ind - 1] in amsign) and not cur_words[ind - 1] == 'from':
    #         eveConAmount.append(event[int(w[-1])])
    #         sentence = sentence.replace(w, 'eveconamount' + str(len(eveConAmount) - 1) + ' era')

    if not field == []:
        coreConcept_dect['field'] = field
    if not object == []:
        coreConcept_dect['object'] = object
    if not objectQuality == []:
        coreConcept_dect['objectquality'] = objectQuality
    if not event == []:
        coreConcept_dect['event'] = event
    if not eventQuality == []:
        coreConcept_dect['eventquality'] = eventQuality
    if not network == []:
        coreConcept_dect['network'] = network
    if not quality == []:
        coreConcept_dect['quality'] = quality
    if not conAmount == []:
        coreConcept_dect['conamount'] = conAmount
    if not len(objConAmount) == 0:
        coreConcept_dect['objconamount'] = objConAmount
    if not len(eveConAmount) == 0:
        coreConcept_dect['eveconamount'] = eveConAmount
    if not covAmount == []:
        coreConcept_dect['covamount'] = covAmount
    if not conConPro == []:
        coreConcept_dect['conconpro'] = conConPro
    if not objConobjConPro == []:
        coreConcept_dect['objconobjconpro'] = objConobjConPro
    if not eveConobjConPro == []:
        coreConcept_dect['eveconobjconpro'] = eveConobjConPro
    if not conCovPro == []:
        coreConcept_dect['concovpro'] = conCovPro
    if not objConobjCovPro == []:
        coreConcept_dect['objconobjcovpro'] = objConobjCovPro
    if not eveConobjCovPro == []:
        coreConcept_dect['eveconobjcovpro'] = eveConobjCovPro
    if not covPro == []:
        coreConcept_dect['covpro'] = covPro
    if not proportion == []:
        coreConcept_dect['proportion'] = proportion

    print(coreConcept_dect)
    print(sentence)

    return coreConcept_dect, sentence.lower()


# [X] Extract parser rules(tags) and text from parserTreeString
def get_text(cur_treeStr):
    nodetextDic = {}
    root = BracketMatch(cur_treeStr)
    cur_match = root
    for i in range(len(cur_treeStr)):
        if '(' == cur_treeStr[i]:
            new_match = BracketMatch(cur_treeStr, cur_match, i)
            cur_match.nested_matches.append(new_match)
            cur_match = new_match
        elif ')' == cur_treeStr[i]:
            cur_match.end = i
            cur_match = cur_match.parent
        else:
            continue
    # Here we built the set of matches, now we must print them
    nodes_list = root.nested_matches
    tag = []
    # So we conduct a BFS to visit and print each match...
    while nodes_list != []:
        node = nodes_list.pop(0)
        nodes_list.extend(node.nested_matches)
        nodeStr = str(node).strip()
        nodetextDic.setdefault('tag', []).append(nodeStr.split()[0])
        nodetextDic.setdefault('text', []).append(' '.join(nodeStr.split()[1:][0:len(nodeStr.split()[1:])]))

    return nodetextDic


# [X]Extract core concept from texts and tags of the parse tree
# Input: {'tag': ['condition', 'boolR', 'extremaR', 'coreC', 'coreC', 'coreC'], 'text': ['of to', 'has', 'highest',
# 'proportion 0 ira', 'object 1', 'objconamount 0 count']}
# Output: {'tag': ['coreC', 'coreC', 'coreC'], 'text': ['proportion 0 ira', 'object 1', 'objconamount 0 count']}
def core_concept_extract(TreeDict):
    cur_TD = {}
    keep_set = {'coreC', 'networkC', 'location', 'allocation', 'conAm', 'boolField', 'distField', 'serviceObj', 'aggre'} # 'extremaR', 'compareR'
    tag_in = [i for i, x in enumerate(TreeDict['tag']) if not x in keep_set]
    cur_TD['tag'] = [TreeDict['tag'][i] for i in range(0, len(TreeDict['tag'])) if i not in tag_in]
    cur_TD['text'] = [TreeDict['text'][i] for i in range(0, len(TreeDict['text'])) if i not in tag_in]

    return cur_TD


# [X]Write core concepts in the questions into the designed structure
# Input dictionary: {'tag': ['origin', 'destination', 'networkC', 'serviceObj', 'boolField'],
# 'text': [['object 1', 'hexagonal grids with diameter of 2000 meters'], 'object 0', 'network 0', 'from to', '']}
# Output[0]: [{'type': ['object'], 'id': '0', 'keyword': 'centroid'}, {...}, ...]
# Output[1]:{'tag': ['origin', 'destination', 'networkC', 'serviceObj', 'boolField'],
# 'text': [['object 1', 'hexagonal grids with diameter of equantity 1'], 'object 0', 'network 0', 'from to', ''],
# 'id': [['0', '1'], '2', '3', '4']}
def write_type(coreDict): #, core_index
    global result
    global core_id
    corety = []
    csign = 0

    for cur_tag in coreDict['tag']:
        if cur_tag in gen_coreC or cur_tag == 'location' or cur_tag == 'allocation':
            coreType = {}
            coreType['type'] = [cur_tag]
            coreType['id'] = str(core_id)
            coreType['keyword'] = ''
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'conAm':
            coreType = {}
            coreType['type'] = ['conamount']
            coreType['id'] = str(core_id)
            coreType['keyword'] = ''
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'grid' or cur_tag == 'distanceBand' or cur_tag == 'aggre':
            coreType = {}
            coreType['type'] = [cur_tag]
            coreType['id'] = str(core_id)
            coreType['keyword'] = coreDict['text'][coreDict['tag'].index(cur_tag)]
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'networkC':
            # read network keywords
            coreType = {}
            nts = coreDict['text'][coreDict['tag'].index('networkC')].split(' ')
            coreType['type'] = [nts[0]]
            coreType['id'] = str(core_id)
            coreType['keyword'] = result[nts[0]][int(nts[1])]  # e.g., driving time, network distance
            corety.append(coreType)
            coreDict.setdefault('id', []).append(str(core_id))
            core_id += 1
        elif cur_tag == 'coreC':
            if csign == 1:
                continue
            else:
                clocs = [x for x, y in enumerate(coreDict['tag']) if y == cur_tag]
                # if len(clocs) == 2 and any('conamount' in e for e in coreDict['text']):
                #     conAi = [x for x,y in enumerate(coreDict['text']) if y.startswith('conamount')]
                #     conAts = coreDict['text'][conAi[0]].split(' ')
                #     conA_Rei = [x for x in clocs if not x in conAi]
                #     conA_Reits = coreDict['text'][conA_Rei[0]].split(' ')
                #     coreType = {}
                #     if 'event' in conA_Reits:
                #         coreType['type'] = ['eveconamount']  # number of event -> eveconamount
                #         coreDict['text'] = ['eveconamount']
                #     elif 'object' in conA_Reits:
                #         coreType['type'] = ['objconamount']  # number of object -> objconamount
                #         coreDict['text'] = ['objconamount']
                #     coreType['id'] = str(core_index)
                #     coreType['keyword'] = 'number of ' + result[conA_Reits[0]][int(conA_Reits[1])]
                #     coreType['measureLevel'] = conAts[2]
                #     corety.append(coreType)
                #     coreDict['tag'] = ['coreC']
                #     coreDict.setdefault('id', []).append(str(core_index))
                #     core_index += 1
                # else:
                for cloc in clocs:
                    coreType = {}
                    cts = coreDict['text'][cloc].split(' ')
                    if len(cts) == 2:  # object 0
                        coreType['type'] = [cts[0]]
                        coreType['id'] = str(core_id)
                        coreType['keyword'] = result[cts[0]][int(cts[1])]
                        corety.append(coreType)
                        coreDict.setdefault('id', []).append(str(core_id))
                        core_id += 1
                    elif len(cts) == 3:  # # eveconobjconpro 0 ira
                        coreType['type'] = [cts[0]]
                        coreType['id'] = str(core_id)
                        coreType['keyword'] = result[cts[0]][int(cts[1])]
                        coreType['measureLevel'] = cts[2]
                        corety.append(coreType)
                        coreDict.setdefault('id', []).append(str(core_id))
                        core_id += 1
                csign += 1
        elif cur_tag == 'destination':
            des_id = []
            for d in coreDict['text'][coreDict['tag'].index(cur_tag)]:
                coreType = {}
                dtext = d.split(' ')
                coreType['type'] = [dtext[0]]
                coreType['id'] = str(core_id)
                coreType['keyword'] = result[dtext[0]][int(dtext[1])]
                corety.append(coreType)
                des_id.append(str(core_id))
                core_id += 1
            coreDict.setdefault('id', []).append(des_id)
        elif cur_tag == 'origin':
            ori_id = []
            for o in coreDict['text'][coreDict['tag'].index(cur_tag)]:
                coreType = {}
                if 'grid' in o:
                    coreType['type'] = ['grid']
                    coreType['id'] = str(core_id)
                    coreType['keyword'] = o
                    corety.append(coreType)
                    ori_id.append(str(core_id))
                    core_id += 1
                else:
                    otext = o.split(' ')
                    coreType['type'] = [otext[0]]
                    coreType['id'] = str(core_id)
                    coreType['keyword'] = result[otext[0]][int(otext[1])]
                    corety.append(coreType)
                    ori_id.append(str(core_id))
                    core_id += 1
            coreDict.setdefault('id', []).append(ori_id)

    if 'networkC' in coreDict['tag'] and 'coreC' not in coreDict['tag'] and not [i for i, d in enumerate(corety) if 'placename' in d['type']]:
        coreType = {}
        # add road as object or network for serviceObj, network analysis
        coreType['type'] = ['network', 'object']
        coreType['id'] = str(core_id)
        coreType['keyword'] = 'road data'  # e.g., driving time, network distance
        corety.append(coreType)
        coreDict['tag'].insert(coreDict['tag'].index('networkC'), 'roadData')
        coreDict['text'].insert(coreDict['tag'].index('roadData'), '')
        coreDict['id'].insert(coreDict['tag'].index('roadData'), str(core_id))
        core_id += 1
    if ('serviceObj' in coreDict['tag'] and not'networkC' in coreDict['tag']) and 'coreC' not in coreDict['tag'] and not [i for i, d in enumerate(corety) if 'placename' in d['type']]:
        coreType = {}
        # add road as object or network for serviceObj, network analysis
        coreType['type'] = ['network', 'object']
        coreType['id'] = str(core_id)
        coreType['keyword'] = 'road data'  # e.g., driving time, network distance
        corety.append(coreType)
        coreDict['tag'].insert(coreDict['tag'].index('serviceObj'), 'roadData')
        coreDict['text'].insert(coreDict['tag'].index('roadData'), '')
        coreDict['id'].insert(coreDict['tag'].index('roadData'), str(core_id))
        core_id += 1

    return corety, coreDict


# [X] Generate parser tree of question by the GeoAnQu grammar and extract core concept transformations
def geo_parser(sentence):

    global result
    global core_id

    ques_incorrect = ''

    coreConTrans = {}  # final cctrans output
    coreTypes = {}

    input = InputStream(sentence)  # [X]sentence =  'What areas are with slope larger than 10 in Spain'
    lexer = GeoAnQuLexer(input)  # get lexer rule
    # lexer.removeErrorListeners()
    # lexer.addErrorListener(MyErrorListener())
    stream = CommonTokenStream(lexer)  # token stream to tokens
    # stream.fill()  # Get all tokens from lexer until EOF
    parser = GeoAnQuParser(stream)
    # parser.addErrorListener(MyErrorListener())
    try:
        tree = parser.start()  # [X] get parsed tree of the sentence
        treeStr = Trees.toStringTree(tree, None, parser)  # Print out a whole tree in LISP form
        quesTextDic = get_text(treeStr)

        sequence = [ele for ele in quesTextDic['tag'] if ele in que_stru]
        sequence.reverse()
        print(sequence)

        if 'condition' in sequence:
            conCores = []
            con_count = treeStr.count('condition')
            for cur_i in range(0, con_count):
                con_treeStr = Trees.toStringTree(tree.condition(cur_i), None, parser)
                conTextDic = get_text(con_treeStr)
                conCore = core_concept_extract(conTextDic)
                if 'destination' in conTextDic['tag']:
                    if 'serviceObj' in conTextDic['tag']:
                        destination = tree.condition(cur_i).serviceObj().destination()
                        dest_childCount = destination.getChildCount()
                        des_list = []
                        for d_i in range(0, dest_childCount):
                            dest_text = destination.getChild(d_i).getText()
                            if 'object' in dest_text or 'event' in dest_text:
                                dest_text = dest_text[:-1] + ' ' + dest_text[-1]
                                des_list.append(dest_text)
                            elif 'placename' in dest_text:
                                dest_text = dest_text[:-1] + ' ' + dest_text[-1]
                                des_list.append(dest_text)
                        des_list.reverse()
                        conCore['tag'].append('destination')
                        conCore['text'].append(des_list)
                if 'origin' in conTextDic['tag']:  # 'centriods of object/grid' or 'object' or 'grid'
                    if 'serviceObj' in conTextDic['tag']:
                        origin = tree.condition(cur_i).serviceObj().origin()
                        ori_childCount = origin.getChildCount()
                        ori_list = []
                        for o_i in range(0, ori_childCount):
                            ori_text = origin.getChild(o_i).getText()
                            if 'object' in ori_text or 'event' in ori_text :
                                ori_text = ori_text[:-1] + ' ' + ori_text[-1]
                                ori_list.append(ori_text)
                            elif 'grid' in ori_text:
                                if 'equantity' in ori_text:
                                    ein = ori_text.index('equantity') + 9
                                    ori_text = ori_text.replace('equantity' + ori_text[ein], result['quantity'][int(ori_text[ein])] + ' ')
                                if 'of' in ori_text:
                                    ori_text = ori_text.replace('of', 'of ')
                                if 'with' in ori_text:
                                    ori_text = ori_text.replace('with', ' with ')
                                ori_list.append(ori_text.strip())
                                # ori_list in forward order, e.g, [object0, grid], object = centroid
                            elif 'placename' in ori_text:
                                ori_text = ori_text[:-1] + ' ' + ori_text[-1]
                                ori_list.append(ori_text.strip())
                        ori_list.reverse()
                        conCore['tag'].append('origin')
                        conCore['text'].append(ori_list)
                        # conCore {'tag': ['boolField', 'serviceObj', 'networkC', 'destination', 'origin'],
                        # 'text': ['', 'from to', 'network 0', 'object 0 ', ['..grids with diameter of equantity1']}
                if 'grid' in conTextDic['tag'] and 'origin' not in conTextDic['tag'] and 'destination' not in conTextDic['tag']:
                    cgrid_text = tree.condition(cur_i).grid().getText()
                    if 'equantity' in cgrid_text:
                        ein = cgrid_text.index('equantity') + 9
                        cgrid_text = cgrid_text.replace('equantity' + cgrid_text[ein], result['quantity'][int(cgrid_text[ein])] + ' ')
                    conCore['tag'].append('grid')
                    conCore['text'].append(cgrid_text)
                # if 'densityNei' in conTextDic['tag']:
                #     denN_in = conTextDic['tag'].index('densityNei')
                #     denN_text = conTextDic['text'][denN_in+1] + ' ' + conTextDic['text'][denN_in]
                #     conCore['tag'].append('density Neighbor')
                #     conCore['text'].append(denN_text)
                conCore['tag'].reverse()
                conCore['text'].reverse()
                conCores.insert(0, conCore)

        if 'measure' in sequence:
            mea_treeStr = Trees.toStringTree(tree.measure(), None, parser)
            meaTextDic = get_text(mea_treeStr)
            meaCore = core_concept_extract(meaTextDic)
            if 'destination' in meaTextDic['tag']:
                destination = tree.measure().destination(0)
                dest_childCount = destination.getChildCount()  # 'closest object0', childcount = 2
                des_list = []
                for d_i in range(0, dest_childCount):
                    dest_text = destination.getChild(d_i).getText()
                    if 'object' in dest_text or 'event' in dest_text:
                        dest_text = dest_text[:-1] + ' ' + dest_text[-1]
                        des_list.append(dest_text)
                    elif 'placename' in dest_text:
                        dest_text = dest_text[:-1] + ' ' + dest_text[-1]
                        des_list.append(dest_text.strip())
                des_list.reverse()
                meaCore['tag'].append('destination')
                meaCore['text'].append(des_list)
            if 'origin' in meaTextDic['tag']:  # 'centriods of object/grid' or 'object' or 'grid'
                origin = tree.measure().origin(0)
                ori_childCount = origin.getChildCount()
                ori_list = []
                for o_i in range(0, ori_childCount):
                    ori_text = origin.getChild(o_i).getText()
                    if 'object' in ori_text or 'event' in ori_text:
                        ori_text = ori_text[:-1] + ' ' + ori_text[-1]
                        ori_list.append(ori_text)
                    elif 'grid' in ori_text:
                        if 'equantity' in ori_text:
                            ein = ori_text.index('equantity') + 9
                            ori_text = ori_text.replace('equantity' + ori_text[ein], result['quantity'][int(ori_text[ein])] + ' ')
                        if 'of' in ori_text:
                            ori_text = ori_text.replace('of', 'of ')
                        if 'with' in ori_text:
                            ori_text = ori_text.replace('with', ' with ')
                        ori_list.append(ori_text.strip())
                        # ori_list in forward order, e.g, [object0, grid], object = centroid
                    elif 'placename' in ori_text:
                        ori_text = ori_text[:-1] + ' ' + ori_text[-1]
                        ori_list.append(ori_text.strip())
                ori_list.reverse()
                meaCore['tag'].append('origin')
                meaCore['text'].append(ori_list)
            meaCore['tag'].reverse()
            meaCore['text'].reverse()

        if 'measure1' in sequence:
            mea1_treeStr = Trees.toStringTree(tree.measure1(), None, parser)
            mea1TreeDic = get_text(mea1_treeStr)
            mea1Core = core_concept_extract(mea1TreeDic)

        if 'subcon' in sequence:
            subcon_treeStr = Trees.toStringTree(tree.subcon(), None, parser)
            subconTextDic = get_text(subcon_treeStr)
            subconCore = core_concept_extract(subconTextDic)
            subconCore['tag'].reverse()
            subconCore['text'].reverse()

        if 'support' in sequence:
            sup_treeStr = Trees.toStringTree(tree.support(), None, parser)
            supTextDic = get_text(sup_treeStr)
            supCore = core_concept_extract(supTextDic)
            if 'grid' in supTextDic['tag']:
                grid_text = tree.support().grid().getText()
                if 'equantity' in grid_text:
                    ein = grid_text.index('equantity') + 9
                    grid_text = grid_text.replace('equantity' + grid_text[ein], result['quantity'][int(grid_text[ein])] + ' ')
                supCore['tag'].append('grid')
                supCore['text'].append(grid_text)
            if 'distBand' in supTextDic['tag']:
                distBand_text = tree.support().distBand().getText()
                if 'equantity' in distBand_text:
                    eins = [m.start() for m in re.finditer('equantity', distBand_text)]
                    e = 9
                    for ein in eins:
                        distBand_text = distBand_text.replace('equantity'+ distBand_text[ein+e], ' equantity ' + distBand_text[ein+e] + ' ')
                        e = e + 3
                    dBts = distBand_text.split(' ')
                    eqins = [x for x, y in enumerate(dBts) if y == 'equantity']
                    qlocs = []
                    for eqin in eqins:
                        qlocs.append(dBts[eqin+1])
                    for qloc in qlocs:
                        distBand_text = distBand_text.replace('equantity '+ distBand_text[distBand_text.index('equantity')+10], result['quantity'][int(qloc)])
                supCore['tag'].append('distanceBand')
                supCore['text'].append(distBand_text.strip())
            supCore['tag'].reverse()
            supCore['text'].reverse()

        for seq in sequence:
            if seq == 'measure':
                meaTypes = write_type(meaCore)
                coreConTrans.setdefault('types', []).extend(meaTypes[0]) # type info in the final results
                coreTypes.setdefault('funcRole', []).append(seq)
                coreTypes.setdefault('types', []).append(meaTypes[1])
            elif seq == 'measure1':
                mea1Types = write_type(mea1Core)
                coreConTrans.setdefault('types', []).extend(mea1Types[0])
                coreTypes.setdefault('funcRole', []).append(seq)
                coreTypes.setdefault('types', []).append(mea1Types[1])
            elif seq == 'condition':
                conTypes = write_type(conCores[0])
                coreConTrans.setdefault('types', []).extend(conTypes[0])
                coreTypes.setdefault('funcRole', []).append(seq)
                coreTypes.setdefault('types', []).append(conTypes[1])
                conCores.pop(0)
            elif seq == 'subcon':
                subconTypes = write_type(subconCore)
                coreConTrans.setdefault('types', []).extend(subconTypes[0])
                coreTypes.setdefault('funcRole', []).append(seq)
                coreTypes.setdefault('types', []).append(subconTypes[1])
            elif seq == 'support':
                supTypes = write_type(supCore)
                coreConTrans.setdefault('types', []).extend(supTypes[0])
                coreTypes.setdefault('funcRole', []).append(seq)
                coreTypes.setdefault('types', []).append(supTypes[1])

        ext_count = treeStr.count('extent')
        if ext_count:
            for cur_i in range(0, ext_count):
                ext_treeStr = Trees.toStringTree(tree.extent()[cur_i], None, parser)
                extTextDic = get_text(ext_treeStr)
                extsp = extTextDic['text'][0].split(' ')
                coreConTrans.setdefault('extent', []).append(result['placename'][int(extsp[1])])
            coreTypes.setdefault('funcRole', []).append('extent')
            coreTypes.setdefault('types', []).append(coreConTrans['extent'])

        tem_count = treeStr.count('temEx')
        if tem_count:
            for cur_t in range(0, tem_count):
                tem_treeStr = Trees.toStringTree(tree.temEx(cur_t), None, parser)
                temTextDic = get_text(tem_treeStr)
                temsp = temTextDic['text'][0].split(' ')
                coreConTrans.setdefault('temporalEx', []).append(result['date'][int(temsp[1])])
            coreTypes.setdefault('funcRole', []).append('temEx')
            coreTypes.setdefault('types', []).append(coreConTrans['temporalEx'])

        print('coreTypes:', coreTypes)
        print('coreConTrans:', coreConTrans)

    except:
        ques_incorrect = sentence

    return treeStr, coreTypes, coreConTrans, ques_incorrect


# [X] Generate core concept transformations within condition, measure...
# Input TypeDict = {'tag': ['coreC', 'distField', 'boolField'], 'text': ['object 1', 'from', ''], 'id': ['0', '1', '2']}
# Output
def write_trans_within(TypeDict):
    transwithin = []
    coreC_sign = 0
    # wsign = '_w'

    for tt in TypeDict['tag']:
        if tt == 'distField' or tt == 'allocation' or tt == 'conAm':
            if TypeDict['tag'].index(tt) - 1 >= 0:
                trans = {}
                trans['before'] = [TypeDict['id'][TypeDict['tag'].index(tt) - 1]]
                trans['after'] = [TypeDict['id'][TypeDict['tag'].index(tt)]]
                transwithin.append(trans)
        elif tt == 'location' and 'allocation' not in TypeDict['tag']:
            trans = {}
            trans['before'] = [TypeDict['id'][TypeDict['tag'].index(tt) - 1]]
            trans['after'] = [TypeDict['id'][TypeDict['tag'].index(tt)]]
            transwithin.append(trans)
        elif tt == 'serviceObj':
            s_in = TypeDict['tag'].index(tt)
            trans = {}
            if s_in - 3 >= 0 and TypeDict['tag'][s_in - 3] == 'destination':
                if s_in - 4 >= 0 and TypeDict['tag'][
                    s_in - 4] == 'origin':  # ['origin', 'destination', 'roadData', 'networkC', 'serviceObj']
                    if len(TypeDict['id'][
                               s_in - 4]) == 2:  # [['grid', 'centroid'], 'destination', 'roadData', 'networkC', 'serviceObj']
                        trans['before'] = [TypeDict['id'][s_in - 4][0]]
                        trans['after'] = [TypeDict['id'][s_in - 4][1]]
                        transwithin.append(trans)
                    # origin: TypeDict['id'][s_in - 4], destination: TypeDict['id'][s_in - 3], roadData:TypeDict['id'][s_in - 2]
                    # networkC is not used here.
                    trans = {}
                    trans['before'] = [TypeDict['id'][s_in - 4][-1], TypeDict['id'][s_in - 3][-1], TypeDict['id'][s_in - 2]]
                    trans['after'] = [TypeDict['id'][s_in]]
                    transwithin.append(trans)
                elif s_in - 4 < 0 or not TypeDict['tag'][
                                             s_in - 4] == 'origin':  # ['destination', 'roadData', 'networkC', 'serviceObj']
                    trans['before'] = [TypeDict['id'][s_in - 3][-1], TypeDict['id'][s_in - 2]]
                    trans['after'] = [TypeDict['id'][s_in]]
                    transwithin.append(trans)
            elif s_in - 3 >= 0 and TypeDict['tag'][
                s_in - 3] == 'origin':  # ['origin', 'roadData', 'networkC', 'serviceObj']
                if len(TypeDict['id'][s_in - 3]) == 2:  # [['grid', 'centroid'], 'roadData', 'networkC', 'serviceObj']
                    trans['before'] = [TypeDict['id'][s_in - 3][0]]
                    trans['after'] = [TypeDict['id'][s_in - 3][1]]
                    transwithin.append(trans)
                trans = {}
                trans['before'] = [TypeDict['id'][s_in - 3][-1], TypeDict['id'][s_in - 2]]
                trans['after'] = [TypeDict['id'][s_in]]
                transwithin.append(trans)
            elif s_in - 2 >= 0 and TypeDict['tag'][
                s_in - 2] == 'origin':  # ['origin', 'roadData', 'serviceObj']
                if len(TypeDict['id'][s_in - 3]) == 2:  # [['grid', 'centroid'], 'roadData', 'serviceObj']
                    trans['before'] = [TypeDict['id'][s_in - 3][0]]
                    trans['after'] = [TypeDict['id'][s_in - 3][1]]
                    transwithin.append(trans)
                trans = {}
                trans['before'] = [TypeDict['id'][s_in - 2][-1], TypeDict['id'][s_in - 1]]
                trans['after'] = [TypeDict['id'][s_in]]
                transwithin.append(trans)
        elif tt == 'networkC' and (
                'destination' in TypeDict['tag'] or 'origin' in TypeDict['tag']) and 'serviceObj' not in TypeDict[
            'tag']:
            n_in = TypeDict['tag'].index(tt)
            trans = {}
            if n_in - 2 >= 0 and TypeDict['tag'][n_in - 2] == 'destination':
                if n_in - 3 >= 0 and TypeDict['tag'][
                    n_in - 3] == 'origin':  # ['origin', 'destination', 'roadData', 'networkC']
                    if len(TypeDict['id'][
                               n_in - 3]) == 2:  # [['grid', 'centroid'], 'destination', 'roadData', 'networkC']
                        trans['before'] = [TypeDict['id'][n_in - 3][0]]
                        trans['after'] = [TypeDict['id'][n_in - 3][1]]
                        transwithin.append(trans)
                    # origin: TypeDict['id'][n_in - 3], destination: TypeDict['id'][n_in - 2], roadData:TypeDict['id'][n_in - 1]
                    trans = {}
                    trans['before'] = [TypeDict['id'][n_in - 3][-1], TypeDict['id'][n_in - 2][-1], TypeDict['id'][n_in - 1]]
                    trans['after'] = [TypeDict['id'][n_in]]
                    transwithin.append(trans)
                elif n_in - 3 < 0 or not TypeDict['tag'][
                                             n_in - 3] == 'origin':  # ['destination', 'roadData', 'networkC']
                    trans['before'] = [TypeDict['id'][n_in - 2][-1], TypeDict['id'][n_in - 1]]
                    trans['after'] = [TypeDict['id'][n_in]]
                    transwithin.append(trans)
            elif n_in - 2 >= 0 and TypeDict['tag'][n_in - 2] == 'origin':  # ['origin', 'roadData', 'networkC']
                if len(TypeDict['id'][n_in - 2]) == 2:  # [['grid', 'centroid'], 'roadData', 'networkC']
                    trans['before'] = [TypeDict['id'][n_in - 2][0]]
                    trans['after'] = [TypeDict['id'][n_in - 2][1]]
                    transwithin.append(trans)
                trans = {}
                trans['before'] = [TypeDict['id'][n_in - 2][-1], TypeDict['id'][n_in - 1]]
                trans['after'] = [TypeDict['id'][n_in]]
                transwithin.append(trans)
            elif n_in - 1 >= 0 and TypeDict['tag'][n_in - 1] == 'origin':
                trans = {}
                trans['before'] = [TypeDict['id'][n_in - 1][0]]
                trans['after'] = [TypeDict['id'][n_in]]
                transwithin.append(trans)
        # elif tt == 'compareR' or tt == 'extremaR':
        #     if TypeDict['tag'].index(tt) + 1 < len(TypeDict['tag']):
        #         trans = {}
        #         trans['before'] = [TypeDict['id'][TypeDict['tag'].index(tt) + 1]]
        #         trans['after'] = [TypeDict['id'][TypeDict['tag'].index(tt) + 1] + wsign]
        #         transwithin.append(trans)
        #         wsign += '_w'
        #     else:
        #         trans = {}
        #         trans['before'] = [TypeDict['id'][TypeDict['tag'].index(tt) - 1]]
        #         trans['after'] = [TypeDict['id'][TypeDict['tag'].index(tt) - 1] + wsign]
        #         transwithin.append(trans)
        #         wsign += '_w'
        elif tt == 'coreC':
            trans = {}
            if 'destination' in TypeDict['tag']:
                if 'origin' in TypeDict['tag']:  # access score
                    oin = TypeDict['tag'].index('origin')
                    if len(TypeDict['id'][oin]) == 2:
                        trans['before'] = [TypeDict['id'][oin][0]]
                        trans['after'] = [TypeDict['id'][oin][1]]
                        transwithin.append(trans)
                    trans = {}
                    trans['before'] = [TypeDict['id'][oin][-1], TypeDict['id'][TypeDict['tag'].index('destination')][-1]]
                    trans['after'] = [TypeDict['id'][TypeDict['tag'].index('coreC')]]
                    transwithin.append(trans)
                elif 'origin' not in TypeDict['tag']:  # Euclidean distance to object
                    trans = {}
                    trans['before'] = [TypeDict['id'][TypeDict['tag'].index('destination')][-1]]
                    trans['after'] = [TypeDict['id'][TypeDict['tag'].index('coreC')]]
                    transwithin.append(trans)
            else:
                if coreC_sign == 1:
                    continue
                else:
                    coreC_loc = [x for x,y in enumerate(TypeDict['tag']) if y == 'coreC']
                    for coreC_l in coreC_loc:
                        if coreC_l < coreC_loc[-1]:
                            trans = {}
                            trans['before'] = [TypeDict['id'][coreC_l]]
                            trans['after'] = [TypeDict['id'][coreC_l + 1]]
                            transwithin.append(trans)
                coreC_sign = 1

    return transwithin


# Input coreTypeDict(coreTypes):
#   {'funcRole': ['condition', 'condition', 'measure', 'extent', 'temEx'],
# 	 'types': [{'tag': ['coreC', 'distField', 'boolField'], 'text': ['object 1', 'from', ''], 'id': ['0', '1', '2']},
# 			   {'tag': ['coreC'], 'text': ['objectquality 0 boolean'], 'id': ['3']},
# 			   {'tag': ['coreC'], 'text': ['object 0'], 'id': ['4']},
# 			   ['Utrecht'],
# 			   ['2030']]}
# coreTransType = coreConTrans
def write_trans(coreTypeDict, coreTransType):

    try:
        global core_id
        coretrans = []
        subis = []
        conis = []
        supis = []
        meais = []
        mea1is = []
        con_supis = []
        con_meais = []
        mc = []  # if condition number = 2, need to combine m*condition1 and m*condition2
        sign = '_u'

        if 'subcon' in coreTypeDict['funcRole']:
            subis = [x for x, y in enumerate(coreTypeDict['funcRole']) if y == 'subcon']
        if 'condition' in coreTypeDict['funcRole']:
            conis = [x for x, y in enumerate(coreTypeDict['funcRole']) if (y == 'condition' and coreTypeDict['types'][x]['tag'])]
        if 'support' in coreTypeDict['funcRole']:
            supis = [x for x, y in enumerate(coreTypeDict['funcRole']) if y == 'support']
        if 'measure' in coreTypeDict['funcRole']:
            meais = [x for x, y in enumerate(coreTypeDict['funcRole']) if y == 'measure']
        if 'measure1' in coreTypeDict['funcRole']:
            mea1is = [x for x, y in enumerate(coreTypeDict['funcRole']) if y == 'measure1']

        if supis:
            conar = numpy.array(conis)
            supar = numpy.array(supis)
            con_supis = list(conar[conar < supar])
            con_meais = [x for x in conis if x not in con_supis]
        else:
            con_meais = conis

        if subis:
            if len(coreTypeDict['types'][subis[0]]['tag']) > 1:
                sub_trans = write_trans_within(coreTypeDict['types'][subis[0]])
                coretrans.extend(sub_trans)
            if coreTypeDict['funcRole'][subis[0]+1] == 'condition':
                transcross = {}
                transcross['before'] = [coreTypeDict['types'][subis[0]+1]['id'][0], coreTypeDict['types'][subis[0]]['id'][-1]]
                transcross['after'] = [coreTypeDict['types'][subis[0]+1]['id'][0] + sign]
                coreTypeDict['types'][subis[0]+1]['id'][0] = transcross['after'][0]
                sign += '_u'
                coretrans.append(transcross)

        if con_supis:
            if len(coreTypeDict['types'][con_supis[0]]['tag']) > 1:
                con_sup_trans = write_trans_within(coreTypeDict['types'][con_supis[0]])
                coretrans.extend(con_sup_trans[0])
            transcross = {}
            transcross['before'] = [coreTypeDict['types'][supis[0]]['id'][0], coreTypeDict['types'][con_supis[0]]['id'][-1]]
            transcross['after'] = [coreTypeDict['types'][supis[0]]['id'][0] + sign]
            coreTypeDict['types'][supis[0]]['id'][0] = transcross['after'][0]
            sign += '_u'
            coretrans.append(transcross)

        if supis and len(coreTypeDict['types'][supis[0]]['tag']) > 1:
            sup_trans = write_trans_within(coreTypeDict['types'][supis[0]])
            coretrans.extend(sup_trans)

        if con_meais:
            for ci in con_meais:
                if any('proportion' in e for e in coreTypeDict['types'][ci]['text']):
                    amount_id = coreTypeDict['types'][ci]['id'][0:-1]
                    if amount_id:
                        transcross = {}
                        transcross['before'] = amount_id
                        transcross['after'] = [coreTypeDict['types'][ci]['id'][-1]]
                        coretrans.append(transcross)
                elif len(coreTypeDict['types'][ci]['tag']) > 1 and not any('aggre' in e for e in coreTypeDict['types'][ci]['tag']) and not any('proportion' in e for e in coreTypeDict['types'][ci]['text']) :
                    con_mea_trans = write_trans_within(coreTypeDict['types'][ci])
                    # coreTypeDict['types'][ci]['id'][-1] = con_mea_trans[-1]['after'][0]
                    coretrans.extend(con_mea_trans)
                elif any('aggre' in e for e in coreTypeDict['types'][ci]['tag']):
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][ci]['id'][-2]]
                    transcross['after'] = [coreTypeDict['types'][ci]['id'][-1]]
                    coretrans.append(transcross)

        if meais:
            if any('proportion' in e for e in coreTypeDict['types'][meais[0]]['text']):
                # for m in coreTypeDict['types'][meais[0]]['text']:  # if measure = proportion, turn object into objconAmount
                #     if m.startswith('object'):  # object -> object content amount
                #         mi = coreTypeDict['types'][meais[0]]['text'].index(m)
                #         mid = coreTypeDict['types'][meais[0]]['id'][mi]
                #         for ele in coreTransType['types']:
                #             if ele['id'] == mid:
                #                 ele['type'] = 'objconamount'
                #                 ele['keyword'] = 'number of ' + ele['keyword']
                #                 ele['measureLevel'] = 'count'
                #     elif m.startswith('event'):  # event -> event content amount
                #         mi = coreTypeDict['types'][meais[0]]['text'].index(m)
                #         mid = coreTypeDict['types'][meais[0]]['id'][mi]
                #         for ele in coreTransType['types']:
                #             if ele['id'] == mid:
                #                 ele['type'] = 'eveconamount'
                #                 ele['keyword'] = 'number of ' + ele['keyword']
                #                 ele['measureLevel'] = 'count'
                amount_id = coreTypeDict['types'][meais[0]]['id'][0:-1]
                if amount_id:
                    if supis and not con_meais:
                        for a in amount_id:
                            transcross = {}  # objconA * support
                            transcross['before'] = [a, coreTypeDict['types'][supis[0]]['id'][-1]]
                            transcross['after'] = [a + sign]
                            coreTypeDict['types'][meais[0]]['id'][coreTypeDict['types'][meais[0]]['id'].index(a)] = transcross['after'][0]
                            sign += '_u'
                            coretrans.append(transcross)
                        if not mea1is:
                            transcross = {}  # objconA * objconA  = proportion
                            transcross['before'] = coreTypeDict['types'][meais[0]]['id'][0:-1]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            coretrans.append(transcross)
                        elif mea1is:
                            a1 = coreTypeDict['types'][mea1is[0]]['id'][-1]
                            transcross = {}
                            transcross['before'] = [a1, coreTypeDict['types'][supis[0]]['id'][-1]]
                            transcross['after'] = [a1 + sign]
                            coreTypeDict['types'][mea1is[0]]['id'][coreTypeDict['types'][mea1is[0]]['id'].index(a1)] = \
                            transcross['after'][0]
                            sign += '_u'
                            coretrans.append(transcross)
                            transcross = {}  # objconA * objconA  = proportion
                            transcross['before'] = [ coreTypeDict['types'][meais[0]]['id'][0], coreTypeDict['types'][mea1is[0]]['id'][-1]]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            coretrans.append(transcross)
                    elif con_meais and not supis:
                        transcross = {}  # objconA * condi = objconA_u  or field * condi = field_u
                        transcross['before'] = [coreTypeDict['types'][con_meais[0]]['id'][-1],
                                                coreTypeDict['types'][meais[0]]['id'][0]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign]
                        coretrans.append(transcross)
                        if mea1is:
                            transcross = {}
                            transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign,
                                                        coreTypeDict['types'][mea1is[0]]['id'][0]]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            coretrans.append(transcross)
                            sign += '_u'
                        else:
                            if any('conamount' in e for e in coreTypeDict['types'][meais[0]]['text']):
                                transcross = {}  # objconA_u * objconA = proportion for [condition, objconA, proportion]
                                transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign,
                                                        coreTypeDict['types'][meais[0]]['id'][0]]
                                transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                                coretrans.append(transcross)
                                sign += '_u'
                            elif any('field' in e for e in coreTypeDict['types'][meais[0]]['text']):
                                transcross = {}  # field -> field coverage amount
                                transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign]
                                transcross['after'] = [str(core_id)]
                                coretrans.append(transcross)
                                coreTransType.setdefault('types', []).append(
                                    {'type': ['covamount'], 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                                core_id += 1
                                # condition -> conidtion coverage amount
                                transcross = {}
                                transcross['before'] = [coreTypeDict['types'][con_meais[0]]['id'][-1]]
                                transcross['after'] = [str(core_id)]
                                coretrans.append(transcross)
                                coreTransType.setdefault('types', []).append(
                                    {'type': ['covamount'], 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                                # field coverage amount * condition coverage amount = proportion
                                transcross = {}
                                transcross['before'] = [str(core_id - 1), str(core_id)]
                                transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                                coretrans.append(transcross)
                                core_id += 1
                                sign += '_u'
                            else:
                                transcross = {}  # object_u -> object_u amount
                                transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign]
                                transcross['after'] = [str(core_id)]
                                coretrans.append(transcross)
                                coreTransType.setdefault('types', []).append(
                                    {'type': ['amount'], 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                                core_id += 1
                                # condition -> conidtion coverage amount
                                transcross = {}  # object -> object amount
                                transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                                transcross['after'] = [str(core_id)]
                                coretrans.append(transcross)
                                coreTransType.setdefault('types', []).append(
                                    {'type': ['amount'], 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                                # field coverage amount * condition coverage amount = proportion
                                transcross = {}
                                transcross['before'] = [str(core_id - 1), str(core_id)]
                                transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                                coretrans.append(transcross)
                                core_id += 1
                                sign += '_u'
                    # elif supis and con_meais:  # edate problem
                    elif not supis and not con_meais:  # What is the percentage of noise polluted areas in placename0
                        if any('field' in e for e in coreTypeDict['types'][meais[0]]['text']):
                            transcross = {}
                            transcross['before'] = [coreTypeDict['types'][meais[0]]['text'][0]]
                            transcross['after'] = [str(core_id)]
                            coretrans.append(transcross)
                            coreTransType.setdefault('types', []).append(
                                {'type': ['covamount'], 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                            core_id += 1
                            transcross = {}
                            transcross['before'] = ['extent']
                            transcross['after'] = [str(core_id)]
                            coretrans.append(transcross)
                            coreTransType.setdefault('types', []).append(
                                {'type': ['covamount'], 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                            transcross = {}
                            transcross['before'] = [str(core_id - 1), 'extent']
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            coretrans.append(transcross)
                            core_id += 1
            elif any('covpro' in e for e in coreTypeDict['types'][meais[0]]['text']) and not any('objcovpro' in e for e in coreTypeDict['types'][meais[0]]['text']) and len(
                    coreTypeDict['types'][meais[0]]['text']) > 1:
                covRe_id = coreTypeDict['types'][meais[0]]['id'][0:-1]
                if supis and not con_meais:  # density of robberies for each police beat
                    # support -> support coverage amount
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][supis[0]]['id'][-1]]
                    transcross['after'] = [str(core_id)]
                    coretrans.append(transcross)
                    coreTransType.setdefault('types', []).append(
                        {'type': ['covamount'], 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                    core_id += 1
                    if any('amount' in e for e in coreTypeDict['types'][meais[0]]['text'][0:-1]):
                        # objconamount * support = objconamount_u
                        transcross = {}
                        transcross['before'] = [covRe_id[0], coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [covRe_id[0] + sign]
                        coretrans.append(transcross)
                        coreTypeDict['types'][meais[0]]['id'][coreTypeDict['types'][meais[0]]['id'].index(covRe_id[0])] = \
                        transcross['after'][0]
                        sign += '_u'
                        # objconamount_u * support coverage amount = covpro
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0:-1][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                    else:
                        # robberies * support = robberies amount; sometime is content amount, sometime is coverage amount
                        transcross = {}
                        transcross['before'] = [covRe_id[0], coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [str(core_id)]
                        coretrans.append(transcross)
                        coreTransType.setdefault('types', []).append(
                            {'type': ['amount'], 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                        # robberies amount * support coverage amount = covpro
                        transcross = {}
                        transcross['before'] = [str(core_id), str(core_id - 1)]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                        core_id += 1
                elif not supis and not con_meais:  # density of rental units in placename
                    # extent -> extent coverage amount
                    transcross = {}
                    transcross['before'] = ['extent']
                    transcross['after'] = [str(core_id)]
                    coretrans.append(transcross)
                    coreTransType.setdefault('types', []).append(
                        {'type': ['covamount'], 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                    core_id += 1
                    if not any('amount' in e for e in coreTypeDict['types'][meais[0]]['text'][0:-1]):
                        # objconamount * extent coverage amount = covpro
                        transcross = {}
                        transcross['before'] = [covRe_id[0], str(core_id - 1)]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                    else:
                        # robberies * extent = robberies amount; sometime is content amount, sometime is coverage amount
                        transcross = {}
                        transcross['before'] = [covRe_id[0], str(core_id - 1)]
                        transcross['after'] = [str(core_id)]
                        coretrans.append(transcross)
                        coreTransType.setdefault('types', []).append(
                            {'type': ['amount'], 'id': str(core_id), 'keyword': '', 'measureLevel': 'era'})
                        # robberies amount * extent coverage amount = covpro
                        transcross = {}
                        transcross['before'] = [str(core_id), str(core_id - 1)]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                        core_id += 1
            elif any('conamount' in e for e in coreTypeDict['types'][meais[0]]['text']) and not any(
                    'aggre' in e for e in coreTypeDict['types'][meais[0]]['tag']) and not any(
                'proportion' in e for e in coreTypeDict['types'][meais[0]]['text']) and not any(
                'covpro' in e for e in coreTypeDict['types'][meais[0]]['text']):
                if supis and not con_meais:
                    if len(coreTypeDict['types'][meais[0]]['tag']) > 1:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                            coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                    else:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign]
                        coretrans.append(transcross)
                        sign += '_u'
                elif con_meais and not supis:
                    if len(coreTypeDict['types'][meais[0]]['tag']) > 1:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][con_meais[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign]
                        coreTypeDict['types'][meais[0]]['id'][0] = transcross['after'][0]
                        coretrans.append(transcross)
                        sign += '_u'
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                    else:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][con_meais[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign]
                        coretrans.append(transcross)
                        sign += '_u'
            elif any('covamount' in e for e in coreTypeDict['types'][meais[0]]['text']) and not any(
                    'aggre' in e for e in coreTypeDict['types'][meais[0]]['tag']):
                if not supis and not con_meais:
                    cov_trans = write_trans_within(coreTypeDict['types'][meais[0]])
                    coretrans.extend(cov_trans)
                elif supis and not con_meais:
                    if 'location' in coreTypeDict['types'][meais[0]]['tag']:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-2]]
                        coretrans.append(transcross)
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][-2]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                    else:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                elif con_meais and not supis:
                    if 'location' in coreTypeDict['types'][meais[0]]['tag']:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][conis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-2]]
                        coretrans.append(transcross)
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][-2]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                    else:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][conis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                elif supis and con_meais:
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                            coreTypeDict['types'][supis[0]]['id'][-1]]
                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][1]]
                    coretrans.append(transcross)
                    if 'location' in coreTypeDict['types'][meais[0]]['tag']:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
            elif any('aggre' in e for e in coreTypeDict['types'][meais[0]]['tag']):
                if len(coreTypeDict['types'][meais[0]]['tag']) - 1 > 1:
                    befagg_trans = write_trans_within(coreTypeDict['types'][meais[0]])
                    coretrans.extend(befagg_trans)
                if supis:
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][-2],
                                            coreTypeDict['types'][supis[0]]['id'][-1]]
                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                    coretrans.append(transcross)
                elif con_meais:
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][-2],coreTypeDict['types'][con_meais[0]]['id'][-1]]
                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                    coretrans.append(transcross)
                else:
                    transcross = {}
                    transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][-2]]
                    transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                    coretrans.append(transcross)
            else:
                if supis and not con_meais:
                    if len(coreTypeDict['types'][meais[0]]['id']) == 1:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign]
                        coretrans.append(transcross)
                        sign += '_u'
                    else:
                        transcross = {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][supis[0]]['id'][-1]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                        coretrans.append(transcross)
                elif con_meais and not supis:
                    for ci in con_meais:
                        # if len(coreTypeDict['types'][ci]['tag']) == 1 and (coreTypeDict['types'][ci]['tag'][0] == 'extremaR' or coreTypeDict['types'][ci]['tag'][0] == 'compareR'):
                        #     transcross = {}
                        #     transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                        #     transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign]
                        #     coretrans.append(transcross)
                        # else:
                        if coreTypeDict['types'][meais[0]]['tag'][0] == 'location' or coreTypeDict['types'][meais[0]]['tag'][0] == 'allocation':
                            transcross = {}
                            transcross['before'] = [coreTypeDict['types'][ci]['id'][-1]]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][-1]]
                            coretrans.append(transcross)
                        else:
                            transcross = {}
                            transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0],
                                                coreTypeDict['types'][ci]['id'][-1]]
                            transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign]
                            coretrans.append(transcross)
                            sign += '_u'
                        if len(coreTypeDict['types'][meais[0]]['tag']) > 1:
                            coreTypeDict['types'][meais[0]]['id'][0] = transcross['after'][0]
                            mea_trans = write_trans_within(coreTypeDict['types'][meais[0]])
                            if len(con_meais) > 1:
                                mea_trans[-1]['after'][0] = mea_trans[-1]['after'][0] + sign
                            coretrans.extend(mea_trans)
                            mc.append(mea_trans[-1]['after'][0])
                            sign += '_u'
                        else:
                            mc.append(transcross['after'][0])
                    if len(mc) > 1:
                        transcross = {}
                        transcross['before'] = mc
                        transcross['after'] = [mc[0][0] + sign]
                        coretrans.append(transcross)
                else:
                    if len(coreTypeDict['types'][meais[0]]['tag']) > 1:
                        mea_trans = write_trans_within(coreTypeDict['types'][meais[0]])
                        coretrans.extend(mea_trans)
                    else:
                        transcross= {}
                        transcross['before'] = [coreTypeDict['types'][meais[0]]['id'][0]]
                        transcross['after'] = [coreTypeDict['types'][meais[0]]['id'][0] + sign]
                        coretrans.append(transcross)
                        sign += '_u'


        coreTransType.setdefault('transformation', []).extend(coretrans)

        print(coreTransType)

    except:
        coreTransType['transformation'] = []

    return coreTransType


if __name__ == '__main__':
    results = []
    # testresults = []
    nlp_en = CustomEnglish()  # [X] Load English stopwords
    nlp = en_core_web_sm.load()  # load en_core_web_sm of English for NER, noun chunks
    matcher = PhraseMatcher(nlp.vocab)  # add noun phrases when doing noun_chunks
    patterns = [nlp('bus stops'), nlp('driving time'), nlp('grid cell'), nlp('grid cells'), nlp('off street paths'),
                nlp('degree of clustering'), nlp('degree of dispersion'), nlp('fire call'), nlp('fire calls'),
                nlp('wetlands'), nlp('house totals'), nlp('fire hydrant'), nlp('fire scene'), nlp('fire scenes'),
                nlp('owner occupied houses'), nlp('temperature in celsius'), nlp('police beat'), nlp('police beats'),
                nlp('tornado touchdowns'), nlp('nurse practitioner services'), nlp('priority rankings'),
                nlp('plumbing'), nlp('political leaning'), nlp('predicted probability surface'), nlp('fire accidents'),
                nlp('for sale'), nlp('open at'), nlp('predicted distribution probability'), nlp('age of people'),
                nlp('income of households'), nlp('interpolated surface'), nlp('average cost per acre'),
                nlp('wind farm proposals'), nlp('planned commercial district'), nlp('protected region'),
                nlp('aspect'), nlp('monthly rainfall'), nlp('hot spots and cold spots'), nlp('per household online loan application rates'),
                nlp('mean annual PM 2.5 concentration'), nlp('PM 2.5 concentration'), nlp('cesium 137 concentration')]
    # phrases missed by noun_chunks, add manually
    # [nlp('911 calls'), nlp('precinct'), nlp('forest areas'), nlp('flower stores'), nlp('alarm territory'), nlp('airport')]
    matcher.add("PHRASES", patterns)

    predictorELMo = Predictor.from_path(
        "https://storage.googleapis.com/allennlp-public-models/ner-model-2020.02.10.tar.gz")  # Allennlp Elmo-based NER

    # [X] Read question file
    questionFilepath = 'corpus.txt'
    errorQuestionFilePath = 'error.txt'
    error_ques = open(errorQuestionFilePath, 'w+')

    # [X] Read place type set
    ptypePath = 'Dictionary/place_type.txt'
    pt_set = set(line.strip() for line in open(ptypePath, encoding="utf-8"))

    # [X] Read core concept dictionary
    corePath = 'Dictionary/coreConceptsML.txt'
    coreCon_dict = load_ccdict(corePath)
    networkPath = 'Dictionary/network.txt'
    networkSet = set(l.strip() for l in open(networkPath, encoding="utf-8"))

    pos = []
    distWords = {'meter', 'meters', 'km', 'kilometers', 'kilometer', 'mile', 'miles'}
    humanWords = {'people', 'population', 'children'}
    amsign = {'have', 'has', 'had', 'no'}
    compR = ['lower than','larger than','at least','less than','more than','greater than','greater than or equal to','smaller than','equal to']
    cn = {'least cost route', 'least cost path', 'least costly route', 'least costly path', 'driving time',
          'travel time', 'forest areas', 'for sale', 'open at', 'shortest network based paths', 'hot spots and cold spots',
          'cesium 137 concentration', 'PM2.5 concentration'}
    removeWords = {'what', 'where', 'which', 'how', 'for', 'each', 'when', 'who', 'why', 'new', 'no', 'similar',
                   'nearest', 'most', 'to', 'at', 'low', 'high'}
    que_stru = {'measure', 'measure1', 'condition', 'subcon', 'support'}
    gen_coreC = {'distField', 'serviceObj'}


    with open(questionFilepath, encoding="utf-8") as questions:
        for question in questions:
            try:
                result = {}
                # testresult = {}
                core_id = 0
                sym = '" ? \n \t'
                result['question'] = question.strip(sym)
                # testresult['question'] = question.strip(sym)
                print('---------Question---------')
                print(question)

                # [X] Tokenization
                doc = nlp_en(result['question'])

                # [X] Cleaning text: remove stopwords and save the tokens in a list
                # text = ' '.join([word for word in text if word not in string.punctuation])
                token_list = []
                for word in doc:
                    if not word.is_stop and not word.is_punct or word.text == ',':
                        token_list.append(word)
                sen = ' '.join(word.text for word in token_list).strip()  # Question in string without stopwords
                sen_Clean = word2num(sen)  # Convert numeric words into digit numbers
                result['cleaned_Question'] = sen_Clean

                # XIdentify place names
                re_Place = place_ner(sen_Clean)
                result['placename'] = re_Place[0]  # re_Place[0]: list - PlaceName

                # [X] Identify Date, Time, Quantity, Cardinal, Percent
                re_Entities = entity_ner(re_Place[1])  # parsed_Place[1]: sentence
                result.update(re_Entities[0])  # parsed_Entities[0]: dictionary - Time, Quantity, Percent, Date

                # [X] Identify Core Concept
                re_CoreCon = core_concept_match(re_Entities[1].lower())  # parsed_Entities[1]: sentence
                result.update(re_CoreCon[0])  # re_CoreCon[0]: dictionary - Core Concepts
                result['ner_Question'] = re_CoreCon[1]  # re_CoreCon[1] : sentence with core concepts holders

                # [X] Generate parser tree & Extract core concept transformation
                parsedQuestion = geo_parser(re_CoreCon[1])
                if parsedQuestion[0]:
                    result['parseTreeStr'] = parsedQuestion[0]
                if parsedQuestion[3]:
                    error_ques.write(parsedQuestion[3] + '\n')  # questions can not be parsed in the grammar
                if parsedQuestion[1] and parsedQuestion[2]:
                    result['cctrans'] = write_trans(parsedQuestion[1], parsedQuestion[2])
                    # testresult['cctrans'] = result['cctrans']

                # print(result)

                results.append(result)
                # testresults.append(testresult)
            except:
                ques_incorrect = question
                error_ques.write(ques_incorrect + '\n')



    with open('Results_test_Auto.json', 'w') as outputFile:
        json.dump(results, outputFile)

    # with open('Results_test_Manual.json', 'w') as outputFileTest:
    #     json.dump(testresults, outputFileTest)

    error_ques.close()